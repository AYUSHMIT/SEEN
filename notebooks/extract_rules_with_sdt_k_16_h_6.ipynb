{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from queue import LifoQueue\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import network.cpc\n",
    "from network.cpc import CDCK2\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from utils.ClassificationUtiols import onehot_coding\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn import tree as tt\n",
    "\n",
    "# IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: /home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_16/models/epoch_28.pt\n",
      "sensor names: (18 total)\n",
      "- speed\n",
      "- steering_angle\n",
      "- wheel_speed_0\n",
      "- wheel_speed_1\n",
      "- wheel_speed_2\n",
      "- wheel_speed_3\n",
      "- accelerometer_0\n",
      "- accelerometer_1\n",
      "- accelerometer_2\n",
      "- gyro_0\n",
      "- gyro_1\n",
      "- gyro_2\n",
      "- gyro_bias_0\n",
      "- gyro_bias_1\n",
      "- gyro_bias_2\n",
      "- gyro_uncalibrated_0\n",
      "- gyro_uncalibrated_1\n",
      "- gyro_uncalibrated_2\n",
      "Multihorizon size of the model: 30\n",
      "Test split ratio: 0.2\n",
      "Total number of windows in the dataset (without splitting): 101465\n"
     ]
    }
   ],
   "source": [
    "model_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_16/models/epoch_28.pt'\n",
    "dataset_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_16/data/test_data.file'\n",
    "\n",
    "print(f\"Load the model from: {model_path}\")\n",
    "model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "with open(dataset_path, 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "all_sensors = dataset.dataset.all_signals    \n",
    "print(f\"sensor names: ({len(all_sensors)} total)\")\n",
    "\n",
    "for s in all_sensors:\n",
    "    print(f\"- {s}\")\n",
    "    \n",
    "print(f\"Multihorizon size of the model: {model.timestep}\")\n",
    "print(f\"Test split ratio: {len(dataset) / len(dataset.dataset)}\")\n",
    "print(f\"Total number of windows in the dataset (without splitting): {len(dataset.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6059fb549f14380838978acd77425be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20293.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projections = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "device = 'cuda'\n",
    "model = model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(total=len(loader.dataset))\n",
    "    for batch in loader:\n",
    "        hidden = CDCK2.init_hidden(len(batch))\n",
    "        batch = batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        y = model.predict(batch, hidden).detach().cpu()\n",
    "        projections = torch.cat([projections, y.detach().cpu()])\n",
    "        samples = torch.cat([samples, batch.detach().cpu()])\n",
    "        bar.update(y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM and calculate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b0ddcceab64f0795d8a839d499d1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "best_score = float('inf')\n",
    "clusters = None\n",
    "range_ = list(range(5, 80))\n",
    "for k in tqdm(range_):\n",
    "    y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "    cur_score = davies_bouldin_score(projections, y)\n",
    "    scores.append(cur_score)\n",
    "    \n",
    "    if cur_score < best_score:\n",
    "        best_score = cur_score\n",
    "        clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('DB Score')\n",
    "plt.plot(range_, scores)\n",
    "best_k = range_[np.argmin(scores)]\n",
    "plt.axvline(best_k, color='r')\n",
    "plt.show()\n",
    "\n",
    "labels = set(clusters)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 200\n",
    "\n",
    "p = reduce_dims_and_plot(projections,\n",
    "                         y=clusters,\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnormalized_samples = samples.clone()\n",
    "\n",
    "# for col, sensor in enumerate(tqdm(dataset.dataset.all_signals)):\n",
    "#     denormalizer = dataset.dataset.get_denormalization_for_sensor(sensor)\n",
    "#     unnormalized_samples[:, col, :] = denormalizer(unnormalized_samples[:, col, :])\n",
    "\n",
    "sampled = samples[..., range(0, samples.shape[-1], 200)]\n",
    "\n",
    "samples_f = sampled.flatten(1)\n",
    "tree_dataset = list(zip(samples_f, clusters))\n",
    "batch_size = 2000\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 500\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "tree_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT accuracy: 0.9065194894791307\n"
     ]
    }
   ],
   "source": [
    "tree = SDT(input_dim=samples_f.shape[1], output_dim=len(labels), depth=tree_depth, lamda=1e-3, use_cuda=True)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)\n",
    "clf = DecisionTreeClassifier(max_depth=tree_depth).fit(samples_f, clusters)\n",
    "print(f\"DT accuracy: {clf.score(samples_f, clusters)}\")\n",
    "tree.initialize_from_decision_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.8947645356485137\n",
      "layer 0: 0.988950276243094\n",
      "layer 1: 0.988950276243094\n",
      "layer 2: 0.988950276243094\n",
      "layer 3: 0.988950276243094\n",
      "layer 4: 0.9271408839779005\n",
      "Epoch: 00 | Batch: 000 / 011 | Total loss: 2.818 | Reg loss: 0.013 | Tree loss: 2.818 | Accuracy: 0.088500 | 0.202 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 011 | Total loss: 2.809 | Reg loss: 0.013 | Tree loss: 2.809 | Accuracy: 0.112000 | 0.167 sec/iter\n",
      "Epoch: 00 | Batch: 002 / 011 | Total loss: 2.797 | Reg loss: 0.013 | Tree loss: 2.797 | Accuracy: 0.149500 | 0.153 sec/iter\n",
      "Epoch: 00 | Batch: 003 / 011 | Total loss: 2.792 | Reg loss: 0.013 | Tree loss: 2.792 | Accuracy: 0.132000 | 0.143 sec/iter\n",
      "Epoch: 00 | Batch: 004 / 011 | Total loss: 2.784 | Reg loss: 0.013 | Tree loss: 2.784 | Accuracy: 0.232000 | 0.134 sec/iter\n",
      "Epoch: 00 | Batch: 005 / 011 | Total loss: 2.772 | Reg loss: 0.013 | Tree loss: 2.772 | Accuracy: 0.230500 | 0.129 sec/iter\n",
      "Epoch: 00 | Batch: 006 / 011 | Total loss: 2.763 | Reg loss: 0.013 | Tree loss: 2.763 | Accuracy: 0.244000 | 0.126 sec/iter\n",
      "Epoch: 00 | Batch: 007 / 011 | Total loss: 2.751 | Reg loss: 0.013 | Tree loss: 2.751 | Accuracy: 0.258000 | 0.122 sec/iter\n",
      "Epoch: 00 | Batch: 008 / 011 | Total loss: 2.748 | Reg loss: 0.013 | Tree loss: 2.748 | Accuracy: 0.245500 | 0.12 sec/iter\n",
      "Epoch: 00 | Batch: 009 / 011 | Total loss: 2.739 | Reg loss: 0.014 | Tree loss: 2.739 | Accuracy: 0.256000 | 0.119 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 011 | Total loss: 2.721 | Reg loss: 0.014 | Tree loss: 2.721 | Accuracy: 0.262799 | 0.117 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 01 | Batch: 000 / 011 | Total loss: 2.794 | Reg loss: 0.013 | Tree loss: 2.794 | Accuracy: 0.210000 | 0.121 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 011 | Total loss: 2.783 | Reg loss: 0.013 | Tree loss: 2.783 | Accuracy: 0.309500 | 0.119 sec/iter\n",
      "Epoch: 01 | Batch: 002 / 011 | Total loss: 2.775 | Reg loss: 0.013 | Tree loss: 2.775 | Accuracy: 0.306500 | 0.118 sec/iter\n",
      "Epoch: 01 | Batch: 003 / 011 | Total loss: 2.768 | Reg loss: 0.013 | Tree loss: 2.768 | Accuracy: 0.274500 | 0.116 sec/iter\n",
      "Epoch: 01 | Batch: 004 / 011 | Total loss: 2.753 | Reg loss: 0.013 | Tree loss: 2.753 | Accuracy: 0.279000 | 0.115 sec/iter\n",
      "Epoch: 01 | Batch: 005 / 011 | Total loss: 2.738 | Reg loss: 0.013 | Tree loss: 2.738 | Accuracy: 0.297500 | 0.114 sec/iter\n",
      "Epoch: 01 | Batch: 006 / 011 | Total loss: 2.730 | Reg loss: 0.013 | Tree loss: 2.730 | Accuracy: 0.269500 | 0.113 sec/iter\n",
      "Epoch: 01 | Batch: 007 / 011 | Total loss: 2.708 | Reg loss: 0.013 | Tree loss: 2.708 | Accuracy: 0.289000 | 0.113 sec/iter\n",
      "Epoch: 01 | Batch: 008 / 011 | Total loss: 2.713 | Reg loss: 0.013 | Tree loss: 2.713 | Accuracy: 0.261000 | 0.112 sec/iter\n",
      "Epoch: 01 | Batch: 009 / 011 | Total loss: 2.707 | Reg loss: 0.014 | Tree loss: 2.707 | Accuracy: 0.246000 | 0.111 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 011 | Total loss: 2.702 | Reg loss: 0.014 | Tree loss: 2.702 | Accuracy: 0.249147 | 0.11 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 02 | Batch: 000 / 011 | Total loss: 2.774 | Reg loss: 0.013 | Tree loss: 2.774 | Accuracy: 0.268500 | 0.11 sec/iter\n",
      "Epoch: 02 | Batch: 001 / 011 | Total loss: 2.759 | Reg loss: 0.013 | Tree loss: 2.759 | Accuracy: 0.296500 | 0.108 sec/iter\n",
      "Epoch: 02 | Batch: 002 / 011 | Total loss: 2.741 | Reg loss: 0.013 | Tree loss: 2.741 | Accuracy: 0.313500 | 0.109 sec/iter\n",
      "Epoch: 02 | Batch: 003 / 011 | Total loss: 2.731 | Reg loss: 0.013 | Tree loss: 2.731 | Accuracy: 0.289000 | 0.11 sec/iter\n",
      "Epoch: 02 | Batch: 004 / 011 | Total loss: 2.719 | Reg loss: 0.013 | Tree loss: 2.719 | Accuracy: 0.278000 | 0.111 sec/iter\n",
      "Epoch: 02 | Batch: 005 / 011 | Total loss: 2.702 | Reg loss: 0.013 | Tree loss: 2.702 | Accuracy: 0.281000 | 0.112 sec/iter\n",
      "Epoch: 02 | Batch: 006 / 011 | Total loss: 2.695 | Reg loss: 0.013 | Tree loss: 2.695 | Accuracy: 0.263000 | 0.113 sec/iter\n",
      "Epoch: 02 | Batch: 007 / 011 | Total loss: 2.688 | Reg loss: 0.013 | Tree loss: 2.688 | Accuracy: 0.258500 | 0.113 sec/iter\n",
      "Epoch: 02 | Batch: 008 / 011 | Total loss: 2.669 | Reg loss: 0.014 | Tree loss: 2.669 | Accuracy: 0.270000 | 0.114 sec/iter\n",
      "Epoch: 02 | Batch: 009 / 011 | Total loss: 2.658 | Reg loss: 0.014 | Tree loss: 2.658 | Accuracy: 0.267000 | 0.114 sec/iter\n",
      "Epoch: 02 | Batch: 010 / 011 | Total loss: 2.654 | Reg loss: 0.014 | Tree loss: 2.654 | Accuracy: 0.266212 | 0.115 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 03 | Batch: 000 / 011 | Total loss: 2.746 | Reg loss: 0.013 | Tree loss: 2.746 | Accuracy: 0.300000 | 0.132 sec/iter\n",
      "Epoch: 03 | Batch: 001 / 011 | Total loss: 2.730 | Reg loss: 0.013 | Tree loss: 2.730 | Accuracy: 0.301000 | 0.132 sec/iter\n",
      "Epoch: 03 | Batch: 002 / 011 | Total loss: 2.714 | Reg loss: 0.013 | Tree loss: 2.714 | Accuracy: 0.288500 | 0.131 sec/iter\n",
      "Epoch: 03 | Batch: 003 / 011 | Total loss: 2.701 | Reg loss: 0.013 | Tree loss: 2.701 | Accuracy: 0.283500 | 0.131 sec/iter\n",
      "Epoch: 03 | Batch: 004 / 011 | Total loss: 2.688 | Reg loss: 0.013 | Tree loss: 2.688 | Accuracy: 0.264000 | 0.13 sec/iter\n",
      "Epoch: 03 | Batch: 005 / 011 | Total loss: 2.657 | Reg loss: 0.013 | Tree loss: 2.657 | Accuracy: 0.294500 | 0.129 sec/iter\n",
      "Epoch: 03 | Batch: 006 / 011 | Total loss: 2.648 | Reg loss: 0.014 | Tree loss: 2.648 | Accuracy: 0.284500 | 0.129 sec/iter\n",
      "Epoch: 03 | Batch: 007 / 011 | Total loss: 2.634 | Reg loss: 0.014 | Tree loss: 2.634 | Accuracy: 0.275500 | 0.128 sec/iter\n",
      "Epoch: 03 | Batch: 008 / 011 | Total loss: 2.624 | Reg loss: 0.014 | Tree loss: 2.624 | Accuracy: 0.273500 | 0.128 sec/iter\n",
      "Epoch: 03 | Batch: 009 / 011 | Total loss: 2.620 | Reg loss: 0.014 | Tree loss: 2.620 | Accuracy: 0.268500 | 0.127 sec/iter\n",
      "Epoch: 03 | Batch: 010 / 011 | Total loss: 2.609 | Reg loss: 0.015 | Tree loss: 2.609 | Accuracy: 0.286689 | 0.127 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 04 | Batch: 000 / 011 | Total loss: 2.711 | Reg loss: 0.013 | Tree loss: 2.711 | Accuracy: 0.308500 | 0.14 sec/iter\n",
      "Epoch: 04 | Batch: 001 / 011 | Total loss: 2.702 | Reg loss: 0.013 | Tree loss: 2.702 | Accuracy: 0.285000 | 0.139 sec/iter\n",
      "Epoch: 04 | Batch: 002 / 011 | Total loss: 2.681 | Reg loss: 0.013 | Tree loss: 2.681 | Accuracy: 0.285500 | 0.138 sec/iter\n",
      "Epoch: 04 | Batch: 003 / 011 | Total loss: 2.647 | Reg loss: 0.014 | Tree loss: 2.647 | Accuracy: 0.307500 | 0.137 sec/iter\n",
      "Epoch: 04 | Batch: 004 / 011 | Total loss: 2.648 | Reg loss: 0.014 | Tree loss: 2.648 | Accuracy: 0.272500 | 0.136 sec/iter\n",
      "Epoch: 04 | Batch: 005 / 011 | Total loss: 2.626 | Reg loss: 0.014 | Tree loss: 2.626 | Accuracy: 0.280500 | 0.135 sec/iter\n",
      "Epoch: 04 | Batch: 006 / 011 | Total loss: 2.605 | Reg loss: 0.014 | Tree loss: 2.605 | Accuracy: 0.278500 | 0.134 sec/iter\n",
      "Epoch: 04 | Batch: 007 / 011 | Total loss: 2.599 | Reg loss: 0.014 | Tree loss: 2.599 | Accuracy: 0.271000 | 0.133 sec/iter\n",
      "Epoch: 04 | Batch: 008 / 011 | Total loss: 2.573 | Reg loss: 0.015 | Tree loss: 2.573 | Accuracy: 0.282500 | 0.133 sec/iter\n",
      "Epoch: 04 | Batch: 009 / 011 | Total loss: 2.559 | Reg loss: 0.015 | Tree loss: 2.559 | Accuracy: 0.280500 | 0.132 sec/iter\n",
      "Epoch: 04 | Batch: 010 / 011 | Total loss: 2.585 | Reg loss: 0.015 | Tree loss: 2.585 | Accuracy: 0.245734 | 0.132 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 05 | Batch: 000 / 011 | Total loss: 2.681 | Reg loss: 0.014 | Tree loss: 2.681 | Accuracy: 0.300000 | 0.132 sec/iter\n",
      "Epoch: 05 | Batch: 001 / 011 | Total loss: 2.658 | Reg loss: 0.014 | Tree loss: 2.658 | Accuracy: 0.306500 | 0.132 sec/iter\n",
      "Epoch: 05 | Batch: 002 / 011 | Total loss: 2.626 | Reg loss: 0.014 | Tree loss: 2.626 | Accuracy: 0.322000 | 0.131 sec/iter\n",
      "Epoch: 05 | Batch: 003 / 011 | Total loss: 2.622 | Reg loss: 0.014 | Tree loss: 2.622 | Accuracy: 0.275000 | 0.131 sec/iter\n",
      "Epoch: 05 | Batch: 004 / 011 | Total loss: 2.606 | Reg loss: 0.014 | Tree loss: 2.606 | Accuracy: 0.272000 | 0.13 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Batch: 005 / 011 | Total loss: 2.580 | Reg loss: 0.015 | Tree loss: 2.580 | Accuracy: 0.281500 | 0.13 sec/iter\n",
      "Epoch: 05 | Batch: 006 / 011 | Total loss: 2.559 | Reg loss: 0.015 | Tree loss: 2.559 | Accuracy: 0.281500 | 0.129 sec/iter\n",
      "Epoch: 05 | Batch: 007 / 011 | Total loss: 2.549 | Reg loss: 0.015 | Tree loss: 2.549 | Accuracy: 0.269500 | 0.128 sec/iter\n",
      "Epoch: 05 | Batch: 008 / 011 | Total loss: 2.532 | Reg loss: 0.015 | Tree loss: 2.532 | Accuracy: 0.273500 | 0.128 sec/iter\n",
      "Epoch: 05 | Batch: 009 / 011 | Total loss: 2.523 | Reg loss: 0.016 | Tree loss: 2.523 | Accuracy: 0.272500 | 0.127 sec/iter\n",
      "Epoch: 05 | Batch: 010 / 011 | Total loss: 2.516 | Reg loss: 0.016 | Tree loss: 2.516 | Accuracy: 0.269625 | 0.127 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 06 | Batch: 000 / 011 | Total loss: 2.648 | Reg loss: 0.014 | Tree loss: 2.648 | Accuracy: 0.302500 | 0.127 sec/iter\n",
      "Epoch: 06 | Batch: 001 / 011 | Total loss: 2.622 | Reg loss: 0.015 | Tree loss: 2.622 | Accuracy: 0.293000 | 0.126 sec/iter\n",
      "Epoch: 06 | Batch: 002 / 011 | Total loss: 2.594 | Reg loss: 0.015 | Tree loss: 2.594 | Accuracy: 0.307500 | 0.126 sec/iter\n",
      "Epoch: 06 | Batch: 003 / 011 | Total loss: 2.566 | Reg loss: 0.015 | Tree loss: 2.566 | Accuracy: 0.309500 | 0.126 sec/iter\n",
      "Epoch: 06 | Batch: 004 / 011 | Total loss: 2.553 | Reg loss: 0.015 | Tree loss: 2.553 | Accuracy: 0.282500 | 0.125 sec/iter\n",
      "Epoch: 06 | Batch: 005 / 011 | Total loss: 2.526 | Reg loss: 0.015 | Tree loss: 2.526 | Accuracy: 0.282000 | 0.125 sec/iter\n",
      "Epoch: 06 | Batch: 006 / 011 | Total loss: 2.508 | Reg loss: 0.016 | Tree loss: 2.508 | Accuracy: 0.281000 | 0.125 sec/iter\n",
      "Epoch: 06 | Batch: 007 / 011 | Total loss: 2.498 | Reg loss: 0.016 | Tree loss: 2.498 | Accuracy: 0.276000 | 0.125 sec/iter\n",
      "Epoch: 06 | Batch: 008 / 011 | Total loss: 2.489 | Reg loss: 0.016 | Tree loss: 2.489 | Accuracy: 0.271500 | 0.124 sec/iter\n",
      "Epoch: 06 | Batch: 009 / 011 | Total loss: 2.484 | Reg loss: 0.016 | Tree loss: 2.484 | Accuracy: 0.270000 | 0.124 sec/iter\n",
      "Epoch: 06 | Batch: 010 / 011 | Total loss: 2.455 | Reg loss: 0.017 | Tree loss: 2.455 | Accuracy: 0.290102 | 0.124 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 07 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.015 | Tree loss: 2.602 | Accuracy: 0.311500 | 0.132 sec/iter\n",
      "Epoch: 07 | Batch: 001 / 011 | Total loss: 2.575 | Reg loss: 0.015 | Tree loss: 2.575 | Accuracy: 0.301500 | 0.131 sec/iter\n",
      "Epoch: 07 | Batch: 002 / 011 | Total loss: 2.573 | Reg loss: 0.015 | Tree loss: 2.573 | Accuracy: 0.274000 | 0.131 sec/iter\n",
      "Epoch: 07 | Batch: 003 / 011 | Total loss: 2.529 | Reg loss: 0.016 | Tree loss: 2.529 | Accuracy: 0.281000 | 0.131 sec/iter\n",
      "Epoch: 07 | Batch: 004 / 011 | Total loss: 2.514 | Reg loss: 0.016 | Tree loss: 2.514 | Accuracy: 0.268000 | 0.13 sec/iter\n",
      "Epoch: 07 | Batch: 005 / 011 | Total loss: 2.483 | Reg loss: 0.016 | Tree loss: 2.483 | Accuracy: 0.273500 | 0.13 sec/iter\n",
      "Epoch: 07 | Batch: 006 / 011 | Total loss: 2.460 | Reg loss: 0.016 | Tree loss: 2.460 | Accuracy: 0.296000 | 0.13 sec/iter\n",
      "Epoch: 07 | Batch: 007 / 011 | Total loss: 2.451 | Reg loss: 0.017 | Tree loss: 2.451 | Accuracy: 0.281000 | 0.13 sec/iter\n",
      "Epoch: 07 | Batch: 008 / 011 | Total loss: 2.427 | Reg loss: 0.017 | Tree loss: 2.427 | Accuracy: 0.281500 | 0.129 sec/iter\n",
      "Epoch: 07 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.017 | Tree loss: 2.410 | Accuracy: 0.288000 | 0.129 sec/iter\n",
      "Epoch: 07 | Batch: 010 / 011 | Total loss: 2.414 | Reg loss: 0.017 | Tree loss: 2.414 | Accuracy: 0.273038 | 0.129 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 08 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.016 | Tree loss: 2.583 | Accuracy: 0.280500 | 0.135 sec/iter\n",
      "Epoch: 08 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.016 | Tree loss: 2.545 | Accuracy: 0.292000 | 0.135 sec/iter\n",
      "Epoch: 08 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.016 | Tree loss: 2.517 | Accuracy: 0.292000 | 0.134 sec/iter\n",
      "Epoch: 08 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.016 | Tree loss: 2.480 | Accuracy: 0.294500 | 0.134 sec/iter\n",
      "Epoch: 08 | Batch: 004 / 011 | Total loss: 2.448 | Reg loss: 0.017 | Tree loss: 2.448 | Accuracy: 0.301500 | 0.134 sec/iter\n",
      "Epoch: 08 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.017 | Tree loss: 2.440 | Accuracy: 0.296000 | 0.133 sec/iter\n",
      "Epoch: 08 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.017 | Tree loss: 2.410 | Accuracy: 0.296500 | 0.132 sec/iter\n",
      "Epoch: 08 | Batch: 007 / 011 | Total loss: 2.395 | Reg loss: 0.017 | Tree loss: 2.395 | Accuracy: 0.299500 | 0.132 sec/iter\n",
      "Epoch: 08 | Batch: 008 / 011 | Total loss: 2.375 | Reg loss: 0.018 | Tree loss: 2.375 | Accuracy: 0.302500 | 0.132 sec/iter\n",
      "Epoch: 08 | Batch: 009 / 011 | Total loss: 2.366 | Reg loss: 0.018 | Tree loss: 2.366 | Accuracy: 0.294500 | 0.131 sec/iter\n",
      "Epoch: 08 | Batch: 010 / 011 | Total loss: 2.378 | Reg loss: 0.018 | Tree loss: 2.378 | Accuracy: 0.269625 | 0.131 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 09 | Batch: 000 / 011 | Total loss: 2.530 | Reg loss: 0.017 | Tree loss: 2.530 | Accuracy: 0.308000 | 0.131 sec/iter\n",
      "Epoch: 09 | Batch: 001 / 011 | Total loss: 2.488 | Reg loss: 0.017 | Tree loss: 2.488 | Accuracy: 0.325000 | 0.131 sec/iter\n",
      "Epoch: 09 | Batch: 002 / 011 | Total loss: 2.469 | Reg loss: 0.017 | Tree loss: 2.469 | Accuracy: 0.305000 | 0.13 sec/iter\n",
      "Epoch: 09 | Batch: 003 / 011 | Total loss: 2.449 | Reg loss: 0.017 | Tree loss: 2.449 | Accuracy: 0.289500 | 0.13 sec/iter\n",
      "Epoch: 09 | Batch: 004 / 011 | Total loss: 2.415 | Reg loss: 0.017 | Tree loss: 2.415 | Accuracy: 0.300500 | 0.129 sec/iter\n",
      "Epoch: 09 | Batch: 005 / 011 | Total loss: 2.395 | Reg loss: 0.018 | Tree loss: 2.395 | Accuracy: 0.313000 | 0.128 sec/iter\n",
      "Epoch: 09 | Batch: 006 / 011 | Total loss: 2.368 | Reg loss: 0.018 | Tree loss: 2.368 | Accuracy: 0.325000 | 0.128 sec/iter\n",
      "Epoch: 09 | Batch: 007 / 011 | Total loss: 2.345 | Reg loss: 0.018 | Tree loss: 2.345 | Accuracy: 0.326000 | 0.127 sec/iter\n",
      "Epoch: 09 | Batch: 008 / 011 | Total loss: 2.328 | Reg loss: 0.018 | Tree loss: 2.328 | Accuracy: 0.332500 | 0.127 sec/iter\n",
      "Epoch: 09 | Batch: 009 / 011 | Total loss: 2.313 | Reg loss: 0.019 | Tree loss: 2.313 | Accuracy: 0.336000 | 0.127 sec/iter\n",
      "Epoch: 09 | Batch: 010 / 011 | Total loss: 2.304 | Reg loss: 0.019 | Tree loss: 2.304 | Accuracy: 0.303754 | 0.126 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 10 | Batch: 000 / 011 | Total loss: 2.490 | Reg loss: 0.018 | Tree loss: 2.490 | Accuracy: 0.327000 | 0.126 sec/iter\n",
      "Epoch: 10 | Batch: 001 / 011 | Total loss: 2.449 | Reg loss: 0.018 | Tree loss: 2.449 | Accuracy: 0.337500 | 0.126 sec/iter\n",
      "Epoch: 10 | Batch: 002 / 011 | Total loss: 2.438 | Reg loss: 0.018 | Tree loss: 2.438 | Accuracy: 0.308500 | 0.126 sec/iter\n",
      "Epoch: 10 | Batch: 003 / 011 | Total loss: 2.398 | Reg loss: 0.018 | Tree loss: 2.398 | Accuracy: 0.334000 | 0.125 sec/iter\n",
      "Epoch: 10 | Batch: 004 / 011 | Total loss: 2.357 | Reg loss: 0.018 | Tree loss: 2.357 | Accuracy: 0.352000 | 0.125 sec/iter\n",
      "Epoch: 10 | Batch: 005 / 011 | Total loss: 2.349 | Reg loss: 0.019 | Tree loss: 2.349 | Accuracy: 0.333000 | 0.125 sec/iter\n",
      "Epoch: 10 | Batch: 006 / 011 | Total loss: 2.312 | Reg loss: 0.019 | Tree loss: 2.312 | Accuracy: 0.357000 | 0.124 sec/iter\n",
      "Epoch: 10 | Batch: 007 / 011 | Total loss: 2.292 | Reg loss: 0.019 | Tree loss: 2.292 | Accuracy: 0.348000 | 0.124 sec/iter\n",
      "Epoch: 10 | Batch: 008 / 011 | Total loss: 2.276 | Reg loss: 0.019 | Tree loss: 2.276 | Accuracy: 0.352000 | 0.124 sec/iter\n",
      "Epoch: 10 | Batch: 009 / 011 | Total loss: 2.287 | Reg loss: 0.020 | Tree loss: 2.287 | Accuracy: 0.319000 | 0.123 sec/iter\n",
      "Epoch: 10 | Batch: 010 / 011 | Total loss: 2.291 | Reg loss: 0.020 | Tree loss: 2.291 | Accuracy: 0.327645 | 0.123 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 11 | Batch: 000 / 011 | Total loss: 2.444 | Reg loss: 0.019 | Tree loss: 2.444 | Accuracy: 0.342000 | 0.123 sec/iter\n",
      "Epoch: 11 | Batch: 001 / 011 | Total loss: 2.414 | Reg loss: 0.019 | Tree loss: 2.414 | Accuracy: 0.338500 | 0.123 sec/iter\n",
      "Epoch: 11 | Batch: 002 / 011 | Total loss: 2.386 | Reg loss: 0.019 | Tree loss: 2.386 | Accuracy: 0.353000 | 0.122 sec/iter\n",
      "Epoch: 11 | Batch: 003 / 011 | Total loss: 2.358 | Reg loss: 0.019 | Tree loss: 2.358 | Accuracy: 0.349000 | 0.122 sec/iter\n",
      "Epoch: 11 | Batch: 004 / 011 | Total loss: 2.315 | Reg loss: 0.019 | Tree loss: 2.315 | Accuracy: 0.354500 | 0.121 sec/iter\n",
      "Epoch: 11 | Batch: 005 / 011 | Total loss: 2.289 | Reg loss: 0.019 | Tree loss: 2.289 | Accuracy: 0.357000 | 0.121 sec/iter\n",
      "Epoch: 11 | Batch: 006 / 011 | Total loss: 2.282 | Reg loss: 0.020 | Tree loss: 2.282 | Accuracy: 0.339000 | 0.121 sec/iter\n",
      "Epoch: 11 | Batch: 007 / 011 | Total loss: 2.248 | Reg loss: 0.020 | Tree loss: 2.248 | Accuracy: 0.353500 | 0.12 sec/iter\n",
      "Epoch: 11 | Batch: 008 / 011 | Total loss: 2.247 | Reg loss: 0.020 | Tree loss: 2.247 | Accuracy: 0.346500 | 0.12 sec/iter\n",
      "Epoch: 11 | Batch: 009 / 011 | Total loss: 2.239 | Reg loss: 0.020 | Tree loss: 2.239 | Accuracy: 0.339000 | 0.12 sec/iter\n",
      "Epoch: 11 | Batch: 010 / 011 | Total loss: 2.241 | Reg loss: 0.021 | Tree loss: 2.241 | Accuracy: 0.344710 | 0.119 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 12 | Batch: 000 / 011 | Total loss: 2.411 | Reg loss: 0.019 | Tree loss: 2.411 | Accuracy: 0.343500 | 0.123 sec/iter\n",
      "Epoch: 12 | Batch: 001 / 011 | Total loss: 2.375 | Reg loss: 0.020 | Tree loss: 2.375 | Accuracy: 0.375000 | 0.123 sec/iter\n",
      "Epoch: 12 | Batch: 002 / 011 | Total loss: 2.335 | Reg loss: 0.020 | Tree loss: 2.335 | Accuracy: 0.389000 | 0.123 sec/iter\n",
      "Epoch: 12 | Batch: 003 / 011 | Total loss: 2.301 | Reg loss: 0.020 | Tree loss: 2.301 | Accuracy: 0.375500 | 0.123 sec/iter\n",
      "Epoch: 12 | Batch: 004 / 011 | Total loss: 2.292 | Reg loss: 0.020 | Tree loss: 2.292 | Accuracy: 0.357500 | 0.123 sec/iter\n",
      "Epoch: 12 | Batch: 005 / 011 | Total loss: 2.238 | Reg loss: 0.020 | Tree loss: 2.238 | Accuracy: 0.381000 | 0.122 sec/iter\n",
      "Epoch: 12 | Batch: 006 / 011 | Total loss: 2.254 | Reg loss: 0.020 | Tree loss: 2.254 | Accuracy: 0.333500 | 0.122 sec/iter\n",
      "Epoch: 12 | Batch: 007 / 011 | Total loss: 2.205 | Reg loss: 0.021 | Tree loss: 2.205 | Accuracy: 0.357500 | 0.122 sec/iter\n",
      "Epoch: 12 | Batch: 008 / 011 | Total loss: 2.192 | Reg loss: 0.021 | Tree loss: 2.192 | Accuracy: 0.374000 | 0.122 sec/iter\n",
      "Epoch: 12 | Batch: 009 / 011 | Total loss: 2.179 | Reg loss: 0.021 | Tree loss: 2.179 | Accuracy: 0.386500 | 0.122 sec/iter\n",
      "Epoch: 12 | Batch: 010 / 011 | Total loss: 2.146 | Reg loss: 0.021 | Tree loss: 2.146 | Accuracy: 0.416382 | 0.121 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 13 | Batch: 000 / 011 | Total loss: 2.369 | Reg loss: 0.020 | Tree loss: 2.369 | Accuracy: 0.354000 | 0.126 sec/iter\n",
      "Epoch: 13 | Batch: 001 / 011 | Total loss: 2.344 | Reg loss: 0.020 | Tree loss: 2.344 | Accuracy: 0.363500 | 0.126 sec/iter\n",
      "Epoch: 13 | Batch: 002 / 011 | Total loss: 2.286 | Reg loss: 0.020 | Tree loss: 2.286 | Accuracy: 0.396000 | 0.126 sec/iter\n",
      "Epoch: 13 | Batch: 003 / 011 | Total loss: 2.264 | Reg loss: 0.021 | Tree loss: 2.264 | Accuracy: 0.378000 | 0.125 sec/iter\n",
      "Epoch: 13 | Batch: 004 / 011 | Total loss: 2.244 | Reg loss: 0.021 | Tree loss: 2.244 | Accuracy: 0.354500 | 0.125 sec/iter\n",
      "Epoch: 13 | Batch: 005 / 011 | Total loss: 2.191 | Reg loss: 0.021 | Tree loss: 2.191 | Accuracy: 0.374000 | 0.125 sec/iter\n",
      "Epoch: 13 | Batch: 006 / 011 | Total loss: 2.203 | Reg loss: 0.021 | Tree loss: 2.203 | Accuracy: 0.344000 | 0.125 sec/iter\n",
      "Epoch: 13 | Batch: 007 / 011 | Total loss: 2.155 | Reg loss: 0.021 | Tree loss: 2.155 | Accuracy: 0.381000 | 0.124 sec/iter\n",
      "Epoch: 13 | Batch: 008 / 011 | Total loss: 2.169 | Reg loss: 0.022 | Tree loss: 2.169 | Accuracy: 0.372500 | 0.124 sec/iter\n",
      "Epoch: 13 | Batch: 009 / 011 | Total loss: 2.139 | Reg loss: 0.022 | Tree loss: 2.139 | Accuracy: 0.384500 | 0.124 sec/iter\n",
      "Epoch: 13 | Batch: 010 / 011 | Total loss: 2.116 | Reg loss: 0.022 | Tree loss: 2.116 | Accuracy: 0.382253 | 0.124 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 14 | Batch: 000 / 011 | Total loss: 2.303 | Reg loss: 0.021 | Tree loss: 2.303 | Accuracy: 0.395500 | 0.125 sec/iter\n",
      "Epoch: 14 | Batch: 001 / 011 | Total loss: 2.302 | Reg loss: 0.021 | Tree loss: 2.302 | Accuracy: 0.369500 | 0.125 sec/iter\n",
      "Epoch: 14 | Batch: 002 / 011 | Total loss: 2.261 | Reg loss: 0.021 | Tree loss: 2.261 | Accuracy: 0.379500 | 0.125 sec/iter\n",
      "Epoch: 14 | Batch: 003 / 011 | Total loss: 2.223 | Reg loss: 0.021 | Tree loss: 2.223 | Accuracy: 0.390500 | 0.124 sec/iter\n",
      "Epoch: 14 | Batch: 004 / 011 | Total loss: 2.197 | Reg loss: 0.022 | Tree loss: 2.197 | Accuracy: 0.366000 | 0.124 sec/iter\n",
      "Epoch: 14 | Batch: 005 / 011 | Total loss: 2.163 | Reg loss: 0.022 | Tree loss: 2.163 | Accuracy: 0.374500 | 0.124 sec/iter\n",
      "Epoch: 14 | Batch: 006 / 011 | Total loss: 2.150 | Reg loss: 0.022 | Tree loss: 2.150 | Accuracy: 0.361500 | 0.124 sec/iter\n",
      "Epoch: 14 | Batch: 007 / 011 | Total loss: 2.131 | Reg loss: 0.022 | Tree loss: 2.131 | Accuracy: 0.380000 | 0.123 sec/iter\n",
      "Epoch: 14 | Batch: 008 / 011 | Total loss: 2.093 | Reg loss: 0.022 | Tree loss: 2.093 | Accuracy: 0.403500 | 0.123 sec/iter\n",
      "Epoch: 14 | Batch: 009 / 011 | Total loss: 2.100 | Reg loss: 0.023 | Tree loss: 2.100 | Accuracy: 0.402000 | 0.123 sec/iter\n",
      "Epoch: 14 | Batch: 010 / 011 | Total loss: 2.130 | Reg loss: 0.023 | Tree loss: 2.130 | Accuracy: 0.395904 | 0.123 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 15 | Batch: 000 / 011 | Total loss: 2.268 | Reg loss: 0.022 | Tree loss: 2.268 | Accuracy: 0.391000 | 0.123 sec/iter\n",
      "Epoch: 15 | Batch: 001 / 011 | Total loss: 2.255 | Reg loss: 0.022 | Tree loss: 2.255 | Accuracy: 0.383000 | 0.122 sec/iter\n",
      "Epoch: 15 | Batch: 002 / 011 | Total loss: 2.220 | Reg loss: 0.022 | Tree loss: 2.220 | Accuracy: 0.388000 | 0.122 sec/iter\n",
      "Epoch: 15 | Batch: 003 / 011 | Total loss: 2.182 | Reg loss: 0.022 | Tree loss: 2.182 | Accuracy: 0.381500 | 0.122 sec/iter\n",
      "Epoch: 15 | Batch: 004 / 011 | Total loss: 2.143 | Reg loss: 0.022 | Tree loss: 2.143 | Accuracy: 0.382000 | 0.121 sec/iter\n",
      "Epoch: 15 | Batch: 005 / 011 | Total loss: 2.134 | Reg loss: 0.023 | Tree loss: 2.134 | Accuracy: 0.378500 | 0.121 sec/iter\n",
      "Epoch: 15 | Batch: 006 / 011 | Total loss: 2.092 | Reg loss: 0.023 | Tree loss: 2.092 | Accuracy: 0.392000 | 0.121 sec/iter\n",
      "Epoch: 15 | Batch: 007 / 011 | Total loss: 2.098 | Reg loss: 0.023 | Tree loss: 2.098 | Accuracy: 0.398500 | 0.121 sec/iter\n",
      "Epoch: 15 | Batch: 008 / 011 | Total loss: 2.081 | Reg loss: 0.023 | Tree loss: 2.081 | Accuracy: 0.404000 | 0.12 sec/iter\n",
      "Epoch: 15 | Batch: 009 / 011 | Total loss: 2.046 | Reg loss: 0.023 | Tree loss: 2.046 | Accuracy: 0.413000 | 0.12 sec/iter\n",
      "Epoch: 15 | Batch: 010 / 011 | Total loss: 2.051 | Reg loss: 0.024 | Tree loss: 2.051 | Accuracy: 0.430034 | 0.12 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 16 | Batch: 000 / 011 | Total loss: 2.238 | Reg loss: 0.023 | Tree loss: 2.238 | Accuracy: 0.396500 | 0.12 sec/iter\n",
      "Epoch: 16 | Batch: 001 / 011 | Total loss: 2.217 | Reg loss: 0.023 | Tree loss: 2.217 | Accuracy: 0.384500 | 0.12 sec/iter\n",
      "Epoch: 16 | Batch: 002 / 011 | Total loss: 2.187 | Reg loss: 0.023 | Tree loss: 2.187 | Accuracy: 0.389500 | 0.12 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Batch: 003 / 011 | Total loss: 2.150 | Reg loss: 0.023 | Tree loss: 2.150 | Accuracy: 0.376000 | 0.12 sec/iter\n",
      "Epoch: 16 | Batch: 004 / 011 | Total loss: 2.101 | Reg loss: 0.023 | Tree loss: 2.101 | Accuracy: 0.385000 | 0.119 sec/iter\n",
      "Epoch: 16 | Batch: 005 / 011 | Total loss: 2.081 | Reg loss: 0.023 | Tree loss: 2.081 | Accuracy: 0.405500 | 0.119 sec/iter\n",
      "Epoch: 16 | Batch: 006 / 011 | Total loss: 2.047 | Reg loss: 0.023 | Tree loss: 2.047 | Accuracy: 0.434000 | 0.119 sec/iter\n",
      "Epoch: 16 | Batch: 007 / 011 | Total loss: 2.048 | Reg loss: 0.024 | Tree loss: 2.048 | Accuracy: 0.432500 | 0.119 sec/iter\n",
      "Epoch: 16 | Batch: 008 / 011 | Total loss: 2.032 | Reg loss: 0.024 | Tree loss: 2.032 | Accuracy: 0.430000 | 0.119 sec/iter\n",
      "Epoch: 16 | Batch: 009 / 011 | Total loss: 2.026 | Reg loss: 0.024 | Tree loss: 2.026 | Accuracy: 0.445500 | 0.118 sec/iter\n",
      "Epoch: 16 | Batch: 010 / 011 | Total loss: 2.013 | Reg loss: 0.024 | Tree loss: 2.013 | Accuracy: 0.453925 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 17 | Batch: 000 / 011 | Total loss: 2.188 | Reg loss: 0.023 | Tree loss: 2.188 | Accuracy: 0.401500 | 0.118 sec/iter\n",
      "Epoch: 17 | Batch: 001 / 011 | Total loss: 2.187 | Reg loss: 0.023 | Tree loss: 2.187 | Accuracy: 0.387000 | 0.118 sec/iter\n",
      "Epoch: 17 | Batch: 002 / 011 | Total loss: 2.133 | Reg loss: 0.024 | Tree loss: 2.133 | Accuracy: 0.407000 | 0.118 sec/iter\n",
      "Epoch: 17 | Batch: 003 / 011 | Total loss: 2.080 | Reg loss: 0.024 | Tree loss: 2.080 | Accuracy: 0.411500 | 0.117 sec/iter\n",
      "Epoch: 17 | Batch: 004 / 011 | Total loss: 2.081 | Reg loss: 0.024 | Tree loss: 2.081 | Accuracy: 0.393500 | 0.117 sec/iter\n",
      "Epoch: 17 | Batch: 005 / 011 | Total loss: 2.052 | Reg loss: 0.024 | Tree loss: 2.052 | Accuracy: 0.422500 | 0.117 sec/iter\n",
      "Epoch: 17 | Batch: 006 / 011 | Total loss: 2.036 | Reg loss: 0.024 | Tree loss: 2.036 | Accuracy: 0.427500 | 0.117 sec/iter\n",
      "Epoch: 17 | Batch: 007 / 011 | Total loss: 2.016 | Reg loss: 0.024 | Tree loss: 2.016 | Accuracy: 0.423500 | 0.117 sec/iter\n",
      "Epoch: 17 | Batch: 008 / 011 | Total loss: 1.996 | Reg loss: 0.025 | Tree loss: 1.996 | Accuracy: 0.425000 | 0.117 sec/iter\n",
      "Epoch: 17 | Batch: 009 / 011 | Total loss: 1.970 | Reg loss: 0.025 | Tree loss: 1.970 | Accuracy: 0.461000 | 0.116 sec/iter\n",
      "Epoch: 17 | Batch: 010 / 011 | Total loss: 1.991 | Reg loss: 0.025 | Tree loss: 1.991 | Accuracy: 0.474403 | 0.116 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 18 | Batch: 000 / 011 | Total loss: 2.160 | Reg loss: 0.024 | Tree loss: 2.160 | Accuracy: 0.409000 | 0.119 sec/iter\n",
      "Epoch: 18 | Batch: 001 / 011 | Total loss: 2.144 | Reg loss: 0.024 | Tree loss: 2.144 | Accuracy: 0.386000 | 0.119 sec/iter\n",
      "Epoch: 18 | Batch: 002 / 011 | Total loss: 2.111 | Reg loss: 0.024 | Tree loss: 2.111 | Accuracy: 0.388000 | 0.119 sec/iter\n",
      "Epoch: 18 | Batch: 003 / 011 | Total loss: 2.058 | Reg loss: 0.024 | Tree loss: 2.058 | Accuracy: 0.395000 | 0.119 sec/iter\n",
      "Epoch: 18 | Batch: 004 / 011 | Total loss: 2.036 | Reg loss: 0.025 | Tree loss: 2.036 | Accuracy: 0.425000 | 0.118 sec/iter\n",
      "Epoch: 18 | Batch: 005 / 011 | Total loss: 2.010 | Reg loss: 0.025 | Tree loss: 2.010 | Accuracy: 0.425500 | 0.118 sec/iter\n",
      "Epoch: 18 | Batch: 006 / 011 | Total loss: 1.981 | Reg loss: 0.025 | Tree loss: 1.981 | Accuracy: 0.431000 | 0.118 sec/iter\n",
      "Epoch: 18 | Batch: 007 / 011 | Total loss: 1.949 | Reg loss: 0.025 | Tree loss: 1.949 | Accuracy: 0.448500 | 0.118 sec/iter\n",
      "Epoch: 18 | Batch: 008 / 011 | Total loss: 1.966 | Reg loss: 0.025 | Tree loss: 1.966 | Accuracy: 0.422000 | 0.118 sec/iter\n",
      "Epoch: 18 | Batch: 009 / 011 | Total loss: 1.954 | Reg loss: 0.025 | Tree loss: 1.954 | Accuracy: 0.433500 | 0.118 sec/iter\n",
      "Epoch: 18 | Batch: 010 / 011 | Total loss: 1.975 | Reg loss: 0.025 | Tree loss: 1.975 | Accuracy: 0.453925 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 19 | Batch: 000 / 011 | Total loss: 2.154 | Reg loss: 0.025 | Tree loss: 2.154 | Accuracy: 0.374500 | 0.121 sec/iter\n",
      "Epoch: 19 | Batch: 001 / 011 | Total loss: 2.092 | Reg loss: 0.025 | Tree loss: 2.092 | Accuracy: 0.406000 | 0.121 sec/iter\n",
      "Epoch: 19 | Batch: 002 / 011 | Total loss: 2.068 | Reg loss: 0.025 | Tree loss: 2.068 | Accuracy: 0.392500 | 0.121 sec/iter\n",
      "Epoch: 19 | Batch: 003 / 011 | Total loss: 2.025 | Reg loss: 0.025 | Tree loss: 2.025 | Accuracy: 0.422000 | 0.121 sec/iter\n",
      "Epoch: 19 | Batch: 004 / 011 | Total loss: 1.996 | Reg loss: 0.025 | Tree loss: 1.996 | Accuracy: 0.428000 | 0.121 sec/iter\n",
      "Epoch: 19 | Batch: 005 / 011 | Total loss: 1.970 | Reg loss: 0.025 | Tree loss: 1.970 | Accuracy: 0.441500 | 0.12 sec/iter\n",
      "Epoch: 19 | Batch: 006 / 011 | Total loss: 1.942 | Reg loss: 0.025 | Tree loss: 1.942 | Accuracy: 0.445500 | 0.12 sec/iter\n",
      "Epoch: 19 | Batch: 007 / 011 | Total loss: 1.942 | Reg loss: 0.026 | Tree loss: 1.942 | Accuracy: 0.449000 | 0.12 sec/iter\n",
      "Epoch: 19 | Batch: 008 / 011 | Total loss: 1.909 | Reg loss: 0.026 | Tree loss: 1.909 | Accuracy: 0.446500 | 0.12 sec/iter\n",
      "Epoch: 19 | Batch: 009 / 011 | Total loss: 1.918 | Reg loss: 0.026 | Tree loss: 1.918 | Accuracy: 0.456000 | 0.12 sec/iter\n",
      "Epoch: 19 | Batch: 010 / 011 | Total loss: 1.943 | Reg loss: 0.026 | Tree loss: 1.943 | Accuracy: 0.409556 | 0.12 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 20 | Batch: 000 / 011 | Total loss: 2.095 | Reg loss: 0.025 | Tree loss: 2.095 | Accuracy: 0.391000 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 001 / 011 | Total loss: 2.086 | Reg loss: 0.025 | Tree loss: 2.086 | Accuracy: 0.392500 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 002 / 011 | Total loss: 2.051 | Reg loss: 0.026 | Tree loss: 2.051 | Accuracy: 0.368000 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 003 / 011 | Total loss: 1.976 | Reg loss: 0.026 | Tree loss: 1.976 | Accuracy: 0.445500 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 004 / 011 | Total loss: 1.963 | Reg loss: 0.026 | Tree loss: 1.963 | Accuracy: 0.446000 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 005 / 011 | Total loss: 1.931 | Reg loss: 0.026 | Tree loss: 1.931 | Accuracy: 0.444500 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 006 / 011 | Total loss: 1.903 | Reg loss: 0.026 | Tree loss: 1.903 | Accuracy: 0.446500 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 007 / 011 | Total loss: 1.898 | Reg loss: 0.026 | Tree loss: 1.898 | Accuracy: 0.446500 | 0.12 sec/iter\n",
      "Epoch: 20 | Batch: 008 / 011 | Total loss: 1.899 | Reg loss: 0.026 | Tree loss: 1.899 | Accuracy: 0.453500 | 0.119 sec/iter\n",
      "Epoch: 20 | Batch: 009 / 011 | Total loss: 1.879 | Reg loss: 0.026 | Tree loss: 1.879 | Accuracy: 0.469000 | 0.119 sec/iter\n",
      "Epoch: 20 | Batch: 010 / 011 | Total loss: 1.882 | Reg loss: 0.027 | Tree loss: 1.882 | Accuracy: 0.433447 | 0.119 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 21 | Batch: 000 / 011 | Total loss: 2.053 | Reg loss: 0.026 | Tree loss: 2.053 | Accuracy: 0.411000 | 0.119 sec/iter\n",
      "Epoch: 21 | Batch: 001 / 011 | Total loss: 2.052 | Reg loss: 0.026 | Tree loss: 2.052 | Accuracy: 0.376000 | 0.119 sec/iter\n",
      "Epoch: 21 | Batch: 002 / 011 | Total loss: 1.983 | Reg loss: 0.026 | Tree loss: 1.983 | Accuracy: 0.441000 | 0.119 sec/iter\n",
      "Epoch: 21 | Batch: 003 / 011 | Total loss: 1.957 | Reg loss: 0.026 | Tree loss: 1.957 | Accuracy: 0.423500 | 0.119 sec/iter\n",
      "Epoch: 21 | Batch: 004 / 011 | Total loss: 1.932 | Reg loss: 0.026 | Tree loss: 1.932 | Accuracy: 0.432500 | 0.119 sec/iter\n",
      "Epoch: 21 | Batch: 005 / 011 | Total loss: 1.913 | Reg loss: 0.026 | Tree loss: 1.913 | Accuracy: 0.442500 | 0.118 sec/iter\n",
      "Epoch: 21 | Batch: 006 / 011 | Total loss: 1.908 | Reg loss: 0.027 | Tree loss: 1.908 | Accuracy: 0.424000 | 0.118 sec/iter\n",
      "Epoch: 21 | Batch: 007 / 011 | Total loss: 1.872 | Reg loss: 0.027 | Tree loss: 1.872 | Accuracy: 0.447000 | 0.118 sec/iter\n",
      "Epoch: 21 | Batch: 008 / 011 | Total loss: 1.856 | Reg loss: 0.027 | Tree loss: 1.856 | Accuracy: 0.462000 | 0.118 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Batch: 009 / 011 | Total loss: 1.850 | Reg loss: 0.027 | Tree loss: 1.850 | Accuracy: 0.457000 | 0.118 sec/iter\n",
      "Epoch: 21 | Batch: 010 / 011 | Total loss: 1.814 | Reg loss: 0.027 | Tree loss: 1.814 | Accuracy: 0.457338 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 22 | Batch: 000 / 011 | Total loss: 2.029 | Reg loss: 0.027 | Tree loss: 2.029 | Accuracy: 0.402000 | 0.118 sec/iter\n",
      "Epoch: 22 | Batch: 001 / 011 | Total loss: 1.992 | Reg loss: 0.027 | Tree loss: 1.992 | Accuracy: 0.410000 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 002 / 011 | Total loss: 1.978 | Reg loss: 0.027 | Tree loss: 1.978 | Accuracy: 0.410000 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 003 / 011 | Total loss: 1.932 | Reg loss: 0.027 | Tree loss: 1.932 | Accuracy: 0.434000 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 004 / 011 | Total loss: 1.916 | Reg loss: 0.027 | Tree loss: 1.916 | Accuracy: 0.417500 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 005 / 011 | Total loss: 1.863 | Reg loss: 0.027 | Tree loss: 1.863 | Accuracy: 0.473000 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 006 / 011 | Total loss: 1.853 | Reg loss: 0.027 | Tree loss: 1.853 | Accuracy: 0.445500 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 007 / 011 | Total loss: 1.842 | Reg loss: 0.027 | Tree loss: 1.842 | Accuracy: 0.448500 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 008 / 011 | Total loss: 1.826 | Reg loss: 0.027 | Tree loss: 1.826 | Accuracy: 0.468500 | 0.117 sec/iter\n",
      "Epoch: 22 | Batch: 009 / 011 | Total loss: 1.830 | Reg loss: 0.028 | Tree loss: 1.830 | Accuracy: 0.457000 | 0.116 sec/iter\n",
      "Epoch: 22 | Batch: 010 / 011 | Total loss: 1.789 | Reg loss: 0.028 | Tree loss: 1.789 | Accuracy: 0.508532 | 0.116 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 23 | Batch: 000 / 011 | Total loss: 2.003 | Reg loss: 0.027 | Tree loss: 2.003 | Accuracy: 0.414000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 001 / 011 | Total loss: 1.959 | Reg loss: 0.027 | Tree loss: 1.959 | Accuracy: 0.418000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 002 / 011 | Total loss: 1.926 | Reg loss: 0.027 | Tree loss: 1.926 | Accuracy: 0.438000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 003 / 011 | Total loss: 1.930 | Reg loss: 0.027 | Tree loss: 1.930 | Accuracy: 0.413000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 004 / 011 | Total loss: 1.887 | Reg loss: 0.027 | Tree loss: 1.887 | Accuracy: 0.449000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 005 / 011 | Total loss: 1.853 | Reg loss: 0.028 | Tree loss: 1.853 | Accuracy: 0.445500 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 006 / 011 | Total loss: 1.787 | Reg loss: 0.028 | Tree loss: 1.787 | Accuracy: 0.479000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 007 / 011 | Total loss: 1.821 | Reg loss: 0.028 | Tree loss: 1.821 | Accuracy: 0.464000 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 008 / 011 | Total loss: 1.808 | Reg loss: 0.028 | Tree loss: 1.808 | Accuracy: 0.460500 | 0.119 sec/iter\n",
      "Epoch: 23 | Batch: 009 / 011 | Total loss: 1.776 | Reg loss: 0.028 | Tree loss: 1.776 | Accuracy: 0.487500 | 0.118 sec/iter\n",
      "Epoch: 23 | Batch: 010 / 011 | Total loss: 1.803 | Reg loss: 0.028 | Tree loss: 1.803 | Accuracy: 0.467577 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 24 | Batch: 000 / 011 | Total loss: 1.963 | Reg loss: 0.028 | Tree loss: 1.963 | Accuracy: 0.419000 | 0.121 sec/iter\n",
      "Epoch: 24 | Batch: 001 / 011 | Total loss: 1.932 | Reg loss: 0.028 | Tree loss: 1.932 | Accuracy: 0.426000 | 0.121 sec/iter\n",
      "Epoch: 24 | Batch: 002 / 011 | Total loss: 1.896 | Reg loss: 0.028 | Tree loss: 1.896 | Accuracy: 0.445000 | 0.121 sec/iter\n",
      "Epoch: 24 | Batch: 003 / 011 | Total loss: 1.892 | Reg loss: 0.028 | Tree loss: 1.892 | Accuracy: 0.447500 | 0.121 sec/iter\n",
      "Epoch: 24 | Batch: 004 / 011 | Total loss: 1.846 | Reg loss: 0.028 | Tree loss: 1.846 | Accuracy: 0.449000 | 0.121 sec/iter\n",
      "Epoch: 24 | Batch: 005 / 011 | Total loss: 1.824 | Reg loss: 0.028 | Tree loss: 1.824 | Accuracy: 0.458000 | 0.121 sec/iter\n",
      "Epoch: 24 | Batch: 006 / 011 | Total loss: 1.802 | Reg loss: 0.028 | Tree loss: 1.802 | Accuracy: 0.452500 | 0.12 sec/iter\n",
      "Epoch: 24 | Batch: 007 / 011 | Total loss: 1.797 | Reg loss: 0.028 | Tree loss: 1.797 | Accuracy: 0.478500 | 0.12 sec/iter\n",
      "Epoch: 24 | Batch: 008 / 011 | Total loss: 1.777 | Reg loss: 0.028 | Tree loss: 1.777 | Accuracy: 0.481500 | 0.12 sec/iter\n",
      "Epoch: 24 | Batch: 009 / 011 | Total loss: 1.756 | Reg loss: 0.029 | Tree loss: 1.756 | Accuracy: 0.488500 | 0.12 sec/iter\n",
      "Epoch: 24 | Batch: 010 / 011 | Total loss: 1.749 | Reg loss: 0.029 | Tree loss: 1.749 | Accuracy: 0.474403 | 0.12 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 25 | Batch: 000 / 011 | Total loss: 1.954 | Reg loss: 0.028 | Tree loss: 1.954 | Accuracy: 0.400500 | 0.122 sec/iter\n",
      "Epoch: 25 | Batch: 001 / 011 | Total loss: 1.915 | Reg loss: 0.028 | Tree loss: 1.915 | Accuracy: 0.433000 | 0.122 sec/iter\n",
      "Epoch: 25 | Batch: 002 / 011 | Total loss: 1.879 | Reg loss: 0.028 | Tree loss: 1.879 | Accuracy: 0.439000 | 0.122 sec/iter\n",
      "Epoch: 25 | Batch: 003 / 011 | Total loss: 1.844 | Reg loss: 0.028 | Tree loss: 1.844 | Accuracy: 0.469500 | 0.122 sec/iter\n",
      "Epoch: 25 | Batch: 004 / 011 | Total loss: 1.813 | Reg loss: 0.028 | Tree loss: 1.813 | Accuracy: 0.479500 | 0.122 sec/iter\n",
      "Epoch: 25 | Batch: 005 / 011 | Total loss: 1.782 | Reg loss: 0.029 | Tree loss: 1.782 | Accuracy: 0.477000 | 0.121 sec/iter\n",
      "Epoch: 25 | Batch: 006 / 011 | Total loss: 1.770 | Reg loss: 0.029 | Tree loss: 1.770 | Accuracy: 0.474500 | 0.121 sec/iter\n",
      "Epoch: 25 | Batch: 007 / 011 | Total loss: 1.758 | Reg loss: 0.029 | Tree loss: 1.758 | Accuracy: 0.481000 | 0.121 sec/iter\n",
      "Epoch: 25 | Batch: 008 / 011 | Total loss: 1.748 | Reg loss: 0.029 | Tree loss: 1.748 | Accuracy: 0.481500 | 0.121 sec/iter\n",
      "Epoch: 25 | Batch: 009 / 011 | Total loss: 1.748 | Reg loss: 0.029 | Tree loss: 1.748 | Accuracy: 0.483000 | 0.121 sec/iter\n",
      "Epoch: 25 | Batch: 010 / 011 | Total loss: 1.761 | Reg loss: 0.029 | Tree loss: 1.761 | Accuracy: 0.494881 | 0.121 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 26 | Batch: 000 / 011 | Total loss: 1.921 | Reg loss: 0.029 | Tree loss: 1.921 | Accuracy: 0.427000 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 001 / 011 | Total loss: 1.871 | Reg loss: 0.029 | Tree loss: 1.871 | Accuracy: 0.459500 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 002 / 011 | Total loss: 1.852 | Reg loss: 0.029 | Tree loss: 1.852 | Accuracy: 0.460500 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 003 / 011 | Total loss: 1.826 | Reg loss: 0.029 | Tree loss: 1.826 | Accuracy: 0.468500 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 004 / 011 | Total loss: 1.783 | Reg loss: 0.029 | Tree loss: 1.783 | Accuracy: 0.484500 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 005 / 011 | Total loss: 1.772 | Reg loss: 0.029 | Tree loss: 1.772 | Accuracy: 0.459500 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 006 / 011 | Total loss: 1.772 | Reg loss: 0.029 | Tree loss: 1.772 | Accuracy: 0.467000 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 007 / 011 | Total loss: 1.722 | Reg loss: 0.029 | Tree loss: 1.722 | Accuracy: 0.484500 | 0.121 sec/iter\n",
      "Epoch: 26 | Batch: 008 / 011 | Total loss: 1.731 | Reg loss: 0.029 | Tree loss: 1.731 | Accuracy: 0.487500 | 0.12 sec/iter\n",
      "Epoch: 26 | Batch: 009 / 011 | Total loss: 1.716 | Reg loss: 0.029 | Tree loss: 1.716 | Accuracy: 0.497000 | 0.12 sec/iter\n",
      "Epoch: 26 | Batch: 010 / 011 | Total loss: 1.701 | Reg loss: 0.030 | Tree loss: 1.701 | Accuracy: 0.508532 | 0.12 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 27 | Batch: 000 / 011 | Total loss: 1.863 | Reg loss: 0.029 | Tree loss: 1.863 | Accuracy: 0.457000 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 001 / 011 | Total loss: 1.874 | Reg loss: 0.029 | Tree loss: 1.874 | Accuracy: 0.444000 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 002 / 011 | Total loss: 1.829 | Reg loss: 0.029 | Tree loss: 1.829 | Accuracy: 0.464500 | 0.12 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Batch: 003 / 011 | Total loss: 1.810 | Reg loss: 0.029 | Tree loss: 1.810 | Accuracy: 0.475000 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 004 / 011 | Total loss: 1.772 | Reg loss: 0.029 | Tree loss: 1.772 | Accuracy: 0.465500 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 005 / 011 | Total loss: 1.741 | Reg loss: 0.029 | Tree loss: 1.741 | Accuracy: 0.488500 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 006 / 011 | Total loss: 1.722 | Reg loss: 0.030 | Tree loss: 1.722 | Accuracy: 0.480500 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 007 / 011 | Total loss: 1.716 | Reg loss: 0.030 | Tree loss: 1.716 | Accuracy: 0.486000 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 008 / 011 | Total loss: 1.702 | Reg loss: 0.030 | Tree loss: 1.702 | Accuracy: 0.487000 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 009 / 011 | Total loss: 1.700 | Reg loss: 0.030 | Tree loss: 1.700 | Accuracy: 0.485000 | 0.12 sec/iter\n",
      "Epoch: 27 | Batch: 010 / 011 | Total loss: 1.669 | Reg loss: 0.030 | Tree loss: 1.669 | Accuracy: 0.508532 | 0.12 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 28 | Batch: 000 / 011 | Total loss: 1.873 | Reg loss: 0.030 | Tree loss: 1.873 | Accuracy: 0.446000 | 0.122 sec/iter\n",
      "Epoch: 28 | Batch: 001 / 011 | Total loss: 1.848 | Reg loss: 0.030 | Tree loss: 1.848 | Accuracy: 0.458000 | 0.122 sec/iter\n",
      "Epoch: 28 | Batch: 002 / 011 | Total loss: 1.799 | Reg loss: 0.030 | Tree loss: 1.799 | Accuracy: 0.478000 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 003 / 011 | Total loss: 1.758 | Reg loss: 0.030 | Tree loss: 1.758 | Accuracy: 0.514000 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 004 / 011 | Total loss: 1.744 | Reg loss: 0.030 | Tree loss: 1.744 | Accuracy: 0.489500 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 005 / 011 | Total loss: 1.714 | Reg loss: 0.030 | Tree loss: 1.714 | Accuracy: 0.499500 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 006 / 011 | Total loss: 1.701 | Reg loss: 0.030 | Tree loss: 1.701 | Accuracy: 0.503000 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 007 / 011 | Total loss: 1.690 | Reg loss: 0.030 | Tree loss: 1.690 | Accuracy: 0.486000 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 008 / 011 | Total loss: 1.699 | Reg loss: 0.030 | Tree loss: 1.699 | Accuracy: 0.471500 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 009 / 011 | Total loss: 1.662 | Reg loss: 0.030 | Tree loss: 1.662 | Accuracy: 0.501000 | 0.121 sec/iter\n",
      "Epoch: 28 | Batch: 010 / 011 | Total loss: 1.656 | Reg loss: 0.030 | Tree loss: 1.656 | Accuracy: 0.491468 | 0.121 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 29 | Batch: 000 / 011 | Total loss: 1.840 | Reg loss: 0.030 | Tree loss: 1.840 | Accuracy: 0.474000 | 0.123 sec/iter\n",
      "Epoch: 29 | Batch: 001 / 011 | Total loss: 1.817 | Reg loss: 0.030 | Tree loss: 1.817 | Accuracy: 0.464500 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 002 / 011 | Total loss: 1.781 | Reg loss: 0.030 | Tree loss: 1.781 | Accuracy: 0.471500 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 003 / 011 | Total loss: 1.768 | Reg loss: 0.030 | Tree loss: 1.768 | Accuracy: 0.494000 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 004 / 011 | Total loss: 1.714 | Reg loss: 0.030 | Tree loss: 1.714 | Accuracy: 0.491000 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 005 / 011 | Total loss: 1.681 | Reg loss: 0.030 | Tree loss: 1.681 | Accuracy: 0.499500 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 006 / 011 | Total loss: 1.702 | Reg loss: 0.030 | Tree loss: 1.702 | Accuracy: 0.469500 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 007 / 011 | Total loss: 1.672 | Reg loss: 0.030 | Tree loss: 1.672 | Accuracy: 0.491500 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 008 / 011 | Total loss: 1.660 | Reg loss: 0.031 | Tree loss: 1.660 | Accuracy: 0.484000 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 009 / 011 | Total loss: 1.639 | Reg loss: 0.031 | Tree loss: 1.639 | Accuracy: 0.514000 | 0.122 sec/iter\n",
      "Epoch: 29 | Batch: 010 / 011 | Total loss: 1.617 | Reg loss: 0.031 | Tree loss: 1.617 | Accuracy: 0.535836 | 0.122 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 30 | Batch: 000 / 011 | Total loss: 1.825 | Reg loss: 0.030 | Tree loss: 1.825 | Accuracy: 0.475000 | 0.123 sec/iter\n",
      "Epoch: 30 | Batch: 001 / 011 | Total loss: 1.788 | Reg loss: 0.030 | Tree loss: 1.788 | Accuracy: 0.499000 | 0.123 sec/iter\n",
      "Epoch: 30 | Batch: 002 / 011 | Total loss: 1.756 | Reg loss: 0.030 | Tree loss: 1.756 | Accuracy: 0.489000 | 0.123 sec/iter\n",
      "Epoch: 30 | Batch: 003 / 011 | Total loss: 1.718 | Reg loss: 0.031 | Tree loss: 1.718 | Accuracy: 0.496000 | 0.123 sec/iter\n",
      "Epoch: 30 | Batch: 004 / 011 | Total loss: 1.706 | Reg loss: 0.031 | Tree loss: 1.706 | Accuracy: 0.483000 | 0.122 sec/iter\n",
      "Epoch: 30 | Batch: 005 / 011 | Total loss: 1.672 | Reg loss: 0.031 | Tree loss: 1.672 | Accuracy: 0.498500 | 0.122 sec/iter\n",
      "Epoch: 30 | Batch: 006 / 011 | Total loss: 1.667 | Reg loss: 0.031 | Tree loss: 1.667 | Accuracy: 0.485500 | 0.122 sec/iter\n",
      "Epoch: 30 | Batch: 007 / 011 | Total loss: 1.656 | Reg loss: 0.031 | Tree loss: 1.656 | Accuracy: 0.496500 | 0.122 sec/iter\n",
      "Epoch: 30 | Batch: 008 / 011 | Total loss: 1.651 | Reg loss: 0.031 | Tree loss: 1.651 | Accuracy: 0.491000 | 0.122 sec/iter\n",
      "Epoch: 30 | Batch: 009 / 011 | Total loss: 1.633 | Reg loss: 0.031 | Tree loss: 1.633 | Accuracy: 0.484000 | 0.122 sec/iter\n",
      "Epoch: 30 | Batch: 010 / 011 | Total loss: 1.674 | Reg loss: 0.031 | Tree loss: 1.674 | Accuracy: 0.498294 | 0.122 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 31 | Batch: 000 / 011 | Total loss: 1.807 | Reg loss: 0.031 | Tree loss: 1.807 | Accuracy: 0.471500 | 0.122 sec/iter\n",
      "Epoch: 31 | Batch: 001 / 011 | Total loss: 1.760 | Reg loss: 0.031 | Tree loss: 1.760 | Accuracy: 0.485000 | 0.122 sec/iter\n",
      "Epoch: 31 | Batch: 002 / 011 | Total loss: 1.726 | Reg loss: 0.031 | Tree loss: 1.726 | Accuracy: 0.510500 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 003 / 011 | Total loss: 1.742 | Reg loss: 0.031 | Tree loss: 1.742 | Accuracy: 0.482500 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 004 / 011 | Total loss: 1.680 | Reg loss: 0.031 | Tree loss: 1.680 | Accuracy: 0.486000 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 005 / 011 | Total loss: 1.651 | Reg loss: 0.031 | Tree loss: 1.651 | Accuracy: 0.517000 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 006 / 011 | Total loss: 1.638 | Reg loss: 0.031 | Tree loss: 1.638 | Accuracy: 0.501000 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 007 / 011 | Total loss: 1.637 | Reg loss: 0.031 | Tree loss: 1.637 | Accuracy: 0.499000 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 008 / 011 | Total loss: 1.624 | Reg loss: 0.031 | Tree loss: 1.624 | Accuracy: 0.492500 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 009 / 011 | Total loss: 1.618 | Reg loss: 0.031 | Tree loss: 1.618 | Accuracy: 0.495000 | 0.121 sec/iter\n",
      "Epoch: 31 | Batch: 010 / 011 | Total loss: 1.574 | Reg loss: 0.032 | Tree loss: 1.574 | Accuracy: 0.522184 | 0.121 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 32 | Batch: 000 / 011 | Total loss: 1.794 | Reg loss: 0.031 | Tree loss: 1.794 | Accuracy: 0.471000 | 0.121 sec/iter\n",
      "Epoch: 32 | Batch: 001 / 011 | Total loss: 1.750 | Reg loss: 0.031 | Tree loss: 1.750 | Accuracy: 0.489500 | 0.121 sec/iter\n",
      "Epoch: 32 | Batch: 002 / 011 | Total loss: 1.732 | Reg loss: 0.031 | Tree loss: 1.732 | Accuracy: 0.463000 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 003 / 011 | Total loss: 1.703 | Reg loss: 0.031 | Tree loss: 1.703 | Accuracy: 0.478500 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 004 / 011 | Total loss: 1.655 | Reg loss: 0.031 | Tree loss: 1.655 | Accuracy: 0.507000 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 005 / 011 | Total loss: 1.619 | Reg loss: 0.031 | Tree loss: 1.619 | Accuracy: 0.514500 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 006 / 011 | Total loss: 1.636 | Reg loss: 0.032 | Tree loss: 1.636 | Accuracy: 0.505000 | 0.12 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Batch: 007 / 011 | Total loss: 1.599 | Reg loss: 0.032 | Tree loss: 1.599 | Accuracy: 0.510000 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 008 / 011 | Total loss: 1.615 | Reg loss: 0.032 | Tree loss: 1.615 | Accuracy: 0.482000 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 009 / 011 | Total loss: 1.593 | Reg loss: 0.032 | Tree loss: 1.593 | Accuracy: 0.503000 | 0.12 sec/iter\n",
      "Epoch: 32 | Batch: 010 / 011 | Total loss: 1.573 | Reg loss: 0.032 | Tree loss: 1.573 | Accuracy: 0.529010 | 0.119 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 33 | Batch: 000 / 011 | Total loss: 1.749 | Reg loss: 0.032 | Tree loss: 1.749 | Accuracy: 0.499500 | 0.12 sec/iter\n",
      "Epoch: 33 | Batch: 001 / 011 | Total loss: 1.739 | Reg loss: 0.032 | Tree loss: 1.739 | Accuracy: 0.484500 | 0.12 sec/iter\n",
      "Epoch: 33 | Batch: 002 / 011 | Total loss: 1.714 | Reg loss: 0.032 | Tree loss: 1.714 | Accuracy: 0.482500 | 0.12 sec/iter\n",
      "Epoch: 33 | Batch: 003 / 011 | Total loss: 1.686 | Reg loss: 0.032 | Tree loss: 1.686 | Accuracy: 0.485000 | 0.12 sec/iter\n",
      "Epoch: 33 | Batch: 004 / 011 | Total loss: 1.640 | Reg loss: 0.032 | Tree loss: 1.640 | Accuracy: 0.489500 | 0.119 sec/iter\n",
      "Epoch: 33 | Batch: 005 / 011 | Total loss: 1.633 | Reg loss: 0.032 | Tree loss: 1.633 | Accuracy: 0.490000 | 0.119 sec/iter\n",
      "Epoch: 33 | Batch: 006 / 011 | Total loss: 1.596 | Reg loss: 0.032 | Tree loss: 1.596 | Accuracy: 0.502500 | 0.119 sec/iter\n",
      "Epoch: 33 | Batch: 007 / 011 | Total loss: 1.593 | Reg loss: 0.032 | Tree loss: 1.593 | Accuracy: 0.506500 | 0.119 sec/iter\n",
      "Epoch: 33 | Batch: 008 / 011 | Total loss: 1.582 | Reg loss: 0.032 | Tree loss: 1.582 | Accuracy: 0.514000 | 0.119 sec/iter\n",
      "Epoch: 33 | Batch: 009 / 011 | Total loss: 1.576 | Reg loss: 0.032 | Tree loss: 1.576 | Accuracy: 0.496500 | 0.119 sec/iter\n",
      "Epoch: 33 | Batch: 010 / 011 | Total loss: 1.589 | Reg loss: 0.032 | Tree loss: 1.589 | Accuracy: 0.511945 | 0.119 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 34 | Batch: 000 / 011 | Total loss: 1.730 | Reg loss: 0.032 | Tree loss: 1.730 | Accuracy: 0.478000 | 0.119 sec/iter\n",
      "Epoch: 34 | Batch: 001 / 011 | Total loss: 1.717 | Reg loss: 0.032 | Tree loss: 1.717 | Accuracy: 0.480500 | 0.119 sec/iter\n",
      "Epoch: 34 | Batch: 002 / 011 | Total loss: 1.685 | Reg loss: 0.032 | Tree loss: 1.685 | Accuracy: 0.487500 | 0.119 sec/iter\n",
      "Epoch: 34 | Batch: 003 / 011 | Total loss: 1.655 | Reg loss: 0.032 | Tree loss: 1.655 | Accuracy: 0.498500 | 0.119 sec/iter\n",
      "Epoch: 34 | Batch: 004 / 011 | Total loss: 1.624 | Reg loss: 0.032 | Tree loss: 1.624 | Accuracy: 0.506000 | 0.119 sec/iter\n",
      "Epoch: 34 | Batch: 005 / 011 | Total loss: 1.616 | Reg loss: 0.032 | Tree loss: 1.616 | Accuracy: 0.507000 | 0.118 sec/iter\n",
      "Epoch: 34 | Batch: 006 / 011 | Total loss: 1.581 | Reg loss: 0.032 | Tree loss: 1.581 | Accuracy: 0.520000 | 0.118 sec/iter\n",
      "Epoch: 34 | Batch: 007 / 011 | Total loss: 1.576 | Reg loss: 0.032 | Tree loss: 1.576 | Accuracy: 0.514000 | 0.118 sec/iter\n",
      "Epoch: 34 | Batch: 008 / 011 | Total loss: 1.591 | Reg loss: 0.032 | Tree loss: 1.591 | Accuracy: 0.494000 | 0.118 sec/iter\n",
      "Epoch: 34 | Batch: 009 / 011 | Total loss: 1.562 | Reg loss: 0.032 | Tree loss: 1.562 | Accuracy: 0.514500 | 0.118 sec/iter\n",
      "Epoch: 34 | Batch: 010 / 011 | Total loss: 1.567 | Reg loss: 0.033 | Tree loss: 1.567 | Accuracy: 0.522184 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 35 | Batch: 000 / 011 | Total loss: 1.733 | Reg loss: 0.032 | Tree loss: 1.733 | Accuracy: 0.495500 | 0.118 sec/iter\n",
      "Epoch: 35 | Batch: 001 / 011 | Total loss: 1.680 | Reg loss: 0.032 | Tree loss: 1.680 | Accuracy: 0.490000 | 0.118 sec/iter\n",
      "Epoch: 35 | Batch: 002 / 011 | Total loss: 1.668 | Reg loss: 0.032 | Tree loss: 1.668 | Accuracy: 0.484500 | 0.118 sec/iter\n",
      "Epoch: 35 | Batch: 003 / 011 | Total loss: 1.640 | Reg loss: 0.032 | Tree loss: 1.640 | Accuracy: 0.510500 | 0.118 sec/iter\n",
      "Epoch: 35 | Batch: 004 / 011 | Total loss: 1.621 | Reg loss: 0.032 | Tree loss: 1.621 | Accuracy: 0.495500 | 0.118 sec/iter\n",
      "Epoch: 35 | Batch: 005 / 011 | Total loss: 1.576 | Reg loss: 0.033 | Tree loss: 1.576 | Accuracy: 0.522500 | 0.117 sec/iter\n",
      "Epoch: 35 | Batch: 006 / 011 | Total loss: 1.580 | Reg loss: 0.033 | Tree loss: 1.580 | Accuracy: 0.513500 | 0.117 sec/iter\n",
      "Epoch: 35 | Batch: 007 / 011 | Total loss: 1.549 | Reg loss: 0.033 | Tree loss: 1.549 | Accuracy: 0.519500 | 0.117 sec/iter\n",
      "Epoch: 35 | Batch: 008 / 011 | Total loss: 1.571 | Reg loss: 0.033 | Tree loss: 1.571 | Accuracy: 0.495500 | 0.117 sec/iter\n",
      "Epoch: 35 | Batch: 009 / 011 | Total loss: 1.567 | Reg loss: 0.033 | Tree loss: 1.567 | Accuracy: 0.481000 | 0.117 sec/iter\n",
      "Epoch: 35 | Batch: 010 / 011 | Total loss: 1.577 | Reg loss: 0.033 | Tree loss: 1.577 | Accuracy: 0.457338 | 0.117 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 36 | Batch: 000 / 011 | Total loss: 1.726 | Reg loss: 0.033 | Tree loss: 1.726 | Accuracy: 0.474500 | 0.117 sec/iter\n",
      "Epoch: 36 | Batch: 001 / 011 | Total loss: 1.684 | Reg loss: 0.033 | Tree loss: 1.684 | Accuracy: 0.498500 | 0.117 sec/iter\n",
      "Epoch: 36 | Batch: 002 / 011 | Total loss: 1.655 | Reg loss: 0.033 | Tree loss: 1.655 | Accuracy: 0.480500 | 0.117 sec/iter\n",
      "Epoch: 36 | Batch: 003 / 011 | Total loss: 1.633 | Reg loss: 0.033 | Tree loss: 1.633 | Accuracy: 0.501500 | 0.117 sec/iter\n",
      "Epoch: 36 | Batch: 004 / 011 | Total loss: 1.598 | Reg loss: 0.033 | Tree loss: 1.598 | Accuracy: 0.511500 | 0.116 sec/iter\n",
      "Epoch: 36 | Batch: 005 / 011 | Total loss: 1.577 | Reg loss: 0.033 | Tree loss: 1.577 | Accuracy: 0.509000 | 0.116 sec/iter\n",
      "Epoch: 36 | Batch: 006 / 011 | Total loss: 1.556 | Reg loss: 0.033 | Tree loss: 1.556 | Accuracy: 0.519500 | 0.116 sec/iter\n",
      "Epoch: 36 | Batch: 007 / 011 | Total loss: 1.540 | Reg loss: 0.033 | Tree loss: 1.540 | Accuracy: 0.538500 | 0.116 sec/iter\n",
      "Epoch: 36 | Batch: 008 / 011 | Total loss: 1.527 | Reg loss: 0.033 | Tree loss: 1.527 | Accuracy: 0.513500 | 0.116 sec/iter\n",
      "Epoch: 36 | Batch: 009 / 011 | Total loss: 1.532 | Reg loss: 0.033 | Tree loss: 1.532 | Accuracy: 0.508500 | 0.116 sec/iter\n",
      "Epoch: 36 | Batch: 010 / 011 | Total loss: 1.572 | Reg loss: 0.033 | Tree loss: 1.572 | Accuracy: 0.484642 | 0.116 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 37 | Batch: 000 / 011 | Total loss: 1.704 | Reg loss: 0.033 | Tree loss: 1.704 | Accuracy: 0.486500 | 0.116 sec/iter\n",
      "Epoch: 37 | Batch: 001 / 011 | Total loss: 1.678 | Reg loss: 0.033 | Tree loss: 1.678 | Accuracy: 0.485500 | 0.116 sec/iter\n",
      "Epoch: 37 | Batch: 002 / 011 | Total loss: 1.633 | Reg loss: 0.033 | Tree loss: 1.633 | Accuracy: 0.493500 | 0.116 sec/iter\n",
      "Epoch: 37 | Batch: 003 / 011 | Total loss: 1.607 | Reg loss: 0.033 | Tree loss: 1.607 | Accuracy: 0.512000 | 0.116 sec/iter\n",
      "Epoch: 37 | Batch: 004 / 011 | Total loss: 1.574 | Reg loss: 0.033 | Tree loss: 1.574 | Accuracy: 0.523500 | 0.115 sec/iter\n",
      "Epoch: 37 | Batch: 005 / 011 | Total loss: 1.575 | Reg loss: 0.033 | Tree loss: 1.575 | Accuracy: 0.496500 | 0.115 sec/iter\n",
      "Epoch: 37 | Batch: 006 / 011 | Total loss: 1.543 | Reg loss: 0.033 | Tree loss: 1.543 | Accuracy: 0.521000 | 0.115 sec/iter\n",
      "Epoch: 37 | Batch: 007 / 011 | Total loss: 1.517 | Reg loss: 0.033 | Tree loss: 1.517 | Accuracy: 0.507500 | 0.115 sec/iter\n",
      "Epoch: 37 | Batch: 008 / 011 | Total loss: 1.521 | Reg loss: 0.033 | Tree loss: 1.521 | Accuracy: 0.501500 | 0.115 sec/iter\n",
      "Epoch: 37 | Batch: 009 / 011 | Total loss: 1.525 | Reg loss: 0.033 | Tree loss: 1.525 | Accuracy: 0.513500 | 0.115 sec/iter\n",
      "Epoch: 37 | Batch: 010 / 011 | Total loss: 1.486 | Reg loss: 0.034 | Tree loss: 1.486 | Accuracy: 0.518771 | 0.115 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Batch: 000 / 011 | Total loss: 1.650 | Reg loss: 0.033 | Tree loss: 1.650 | Accuracy: 0.509500 | 0.115 sec/iter\n",
      "Epoch: 38 | Batch: 001 / 011 | Total loss: 1.642 | Reg loss: 0.033 | Tree loss: 1.642 | Accuracy: 0.485500 | 0.115 sec/iter\n",
      "Epoch: 38 | Batch: 002 / 011 | Total loss: 1.637 | Reg loss: 0.033 | Tree loss: 1.637 | Accuracy: 0.464500 | 0.115 sec/iter\n",
      "Epoch: 38 | Batch: 003 / 011 | Total loss: 1.602 | Reg loss: 0.033 | Tree loss: 1.602 | Accuracy: 0.485000 | 0.115 sec/iter\n",
      "Epoch: 38 | Batch: 004 / 011 | Total loss: 1.576 | Reg loss: 0.033 | Tree loss: 1.576 | Accuracy: 0.487500 | 0.115 sec/iter\n",
      "Epoch: 38 | Batch: 005 / 011 | Total loss: 1.553 | Reg loss: 0.033 | Tree loss: 1.553 | Accuracy: 0.533000 | 0.114 sec/iter\n",
      "Epoch: 38 | Batch: 006 / 011 | Total loss: 1.515 | Reg loss: 0.034 | Tree loss: 1.515 | Accuracy: 0.553000 | 0.114 sec/iter\n",
      "Epoch: 38 | Batch: 007 / 011 | Total loss: 1.525 | Reg loss: 0.034 | Tree loss: 1.525 | Accuracy: 0.521500 | 0.114 sec/iter\n",
      "Epoch: 38 | Batch: 008 / 011 | Total loss: 1.516 | Reg loss: 0.034 | Tree loss: 1.516 | Accuracy: 0.508000 | 0.114 sec/iter\n",
      "Epoch: 38 | Batch: 009 / 011 | Total loss: 1.513 | Reg loss: 0.034 | Tree loss: 1.513 | Accuracy: 0.500500 | 0.114 sec/iter\n",
      "Epoch: 38 | Batch: 010 / 011 | Total loss: 1.535 | Reg loss: 0.034 | Tree loss: 1.535 | Accuracy: 0.505119 | 0.114 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 39 | Batch: 000 / 011 | Total loss: 1.660 | Reg loss: 0.034 | Tree loss: 1.660 | Accuracy: 0.475500 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 001 / 011 | Total loss: 1.655 | Reg loss: 0.034 | Tree loss: 1.655 | Accuracy: 0.479000 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 002 / 011 | Total loss: 1.607 | Reg loss: 0.034 | Tree loss: 1.607 | Accuracy: 0.498500 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 003 / 011 | Total loss: 1.584 | Reg loss: 0.034 | Tree loss: 1.584 | Accuracy: 0.500500 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 004 / 011 | Total loss: 1.538 | Reg loss: 0.034 | Tree loss: 1.538 | Accuracy: 0.520000 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 005 / 011 | Total loss: 1.532 | Reg loss: 0.034 | Tree loss: 1.532 | Accuracy: 0.512500 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 006 / 011 | Total loss: 1.505 | Reg loss: 0.034 | Tree loss: 1.505 | Accuracy: 0.527000 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 007 / 011 | Total loss: 1.509 | Reg loss: 0.034 | Tree loss: 1.509 | Accuracy: 0.506000 | 0.114 sec/iter\n",
      "Epoch: 39 | Batch: 008 / 011 | Total loss: 1.508 | Reg loss: 0.034 | Tree loss: 1.508 | Accuracy: 0.505500 | 0.113 sec/iter\n",
      "Epoch: 39 | Batch: 009 / 011 | Total loss: 1.489 | Reg loss: 0.034 | Tree loss: 1.489 | Accuracy: 0.510500 | 0.113 sec/iter\n",
      "Epoch: 39 | Batch: 010 / 011 | Total loss: 1.495 | Reg loss: 0.034 | Tree loss: 1.495 | Accuracy: 0.484642 | 0.113 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 40 | Batch: 000 / 011 | Total loss: 1.659 | Reg loss: 0.034 | Tree loss: 1.659 | Accuracy: 0.475500 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 001 / 011 | Total loss: 1.630 | Reg loss: 0.034 | Tree loss: 1.630 | Accuracy: 0.490000 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 002 / 011 | Total loss: 1.599 | Reg loss: 0.034 | Tree loss: 1.599 | Accuracy: 0.483500 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 003 / 011 | Total loss: 1.575 | Reg loss: 0.034 | Tree loss: 1.575 | Accuracy: 0.488500 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 004 / 011 | Total loss: 1.522 | Reg loss: 0.034 | Tree loss: 1.522 | Accuracy: 0.518000 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 005 / 011 | Total loss: 1.512 | Reg loss: 0.034 | Tree loss: 1.512 | Accuracy: 0.518000 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 006 / 011 | Total loss: 1.490 | Reg loss: 0.034 | Tree loss: 1.490 | Accuracy: 0.533500 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 007 / 011 | Total loss: 1.499 | Reg loss: 0.034 | Tree loss: 1.499 | Accuracy: 0.526500 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 008 / 011 | Total loss: 1.493 | Reg loss: 0.034 | Tree loss: 1.493 | Accuracy: 0.517500 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 009 / 011 | Total loss: 1.474 | Reg loss: 0.034 | Tree loss: 1.474 | Accuracy: 0.511000 | 0.113 sec/iter\n",
      "Epoch: 40 | Batch: 010 / 011 | Total loss: 1.463 | Reg loss: 0.034 | Tree loss: 1.463 | Accuracy: 0.546075 | 0.113 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 41 | Batch: 000 / 011 | Total loss: 1.638 | Reg loss: 0.034 | Tree loss: 1.638 | Accuracy: 0.480000 | 0.113 sec/iter\n",
      "Epoch: 41 | Batch: 001 / 011 | Total loss: 1.601 | Reg loss: 0.034 | Tree loss: 1.601 | Accuracy: 0.488000 | 0.113 sec/iter\n",
      "Epoch: 41 | Batch: 002 / 011 | Total loss: 1.584 | Reg loss: 0.034 | Tree loss: 1.584 | Accuracy: 0.476000 | 0.113 sec/iter\n",
      "Epoch: 41 | Batch: 003 / 011 | Total loss: 1.571 | Reg loss: 0.034 | Tree loss: 1.571 | Accuracy: 0.498500 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 004 / 011 | Total loss: 1.494 | Reg loss: 0.034 | Tree loss: 1.494 | Accuracy: 0.540500 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 005 / 011 | Total loss: 1.505 | Reg loss: 0.034 | Tree loss: 1.505 | Accuracy: 0.531500 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 006 / 011 | Total loss: 1.509 | Reg loss: 0.034 | Tree loss: 1.509 | Accuracy: 0.513000 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 007 / 011 | Total loss: 1.469 | Reg loss: 0.034 | Tree loss: 1.469 | Accuracy: 0.530000 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 008 / 011 | Total loss: 1.468 | Reg loss: 0.035 | Tree loss: 1.468 | Accuracy: 0.493500 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 009 / 011 | Total loss: 1.482 | Reg loss: 0.035 | Tree loss: 1.482 | Accuracy: 0.495500 | 0.112 sec/iter\n",
      "Epoch: 41 | Batch: 010 / 011 | Total loss: 1.440 | Reg loss: 0.035 | Tree loss: 1.440 | Accuracy: 0.556314 | 0.112 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 42 | Batch: 000 / 011 | Total loss: 1.631 | Reg loss: 0.034 | Tree loss: 1.631 | Accuracy: 0.466500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 001 / 011 | Total loss: 1.590 | Reg loss: 0.034 | Tree loss: 1.590 | Accuracy: 0.470500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 002 / 011 | Total loss: 1.571 | Reg loss: 0.034 | Tree loss: 1.571 | Accuracy: 0.491500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 003 / 011 | Total loss: 1.530 | Reg loss: 0.034 | Tree loss: 1.530 | Accuracy: 0.497500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 004 / 011 | Total loss: 1.516 | Reg loss: 0.035 | Tree loss: 1.516 | Accuracy: 0.503500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 005 / 011 | Total loss: 1.493 | Reg loss: 0.035 | Tree loss: 1.493 | Accuracy: 0.528500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 006 / 011 | Total loss: 1.485 | Reg loss: 0.035 | Tree loss: 1.485 | Accuracy: 0.536500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 007 / 011 | Total loss: 1.458 | Reg loss: 0.035 | Tree loss: 1.458 | Accuracy: 0.530500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 008 / 011 | Total loss: 1.439 | Reg loss: 0.035 | Tree loss: 1.439 | Accuracy: 0.536000 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 009 / 011 | Total loss: 1.459 | Reg loss: 0.035 | Tree loss: 1.459 | Accuracy: 0.514500 | 0.112 sec/iter\n",
      "Epoch: 42 | Batch: 010 / 011 | Total loss: 1.517 | Reg loss: 0.035 | Tree loss: 1.517 | Accuracy: 0.477816 | 0.112 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 43 | Batch: 000 / 011 | Total loss: 1.600 | Reg loss: 0.035 | Tree loss: 1.600 | Accuracy: 0.468000 | 0.112 sec/iter\n",
      "Epoch: 43 | Batch: 001 / 011 | Total loss: 1.580 | Reg loss: 0.035 | Tree loss: 1.580 | Accuracy: 0.489000 | 0.112 sec/iter\n",
      "Epoch: 43 | Batch: 002 / 011 | Total loss: 1.565 | Reg loss: 0.035 | Tree loss: 1.565 | Accuracy: 0.476000 | 0.112 sec/iter\n",
      "Epoch: 43 | Batch: 003 / 011 | Total loss: 1.546 | Reg loss: 0.035 | Tree loss: 1.546 | Accuracy: 0.488500 | 0.112 sec/iter\n",
      "Epoch: 43 | Batch: 004 / 011 | Total loss: 1.492 | Reg loss: 0.035 | Tree loss: 1.492 | Accuracy: 0.524500 | 0.112 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Batch: 005 / 011 | Total loss: 1.471 | Reg loss: 0.035 | Tree loss: 1.471 | Accuracy: 0.533500 | 0.111 sec/iter\n",
      "Epoch: 43 | Batch: 006 / 011 | Total loss: 1.468 | Reg loss: 0.035 | Tree loss: 1.468 | Accuracy: 0.502500 | 0.111 sec/iter\n",
      "Epoch: 43 | Batch: 007 / 011 | Total loss: 1.450 | Reg loss: 0.035 | Tree loss: 1.450 | Accuracy: 0.515000 | 0.111 sec/iter\n",
      "Epoch: 43 | Batch: 008 / 011 | Total loss: 1.434 | Reg loss: 0.035 | Tree loss: 1.434 | Accuracy: 0.523000 | 0.111 sec/iter\n",
      "Epoch: 43 | Batch: 009 / 011 | Total loss: 1.448 | Reg loss: 0.035 | Tree loss: 1.448 | Accuracy: 0.517000 | 0.111 sec/iter\n",
      "Epoch: 43 | Batch: 010 / 011 | Total loss: 1.415 | Reg loss: 0.035 | Tree loss: 1.415 | Accuracy: 0.542662 | 0.111 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 44 | Batch: 000 / 011 | Total loss: 1.604 | Reg loss: 0.035 | Tree loss: 1.604 | Accuracy: 0.470500 | 0.113 sec/iter\n",
      "Epoch: 44 | Batch: 001 / 011 | Total loss: 1.571 | Reg loss: 0.035 | Tree loss: 1.571 | Accuracy: 0.479500 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 002 / 011 | Total loss: 1.526 | Reg loss: 0.035 | Tree loss: 1.526 | Accuracy: 0.499500 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 003 / 011 | Total loss: 1.498 | Reg loss: 0.035 | Tree loss: 1.498 | Accuracy: 0.489000 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 004 / 011 | Total loss: 1.502 | Reg loss: 0.035 | Tree loss: 1.502 | Accuracy: 0.489000 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 005 / 011 | Total loss: 1.452 | Reg loss: 0.035 | Tree loss: 1.452 | Accuracy: 0.540000 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 006 / 011 | Total loss: 1.447 | Reg loss: 0.035 | Tree loss: 1.447 | Accuracy: 0.543500 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 007 / 011 | Total loss: 1.447 | Reg loss: 0.035 | Tree loss: 1.447 | Accuracy: 0.517000 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 008 / 011 | Total loss: 1.428 | Reg loss: 0.035 | Tree loss: 1.428 | Accuracy: 0.526000 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 009 / 011 | Total loss: 1.444 | Reg loss: 0.035 | Tree loss: 1.444 | Accuracy: 0.501500 | 0.112 sec/iter\n",
      "Epoch: 44 | Batch: 010 / 011 | Total loss: 1.472 | Reg loss: 0.035 | Tree loss: 1.472 | Accuracy: 0.511945 | 0.112 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 45 | Batch: 000 / 011 | Total loss: 1.573 | Reg loss: 0.035 | Tree loss: 1.573 | Accuracy: 0.489500 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 001 / 011 | Total loss: 1.555 | Reg loss: 0.035 | Tree loss: 1.555 | Accuracy: 0.482000 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 002 / 011 | Total loss: 1.526 | Reg loss: 0.035 | Tree loss: 1.526 | Accuracy: 0.496000 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 003 / 011 | Total loss: 1.476 | Reg loss: 0.035 | Tree loss: 1.476 | Accuracy: 0.517500 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 004 / 011 | Total loss: 1.468 | Reg loss: 0.035 | Tree loss: 1.468 | Accuracy: 0.524000 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 005 / 011 | Total loss: 1.454 | Reg loss: 0.035 | Tree loss: 1.454 | Accuracy: 0.534500 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 006 / 011 | Total loss: 1.420 | Reg loss: 0.035 | Tree loss: 1.420 | Accuracy: 0.534000 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 007 / 011 | Total loss: 1.452 | Reg loss: 0.035 | Tree loss: 1.452 | Accuracy: 0.486500 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 008 / 011 | Total loss: 1.422 | Reg loss: 0.035 | Tree loss: 1.422 | Accuracy: 0.524000 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 009 / 011 | Total loss: 1.455 | Reg loss: 0.036 | Tree loss: 1.455 | Accuracy: 0.485500 | 0.113 sec/iter\n",
      "Epoch: 45 | Batch: 010 / 011 | Total loss: 1.418 | Reg loss: 0.036 | Tree loss: 1.418 | Accuracy: 0.552901 | 0.113 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 46 | Batch: 000 / 011 | Total loss: 1.584 | Reg loss: 0.035 | Tree loss: 1.584 | Accuracy: 0.464500 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 001 / 011 | Total loss: 1.539 | Reg loss: 0.035 | Tree loss: 1.539 | Accuracy: 0.470000 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 002 / 011 | Total loss: 1.527 | Reg loss: 0.035 | Tree loss: 1.527 | Accuracy: 0.478500 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 003 / 011 | Total loss: 1.477 | Reg loss: 0.035 | Tree loss: 1.477 | Accuracy: 0.501500 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 004 / 011 | Total loss: 1.465 | Reg loss: 0.036 | Tree loss: 1.465 | Accuracy: 0.519000 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 005 / 011 | Total loss: 1.437 | Reg loss: 0.036 | Tree loss: 1.437 | Accuracy: 0.518000 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 006 / 011 | Total loss: 1.414 | Reg loss: 0.036 | Tree loss: 1.414 | Accuracy: 0.533500 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 007 / 011 | Total loss: 1.424 | Reg loss: 0.036 | Tree loss: 1.424 | Accuracy: 0.527500 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 008 / 011 | Total loss: 1.421 | Reg loss: 0.036 | Tree loss: 1.421 | Accuracy: 0.511000 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 009 / 011 | Total loss: 1.407 | Reg loss: 0.036 | Tree loss: 1.407 | Accuracy: 0.523000 | 0.114 sec/iter\n",
      "Epoch: 46 | Batch: 010 / 011 | Total loss: 1.429 | Reg loss: 0.036 | Tree loss: 1.429 | Accuracy: 0.481229 | 0.114 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 47 | Batch: 000 / 011 | Total loss: 1.552 | Reg loss: 0.036 | Tree loss: 1.552 | Accuracy: 0.473000 | 0.114 sec/iter\n",
      "Epoch: 47 | Batch: 001 / 011 | Total loss: 1.553 | Reg loss: 0.036 | Tree loss: 1.553 | Accuracy: 0.454000 | 0.114 sec/iter\n",
      "Epoch: 47 | Batch: 002 / 011 | Total loss: 1.505 | Reg loss: 0.036 | Tree loss: 1.505 | Accuracy: 0.485500 | 0.114 sec/iter\n",
      "Epoch: 47 | Batch: 003 / 011 | Total loss: 1.454 | Reg loss: 0.036 | Tree loss: 1.454 | Accuracy: 0.512000 | 0.114 sec/iter\n",
      "Epoch: 47 | Batch: 004 / 011 | Total loss: 1.459 | Reg loss: 0.036 | Tree loss: 1.459 | Accuracy: 0.496500 | 0.113 sec/iter\n",
      "Epoch: 47 | Batch: 005 / 011 | Total loss: 1.422 | Reg loss: 0.036 | Tree loss: 1.422 | Accuracy: 0.539500 | 0.113 sec/iter\n",
      "Epoch: 47 | Batch: 006 / 011 | Total loss: 1.427 | Reg loss: 0.036 | Tree loss: 1.427 | Accuracy: 0.509500 | 0.113 sec/iter\n",
      "Epoch: 47 | Batch: 007 / 011 | Total loss: 1.393 | Reg loss: 0.036 | Tree loss: 1.393 | Accuracy: 0.535500 | 0.113 sec/iter\n",
      "Epoch: 47 | Batch: 008 / 011 | Total loss: 1.420 | Reg loss: 0.036 | Tree loss: 1.420 | Accuracy: 0.512000 | 0.113 sec/iter\n",
      "Epoch: 47 | Batch: 009 / 011 | Total loss: 1.401 | Reg loss: 0.036 | Tree loss: 1.401 | Accuracy: 0.513000 | 0.113 sec/iter\n",
      "Epoch: 47 | Batch: 010 / 011 | Total loss: 1.395 | Reg loss: 0.036 | Tree loss: 1.395 | Accuracy: 0.488055 | 0.113 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 48 | Batch: 000 / 011 | Total loss: 1.535 | Reg loss: 0.036 | Tree loss: 1.535 | Accuracy: 0.479500 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 001 / 011 | Total loss: 1.511 | Reg loss: 0.036 | Tree loss: 1.511 | Accuracy: 0.471500 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 002 / 011 | Total loss: 1.520 | Reg loss: 0.036 | Tree loss: 1.520 | Accuracy: 0.460000 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 003 / 011 | Total loss: 1.454 | Reg loss: 0.036 | Tree loss: 1.454 | Accuracy: 0.489500 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 004 / 011 | Total loss: 1.435 | Reg loss: 0.036 | Tree loss: 1.435 | Accuracy: 0.511000 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 005 / 011 | Total loss: 1.425 | Reg loss: 0.036 | Tree loss: 1.425 | Accuracy: 0.534500 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 006 / 011 | Total loss: 1.398 | Reg loss: 0.036 | Tree loss: 1.398 | Accuracy: 0.541000 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 007 / 011 | Total loss: 1.409 | Reg loss: 0.036 | Tree loss: 1.409 | Accuracy: 0.503000 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 008 / 011 | Total loss: 1.398 | Reg loss: 0.036 | Tree loss: 1.398 | Accuracy: 0.523000 | 0.113 sec/iter\n",
      "Epoch: 48 | Batch: 009 / 011 | Total loss: 1.397 | Reg loss: 0.036 | Tree loss: 1.397 | Accuracy: 0.505500 | 0.113 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Batch: 010 / 011 | Total loss: 1.441 | Reg loss: 0.036 | Tree loss: 1.441 | Accuracy: 0.505119 | 0.113 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 49 | Batch: 000 / 011 | Total loss: 1.532 | Reg loss: 0.036 | Tree loss: 1.532 | Accuracy: 0.478000 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 001 / 011 | Total loss: 1.483 | Reg loss: 0.036 | Tree loss: 1.483 | Accuracy: 0.493000 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 002 / 011 | Total loss: 1.491 | Reg loss: 0.036 | Tree loss: 1.491 | Accuracy: 0.464000 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 003 / 011 | Total loss: 1.462 | Reg loss: 0.036 | Tree loss: 1.462 | Accuracy: 0.504500 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 004 / 011 | Total loss: 1.428 | Reg loss: 0.036 | Tree loss: 1.428 | Accuracy: 0.518500 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 005 / 011 | Total loss: 1.391 | Reg loss: 0.036 | Tree loss: 1.391 | Accuracy: 0.538500 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 006 / 011 | Total loss: 1.394 | Reg loss: 0.036 | Tree loss: 1.394 | Accuracy: 0.522500 | 0.114 sec/iter\n",
      "Epoch: 49 | Batch: 007 / 011 | Total loss: 1.419 | Reg loss: 0.036 | Tree loss: 1.419 | Accuracy: 0.491500 | 0.113 sec/iter\n",
      "Epoch: 49 | Batch: 008 / 011 | Total loss: 1.387 | Reg loss: 0.036 | Tree loss: 1.387 | Accuracy: 0.526500 | 0.113 sec/iter\n",
      "Epoch: 49 | Batch: 009 / 011 | Total loss: 1.384 | Reg loss: 0.036 | Tree loss: 1.384 | Accuracy: 0.501500 | 0.113 sec/iter\n",
      "Epoch: 49 | Batch: 010 / 011 | Total loss: 1.391 | Reg loss: 0.036 | Tree loss: 1.391 | Accuracy: 0.532423 | 0.113 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 50 | Batch: 000 / 011 | Total loss: 1.521 | Reg loss: 0.036 | Tree loss: 1.521 | Accuracy: 0.466000 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 001 / 011 | Total loss: 1.497 | Reg loss: 0.036 | Tree loss: 1.497 | Accuracy: 0.478000 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 002 / 011 | Total loss: 1.486 | Reg loss: 0.036 | Tree loss: 1.486 | Accuracy: 0.477500 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 003 / 011 | Total loss: 1.437 | Reg loss: 0.036 | Tree loss: 1.437 | Accuracy: 0.497500 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 004 / 011 | Total loss: 1.405 | Reg loss: 0.036 | Tree loss: 1.405 | Accuracy: 0.508000 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 005 / 011 | Total loss: 1.396 | Reg loss: 0.036 | Tree loss: 1.396 | Accuracy: 0.548000 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 006 / 011 | Total loss: 1.390 | Reg loss: 0.036 | Tree loss: 1.390 | Accuracy: 0.532500 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 007 / 011 | Total loss: 1.391 | Reg loss: 0.036 | Tree loss: 1.391 | Accuracy: 0.530000 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 008 / 011 | Total loss: 1.383 | Reg loss: 0.037 | Tree loss: 1.383 | Accuracy: 0.512500 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 009 / 011 | Total loss: 1.387 | Reg loss: 0.037 | Tree loss: 1.387 | Accuracy: 0.504500 | 0.115 sec/iter\n",
      "Epoch: 50 | Batch: 010 / 011 | Total loss: 1.348 | Reg loss: 0.037 | Tree loss: 1.348 | Accuracy: 0.515358 | 0.115 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 51 | Batch: 000 / 011 | Total loss: 1.509 | Reg loss: 0.036 | Tree loss: 1.509 | Accuracy: 0.474500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 001 / 011 | Total loss: 1.485 | Reg loss: 0.036 | Tree loss: 1.485 | Accuracy: 0.488500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 002 / 011 | Total loss: 1.458 | Reg loss: 0.036 | Tree loss: 1.458 | Accuracy: 0.474000 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 003 / 011 | Total loss: 1.416 | Reg loss: 0.037 | Tree loss: 1.416 | Accuracy: 0.505500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 004 / 011 | Total loss: 1.408 | Reg loss: 0.037 | Tree loss: 1.408 | Accuracy: 0.508000 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 005 / 011 | Total loss: 1.404 | Reg loss: 0.037 | Tree loss: 1.404 | Accuracy: 0.511500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 006 / 011 | Total loss: 1.389 | Reg loss: 0.037 | Tree loss: 1.389 | Accuracy: 0.532500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 007 / 011 | Total loss: 1.371 | Reg loss: 0.037 | Tree loss: 1.371 | Accuracy: 0.524500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 008 / 011 | Total loss: 1.375 | Reg loss: 0.037 | Tree loss: 1.375 | Accuracy: 0.509500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 009 / 011 | Total loss: 1.369 | Reg loss: 0.037 | Tree loss: 1.369 | Accuracy: 0.504500 | 0.116 sec/iter\n",
      "Epoch: 51 | Batch: 010 / 011 | Total loss: 1.385 | Reg loss: 0.037 | Tree loss: 1.385 | Accuracy: 0.525597 | 0.116 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 52 | Batch: 000 / 011 | Total loss: 1.523 | Reg loss: 0.037 | Tree loss: 1.523 | Accuracy: 0.471000 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 001 / 011 | Total loss: 1.456 | Reg loss: 0.037 | Tree loss: 1.456 | Accuracy: 0.486000 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 002 / 011 | Total loss: 1.451 | Reg loss: 0.037 | Tree loss: 1.451 | Accuracy: 0.466500 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 003 / 011 | Total loss: 1.417 | Reg loss: 0.037 | Tree loss: 1.417 | Accuracy: 0.500000 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 004 / 011 | Total loss: 1.405 | Reg loss: 0.037 | Tree loss: 1.405 | Accuracy: 0.504500 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 005 / 011 | Total loss: 1.369 | Reg loss: 0.037 | Tree loss: 1.369 | Accuracy: 0.557000 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 006 / 011 | Total loss: 1.392 | Reg loss: 0.037 | Tree loss: 1.392 | Accuracy: 0.523500 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 007 / 011 | Total loss: 1.364 | Reg loss: 0.037 | Tree loss: 1.364 | Accuracy: 0.522500 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 008 / 011 | Total loss: 1.357 | Reg loss: 0.037 | Tree loss: 1.357 | Accuracy: 0.523000 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 009 / 011 | Total loss: 1.352 | Reg loss: 0.037 | Tree loss: 1.352 | Accuracy: 0.519500 | 0.116 sec/iter\n",
      "Epoch: 52 | Batch: 010 / 011 | Total loss: 1.396 | Reg loss: 0.037 | Tree loss: 1.396 | Accuracy: 0.484642 | 0.116 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 53 | Batch: 000 / 011 | Total loss: 1.480 | Reg loss: 0.037 | Tree loss: 1.480 | Accuracy: 0.465500 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 001 / 011 | Total loss: 1.477 | Reg loss: 0.037 | Tree loss: 1.477 | Accuracy: 0.449500 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 002 / 011 | Total loss: 1.445 | Reg loss: 0.037 | Tree loss: 1.445 | Accuracy: 0.479500 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 003 / 011 | Total loss: 1.432 | Reg loss: 0.037 | Tree loss: 1.432 | Accuracy: 0.482000 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 004 / 011 | Total loss: 1.387 | Reg loss: 0.037 | Tree loss: 1.387 | Accuracy: 0.533000 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 005 / 011 | Total loss: 1.373 | Reg loss: 0.037 | Tree loss: 1.373 | Accuracy: 0.541500 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 006 / 011 | Total loss: 1.371 | Reg loss: 0.037 | Tree loss: 1.371 | Accuracy: 0.532000 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 007 / 011 | Total loss: 1.356 | Reg loss: 0.037 | Tree loss: 1.356 | Accuracy: 0.513000 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 008 / 011 | Total loss: 1.320 | Reg loss: 0.037 | Tree loss: 1.320 | Accuracy: 0.535500 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 009 / 011 | Total loss: 1.359 | Reg loss: 0.037 | Tree loss: 1.359 | Accuracy: 0.519000 | 0.117 sec/iter\n",
      "Epoch: 53 | Batch: 010 / 011 | Total loss: 1.339 | Reg loss: 0.037 | Tree loss: 1.339 | Accuracy: 0.535836 | 0.117 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 54 | Batch: 000 / 011 | Total loss: 1.477 | Reg loss: 0.037 | Tree loss: 1.477 | Accuracy: 0.479000 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 001 / 011 | Total loss: 1.452 | Reg loss: 0.037 | Tree loss: 1.452 | Accuracy: 0.493500 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 002 / 011 | Total loss: 1.448 | Reg loss: 0.037 | Tree loss: 1.448 | Accuracy: 0.471000 | 0.118 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 | Batch: 003 / 011 | Total loss: 1.384 | Reg loss: 0.037 | Tree loss: 1.384 | Accuracy: 0.511500 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 004 / 011 | Total loss: 1.381 | Reg loss: 0.037 | Tree loss: 1.381 | Accuracy: 0.515500 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 005 / 011 | Total loss: 1.352 | Reg loss: 0.037 | Tree loss: 1.352 | Accuracy: 0.534000 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 006 / 011 | Total loss: 1.370 | Reg loss: 0.037 | Tree loss: 1.370 | Accuracy: 0.519000 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 007 / 011 | Total loss: 1.341 | Reg loss: 0.037 | Tree loss: 1.341 | Accuracy: 0.523000 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 008 / 011 | Total loss: 1.366 | Reg loss: 0.037 | Tree loss: 1.366 | Accuracy: 0.502500 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 009 / 011 | Total loss: 1.328 | Reg loss: 0.037 | Tree loss: 1.328 | Accuracy: 0.523500 | 0.118 sec/iter\n",
      "Epoch: 54 | Batch: 010 / 011 | Total loss: 1.359 | Reg loss: 0.037 | Tree loss: 1.359 | Accuracy: 0.498294 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 55 | Batch: 000 / 011 | Total loss: 1.487 | Reg loss: 0.037 | Tree loss: 1.487 | Accuracy: 0.461000 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 001 / 011 | Total loss: 1.447 | Reg loss: 0.037 | Tree loss: 1.447 | Accuracy: 0.477000 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 002 / 011 | Total loss: 1.434 | Reg loss: 0.037 | Tree loss: 1.434 | Accuracy: 0.466000 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 003 / 011 | Total loss: 1.394 | Reg loss: 0.037 | Tree loss: 1.394 | Accuracy: 0.498500 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 004 / 011 | Total loss: 1.378 | Reg loss: 0.037 | Tree loss: 1.378 | Accuracy: 0.524500 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 005 / 011 | Total loss: 1.349 | Reg loss: 0.037 | Tree loss: 1.349 | Accuracy: 0.544000 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 006 / 011 | Total loss: 1.345 | Reg loss: 0.037 | Tree loss: 1.345 | Accuracy: 0.532500 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 007 / 011 | Total loss: 1.326 | Reg loss: 0.037 | Tree loss: 1.326 | Accuracy: 0.526500 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 008 / 011 | Total loss: 1.334 | Reg loss: 0.037 | Tree loss: 1.334 | Accuracy: 0.531500 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 009 / 011 | Total loss: 1.349 | Reg loss: 0.037 | Tree loss: 1.349 | Accuracy: 0.500000 | 0.118 sec/iter\n",
      "Epoch: 55 | Batch: 010 / 011 | Total loss: 1.321 | Reg loss: 0.037 | Tree loss: 1.321 | Accuracy: 0.556314 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 56 | Batch: 000 / 011 | Total loss: 1.473 | Reg loss: 0.037 | Tree loss: 1.473 | Accuracy: 0.466000 | 0.118 sec/iter\n",
      "Epoch: 56 | Batch: 001 / 011 | Total loss: 1.437 | Reg loss: 0.037 | Tree loss: 1.437 | Accuracy: 0.477000 | 0.118 sec/iter\n",
      "Epoch: 56 | Batch: 002 / 011 | Total loss: 1.409 | Reg loss: 0.037 | Tree loss: 1.409 | Accuracy: 0.486000 | 0.118 sec/iter\n",
      "Epoch: 56 | Batch: 003 / 011 | Total loss: 1.398 | Reg loss: 0.037 | Tree loss: 1.398 | Accuracy: 0.489500 | 0.118 sec/iter\n",
      "Epoch: 56 | Batch: 004 / 011 | Total loss: 1.358 | Reg loss: 0.037 | Tree loss: 1.358 | Accuracy: 0.503500 | 0.118 sec/iter\n",
      "Epoch: 56 | Batch: 005 / 011 | Total loss: 1.362 | Reg loss: 0.037 | Tree loss: 1.362 | Accuracy: 0.525500 | 0.118 sec/iter\n",
      "Epoch: 56 | Batch: 006 / 011 | Total loss: 1.335 | Reg loss: 0.037 | Tree loss: 1.335 | Accuracy: 0.550000 | 0.117 sec/iter\n",
      "Epoch: 56 | Batch: 007 / 011 | Total loss: 1.335 | Reg loss: 0.038 | Tree loss: 1.335 | Accuracy: 0.521500 | 0.117 sec/iter\n",
      "Epoch: 56 | Batch: 008 / 011 | Total loss: 1.326 | Reg loss: 0.038 | Tree loss: 1.326 | Accuracy: 0.524000 | 0.117 sec/iter\n",
      "Epoch: 56 | Batch: 009 / 011 | Total loss: 1.329 | Reg loss: 0.038 | Tree loss: 1.329 | Accuracy: 0.524500 | 0.117 sec/iter\n",
      "Epoch: 56 | Batch: 010 / 011 | Total loss: 1.268 | Reg loss: 0.038 | Tree loss: 1.268 | Accuracy: 0.522184 | 0.117 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 57 | Batch: 000 / 011 | Total loss: 1.435 | Reg loss: 0.037 | Tree loss: 1.435 | Accuracy: 0.485000 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 001 / 011 | Total loss: 1.433 | Reg loss: 0.038 | Tree loss: 1.433 | Accuracy: 0.483500 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 002 / 011 | Total loss: 1.394 | Reg loss: 0.038 | Tree loss: 1.394 | Accuracy: 0.494500 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 003 / 011 | Total loss: 1.392 | Reg loss: 0.038 | Tree loss: 1.392 | Accuracy: 0.481500 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 004 / 011 | Total loss: 1.372 | Reg loss: 0.038 | Tree loss: 1.372 | Accuracy: 0.523500 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 005 / 011 | Total loss: 1.353 | Reg loss: 0.038 | Tree loss: 1.353 | Accuracy: 0.524000 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 006 / 011 | Total loss: 1.307 | Reg loss: 0.038 | Tree loss: 1.307 | Accuracy: 0.537500 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 007 / 011 | Total loss: 1.308 | Reg loss: 0.038 | Tree loss: 1.308 | Accuracy: 0.526000 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 008 / 011 | Total loss: 1.332 | Reg loss: 0.038 | Tree loss: 1.332 | Accuracy: 0.526500 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 009 / 011 | Total loss: 1.337 | Reg loss: 0.038 | Tree loss: 1.337 | Accuracy: 0.498000 | 0.117 sec/iter\n",
      "Epoch: 57 | Batch: 010 / 011 | Total loss: 1.358 | Reg loss: 0.038 | Tree loss: 1.358 | Accuracy: 0.511945 | 0.117 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 58 | Batch: 000 / 011 | Total loss: 1.447 | Reg loss: 0.038 | Tree loss: 1.447 | Accuracy: 0.477500 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 001 / 011 | Total loss: 1.422 | Reg loss: 0.038 | Tree loss: 1.422 | Accuracy: 0.476000 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 002 / 011 | Total loss: 1.400 | Reg loss: 0.038 | Tree loss: 1.400 | Accuracy: 0.476000 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 003 / 011 | Total loss: 1.362 | Reg loss: 0.038 | Tree loss: 1.362 | Accuracy: 0.508500 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 004 / 011 | Total loss: 1.356 | Reg loss: 0.038 | Tree loss: 1.356 | Accuracy: 0.517500 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 005 / 011 | Total loss: 1.357 | Reg loss: 0.038 | Tree loss: 1.357 | Accuracy: 0.516000 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 006 / 011 | Total loss: 1.316 | Reg loss: 0.038 | Tree loss: 1.316 | Accuracy: 0.546000 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 007 / 011 | Total loss: 1.320 | Reg loss: 0.038 | Tree loss: 1.320 | Accuracy: 0.525500 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 008 / 011 | Total loss: 1.308 | Reg loss: 0.038 | Tree loss: 1.308 | Accuracy: 0.531000 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 009 / 011 | Total loss: 1.320 | Reg loss: 0.038 | Tree loss: 1.320 | Accuracy: 0.527500 | 0.118 sec/iter\n",
      "Epoch: 58 | Batch: 010 / 011 | Total loss: 1.339 | Reg loss: 0.038 | Tree loss: 1.339 | Accuracy: 0.511945 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 59 | Batch: 000 / 011 | Total loss: 1.439 | Reg loss: 0.038 | Tree loss: 1.439 | Accuracy: 0.468500 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 001 / 011 | Total loss: 1.437 | Reg loss: 0.038 | Tree loss: 1.437 | Accuracy: 0.457500 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 002 / 011 | Total loss: 1.367 | Reg loss: 0.038 | Tree loss: 1.367 | Accuracy: 0.495000 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 003 / 011 | Total loss: 1.382 | Reg loss: 0.038 | Tree loss: 1.382 | Accuracy: 0.477500 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 004 / 011 | Total loss: 1.336 | Reg loss: 0.038 | Tree loss: 1.336 | Accuracy: 0.514500 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 005 / 011 | Total loss: 1.316 | Reg loss: 0.038 | Tree loss: 1.316 | Accuracy: 0.533500 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 006 / 011 | Total loss: 1.318 | Reg loss: 0.038 | Tree loss: 1.318 | Accuracy: 0.548000 | 0.119 sec/iter\n",
      "Epoch: 59 | Batch: 007 / 011 | Total loss: 1.319 | Reg loss: 0.038 | Tree loss: 1.319 | Accuracy: 0.549000 | 0.118 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 | Batch: 008 / 011 | Total loss: 1.315 | Reg loss: 0.038 | Tree loss: 1.315 | Accuracy: 0.526000 | 0.118 sec/iter\n",
      "Epoch: 59 | Batch: 009 / 011 | Total loss: 1.304 | Reg loss: 0.038 | Tree loss: 1.304 | Accuracy: 0.536000 | 0.118 sec/iter\n",
      "Epoch: 59 | Batch: 010 / 011 | Total loss: 1.327 | Reg loss: 0.038 | Tree loss: 1.327 | Accuracy: 0.470990 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 60 | Batch: 000 / 011 | Total loss: 1.435 | Reg loss: 0.038 | Tree loss: 1.435 | Accuracy: 0.472000 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 001 / 011 | Total loss: 1.416 | Reg loss: 0.038 | Tree loss: 1.416 | Accuracy: 0.470500 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 002 / 011 | Total loss: 1.396 | Reg loss: 0.038 | Tree loss: 1.396 | Accuracy: 0.477000 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 003 / 011 | Total loss: 1.352 | Reg loss: 0.038 | Tree loss: 1.352 | Accuracy: 0.517000 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 004 / 011 | Total loss: 1.328 | Reg loss: 0.038 | Tree loss: 1.328 | Accuracy: 0.519500 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 005 / 011 | Total loss: 1.321 | Reg loss: 0.038 | Tree loss: 1.321 | Accuracy: 0.545500 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 006 / 011 | Total loss: 1.314 | Reg loss: 0.038 | Tree loss: 1.314 | Accuracy: 0.541000 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 007 / 011 | Total loss: 1.312 | Reg loss: 0.038 | Tree loss: 1.312 | Accuracy: 0.525500 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 008 / 011 | Total loss: 1.294 | Reg loss: 0.038 | Tree loss: 1.294 | Accuracy: 0.537500 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 009 / 011 | Total loss: 1.283 | Reg loss: 0.038 | Tree loss: 1.283 | Accuracy: 0.551000 | 0.119 sec/iter\n",
      "Epoch: 60 | Batch: 010 / 011 | Total loss: 1.301 | Reg loss: 0.038 | Tree loss: 1.301 | Accuracy: 0.508532 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 61 | Batch: 000 / 011 | Total loss: 1.426 | Reg loss: 0.038 | Tree loss: 1.426 | Accuracy: 0.478500 | 0.119 sec/iter\n",
      "Epoch: 61 | Batch: 001 / 011 | Total loss: 1.394 | Reg loss: 0.038 | Tree loss: 1.394 | Accuracy: 0.474500 | 0.119 sec/iter\n",
      "Epoch: 61 | Batch: 002 / 011 | Total loss: 1.409 | Reg loss: 0.038 | Tree loss: 1.409 | Accuracy: 0.448000 | 0.119 sec/iter\n",
      "Epoch: 61 | Batch: 003 / 011 | Total loss: 1.356 | Reg loss: 0.038 | Tree loss: 1.356 | Accuracy: 0.500500 | 0.119 sec/iter\n",
      "Epoch: 61 | Batch: 004 / 011 | Total loss: 1.321 | Reg loss: 0.038 | Tree loss: 1.321 | Accuracy: 0.526500 | 0.119 sec/iter\n",
      "Epoch: 61 | Batch: 005 / 011 | Total loss: 1.305 | Reg loss: 0.038 | Tree loss: 1.305 | Accuracy: 0.537000 | 0.119 sec/iter\n",
      "Epoch: 61 | Batch: 006 / 011 | Total loss: 1.306 | Reg loss: 0.038 | Tree loss: 1.306 | Accuracy: 0.551500 | 0.118 sec/iter\n",
      "Epoch: 61 | Batch: 007 / 011 | Total loss: 1.297 | Reg loss: 0.038 | Tree loss: 1.297 | Accuracy: 0.545000 | 0.118 sec/iter\n",
      "Epoch: 61 | Batch: 008 / 011 | Total loss: 1.303 | Reg loss: 0.038 | Tree loss: 1.303 | Accuracy: 0.527500 | 0.118 sec/iter\n",
      "Epoch: 61 | Batch: 009 / 011 | Total loss: 1.292 | Reg loss: 0.038 | Tree loss: 1.292 | Accuracy: 0.528000 | 0.118 sec/iter\n",
      "Epoch: 61 | Batch: 010 / 011 | Total loss: 1.225 | Reg loss: 0.038 | Tree loss: 1.225 | Accuracy: 0.597270 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 62 | Batch: 000 / 011 | Total loss: 1.405 | Reg loss: 0.038 | Tree loss: 1.405 | Accuracy: 0.490000 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 001 / 011 | Total loss: 1.383 | Reg loss: 0.038 | Tree loss: 1.383 | Accuracy: 0.488500 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 002 / 011 | Total loss: 1.361 | Reg loss: 0.038 | Tree loss: 1.361 | Accuracy: 0.496500 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 003 / 011 | Total loss: 1.351 | Reg loss: 0.038 | Tree loss: 1.351 | Accuracy: 0.490500 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 004 / 011 | Total loss: 1.321 | Reg loss: 0.038 | Tree loss: 1.321 | Accuracy: 0.543000 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 005 / 011 | Total loss: 1.330 | Reg loss: 0.038 | Tree loss: 1.330 | Accuracy: 0.531500 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 006 / 011 | Total loss: 1.295 | Reg loss: 0.038 | Tree loss: 1.295 | Accuracy: 0.555500 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 007 / 011 | Total loss: 1.299 | Reg loss: 0.038 | Tree loss: 1.299 | Accuracy: 0.536000 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 008 / 011 | Total loss: 1.308 | Reg loss: 0.038 | Tree loss: 1.308 | Accuracy: 0.503000 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 009 / 011 | Total loss: 1.280 | Reg loss: 0.038 | Tree loss: 1.280 | Accuracy: 0.540000 | 0.118 sec/iter\n",
      "Epoch: 62 | Batch: 010 / 011 | Total loss: 1.267 | Reg loss: 0.038 | Tree loss: 1.267 | Accuracy: 0.539249 | 0.118 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 63 | Batch: 000 / 011 | Total loss: 1.427 | Reg loss: 0.038 | Tree loss: 1.427 | Accuracy: 0.476000 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 001 / 011 | Total loss: 1.387 | Reg loss: 0.038 | Tree loss: 1.387 | Accuracy: 0.486500 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 002 / 011 | Total loss: 1.368 | Reg loss: 0.038 | Tree loss: 1.368 | Accuracy: 0.486000 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 003 / 011 | Total loss: 1.331 | Reg loss: 0.038 | Tree loss: 1.331 | Accuracy: 0.513500 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 004 / 011 | Total loss: 1.328 | Reg loss: 0.038 | Tree loss: 1.328 | Accuracy: 0.525000 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 005 / 011 | Total loss: 1.293 | Reg loss: 0.038 | Tree loss: 1.293 | Accuracy: 0.548000 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 006 / 011 | Total loss: 1.304 | Reg loss: 0.038 | Tree loss: 1.304 | Accuracy: 0.535000 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 007 / 011 | Total loss: 1.266 | Reg loss: 0.038 | Tree loss: 1.266 | Accuracy: 0.554500 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 008 / 011 | Total loss: 1.293 | Reg loss: 0.039 | Tree loss: 1.293 | Accuracy: 0.533000 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 009 / 011 | Total loss: 1.277 | Reg loss: 0.039 | Tree loss: 1.277 | Accuracy: 0.529500 | 0.12 sec/iter\n",
      "Epoch: 63 | Batch: 010 / 011 | Total loss: 1.226 | Reg loss: 0.039 | Tree loss: 1.226 | Accuracy: 0.576792 | 0.12 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 64 | Batch: 000 / 011 | Total loss: 1.396 | Reg loss: 0.038 | Tree loss: 1.396 | Accuracy: 0.479500 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 001 / 011 | Total loss: 1.392 | Reg loss: 0.038 | Tree loss: 1.392 | Accuracy: 0.475000 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 002 / 011 | Total loss: 1.349 | Reg loss: 0.038 | Tree loss: 1.349 | Accuracy: 0.518500 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 003 / 011 | Total loss: 1.330 | Reg loss: 0.039 | Tree loss: 1.330 | Accuracy: 0.516000 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 004 / 011 | Total loss: 1.301 | Reg loss: 0.039 | Tree loss: 1.301 | Accuracy: 0.541000 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 005 / 011 | Total loss: 1.293 | Reg loss: 0.039 | Tree loss: 1.293 | Accuracy: 0.555000 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 006 / 011 | Total loss: 1.295 | Reg loss: 0.039 | Tree loss: 1.295 | Accuracy: 0.546500 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 007 / 011 | Total loss: 1.286 | Reg loss: 0.039 | Tree loss: 1.286 | Accuracy: 0.528500 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 008 / 011 | Total loss: 1.268 | Reg loss: 0.039 | Tree loss: 1.268 | Accuracy: 0.536500 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 009 / 011 | Total loss: 1.286 | Reg loss: 0.039 | Tree loss: 1.286 | Accuracy: 0.506500 | 0.121 sec/iter\n",
      "Epoch: 64 | Batch: 010 / 011 | Total loss: 1.259 | Reg loss: 0.039 | Tree loss: 1.259 | Accuracy: 0.539249 | 0.121 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 | Batch: 000 / 011 | Total loss: 1.392 | Reg loss: 0.039 | Tree loss: 1.392 | Accuracy: 0.496500 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 001 / 011 | Total loss: 1.365 | Reg loss: 0.039 | Tree loss: 1.365 | Accuracy: 0.491000 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 002 / 011 | Total loss: 1.353 | Reg loss: 0.039 | Tree loss: 1.353 | Accuracy: 0.472500 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 003 / 011 | Total loss: 1.340 | Reg loss: 0.039 | Tree loss: 1.340 | Accuracy: 0.504000 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 004 / 011 | Total loss: 1.296 | Reg loss: 0.039 | Tree loss: 1.296 | Accuracy: 0.533500 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 005 / 011 | Total loss: 1.293 | Reg loss: 0.039 | Tree loss: 1.293 | Accuracy: 0.536000 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 006 / 011 | Total loss: 1.280 | Reg loss: 0.039 | Tree loss: 1.280 | Accuracy: 0.550000 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 007 / 011 | Total loss: 1.291 | Reg loss: 0.039 | Tree loss: 1.291 | Accuracy: 0.526500 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 008 / 011 | Total loss: 1.260 | Reg loss: 0.039 | Tree loss: 1.260 | Accuracy: 0.555000 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 009 / 011 | Total loss: 1.274 | Reg loss: 0.039 | Tree loss: 1.274 | Accuracy: 0.533000 | 0.122 sec/iter\n",
      "Epoch: 65 | Batch: 010 / 011 | Total loss: 1.276 | Reg loss: 0.039 | Tree loss: 1.276 | Accuracy: 0.552901 | 0.122 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 66 | Batch: 000 / 011 | Total loss: 1.382 | Reg loss: 0.039 | Tree loss: 1.382 | Accuracy: 0.494500 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 001 / 011 | Total loss: 1.368 | Reg loss: 0.039 | Tree loss: 1.368 | Accuracy: 0.492000 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 002 / 011 | Total loss: 1.345 | Reg loss: 0.039 | Tree loss: 1.345 | Accuracy: 0.494000 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 003 / 011 | Total loss: 1.312 | Reg loss: 0.039 | Tree loss: 1.312 | Accuracy: 0.521000 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 004 / 011 | Total loss: 1.304 | Reg loss: 0.039 | Tree loss: 1.304 | Accuracy: 0.531500 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 005 / 011 | Total loss: 1.288 | Reg loss: 0.039 | Tree loss: 1.288 | Accuracy: 0.552000 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 006 / 011 | Total loss: 1.263 | Reg loss: 0.039 | Tree loss: 1.263 | Accuracy: 0.554500 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 007 / 011 | Total loss: 1.267 | Reg loss: 0.039 | Tree loss: 1.267 | Accuracy: 0.549000 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 008 / 011 | Total loss: 1.276 | Reg loss: 0.039 | Tree loss: 1.276 | Accuracy: 0.531500 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 009 / 011 | Total loss: 1.280 | Reg loss: 0.039 | Tree loss: 1.280 | Accuracy: 0.515500 | 0.122 sec/iter\n",
      "Epoch: 66 | Batch: 010 / 011 | Total loss: 1.239 | Reg loss: 0.039 | Tree loss: 1.239 | Accuracy: 0.576792 | 0.122 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 67 | Batch: 000 / 011 | Total loss: 1.382 | Reg loss: 0.039 | Tree loss: 1.382 | Accuracy: 0.493500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 001 / 011 | Total loss: 1.354 | Reg loss: 0.039 | Tree loss: 1.354 | Accuracy: 0.517000 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 002 / 011 | Total loss: 1.324 | Reg loss: 0.039 | Tree loss: 1.324 | Accuracy: 0.498500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 003 / 011 | Total loss: 1.335 | Reg loss: 0.039 | Tree loss: 1.335 | Accuracy: 0.480500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 004 / 011 | Total loss: 1.286 | Reg loss: 0.039 | Tree loss: 1.286 | Accuracy: 0.540000 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 005 / 011 | Total loss: 1.300 | Reg loss: 0.039 | Tree loss: 1.300 | Accuracy: 0.525500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 006 / 011 | Total loss: 1.279 | Reg loss: 0.039 | Tree loss: 1.279 | Accuracy: 0.534000 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 007 / 011 | Total loss: 1.256 | Reg loss: 0.039 | Tree loss: 1.256 | Accuracy: 0.560500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 008 / 011 | Total loss: 1.263 | Reg loss: 0.039 | Tree loss: 1.263 | Accuracy: 0.514500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 009 / 011 | Total loss: 1.256 | Reg loss: 0.039 | Tree loss: 1.256 | Accuracy: 0.529500 | 0.122 sec/iter\n",
      "Epoch: 67 | Batch: 010 / 011 | Total loss: 1.254 | Reg loss: 0.039 | Tree loss: 1.254 | Accuracy: 0.569966 | 0.122 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 68 | Batch: 000 / 011 | Total loss: 1.376 | Reg loss: 0.039 | Tree loss: 1.376 | Accuracy: 0.502000 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 001 / 011 | Total loss: 1.376 | Reg loss: 0.039 | Tree loss: 1.376 | Accuracy: 0.482500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 002 / 011 | Total loss: 1.328 | Reg loss: 0.039 | Tree loss: 1.328 | Accuracy: 0.508500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 003 / 011 | Total loss: 1.317 | Reg loss: 0.039 | Tree loss: 1.317 | Accuracy: 0.493500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 004 / 011 | Total loss: 1.286 | Reg loss: 0.039 | Tree loss: 1.286 | Accuracy: 0.532500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 005 / 011 | Total loss: 1.273 | Reg loss: 0.039 | Tree loss: 1.273 | Accuracy: 0.540500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 006 / 011 | Total loss: 1.271 | Reg loss: 0.039 | Tree loss: 1.271 | Accuracy: 0.553000 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 007 / 011 | Total loss: 1.250 | Reg loss: 0.039 | Tree loss: 1.250 | Accuracy: 0.541500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 008 / 011 | Total loss: 1.250 | Reg loss: 0.039 | Tree loss: 1.250 | Accuracy: 0.530500 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 009 / 011 | Total loss: 1.253 | Reg loss: 0.039 | Tree loss: 1.253 | Accuracy: 0.540000 | 0.123 sec/iter\n",
      "Epoch: 68 | Batch: 010 / 011 | Total loss: 1.247 | Reg loss: 0.039 | Tree loss: 1.247 | Accuracy: 0.566553 | 0.123 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 69 | Batch: 000 / 011 | Total loss: 1.360 | Reg loss: 0.039 | Tree loss: 1.360 | Accuracy: 0.509000 | 0.124 sec/iter\n",
      "Epoch: 69 | Batch: 001 / 011 | Total loss: 1.346 | Reg loss: 0.039 | Tree loss: 1.346 | Accuracy: 0.505000 | 0.124 sec/iter\n",
      "Epoch: 69 | Batch: 002 / 011 | Total loss: 1.336 | Reg loss: 0.039 | Tree loss: 1.336 | Accuracy: 0.496500 | 0.124 sec/iter\n",
      "Epoch: 69 | Batch: 003 / 011 | Total loss: 1.309 | Reg loss: 0.039 | Tree loss: 1.309 | Accuracy: 0.508000 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 004 / 011 | Total loss: 1.287 | Reg loss: 0.039 | Tree loss: 1.287 | Accuracy: 0.508500 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 005 / 011 | Total loss: 1.275 | Reg loss: 0.039 | Tree loss: 1.275 | Accuracy: 0.547500 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 006 / 011 | Total loss: 1.258 | Reg loss: 0.039 | Tree loss: 1.258 | Accuracy: 0.551500 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 007 / 011 | Total loss: 1.273 | Reg loss: 0.039 | Tree loss: 1.273 | Accuracy: 0.531500 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 008 / 011 | Total loss: 1.250 | Reg loss: 0.039 | Tree loss: 1.250 | Accuracy: 0.540500 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 009 / 011 | Total loss: 1.237 | Reg loss: 0.039 | Tree loss: 1.237 | Accuracy: 0.539000 | 0.123 sec/iter\n",
      "Epoch: 69 | Batch: 010 / 011 | Total loss: 1.219 | Reg loss: 0.039 | Tree loss: 1.219 | Accuracy: 0.569966 | 0.123 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 70 | Batch: 000 / 011 | Total loss: 1.371 | Reg loss: 0.039 | Tree loss: 1.371 | Accuracy: 0.489500 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 001 / 011 | Total loss: 1.356 | Reg loss: 0.039 | Tree loss: 1.356 | Accuracy: 0.487000 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 002 / 011 | Total loss: 1.317 | Reg loss: 0.039 | Tree loss: 1.317 | Accuracy: 0.506000 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 003 / 011 | Total loss: 1.308 | Reg loss: 0.039 | Tree loss: 1.308 | Accuracy: 0.497000 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 004 / 011 | Total loss: 1.288 | Reg loss: 0.039 | Tree loss: 1.288 | Accuracy: 0.543500 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 005 / 011 | Total loss: 1.254 | Reg loss: 0.039 | Tree loss: 1.254 | Accuracy: 0.576000 | 0.124 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 | Batch: 006 / 011 | Total loss: 1.235 | Reg loss: 0.039 | Tree loss: 1.235 | Accuracy: 0.575500 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 007 / 011 | Total loss: 1.242 | Reg loss: 0.039 | Tree loss: 1.242 | Accuracy: 0.553500 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 008 / 011 | Total loss: 1.246 | Reg loss: 0.039 | Tree loss: 1.246 | Accuracy: 0.525000 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 009 / 011 | Total loss: 1.250 | Reg loss: 0.039 | Tree loss: 1.250 | Accuracy: 0.521000 | 0.124 sec/iter\n",
      "Epoch: 70 | Batch: 010 / 011 | Total loss: 1.274 | Reg loss: 0.039 | Tree loss: 1.274 | Accuracy: 0.529010 | 0.124 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 71 | Batch: 000 / 011 | Total loss: 1.356 | Reg loss: 0.039 | Tree loss: 1.356 | Accuracy: 0.502500 | 0.124 sec/iter\n",
      "Epoch: 71 | Batch: 001 / 011 | Total loss: 1.359 | Reg loss: 0.039 | Tree loss: 1.359 | Accuracy: 0.483000 | 0.124 sec/iter\n",
      "Epoch: 71 | Batch: 002 / 011 | Total loss: 1.313 | Reg loss: 0.039 | Tree loss: 1.313 | Accuracy: 0.491500 | 0.124 sec/iter\n",
      "Epoch: 71 | Batch: 003 / 011 | Total loss: 1.286 | Reg loss: 0.039 | Tree loss: 1.286 | Accuracy: 0.512500 | 0.124 sec/iter\n",
      "Epoch: 71 | Batch: 004 / 011 | Total loss: 1.279 | Reg loss: 0.039 | Tree loss: 1.279 | Accuracy: 0.539000 | 0.124 sec/iter\n",
      "Epoch: 71 | Batch: 005 / 011 | Total loss: 1.261 | Reg loss: 0.039 | Tree loss: 1.261 | Accuracy: 0.555000 | 0.123 sec/iter\n",
      "Epoch: 71 | Batch: 006 / 011 | Total loss: 1.244 | Reg loss: 0.039 | Tree loss: 1.244 | Accuracy: 0.571000 | 0.123 sec/iter\n",
      "Epoch: 71 | Batch: 007 / 011 | Total loss: 1.237 | Reg loss: 0.039 | Tree loss: 1.237 | Accuracy: 0.541000 | 0.123 sec/iter\n",
      "Epoch: 71 | Batch: 008 / 011 | Total loss: 1.254 | Reg loss: 0.039 | Tree loss: 1.254 | Accuracy: 0.537500 | 0.123 sec/iter\n",
      "Epoch: 71 | Batch: 009 / 011 | Total loss: 1.237 | Reg loss: 0.039 | Tree loss: 1.237 | Accuracy: 0.535500 | 0.123 sec/iter\n",
      "Epoch: 71 | Batch: 010 / 011 | Total loss: 1.241 | Reg loss: 0.039 | Tree loss: 1.241 | Accuracy: 0.505119 | 0.123 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 72 | Batch: 000 / 011 | Total loss: 1.363 | Reg loss: 0.039 | Tree loss: 1.363 | Accuracy: 0.485500 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 001 / 011 | Total loss: 1.346 | Reg loss: 0.039 | Tree loss: 1.346 | Accuracy: 0.485500 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 002 / 011 | Total loss: 1.315 | Reg loss: 0.039 | Tree loss: 1.315 | Accuracy: 0.496000 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 003 / 011 | Total loss: 1.295 | Reg loss: 0.039 | Tree loss: 1.295 | Accuracy: 0.517000 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 004 / 011 | Total loss: 1.260 | Reg loss: 0.039 | Tree loss: 1.260 | Accuracy: 0.544000 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 005 / 011 | Total loss: 1.259 | Reg loss: 0.039 | Tree loss: 1.259 | Accuracy: 0.561000 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 006 / 011 | Total loss: 1.224 | Reg loss: 0.039 | Tree loss: 1.224 | Accuracy: 0.602500 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 007 / 011 | Total loss: 1.245 | Reg loss: 0.039 | Tree loss: 1.245 | Accuracy: 0.535000 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 008 / 011 | Total loss: 1.242 | Reg loss: 0.040 | Tree loss: 1.242 | Accuracy: 0.531000 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 009 / 011 | Total loss: 1.241 | Reg loss: 0.040 | Tree loss: 1.241 | Accuracy: 0.535500 | 0.123 sec/iter\n",
      "Epoch: 72 | Batch: 010 / 011 | Total loss: 1.207 | Reg loss: 0.040 | Tree loss: 1.207 | Accuracy: 0.563140 | 0.123 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 73 | Batch: 000 / 011 | Total loss: 1.345 | Reg loss: 0.039 | Tree loss: 1.345 | Accuracy: 0.511500 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 001 / 011 | Total loss: 1.324 | Reg loss: 0.039 | Tree loss: 1.324 | Accuracy: 0.491500 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 002 / 011 | Total loss: 1.306 | Reg loss: 0.039 | Tree loss: 1.306 | Accuracy: 0.504000 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 003 / 011 | Total loss: 1.288 | Reg loss: 0.039 | Tree loss: 1.288 | Accuracy: 0.513000 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 004 / 011 | Total loss: 1.274 | Reg loss: 0.039 | Tree loss: 1.274 | Accuracy: 0.525500 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 005 / 011 | Total loss: 1.231 | Reg loss: 0.040 | Tree loss: 1.231 | Accuracy: 0.565000 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 006 / 011 | Total loss: 1.232 | Reg loss: 0.040 | Tree loss: 1.232 | Accuracy: 0.562000 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 007 / 011 | Total loss: 1.247 | Reg loss: 0.040 | Tree loss: 1.247 | Accuracy: 0.532000 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 008 / 011 | Total loss: 1.240 | Reg loss: 0.040 | Tree loss: 1.240 | Accuracy: 0.538000 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 009 / 011 | Total loss: 1.240 | Reg loss: 0.040 | Tree loss: 1.240 | Accuracy: 0.524500 | 0.125 sec/iter\n",
      "Epoch: 73 | Batch: 010 / 011 | Total loss: 1.233 | Reg loss: 0.040 | Tree loss: 1.233 | Accuracy: 0.505119 | 0.125 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 74 | Batch: 000 / 011 | Total loss: 1.342 | Reg loss: 0.040 | Tree loss: 1.342 | Accuracy: 0.496500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 001 / 011 | Total loss: 1.318 | Reg loss: 0.040 | Tree loss: 1.318 | Accuracy: 0.498500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 002 / 011 | Total loss: 1.310 | Reg loss: 0.040 | Tree loss: 1.310 | Accuracy: 0.489500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 003 / 011 | Total loss: 1.290 | Reg loss: 0.040 | Tree loss: 1.290 | Accuracy: 0.498500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 004 / 011 | Total loss: 1.274 | Reg loss: 0.040 | Tree loss: 1.274 | Accuracy: 0.530000 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 005 / 011 | Total loss: 1.235 | Reg loss: 0.040 | Tree loss: 1.235 | Accuracy: 0.566000 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 006 / 011 | Total loss: 1.235 | Reg loss: 0.040 | Tree loss: 1.235 | Accuracy: 0.566500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 007 / 011 | Total loss: 1.245 | Reg loss: 0.040 | Tree loss: 1.245 | Accuracy: 0.534500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 008 / 011 | Total loss: 1.237 | Reg loss: 0.040 | Tree loss: 1.237 | Accuracy: 0.540500 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 009 / 011 | Total loss: 1.215 | Reg loss: 0.040 | Tree loss: 1.215 | Accuracy: 0.538000 | 0.127 sec/iter\n",
      "Epoch: 74 | Batch: 010 / 011 | Total loss: 1.225 | Reg loss: 0.040 | Tree loss: 1.225 | Accuracy: 0.511945 | 0.127 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 75 | Batch: 000 / 011 | Total loss: 1.335 | Reg loss: 0.040 | Tree loss: 1.335 | Accuracy: 0.510500 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 001 / 011 | Total loss: 1.318 | Reg loss: 0.040 | Tree loss: 1.318 | Accuracy: 0.510500 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 002 / 011 | Total loss: 1.323 | Reg loss: 0.040 | Tree loss: 1.323 | Accuracy: 0.478000 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 003 / 011 | Total loss: 1.277 | Reg loss: 0.040 | Tree loss: 1.277 | Accuracy: 0.510500 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 004 / 011 | Total loss: 1.260 | Reg loss: 0.040 | Tree loss: 1.260 | Accuracy: 0.514000 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 005 / 011 | Total loss: 1.240 | Reg loss: 0.040 | Tree loss: 1.240 | Accuracy: 0.549500 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 006 / 011 | Total loss: 1.222 | Reg loss: 0.040 | Tree loss: 1.222 | Accuracy: 0.565500 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 007 / 011 | Total loss: 1.218 | Reg loss: 0.040 | Tree loss: 1.218 | Accuracy: 0.555000 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 008 / 011 | Total loss: 1.231 | Reg loss: 0.040 | Tree loss: 1.231 | Accuracy: 0.543500 | 0.129 sec/iter\n",
      "Epoch: 75 | Batch: 009 / 011 | Total loss: 1.235 | Reg loss: 0.040 | Tree loss: 1.235 | Accuracy: 0.541000 | 0.129 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 | Batch: 010 / 011 | Total loss: 1.199 | Reg loss: 0.040 | Tree loss: 1.199 | Accuracy: 0.525597 | 0.129 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 76 | Batch: 000 / 011 | Total loss: 1.337 | Reg loss: 0.040 | Tree loss: 1.337 | Accuracy: 0.504500 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 001 / 011 | Total loss: 1.338 | Reg loss: 0.040 | Tree loss: 1.338 | Accuracy: 0.497000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 002 / 011 | Total loss: 1.288 | Reg loss: 0.040 | Tree loss: 1.288 | Accuracy: 0.504500 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 003 / 011 | Total loss: 1.262 | Reg loss: 0.040 | Tree loss: 1.262 | Accuracy: 0.522000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 004 / 011 | Total loss: 1.251 | Reg loss: 0.040 | Tree loss: 1.251 | Accuracy: 0.546000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 005 / 011 | Total loss: 1.238 | Reg loss: 0.040 | Tree loss: 1.238 | Accuracy: 0.555000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 006 / 011 | Total loss: 1.222 | Reg loss: 0.040 | Tree loss: 1.222 | Accuracy: 0.560000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 007 / 011 | Total loss: 1.231 | Reg loss: 0.040 | Tree loss: 1.231 | Accuracy: 0.531000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 008 / 011 | Total loss: 1.222 | Reg loss: 0.040 | Tree loss: 1.222 | Accuracy: 0.532500 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 009 / 011 | Total loss: 1.210 | Reg loss: 0.040 | Tree loss: 1.210 | Accuracy: 0.543000 | 0.13 sec/iter\n",
      "Epoch: 76 | Batch: 010 / 011 | Total loss: 1.220 | Reg loss: 0.040 | Tree loss: 1.220 | Accuracy: 0.522184 | 0.13 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 77 | Batch: 000 / 011 | Total loss: 1.332 | Reg loss: 0.040 | Tree loss: 1.332 | Accuracy: 0.483000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 001 / 011 | Total loss: 1.306 | Reg loss: 0.040 | Tree loss: 1.306 | Accuracy: 0.513000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 002 / 011 | Total loss: 1.298 | Reg loss: 0.040 | Tree loss: 1.298 | Accuracy: 0.483500 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 003 / 011 | Total loss: 1.279 | Reg loss: 0.040 | Tree loss: 1.279 | Accuracy: 0.511500 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 004 / 011 | Total loss: 1.255 | Reg loss: 0.040 | Tree loss: 1.255 | Accuracy: 0.545000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 005 / 011 | Total loss: 1.241 | Reg loss: 0.040 | Tree loss: 1.241 | Accuracy: 0.560000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 006 / 011 | Total loss: 1.210 | Reg loss: 0.040 | Tree loss: 1.210 | Accuracy: 0.563000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 007 / 011 | Total loss: 1.210 | Reg loss: 0.040 | Tree loss: 1.210 | Accuracy: 0.574000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 008 / 011 | Total loss: 1.196 | Reg loss: 0.040 | Tree loss: 1.196 | Accuracy: 0.561000 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 009 / 011 | Total loss: 1.212 | Reg loss: 0.040 | Tree loss: 1.212 | Accuracy: 0.546500 | 0.132 sec/iter\n",
      "Epoch: 77 | Batch: 010 / 011 | Total loss: 1.251 | Reg loss: 0.040 | Tree loss: 1.251 | Accuracy: 0.552901 | 0.132 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 78 | Batch: 000 / 011 | Total loss: 1.339 | Reg loss: 0.040 | Tree loss: 1.339 | Accuracy: 0.503500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 001 / 011 | Total loss: 1.313 | Reg loss: 0.040 | Tree loss: 1.313 | Accuracy: 0.496500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 002 / 011 | Total loss: 1.285 | Reg loss: 0.040 | Tree loss: 1.285 | Accuracy: 0.509000 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 003 / 011 | Total loss: 1.249 | Reg loss: 0.040 | Tree loss: 1.249 | Accuracy: 0.527500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 004 / 011 | Total loss: 1.247 | Reg loss: 0.040 | Tree loss: 1.247 | Accuracy: 0.521500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 005 / 011 | Total loss: 1.212 | Reg loss: 0.040 | Tree loss: 1.212 | Accuracy: 0.563500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 006 / 011 | Total loss: 1.213 | Reg loss: 0.040 | Tree loss: 1.213 | Accuracy: 0.563500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 007 / 011 | Total loss: 1.236 | Reg loss: 0.040 | Tree loss: 1.236 | Accuracy: 0.517500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 008 / 011 | Total loss: 1.200 | Reg loss: 0.040 | Tree loss: 1.200 | Accuracy: 0.551500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 009 / 011 | Total loss: 1.212 | Reg loss: 0.040 | Tree loss: 1.212 | Accuracy: 0.543500 | 0.133 sec/iter\n",
      "Epoch: 78 | Batch: 010 / 011 | Total loss: 1.256 | Reg loss: 0.040 | Tree loss: 1.256 | Accuracy: 0.525597 | 0.133 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 79 | Batch: 000 / 011 | Total loss: 1.311 | Reg loss: 0.040 | Tree loss: 1.311 | Accuracy: 0.513000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 001 / 011 | Total loss: 1.324 | Reg loss: 0.040 | Tree loss: 1.324 | Accuracy: 0.499000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 002 / 011 | Total loss: 1.280 | Reg loss: 0.040 | Tree loss: 1.280 | Accuracy: 0.503500 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 003 / 011 | Total loss: 1.254 | Reg loss: 0.040 | Tree loss: 1.254 | Accuracy: 0.528000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 004 / 011 | Total loss: 1.248 | Reg loss: 0.040 | Tree loss: 1.248 | Accuracy: 0.538000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 005 / 011 | Total loss: 1.227 | Reg loss: 0.040 | Tree loss: 1.227 | Accuracy: 0.576000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 006 / 011 | Total loss: 1.211 | Reg loss: 0.040 | Tree loss: 1.211 | Accuracy: 0.554000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 007 / 011 | Total loss: 1.214 | Reg loss: 0.040 | Tree loss: 1.214 | Accuracy: 0.540000 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 008 / 011 | Total loss: 1.208 | Reg loss: 0.040 | Tree loss: 1.208 | Accuracy: 0.556500 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 009 / 011 | Total loss: 1.194 | Reg loss: 0.040 | Tree loss: 1.194 | Accuracy: 0.540500 | 0.134 sec/iter\n",
      "Epoch: 79 | Batch: 010 / 011 | Total loss: 1.179 | Reg loss: 0.040 | Tree loss: 1.179 | Accuracy: 0.542662 | 0.134 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 80 | Batch: 000 / 011 | Total loss: 1.319 | Reg loss: 0.040 | Tree loss: 1.319 | Accuracy: 0.500500 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 001 / 011 | Total loss: 1.292 | Reg loss: 0.040 | Tree loss: 1.292 | Accuracy: 0.498500 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 002 / 011 | Total loss: 1.275 | Reg loss: 0.040 | Tree loss: 1.275 | Accuracy: 0.506000 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 003 / 011 | Total loss: 1.268 | Reg loss: 0.040 | Tree loss: 1.268 | Accuracy: 0.503000 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 004 / 011 | Total loss: 1.232 | Reg loss: 0.040 | Tree loss: 1.232 | Accuracy: 0.546500 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 005 / 011 | Total loss: 1.245 | Reg loss: 0.040 | Tree loss: 1.245 | Accuracy: 0.553500 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 006 / 011 | Total loss: 1.213 | Reg loss: 0.040 | Tree loss: 1.213 | Accuracy: 0.548000 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 007 / 011 | Total loss: 1.189 | Reg loss: 0.040 | Tree loss: 1.189 | Accuracy: 0.566500 | 0.136 sec/iter\n",
      "Epoch: 80 | Batch: 008 / 011 | Total loss: 1.215 | Reg loss: 0.040 | Tree loss: 1.215 | Accuracy: 0.542000 | 0.135 sec/iter\n",
      "Epoch: 80 | Batch: 009 / 011 | Total loss: 1.187 | Reg loss: 0.040 | Tree loss: 1.187 | Accuracy: 0.562500 | 0.135 sec/iter\n",
      "Epoch: 80 | Batch: 010 / 011 | Total loss: 1.171 | Reg loss: 0.040 | Tree loss: 1.171 | Accuracy: 0.535836 | 0.135 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 81 | Batch: 000 / 011 | Total loss: 1.334 | Reg loss: 0.040 | Tree loss: 1.334 | Accuracy: 0.501000 | 0.136 sec/iter\n",
      "Epoch: 81 | Batch: 001 / 011 | Total loss: 1.289 | Reg loss: 0.040 | Tree loss: 1.289 | Accuracy: 0.502000 | 0.136 sec/iter\n",
      "Epoch: 81 | Batch: 002 / 011 | Total loss: 1.291 | Reg loss: 0.040 | Tree loss: 1.291 | Accuracy: 0.505000 | 0.136 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 | Batch: 003 / 011 | Total loss: 1.257 | Reg loss: 0.040 | Tree loss: 1.257 | Accuracy: 0.516000 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 004 / 011 | Total loss: 1.222 | Reg loss: 0.040 | Tree loss: 1.222 | Accuracy: 0.551500 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 005 / 011 | Total loss: 1.208 | Reg loss: 0.040 | Tree loss: 1.208 | Accuracy: 0.578000 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 006 / 011 | Total loss: 1.223 | Reg loss: 0.040 | Tree loss: 1.223 | Accuracy: 0.542000 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 007 / 011 | Total loss: 1.198 | Reg loss: 0.040 | Tree loss: 1.198 | Accuracy: 0.559500 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 008 / 011 | Total loss: 1.180 | Reg loss: 0.040 | Tree loss: 1.180 | Accuracy: 0.561500 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 009 / 011 | Total loss: 1.192 | Reg loss: 0.040 | Tree loss: 1.192 | Accuracy: 0.548000 | 0.135 sec/iter\n",
      "Epoch: 81 | Batch: 010 / 011 | Total loss: 1.247 | Reg loss: 0.040 | Tree loss: 1.247 | Accuracy: 0.529010 | 0.135 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 82 | Batch: 000 / 011 | Total loss: 1.326 | Reg loss: 0.040 | Tree loss: 1.326 | Accuracy: 0.491000 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 001 / 011 | Total loss: 1.314 | Reg loss: 0.040 | Tree loss: 1.314 | Accuracy: 0.492500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 002 / 011 | Total loss: 1.279 | Reg loss: 0.040 | Tree loss: 1.279 | Accuracy: 0.521000 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 003 / 011 | Total loss: 1.237 | Reg loss: 0.040 | Tree loss: 1.237 | Accuracy: 0.534500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 004 / 011 | Total loss: 1.197 | Reg loss: 0.040 | Tree loss: 1.197 | Accuracy: 0.553000 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 005 / 011 | Total loss: 1.227 | Reg loss: 0.040 | Tree loss: 1.227 | Accuracy: 0.557500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 006 / 011 | Total loss: 1.209 | Reg loss: 0.040 | Tree loss: 1.209 | Accuracy: 0.554500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 007 / 011 | Total loss: 1.203 | Reg loss: 0.040 | Tree loss: 1.203 | Accuracy: 0.547500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 008 / 011 | Total loss: 1.177 | Reg loss: 0.040 | Tree loss: 1.177 | Accuracy: 0.554500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 009 / 011 | Total loss: 1.195 | Reg loss: 0.040 | Tree loss: 1.195 | Accuracy: 0.557500 | 0.136 sec/iter\n",
      "Epoch: 82 | Batch: 010 / 011 | Total loss: 1.202 | Reg loss: 0.040 | Tree loss: 1.202 | Accuracy: 0.552901 | 0.136 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 83 | Batch: 000 / 011 | Total loss: 1.291 | Reg loss: 0.040 | Tree loss: 1.291 | Accuracy: 0.518000 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 001 / 011 | Total loss: 1.277 | Reg loss: 0.040 | Tree loss: 1.277 | Accuracy: 0.510000 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 002 / 011 | Total loss: 1.280 | Reg loss: 0.040 | Tree loss: 1.280 | Accuracy: 0.503500 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 003 / 011 | Total loss: 1.240 | Reg loss: 0.040 | Tree loss: 1.240 | Accuracy: 0.527500 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 004 / 011 | Total loss: 1.212 | Reg loss: 0.040 | Tree loss: 1.212 | Accuracy: 0.549000 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 005 / 011 | Total loss: 1.216 | Reg loss: 0.040 | Tree loss: 1.216 | Accuracy: 0.558000 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 006 / 011 | Total loss: 1.190 | Reg loss: 0.040 | Tree loss: 1.190 | Accuracy: 0.570000 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 007 / 011 | Total loss: 1.205 | Reg loss: 0.040 | Tree loss: 1.205 | Accuracy: 0.542000 | 0.138 sec/iter\n",
      "Epoch: 83 | Batch: 008 / 011 | Total loss: 1.202 | Reg loss: 0.040 | Tree loss: 1.202 | Accuracy: 0.542000 | 0.137 sec/iter\n",
      "Epoch: 83 | Batch: 009 / 011 | Total loss: 1.211 | Reg loss: 0.040 | Tree loss: 1.211 | Accuracy: 0.542000 | 0.137 sec/iter\n",
      "Epoch: 83 | Batch: 010 / 011 | Total loss: 1.214 | Reg loss: 0.040 | Tree loss: 1.214 | Accuracy: 0.546075 | 0.137 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 84 | Batch: 000 / 011 | Total loss: 1.309 | Reg loss: 0.040 | Tree loss: 1.309 | Accuracy: 0.502500 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 001 / 011 | Total loss: 1.298 | Reg loss: 0.040 | Tree loss: 1.298 | Accuracy: 0.486000 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 002 / 011 | Total loss: 1.268 | Reg loss: 0.040 | Tree loss: 1.268 | Accuracy: 0.521500 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 003 / 011 | Total loss: 1.234 | Reg loss: 0.040 | Tree loss: 1.234 | Accuracy: 0.538500 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 004 / 011 | Total loss: 1.224 | Reg loss: 0.040 | Tree loss: 1.224 | Accuracy: 0.544000 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 005 / 011 | Total loss: 1.210 | Reg loss: 0.040 | Tree loss: 1.210 | Accuracy: 0.568000 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 006 / 011 | Total loss: 1.199 | Reg loss: 0.040 | Tree loss: 1.199 | Accuracy: 0.551000 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 007 / 011 | Total loss: 1.191 | Reg loss: 0.040 | Tree loss: 1.191 | Accuracy: 0.541000 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 008 / 011 | Total loss: 1.193 | Reg loss: 0.040 | Tree loss: 1.193 | Accuracy: 0.542000 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 009 / 011 | Total loss: 1.166 | Reg loss: 0.040 | Tree loss: 1.166 | Accuracy: 0.570500 | 0.139 sec/iter\n",
      "Epoch: 84 | Batch: 010 / 011 | Total loss: 1.174 | Reg loss: 0.041 | Tree loss: 1.174 | Accuracy: 0.552901 | 0.139 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 85 | Batch: 000 / 011 | Total loss: 1.288 | Reg loss: 0.040 | Tree loss: 1.288 | Accuracy: 0.508500 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 001 / 011 | Total loss: 1.268 | Reg loss: 0.040 | Tree loss: 1.268 | Accuracy: 0.512000 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 002 / 011 | Total loss: 1.258 | Reg loss: 0.040 | Tree loss: 1.258 | Accuracy: 0.513000 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 003 / 011 | Total loss: 1.238 | Reg loss: 0.040 | Tree loss: 1.238 | Accuracy: 0.526500 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 004 / 011 | Total loss: 1.205 | Reg loss: 0.040 | Tree loss: 1.205 | Accuracy: 0.560000 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 005 / 011 | Total loss: 1.195 | Reg loss: 0.040 | Tree loss: 1.195 | Accuracy: 0.567000 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 006 / 011 | Total loss: 1.184 | Reg loss: 0.040 | Tree loss: 1.184 | Accuracy: 0.561000 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 007 / 011 | Total loss: 1.187 | Reg loss: 0.041 | Tree loss: 1.187 | Accuracy: 0.554000 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 008 / 011 | Total loss: 1.204 | Reg loss: 0.041 | Tree loss: 1.204 | Accuracy: 0.544500 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 009 / 011 | Total loss: 1.218 | Reg loss: 0.041 | Tree loss: 1.218 | Accuracy: 0.524500 | 0.14 sec/iter\n",
      "Epoch: 85 | Batch: 010 / 011 | Total loss: 1.234 | Reg loss: 0.041 | Tree loss: 1.234 | Accuracy: 0.484642 | 0.14 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 86 | Batch: 000 / 011 | Total loss: 1.304 | Reg loss: 0.040 | Tree loss: 1.304 | Accuracy: 0.491000 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 001 / 011 | Total loss: 1.279 | Reg loss: 0.040 | Tree loss: 1.279 | Accuracy: 0.524000 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 002 / 011 | Total loss: 1.245 | Reg loss: 0.040 | Tree loss: 1.245 | Accuracy: 0.514500 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 003 / 011 | Total loss: 1.242 | Reg loss: 0.040 | Tree loss: 1.242 | Accuracy: 0.519500 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 004 / 011 | Total loss: 1.229 | Reg loss: 0.041 | Tree loss: 1.229 | Accuracy: 0.537500 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 005 / 011 | Total loss: 1.207 | Reg loss: 0.041 | Tree loss: 1.207 | Accuracy: 0.562500 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 006 / 011 | Total loss: 1.165 | Reg loss: 0.041 | Tree loss: 1.165 | Accuracy: 0.585000 | 0.14 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 | Batch: 007 / 011 | Total loss: 1.182 | Reg loss: 0.041 | Tree loss: 1.182 | Accuracy: 0.561000 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 008 / 011 | Total loss: 1.176 | Reg loss: 0.041 | Tree loss: 1.176 | Accuracy: 0.559000 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 009 / 011 | Total loss: 1.188 | Reg loss: 0.041 | Tree loss: 1.188 | Accuracy: 0.550500 | 0.14 sec/iter\n",
      "Epoch: 86 | Batch: 010 / 011 | Total loss: 1.159 | Reg loss: 0.041 | Tree loss: 1.159 | Accuracy: 0.587031 | 0.14 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 87 | Batch: 000 / 011 | Total loss: 1.297 | Reg loss: 0.041 | Tree loss: 1.297 | Accuracy: 0.504000 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 001 / 011 | Total loss: 1.274 | Reg loss: 0.041 | Tree loss: 1.274 | Accuracy: 0.500000 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 002 / 011 | Total loss: 1.245 | Reg loss: 0.041 | Tree loss: 1.245 | Accuracy: 0.518000 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 003 / 011 | Total loss: 1.220 | Reg loss: 0.041 | Tree loss: 1.220 | Accuracy: 0.541000 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 004 / 011 | Total loss: 1.195 | Reg loss: 0.041 | Tree loss: 1.195 | Accuracy: 0.574500 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 005 / 011 | Total loss: 1.200 | Reg loss: 0.041 | Tree loss: 1.200 | Accuracy: 0.547500 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 006 / 011 | Total loss: 1.187 | Reg loss: 0.041 | Tree loss: 1.187 | Accuracy: 0.559500 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 007 / 011 | Total loss: 1.172 | Reg loss: 0.041 | Tree loss: 1.172 | Accuracy: 0.561000 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 008 / 011 | Total loss: 1.184 | Reg loss: 0.041 | Tree loss: 1.184 | Accuracy: 0.559000 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 009 / 011 | Total loss: 1.193 | Reg loss: 0.041 | Tree loss: 1.193 | Accuracy: 0.529500 | 0.142 sec/iter\n",
      "Epoch: 87 | Batch: 010 / 011 | Total loss: 1.215 | Reg loss: 0.041 | Tree loss: 1.215 | Accuracy: 0.552901 | 0.142 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 88 | Batch: 000 / 011 | Total loss: 1.280 | Reg loss: 0.041 | Tree loss: 1.280 | Accuracy: 0.515500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 001 / 011 | Total loss: 1.282 | Reg loss: 0.041 | Tree loss: 1.282 | Accuracy: 0.504000 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 002 / 011 | Total loss: 1.251 | Reg loss: 0.041 | Tree loss: 1.251 | Accuracy: 0.515500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 003 / 011 | Total loss: 1.235 | Reg loss: 0.041 | Tree loss: 1.235 | Accuracy: 0.521500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 004 / 011 | Total loss: 1.208 | Reg loss: 0.041 | Tree loss: 1.208 | Accuracy: 0.566500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 005 / 011 | Total loss: 1.198 | Reg loss: 0.041 | Tree loss: 1.198 | Accuracy: 0.571500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 006 / 011 | Total loss: 1.184 | Reg loss: 0.041 | Tree loss: 1.184 | Accuracy: 0.539500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 007 / 011 | Total loss: 1.181 | Reg loss: 0.041 | Tree loss: 1.181 | Accuracy: 0.560500 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 008 / 011 | Total loss: 1.170 | Reg loss: 0.041 | Tree loss: 1.170 | Accuracy: 0.553000 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 009 / 011 | Total loss: 1.163 | Reg loss: 0.041 | Tree loss: 1.163 | Accuracy: 0.573000 | 0.143 sec/iter\n",
      "Epoch: 88 | Batch: 010 / 011 | Total loss: 1.134 | Reg loss: 0.041 | Tree loss: 1.134 | Accuracy: 0.542662 | 0.143 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 89 | Batch: 000 / 011 | Total loss: 1.274 | Reg loss: 0.041 | Tree loss: 1.274 | Accuracy: 0.512000 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 001 / 011 | Total loss: 1.262 | Reg loss: 0.041 | Tree loss: 1.262 | Accuracy: 0.507000 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 002 / 011 | Total loss: 1.226 | Reg loss: 0.041 | Tree loss: 1.226 | Accuracy: 0.529500 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 003 / 011 | Total loss: 1.230 | Reg loss: 0.041 | Tree loss: 1.230 | Accuracy: 0.529000 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 004 / 011 | Total loss: 1.208 | Reg loss: 0.041 | Tree loss: 1.208 | Accuracy: 0.557000 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 005 / 011 | Total loss: 1.189 | Reg loss: 0.041 | Tree loss: 1.189 | Accuracy: 0.559500 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 006 / 011 | Total loss: 1.167 | Reg loss: 0.041 | Tree loss: 1.167 | Accuracy: 0.576000 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 007 / 011 | Total loss: 1.197 | Reg loss: 0.041 | Tree loss: 1.197 | Accuracy: 0.550500 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 008 / 011 | Total loss: 1.186 | Reg loss: 0.041 | Tree loss: 1.186 | Accuracy: 0.548000 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 009 / 011 | Total loss: 1.166 | Reg loss: 0.041 | Tree loss: 1.166 | Accuracy: 0.546500 | 0.145 sec/iter\n",
      "Epoch: 89 | Batch: 010 / 011 | Total loss: 1.200 | Reg loss: 0.041 | Tree loss: 1.200 | Accuracy: 0.525597 | 0.145 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 90 | Batch: 000 / 011 | Total loss: 1.270 | Reg loss: 0.041 | Tree loss: 1.270 | Accuracy: 0.509500 | 0.146 sec/iter\n",
      "Epoch: 90 | Batch: 001 / 011 | Total loss: 1.248 | Reg loss: 0.041 | Tree loss: 1.248 | Accuracy: 0.520000 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 002 / 011 | Total loss: 1.240 | Reg loss: 0.041 | Tree loss: 1.240 | Accuracy: 0.521000 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 003 / 011 | Total loss: 1.219 | Reg loss: 0.041 | Tree loss: 1.219 | Accuracy: 0.535500 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 004 / 011 | Total loss: 1.205 | Reg loss: 0.041 | Tree loss: 1.205 | Accuracy: 0.570500 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 005 / 011 | Total loss: 1.196 | Reg loss: 0.041 | Tree loss: 1.196 | Accuracy: 0.551500 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 006 / 011 | Total loss: 1.177 | Reg loss: 0.041 | Tree loss: 1.177 | Accuracy: 0.562500 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 007 / 011 | Total loss: 1.183 | Reg loss: 0.041 | Tree loss: 1.183 | Accuracy: 0.548500 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 008 / 011 | Total loss: 1.176 | Reg loss: 0.041 | Tree loss: 1.176 | Accuracy: 0.552000 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 009 / 011 | Total loss: 1.162 | Reg loss: 0.041 | Tree loss: 1.162 | Accuracy: 0.565500 | 0.145 sec/iter\n",
      "Epoch: 90 | Batch: 010 / 011 | Total loss: 1.117 | Reg loss: 0.041 | Tree loss: 1.117 | Accuracy: 0.546075 | 0.145 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 91 | Batch: 000 / 011 | Total loss: 1.277 | Reg loss: 0.041 | Tree loss: 1.277 | Accuracy: 0.505000 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 001 / 011 | Total loss: 1.257 | Reg loss: 0.041 | Tree loss: 1.257 | Accuracy: 0.517500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 002 / 011 | Total loss: 1.229 | Reg loss: 0.041 | Tree loss: 1.229 | Accuracy: 0.517500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 003 / 011 | Total loss: 1.207 | Reg loss: 0.041 | Tree loss: 1.207 | Accuracy: 0.539500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 004 / 011 | Total loss: 1.180 | Reg loss: 0.041 | Tree loss: 1.180 | Accuracy: 0.567000 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 005 / 011 | Total loss: 1.183 | Reg loss: 0.041 | Tree loss: 1.183 | Accuracy: 0.567500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 006 / 011 | Total loss: 1.193 | Reg loss: 0.041 | Tree loss: 1.193 | Accuracy: 0.545500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 007 / 011 | Total loss: 1.180 | Reg loss: 0.041 | Tree loss: 1.180 | Accuracy: 0.554000 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 008 / 011 | Total loss: 1.157 | Reg loss: 0.041 | Tree loss: 1.157 | Accuracy: 0.574500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 009 / 011 | Total loss: 1.174 | Reg loss: 0.041 | Tree loss: 1.174 | Accuracy: 0.559500 | 0.145 sec/iter\n",
      "Epoch: 91 | Batch: 010 / 011 | Total loss: 1.171 | Reg loss: 0.041 | Tree loss: 1.171 | Accuracy: 0.529010 | 0.145 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 92 | Batch: 000 / 011 | Total loss: 1.262 | Reg loss: 0.041 | Tree loss: 1.262 | Accuracy: 0.513500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 001 / 011 | Total loss: 1.257 | Reg loss: 0.041 | Tree loss: 1.257 | Accuracy: 0.521000 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 002 / 011 | Total loss: 1.242 | Reg loss: 0.041 | Tree loss: 1.242 | Accuracy: 0.529500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 003 / 011 | Total loss: 1.214 | Reg loss: 0.041 | Tree loss: 1.214 | Accuracy: 0.530500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 004 / 011 | Total loss: 1.177 | Reg loss: 0.041 | Tree loss: 1.177 | Accuracy: 0.579000 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 005 / 011 | Total loss: 1.178 | Reg loss: 0.041 | Tree loss: 1.178 | Accuracy: 0.578500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 006 / 011 | Total loss: 1.163 | Reg loss: 0.041 | Tree loss: 1.163 | Accuracy: 0.574500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 007 / 011 | Total loss: 1.181 | Reg loss: 0.041 | Tree loss: 1.181 | Accuracy: 0.537500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 008 / 011 | Total loss: 1.159 | Reg loss: 0.041 | Tree loss: 1.159 | Accuracy: 0.576500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 009 / 011 | Total loss: 1.165 | Reg loss: 0.041 | Tree loss: 1.165 | Accuracy: 0.555500 | 0.146 sec/iter\n",
      "Epoch: 92 | Batch: 010 / 011 | Total loss: 1.159 | Reg loss: 0.041 | Tree loss: 1.159 | Accuracy: 0.559727 | 0.146 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 93 | Batch: 000 / 011 | Total loss: 1.261 | Reg loss: 0.041 | Tree loss: 1.261 | Accuracy: 0.532000 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 001 / 011 | Total loss: 1.245 | Reg loss: 0.041 | Tree loss: 1.245 | Accuracy: 0.527500 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 002 / 011 | Total loss: 1.209 | Reg loss: 0.041 | Tree loss: 1.209 | Accuracy: 0.544000 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 003 / 011 | Total loss: 1.217 | Reg loss: 0.041 | Tree loss: 1.217 | Accuracy: 0.539000 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 004 / 011 | Total loss: 1.187 | Reg loss: 0.041 | Tree loss: 1.187 | Accuracy: 0.561500 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 005 / 011 | Total loss: 1.177 | Reg loss: 0.041 | Tree loss: 1.177 | Accuracy: 0.568500 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 006 / 011 | Total loss: 1.167 | Reg loss: 0.041 | Tree loss: 1.167 | Accuracy: 0.565500 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 007 / 011 | Total loss: 1.169 | Reg loss: 0.041 | Tree loss: 1.169 | Accuracy: 0.570000 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 008 / 011 | Total loss: 1.158 | Reg loss: 0.041 | Tree loss: 1.158 | Accuracy: 0.575000 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 009 / 011 | Total loss: 1.178 | Reg loss: 0.041 | Tree loss: 1.178 | Accuracy: 0.538000 | 0.146 sec/iter\n",
      "Epoch: 93 | Batch: 010 / 011 | Total loss: 1.174 | Reg loss: 0.041 | Tree loss: 1.174 | Accuracy: 0.511945 | 0.146 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 94 | Batch: 000 / 011 | Total loss: 1.275 | Reg loss: 0.041 | Tree loss: 1.275 | Accuracy: 0.516000 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 001 / 011 | Total loss: 1.250 | Reg loss: 0.041 | Tree loss: 1.250 | Accuracy: 0.521500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 002 / 011 | Total loss: 1.224 | Reg loss: 0.041 | Tree loss: 1.224 | Accuracy: 0.543500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 003 / 011 | Total loss: 1.196 | Reg loss: 0.041 | Tree loss: 1.196 | Accuracy: 0.554000 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 004 / 011 | Total loss: 1.202 | Reg loss: 0.041 | Tree loss: 1.202 | Accuracy: 0.547500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 005 / 011 | Total loss: 1.167 | Reg loss: 0.041 | Tree loss: 1.167 | Accuracy: 0.577500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 006 / 011 | Total loss: 1.151 | Reg loss: 0.041 | Tree loss: 1.151 | Accuracy: 0.569000 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 007 / 011 | Total loss: 1.173 | Reg loss: 0.041 | Tree loss: 1.173 | Accuracy: 0.559500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 008 / 011 | Total loss: 1.153 | Reg loss: 0.041 | Tree loss: 1.153 | Accuracy: 0.564500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 009 / 011 | Total loss: 1.158 | Reg loss: 0.041 | Tree loss: 1.158 | Accuracy: 0.566500 | 0.146 sec/iter\n",
      "Epoch: 94 | Batch: 010 / 011 | Total loss: 1.133 | Reg loss: 0.041 | Tree loss: 1.133 | Accuracy: 0.573379 | 0.146 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 95 | Batch: 000 / 011 | Total loss: 1.265 | Reg loss: 0.041 | Tree loss: 1.265 | Accuracy: 0.520000 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 001 / 011 | Total loss: 1.240 | Reg loss: 0.041 | Tree loss: 1.240 | Accuracy: 0.529500 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 002 / 011 | Total loss: 1.238 | Reg loss: 0.041 | Tree loss: 1.238 | Accuracy: 0.535500 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 003 / 011 | Total loss: 1.195 | Reg loss: 0.041 | Tree loss: 1.195 | Accuracy: 0.566000 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 004 / 011 | Total loss: 1.186 | Reg loss: 0.041 | Tree loss: 1.186 | Accuracy: 0.583500 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 005 / 011 | Total loss: 1.173 | Reg loss: 0.041 | Tree loss: 1.173 | Accuracy: 0.574500 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 006 / 011 | Total loss: 1.183 | Reg loss: 0.041 | Tree loss: 1.183 | Accuracy: 0.547500 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 007 / 011 | Total loss: 1.149 | Reg loss: 0.041 | Tree loss: 1.149 | Accuracy: 0.581500 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 008 / 011 | Total loss: 1.144 | Reg loss: 0.041 | Tree loss: 1.144 | Accuracy: 0.575000 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 009 / 011 | Total loss: 1.149 | Reg loss: 0.041 | Tree loss: 1.149 | Accuracy: 0.568000 | 0.146 sec/iter\n",
      "Epoch: 95 | Batch: 010 / 011 | Total loss: 1.169 | Reg loss: 0.041 | Tree loss: 1.169 | Accuracy: 0.552901 | 0.146 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 96 | Batch: 000 / 011 | Total loss: 1.280 | Reg loss: 0.041 | Tree loss: 1.280 | Accuracy: 0.510500 | 0.147 sec/iter\n",
      "Epoch: 96 | Batch: 001 / 011 | Total loss: 1.222 | Reg loss: 0.041 | Tree loss: 1.222 | Accuracy: 0.547500 | 0.147 sec/iter\n",
      "Epoch: 96 | Batch: 002 / 011 | Total loss: 1.212 | Reg loss: 0.041 | Tree loss: 1.212 | Accuracy: 0.545000 | 0.147 sec/iter\n",
      "Epoch: 96 | Batch: 003 / 011 | Total loss: 1.199 | Reg loss: 0.041 | Tree loss: 1.199 | Accuracy: 0.554500 | 0.147 sec/iter\n",
      "Epoch: 96 | Batch: 004 / 011 | Total loss: 1.193 | Reg loss: 0.041 | Tree loss: 1.193 | Accuracy: 0.557500 | 0.146 sec/iter\n",
      "Epoch: 96 | Batch: 005 / 011 | Total loss: 1.162 | Reg loss: 0.041 | Tree loss: 1.162 | Accuracy: 0.586500 | 0.146 sec/iter\n",
      "Epoch: 96 | Batch: 006 / 011 | Total loss: 1.150 | Reg loss: 0.041 | Tree loss: 1.150 | Accuracy: 0.568000 | 0.146 sec/iter\n",
      "Epoch: 96 | Batch: 007 / 011 | Total loss: 1.151 | Reg loss: 0.041 | Tree loss: 1.151 | Accuracy: 0.573000 | 0.146 sec/iter\n",
      "Epoch: 96 | Batch: 008 / 011 | Total loss: 1.169 | Reg loss: 0.041 | Tree loss: 1.169 | Accuracy: 0.564500 | 0.146 sec/iter\n",
      "Epoch: 96 | Batch: 009 / 011 | Total loss: 1.151 | Reg loss: 0.041 | Tree loss: 1.151 | Accuracy: 0.569500 | 0.146 sec/iter\n",
      "Epoch: 96 | Batch: 010 / 011 | Total loss: 1.126 | Reg loss: 0.041 | Tree loss: 1.126 | Accuracy: 0.559727 | 0.146 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 97 | Batch: 000 / 011 | Total loss: 1.239 | Reg loss: 0.041 | Tree loss: 1.239 | Accuracy: 0.538500 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 001 / 011 | Total loss: 1.233 | Reg loss: 0.041 | Tree loss: 1.233 | Accuracy: 0.533500 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 002 / 011 | Total loss: 1.219 | Reg loss: 0.041 | Tree loss: 1.219 | Accuracy: 0.540500 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 003 / 011 | Total loss: 1.200 | Reg loss: 0.041 | Tree loss: 1.200 | Accuracy: 0.556000 | 0.147 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 | Batch: 004 / 011 | Total loss: 1.185 | Reg loss: 0.041 | Tree loss: 1.185 | Accuracy: 0.572000 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 005 / 011 | Total loss: 1.173 | Reg loss: 0.041 | Tree loss: 1.173 | Accuracy: 0.572500 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 006 / 011 | Total loss: 1.158 | Reg loss: 0.041 | Tree loss: 1.158 | Accuracy: 0.583000 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 007 / 011 | Total loss: 1.148 | Reg loss: 0.041 | Tree loss: 1.148 | Accuracy: 0.584000 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 008 / 011 | Total loss: 1.135 | Reg loss: 0.041 | Tree loss: 1.135 | Accuracy: 0.573500 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 009 / 011 | Total loss: 1.155 | Reg loss: 0.041 | Tree loss: 1.155 | Accuracy: 0.547500 | 0.147 sec/iter\n",
      "Epoch: 97 | Batch: 010 / 011 | Total loss: 1.202 | Reg loss: 0.041 | Tree loss: 1.202 | Accuracy: 0.491468 | 0.147 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 98 | Batch: 000 / 011 | Total loss: 1.234 | Reg loss: 0.041 | Tree loss: 1.234 | Accuracy: 0.533500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 001 / 011 | Total loss: 1.236 | Reg loss: 0.041 | Tree loss: 1.236 | Accuracy: 0.539500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 002 / 011 | Total loss: 1.218 | Reg loss: 0.041 | Tree loss: 1.218 | Accuracy: 0.553500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 003 / 011 | Total loss: 1.188 | Reg loss: 0.041 | Tree loss: 1.188 | Accuracy: 0.561500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 004 / 011 | Total loss: 1.175 | Reg loss: 0.041 | Tree loss: 1.175 | Accuracy: 0.578000 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 005 / 011 | Total loss: 1.157 | Reg loss: 0.041 | Tree loss: 1.157 | Accuracy: 0.584500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 006 / 011 | Total loss: 1.145 | Reg loss: 0.041 | Tree loss: 1.145 | Accuracy: 0.589500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 007 / 011 | Total loss: 1.151 | Reg loss: 0.041 | Tree loss: 1.151 | Accuracy: 0.574000 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 008 / 011 | Total loss: 1.150 | Reg loss: 0.041 | Tree loss: 1.150 | Accuracy: 0.567000 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 009 / 011 | Total loss: 1.162 | Reg loss: 0.041 | Tree loss: 1.162 | Accuracy: 0.544500 | 0.148 sec/iter\n",
      "Epoch: 98 | Batch: 010 / 011 | Total loss: 1.169 | Reg loss: 0.041 | Tree loss: 1.169 | Accuracy: 0.549488 | 0.148 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 99 | Batch: 000 / 011 | Total loss: 1.236 | Reg loss: 0.041 | Tree loss: 1.236 | Accuracy: 0.524500 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 001 / 011 | Total loss: 1.245 | Reg loss: 0.041 | Tree loss: 1.245 | Accuracy: 0.527000 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 002 / 011 | Total loss: 1.195 | Reg loss: 0.041 | Tree loss: 1.195 | Accuracy: 0.567000 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 003 / 011 | Total loss: 1.187 | Reg loss: 0.041 | Tree loss: 1.187 | Accuracy: 0.561500 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 004 / 011 | Total loss: 1.173 | Reg loss: 0.041 | Tree loss: 1.173 | Accuracy: 0.586000 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 005 / 011 | Total loss: 1.164 | Reg loss: 0.041 | Tree loss: 1.164 | Accuracy: 0.567500 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 006 / 011 | Total loss: 1.160 | Reg loss: 0.041 | Tree loss: 1.160 | Accuracy: 0.564500 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 007 / 011 | Total loss: 1.149 | Reg loss: 0.041 | Tree loss: 1.149 | Accuracy: 0.573500 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 008 / 011 | Total loss: 1.158 | Reg loss: 0.041 | Tree loss: 1.158 | Accuracy: 0.569000 | 0.148 sec/iter\n",
      "Epoch: 99 | Batch: 009 / 011 | Total loss: 1.134 | Reg loss: 0.041 | Tree loss: 1.134 | Accuracy: 0.563000 | 0.147 sec/iter\n",
      "Epoch: 99 | Batch: 010 / 011 | Total loss: 1.149 | Reg loss: 0.041 | Tree loss: 1.149 | Accuracy: 0.539249 | 0.147 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 100 | Batch: 000 / 011 | Total loss: 1.257 | Reg loss: 0.041 | Tree loss: 1.257 | Accuracy: 0.516500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 001 / 011 | Total loss: 1.232 | Reg loss: 0.041 | Tree loss: 1.232 | Accuracy: 0.538500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 002 / 011 | Total loss: 1.184 | Reg loss: 0.041 | Tree loss: 1.184 | Accuracy: 0.568500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 003 / 011 | Total loss: 1.180 | Reg loss: 0.041 | Tree loss: 1.180 | Accuracy: 0.569000 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 004 / 011 | Total loss: 1.201 | Reg loss: 0.041 | Tree loss: 1.201 | Accuracy: 0.565500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 005 / 011 | Total loss: 1.160 | Reg loss: 0.041 | Tree loss: 1.160 | Accuracy: 0.573500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 006 / 011 | Total loss: 1.135 | Reg loss: 0.041 | Tree loss: 1.135 | Accuracy: 0.588500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 007 / 011 | Total loss: 1.129 | Reg loss: 0.041 | Tree loss: 1.129 | Accuracy: 0.576000 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 008 / 011 | Total loss: 1.126 | Reg loss: 0.041 | Tree loss: 1.126 | Accuracy: 0.568500 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 009 / 011 | Total loss: 1.151 | Reg loss: 0.041 | Tree loss: 1.151 | Accuracy: 0.570000 | 0.148 sec/iter\n",
      "Epoch: 100 | Batch: 010 / 011 | Total loss: 1.156 | Reg loss: 0.041 | Tree loss: 1.156 | Accuracy: 0.546075 | 0.148 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 101 | Batch: 000 / 011 | Total loss: 1.247 | Reg loss: 0.041 | Tree loss: 1.247 | Accuracy: 0.527500 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 001 / 011 | Total loss: 1.226 | Reg loss: 0.041 | Tree loss: 1.226 | Accuracy: 0.522500 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 002 / 011 | Total loss: 1.215 | Reg loss: 0.041 | Tree loss: 1.215 | Accuracy: 0.550000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 003 / 011 | Total loss: 1.188 | Reg loss: 0.041 | Tree loss: 1.188 | Accuracy: 0.566500 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 004 / 011 | Total loss: 1.165 | Reg loss: 0.041 | Tree loss: 1.165 | Accuracy: 0.572000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 005 / 011 | Total loss: 1.166 | Reg loss: 0.041 | Tree loss: 1.166 | Accuracy: 0.589000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 006 / 011 | Total loss: 1.154 | Reg loss: 0.041 | Tree loss: 1.154 | Accuracy: 0.599000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 007 / 011 | Total loss: 1.125 | Reg loss: 0.041 | Tree loss: 1.125 | Accuracy: 0.595000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 008 / 011 | Total loss: 1.117 | Reg loss: 0.041 | Tree loss: 1.117 | Accuracy: 0.582000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 009 / 011 | Total loss: 1.136 | Reg loss: 0.041 | Tree loss: 1.136 | Accuracy: 0.576000 | 0.149 sec/iter\n",
      "Epoch: 101 | Batch: 010 / 011 | Total loss: 1.168 | Reg loss: 0.042 | Tree loss: 1.168 | Accuracy: 0.549488 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 102 | Batch: 000 / 011 | Total loss: 1.240 | Reg loss: 0.041 | Tree loss: 1.240 | Accuracy: 0.526000 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 001 / 011 | Total loss: 1.215 | Reg loss: 0.041 | Tree loss: 1.215 | Accuracy: 0.539000 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 002 / 011 | Total loss: 1.210 | Reg loss: 0.041 | Tree loss: 1.210 | Accuracy: 0.548000 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 003 / 011 | Total loss: 1.178 | Reg loss: 0.041 | Tree loss: 1.178 | Accuracy: 0.568500 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 004 / 011 | Total loss: 1.172 | Reg loss: 0.041 | Tree loss: 1.172 | Accuracy: 0.569500 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 005 / 011 | Total loss: 1.136 | Reg loss: 0.041 | Tree loss: 1.136 | Accuracy: 0.597500 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 006 / 011 | Total loss: 1.146 | Reg loss: 0.041 | Tree loss: 1.146 | Accuracy: 0.588000 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 007 / 011 | Total loss: 1.130 | Reg loss: 0.041 | Tree loss: 1.130 | Accuracy: 0.583000 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 008 / 011 | Total loss: 1.134 | Reg loss: 0.042 | Tree loss: 1.134 | Accuracy: 0.583500 | 0.149 sec/iter\n",
      "Epoch: 102 | Batch: 009 / 011 | Total loss: 1.158 | Reg loss: 0.042 | Tree loss: 1.158 | Accuracy: 0.567000 | 0.149 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102 | Batch: 010 / 011 | Total loss: 1.129 | Reg loss: 0.042 | Tree loss: 1.129 | Accuracy: 0.546075 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 103 | Batch: 000 / 011 | Total loss: 1.252 | Reg loss: 0.041 | Tree loss: 1.252 | Accuracy: 0.513000 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 001 / 011 | Total loss: 1.195 | Reg loss: 0.041 | Tree loss: 1.195 | Accuracy: 0.563000 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 002 / 011 | Total loss: 1.199 | Reg loss: 0.041 | Tree loss: 1.199 | Accuracy: 0.557500 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 003 / 011 | Total loss: 1.171 | Reg loss: 0.041 | Tree loss: 1.171 | Accuracy: 0.568000 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 004 / 011 | Total loss: 1.171 | Reg loss: 0.041 | Tree loss: 1.171 | Accuracy: 0.572000 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 005 / 011 | Total loss: 1.139 | Reg loss: 0.041 | Tree loss: 1.139 | Accuracy: 0.583000 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 006 / 011 | Total loss: 1.144 | Reg loss: 0.042 | Tree loss: 1.144 | Accuracy: 0.584000 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 007 / 011 | Total loss: 1.143 | Reg loss: 0.042 | Tree loss: 1.143 | Accuracy: 0.582500 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 008 / 011 | Total loss: 1.134 | Reg loss: 0.042 | Tree loss: 1.134 | Accuracy: 0.567500 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 009 / 011 | Total loss: 1.145 | Reg loss: 0.042 | Tree loss: 1.145 | Accuracy: 0.544500 | 0.149 sec/iter\n",
      "Epoch: 103 | Batch: 010 / 011 | Total loss: 1.142 | Reg loss: 0.042 | Tree loss: 1.142 | Accuracy: 0.566553 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 104 | Batch: 000 / 011 | Total loss: 1.225 | Reg loss: 0.041 | Tree loss: 1.225 | Accuracy: 0.538500 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 001 / 011 | Total loss: 1.227 | Reg loss: 0.041 | Tree loss: 1.227 | Accuracy: 0.523000 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 002 / 011 | Total loss: 1.205 | Reg loss: 0.041 | Tree loss: 1.205 | Accuracy: 0.565500 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 003 / 011 | Total loss: 1.168 | Reg loss: 0.041 | Tree loss: 1.168 | Accuracy: 0.587000 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 004 / 011 | Total loss: 1.149 | Reg loss: 0.042 | Tree loss: 1.149 | Accuracy: 0.596500 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 005 / 011 | Total loss: 1.144 | Reg loss: 0.042 | Tree loss: 1.144 | Accuracy: 0.600500 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 006 / 011 | Total loss: 1.140 | Reg loss: 0.042 | Tree loss: 1.140 | Accuracy: 0.574000 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 007 / 011 | Total loss: 1.149 | Reg loss: 0.042 | Tree loss: 1.149 | Accuracy: 0.567000 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 008 / 011 | Total loss: 1.132 | Reg loss: 0.042 | Tree loss: 1.132 | Accuracy: 0.587500 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 009 / 011 | Total loss: 1.129 | Reg loss: 0.042 | Tree loss: 1.129 | Accuracy: 0.587000 | 0.149 sec/iter\n",
      "Epoch: 104 | Batch: 010 / 011 | Total loss: 1.085 | Reg loss: 0.042 | Tree loss: 1.085 | Accuracy: 0.593857 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 105 | Batch: 000 / 011 | Total loss: 1.226 | Reg loss: 0.042 | Tree loss: 1.226 | Accuracy: 0.532500 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 001 / 011 | Total loss: 1.219 | Reg loss: 0.042 | Tree loss: 1.219 | Accuracy: 0.523500 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 002 / 011 | Total loss: 1.177 | Reg loss: 0.042 | Tree loss: 1.177 | Accuracy: 0.570000 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 003 / 011 | Total loss: 1.180 | Reg loss: 0.042 | Tree loss: 1.180 | Accuracy: 0.566000 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 004 / 011 | Total loss: 1.167 | Reg loss: 0.042 | Tree loss: 1.167 | Accuracy: 0.562500 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 005 / 011 | Total loss: 1.134 | Reg loss: 0.042 | Tree loss: 1.134 | Accuracy: 0.584000 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 006 / 011 | Total loss: 1.137 | Reg loss: 0.042 | Tree loss: 1.137 | Accuracy: 0.588500 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 007 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.583500 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 008 / 011 | Total loss: 1.130 | Reg loss: 0.042 | Tree loss: 1.130 | Accuracy: 0.556000 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 009 / 011 | Total loss: 1.133 | Reg loss: 0.042 | Tree loss: 1.133 | Accuracy: 0.569500 | 0.149 sec/iter\n",
      "Epoch: 105 | Batch: 010 / 011 | Total loss: 1.149 | Reg loss: 0.042 | Tree loss: 1.149 | Accuracy: 0.501706 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 106 | Batch: 000 / 011 | Total loss: 1.231 | Reg loss: 0.042 | Tree loss: 1.231 | Accuracy: 0.526000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 001 / 011 | Total loss: 1.196 | Reg loss: 0.042 | Tree loss: 1.196 | Accuracy: 0.563500 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 002 / 011 | Total loss: 1.189 | Reg loss: 0.042 | Tree loss: 1.189 | Accuracy: 0.566000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 003 / 011 | Total loss: 1.164 | Reg loss: 0.042 | Tree loss: 1.164 | Accuracy: 0.600000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 004 / 011 | Total loss: 1.166 | Reg loss: 0.042 | Tree loss: 1.166 | Accuracy: 0.572000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 005 / 011 | Total loss: 1.140 | Reg loss: 0.042 | Tree loss: 1.140 | Accuracy: 0.595000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 006 / 011 | Total loss: 1.145 | Reg loss: 0.042 | Tree loss: 1.145 | Accuracy: 0.582000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 007 / 011 | Total loss: 1.128 | Reg loss: 0.042 | Tree loss: 1.128 | Accuracy: 0.573500 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 008 / 011 | Total loss: 1.130 | Reg loss: 0.042 | Tree loss: 1.130 | Accuracy: 0.579000 | 0.15 sec/iter\n",
      "Epoch: 106 | Batch: 009 / 011 | Total loss: 1.118 | Reg loss: 0.042 | Tree loss: 1.118 | Accuracy: 0.590000 | 0.149 sec/iter\n",
      "Epoch: 106 | Batch: 010 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.556314 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 107 | Batch: 000 / 011 | Total loss: 1.222 | Reg loss: 0.042 | Tree loss: 1.222 | Accuracy: 0.531500 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 001 / 011 | Total loss: 1.212 | Reg loss: 0.042 | Tree loss: 1.212 | Accuracy: 0.554000 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 002 / 011 | Total loss: 1.195 | Reg loss: 0.042 | Tree loss: 1.195 | Accuracy: 0.543000 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 003 / 011 | Total loss: 1.168 | Reg loss: 0.042 | Tree loss: 1.168 | Accuracy: 0.567500 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 004 / 011 | Total loss: 1.134 | Reg loss: 0.042 | Tree loss: 1.134 | Accuracy: 0.598500 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 005 / 011 | Total loss: 1.137 | Reg loss: 0.042 | Tree loss: 1.137 | Accuracy: 0.573500 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 006 / 011 | Total loss: 1.136 | Reg loss: 0.042 | Tree loss: 1.136 | Accuracy: 0.586000 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 007 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.583500 | 0.15 sec/iter\n",
      "Epoch: 107 | Batch: 008 / 011 | Total loss: 1.111 | Reg loss: 0.042 | Tree loss: 1.111 | Accuracy: 0.591500 | 0.149 sec/iter\n",
      "Epoch: 107 | Batch: 009 / 011 | Total loss: 1.135 | Reg loss: 0.042 | Tree loss: 1.135 | Accuracy: 0.555000 | 0.149 sec/iter\n",
      "Epoch: 107 | Batch: 010 / 011 | Total loss: 1.130 | Reg loss: 0.042 | Tree loss: 1.130 | Accuracy: 0.556314 | 0.149 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 108 | Batch: 000 / 011 | Total loss: 1.227 | Reg loss: 0.042 | Tree loss: 1.227 | Accuracy: 0.536500 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 001 / 011 | Total loss: 1.205 | Reg loss: 0.042 | Tree loss: 1.205 | Accuracy: 0.547500 | 0.15 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108 | Batch: 002 / 011 | Total loss: 1.182 | Reg loss: 0.042 | Tree loss: 1.182 | Accuracy: 0.576500 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 003 / 011 | Total loss: 1.164 | Reg loss: 0.042 | Tree loss: 1.164 | Accuracy: 0.575000 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 004 / 011 | Total loss: 1.146 | Reg loss: 0.042 | Tree loss: 1.146 | Accuracy: 0.561500 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 005 / 011 | Total loss: 1.122 | Reg loss: 0.042 | Tree loss: 1.122 | Accuracy: 0.590000 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 006 / 011 | Total loss: 1.126 | Reg loss: 0.042 | Tree loss: 1.126 | Accuracy: 0.591500 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 007 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.586500 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 008 / 011 | Total loss: 1.126 | Reg loss: 0.042 | Tree loss: 1.126 | Accuracy: 0.572000 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 009 / 011 | Total loss: 1.133 | Reg loss: 0.042 | Tree loss: 1.133 | Accuracy: 0.579000 | 0.15 sec/iter\n",
      "Epoch: 108 | Batch: 010 / 011 | Total loss: 1.187 | Reg loss: 0.042 | Tree loss: 1.187 | Accuracy: 0.529010 | 0.15 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 109 | Batch: 000 / 011 | Total loss: 1.215 | Reg loss: 0.042 | Tree loss: 1.215 | Accuracy: 0.533000 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 001 / 011 | Total loss: 1.213 | Reg loss: 0.042 | Tree loss: 1.213 | Accuracy: 0.553500 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 002 / 011 | Total loss: 1.178 | Reg loss: 0.042 | Tree loss: 1.178 | Accuracy: 0.573000 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 003 / 011 | Total loss: 1.171 | Reg loss: 0.042 | Tree loss: 1.171 | Accuracy: 0.569000 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 004 / 011 | Total loss: 1.154 | Reg loss: 0.042 | Tree loss: 1.154 | Accuracy: 0.570000 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 005 / 011 | Total loss: 1.128 | Reg loss: 0.042 | Tree loss: 1.128 | Accuracy: 0.580000 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 006 / 011 | Total loss: 1.119 | Reg loss: 0.042 | Tree loss: 1.119 | Accuracy: 0.600000 | 0.151 sec/iter\n",
      "Epoch: 109 | Batch: 007 / 011 | Total loss: 1.118 | Reg loss: 0.042 | Tree loss: 1.118 | Accuracy: 0.599000 | 0.15 sec/iter\n",
      "Epoch: 109 | Batch: 008 / 011 | Total loss: 1.119 | Reg loss: 0.042 | Tree loss: 1.119 | Accuracy: 0.580000 | 0.15 sec/iter\n",
      "Epoch: 109 | Batch: 009 / 011 | Total loss: 1.122 | Reg loss: 0.042 | Tree loss: 1.122 | Accuracy: 0.591000 | 0.15 sec/iter\n",
      "Epoch: 109 | Batch: 010 / 011 | Total loss: 1.149 | Reg loss: 0.042 | Tree loss: 1.149 | Accuracy: 0.569966 | 0.15 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 110 | Batch: 000 / 011 | Total loss: 1.213 | Reg loss: 0.042 | Tree loss: 1.213 | Accuracy: 0.554500 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 001 / 011 | Total loss: 1.189 | Reg loss: 0.042 | Tree loss: 1.189 | Accuracy: 0.562000 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 002 / 011 | Total loss: 1.184 | Reg loss: 0.042 | Tree loss: 1.184 | Accuracy: 0.553500 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 003 / 011 | Total loss: 1.150 | Reg loss: 0.042 | Tree loss: 1.150 | Accuracy: 0.586000 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 004 / 011 | Total loss: 1.145 | Reg loss: 0.042 | Tree loss: 1.145 | Accuracy: 0.608500 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 005 / 011 | Total loss: 1.130 | Reg loss: 0.042 | Tree loss: 1.130 | Accuracy: 0.589000 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 006 / 011 | Total loss: 1.126 | Reg loss: 0.042 | Tree loss: 1.126 | Accuracy: 0.587500 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 007 / 011 | Total loss: 1.113 | Reg loss: 0.042 | Tree loss: 1.113 | Accuracy: 0.597500 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 008 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.574500 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 009 / 011 | Total loss: 1.125 | Reg loss: 0.042 | Tree loss: 1.125 | Accuracy: 0.572000 | 0.151 sec/iter\n",
      "Epoch: 110 | Batch: 010 / 011 | Total loss: 1.097 | Reg loss: 0.042 | Tree loss: 1.097 | Accuracy: 0.624573 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 111 | Batch: 000 / 011 | Total loss: 1.220 | Reg loss: 0.042 | Tree loss: 1.220 | Accuracy: 0.546000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 001 / 011 | Total loss: 1.211 | Reg loss: 0.042 | Tree loss: 1.211 | Accuracy: 0.540000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 002 / 011 | Total loss: 1.183 | Reg loss: 0.042 | Tree loss: 1.183 | Accuracy: 0.548000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 003 / 011 | Total loss: 1.163 | Reg loss: 0.042 | Tree loss: 1.163 | Accuracy: 0.564500 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 004 / 011 | Total loss: 1.151 | Reg loss: 0.042 | Tree loss: 1.151 | Accuracy: 0.580000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 005 / 011 | Total loss: 1.134 | Reg loss: 0.042 | Tree loss: 1.134 | Accuracy: 0.589000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 006 / 011 | Total loss: 1.120 | Reg loss: 0.042 | Tree loss: 1.120 | Accuracy: 0.605500 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 007 / 011 | Total loss: 1.106 | Reg loss: 0.042 | Tree loss: 1.106 | Accuracy: 0.602500 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 008 / 011 | Total loss: 1.108 | Reg loss: 0.042 | Tree loss: 1.108 | Accuracy: 0.592000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 009 / 011 | Total loss: 1.104 | Reg loss: 0.042 | Tree loss: 1.104 | Accuracy: 0.586000 | 0.151 sec/iter\n",
      "Epoch: 111 | Batch: 010 / 011 | Total loss: 1.092 | Reg loss: 0.042 | Tree loss: 1.092 | Accuracy: 0.587031 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 112 | Batch: 000 / 011 | Total loss: 1.222 | Reg loss: 0.042 | Tree loss: 1.222 | Accuracy: 0.534500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 001 / 011 | Total loss: 1.199 | Reg loss: 0.042 | Tree loss: 1.199 | Accuracy: 0.546500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 002 / 011 | Total loss: 1.169 | Reg loss: 0.042 | Tree loss: 1.169 | Accuracy: 0.564500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 003 / 011 | Total loss: 1.156 | Reg loss: 0.042 | Tree loss: 1.156 | Accuracy: 0.574000 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 004 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.601500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 005 / 011 | Total loss: 1.130 | Reg loss: 0.042 | Tree loss: 1.130 | Accuracy: 0.571500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 006 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.586000 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 007 / 011 | Total loss: 1.118 | Reg loss: 0.042 | Tree loss: 1.118 | Accuracy: 0.597500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 008 / 011 | Total loss: 1.100 | Reg loss: 0.042 | Tree loss: 1.100 | Accuracy: 0.606000 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 009 / 011 | Total loss: 1.120 | Reg loss: 0.042 | Tree loss: 1.120 | Accuracy: 0.602500 | 0.151 sec/iter\n",
      "Epoch: 112 | Batch: 010 / 011 | Total loss: 1.149 | Reg loss: 0.042 | Tree loss: 1.149 | Accuracy: 0.593857 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 113 | Batch: 000 / 011 | Total loss: 1.221 | Reg loss: 0.042 | Tree loss: 1.221 | Accuracy: 0.548000 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 001 / 011 | Total loss: 1.195 | Reg loss: 0.042 | Tree loss: 1.195 | Accuracy: 0.560500 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 002 / 011 | Total loss: 1.173 | Reg loss: 0.042 | Tree loss: 1.173 | Accuracy: 0.560000 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 003 / 011 | Total loss: 1.161 | Reg loss: 0.042 | Tree loss: 1.161 | Accuracy: 0.569500 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 004 / 011 | Total loss: 1.141 | Reg loss: 0.042 | Tree loss: 1.141 | Accuracy: 0.592500 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 005 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.592500 | 0.152 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113 | Batch: 006 / 011 | Total loss: 1.128 | Reg loss: 0.042 | Tree loss: 1.128 | Accuracy: 0.594000 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 007 / 011 | Total loss: 1.096 | Reg loss: 0.042 | Tree loss: 1.096 | Accuracy: 0.602000 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 008 / 011 | Total loss: 1.098 | Reg loss: 0.042 | Tree loss: 1.098 | Accuracy: 0.607500 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 009 / 011 | Total loss: 1.113 | Reg loss: 0.042 | Tree loss: 1.113 | Accuracy: 0.590000 | 0.152 sec/iter\n",
      "Epoch: 113 | Batch: 010 / 011 | Total loss: 1.087 | Reg loss: 0.042 | Tree loss: 1.087 | Accuracy: 0.607509 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 114 | Batch: 000 / 011 | Total loss: 1.204 | Reg loss: 0.042 | Tree loss: 1.204 | Accuracy: 0.540500 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 001 / 011 | Total loss: 1.189 | Reg loss: 0.042 | Tree loss: 1.189 | Accuracy: 0.560000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 002 / 011 | Total loss: 1.158 | Reg loss: 0.042 | Tree loss: 1.158 | Accuracy: 0.586000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 003 / 011 | Total loss: 1.155 | Reg loss: 0.042 | Tree loss: 1.155 | Accuracy: 0.580000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 004 / 011 | Total loss: 1.136 | Reg loss: 0.042 | Tree loss: 1.136 | Accuracy: 0.571000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 005 / 011 | Total loss: 1.112 | Reg loss: 0.042 | Tree loss: 1.112 | Accuracy: 0.603000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 006 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.592000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 007 / 011 | Total loss: 1.121 | Reg loss: 0.042 | Tree loss: 1.121 | Accuracy: 0.594000 | 0.153 sec/iter\n",
      "Epoch: 114 | Batch: 008 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.586500 | 0.152 sec/iter\n",
      "Epoch: 114 | Batch: 009 / 011 | Total loss: 1.108 | Reg loss: 0.042 | Tree loss: 1.108 | Accuracy: 0.606000 | 0.152 sec/iter\n",
      "Epoch: 114 | Batch: 010 / 011 | Total loss: 1.065 | Reg loss: 0.042 | Tree loss: 1.065 | Accuracy: 0.675768 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 115 | Batch: 000 / 011 | Total loss: 1.221 | Reg loss: 0.042 | Tree loss: 1.221 | Accuracy: 0.533000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 001 / 011 | Total loss: 1.201 | Reg loss: 0.042 | Tree loss: 1.201 | Accuracy: 0.549000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 002 / 011 | Total loss: 1.167 | Reg loss: 0.042 | Tree loss: 1.167 | Accuracy: 0.578500 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 003 / 011 | Total loss: 1.157 | Reg loss: 0.042 | Tree loss: 1.157 | Accuracy: 0.585500 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 004 / 011 | Total loss: 1.119 | Reg loss: 0.042 | Tree loss: 1.119 | Accuracy: 0.584000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 005 / 011 | Total loss: 1.115 | Reg loss: 0.042 | Tree loss: 1.115 | Accuracy: 0.610000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 006 / 011 | Total loss: 1.122 | Reg loss: 0.042 | Tree loss: 1.122 | Accuracy: 0.575500 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 007 / 011 | Total loss: 1.100 | Reg loss: 0.042 | Tree loss: 1.100 | Accuracy: 0.602000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 008 / 011 | Total loss: 1.103 | Reg loss: 0.042 | Tree loss: 1.103 | Accuracy: 0.606000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 009 / 011 | Total loss: 1.115 | Reg loss: 0.042 | Tree loss: 1.115 | Accuracy: 0.602000 | 0.153 sec/iter\n",
      "Epoch: 115 | Batch: 010 / 011 | Total loss: 1.055 | Reg loss: 0.042 | Tree loss: 1.055 | Accuracy: 0.604096 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 116 | Batch: 000 / 011 | Total loss: 1.213 | Reg loss: 0.042 | Tree loss: 1.213 | Accuracy: 0.539000 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 001 / 011 | Total loss: 1.192 | Reg loss: 0.042 | Tree loss: 1.192 | Accuracy: 0.576000 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 002 / 011 | Total loss: 1.166 | Reg loss: 0.042 | Tree loss: 1.166 | Accuracy: 0.575000 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 003 / 011 | Total loss: 1.159 | Reg loss: 0.042 | Tree loss: 1.159 | Accuracy: 0.550000 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 004 / 011 | Total loss: 1.116 | Reg loss: 0.042 | Tree loss: 1.116 | Accuracy: 0.601000 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 005 / 011 | Total loss: 1.111 | Reg loss: 0.042 | Tree loss: 1.111 | Accuracy: 0.586500 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 006 / 011 | Total loss: 1.119 | Reg loss: 0.042 | Tree loss: 1.119 | Accuracy: 0.590500 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 007 / 011 | Total loss: 1.106 | Reg loss: 0.042 | Tree loss: 1.106 | Accuracy: 0.590000 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 008 / 011 | Total loss: 1.106 | Reg loss: 0.042 | Tree loss: 1.106 | Accuracy: 0.580500 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 009 / 011 | Total loss: 1.096 | Reg loss: 0.042 | Tree loss: 1.096 | Accuracy: 0.595500 | 0.153 sec/iter\n",
      "Epoch: 116 | Batch: 010 / 011 | Total loss: 1.120 | Reg loss: 0.042 | Tree loss: 1.120 | Accuracy: 0.621160 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 117 | Batch: 000 / 011 | Total loss: 1.188 | Reg loss: 0.042 | Tree loss: 1.188 | Accuracy: 0.573500 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 001 / 011 | Total loss: 1.186 | Reg loss: 0.042 | Tree loss: 1.186 | Accuracy: 0.567500 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 002 / 011 | Total loss: 1.161 | Reg loss: 0.042 | Tree loss: 1.161 | Accuracy: 0.585500 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 003 / 011 | Total loss: 1.154 | Reg loss: 0.042 | Tree loss: 1.154 | Accuracy: 0.594000 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 004 / 011 | Total loss: 1.129 | Reg loss: 0.042 | Tree loss: 1.129 | Accuracy: 0.598500 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 005 / 011 | Total loss: 1.111 | Reg loss: 0.042 | Tree loss: 1.111 | Accuracy: 0.604000 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 006 / 011 | Total loss: 1.123 | Reg loss: 0.042 | Tree loss: 1.123 | Accuracy: 0.595000 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 007 / 011 | Total loss: 1.116 | Reg loss: 0.042 | Tree loss: 1.116 | Accuracy: 0.571500 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 008 / 011 | Total loss: 1.110 | Reg loss: 0.042 | Tree loss: 1.110 | Accuracy: 0.590000 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 009 / 011 | Total loss: 1.099 | Reg loss: 0.042 | Tree loss: 1.099 | Accuracy: 0.599500 | 0.153 sec/iter\n",
      "Epoch: 117 | Batch: 010 / 011 | Total loss: 1.098 | Reg loss: 0.042 | Tree loss: 1.098 | Accuracy: 0.583618 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 118 | Batch: 000 / 011 | Total loss: 1.179 | Reg loss: 0.042 | Tree loss: 1.179 | Accuracy: 0.573000 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 001 / 011 | Total loss: 1.185 | Reg loss: 0.042 | Tree loss: 1.185 | Accuracy: 0.559000 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 002 / 011 | Total loss: 1.165 | Reg loss: 0.042 | Tree loss: 1.165 | Accuracy: 0.575500 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 003 / 011 | Total loss: 1.151 | Reg loss: 0.042 | Tree loss: 1.151 | Accuracy: 0.585500 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 004 / 011 | Total loss: 1.120 | Reg loss: 0.042 | Tree loss: 1.120 | Accuracy: 0.601000 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 005 / 011 | Total loss: 1.134 | Reg loss: 0.042 | Tree loss: 1.134 | Accuracy: 0.598500 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 006 / 011 | Total loss: 1.097 | Reg loss: 0.042 | Tree loss: 1.097 | Accuracy: 0.607500 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 007 / 011 | Total loss: 1.105 | Reg loss: 0.042 | Tree loss: 1.105 | Accuracy: 0.599000 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 008 / 011 | Total loss: 1.103 | Reg loss: 0.042 | Tree loss: 1.103 | Accuracy: 0.591000 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 009 / 011 | Total loss: 1.098 | Reg loss: 0.042 | Tree loss: 1.098 | Accuracy: 0.600500 | 0.153 sec/iter\n",
      "Epoch: 118 | Batch: 010 / 011 | Total loss: 1.117 | Reg loss: 0.042 | Tree loss: 1.117 | Accuracy: 0.573379 | 0.153 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 119 | Batch: 000 / 011 | Total loss: 1.198 | Reg loss: 0.042 | Tree loss: 1.198 | Accuracy: 0.567000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 001 / 011 | Total loss: 1.188 | Reg loss: 0.042 | Tree loss: 1.188 | Accuracy: 0.580000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 002 / 011 | Total loss: 1.161 | Reg loss: 0.042 | Tree loss: 1.161 | Accuracy: 0.580000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 003 / 011 | Total loss: 1.143 | Reg loss: 0.042 | Tree loss: 1.143 | Accuracy: 0.590500 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 004 / 011 | Total loss: 1.113 | Reg loss: 0.042 | Tree loss: 1.113 | Accuracy: 0.620000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 005 / 011 | Total loss: 1.111 | Reg loss: 0.042 | Tree loss: 1.111 | Accuracy: 0.610000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 006 / 011 | Total loss: 1.119 | Reg loss: 0.042 | Tree loss: 1.119 | Accuracy: 0.589500 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 007 / 011 | Total loss: 1.104 | Reg loss: 0.042 | Tree loss: 1.104 | Accuracy: 0.579000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 008 / 011 | Total loss: 1.099 | Reg loss: 0.042 | Tree loss: 1.099 | Accuracy: 0.589500 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 009 / 011 | Total loss: 1.093 | Reg loss: 0.042 | Tree loss: 1.093 | Accuracy: 0.585000 | 0.153 sec/iter\n",
      "Epoch: 119 | Batch: 010 / 011 | Total loss: 1.088 | Reg loss: 0.042 | Tree loss: 1.088 | Accuracy: 0.576792 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 120 | Batch: 000 / 011 | Total loss: 1.212 | Reg loss: 0.042 | Tree loss: 1.212 | Accuracy: 0.547500 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 001 / 011 | Total loss: 1.178 | Reg loss: 0.042 | Tree loss: 1.178 | Accuracy: 0.578000 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 002 / 011 | Total loss: 1.172 | Reg loss: 0.042 | Tree loss: 1.172 | Accuracy: 0.555500 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 003 / 011 | Total loss: 1.129 | Reg loss: 0.042 | Tree loss: 1.129 | Accuracy: 0.591000 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 004 / 011 | Total loss: 1.139 | Reg loss: 0.042 | Tree loss: 1.139 | Accuracy: 0.596000 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 005 / 011 | Total loss: 1.110 | Reg loss: 0.042 | Tree loss: 1.110 | Accuracy: 0.598000 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 006 / 011 | Total loss: 1.107 | Reg loss: 0.042 | Tree loss: 1.107 | Accuracy: 0.581500 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 007 / 011 | Total loss: 1.081 | Reg loss: 0.042 | Tree loss: 1.081 | Accuracy: 0.622000 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 008 / 011 | Total loss: 1.098 | Reg loss: 0.042 | Tree loss: 1.098 | Accuracy: 0.600000 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 009 / 011 | Total loss: 1.096 | Reg loss: 0.042 | Tree loss: 1.096 | Accuracy: 0.587500 | 0.153 sec/iter\n",
      "Epoch: 120 | Batch: 010 / 011 | Total loss: 1.080 | Reg loss: 0.042 | Tree loss: 1.080 | Accuracy: 0.593857 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 121 | Batch: 000 / 011 | Total loss: 1.176 | Reg loss: 0.042 | Tree loss: 1.176 | Accuracy: 0.576000 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 001 / 011 | Total loss: 1.184 | Reg loss: 0.042 | Tree loss: 1.184 | Accuracy: 0.586000 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 002 / 011 | Total loss: 1.159 | Reg loss: 0.042 | Tree loss: 1.159 | Accuracy: 0.581000 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 003 / 011 | Total loss: 1.142 | Reg loss: 0.042 | Tree loss: 1.142 | Accuracy: 0.594500 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 004 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.587500 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 005 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.580500 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 006 / 011 | Total loss: 1.087 | Reg loss: 0.042 | Tree loss: 1.087 | Accuracy: 0.599500 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 007 / 011 | Total loss: 1.111 | Reg loss: 0.042 | Tree loss: 1.111 | Accuracy: 0.587500 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 008 / 011 | Total loss: 1.091 | Reg loss: 0.042 | Tree loss: 1.091 | Accuracy: 0.580000 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 009 / 011 | Total loss: 1.095 | Reg loss: 0.042 | Tree loss: 1.095 | Accuracy: 0.587000 | 0.153 sec/iter\n",
      "Epoch: 121 | Batch: 010 / 011 | Total loss: 1.064 | Reg loss: 0.042 | Tree loss: 1.064 | Accuracy: 0.610922 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 122 | Batch: 000 / 011 | Total loss: 1.185 | Reg loss: 0.042 | Tree loss: 1.185 | Accuracy: 0.556500 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 001 / 011 | Total loss: 1.174 | Reg loss: 0.042 | Tree loss: 1.174 | Accuracy: 0.571000 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 002 / 011 | Total loss: 1.161 | Reg loss: 0.042 | Tree loss: 1.161 | Accuracy: 0.576000 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 003 / 011 | Total loss: 1.145 | Reg loss: 0.042 | Tree loss: 1.145 | Accuracy: 0.589000 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 004 / 011 | Total loss: 1.118 | Reg loss: 0.042 | Tree loss: 1.118 | Accuracy: 0.607000 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 005 / 011 | Total loss: 1.128 | Reg loss: 0.042 | Tree loss: 1.128 | Accuracy: 0.580500 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 006 / 011 | Total loss: 1.096 | Reg loss: 0.042 | Tree loss: 1.096 | Accuracy: 0.602000 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 007 / 011 | Total loss: 1.090 | Reg loss: 0.042 | Tree loss: 1.090 | Accuracy: 0.597500 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 008 / 011 | Total loss: 1.090 | Reg loss: 0.042 | Tree loss: 1.090 | Accuracy: 0.602500 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 009 / 011 | Total loss: 1.098 | Reg loss: 0.042 | Tree loss: 1.098 | Accuracy: 0.574000 | 0.153 sec/iter\n",
      "Epoch: 122 | Batch: 010 / 011 | Total loss: 1.048 | Reg loss: 0.042 | Tree loss: 1.048 | Accuracy: 0.638225 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 123 | Batch: 000 / 011 | Total loss: 1.197 | Reg loss: 0.042 | Tree loss: 1.197 | Accuracy: 0.551000 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 001 / 011 | Total loss: 1.146 | Reg loss: 0.042 | Tree loss: 1.146 | Accuracy: 0.587000 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 002 / 011 | Total loss: 1.150 | Reg loss: 0.042 | Tree loss: 1.150 | Accuracy: 0.593000 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 003 / 011 | Total loss: 1.132 | Reg loss: 0.042 | Tree loss: 1.132 | Accuracy: 0.596500 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 004 / 011 | Total loss: 1.132 | Reg loss: 0.042 | Tree loss: 1.132 | Accuracy: 0.582500 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 005 / 011 | Total loss: 1.110 | Reg loss: 0.042 | Tree loss: 1.110 | Accuracy: 0.582500 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 006 / 011 | Total loss: 1.101 | Reg loss: 0.042 | Tree loss: 1.101 | Accuracy: 0.593000 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 007 / 011 | Total loss: 1.091 | Reg loss: 0.042 | Tree loss: 1.091 | Accuracy: 0.598500 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 008 / 011 | Total loss: 1.099 | Reg loss: 0.042 | Tree loss: 1.099 | Accuracy: 0.599500 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 009 / 011 | Total loss: 1.102 | Reg loss: 0.042 | Tree loss: 1.102 | Accuracy: 0.604500 | 0.153 sec/iter\n",
      "Epoch: 123 | Batch: 010 / 011 | Total loss: 1.126 | Reg loss: 0.042 | Tree loss: 1.126 | Accuracy: 0.610922 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 124 | Batch: 000 / 011 | Total loss: 1.184 | Reg loss: 0.042 | Tree loss: 1.184 | Accuracy: 0.572500 | 0.154 sec/iter\n",
      "Epoch: 124 | Batch: 001 / 011 | Total loss: 1.156 | Reg loss: 0.042 | Tree loss: 1.156 | Accuracy: 0.593500 | 0.154 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124 | Batch: 002 / 011 | Total loss: 1.165 | Reg loss: 0.042 | Tree loss: 1.165 | Accuracy: 0.580500 | 0.154 sec/iter\n",
      "Epoch: 124 | Batch: 003 / 011 | Total loss: 1.153 | Reg loss: 0.042 | Tree loss: 1.153 | Accuracy: 0.585000 | 0.154 sec/iter\n",
      "Epoch: 124 | Batch: 004 / 011 | Total loss: 1.126 | Reg loss: 0.042 | Tree loss: 1.126 | Accuracy: 0.587000 | 0.154 sec/iter\n",
      "Epoch: 124 | Batch: 005 / 011 | Total loss: 1.106 | Reg loss: 0.042 | Tree loss: 1.106 | Accuracy: 0.602000 | 0.153 sec/iter\n",
      "Epoch: 124 | Batch: 006 / 011 | Total loss: 1.086 | Reg loss: 0.042 | Tree loss: 1.086 | Accuracy: 0.624000 | 0.153 sec/iter\n",
      "Epoch: 124 | Batch: 007 / 011 | Total loss: 1.101 | Reg loss: 0.042 | Tree loss: 1.101 | Accuracy: 0.585500 | 0.153 sec/iter\n",
      "Epoch: 124 | Batch: 008 / 011 | Total loss: 1.081 | Reg loss: 0.042 | Tree loss: 1.081 | Accuracy: 0.610500 | 0.153 sec/iter\n",
      "Epoch: 124 | Batch: 009 / 011 | Total loss: 1.086 | Reg loss: 0.042 | Tree loss: 1.086 | Accuracy: 0.594000 | 0.153 sec/iter\n",
      "Epoch: 124 | Batch: 010 / 011 | Total loss: 1.087 | Reg loss: 0.042 | Tree loss: 1.087 | Accuracy: 0.597270 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 125 | Batch: 000 / 011 | Total loss: 1.191 | Reg loss: 0.042 | Tree loss: 1.191 | Accuracy: 0.563500 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 001 / 011 | Total loss: 1.155 | Reg loss: 0.042 | Tree loss: 1.155 | Accuracy: 0.578000 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 002 / 011 | Total loss: 1.166 | Reg loss: 0.042 | Tree loss: 1.166 | Accuracy: 0.571000 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 003 / 011 | Total loss: 1.135 | Reg loss: 0.042 | Tree loss: 1.135 | Accuracy: 0.576000 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 004 / 011 | Total loss: 1.119 | Reg loss: 0.042 | Tree loss: 1.119 | Accuracy: 0.581500 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 005 / 011 | Total loss: 1.101 | Reg loss: 0.042 | Tree loss: 1.101 | Accuracy: 0.596500 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 006 / 011 | Total loss: 1.105 | Reg loss: 0.042 | Tree loss: 1.105 | Accuracy: 0.592500 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 007 / 011 | Total loss: 1.076 | Reg loss: 0.042 | Tree loss: 1.076 | Accuracy: 0.614000 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 008 / 011 | Total loss: 1.070 | Reg loss: 0.042 | Tree loss: 1.070 | Accuracy: 0.633000 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 009 / 011 | Total loss: 1.091 | Reg loss: 0.042 | Tree loss: 1.091 | Accuracy: 0.619500 | 0.154 sec/iter\n",
      "Epoch: 125 | Batch: 010 / 011 | Total loss: 1.108 | Reg loss: 0.042 | Tree loss: 1.108 | Accuracy: 0.576792 | 0.154 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 126 | Batch: 000 / 011 | Total loss: 1.176 | Reg loss: 0.042 | Tree loss: 1.176 | Accuracy: 0.575000 | 0.154 sec/iter\n",
      "Epoch: 126 | Batch: 001 / 011 | Total loss: 1.150 | Reg loss: 0.042 | Tree loss: 1.150 | Accuracy: 0.605500 | 0.154 sec/iter\n",
      "Epoch: 126 | Batch: 002 / 011 | Total loss: 1.162 | Reg loss: 0.042 | Tree loss: 1.162 | Accuracy: 0.584000 | 0.154 sec/iter\n",
      "Epoch: 126 | Batch: 003 / 011 | Total loss: 1.127 | Reg loss: 0.042 | Tree loss: 1.127 | Accuracy: 0.612000 | 0.154 sec/iter\n",
      "Epoch: 126 | Batch: 004 / 011 | Total loss: 1.112 | Reg loss: 0.042 | Tree loss: 1.112 | Accuracy: 0.612500 | 0.153 sec/iter\n",
      "Epoch: 126 | Batch: 005 / 011 | Total loss: 1.115 | Reg loss: 0.042 | Tree loss: 1.115 | Accuracy: 0.601000 | 0.153 sec/iter\n",
      "Epoch: 126 | Batch: 006 / 011 | Total loss: 1.096 | Reg loss: 0.042 | Tree loss: 1.096 | Accuracy: 0.591500 | 0.153 sec/iter\n",
      "Epoch: 126 | Batch: 007 / 011 | Total loss: 1.100 | Reg loss: 0.042 | Tree loss: 1.100 | Accuracy: 0.610500 | 0.153 sec/iter\n",
      "Epoch: 126 | Batch: 008 / 011 | Total loss: 1.078 | Reg loss: 0.042 | Tree loss: 1.078 | Accuracy: 0.598000 | 0.153 sec/iter\n",
      "Epoch: 126 | Batch: 009 / 011 | Total loss: 1.086 | Reg loss: 0.043 | Tree loss: 1.086 | Accuracy: 0.585000 | 0.153 sec/iter\n",
      "Epoch: 126 | Batch: 010 / 011 | Total loss: 1.096 | Reg loss: 0.043 | Tree loss: 1.096 | Accuracy: 0.566553 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 127 | Batch: 000 / 011 | Total loss: 1.180 | Reg loss: 0.042 | Tree loss: 1.180 | Accuracy: 0.558500 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 001 / 011 | Total loss: 1.152 | Reg loss: 0.042 | Tree loss: 1.152 | Accuracy: 0.607500 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 002 / 011 | Total loss: 1.151 | Reg loss: 0.042 | Tree loss: 1.151 | Accuracy: 0.580000 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 003 / 011 | Total loss: 1.128 | Reg loss: 0.042 | Tree loss: 1.128 | Accuracy: 0.591500 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 004 / 011 | Total loss: 1.115 | Reg loss: 0.042 | Tree loss: 1.115 | Accuracy: 0.599000 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 005 / 011 | Total loss: 1.091 | Reg loss: 0.042 | Tree loss: 1.091 | Accuracy: 0.604000 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 006 / 011 | Total loss: 1.083 | Reg loss: 0.042 | Tree loss: 1.083 | Accuracy: 0.602500 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 007 / 011 | Total loss: 1.122 | Reg loss: 0.042 | Tree loss: 1.122 | Accuracy: 0.576000 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 008 / 011 | Total loss: 1.080 | Reg loss: 0.043 | Tree loss: 1.080 | Accuracy: 0.617000 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 009 / 011 | Total loss: 1.099 | Reg loss: 0.043 | Tree loss: 1.099 | Accuracy: 0.596500 | 0.153 sec/iter\n",
      "Epoch: 127 | Batch: 010 / 011 | Total loss: 1.041 | Reg loss: 0.043 | Tree loss: 1.041 | Accuracy: 0.624573 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 128 | Batch: 000 / 011 | Total loss: 1.183 | Reg loss: 0.042 | Tree loss: 1.183 | Accuracy: 0.572500 | 0.153 sec/iter\n",
      "Epoch: 128 | Batch: 001 / 011 | Total loss: 1.174 | Reg loss: 0.042 | Tree loss: 1.174 | Accuracy: 0.559500 | 0.153 sec/iter\n",
      "Epoch: 128 | Batch: 002 / 011 | Total loss: 1.145 | Reg loss: 0.042 | Tree loss: 1.145 | Accuracy: 0.593000 | 0.153 sec/iter\n",
      "Epoch: 128 | Batch: 003 / 011 | Total loss: 1.124 | Reg loss: 0.042 | Tree loss: 1.124 | Accuracy: 0.579000 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 004 / 011 | Total loss: 1.111 | Reg loss: 0.042 | Tree loss: 1.111 | Accuracy: 0.600000 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 005 / 011 | Total loss: 1.086 | Reg loss: 0.042 | Tree loss: 1.086 | Accuracy: 0.613000 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 006 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.614000 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 007 / 011 | Total loss: 1.096 | Reg loss: 0.043 | Tree loss: 1.096 | Accuracy: 0.598000 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 008 / 011 | Total loss: 1.081 | Reg loss: 0.043 | Tree loss: 1.081 | Accuracy: 0.596500 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 009 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.606000 | 0.152 sec/iter\n",
      "Epoch: 128 | Batch: 010 / 011 | Total loss: 1.065 | Reg loss: 0.043 | Tree loss: 1.065 | Accuracy: 0.604096 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 129 | Batch: 000 / 011 | Total loss: 1.175 | Reg loss: 0.042 | Tree loss: 1.175 | Accuracy: 0.575000 | 0.153 sec/iter\n",
      "Epoch: 129 | Batch: 001 / 011 | Total loss: 1.173 | Reg loss: 0.042 | Tree loss: 1.173 | Accuracy: 0.583500 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 002 / 011 | Total loss: 1.149 | Reg loss: 0.042 | Tree loss: 1.149 | Accuracy: 0.597000 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 003 / 011 | Total loss: 1.108 | Reg loss: 0.042 | Tree loss: 1.108 | Accuracy: 0.615000 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 004 / 011 | Total loss: 1.116 | Reg loss: 0.043 | Tree loss: 1.116 | Accuracy: 0.589000 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 005 / 011 | Total loss: 1.088 | Reg loss: 0.043 | Tree loss: 1.088 | Accuracy: 0.596000 | 0.152 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129 | Batch: 006 / 011 | Total loss: 1.090 | Reg loss: 0.043 | Tree loss: 1.090 | Accuracy: 0.608500 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 007 / 011 | Total loss: 1.072 | Reg loss: 0.043 | Tree loss: 1.072 | Accuracy: 0.604500 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 008 / 011 | Total loss: 1.092 | Reg loss: 0.043 | Tree loss: 1.092 | Accuracy: 0.600500 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 009 / 011 | Total loss: 1.090 | Reg loss: 0.043 | Tree loss: 1.090 | Accuracy: 0.588000 | 0.152 sec/iter\n",
      "Epoch: 129 | Batch: 010 / 011 | Total loss: 1.113 | Reg loss: 0.043 | Tree loss: 1.113 | Accuracy: 0.515358 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 130 | Batch: 000 / 011 | Total loss: 1.194 | Reg loss: 0.043 | Tree loss: 1.194 | Accuracy: 0.567500 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 001 / 011 | Total loss: 1.149 | Reg loss: 0.043 | Tree loss: 1.149 | Accuracy: 0.603500 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 002 / 011 | Total loss: 1.132 | Reg loss: 0.043 | Tree loss: 1.132 | Accuracy: 0.595000 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 003 / 011 | Total loss: 1.134 | Reg loss: 0.043 | Tree loss: 1.134 | Accuracy: 0.590000 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 004 / 011 | Total loss: 1.108 | Reg loss: 0.043 | Tree loss: 1.108 | Accuracy: 0.601000 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 005 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.608000 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 006 / 011 | Total loss: 1.087 | Reg loss: 0.043 | Tree loss: 1.087 | Accuracy: 0.600500 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 007 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.606000 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 008 / 011 | Total loss: 1.083 | Reg loss: 0.043 | Tree loss: 1.083 | Accuracy: 0.595500 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 009 / 011 | Total loss: 1.089 | Reg loss: 0.043 | Tree loss: 1.089 | Accuracy: 0.602500 | 0.152 sec/iter\n",
      "Epoch: 130 | Batch: 010 / 011 | Total loss: 1.043 | Reg loss: 0.043 | Tree loss: 1.043 | Accuracy: 0.662116 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 131 | Batch: 000 / 011 | Total loss: 1.174 | Reg loss: 0.043 | Tree loss: 1.174 | Accuracy: 0.581000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 001 / 011 | Total loss: 1.136 | Reg loss: 0.043 | Tree loss: 1.136 | Accuracy: 0.602000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 002 / 011 | Total loss: 1.159 | Reg loss: 0.043 | Tree loss: 1.159 | Accuracy: 0.582500 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 003 / 011 | Total loss: 1.119 | Reg loss: 0.043 | Tree loss: 1.119 | Accuracy: 0.595500 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 004 / 011 | Total loss: 1.110 | Reg loss: 0.043 | Tree loss: 1.110 | Accuracy: 0.600000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 005 / 011 | Total loss: 1.081 | Reg loss: 0.043 | Tree loss: 1.081 | Accuracy: 0.598000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 006 / 011 | Total loss: 1.096 | Reg loss: 0.043 | Tree loss: 1.096 | Accuracy: 0.604000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 007 / 011 | Total loss: 1.082 | Reg loss: 0.043 | Tree loss: 1.082 | Accuracy: 0.605000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 008 / 011 | Total loss: 1.080 | Reg loss: 0.043 | Tree loss: 1.080 | Accuracy: 0.605500 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 009 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.597000 | 0.152 sec/iter\n",
      "Epoch: 131 | Batch: 010 / 011 | Total loss: 1.086 | Reg loss: 0.043 | Tree loss: 1.086 | Accuracy: 0.593857 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 132 | Batch: 000 / 011 | Total loss: 1.163 | Reg loss: 0.043 | Tree loss: 1.163 | Accuracy: 0.589500 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 001 / 011 | Total loss: 1.148 | Reg loss: 0.043 | Tree loss: 1.148 | Accuracy: 0.608000 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 002 / 011 | Total loss: 1.151 | Reg loss: 0.043 | Tree loss: 1.151 | Accuracy: 0.602000 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 003 / 011 | Total loss: 1.120 | Reg loss: 0.043 | Tree loss: 1.120 | Accuracy: 0.615000 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 004 / 011 | Total loss: 1.098 | Reg loss: 0.043 | Tree loss: 1.098 | Accuracy: 0.605500 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 005 / 011 | Total loss: 1.106 | Reg loss: 0.043 | Tree loss: 1.106 | Accuracy: 0.601000 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 006 / 011 | Total loss: 1.098 | Reg loss: 0.043 | Tree loss: 1.098 | Accuracy: 0.593500 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 007 / 011 | Total loss: 1.087 | Reg loss: 0.043 | Tree loss: 1.087 | Accuracy: 0.586000 | 0.152 sec/iter\n",
      "Epoch: 132 | Batch: 008 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.586000 | 0.151 sec/iter\n",
      "Epoch: 132 | Batch: 009 / 011 | Total loss: 1.067 | Reg loss: 0.043 | Tree loss: 1.067 | Accuracy: 0.626000 | 0.151 sec/iter\n",
      "Epoch: 132 | Batch: 010 / 011 | Total loss: 1.083 | Reg loss: 0.043 | Tree loss: 1.083 | Accuracy: 0.597270 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 133 | Batch: 000 / 011 | Total loss: 1.173 | Reg loss: 0.043 | Tree loss: 1.173 | Accuracy: 0.585000 | 0.152 sec/iter\n",
      "Epoch: 133 | Batch: 001 / 011 | Total loss: 1.147 | Reg loss: 0.043 | Tree loss: 1.147 | Accuracy: 0.590500 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 002 / 011 | Total loss: 1.159 | Reg loss: 0.043 | Tree loss: 1.159 | Accuracy: 0.599000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 003 / 011 | Total loss: 1.111 | Reg loss: 0.043 | Tree loss: 1.111 | Accuracy: 0.592000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 004 / 011 | Total loss: 1.093 | Reg loss: 0.043 | Tree loss: 1.093 | Accuracy: 0.619000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 005 / 011 | Total loss: 1.091 | Reg loss: 0.043 | Tree loss: 1.091 | Accuracy: 0.598500 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 006 / 011 | Total loss: 1.081 | Reg loss: 0.043 | Tree loss: 1.081 | Accuracy: 0.608000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 007 / 011 | Total loss: 1.082 | Reg loss: 0.043 | Tree loss: 1.082 | Accuracy: 0.598000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 008 / 011 | Total loss: 1.092 | Reg loss: 0.043 | Tree loss: 1.092 | Accuracy: 0.602000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 009 / 011 | Total loss: 1.083 | Reg loss: 0.043 | Tree loss: 1.083 | Accuracy: 0.604000 | 0.151 sec/iter\n",
      "Epoch: 133 | Batch: 010 / 011 | Total loss: 1.063 | Reg loss: 0.043 | Tree loss: 1.063 | Accuracy: 0.597270 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 134 | Batch: 000 / 011 | Total loss: 1.189 | Reg loss: 0.043 | Tree loss: 1.189 | Accuracy: 0.560000 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 001 / 011 | Total loss: 1.148 | Reg loss: 0.043 | Tree loss: 1.148 | Accuracy: 0.605000 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 002 / 011 | Total loss: 1.130 | Reg loss: 0.043 | Tree loss: 1.130 | Accuracy: 0.598500 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 003 / 011 | Total loss: 1.121 | Reg loss: 0.043 | Tree loss: 1.121 | Accuracy: 0.588500 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 004 / 011 | Total loss: 1.112 | Reg loss: 0.043 | Tree loss: 1.112 | Accuracy: 0.608500 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 005 / 011 | Total loss: 1.090 | Reg loss: 0.043 | Tree loss: 1.090 | Accuracy: 0.615500 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 006 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.610000 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 007 / 011 | Total loss: 1.076 | Reg loss: 0.043 | Tree loss: 1.076 | Accuracy: 0.612500 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 008 / 011 | Total loss: 1.070 | Reg loss: 0.043 | Tree loss: 1.070 | Accuracy: 0.606000 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 009 / 011 | Total loss: 1.084 | Reg loss: 0.043 | Tree loss: 1.084 | Accuracy: 0.605000 | 0.152 sec/iter\n",
      "Epoch: 134 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.043 | Tree loss: 1.050 | Accuracy: 0.621160 | 0.152 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 135 | Batch: 000 / 011 | Total loss: 1.178 | Reg loss: 0.043 | Tree loss: 1.178 | Accuracy: 0.585500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 001 / 011 | Total loss: 1.158 | Reg loss: 0.043 | Tree loss: 1.158 | Accuracy: 0.595500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 002 / 011 | Total loss: 1.127 | Reg loss: 0.043 | Tree loss: 1.127 | Accuracy: 0.605500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 003 / 011 | Total loss: 1.117 | Reg loss: 0.043 | Tree loss: 1.117 | Accuracy: 0.588500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 004 / 011 | Total loss: 1.088 | Reg loss: 0.043 | Tree loss: 1.088 | Accuracy: 0.617000 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 005 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.600500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 006 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.597500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 007 / 011 | Total loss: 1.076 | Reg loss: 0.043 | Tree loss: 1.076 | Accuracy: 0.626500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 008 / 011 | Total loss: 1.069 | Reg loss: 0.043 | Tree loss: 1.069 | Accuracy: 0.615500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 009 / 011 | Total loss: 1.087 | Reg loss: 0.043 | Tree loss: 1.087 | Accuracy: 0.599500 | 0.152 sec/iter\n",
      "Epoch: 135 | Batch: 010 / 011 | Total loss: 1.108 | Reg loss: 0.043 | Tree loss: 1.108 | Accuracy: 0.580205 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 136 | Batch: 000 / 011 | Total loss: 1.197 | Reg loss: 0.043 | Tree loss: 1.197 | Accuracy: 0.553500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 001 / 011 | Total loss: 1.155 | Reg loss: 0.043 | Tree loss: 1.155 | Accuracy: 0.595500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 002 / 011 | Total loss: 1.133 | Reg loss: 0.043 | Tree loss: 1.133 | Accuracy: 0.613500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 003 / 011 | Total loss: 1.107 | Reg loss: 0.043 | Tree loss: 1.107 | Accuracy: 0.604500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 004 / 011 | Total loss: 1.109 | Reg loss: 0.043 | Tree loss: 1.109 | Accuracy: 0.602500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 005 / 011 | Total loss: 1.088 | Reg loss: 0.043 | Tree loss: 1.088 | Accuracy: 0.625500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 006 / 011 | Total loss: 1.070 | Reg loss: 0.043 | Tree loss: 1.070 | Accuracy: 0.629500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 007 / 011 | Total loss: 1.068 | Reg loss: 0.043 | Tree loss: 1.068 | Accuracy: 0.615500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 008 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.629000 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 009 / 011 | Total loss: 1.073 | Reg loss: 0.043 | Tree loss: 1.073 | Accuracy: 0.600500 | 0.152 sec/iter\n",
      "Epoch: 136 | Batch: 010 / 011 | Total loss: 1.047 | Reg loss: 0.043 | Tree loss: 1.047 | Accuracy: 0.607509 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 137 | Batch: 000 / 011 | Total loss: 1.162 | Reg loss: 0.043 | Tree loss: 1.162 | Accuracy: 0.591000 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 001 / 011 | Total loss: 1.155 | Reg loss: 0.043 | Tree loss: 1.155 | Accuracy: 0.586500 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 002 / 011 | Total loss: 1.138 | Reg loss: 0.043 | Tree loss: 1.138 | Accuracy: 0.601000 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 003 / 011 | Total loss: 1.116 | Reg loss: 0.043 | Tree loss: 1.116 | Accuracy: 0.593500 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 004 / 011 | Total loss: 1.093 | Reg loss: 0.043 | Tree loss: 1.093 | Accuracy: 0.610500 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 005 / 011 | Total loss: 1.078 | Reg loss: 0.043 | Tree loss: 1.078 | Accuracy: 0.598000 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 006 / 011 | Total loss: 1.080 | Reg loss: 0.043 | Tree loss: 1.080 | Accuracy: 0.592500 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 007 / 011 | Total loss: 1.106 | Reg loss: 0.043 | Tree loss: 1.106 | Accuracy: 0.583500 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 008 / 011 | Total loss: 1.072 | Reg loss: 0.043 | Tree loss: 1.072 | Accuracy: 0.628500 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 009 / 011 | Total loss: 1.074 | Reg loss: 0.043 | Tree loss: 1.074 | Accuracy: 0.600000 | 0.152 sec/iter\n",
      "Epoch: 137 | Batch: 010 / 011 | Total loss: 1.043 | Reg loss: 0.043 | Tree loss: 1.043 | Accuracy: 0.662116 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 138 | Batch: 000 / 011 | Total loss: 1.147 | Reg loss: 0.043 | Tree loss: 1.147 | Accuracy: 0.611500 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 001 / 011 | Total loss: 1.156 | Reg loss: 0.043 | Tree loss: 1.156 | Accuracy: 0.590500 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 002 / 011 | Total loss: 1.133 | Reg loss: 0.043 | Tree loss: 1.133 | Accuracy: 0.601500 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 003 / 011 | Total loss: 1.103 | Reg loss: 0.043 | Tree loss: 1.103 | Accuracy: 0.620500 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 004 / 011 | Total loss: 1.117 | Reg loss: 0.043 | Tree loss: 1.117 | Accuracy: 0.590000 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 005 / 011 | Total loss: 1.073 | Reg loss: 0.043 | Tree loss: 1.073 | Accuracy: 0.618500 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 006 / 011 | Total loss: 1.078 | Reg loss: 0.043 | Tree loss: 1.078 | Accuracy: 0.621000 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 007 / 011 | Total loss: 1.092 | Reg loss: 0.043 | Tree loss: 1.092 | Accuracy: 0.600000 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 008 / 011 | Total loss: 1.074 | Reg loss: 0.043 | Tree loss: 1.074 | Accuracy: 0.619000 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 009 / 011 | Total loss: 1.067 | Reg loss: 0.043 | Tree loss: 1.067 | Accuracy: 0.597000 | 0.152 sec/iter\n",
      "Epoch: 138 | Batch: 010 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.621160 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 139 | Batch: 000 / 011 | Total loss: 1.168 | Reg loss: 0.043 | Tree loss: 1.168 | Accuracy: 0.584500 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 001 / 011 | Total loss: 1.132 | Reg loss: 0.043 | Tree loss: 1.132 | Accuracy: 0.605500 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 002 / 011 | Total loss: 1.135 | Reg loss: 0.043 | Tree loss: 1.135 | Accuracy: 0.603000 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 003 / 011 | Total loss: 1.108 | Reg loss: 0.043 | Tree loss: 1.108 | Accuracy: 0.603000 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 004 / 011 | Total loss: 1.111 | Reg loss: 0.043 | Tree loss: 1.111 | Accuracy: 0.598000 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 005 / 011 | Total loss: 1.109 | Reg loss: 0.043 | Tree loss: 1.109 | Accuracy: 0.598000 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 006 / 011 | Total loss: 1.100 | Reg loss: 0.043 | Tree loss: 1.100 | Accuracy: 0.581500 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 007 / 011 | Total loss: 1.064 | Reg loss: 0.043 | Tree loss: 1.064 | Accuracy: 0.639500 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 008 / 011 | Total loss: 1.057 | Reg loss: 0.043 | Tree loss: 1.057 | Accuracy: 0.628000 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 009 / 011 | Total loss: 1.054 | Reg loss: 0.043 | Tree loss: 1.054 | Accuracy: 0.612500 | 0.152 sec/iter\n",
      "Epoch: 139 | Batch: 010 / 011 | Total loss: 1.051 | Reg loss: 0.043 | Tree loss: 1.051 | Accuracy: 0.631399 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 140 | Batch: 000 / 011 | Total loss: 1.171 | Reg loss: 0.043 | Tree loss: 1.171 | Accuracy: 0.600000 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 001 / 011 | Total loss: 1.146 | Reg loss: 0.043 | Tree loss: 1.146 | Accuracy: 0.592000 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 002 / 011 | Total loss: 1.145 | Reg loss: 0.043 | Tree loss: 1.145 | Accuracy: 0.567500 | 0.152 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 | Batch: 003 / 011 | Total loss: 1.118 | Reg loss: 0.043 | Tree loss: 1.118 | Accuracy: 0.564500 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 004 / 011 | Total loss: 1.097 | Reg loss: 0.043 | Tree loss: 1.097 | Accuracy: 0.592000 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 005 / 011 | Total loss: 1.058 | Reg loss: 0.043 | Tree loss: 1.058 | Accuracy: 0.625000 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 006 / 011 | Total loss: 1.071 | Reg loss: 0.043 | Tree loss: 1.071 | Accuracy: 0.610500 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 007 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.599500 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 008 / 011 | Total loss: 1.068 | Reg loss: 0.043 | Tree loss: 1.068 | Accuracy: 0.622500 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 009 / 011 | Total loss: 1.075 | Reg loss: 0.043 | Tree loss: 1.075 | Accuracy: 0.616000 | 0.152 sec/iter\n",
      "Epoch: 140 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.043 | Tree loss: 1.050 | Accuracy: 0.624573 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 141 | Batch: 000 / 011 | Total loss: 1.184 | Reg loss: 0.043 | Tree loss: 1.184 | Accuracy: 0.567500 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 001 / 011 | Total loss: 1.143 | Reg loss: 0.043 | Tree loss: 1.143 | Accuracy: 0.584000 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 002 / 011 | Total loss: 1.122 | Reg loss: 0.043 | Tree loss: 1.122 | Accuracy: 0.605500 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 003 / 011 | Total loss: 1.110 | Reg loss: 0.043 | Tree loss: 1.110 | Accuracy: 0.609000 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 004 / 011 | Total loss: 1.090 | Reg loss: 0.043 | Tree loss: 1.090 | Accuracy: 0.612000 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 005 / 011 | Total loss: 1.101 | Reg loss: 0.043 | Tree loss: 1.101 | Accuracy: 0.608500 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 006 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.612500 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 007 / 011 | Total loss: 1.053 | Reg loss: 0.043 | Tree loss: 1.053 | Accuracy: 0.610000 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 008 / 011 | Total loss: 1.068 | Reg loss: 0.043 | Tree loss: 1.068 | Accuracy: 0.614000 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 009 / 011 | Total loss: 1.063 | Reg loss: 0.043 | Tree loss: 1.063 | Accuracy: 0.610500 | 0.152 sec/iter\n",
      "Epoch: 141 | Batch: 010 / 011 | Total loss: 1.105 | Reg loss: 0.043 | Tree loss: 1.105 | Accuracy: 0.597270 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 142 | Batch: 000 / 011 | Total loss: 1.158 | Reg loss: 0.043 | Tree loss: 1.158 | Accuracy: 0.589500 | 0.152 sec/iter\n",
      "Epoch: 142 | Batch: 001 / 011 | Total loss: 1.170 | Reg loss: 0.043 | Tree loss: 1.170 | Accuracy: 0.568000 | 0.152 sec/iter\n",
      "Epoch: 142 | Batch: 002 / 011 | Total loss: 1.134 | Reg loss: 0.043 | Tree loss: 1.134 | Accuracy: 0.601500 | 0.152 sec/iter\n",
      "Epoch: 142 | Batch: 003 / 011 | Total loss: 1.106 | Reg loss: 0.043 | Tree loss: 1.106 | Accuracy: 0.609000 | 0.152 sec/iter\n",
      "Epoch: 142 | Batch: 004 / 011 | Total loss: 1.092 | Reg loss: 0.043 | Tree loss: 1.092 | Accuracy: 0.600500 | 0.151 sec/iter\n",
      "Epoch: 142 | Batch: 005 / 011 | Total loss: 1.078 | Reg loss: 0.043 | Tree loss: 1.078 | Accuracy: 0.594500 | 0.151 sec/iter\n",
      "Epoch: 142 | Batch: 006 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.609500 | 0.151 sec/iter\n",
      "Epoch: 142 | Batch: 007 / 011 | Total loss: 1.068 | Reg loss: 0.043 | Tree loss: 1.068 | Accuracy: 0.631000 | 0.151 sec/iter\n",
      "Epoch: 142 | Batch: 008 / 011 | Total loss: 1.060 | Reg loss: 0.043 | Tree loss: 1.060 | Accuracy: 0.615500 | 0.151 sec/iter\n",
      "Epoch: 142 | Batch: 009 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.616000 | 0.151 sec/iter\n",
      "Epoch: 142 | Batch: 010 / 011 | Total loss: 1.104 | Reg loss: 0.043 | Tree loss: 1.104 | Accuracy: 0.563140 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 143 | Batch: 000 / 011 | Total loss: 1.189 | Reg loss: 0.043 | Tree loss: 1.189 | Accuracy: 0.581000 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 001 / 011 | Total loss: 1.138 | Reg loss: 0.043 | Tree loss: 1.138 | Accuracy: 0.600500 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 002 / 011 | Total loss: 1.122 | Reg loss: 0.043 | Tree loss: 1.122 | Accuracy: 0.597000 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 003 / 011 | Total loss: 1.097 | Reg loss: 0.043 | Tree loss: 1.097 | Accuracy: 0.610500 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 004 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.609000 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 005 / 011 | Total loss: 1.083 | Reg loss: 0.043 | Tree loss: 1.083 | Accuracy: 0.614500 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 006 / 011 | Total loss: 1.074 | Reg loss: 0.043 | Tree loss: 1.074 | Accuracy: 0.610500 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 007 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.595000 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 008 / 011 | Total loss: 1.059 | Reg loss: 0.043 | Tree loss: 1.059 | Accuracy: 0.612500 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 009 / 011 | Total loss: 1.052 | Reg loss: 0.043 | Tree loss: 1.052 | Accuracy: 0.638000 | 0.151 sec/iter\n",
      "Epoch: 143 | Batch: 010 / 011 | Total loss: 1.080 | Reg loss: 0.043 | Tree loss: 1.080 | Accuracy: 0.607509 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 144 | Batch: 000 / 011 | Total loss: 1.165 | Reg loss: 0.043 | Tree loss: 1.165 | Accuracy: 0.582000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 001 / 011 | Total loss: 1.142 | Reg loss: 0.043 | Tree loss: 1.142 | Accuracy: 0.601000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 002 / 011 | Total loss: 1.132 | Reg loss: 0.043 | Tree loss: 1.132 | Accuracy: 0.599500 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 003 / 011 | Total loss: 1.119 | Reg loss: 0.043 | Tree loss: 1.119 | Accuracy: 0.602000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 004 / 011 | Total loss: 1.074 | Reg loss: 0.043 | Tree loss: 1.074 | Accuracy: 0.608000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 005 / 011 | Total loss: 1.069 | Reg loss: 0.043 | Tree loss: 1.069 | Accuracy: 0.618000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 006 / 011 | Total loss: 1.070 | Reg loss: 0.043 | Tree loss: 1.070 | Accuracy: 0.599000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 007 / 011 | Total loss: 1.075 | Reg loss: 0.043 | Tree loss: 1.075 | Accuracy: 0.611500 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 008 / 011 | Total loss: 1.062 | Reg loss: 0.043 | Tree loss: 1.062 | Accuracy: 0.622000 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 009 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.622500 | 0.151 sec/iter\n",
      "Epoch: 144 | Batch: 010 / 011 | Total loss: 1.097 | Reg loss: 0.043 | Tree loss: 1.097 | Accuracy: 0.614334 | 0.15 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 145 | Batch: 000 / 011 | Total loss: 1.165 | Reg loss: 0.043 | Tree loss: 1.165 | Accuracy: 0.579500 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 001 / 011 | Total loss: 1.139 | Reg loss: 0.043 | Tree loss: 1.139 | Accuracy: 0.605000 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 002 / 011 | Total loss: 1.131 | Reg loss: 0.043 | Tree loss: 1.131 | Accuracy: 0.605000 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 003 / 011 | Total loss: 1.092 | Reg loss: 0.043 | Tree loss: 1.092 | Accuracy: 0.626000 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 004 / 011 | Total loss: 1.087 | Reg loss: 0.043 | Tree loss: 1.087 | Accuracy: 0.616000 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 005 / 011 | Total loss: 1.078 | Reg loss: 0.043 | Tree loss: 1.078 | Accuracy: 0.625000 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 006 / 011 | Total loss: 1.065 | Reg loss: 0.043 | Tree loss: 1.065 | Accuracy: 0.605000 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 007 / 011 | Total loss: 1.076 | Reg loss: 0.043 | Tree loss: 1.076 | Accuracy: 0.597500 | 0.151 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145 | Batch: 008 / 011 | Total loss: 1.064 | Reg loss: 0.043 | Tree loss: 1.064 | Accuracy: 0.611500 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 009 / 011 | Total loss: 1.047 | Reg loss: 0.043 | Tree loss: 1.047 | Accuracy: 0.629500 | 0.151 sec/iter\n",
      "Epoch: 145 | Batch: 010 / 011 | Total loss: 1.115 | Reg loss: 0.043 | Tree loss: 1.115 | Accuracy: 0.587031 | 0.151 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 146 | Batch: 000 / 011 | Total loss: 1.155 | Reg loss: 0.043 | Tree loss: 1.155 | Accuracy: 0.587000 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 001 / 011 | Total loss: 1.146 | Reg loss: 0.043 | Tree loss: 1.146 | Accuracy: 0.593500 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 002 / 011 | Total loss: 1.118 | Reg loss: 0.043 | Tree loss: 1.118 | Accuracy: 0.606000 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 003 / 011 | Total loss: 1.089 | Reg loss: 0.043 | Tree loss: 1.089 | Accuracy: 0.616500 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 004 / 011 | Total loss: 1.106 | Reg loss: 0.043 | Tree loss: 1.106 | Accuracy: 0.602000 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 005 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.615000 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 006 / 011 | Total loss: 1.081 | Reg loss: 0.043 | Tree loss: 1.081 | Accuracy: 0.604000 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 007 / 011 | Total loss: 1.064 | Reg loss: 0.043 | Tree loss: 1.064 | Accuracy: 0.611500 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 008 / 011 | Total loss: 1.053 | Reg loss: 0.043 | Tree loss: 1.053 | Accuracy: 0.623000 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 009 / 011 | Total loss: 1.070 | Reg loss: 0.043 | Tree loss: 1.070 | Accuracy: 0.617500 | 0.152 sec/iter\n",
      "Epoch: 146 | Batch: 010 / 011 | Total loss: 1.032 | Reg loss: 0.043 | Tree loss: 1.032 | Accuracy: 0.631399 | 0.152 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 147 | Batch: 000 / 011 | Total loss: 1.160 | Reg loss: 0.043 | Tree loss: 1.160 | Accuracy: 0.584000 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 001 / 011 | Total loss: 1.126 | Reg loss: 0.043 | Tree loss: 1.126 | Accuracy: 0.596000 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 002 / 011 | Total loss: 1.129 | Reg loss: 0.043 | Tree loss: 1.129 | Accuracy: 0.596500 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 003 / 011 | Total loss: 1.102 | Reg loss: 0.043 | Tree loss: 1.102 | Accuracy: 0.607000 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 004 / 011 | Total loss: 1.094 | Reg loss: 0.043 | Tree loss: 1.094 | Accuracy: 0.598500 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 005 / 011 | Total loss: 1.068 | Reg loss: 0.043 | Tree loss: 1.068 | Accuracy: 0.619000 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 006 / 011 | Total loss: 1.072 | Reg loss: 0.043 | Tree loss: 1.072 | Accuracy: 0.608000 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 007 / 011 | Total loss: 1.068 | Reg loss: 0.043 | Tree loss: 1.068 | Accuracy: 0.621500 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 008 / 011 | Total loss: 1.078 | Reg loss: 0.043 | Tree loss: 1.078 | Accuracy: 0.609500 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 009 / 011 | Total loss: 1.040 | Reg loss: 0.043 | Tree loss: 1.040 | Accuracy: 0.631500 | 0.153 sec/iter\n",
      "Epoch: 147 | Batch: 010 / 011 | Total loss: 1.100 | Reg loss: 0.043 | Tree loss: 1.100 | Accuracy: 0.614334 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 148 | Batch: 000 / 011 | Total loss: 1.135 | Reg loss: 0.043 | Tree loss: 1.135 | Accuracy: 0.603000 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 001 / 011 | Total loss: 1.149 | Reg loss: 0.043 | Tree loss: 1.149 | Accuracy: 0.583500 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 002 / 011 | Total loss: 1.137 | Reg loss: 0.043 | Tree loss: 1.137 | Accuracy: 0.593000 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 003 / 011 | Total loss: 1.096 | Reg loss: 0.043 | Tree loss: 1.096 | Accuracy: 0.623000 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 004 / 011 | Total loss: 1.087 | Reg loss: 0.043 | Tree loss: 1.087 | Accuracy: 0.607500 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 005 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.614000 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 006 / 011 | Total loss: 1.051 | Reg loss: 0.043 | Tree loss: 1.051 | Accuracy: 0.628500 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 007 / 011 | Total loss: 1.074 | Reg loss: 0.043 | Tree loss: 1.074 | Accuracy: 0.616500 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 008 / 011 | Total loss: 1.050 | Reg loss: 0.043 | Tree loss: 1.050 | Accuracy: 0.622000 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 009 / 011 | Total loss: 1.072 | Reg loss: 0.043 | Tree loss: 1.072 | Accuracy: 0.602000 | 0.153 sec/iter\n",
      "Epoch: 148 | Batch: 010 / 011 | Total loss: 1.110 | Reg loss: 0.043 | Tree loss: 1.110 | Accuracy: 0.566553 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 149 | Batch: 000 / 011 | Total loss: 1.143 | Reg loss: 0.043 | Tree loss: 1.143 | Accuracy: 0.599000 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 001 / 011 | Total loss: 1.155 | Reg loss: 0.043 | Tree loss: 1.155 | Accuracy: 0.590000 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 002 / 011 | Total loss: 1.133 | Reg loss: 0.043 | Tree loss: 1.133 | Accuracy: 0.603000 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 003 / 011 | Total loss: 1.101 | Reg loss: 0.043 | Tree loss: 1.101 | Accuracy: 0.605500 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 004 / 011 | Total loss: 1.071 | Reg loss: 0.043 | Tree loss: 1.071 | Accuracy: 0.626500 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 005 / 011 | Total loss: 1.091 | Reg loss: 0.043 | Tree loss: 1.091 | Accuracy: 0.604500 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 006 / 011 | Total loss: 1.072 | Reg loss: 0.043 | Tree loss: 1.072 | Accuracy: 0.606000 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 007 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.591500 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 008 / 011 | Total loss: 1.044 | Reg loss: 0.043 | Tree loss: 1.044 | Accuracy: 0.625000 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 009 / 011 | Total loss: 1.040 | Reg loss: 0.043 | Tree loss: 1.040 | Accuracy: 0.624000 | 0.153 sec/iter\n",
      "Epoch: 149 | Batch: 010 / 011 | Total loss: 1.044 | Reg loss: 0.043 | Tree loss: 1.044 | Accuracy: 0.638225 | 0.153 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 150 | Batch: 000 / 011 | Total loss: 1.155 | Reg loss: 0.043 | Tree loss: 1.155 | Accuracy: 0.595000 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 001 / 011 | Total loss: 1.143 | Reg loss: 0.043 | Tree loss: 1.143 | Accuracy: 0.592500 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 002 / 011 | Total loss: 1.123 | Reg loss: 0.043 | Tree loss: 1.123 | Accuracy: 0.609000 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 003 / 011 | Total loss: 1.124 | Reg loss: 0.043 | Tree loss: 1.124 | Accuracy: 0.603500 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 004 / 011 | Total loss: 1.070 | Reg loss: 0.043 | Tree loss: 1.070 | Accuracy: 0.612500 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 005 / 011 | Total loss: 1.065 | Reg loss: 0.043 | Tree loss: 1.065 | Accuracy: 0.623000 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 006 / 011 | Total loss: 1.044 | Reg loss: 0.043 | Tree loss: 1.044 | Accuracy: 0.625500 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 007 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.613500 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 008 / 011 | Total loss: 1.058 | Reg loss: 0.043 | Tree loss: 1.058 | Accuracy: 0.607000 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 009 / 011 | Total loss: 1.056 | Reg loss: 0.043 | Tree loss: 1.056 | Accuracy: 0.625000 | 0.154 sec/iter\n",
      "Epoch: 150 | Batch: 010 / 011 | Total loss: 1.033 | Reg loss: 0.043 | Tree loss: 1.033 | Accuracy: 0.655290 | 0.154 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4: 0.9723756906077348\n",
      "Epoch: 151 | Batch: 000 / 011 | Total loss: 1.140 | Reg loss: 0.043 | Tree loss: 1.140 | Accuracy: 0.601500 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 001 / 011 | Total loss: 1.113 | Reg loss: 0.043 | Tree loss: 1.113 | Accuracy: 0.615500 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 002 / 011 | Total loss: 1.128 | Reg loss: 0.043 | Tree loss: 1.128 | Accuracy: 0.586000 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 003 / 011 | Total loss: 1.102 | Reg loss: 0.043 | Tree loss: 1.102 | Accuracy: 0.601000 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 004 / 011 | Total loss: 1.074 | Reg loss: 0.043 | Tree loss: 1.074 | Accuracy: 0.617500 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 005 / 011 | Total loss: 1.080 | Reg loss: 0.043 | Tree loss: 1.080 | Accuracy: 0.602500 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 006 / 011 | Total loss: 1.069 | Reg loss: 0.043 | Tree loss: 1.069 | Accuracy: 0.612000 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 007 / 011 | Total loss: 1.055 | Reg loss: 0.043 | Tree loss: 1.055 | Accuracy: 0.609500 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 008 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.605500 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 009 / 011 | Total loss: 1.075 | Reg loss: 0.043 | Tree loss: 1.075 | Accuracy: 0.607000 | 0.155 sec/iter\n",
      "Epoch: 151 | Batch: 010 / 011 | Total loss: 1.029 | Reg loss: 0.043 | Tree loss: 1.029 | Accuracy: 0.668942 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 152 | Batch: 000 / 011 | Total loss: 1.133 | Reg loss: 0.043 | Tree loss: 1.133 | Accuracy: 0.613500 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 001 / 011 | Total loss: 1.128 | Reg loss: 0.043 | Tree loss: 1.128 | Accuracy: 0.599000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 002 / 011 | Total loss: 1.124 | Reg loss: 0.043 | Tree loss: 1.124 | Accuracy: 0.614000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 003 / 011 | Total loss: 1.097 | Reg loss: 0.043 | Tree loss: 1.097 | Accuracy: 0.616500 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 004 / 011 | Total loss: 1.076 | Reg loss: 0.043 | Tree loss: 1.076 | Accuracy: 0.619000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 005 / 011 | Total loss: 1.073 | Reg loss: 0.043 | Tree loss: 1.073 | Accuracy: 0.620000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 006 / 011 | Total loss: 1.080 | Reg loss: 0.043 | Tree loss: 1.080 | Accuracy: 0.598000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 007 / 011 | Total loss: 1.061 | Reg loss: 0.043 | Tree loss: 1.061 | Accuracy: 0.619000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 008 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.612000 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 009 / 011 | Total loss: 1.048 | Reg loss: 0.043 | Tree loss: 1.048 | Accuracy: 0.605500 | 0.155 sec/iter\n",
      "Epoch: 152 | Batch: 010 / 011 | Total loss: 1.004 | Reg loss: 0.043 | Tree loss: 1.004 | Accuracy: 0.658703 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 153 | Batch: 000 / 011 | Total loss: 1.148 | Reg loss: 0.043 | Tree loss: 1.148 | Accuracy: 0.596000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 001 / 011 | Total loss: 1.132 | Reg loss: 0.043 | Tree loss: 1.132 | Accuracy: 0.601000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 002 / 011 | Total loss: 1.102 | Reg loss: 0.043 | Tree loss: 1.102 | Accuracy: 0.614500 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 003 / 011 | Total loss: 1.101 | Reg loss: 0.043 | Tree loss: 1.101 | Accuracy: 0.597000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 004 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.627000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 005 / 011 | Total loss: 1.088 | Reg loss: 0.043 | Tree loss: 1.088 | Accuracy: 0.598000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 006 / 011 | Total loss: 1.060 | Reg loss: 0.043 | Tree loss: 1.060 | Accuracy: 0.603000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 007 / 011 | Total loss: 1.094 | Reg loss: 0.043 | Tree loss: 1.094 | Accuracy: 0.587500 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 008 / 011 | Total loss: 1.057 | Reg loss: 0.043 | Tree loss: 1.057 | Accuracy: 0.616000 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 009 / 011 | Total loss: 1.059 | Reg loss: 0.043 | Tree loss: 1.059 | Accuracy: 0.620500 | 0.155 sec/iter\n",
      "Epoch: 153 | Batch: 010 / 011 | Total loss: 0.971 | Reg loss: 0.043 | Tree loss: 0.971 | Accuracy: 0.672355 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 154 | Batch: 000 / 011 | Total loss: 1.146 | Reg loss: 0.043 | Tree loss: 1.146 | Accuracy: 0.592500 | 0.155 sec/iter\n",
      "Epoch: 154 | Batch: 001 / 011 | Total loss: 1.140 | Reg loss: 0.043 | Tree loss: 1.140 | Accuracy: 0.590000 | 0.155 sec/iter\n",
      "Epoch: 154 | Batch: 002 / 011 | Total loss: 1.126 | Reg loss: 0.043 | Tree loss: 1.126 | Accuracy: 0.596500 | 0.155 sec/iter\n",
      "Epoch: 154 | Batch: 003 / 011 | Total loss: 1.109 | Reg loss: 0.043 | Tree loss: 1.109 | Accuracy: 0.578000 | 0.155 sec/iter\n",
      "Epoch: 154 | Batch: 004 / 011 | Total loss: 1.067 | Reg loss: 0.043 | Tree loss: 1.067 | Accuracy: 0.618000 | 0.155 sec/iter\n",
      "Epoch: 154 | Batch: 005 / 011 | Total loss: 1.075 | Reg loss: 0.043 | Tree loss: 1.075 | Accuracy: 0.609500 | 0.154 sec/iter\n",
      "Epoch: 154 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.043 | Tree loss: 1.046 | Accuracy: 0.635500 | 0.154 sec/iter\n",
      "Epoch: 154 | Batch: 007 / 011 | Total loss: 1.064 | Reg loss: 0.043 | Tree loss: 1.064 | Accuracy: 0.616500 | 0.154 sec/iter\n",
      "Epoch: 154 | Batch: 008 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.606000 | 0.154 sec/iter\n",
      "Epoch: 154 | Batch: 009 / 011 | Total loss: 1.061 | Reg loss: 0.043 | Tree loss: 1.061 | Accuracy: 0.619500 | 0.154 sec/iter\n",
      "Epoch: 154 | Batch: 010 / 011 | Total loss: 1.022 | Reg loss: 0.043 | Tree loss: 1.022 | Accuracy: 0.624573 | 0.154 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 155 | Batch: 000 / 011 | Total loss: 1.162 | Reg loss: 0.043 | Tree loss: 1.162 | Accuracy: 0.583000 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 001 / 011 | Total loss: 1.130 | Reg loss: 0.043 | Tree loss: 1.130 | Accuracy: 0.602000 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 002 / 011 | Total loss: 1.119 | Reg loss: 0.043 | Tree loss: 1.119 | Accuracy: 0.606000 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 003 / 011 | Total loss: 1.102 | Reg loss: 0.043 | Tree loss: 1.102 | Accuracy: 0.604500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 004 / 011 | Total loss: 1.086 | Reg loss: 0.043 | Tree loss: 1.086 | Accuracy: 0.610500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 005 / 011 | Total loss: 1.065 | Reg loss: 0.043 | Tree loss: 1.065 | Accuracy: 0.617500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 006 / 011 | Total loss: 1.045 | Reg loss: 0.043 | Tree loss: 1.045 | Accuracy: 0.634500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 007 / 011 | Total loss: 1.075 | Reg loss: 0.043 | Tree loss: 1.075 | Accuracy: 0.600500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 008 / 011 | Total loss: 1.042 | Reg loss: 0.043 | Tree loss: 1.042 | Accuracy: 0.639500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 009 / 011 | Total loss: 1.060 | Reg loss: 0.043 | Tree loss: 1.060 | Accuracy: 0.621500 | 0.155 sec/iter\n",
      "Epoch: 155 | Batch: 010 / 011 | Total loss: 1.043 | Reg loss: 0.043 | Tree loss: 1.043 | Accuracy: 0.617747 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 156 | Batch: 000 / 011 | Total loss: 1.126 | Reg loss: 0.043 | Tree loss: 1.126 | Accuracy: 0.605500 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 001 / 011 | Total loss: 1.133 | Reg loss: 0.043 | Tree loss: 1.133 | Accuracy: 0.598000 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 002 / 011 | Total loss: 1.121 | Reg loss: 0.043 | Tree loss: 1.121 | Accuracy: 0.591500 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 003 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.613000 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 004 / 011 | Total loss: 1.093 | Reg loss: 0.043 | Tree loss: 1.093 | Accuracy: 0.602000 | 0.155 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156 | Batch: 005 / 011 | Total loss: 1.067 | Reg loss: 0.043 | Tree loss: 1.067 | Accuracy: 0.619500 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 006 / 011 | Total loss: 1.077 | Reg loss: 0.043 | Tree loss: 1.077 | Accuracy: 0.608500 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 007 / 011 | Total loss: 1.072 | Reg loss: 0.043 | Tree loss: 1.072 | Accuracy: 0.612500 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 008 / 011 | Total loss: 1.040 | Reg loss: 0.043 | Tree loss: 1.040 | Accuracy: 0.639500 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 009 / 011 | Total loss: 1.049 | Reg loss: 0.043 | Tree loss: 1.049 | Accuracy: 0.634000 | 0.155 sec/iter\n",
      "Epoch: 156 | Batch: 010 / 011 | Total loss: 1.016 | Reg loss: 0.043 | Tree loss: 1.016 | Accuracy: 0.614334 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 157 | Batch: 000 / 011 | Total loss: 1.148 | Reg loss: 0.043 | Tree loss: 1.148 | Accuracy: 0.595000 | 0.156 sec/iter\n",
      "Epoch: 157 | Batch: 001 / 011 | Total loss: 1.134 | Reg loss: 0.043 | Tree loss: 1.134 | Accuracy: 0.593500 | 0.156 sec/iter\n",
      "Epoch: 157 | Batch: 002 / 011 | Total loss: 1.117 | Reg loss: 0.043 | Tree loss: 1.117 | Accuracy: 0.607000 | 0.156 sec/iter\n",
      "Epoch: 157 | Batch: 003 / 011 | Total loss: 1.098 | Reg loss: 0.043 | Tree loss: 1.098 | Accuracy: 0.599000 | 0.156 sec/iter\n",
      "Epoch: 157 | Batch: 004 / 011 | Total loss: 1.067 | Reg loss: 0.043 | Tree loss: 1.067 | Accuracy: 0.606000 | 0.155 sec/iter\n",
      "Epoch: 157 | Batch: 005 / 011 | Total loss: 1.055 | Reg loss: 0.043 | Tree loss: 1.055 | Accuracy: 0.605500 | 0.155 sec/iter\n",
      "Epoch: 157 | Batch: 006 / 011 | Total loss: 1.063 | Reg loss: 0.043 | Tree loss: 1.063 | Accuracy: 0.615000 | 0.155 sec/iter\n",
      "Epoch: 157 | Batch: 007 / 011 | Total loss: 1.055 | Reg loss: 0.043 | Tree loss: 1.055 | Accuracy: 0.624000 | 0.155 sec/iter\n",
      "Epoch: 157 | Batch: 008 / 011 | Total loss: 1.070 | Reg loss: 0.043 | Tree loss: 1.070 | Accuracy: 0.622500 | 0.155 sec/iter\n",
      "Epoch: 157 | Batch: 009 / 011 | Total loss: 1.041 | Reg loss: 0.043 | Tree loss: 1.041 | Accuracy: 0.623000 | 0.155 sec/iter\n",
      "Epoch: 157 | Batch: 010 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.590444 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 158 | Batch: 000 / 011 | Total loss: 1.155 | Reg loss: 0.043 | Tree loss: 1.155 | Accuracy: 0.593000 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 001 / 011 | Total loss: 1.121 | Reg loss: 0.043 | Tree loss: 1.121 | Accuracy: 0.606000 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 002 / 011 | Total loss: 1.116 | Reg loss: 0.043 | Tree loss: 1.116 | Accuracy: 0.613500 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 003 / 011 | Total loss: 1.109 | Reg loss: 0.043 | Tree loss: 1.109 | Accuracy: 0.615000 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 004 / 011 | Total loss: 1.095 | Reg loss: 0.043 | Tree loss: 1.095 | Accuracy: 0.617500 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 005 / 011 | Total loss: 1.066 | Reg loss: 0.043 | Tree loss: 1.066 | Accuracy: 0.627500 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 006 / 011 | Total loss: 1.054 | Reg loss: 0.043 | Tree loss: 1.054 | Accuracy: 0.620000 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 007 / 011 | Total loss: 1.054 | Reg loss: 0.043 | Tree loss: 1.054 | Accuracy: 0.614000 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 008 / 011 | Total loss: 1.035 | Reg loss: 0.043 | Tree loss: 1.035 | Accuracy: 0.630000 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 009 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.615500 | 0.156 sec/iter\n",
      "Epoch: 158 | Batch: 010 / 011 | Total loss: 1.035 | Reg loss: 0.044 | Tree loss: 1.035 | Accuracy: 0.607509 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 159 | Batch: 000 / 011 | Total loss: 1.142 | Reg loss: 0.043 | Tree loss: 1.142 | Accuracy: 0.602000 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 001 / 011 | Total loss: 1.132 | Reg loss: 0.043 | Tree loss: 1.132 | Accuracy: 0.607500 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 002 / 011 | Total loss: 1.110 | Reg loss: 0.043 | Tree loss: 1.110 | Accuracy: 0.608500 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 003 / 011 | Total loss: 1.079 | Reg loss: 0.043 | Tree loss: 1.079 | Accuracy: 0.623000 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 004 / 011 | Total loss: 1.083 | Reg loss: 0.043 | Tree loss: 1.083 | Accuracy: 0.597500 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 005 / 011 | Total loss: 1.067 | Reg loss: 0.043 | Tree loss: 1.067 | Accuracy: 0.593500 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 006 / 011 | Total loss: 1.064 | Reg loss: 0.043 | Tree loss: 1.064 | Accuracy: 0.613000 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 007 / 011 | Total loss: 1.057 | Reg loss: 0.043 | Tree loss: 1.057 | Accuracy: 0.618000 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 008 / 011 | Total loss: 1.067 | Reg loss: 0.044 | Tree loss: 1.067 | Accuracy: 0.612000 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 009 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.638000 | 0.156 sec/iter\n",
      "Epoch: 159 | Batch: 010 / 011 | Total loss: 1.005 | Reg loss: 0.044 | Tree loss: 1.005 | Accuracy: 0.648464 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 160 | Batch: 000 / 011 | Total loss: 1.138 | Reg loss: 0.043 | Tree loss: 1.138 | Accuracy: 0.606500 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 001 / 011 | Total loss: 1.116 | Reg loss: 0.043 | Tree loss: 1.116 | Accuracy: 0.609500 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 002 / 011 | Total loss: 1.111 | Reg loss: 0.043 | Tree loss: 1.111 | Accuracy: 0.619500 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 003 / 011 | Total loss: 1.101 | Reg loss: 0.043 | Tree loss: 1.101 | Accuracy: 0.592000 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 004 / 011 | Total loss: 1.082 | Reg loss: 0.043 | Tree loss: 1.082 | Accuracy: 0.609000 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 005 / 011 | Total loss: 1.057 | Reg loss: 0.043 | Tree loss: 1.057 | Accuracy: 0.620000 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 006 / 011 | Total loss: 1.070 | Reg loss: 0.044 | Tree loss: 1.070 | Accuracy: 0.614500 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 007 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.639500 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 008 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.616000 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 009 / 011 | Total loss: 1.073 | Reg loss: 0.044 | Tree loss: 1.073 | Accuracy: 0.617500 | 0.156 sec/iter\n",
      "Epoch: 160 | Batch: 010 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.641638 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 161 | Batch: 000 / 011 | Total loss: 1.126 | Reg loss: 0.043 | Tree loss: 1.126 | Accuracy: 0.610500 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 001 / 011 | Total loss: 1.120 | Reg loss: 0.043 | Tree loss: 1.120 | Accuracy: 0.601000 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 002 / 011 | Total loss: 1.113 | Reg loss: 0.043 | Tree loss: 1.113 | Accuracy: 0.597500 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 003 / 011 | Total loss: 1.085 | Reg loss: 0.043 | Tree loss: 1.085 | Accuracy: 0.620000 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 004 / 011 | Total loss: 1.098 | Reg loss: 0.043 | Tree loss: 1.098 | Accuracy: 0.601500 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 005 / 011 | Total loss: 1.074 | Reg loss: 0.044 | Tree loss: 1.074 | Accuracy: 0.602000 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 006 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.616000 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 007 / 011 | Total loss: 1.056 | Reg loss: 0.044 | Tree loss: 1.056 | Accuracy: 0.609500 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 008 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.615500 | 0.157 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161 | Batch: 009 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.616500 | 0.157 sec/iter\n",
      "Epoch: 161 | Batch: 010 / 011 | Total loss: 1.109 | Reg loss: 0.044 | Tree loss: 1.109 | Accuracy: 0.590444 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 162 | Batch: 000 / 011 | Total loss: 1.128 | Reg loss: 0.043 | Tree loss: 1.128 | Accuracy: 0.608500 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 001 / 011 | Total loss: 1.118 | Reg loss: 0.043 | Tree loss: 1.118 | Accuracy: 0.610500 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 002 / 011 | Total loss: 1.116 | Reg loss: 0.043 | Tree loss: 1.116 | Accuracy: 0.613000 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 003 / 011 | Total loss: 1.103 | Reg loss: 0.044 | Tree loss: 1.103 | Accuracy: 0.607500 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 004 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.610000 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 005 / 011 | Total loss: 1.071 | Reg loss: 0.044 | Tree loss: 1.071 | Accuracy: 0.613500 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 006 / 011 | Total loss: 1.067 | Reg loss: 0.044 | Tree loss: 1.067 | Accuracy: 0.603500 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 007 / 011 | Total loss: 1.038 | Reg loss: 0.044 | Tree loss: 1.038 | Accuracy: 0.630000 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 008 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.613000 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 009 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.627500 | 0.158 sec/iter\n",
      "Epoch: 162 | Batch: 010 / 011 | Total loss: 1.009 | Reg loss: 0.044 | Tree loss: 1.009 | Accuracy: 0.645051 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 163 | Batch: 000 / 011 | Total loss: 1.149 | Reg loss: 0.044 | Tree loss: 1.149 | Accuracy: 0.598500 | 0.159 sec/iter\n",
      "Epoch: 163 | Batch: 001 / 011 | Total loss: 1.102 | Reg loss: 0.044 | Tree loss: 1.102 | Accuracy: 0.621000 | 0.159 sec/iter\n",
      "Epoch: 163 | Batch: 002 / 011 | Total loss: 1.108 | Reg loss: 0.044 | Tree loss: 1.108 | Accuracy: 0.603000 | 0.159 sec/iter\n",
      "Epoch: 163 | Batch: 003 / 011 | Total loss: 1.104 | Reg loss: 0.044 | Tree loss: 1.104 | Accuracy: 0.597500 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 004 / 011 | Total loss: 1.082 | Reg loss: 0.044 | Tree loss: 1.082 | Accuracy: 0.600500 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 005 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.632500 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 006 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.622500 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 007 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 008 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 009 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.627000 | 0.158 sec/iter\n",
      "Epoch: 163 | Batch: 010 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.593857 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 164 | Batch: 000 / 011 | Total loss: 1.133 | Reg loss: 0.044 | Tree loss: 1.133 | Accuracy: 0.603000 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 001 / 011 | Total loss: 1.116 | Reg loss: 0.044 | Tree loss: 1.116 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 002 / 011 | Total loss: 1.115 | Reg loss: 0.044 | Tree loss: 1.115 | Accuracy: 0.595000 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 003 / 011 | Total loss: 1.108 | Reg loss: 0.044 | Tree loss: 1.108 | Accuracy: 0.596000 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 004 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.622500 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 005 / 011 | Total loss: 1.069 | Reg loss: 0.044 | Tree loss: 1.069 | Accuracy: 0.596000 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 006 / 011 | Total loss: 1.053 | Reg loss: 0.044 | Tree loss: 1.053 | Accuracy: 0.620500 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 007 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.621500 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 008 / 011 | Total loss: 1.055 | Reg loss: 0.044 | Tree loss: 1.055 | Accuracy: 0.627500 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 009 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.640000 | 0.158 sec/iter\n",
      "Epoch: 164 | Batch: 010 / 011 | Total loss: 1.068 | Reg loss: 0.044 | Tree loss: 1.068 | Accuracy: 0.614334 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 165 | Batch: 000 / 011 | Total loss: 1.140 | Reg loss: 0.044 | Tree loss: 1.140 | Accuracy: 0.598500 | 0.159 sec/iter\n",
      "Epoch: 165 | Batch: 001 / 011 | Total loss: 1.113 | Reg loss: 0.044 | Tree loss: 1.113 | Accuracy: 0.630500 | 0.159 sec/iter\n",
      "Epoch: 165 | Batch: 002 / 011 | Total loss: 1.100 | Reg loss: 0.044 | Tree loss: 1.100 | Accuracy: 0.611500 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 003 / 011 | Total loss: 1.079 | Reg loss: 0.044 | Tree loss: 1.079 | Accuracy: 0.606000 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 004 / 011 | Total loss: 1.078 | Reg loss: 0.044 | Tree loss: 1.078 | Accuracy: 0.602500 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 005 / 011 | Total loss: 1.056 | Reg loss: 0.044 | Tree loss: 1.056 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 006 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.610000 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 007 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 008 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 009 / 011 | Total loss: 1.065 | Reg loss: 0.044 | Tree loss: 1.065 | Accuracy: 0.614000 | 0.158 sec/iter\n",
      "Epoch: 165 | Batch: 010 / 011 | Total loss: 1.053 | Reg loss: 0.044 | Tree loss: 1.053 | Accuracy: 0.627986 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 166 | Batch: 000 / 011 | Total loss: 1.146 | Reg loss: 0.044 | Tree loss: 1.146 | Accuracy: 0.595000 | 0.159 sec/iter\n",
      "Epoch: 166 | Batch: 001 / 011 | Total loss: 1.110 | Reg loss: 0.044 | Tree loss: 1.110 | Accuracy: 0.621500 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 002 / 011 | Total loss: 1.099 | Reg loss: 0.044 | Tree loss: 1.099 | Accuracy: 0.623000 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 003 / 011 | Total loss: 1.085 | Reg loss: 0.044 | Tree loss: 1.085 | Accuracy: 0.598500 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 004 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.602500 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 005 / 011 | Total loss: 1.056 | Reg loss: 0.044 | Tree loss: 1.056 | Accuracy: 0.608000 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 006 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.609500 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 007 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.615500 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 008 / 011 | Total loss: 1.055 | Reg loss: 0.044 | Tree loss: 1.055 | Accuracy: 0.614000 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 009 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.606000 | 0.158 sec/iter\n",
      "Epoch: 166 | Batch: 010 / 011 | Total loss: 1.074 | Reg loss: 0.044 | Tree loss: 1.074 | Accuracy: 0.600683 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167 | Batch: 000 / 011 | Total loss: 1.143 | Reg loss: 0.044 | Tree loss: 1.143 | Accuracy: 0.599000 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 001 / 011 | Total loss: 1.112 | Reg loss: 0.044 | Tree loss: 1.112 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 002 / 011 | Total loss: 1.108 | Reg loss: 0.044 | Tree loss: 1.108 | Accuracy: 0.612500 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 003 / 011 | Total loss: 1.085 | Reg loss: 0.044 | Tree loss: 1.085 | Accuracy: 0.618000 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 004 / 011 | Total loss: 1.066 | Reg loss: 0.044 | Tree loss: 1.066 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 005 / 011 | Total loss: 1.064 | Reg loss: 0.044 | Tree loss: 1.064 | Accuracy: 0.589500 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 006 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.613500 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.044 | Tree loss: 1.028 | Accuracy: 0.630000 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 008 / 011 | Total loss: 1.062 | Reg loss: 0.044 | Tree loss: 1.062 | Accuracy: 0.611000 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 009 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 167 | Batch: 010 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.604096 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 168 | Batch: 000 / 011 | Total loss: 1.128 | Reg loss: 0.044 | Tree loss: 1.128 | Accuracy: 0.625000 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 001 / 011 | Total loss: 1.098 | Reg loss: 0.044 | Tree loss: 1.098 | Accuracy: 0.619500 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 002 / 011 | Total loss: 1.096 | Reg loss: 0.044 | Tree loss: 1.096 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 003 / 011 | Total loss: 1.076 | Reg loss: 0.044 | Tree loss: 1.076 | Accuracy: 0.612500 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 004 / 011 | Total loss: 1.076 | Reg loss: 0.044 | Tree loss: 1.076 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 005 / 011 | Total loss: 1.064 | Reg loss: 0.044 | Tree loss: 1.064 | Accuracy: 0.612000 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 006 / 011 | Total loss: 1.074 | Reg loss: 0.044 | Tree loss: 1.074 | Accuracy: 0.597500 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 007 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.615500 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 008 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.622500 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 009 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.628000 | 0.158 sec/iter\n",
      "Epoch: 168 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.614334 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 169 | Batch: 000 / 011 | Total loss: 1.130 | Reg loss: 0.044 | Tree loss: 1.130 | Accuracy: 0.612500 | 0.158 sec/iter\n",
      "Epoch: 169 | Batch: 001 / 011 | Total loss: 1.111 | Reg loss: 0.044 | Tree loss: 1.111 | Accuracy: 0.613500 | 0.158 sec/iter\n",
      "Epoch: 169 | Batch: 002 / 011 | Total loss: 1.103 | Reg loss: 0.044 | Tree loss: 1.103 | Accuracy: 0.616500 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 003 / 011 | Total loss: 1.078 | Reg loss: 0.044 | Tree loss: 1.078 | Accuracy: 0.605500 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 004 / 011 | Total loss: 1.068 | Reg loss: 0.044 | Tree loss: 1.068 | Accuracy: 0.617500 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 005 / 011 | Total loss: 1.067 | Reg loss: 0.044 | Tree loss: 1.067 | Accuracy: 0.617500 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.626000 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 007 / 011 | Total loss: 1.062 | Reg loss: 0.044 | Tree loss: 1.062 | Accuracy: 0.626500 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 008 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.627000 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 009 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.631000 | 0.157 sec/iter\n",
      "Epoch: 169 | Batch: 010 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.641638 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 170 | Batch: 000 / 011 | Total loss: 1.155 | Reg loss: 0.044 | Tree loss: 1.155 | Accuracy: 0.596000 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 001 / 011 | Total loss: 1.114 | Reg loss: 0.044 | Tree loss: 1.114 | Accuracy: 0.615500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 002 / 011 | Total loss: 1.112 | Reg loss: 0.044 | Tree loss: 1.112 | Accuracy: 0.597500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 003 / 011 | Total loss: 1.064 | Reg loss: 0.044 | Tree loss: 1.064 | Accuracy: 0.628500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 004 / 011 | Total loss: 1.085 | Reg loss: 0.044 | Tree loss: 1.085 | Accuracy: 0.599500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.619500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 006 / 011 | Total loss: 1.039 | Reg loss: 0.044 | Tree loss: 1.039 | Accuracy: 0.645500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 007 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 008 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.623000 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 009 / 011 | Total loss: 1.038 | Reg loss: 0.044 | Tree loss: 1.038 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 170 | Batch: 010 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.614334 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 171 | Batch: 000 / 011 | Total loss: 1.145 | Reg loss: 0.044 | Tree loss: 1.145 | Accuracy: 0.593000 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 001 / 011 | Total loss: 1.109 | Reg loss: 0.044 | Tree loss: 1.109 | Accuracy: 0.605500 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 002 / 011 | Total loss: 1.100 | Reg loss: 0.044 | Tree loss: 1.100 | Accuracy: 0.613000 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 003 / 011 | Total loss: 1.091 | Reg loss: 0.044 | Tree loss: 1.091 | Accuracy: 0.609000 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 004 / 011 | Total loss: 1.073 | Reg loss: 0.044 | Tree loss: 1.073 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 005 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.623000 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 006 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.612500 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 007 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.624500 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 008 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.651500 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 009 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.641000 | 0.157 sec/iter\n",
      "Epoch: 171 | Batch: 010 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.604096 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 172 | Batch: 000 / 011 | Total loss: 1.128 | Reg loss: 0.044 | Tree loss: 1.128 | Accuracy: 0.609000 | 0.158 sec/iter\n",
      "Epoch: 172 | Batch: 001 / 011 | Total loss: 1.119 | Reg loss: 0.044 | Tree loss: 1.119 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 172 | Batch: 002 / 011 | Total loss: 1.103 | Reg loss: 0.044 | Tree loss: 1.103 | Accuracy: 0.619000 | 0.158 sec/iter\n",
      "Epoch: 172 | Batch: 003 / 011 | Total loss: 1.089 | Reg loss: 0.044 | Tree loss: 1.089 | Accuracy: 0.614000 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172 | Batch: 004 / 011 | Total loss: 1.073 | Reg loss: 0.044 | Tree loss: 1.073 | Accuracy: 0.615000 | 0.158 sec/iter\n",
      "Epoch: 172 | Batch: 005 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.624500 | 0.158 sec/iter\n",
      "Epoch: 172 | Batch: 006 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.626000 | 0.158 sec/iter\n",
      "Epoch: 172 | Batch: 007 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 172 | Batch: 008 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.624500 | 0.157 sec/iter\n",
      "Epoch: 172 | Batch: 009 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.619500 | 0.157 sec/iter\n",
      "Epoch: 172 | Batch: 010 / 011 | Total loss: 1.019 | Reg loss: 0.044 | Tree loss: 1.019 | Accuracy: 0.648464 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 173 | Batch: 000 / 011 | Total loss: 1.127 | Reg loss: 0.044 | Tree loss: 1.127 | Accuracy: 0.621500 | 0.158 sec/iter\n",
      "Epoch: 173 | Batch: 001 / 011 | Total loss: 1.118 | Reg loss: 0.044 | Tree loss: 1.118 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 173 | Batch: 002 / 011 | Total loss: 1.090 | Reg loss: 0.044 | Tree loss: 1.090 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 173 | Batch: 003 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.616000 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 004 / 011 | Total loss: 1.077 | Reg loss: 0.044 | Tree loss: 1.077 | Accuracy: 0.600500 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 005 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.634000 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 006 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.592500 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 007 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.623500 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 008 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.619000 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 009 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.619500 | 0.157 sec/iter\n",
      "Epoch: 173 | Batch: 010 / 011 | Total loss: 0.996 | Reg loss: 0.044 | Tree loss: 0.996 | Accuracy: 0.624573 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 174 | Batch: 000 / 011 | Total loss: 1.128 | Reg loss: 0.044 | Tree loss: 1.128 | Accuracy: 0.598000 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 001 / 011 | Total loss: 1.114 | Reg loss: 0.044 | Tree loss: 1.114 | Accuracy: 0.613500 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 002 / 011 | Total loss: 1.105 | Reg loss: 0.044 | Tree loss: 1.105 | Accuracy: 0.620500 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 003 / 011 | Total loss: 1.075 | Reg loss: 0.044 | Tree loss: 1.075 | Accuracy: 0.617000 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 004 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.631000 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 005 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.615500 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 006 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 007 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.629000 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 008 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.645000 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 009 / 011 | Total loss: 1.033 | Reg loss: 0.044 | Tree loss: 1.033 | Accuracy: 0.634000 | 0.157 sec/iter\n",
      "Epoch: 174 | Batch: 010 / 011 | Total loss: 1.076 | Reg loss: 0.044 | Tree loss: 1.076 | Accuracy: 0.604096 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 175 | Batch: 000 / 011 | Total loss: 1.134 | Reg loss: 0.044 | Tree loss: 1.134 | Accuracy: 0.610500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 001 / 011 | Total loss: 1.105 | Reg loss: 0.044 | Tree loss: 1.105 | Accuracy: 0.634000 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 002 / 011 | Total loss: 1.094 | Reg loss: 0.044 | Tree loss: 1.094 | Accuracy: 0.626000 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 003 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.604500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 004 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.621500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 005 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 006 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.613500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 007 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.622000 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 008 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 009 / 011 | Total loss: 1.039 | Reg loss: 0.044 | Tree loss: 1.039 | Accuracy: 0.636500 | 0.157 sec/iter\n",
      "Epoch: 175 | Batch: 010 / 011 | Total loss: 1.064 | Reg loss: 0.044 | Tree loss: 1.064 | Accuracy: 0.597270 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 176 | Batch: 000 / 011 | Total loss: 1.146 | Reg loss: 0.044 | Tree loss: 1.146 | Accuracy: 0.597500 | 0.158 sec/iter\n",
      "Epoch: 176 | Batch: 001 / 011 | Total loss: 1.099 | Reg loss: 0.044 | Tree loss: 1.099 | Accuracy: 0.619000 | 0.158 sec/iter\n",
      "Epoch: 176 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.617000 | 0.158 sec/iter\n",
      "Epoch: 176 | Batch: 003 / 011 | Total loss: 1.075 | Reg loss: 0.044 | Tree loss: 1.075 | Accuracy: 0.610000 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 004 / 011 | Total loss: 1.079 | Reg loss: 0.044 | Tree loss: 1.079 | Accuracy: 0.605000 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 005 / 011 | Total loss: 1.049 | Reg loss: 0.044 | Tree loss: 1.049 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 006 / 011 | Total loss: 1.055 | Reg loss: 0.044 | Tree loss: 1.055 | Accuracy: 0.608000 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 007 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.650000 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 008 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.657500 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 009 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.629000 | 0.157 sec/iter\n",
      "Epoch: 176 | Batch: 010 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.590444 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 177 | Batch: 000 / 011 | Total loss: 1.151 | Reg loss: 0.044 | Tree loss: 1.151 | Accuracy: 0.597000 | 0.158 sec/iter\n",
      "Epoch: 177 | Batch: 001 / 011 | Total loss: 1.117 | Reg loss: 0.044 | Tree loss: 1.117 | Accuracy: 0.610500 | 0.158 sec/iter\n",
      "Epoch: 177 | Batch: 002 / 011 | Total loss: 1.086 | Reg loss: 0.044 | Tree loss: 1.086 | Accuracy: 0.617500 | 0.158 sec/iter\n",
      "Epoch: 177 | Batch: 003 / 011 | Total loss: 1.081 | Reg loss: 0.044 | Tree loss: 1.081 | Accuracy: 0.602500 | 0.158 sec/iter\n",
      "Epoch: 177 | Batch: 004 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.616000 | 0.158 sec/iter\n",
      "Epoch: 177 | Batch: 005 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 177 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.632500 | 0.157 sec/iter\n",
      "Epoch: 177 | Batch: 007 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.644500 | 0.157 sec/iter\n",
      "Epoch: 177 | Batch: 008 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.637000 | 0.157 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 177 | Batch: 009 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.638500 | 0.157 sec/iter\n",
      "Epoch: 177 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.607509 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 178 | Batch: 000 / 011 | Total loss: 1.124 | Reg loss: 0.044 | Tree loss: 1.124 | Accuracy: 0.602000 | 0.158 sec/iter\n",
      "Epoch: 178 | Batch: 001 / 011 | Total loss: 1.117 | Reg loss: 0.044 | Tree loss: 1.117 | Accuracy: 0.627500 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 002 / 011 | Total loss: 1.103 | Reg loss: 0.044 | Tree loss: 1.103 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 003 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.639000 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.044 | Tree loss: 1.039 | Accuracy: 0.640000 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 005 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 006 / 011 | Total loss: 1.066 | Reg loss: 0.044 | Tree loss: 1.066 | Accuracy: 0.606500 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.044 | Tree loss: 1.033 | Accuracy: 0.632000 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 008 / 011 | Total loss: 1.055 | Reg loss: 0.044 | Tree loss: 1.055 | Accuracy: 0.626500 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 009 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.641500 | 0.157 sec/iter\n",
      "Epoch: 178 | Batch: 010 / 011 | Total loss: 1.017 | Reg loss: 0.044 | Tree loss: 1.017 | Accuracy: 0.624573 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 179 | Batch: 000 / 011 | Total loss: 1.115 | Reg loss: 0.044 | Tree loss: 1.115 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 001 / 011 | Total loss: 1.106 | Reg loss: 0.044 | Tree loss: 1.106 | Accuracy: 0.607000 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 002 / 011 | Total loss: 1.099 | Reg loss: 0.044 | Tree loss: 1.099 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 003 / 011 | Total loss: 1.087 | Reg loss: 0.044 | Tree loss: 1.087 | Accuracy: 0.606500 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 004 / 011 | Total loss: 1.068 | Reg loss: 0.044 | Tree loss: 1.068 | Accuracy: 0.616000 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.044 | Tree loss: 1.030 | Accuracy: 0.632500 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.044 | Tree loss: 1.021 | Accuracy: 0.649500 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 007 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.626000 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 008 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.635000 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 009 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.604500 | 0.157 sec/iter\n",
      "Epoch: 179 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.634812 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 180 | Batch: 000 / 011 | Total loss: 1.134 | Reg loss: 0.044 | Tree loss: 1.134 | Accuracy: 0.609500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 001 / 011 | Total loss: 1.114 | Reg loss: 0.044 | Tree loss: 1.114 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 002 / 011 | Total loss: 1.093 | Reg loss: 0.044 | Tree loss: 1.093 | Accuracy: 0.620500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 003 / 011 | Total loss: 1.090 | Reg loss: 0.044 | Tree loss: 1.090 | Accuracy: 0.610500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 004 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.635000 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 005 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 006 / 011 | Total loss: 1.055 | Reg loss: 0.044 | Tree loss: 1.055 | Accuracy: 0.611000 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 007 / 011 | Total loss: 1.035 | Reg loss: 0.044 | Tree loss: 1.035 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 008 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.044 | Tree loss: 1.018 | Accuracy: 0.645500 | 0.157 sec/iter\n",
      "Epoch: 180 | Batch: 010 / 011 | Total loss: 0.982 | Reg loss: 0.044 | Tree loss: 0.982 | Accuracy: 0.668942 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 181 | Batch: 000 / 011 | Total loss: 1.097 | Reg loss: 0.044 | Tree loss: 1.097 | Accuracy: 0.640500 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 001 / 011 | Total loss: 1.118 | Reg loss: 0.044 | Tree loss: 1.118 | Accuracy: 0.601000 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 003 / 011 | Total loss: 1.081 | Reg loss: 0.044 | Tree loss: 1.081 | Accuracy: 0.609500 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 004 / 011 | Total loss: 1.056 | Reg loss: 0.044 | Tree loss: 1.056 | Accuracy: 0.625000 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 005 / 011 | Total loss: 1.074 | Reg loss: 0.044 | Tree loss: 1.074 | Accuracy: 0.597000 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 006 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.627500 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 007 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.627000 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 008 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.631000 | 0.157 sec/iter\n",
      "Epoch: 181 | Batch: 009 / 011 | Total loss: 1.035 | Reg loss: 0.044 | Tree loss: 1.035 | Accuracy: 0.645500 | 0.156 sec/iter\n",
      "Epoch: 181 | Batch: 010 / 011 | Total loss: 1.098 | Reg loss: 0.044 | Tree loss: 1.098 | Accuracy: 0.573379 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 182 | Batch: 000 / 011 | Total loss: 1.111 | Reg loss: 0.044 | Tree loss: 1.111 | Accuracy: 0.618000 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 001 / 011 | Total loss: 1.098 | Reg loss: 0.044 | Tree loss: 1.098 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 002 / 011 | Total loss: 1.103 | Reg loss: 0.044 | Tree loss: 1.103 | Accuracy: 0.617500 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 003 / 011 | Total loss: 1.065 | Reg loss: 0.044 | Tree loss: 1.065 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 004 / 011 | Total loss: 1.062 | Reg loss: 0.044 | Tree loss: 1.062 | Accuracy: 0.614000 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 005 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 006 / 011 | Total loss: 1.066 | Reg loss: 0.044 | Tree loss: 1.066 | Accuracy: 0.588500 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 007 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.611000 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 008 / 011 | Total loss: 1.053 | Reg loss: 0.044 | Tree loss: 1.053 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 182 | Batch: 009 / 011 | Total loss: 1.031 | Reg loss: 0.044 | Tree loss: 1.031 | Accuracy: 0.648000 | 0.156 sec/iter\n",
      "Epoch: 182 | Batch: 010 / 011 | Total loss: 1.073 | Reg loss: 0.044 | Tree loss: 1.073 | Accuracy: 0.607509 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 183 | Batch: 000 / 011 | Total loss: 1.137 | Reg loss: 0.044 | Tree loss: 1.137 | Accuracy: 0.599500 | 0.157 sec/iter\n",
      "Epoch: 183 | Batch: 001 / 011 | Total loss: 1.099 | Reg loss: 0.044 | Tree loss: 1.099 | Accuracy: 0.632500 | 0.157 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 183 | Batch: 002 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.625500 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 003 / 011 | Total loss: 1.065 | Reg loss: 0.044 | Tree loss: 1.065 | Accuracy: 0.612000 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 004 / 011 | Total loss: 1.089 | Reg loss: 0.044 | Tree loss: 1.089 | Accuracy: 0.599500 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 005 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.620000 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 006 / 011 | Total loss: 1.038 | Reg loss: 0.044 | Tree loss: 1.038 | Accuracy: 0.622500 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 007 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.612500 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 008 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.631500 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 009 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.634500 | 0.156 sec/iter\n",
      "Epoch: 183 | Batch: 010 / 011 | Total loss: 1.002 | Reg loss: 0.044 | Tree loss: 1.002 | Accuracy: 0.641638 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 184 | Batch: 000 / 011 | Total loss: 1.108 | Reg loss: 0.044 | Tree loss: 1.108 | Accuracy: 0.621500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 001 / 011 | Total loss: 1.105 | Reg loss: 0.044 | Tree loss: 1.105 | Accuracy: 0.617500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 002 / 011 | Total loss: 1.091 | Reg loss: 0.044 | Tree loss: 1.091 | Accuracy: 0.615500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 003 / 011 | Total loss: 1.083 | Reg loss: 0.044 | Tree loss: 1.083 | Accuracy: 0.618500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 004 / 011 | Total loss: 1.083 | Reg loss: 0.044 | Tree loss: 1.083 | Accuracy: 0.612000 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 005 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 006 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.607500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.632500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.044 | Tree loss: 1.019 | Accuracy: 0.646000 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.643500 | 0.156 sec/iter\n",
      "Epoch: 184 | Batch: 010 / 011 | Total loss: 1.008 | Reg loss: 0.044 | Tree loss: 1.008 | Accuracy: 0.655290 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 185 | Batch: 000 / 011 | Total loss: 1.113 | Reg loss: 0.044 | Tree loss: 1.113 | Accuracy: 0.602000 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 001 / 011 | Total loss: 1.109 | Reg loss: 0.044 | Tree loss: 1.109 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 002 / 011 | Total loss: 1.083 | Reg loss: 0.044 | Tree loss: 1.083 | Accuracy: 0.642500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 003 / 011 | Total loss: 1.083 | Reg loss: 0.044 | Tree loss: 1.083 | Accuracy: 0.595500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 004 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.615500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 005 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.621500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 006 / 011 | Total loss: 1.049 | Reg loss: 0.044 | Tree loss: 1.049 | Accuracy: 0.632000 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 007 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.635500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 008 / 011 | Total loss: 1.039 | Reg loss: 0.044 | Tree loss: 1.039 | Accuracy: 0.639000 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.634500 | 0.156 sec/iter\n",
      "Epoch: 185 | Batch: 010 / 011 | Total loss: 1.029 | Reg loss: 0.044 | Tree loss: 1.029 | Accuracy: 0.651877 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 186 | Batch: 000 / 011 | Total loss: 1.120 | Reg loss: 0.044 | Tree loss: 1.120 | Accuracy: 0.602500 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 001 / 011 | Total loss: 1.134 | Reg loss: 0.044 | Tree loss: 1.134 | Accuracy: 0.603500 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 002 / 011 | Total loss: 1.094 | Reg loss: 0.044 | Tree loss: 1.094 | Accuracy: 0.620000 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 003 / 011 | Total loss: 1.066 | Reg loss: 0.044 | Tree loss: 1.066 | Accuracy: 0.638500 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 004 / 011 | Total loss: 1.062 | Reg loss: 0.044 | Tree loss: 1.062 | Accuracy: 0.615000 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 005 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.619500 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 006 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.635000 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 007 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.616000 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.044 | Tree loss: 1.021 | Accuracy: 0.653000 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 009 / 011 | Total loss: 1.020 | Reg loss: 0.044 | Tree loss: 1.020 | Accuracy: 0.643000 | 0.156 sec/iter\n",
      "Epoch: 186 | Batch: 010 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.614334 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 187 | Batch: 000 / 011 | Total loss: 1.118 | Reg loss: 0.044 | Tree loss: 1.118 | Accuracy: 0.602000 | 0.157 sec/iter\n",
      "Epoch: 187 | Batch: 001 / 011 | Total loss: 1.109 | Reg loss: 0.044 | Tree loss: 1.109 | Accuracy: 0.614500 | 0.157 sec/iter\n",
      "Epoch: 187 | Batch: 002 / 011 | Total loss: 1.095 | Reg loss: 0.044 | Tree loss: 1.095 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 187 | Batch: 003 / 011 | Total loss: 1.081 | Reg loss: 0.044 | Tree loss: 1.081 | Accuracy: 0.597500 | 0.157 sec/iter\n",
      "Epoch: 187 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.625000 | 0.156 sec/iter\n",
      "Epoch: 187 | Batch: 005 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.603000 | 0.156 sec/iter\n",
      "Epoch: 187 | Batch: 006 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.592500 | 0.156 sec/iter\n",
      "Epoch: 187 | Batch: 007 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.625500 | 0.156 sec/iter\n",
      "Epoch: 187 | Batch: 008 / 011 | Total loss: 1.033 | Reg loss: 0.044 | Tree loss: 1.033 | Accuracy: 0.643000 | 0.156 sec/iter\n",
      "Epoch: 187 | Batch: 009 / 011 | Total loss: 1.025 | Reg loss: 0.044 | Tree loss: 1.025 | Accuracy: 0.656000 | 0.156 sec/iter\n",
      "Epoch: 187 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.044 | Tree loss: 0.981 | Accuracy: 0.675768 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 188 | Batch: 000 / 011 | Total loss: 1.123 | Reg loss: 0.044 | Tree loss: 1.123 | Accuracy: 0.600000 | 0.157 sec/iter\n",
      "Epoch: 188 | Batch: 001 / 011 | Total loss: 1.108 | Reg loss: 0.044 | Tree loss: 1.108 | Accuracy: 0.615000 | 0.157 sec/iter\n",
      "Epoch: 188 | Batch: 002 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.610000 | 0.157 sec/iter\n",
      "Epoch: 188 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.629000 | 0.157 sec/iter\n",
      "Epoch: 188 | Batch: 004 / 011 | Total loss: 1.071 | Reg loss: 0.044 | Tree loss: 1.071 | Accuracy: 0.615000 | 0.156 sec/iter\n",
      "Epoch: 188 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.634500 | 0.156 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 188 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.044 | Tree loss: 1.025 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 188 | Batch: 007 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.623000 | 0.156 sec/iter\n",
      "Epoch: 188 | Batch: 008 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.621000 | 0.156 sec/iter\n",
      "Epoch: 188 | Batch: 009 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 188 | Batch: 010 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.576792 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 189 | Batch: 000 / 011 | Total loss: 1.124 | Reg loss: 0.044 | Tree loss: 1.124 | Accuracy: 0.606500 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 001 / 011 | Total loss: 1.091 | Reg loss: 0.044 | Tree loss: 1.091 | Accuracy: 0.634000 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.044 | Tree loss: 1.066 | Accuracy: 0.635000 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 003 / 011 | Total loss: 1.077 | Reg loss: 0.044 | Tree loss: 1.077 | Accuracy: 0.607000 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 004 / 011 | Total loss: 1.062 | Reg loss: 0.044 | Tree loss: 1.062 | Accuracy: 0.609500 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 005 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.614000 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 006 / 011 | Total loss: 1.056 | Reg loss: 0.044 | Tree loss: 1.056 | Accuracy: 0.616500 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 007 / 011 | Total loss: 1.029 | Reg loss: 0.044 | Tree loss: 1.029 | Accuracy: 0.628500 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 008 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.628000 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.639000 | 0.156 sec/iter\n",
      "Epoch: 189 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.668942 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 190 | Batch: 000 / 011 | Total loss: 1.119 | Reg loss: 0.044 | Tree loss: 1.119 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 190 | Batch: 001 / 011 | Total loss: 1.104 | Reg loss: 0.044 | Tree loss: 1.104 | Accuracy: 0.614000 | 0.157 sec/iter\n",
      "Epoch: 190 | Batch: 002 / 011 | Total loss: 1.073 | Reg loss: 0.044 | Tree loss: 1.073 | Accuracy: 0.639000 | 0.157 sec/iter\n",
      "Epoch: 190 | Batch: 003 / 011 | Total loss: 1.068 | Reg loss: 0.044 | Tree loss: 1.068 | Accuracy: 0.617000 | 0.157 sec/iter\n",
      "Epoch: 190 | Batch: 004 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.618500 | 0.156 sec/iter\n",
      "Epoch: 190 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.044 | Tree loss: 1.035 | Accuracy: 0.623000 | 0.156 sec/iter\n",
      "Epoch: 190 | Batch: 006 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.613000 | 0.156 sec/iter\n",
      "Epoch: 190 | Batch: 007 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.622000 | 0.156 sec/iter\n",
      "Epoch: 190 | Batch: 008 / 011 | Total loss: 1.039 | Reg loss: 0.044 | Tree loss: 1.039 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 190 | Batch: 009 / 011 | Total loss: 1.047 | Reg loss: 0.044 | Tree loss: 1.047 | Accuracy: 0.628500 | 0.156 sec/iter\n",
      "Epoch: 190 | Batch: 010 / 011 | Total loss: 1.091 | Reg loss: 0.044 | Tree loss: 1.091 | Accuracy: 0.576792 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 191 | Batch: 000 / 011 | Total loss: 1.128 | Reg loss: 0.044 | Tree loss: 1.128 | Accuracy: 0.606000 | 0.157 sec/iter\n",
      "Epoch: 191 | Batch: 001 / 011 | Total loss: 1.090 | Reg loss: 0.044 | Tree loss: 1.090 | Accuracy: 0.628500 | 0.157 sec/iter\n",
      "Epoch: 191 | Batch: 002 / 011 | Total loss: 1.094 | Reg loss: 0.044 | Tree loss: 1.094 | Accuracy: 0.603000 | 0.157 sec/iter\n",
      "Epoch: 191 | Batch: 003 / 011 | Total loss: 1.068 | Reg loss: 0.044 | Tree loss: 1.068 | Accuracy: 0.623000 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 004 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.629000 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 005 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.639000 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 006 / 011 | Total loss: 1.055 | Reg loss: 0.044 | Tree loss: 1.055 | Accuracy: 0.601000 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 007 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.634000 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 008 / 011 | Total loss: 1.030 | Reg loss: 0.044 | Tree loss: 1.030 | Accuracy: 0.641000 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 009 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.639500 | 0.156 sec/iter\n",
      "Epoch: 191 | Batch: 010 / 011 | Total loss: 0.988 | Reg loss: 0.044 | Tree loss: 0.988 | Accuracy: 0.655290 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 192 | Batch: 000 / 011 | Total loss: 1.116 | Reg loss: 0.044 | Tree loss: 1.116 | Accuracy: 0.609000 | 0.157 sec/iter\n",
      "Epoch: 192 | Batch: 001 / 011 | Total loss: 1.092 | Reg loss: 0.044 | Tree loss: 1.092 | Accuracy: 0.624000 | 0.157 sec/iter\n",
      "Epoch: 192 | Batch: 002 / 011 | Total loss: 1.092 | Reg loss: 0.044 | Tree loss: 1.092 | Accuracy: 0.617000 | 0.157 sec/iter\n",
      "Epoch: 192 | Batch: 003 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 004 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.616000 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 005 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.613000 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 006 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.630500 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.044 | Tree loss: 1.030 | Accuracy: 0.627000 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 008 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.636000 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 009 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.621500 | 0.156 sec/iter\n",
      "Epoch: 192 | Batch: 010 / 011 | Total loss: 0.966 | Reg loss: 0.044 | Tree loss: 0.966 | Accuracy: 0.689420 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 193 | Batch: 000 / 011 | Total loss: 1.106 | Reg loss: 0.044 | Tree loss: 1.106 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 001 / 011 | Total loss: 1.123 | Reg loss: 0.044 | Tree loss: 1.123 | Accuracy: 0.609500 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 002 / 011 | Total loss: 1.088 | Reg loss: 0.044 | Tree loss: 1.088 | Accuracy: 0.626000 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 003 / 011 | Total loss: 1.079 | Reg loss: 0.044 | Tree loss: 1.079 | Accuracy: 0.614500 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.625000 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 005 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.634500 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 006 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.621500 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 007 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.610500 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 008 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.634000 | 0.156 sec/iter\n",
      "Epoch: 193 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.044 | Tree loss: 1.028 | Accuracy: 0.645500 | 0.156 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 193 | Batch: 010 / 011 | Total loss: 1.015 | Reg loss: 0.044 | Tree loss: 1.015 | Accuracy: 0.655290 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 194 | Batch: 000 / 011 | Total loss: 1.129 | Reg loss: 0.044 | Tree loss: 1.129 | Accuracy: 0.590500 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 001 / 011 | Total loss: 1.093 | Reg loss: 0.044 | Tree loss: 1.093 | Accuracy: 0.615000 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 002 / 011 | Total loss: 1.074 | Reg loss: 0.044 | Tree loss: 1.074 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 003 / 011 | Total loss: 1.070 | Reg loss: 0.044 | Tree loss: 1.070 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 004 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.637000 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 005 / 011 | Total loss: 1.051 | Reg loss: 0.044 | Tree loss: 1.051 | Accuracy: 0.641000 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.634500 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.044 | Tree loss: 1.030 | Accuracy: 0.645000 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 008 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.614500 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 009 / 011 | Total loss: 1.035 | Reg loss: 0.044 | Tree loss: 1.035 | Accuracy: 0.628000 | 0.156 sec/iter\n",
      "Epoch: 194 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.044 | Tree loss: 0.997 | Accuracy: 0.672355 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 195 | Batch: 000 / 011 | Total loss: 1.118 | Reg loss: 0.044 | Tree loss: 1.118 | Accuracy: 0.613500 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 001 / 011 | Total loss: 1.095 | Reg loss: 0.044 | Tree loss: 1.095 | Accuracy: 0.627000 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 002 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.617500 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 003 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.617000 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 004 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.613500 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 005 / 011 | Total loss: 1.049 | Reg loss: 0.044 | Tree loss: 1.049 | Accuracy: 0.619500 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 007 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 008 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.621000 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.639000 | 0.156 sec/iter\n",
      "Epoch: 195 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.044 | Tree loss: 1.011 | Accuracy: 0.706485 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 196 | Batch: 000 / 011 | Total loss: 1.127 | Reg loss: 0.044 | Tree loss: 1.127 | Accuracy: 0.628500 | 0.157 sec/iter\n",
      "Epoch: 196 | Batch: 001 / 011 | Total loss: 1.087 | Reg loss: 0.044 | Tree loss: 1.087 | Accuracy: 0.623500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 002 / 011 | Total loss: 1.078 | Reg loss: 0.044 | Tree loss: 1.078 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 003 / 011 | Total loss: 1.075 | Reg loss: 0.044 | Tree loss: 1.075 | Accuracy: 0.620500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 004 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.611500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 005 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.044 | Tree loss: 1.034 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 007 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.617500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.646500 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 009 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.618000 | 0.156 sec/iter\n",
      "Epoch: 196 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.044 | Tree loss: 0.997 | Accuracy: 0.662116 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 197 | Batch: 000 / 011 | Total loss: 1.135 | Reg loss: 0.044 | Tree loss: 1.135 | Accuracy: 0.603500 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 001 / 011 | Total loss: 1.101 | Reg loss: 0.044 | Tree loss: 1.101 | Accuracy: 0.618500 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 002 / 011 | Total loss: 1.097 | Reg loss: 0.044 | Tree loss: 1.097 | Accuracy: 0.614500 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 003 / 011 | Total loss: 1.065 | Reg loss: 0.044 | Tree loss: 1.065 | Accuracy: 0.606000 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.044 | Tree loss: 1.045 | Accuracy: 0.630500 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 005 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.629500 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 006 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.636000 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.044 | Tree loss: 1.030 | Accuracy: 0.645000 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 008 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.643500 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 009 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.625000 | 0.156 sec/iter\n",
      "Epoch: 197 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.044 | Tree loss: 1.011 | Accuracy: 0.651877 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 198 | Batch: 000 / 011 | Total loss: 1.104 | Reg loss: 0.044 | Tree loss: 1.104 | Accuracy: 0.632000 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 001 / 011 | Total loss: 1.094 | Reg loss: 0.044 | Tree loss: 1.094 | Accuracy: 0.610500 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 002 / 011 | Total loss: 1.078 | Reg loss: 0.044 | Tree loss: 1.078 | Accuracy: 0.607000 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 003 / 011 | Total loss: 1.070 | Reg loss: 0.044 | Tree loss: 1.070 | Accuracy: 0.621500 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 004 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.635000 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 005 / 011 | Total loss: 1.050 | Reg loss: 0.044 | Tree loss: 1.050 | Accuracy: 0.626000 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 006 / 011 | Total loss: 1.033 | Reg loss: 0.044 | Tree loss: 1.033 | Accuracy: 0.633500 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 007 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.629000 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 008 / 011 | Total loss: 1.032 | Reg loss: 0.044 | Tree loss: 1.032 | Accuracy: 0.633000 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 009 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.643500 | 0.156 sec/iter\n",
      "Epoch: 198 | Batch: 010 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.621160 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 199 | Batch: 000 / 011 | Total loss: 1.100 | Reg loss: 0.044 | Tree loss: 1.100 | Accuracy: 0.623500 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 001 / 011 | Total loss: 1.087 | Reg loss: 0.044 | Tree loss: 1.087 | Accuracy: 0.630000 | 0.156 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199 | Batch: 002 / 011 | Total loss: 1.086 | Reg loss: 0.044 | Tree loss: 1.086 | Accuracy: 0.612000 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 003 / 011 | Total loss: 1.078 | Reg loss: 0.044 | Tree loss: 1.078 | Accuracy: 0.609500 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 004 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.610000 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 005 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.595500 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.044 | Tree loss: 1.032 | Accuracy: 0.628500 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 007 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.625500 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 008 / 011 | Total loss: 1.031 | Reg loss: 0.044 | Tree loss: 1.031 | Accuracy: 0.634000 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 009 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 199 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.044 | Tree loss: 1.011 | Accuracy: 0.665529 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 200 | Batch: 000 / 011 | Total loss: 1.109 | Reg loss: 0.044 | Tree loss: 1.109 | Accuracy: 0.619500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 001 / 011 | Total loss: 1.102 | Reg loss: 0.044 | Tree loss: 1.102 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 002 / 011 | Total loss: 1.087 | Reg loss: 0.044 | Tree loss: 1.087 | Accuracy: 0.613000 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 003 / 011 | Total loss: 1.070 | Reg loss: 0.044 | Tree loss: 1.070 | Accuracy: 0.628500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.044 | Tree loss: 1.035 | Accuracy: 0.630500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 006 / 011 | Total loss: 1.038 | Reg loss: 0.044 | Tree loss: 1.038 | Accuracy: 0.634500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 007 / 011 | Total loss: 1.053 | Reg loss: 0.044 | Tree loss: 1.053 | Accuracy: 0.604500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.044 | Tree loss: 1.020 | Accuracy: 0.646500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 009 / 011 | Total loss: 1.042 | Reg loss: 0.044 | Tree loss: 1.042 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 200 | Batch: 010 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.627986 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 201 | Batch: 000 / 011 | Total loss: 1.104 | Reg loss: 0.044 | Tree loss: 1.104 | Accuracy: 0.620500 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 001 / 011 | Total loss: 1.108 | Reg loss: 0.044 | Tree loss: 1.108 | Accuracy: 0.602500 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 002 / 011 | Total loss: 1.092 | Reg loss: 0.044 | Tree loss: 1.092 | Accuracy: 0.617000 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 003 / 011 | Total loss: 1.057 | Reg loss: 0.044 | Tree loss: 1.057 | Accuracy: 0.625500 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.625000 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 005 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.621000 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 006 / 011 | Total loss: 1.041 | Reg loss: 0.044 | Tree loss: 1.041 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.044 | Tree loss: 1.024 | Accuracy: 0.623000 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 008 / 011 | Total loss: 1.040 | Reg loss: 0.044 | Tree loss: 1.040 | Accuracy: 0.644000 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 009 / 011 | Total loss: 1.022 | Reg loss: 0.044 | Tree loss: 1.022 | Accuracy: 0.660000 | 0.156 sec/iter\n",
      "Epoch: 201 | Batch: 010 / 011 | Total loss: 1.048 | Reg loss: 0.044 | Tree loss: 1.048 | Accuracy: 0.617747 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 202 | Batch: 000 / 011 | Total loss: 1.114 | Reg loss: 0.044 | Tree loss: 1.114 | Accuracy: 0.607500 | 0.157 sec/iter\n",
      "Epoch: 202 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.044 | Tree loss: 1.076 | Accuracy: 0.632000 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 002 / 011 | Total loss: 1.093 | Reg loss: 0.044 | Tree loss: 1.093 | Accuracy: 0.612000 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 003 / 011 | Total loss: 1.084 | Reg loss: 0.044 | Tree loss: 1.084 | Accuracy: 0.600000 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.649500 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 005 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.619500 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 006 / 011 | Total loss: 1.038 | Reg loss: 0.044 | Tree loss: 1.038 | Accuracy: 0.620500 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.044 | Tree loss: 1.009 | Accuracy: 0.636500 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 008 / 011 | Total loss: 1.039 | Reg loss: 0.044 | Tree loss: 1.039 | Accuracy: 0.609500 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 009 / 011 | Total loss: 1.038 | Reg loss: 0.044 | Tree loss: 1.038 | Accuracy: 0.633500 | 0.156 sec/iter\n",
      "Epoch: 202 | Batch: 010 / 011 | Total loss: 0.992 | Reg loss: 0.044 | Tree loss: 0.992 | Accuracy: 0.651877 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 203 | Batch: 000 / 011 | Total loss: 1.100 | Reg loss: 0.044 | Tree loss: 1.100 | Accuracy: 0.617000 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 001 / 011 | Total loss: 1.105 | Reg loss: 0.044 | Tree loss: 1.105 | Accuracy: 0.608500 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 002 / 011 | Total loss: 1.079 | Reg loss: 0.044 | Tree loss: 1.079 | Accuracy: 0.621000 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.044 | Tree loss: 1.056 | Accuracy: 0.625500 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 004 / 011 | Total loss: 1.060 | Reg loss: 0.044 | Tree loss: 1.060 | Accuracy: 0.615000 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.044 | Tree loss: 1.025 | Accuracy: 0.628000 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.044 | Tree loss: 1.046 | Accuracy: 0.628500 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 007 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.627000 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 008 / 011 | Total loss: 1.044 | Reg loss: 0.044 | Tree loss: 1.044 | Accuracy: 0.641500 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.044 | Tree loss: 1.009 | Accuracy: 0.667500 | 0.156 sec/iter\n",
      "Epoch: 203 | Batch: 010 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.610922 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 204 | Batch: 000 / 011 | Total loss: 1.121 | Reg loss: 0.044 | Tree loss: 1.121 | Accuracy: 0.603500 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 001 / 011 | Total loss: 1.100 | Reg loss: 0.044 | Tree loss: 1.100 | Accuracy: 0.614500 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 003 / 011 | Total loss: 1.071 | Reg loss: 0.044 | Tree loss: 1.071 | Accuracy: 0.599000 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 004 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 005 / 011 | Total loss: 1.054 | Reg loss: 0.044 | Tree loss: 1.054 | Accuracy: 0.609500 | 0.156 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.616500 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.044 | Tree loss: 1.026 | Accuracy: 0.651500 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 008 / 011 | Total loss: 1.018 | Reg loss: 0.044 | Tree loss: 1.018 | Accuracy: 0.663000 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.044 | Tree loss: 1.028 | Accuracy: 0.654000 | 0.156 sec/iter\n",
      "Epoch: 204 | Batch: 010 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.604096 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 205 | Batch: 000 / 011 | Total loss: 1.105 | Reg loss: 0.044 | Tree loss: 1.105 | Accuracy: 0.608000 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 001 / 011 | Total loss: 1.095 | Reg loss: 0.044 | Tree loss: 1.095 | Accuracy: 0.623500 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 002 / 011 | Total loss: 1.079 | Reg loss: 0.044 | Tree loss: 1.079 | Accuracy: 0.619000 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 003 / 011 | Total loss: 1.072 | Reg loss: 0.044 | Tree loss: 1.072 | Accuracy: 0.622500 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 004 / 011 | Total loss: 1.049 | Reg loss: 0.044 | Tree loss: 1.049 | Accuracy: 0.637500 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 005 / 011 | Total loss: 1.052 | Reg loss: 0.044 | Tree loss: 1.052 | Accuracy: 0.629000 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.044 | Tree loss: 1.019 | Accuracy: 0.638500 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 007 / 011 | Total loss: 1.027 | Reg loss: 0.044 | Tree loss: 1.027 | Accuracy: 0.623000 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 008 / 011 | Total loss: 1.036 | Reg loss: 0.044 | Tree loss: 1.036 | Accuracy: 0.631000 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 009 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.638000 | 0.156 sec/iter\n",
      "Epoch: 205 | Batch: 010 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.624573 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 206 | Batch: 000 / 011 | Total loss: 1.100 | Reg loss: 0.044 | Tree loss: 1.100 | Accuracy: 0.612000 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.044 | Tree loss: 1.085 | Accuracy: 0.633000 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 002 / 011 | Total loss: 1.095 | Reg loss: 0.044 | Tree loss: 1.095 | Accuracy: 0.609500 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 003 / 011 | Total loss: 1.061 | Reg loss: 0.044 | Tree loss: 1.061 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 004 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.618000 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 005 / 011 | Total loss: 1.059 | Reg loss: 0.044 | Tree loss: 1.059 | Accuracy: 0.613500 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 006 / 011 | Total loss: 1.030 | Reg loss: 0.044 | Tree loss: 1.030 | Accuracy: 0.624500 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.044 | Tree loss: 1.024 | Accuracy: 0.625500 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 008 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.625000 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.645500 | 0.156 sec/iter\n",
      "Epoch: 206 | Batch: 010 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.641638 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 207 | Batch: 000 / 011 | Total loss: 1.120 | Reg loss: 0.044 | Tree loss: 1.120 | Accuracy: 0.618500 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 001 / 011 | Total loss: 1.090 | Reg loss: 0.044 | Tree loss: 1.090 | Accuracy: 0.616500 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 002 / 011 | Total loss: 1.074 | Reg loss: 0.044 | Tree loss: 1.074 | Accuracy: 0.637000 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.044 | Tree loss: 1.049 | Accuracy: 0.633500 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 004 / 011 | Total loss: 1.063 | Reg loss: 0.044 | Tree loss: 1.063 | Accuracy: 0.621500 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 005 / 011 | Total loss: 1.029 | Reg loss: 0.044 | Tree loss: 1.029 | Accuracy: 0.653000 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 006 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.639500 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 007 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.613000 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 008 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.632500 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.643000 | 0.156 sec/iter\n",
      "Epoch: 207 | Batch: 010 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.627986 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 208 | Batch: 000 / 011 | Total loss: 1.102 | Reg loss: 0.044 | Tree loss: 1.102 | Accuracy: 0.613500 | 0.156 sec/iter\n",
      "Epoch: 208 | Batch: 001 / 011 | Total loss: 1.103 | Reg loss: 0.044 | Tree loss: 1.103 | Accuracy: 0.613500 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 002 / 011 | Total loss: 1.087 | Reg loss: 0.044 | Tree loss: 1.087 | Accuracy: 0.617000 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 003 / 011 | Total loss: 1.071 | Reg loss: 0.044 | Tree loss: 1.071 | Accuracy: 0.619000 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.044 | Tree loss: 1.043 | Accuracy: 0.646500 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 005 / 011 | Total loss: 1.037 | Reg loss: 0.044 | Tree loss: 1.037 | Accuracy: 0.623500 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 006 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.614000 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.657500 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 008 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.646500 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 009 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.651500 | 0.155 sec/iter\n",
      "Epoch: 208 | Batch: 010 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.648464 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 209 | Batch: 000 / 011 | Total loss: 1.142 | Reg loss: 0.044 | Tree loss: 1.142 | Accuracy: 0.604500 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 001 / 011 | Total loss: 1.088 | Reg loss: 0.044 | Tree loss: 1.088 | Accuracy: 0.607000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.044 | Tree loss: 1.070 | Accuracy: 0.633000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.044 | Tree loss: 1.058 | Accuracy: 0.630000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 004 / 011 | Total loss: 1.067 | Reg loss: 0.044 | Tree loss: 1.067 | Accuracy: 0.621000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 005 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.629500 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.620000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.636000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.633000 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 009 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.643500 | 0.155 sec/iter\n",
      "Epoch: 209 | Batch: 010 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.682594 | 0.155 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 210 | Batch: 000 / 011 | Total loss: 1.104 | Reg loss: 0.044 | Tree loss: 1.104 | Accuracy: 0.631500 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.044 | Tree loss: 1.085 | Accuracy: 0.640000 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 002 / 011 | Total loss: 1.093 | Reg loss: 0.044 | Tree loss: 1.093 | Accuracy: 0.608000 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 003 / 011 | Total loss: 1.067 | Reg loss: 0.044 | Tree loss: 1.067 | Accuracy: 0.633500 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.642000 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 005 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.619000 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.642000 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.618000 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.646500 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 009 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.629500 | 0.155 sec/iter\n",
      "Epoch: 210 | Batch: 010 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.679181 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 211 | Batch: 000 / 011 | Total loss: 1.113 | Reg loss: 0.045 | Tree loss: 1.113 | Accuracy: 0.621000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 001 / 011 | Total loss: 1.101 | Reg loss: 0.045 | Tree loss: 1.101 | Accuracy: 0.613000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.632000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.614500 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.644000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.638000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.620500 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 007 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.630500 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 008 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.645000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 009 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.623000 | 0.155 sec/iter\n",
      "Epoch: 211 | Batch: 010 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.634812 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 212 | Batch: 000 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.621500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 001 / 011 | Total loss: 1.102 | Reg loss: 0.045 | Tree loss: 1.102 | Accuracy: 0.610000 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 002 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.625500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.639000 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 004 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.612500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 005 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.634500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.630000 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.627500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 008 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.641500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.665500 | 0.155 sec/iter\n",
      "Epoch: 212 | Batch: 010 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.645051 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 213 | Batch: 000 / 011 | Total loss: 1.107 | Reg loss: 0.045 | Tree loss: 1.107 | Accuracy: 0.617000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.637000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 002 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.625500 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 003 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.632500 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 004 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.616000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 005 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.609000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 006 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.608500 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 007 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.621000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.659000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.641000 | 0.155 sec/iter\n",
      "Epoch: 213 | Batch: 010 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.624573 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 214 | Batch: 000 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.628000 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 001 / 011 | Total loss: 1.099 | Reg loss: 0.045 | Tree loss: 1.099 | Accuracy: 0.627500 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.632500 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 003 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.635000 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 004 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.633000 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 005 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.624000 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 006 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.602500 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 007 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.611500 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.640500 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.644500 | 0.155 sec/iter\n",
      "Epoch: 214 | Batch: 010 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.559727 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 215 | Batch: 000 / 011 | Total loss: 1.111 | Reg loss: 0.045 | Tree loss: 1.111 | Accuracy: 0.621000 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.625000 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 002 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.622000 | 0.155 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 215 | Batch: 003 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.616500 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.631500 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 005 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.622500 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 006 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.611000 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.646000 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.635000 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 009 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.635000 | 0.155 sec/iter\n",
      "Epoch: 215 | Batch: 010 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.610922 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 216 | Batch: 000 / 011 | Total loss: 1.106 | Reg loss: 0.045 | Tree loss: 1.106 | Accuracy: 0.608500 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.639500 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 002 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.621500 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.627500 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.638000 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.620000 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 006 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.618000 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 007 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.628500 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.633500 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 009 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.645000 | 0.155 sec/iter\n",
      "Epoch: 216 | Batch: 010 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.648464 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 217 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.627500 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 001 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.617000 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 002 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.630500 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 003 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.624000 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.634500 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 005 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.636500 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 006 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.628000 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 007 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.631000 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 008 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.634000 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.638500 | 0.155 sec/iter\n",
      "Epoch: 217 | Batch: 010 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.624573 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 218 | Batch: 000 / 011 | Total loss: 1.115 | Reg loss: 0.045 | Tree loss: 1.115 | Accuracy: 0.605000 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 001 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.640500 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 002 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.621000 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.628000 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 004 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.623000 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.638000 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.638500 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.610000 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.648500 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.637500 | 0.155 sec/iter\n",
      "Epoch: 218 | Batch: 010 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.617747 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 219 | Batch: 000 / 011 | Total loss: 1.096 | Reg loss: 0.045 | Tree loss: 1.096 | Accuracy: 0.620500 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 001 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.633000 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.642000 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.647500 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 004 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.646500 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 005 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.630500 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 006 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.628500 | 0.155 sec/iter\n",
      "Epoch: 219 | Batch: 007 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.629000 | 0.154 sec/iter\n",
      "Epoch: 219 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.640000 | 0.154 sec/iter\n",
      "Epoch: 219 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.644000 | 0.154 sec/iter\n",
      "Epoch: 219 | Batch: 010 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.665529 | 0.154 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 220 | Batch: 000 / 011 | Total loss: 1.101 | Reg loss: 0.045 | Tree loss: 1.101 | Accuracy: 0.629500 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 001 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.632500 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 002 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.629000 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.620500 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.619500 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 005 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.616000 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 006 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.640000 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 007 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.628500 | 0.154 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.663500 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.646500 | 0.154 sec/iter\n",
      "Epoch: 220 | Batch: 010 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.668942 | 0.154 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 221 | Batch: 000 / 011 | Total loss: 1.105 | Reg loss: 0.045 | Tree loss: 1.105 | Accuracy: 0.617500 | 0.155 sec/iter\n",
      "Epoch: 221 | Batch: 001 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.629500 | 0.155 sec/iter\n",
      "Epoch: 221 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.622000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.637000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.637000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.612000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 006 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.627000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 007 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.639000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 008 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.642500 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 009 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.647000 | 0.154 sec/iter\n",
      "Epoch: 221 | Batch: 010 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.651877 | 0.154 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 222 | Batch: 000 / 011 | Total loss: 1.100 | Reg loss: 0.045 | Tree loss: 1.100 | Accuracy: 0.613000 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 001 / 011 | Total loss: 1.108 | Reg loss: 0.045 | Tree loss: 1.108 | Accuracy: 0.602500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 002 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.639000 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 003 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.637500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.634500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.636500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.621500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.659000 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 008 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.621500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 009 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.628500 | 0.155 sec/iter\n",
      "Epoch: 222 | Batch: 010 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.621160 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 223 | Batch: 000 / 011 | Total loss: 1.109 | Reg loss: 0.045 | Tree loss: 1.109 | Accuracy: 0.609000 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.655500 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.623000 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.638500 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 004 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.621000 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 005 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.612000 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 006 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.625500 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 007 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.629000 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 008 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.640500 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 009 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.630500 | 0.155 sec/iter\n",
      "Epoch: 223 | Batch: 010 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.624573 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 224 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.618000 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 001 / 011 | Total loss: 1.103 | Reg loss: 0.045 | Tree loss: 1.103 | Accuracy: 0.606000 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.626000 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 003 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.616000 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.636500 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 005 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.631000 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.641500 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 007 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.633000 | 0.156 sec/iter\n",
      "Epoch: 224 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.659500 | 0.155 sec/iter\n",
      "Epoch: 224 | Batch: 009 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.628500 | 0.155 sec/iter\n",
      "Epoch: 224 | Batch: 010 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.634812 | 0.155 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 225 | Batch: 000 / 011 | Total loss: 1.107 | Reg loss: 0.045 | Tree loss: 1.107 | Accuracy: 0.622500 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 001 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.622000 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 002 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.611000 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 003 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.632000 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.641500 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 005 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.607500 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 006 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.606000 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.637500 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.661500 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.668000 | 0.156 sec/iter\n",
      "Epoch: 225 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.631399 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 226 | Batch: 000 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.626500 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 001 / 011 | Total loss: 1.102 | Reg loss: 0.045 | Tree loss: 1.102 | Accuracy: 0.602500 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.629000 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.639500 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 004 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.649000 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.624000 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.596500 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 007 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.622000 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.658000 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.641500 | 0.156 sec/iter\n",
      "Epoch: 226 | Batch: 010 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.665529 | 0.156 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 227 | Batch: 000 / 011 | Total loss: 1.109 | Reg loss: 0.045 | Tree loss: 1.109 | Accuracy: 0.632500 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.621500 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 002 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.645000 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 003 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.620000 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.634000 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 005 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.622000 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.624000 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 008 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.638000 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 009 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.641500 | 0.157 sec/iter\n",
      "Epoch: 227 | Batch: 010 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.624573 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 228 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.630000 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 001 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.617500 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 002 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.608500 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.642000 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 004 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.631000 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.634500 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 006 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.603500 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 008 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.648000 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 009 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.629000 | 0.157 sec/iter\n",
      "Epoch: 228 | Batch: 010 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.651877 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 229 | Batch: 000 / 011 | Total loss: 1.105 | Reg loss: 0.045 | Tree loss: 1.105 | Accuracy: 0.622000 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 001 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.604000 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.627500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 003 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.627500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 004 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.607500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 005 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.619500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.616500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 007 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.632000 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.656500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.663500 | 0.157 sec/iter\n",
      "Epoch: 229 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.655290 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 230 | Batch: 000 / 011 | Total loss: 1.108 | Reg loss: 0.045 | Tree loss: 1.108 | Accuracy: 0.605500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 002 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.612000 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 003 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 004 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.605500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 005 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.627500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.619500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.635000 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 008 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.631500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.643500 | 0.157 sec/iter\n",
      "Epoch: 230 | Batch: 010 / 011 | Total loss: 0.980 | Reg loss: 0.045 | Tree loss: 0.980 | Accuracy: 0.651877 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 231 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 231 | Batch: 001 / 011 | Total loss: 1.096 | Reg loss: 0.045 | Tree loss: 1.096 | Accuracy: 0.622500 | 0.158 sec/iter\n",
      "Epoch: 231 | Batch: 002 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.619000 | 0.158 sec/iter\n",
      "Epoch: 231 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.632500 | 0.158 sec/iter\n",
      "Epoch: 231 | Batch: 004 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.625500 | 0.158 sec/iter\n",
      "Epoch: 231 | Batch: 005 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.628000 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 231 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.630000 | 0.157 sec/iter\n",
      "Epoch: 231 | Batch: 007 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.615500 | 0.157 sec/iter\n",
      "Epoch: 231 | Batch: 008 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.648500 | 0.157 sec/iter\n",
      "Epoch: 231 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.651000 | 0.157 sec/iter\n",
      "Epoch: 231 | Batch: 010 / 011 | Total loss: 0.986 | Reg loss: 0.045 | Tree loss: 0.986 | Accuracy: 0.641638 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 232 | Batch: 000 / 011 | Total loss: 1.099 | Reg loss: 0.045 | Tree loss: 1.099 | Accuracy: 0.610000 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 001 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.615500 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.611500 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 003 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.618500 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 004 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.649000 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.639000 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 006 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.632000 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 007 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.618500 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.632000 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 009 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.614500 | 0.158 sec/iter\n",
      "Epoch: 232 | Batch: 010 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.662116 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 233 | Batch: 000 / 011 | Total loss: 1.097 | Reg loss: 0.045 | Tree loss: 1.097 | Accuracy: 0.610000 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 001 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.622500 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 002 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.619500 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.623000 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 004 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.614000 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.634500 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.625000 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.632500 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 008 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.640000 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.634000 | 0.158 sec/iter\n",
      "Epoch: 233 | Batch: 010 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.621160 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 234 | Batch: 000 / 011 | Total loss: 1.096 | Reg loss: 0.045 | Tree loss: 1.096 | Accuracy: 0.616500 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.643500 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 003 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.607500 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 004 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.623000 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.636500 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.639000 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 007 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 008 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 009 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 234 | Batch: 010 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.651877 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 235 | Batch: 000 / 011 | Total loss: 1.114 | Reg loss: 0.045 | Tree loss: 1.114 | Accuracy: 0.599500 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 001 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.628000 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.618500 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.632500 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.643000 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 005 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.626000 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 006 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.636000 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 007 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.612500 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 008 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 009 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.627500 | 0.158 sec/iter\n",
      "Epoch: 235 | Batch: 010 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.665529 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 236 | Batch: 000 / 011 | Total loss: 1.114 | Reg loss: 0.045 | Tree loss: 1.114 | Accuracy: 0.603500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.654000 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.665500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 005 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.637500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.623500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 008 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.607500 | 0.158 sec/iter\n",
      "Epoch: 236 | Batch: 009 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.621000 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 236 | Batch: 010 / 011 | Total loss: 0.955 | Reg loss: 0.045 | Tree loss: 0.955 | Accuracy: 0.679181 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 237 | Batch: 000 / 011 | Total loss: 1.104 | Reg loss: 0.045 | Tree loss: 1.104 | Accuracy: 0.616500 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.632000 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 002 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.616000 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.638500 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.626500 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.624000 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.626500 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.632000 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 008 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.632000 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 009 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.648500 | 0.159 sec/iter\n",
      "Epoch: 237 | Batch: 010 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.621160 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 238 | Batch: 000 / 011 | Total loss: 1.101 | Reg loss: 0.045 | Tree loss: 1.101 | Accuracy: 0.624500 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 001 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.628000 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.624500 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 003 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.629500 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.632500 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.626000 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.616500 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 007 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.629000 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.647500 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.654000 | 0.159 sec/iter\n",
      "Epoch: 238 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.651877 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 239 | Batch: 000 / 011 | Total loss: 1.114 | Reg loss: 0.045 | Tree loss: 1.114 | Accuracy: 0.610500 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.612500 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 002 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.613000 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 003 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.639500 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.623500 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.635000 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.639000 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.650000 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.646500 | 0.159 sec/iter\n",
      "Epoch: 239 | Batch: 010 / 011 | Total loss: 0.929 | Reg loss: 0.045 | Tree loss: 0.929 | Accuracy: 0.696246 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 240 | Batch: 000 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 001 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.611500 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 003 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.612500 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 005 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.637000 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 006 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.658500 | 0.16 sec/iter\n",
      "Epoch: 240 | Batch: 010 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.621160 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 241 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.622000 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.614000 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 003 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.616500 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 006 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 009 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.634000 | 0.16 sec/iter\n",
      "Epoch: 241 | Batch: 010 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.665529 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 242 | Batch: 000 / 011 | Total loss: 1.103 | Reg loss: 0.045 | Tree loss: 1.103 | Accuracy: 0.623000 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 001 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.620000 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 242 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.622500 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.624000 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 005 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.647000 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 008 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.657500 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.656000 | 0.16 sec/iter\n",
      "Epoch: 242 | Batch: 010 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.645051 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 243 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 003 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.624000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 004 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 005 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 006 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.634000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 007 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.629500 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 008 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.656000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 243 | Batch: 010 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.641638 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 244 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 002 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.610500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.640500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 004 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.614000 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 006 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.627000 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 007 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.638000 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.668500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.649500 | 0.16 sec/iter\n",
      "Epoch: 244 | Batch: 010 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.662116 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 245 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.609500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 002 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.599500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 005 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 007 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.642500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 009 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.635000 | 0.16 sec/iter\n",
      "Epoch: 245 | Batch: 010 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.617747 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 246 | Batch: 000 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 001 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.607000 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 004 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.641000 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.648500 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.637000 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 008 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.625000 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.653500 | 0.16 sec/iter\n",
      "Epoch: 246 | Batch: 010 / 011 | Total loss: 0.973 | Reg loss: 0.045 | Tree loss: 0.973 | Accuracy: 0.641638 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 247 | Batch: 000 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.607000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 001 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.641000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.635000 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247 | Batch: 006 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.647000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 007 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.639000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 008 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.652000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 009 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 247 | Batch: 010 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.614334 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 248 | Batch: 000 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.652000 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 006 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 007 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.643500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 009 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 248 | Batch: 010 / 011 | Total loss: 0.972 | Reg loss: 0.045 | Tree loss: 0.972 | Accuracy: 0.709898 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 249 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 003 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.616000 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.651500 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 005 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 006 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 007 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.665000 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.647500 | 0.16 sec/iter\n",
      "Epoch: 249 | Batch: 010 / 011 | Total loss: 0.946 | Reg loss: 0.045 | Tree loss: 0.946 | Accuracy: 0.706485 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 250 | Batch: 000 / 011 | Total loss: 1.107 | Reg loss: 0.045 | Tree loss: 1.107 | Accuracy: 0.613500 | 0.16 sec/iter\n",
      "Epoch: 250 | Batch: 001 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 250 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 250 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 250 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.635500 | 0.159 sec/iter\n",
      "Epoch: 250 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.621500 | 0.159 sec/iter\n",
      "Epoch: 250 | Batch: 006 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.607000 | 0.159 sec/iter\n",
      "Epoch: 250 | Batch: 007 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.629000 | 0.159 sec/iter\n",
      "Epoch: 250 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.660500 | 0.159 sec/iter\n",
      "Epoch: 250 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.661000 | 0.159 sec/iter\n",
      "Epoch: 250 | Batch: 010 / 011 | Total loss: 0.985 | Reg loss: 0.045 | Tree loss: 0.985 | Accuracy: 0.655290 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 251 | Batch: 000 / 011 | Total loss: 1.096 | Reg loss: 0.045 | Tree loss: 1.096 | Accuracy: 0.616000 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 001 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.603500 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 002 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.648500 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.638000 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.649500 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 007 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.626000 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.649500 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 251 | Batch: 010 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.624573 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 252 | Batch: 000 / 011 | Total loss: 1.105 | Reg loss: 0.045 | Tree loss: 1.105 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 002 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.602500 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.621500 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 007 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 008 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.644500 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.654000 | 0.16 sec/iter\n",
      "Epoch: 252 | Batch: 010 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.672355 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 253 | Batch: 000 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 001 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.617500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 009 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 253 | Batch: 010 / 011 | Total loss: 0.986 | Reg loss: 0.045 | Tree loss: 0.986 | Accuracy: 0.658703 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 254 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 002 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 003 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.607500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 004 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 006 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.611000 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 008 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.650500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.652500 | 0.16 sec/iter\n",
      "Epoch: 254 | Batch: 010 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.658703 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 255 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.614000 | 0.16 sec/iter\n",
      "Epoch: 255 | Batch: 001 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.617500 | 0.16 sec/iter\n",
      "Epoch: 255 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.615500 | 0.16 sec/iter\n",
      "Epoch: 255 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 255 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 255 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.637500 | 0.159 sec/iter\n",
      "Epoch: 255 | Batch: 006 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.637000 | 0.159 sec/iter\n",
      "Epoch: 255 | Batch: 007 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.628500 | 0.159 sec/iter\n",
      "Epoch: 255 | Batch: 008 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.648000 | 0.159 sec/iter\n",
      "Epoch: 255 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.645500 | 0.159 sec/iter\n",
      "Epoch: 255 | Batch: 010 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.658703 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 256 | Batch: 000 / 011 | Total loss: 1.099 | Reg loss: 0.045 | Tree loss: 1.099 | Accuracy: 0.613000 | 0.16 sec/iter\n",
      "Epoch: 256 | Batch: 001 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.598000 | 0.16 sec/iter\n",
      "Epoch: 256 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.635000 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.635500 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 004 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.617000 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.614500 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.629000 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.649500 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.638000 | 0.159 sec/iter\n",
      "Epoch: 256 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.614334 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 257 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.609500 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 001 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.622000 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 002 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.661500 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.646500 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.638000 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.636500 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 006 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.622000 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.635000 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 008 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.619500 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 009 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.650500 | 0.159 sec/iter\n",
      "Epoch: 257 | Batch: 010 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.610922 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 258 | Batch: 000 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.609500 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.647000 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.633000 | 0.159 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.626500 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 004 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 005 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.634000 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 006 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.627500 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.649500 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.633000 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.645500 | 0.159 sec/iter\n",
      "Epoch: 258 | Batch: 010 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.617747 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 259 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.624000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.624000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 002 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.600000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.610500 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 004 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.645000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 006 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.643000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 007 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.634000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 008 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.645500 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.646000 | 0.159 sec/iter\n",
      "Epoch: 259 | Batch: 010 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.617747 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 260 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.618500 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.630000 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 002 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.621000 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.628500 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.642000 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.621500 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.630500 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 008 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.625000 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.667000 | 0.159 sec/iter\n",
      "Epoch: 260 | Batch: 010 / 011 | Total loss: 0.967 | Reg loss: 0.045 | Tree loss: 0.967 | Accuracy: 0.713311 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 261 | Batch: 000 / 011 | Total loss: 1.101 | Reg loss: 0.045 | Tree loss: 1.101 | Accuracy: 0.595500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 001 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.610000 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.633500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.633500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 004 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.622500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 005 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 006 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.621500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 007 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.652000 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 009 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.651500 | 0.159 sec/iter\n",
      "Epoch: 261 | Batch: 010 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.662116 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 262 | Batch: 000 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.602000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 001 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.647000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 002 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.593000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.615500 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 004 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.617000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.619000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.616000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 007 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.643000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.639000 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 009 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.650500 | 0.159 sec/iter\n",
      "Epoch: 262 | Batch: 010 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.645051 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 263 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.624500 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.625500 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.650000 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 003 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.621000 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.645500 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 005 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.642500 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.617500 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.639500 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 008 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.629000 | 0.159 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.651000 | 0.159 sec/iter\n",
      "Epoch: 263 | Batch: 010 / 011 | Total loss: 0.975 | Reg loss: 0.045 | Tree loss: 0.975 | Accuracy: 0.658703 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 264 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.630000 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.623500 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 002 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.622000 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.627500 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.644000 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.632000 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.617500 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.627500 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 009 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.625500 | 0.159 sec/iter\n",
      "Epoch: 264 | Batch: 010 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.624573 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 265 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.632000 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.619000 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 003 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.624000 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.647000 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 005 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.625500 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 006 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.626500 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.625500 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.628500 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.633000 | 0.159 sec/iter\n",
      "Epoch: 265 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.662116 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 266 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.629000 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 002 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.634000 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.614000 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.632500 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 005 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.640500 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.622500 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 007 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.640000 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 009 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.632000 | 0.159 sec/iter\n",
      "Epoch: 266 | Batch: 010 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.621160 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 267 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.621000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.641500 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.627500 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 005 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.637000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.642000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.652000 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.663500 | 0.159 sec/iter\n",
      "Epoch: 267 | Batch: 010 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.563140 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 268 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.616000 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.640500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.620500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.632500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.650500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 005 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.666500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.642500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 007 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.629500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.638500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 268 | Batch: 010 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.627986 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 269 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.623500 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.629500 | 0.159 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 269 | Batch: 002 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.615000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 003 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.628000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.658500 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 005 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 006 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 007 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.642000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 008 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.663000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 009 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.641000 | 0.159 sec/iter\n",
      "Epoch: 269 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.614334 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 270 | Batch: 000 / 011 | Total loss: 1.102 | Reg loss: 0.045 | Tree loss: 1.102 | Accuracy: 0.610500 | 0.159 sec/iter\n",
      "Epoch: 270 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 270 | Batch: 002 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.627500 | 0.159 sec/iter\n",
      "Epoch: 270 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.630000 | 0.159 sec/iter\n",
      "Epoch: 270 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.624500 | 0.158 sec/iter\n",
      "Epoch: 270 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.615500 | 0.158 sec/iter\n",
      "Epoch: 270 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.646500 | 0.158 sec/iter\n",
      "Epoch: 270 | Batch: 007 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.642000 | 0.158 sec/iter\n",
      "Epoch: 270 | Batch: 008 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.634500 | 0.158 sec/iter\n",
      "Epoch: 270 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.665000 | 0.158 sec/iter\n",
      "Epoch: 270 | Batch: 010 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.686007 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 271 | Batch: 000 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.635000 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.627000 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.617000 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.609500 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.617500 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.636000 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.643500 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.641000 | 0.158 sec/iter\n",
      "Epoch: 271 | Batch: 010 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.658703 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 272 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.639000 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 001 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.635000 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.612500 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 003 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.609500 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.614000 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.625500 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.636500 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.634500 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.641000 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.656000 | 0.158 sec/iter\n",
      "Epoch: 272 | Batch: 010 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.672355 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 273 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.617000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 002 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.631000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.631500 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.626000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.614000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 007 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.639000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 008 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.632000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.644000 | 0.158 sec/iter\n",
      "Epoch: 273 | Batch: 010 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.648464 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 274 | Batch: 000 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.612000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.629000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 003 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.612000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 004 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.623500 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.629500 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 274 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.635000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.636000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.652000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.647000 | 0.158 sec/iter\n",
      "Epoch: 274 | Batch: 010 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.593857 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 275 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.630000 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.609000 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.609500 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.610000 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.604000 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 005 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 006 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.651000 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 009 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.672000 | 0.158 sec/iter\n",
      "Epoch: 275 | Batch: 010 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.655290 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 276 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.643500 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.612000 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 002 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.646000 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.625000 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.612000 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.616000 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.637500 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.639500 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.645500 | 0.158 sec/iter\n",
      "Epoch: 276 | Batch: 010 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.634812 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 277 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 001 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 002 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.652500 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 003 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.620500 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.619000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 005 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.624500 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 006 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.642000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 007 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 008 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.629000 | 0.158 sec/iter\n",
      "Epoch: 277 | Batch: 010 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.627986 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 278 | Batch: 000 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.617500 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.627000 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 003 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.625500 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.624000 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.645000 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.625500 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 007 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.646500 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 008 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.657000 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 278 | Batch: 010 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.610922 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 279 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.644500 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.641500 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 004 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.607500 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 005 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.637000 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 007 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 008 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.651000 | 0.158 sec/iter\n",
      "Epoch: 279 | Batch: 010 / 011 | Total loss: 0.966 | Reg loss: 0.045 | Tree loss: 0.966 | Accuracy: 0.658703 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 280 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.619000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.633000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.632000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.641000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.640000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.647500 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 006 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.609500 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.647000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.645500 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 009 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.623000 | 0.158 sec/iter\n",
      "Epoch: 280 | Batch: 010 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.617747 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 281 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.627000 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.624000 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.643000 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 006 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.647500 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.636000 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.645500 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.625000 | 0.158 sec/iter\n",
      "Epoch: 281 | Batch: 010 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.600683 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 282 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 001 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.619000 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 002 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.605000 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.614500 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.638500 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.621500 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.646000 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.645500 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.645500 | 0.158 sec/iter\n",
      "Epoch: 282 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.658703 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 283 | Batch: 000 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.608000 | 0.158 sec/iter\n",
      "Epoch: 283 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.618000 | 0.158 sec/iter\n",
      "Epoch: 283 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.641500 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 004 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.649000 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 005 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.639000 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 006 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.610500 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.641500 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.645000 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 009 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.642500 | 0.157 sec/iter\n",
      "Epoch: 283 | Batch: 010 / 011 | Total loss: 0.974 | Reg loss: 0.045 | Tree loss: 0.974 | Accuracy: 0.672355 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 284 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.610000 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.625000 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.631500 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.627000 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.615500 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.645000 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 006 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.651000 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 007 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.642500 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.639500 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 284 | Batch: 010 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.638225 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 285 | Batch: 000 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.615500 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.638500 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.626000 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 003 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.643000 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.625500 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.632500 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.636500 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.629000 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.657000 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 009 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.639000 | 0.157 sec/iter\n",
      "Epoch: 285 | Batch: 010 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.679181 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 286 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.618500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.613500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.641000 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 003 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.641500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.649500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 005 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.638500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.622500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 007 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.640000 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 008 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.618000 | 0.158 sec/iter\n",
      "Epoch: 286 | Batch: 010 / 011 | Total loss: 0.951 | Reg loss: 0.045 | Tree loss: 0.951 | Accuracy: 0.686007 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 287 | Batch: 000 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.615500 | 0.158 sec/iter\n",
      "Epoch: 287 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.620500 | 0.158 sec/iter\n",
      "Epoch: 287 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.637500 | 0.158 sec/iter\n",
      "Epoch: 287 | Batch: 003 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.616000 | 0.158 sec/iter\n",
      "Epoch: 287 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.641000 | 0.158 sec/iter\n",
      "Epoch: 287 | Batch: 005 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.647000 | 0.157 sec/iter\n",
      "Epoch: 287 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 287 | Batch: 007 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.616000 | 0.157 sec/iter\n",
      "Epoch: 287 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.655500 | 0.157 sec/iter\n",
      "Epoch: 287 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.642000 | 0.157 sec/iter\n",
      "Epoch: 287 | Batch: 010 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.634812 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 288 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.624500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.629000 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.632000 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 003 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.618000 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.635500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.634500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 007 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.659500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.638500 | 0.157 sec/iter\n",
      "Epoch: 288 | Batch: 010 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.641638 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 289 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 289 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.623000 | 0.158 sec/iter\n",
      "Epoch: 289 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.626500 | 0.158 sec/iter\n",
      "Epoch: 289 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 289 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.634000 | 0.158 sec/iter\n",
      "Epoch: 289 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.627500 | 0.158 sec/iter\n",
      "Epoch: 289 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 289 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.637000 | 0.157 sec/iter\n",
      "Epoch: 289 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.631500 | 0.157 sec/iter\n",
      "Epoch: 289 | Batch: 009 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.635500 | 0.157 sec/iter\n",
      "Epoch: 289 | Batch: 010 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.675768 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 290 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.620000 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.615000 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.609500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.619500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.619500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.641000 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.638500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.648500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 009 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 290 | Batch: 010 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.638225 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 291 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.636000 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 001 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.602500 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 002 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.628500 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.629000 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.626000 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 007 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.631500 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.645000 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 009 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.629500 | 0.158 sec/iter\n",
      "Epoch: 291 | Batch: 010 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.682594 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 292 | Batch: 000 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.629500 | 0.158 sec/iter\n",
      "Epoch: 292 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.631500 | 0.158 sec/iter\n",
      "Epoch: 292 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.618000 | 0.158 sec/iter\n",
      "Epoch: 292 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.623000 | 0.158 sec/iter\n",
      "Epoch: 292 | Batch: 004 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 292 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.641000 | 0.157 sec/iter\n",
      "Epoch: 292 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.626500 | 0.157 sec/iter\n",
      "Epoch: 292 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.618500 | 0.157 sec/iter\n",
      "Epoch: 292 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.628000 | 0.157 sec/iter\n",
      "Epoch: 292 | Batch: 009 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.642500 | 0.157 sec/iter\n",
      "Epoch: 292 | Batch: 010 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.604096 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 293 | Batch: 000 / 011 | Total loss: 1.100 | Reg loss: 0.045 | Tree loss: 1.100 | Accuracy: 0.613500 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.621000 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.628500 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.635000 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.644000 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.628000 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.632500 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.624500 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.650500 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 009 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 293 | Batch: 010 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.631399 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 294 | Batch: 000 / 011 | Total loss: 1.093 | Reg loss: 0.045 | Tree loss: 1.093 | Accuracy: 0.618500 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 001 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.622000 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.627000 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.635500 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.650500 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 005 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.644500 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.645500 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.624000 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.629500 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.624000 | 0.157 sec/iter\n",
      "Epoch: 294 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.645051 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 295 | Batch: 000 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.628500 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.640000 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.644500 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.646000 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.632000 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 005 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.620000 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.626500 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.641000 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.622500 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.636500 | 0.157 sec/iter\n",
      "Epoch: 295 | Batch: 010 / 011 | Total loss: 0.937 | Reg loss: 0.045 | Tree loss: 0.937 | Accuracy: 0.709898 | 0.157 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 296 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.644500 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 001 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.615000 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 002 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.616000 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 003 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.641000 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.622000 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.632500 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.630000 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 007 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.620000 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.658500 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.633500 | 0.157 sec/iter\n",
      "Epoch: 296 | Batch: 010 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.641638 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 297 | Batch: 000 / 011 | Total loss: 1.101 | Reg loss: 0.045 | Tree loss: 1.101 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.617500 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.634000 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.623000 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.630000 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.625500 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 006 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.624500 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.641000 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.640000 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.660000 | 0.157 sec/iter\n",
      "Epoch: 297 | Batch: 010 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.658703 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 298 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.625000 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.635500 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.633000 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.627500 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.640000 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.625500 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 007 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.611500 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 008 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.612000 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 009 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.636500 | 0.157 sec/iter\n",
      "Epoch: 298 | Batch: 010 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.706485 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 299 | Batch: 000 / 011 | Total loss: 1.115 | Reg loss: 0.045 | Tree loss: 1.115 | Accuracy: 0.582000 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.630000 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.630500 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 003 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.635000 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.653500 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.627000 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.645000 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.626500 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 008 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.652000 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.641500 | 0.157 sec/iter\n",
      "Epoch: 299 | Batch: 010 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.614334 | 0.157 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 300 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.621000 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.625500 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 002 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.636500 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 003 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.615000 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 004 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.641500 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.622000 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.623500 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 009 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.656500 | 0.158 sec/iter\n",
      "Epoch: 300 | Batch: 010 / 011 | Total loss: 0.963 | Reg loss: 0.045 | Tree loss: 0.963 | Accuracy: 0.675768 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 301 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.632500 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.623500 | 0.158 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 301 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 003 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.640500 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.650000 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 005 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.624000 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.626000 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.635500 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 009 / 011 | Total loss: 0.989 | Reg loss: 0.045 | Tree loss: 0.989 | Accuracy: 0.653000 | 0.158 sec/iter\n",
      "Epoch: 301 | Batch: 010 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.665529 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 302 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.625500 | 0.159 sec/iter\n",
      "Epoch: 302 | Batch: 001 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.600000 | 0.159 sec/iter\n",
      "Epoch: 302 | Batch: 002 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.618500 | 0.159 sec/iter\n",
      "Epoch: 302 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.628500 | 0.159 sec/iter\n",
      "Epoch: 302 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.639000 | 0.158 sec/iter\n",
      "Epoch: 302 | Batch: 005 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.626000 | 0.158 sec/iter\n",
      "Epoch: 302 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.630000 | 0.158 sec/iter\n",
      "Epoch: 302 | Batch: 007 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.641500 | 0.158 sec/iter\n",
      "Epoch: 302 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.640500 | 0.158 sec/iter\n",
      "Epoch: 302 | Batch: 009 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.621500 | 0.158 sec/iter\n",
      "Epoch: 302 | Batch: 010 / 011 | Total loss: 0.947 | Reg loss: 0.045 | Tree loss: 0.947 | Accuracy: 0.682594 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 303 | Batch: 000 / 011 | Total loss: 1.113 | Reg loss: 0.045 | Tree loss: 1.113 | Accuracy: 0.602000 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 001 / 011 | Total loss: 1.104 | Reg loss: 0.045 | Tree loss: 1.104 | Accuracy: 0.586500 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.635000 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 003 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.656000 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.628000 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 005 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.666500 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 006 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.644500 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.633500 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.659500 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 009 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.641000 | 0.158 sec/iter\n",
      "Epoch: 303 | Batch: 010 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.597270 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 304 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.620000 | 0.159 sec/iter\n",
      "Epoch: 304 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.623000 | 0.159 sec/iter\n",
      "Epoch: 304 | Batch: 002 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.634000 | 0.159 sec/iter\n",
      "Epoch: 304 | Batch: 003 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.612500 | 0.159 sec/iter\n",
      "Epoch: 304 | Batch: 004 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.625000 | 0.159 sec/iter\n",
      "Epoch: 304 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 304 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.630500 | 0.158 sec/iter\n",
      "Epoch: 304 | Batch: 007 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.645500 | 0.158 sec/iter\n",
      "Epoch: 304 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.639500 | 0.158 sec/iter\n",
      "Epoch: 304 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.631500 | 0.158 sec/iter\n",
      "Epoch: 304 | Batch: 010 / 011 | Total loss: 1.103 | Reg loss: 0.045 | Tree loss: 1.103 | Accuracy: 0.593857 | 0.158 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 305 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.624000 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.616500 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.612500 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.630500 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 004 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.642000 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.628500 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 006 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.614000 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.634000 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.650500 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.651000 | 0.159 sec/iter\n",
      "Epoch: 305 | Batch: 010 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.658703 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 306 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.622000 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 001 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 002 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.626000 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 004 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.641500 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 005 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.623500 | 0.159 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 306 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.655000 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.654000 | 0.159 sec/iter\n",
      "Epoch: 306 | Batch: 010 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.651877 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 307 | Batch: 000 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.631000 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.622000 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.628500 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.637500 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.649000 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.658000 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 009 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.629500 | 0.159 sec/iter\n",
      "Epoch: 307 | Batch: 010 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.614334 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 308 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.642000 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 001 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.610000 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.627500 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 003 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.649000 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.639500 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 005 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.646000 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.631000 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.620500 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.613500 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 009 / 011 | Total loss: 0.980 | Reg loss: 0.045 | Tree loss: 0.980 | Accuracy: 0.661000 | 0.159 sec/iter\n",
      "Epoch: 308 | Batch: 010 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.651877 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 309 | Batch: 000 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.604000 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.642000 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.621500 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.624500 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 004 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.650500 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 005 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.637000 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.626000 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.625000 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.638000 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 309 | Batch: 010 / 011 | Total loss: 0.978 | Reg loss: 0.045 | Tree loss: 0.978 | Accuracy: 0.645051 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 310 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.627000 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.617500 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 002 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.600000 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 004 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.657000 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.639500 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 008 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.633000 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.631000 | 0.159 sec/iter\n",
      "Epoch: 310 | Batch: 010 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.665529 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 311 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.624000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.649500 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.636500 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 007 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.649000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.652000 | 0.16 sec/iter\n",
      "Epoch: 311 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.627986 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 312 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.596000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 001 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.618000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.653000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 003 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.615000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.627000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.660000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 006 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.658000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.646500 | 0.16 sec/iter\n",
      "Epoch: 312 | Batch: 010 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.651877 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 313 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.623000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.620500 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 005 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.625000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 007 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.654000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 008 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.645500 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.653000 | 0.16 sec/iter\n",
      "Epoch: 313 | Batch: 010 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.634812 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 314 | Batch: 000 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 314 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.612000 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 002 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.607500 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.616000 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 007 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.660000 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.649500 | 0.16 sec/iter\n",
      "Epoch: 314 | Batch: 010 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.627986 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 315 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.611500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.617500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 003 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.641500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 005 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 008 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 009 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 315 | Batch: 010 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.610922 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 316 | Batch: 000 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 002 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.612500 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 005 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.600500 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 006 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.646000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 007 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 316 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.645051 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 317 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.612000 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.627000 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 317 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.636500 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 006 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.615000 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 008 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.663500 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 317 | Batch: 010 / 011 | Total loss: 0.971 | Reg loss: 0.045 | Tree loss: 0.971 | Accuracy: 0.672355 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 318 | Batch: 000 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 001 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.613000 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 002 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.611000 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 003 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 004 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 007 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 008 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.658500 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.655500 | 0.161 sec/iter\n",
      "Epoch: 318 | Batch: 010 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.593857 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 319 | Batch: 000 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.606000 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 002 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 003 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 005 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.649500 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 008 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 319 | Batch: 010 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.638225 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 320 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.641500 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.621500 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.643500 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 004 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.656000 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 007 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.625000 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 008 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.625000 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 320 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.638225 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 321 | Batch: 000 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.618500 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.611500 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.647500 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 321 | Batch: 010 / 011 | Total loss: 0.975 | Reg loss: 0.045 | Tree loss: 0.975 | Accuracy: 0.662116 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 322 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.650000 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.620500 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 008 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.643500 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 322 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 322 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.631399 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 323 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 003 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.644500 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.636500 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 008 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 009 / 011 | Total loss: 0.980 | Reg loss: 0.045 | Tree loss: 0.980 | Accuracy: 0.655000 | 0.161 sec/iter\n",
      "Epoch: 323 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.600683 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 324 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 001 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.613000 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.625500 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 003 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.628000 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.643500 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 007 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.641500 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 008 / 011 | Total loss: 0.980 | Reg loss: 0.045 | Tree loss: 0.980 | Accuracy: 0.673500 | 0.162 sec/iter\n",
      "Epoch: 324 | Batch: 009 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.655000 | 0.161 sec/iter\n",
      "Epoch: 324 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.665529 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 325 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.605500 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 001 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 002 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.625000 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 003 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.635000 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.644000 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 005 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.661000 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.639000 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.631500 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 008 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.622500 | 0.162 sec/iter\n",
      "Epoch: 325 | Batch: 010 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.651877 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 326 | Batch: 000 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.609000 | 0.162 sec/iter\n",
      "Epoch: 326 | Batch: 001 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 326 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 326 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.644500 | 0.162 sec/iter\n",
      "Epoch: 326 | Batch: 004 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.653500 | 0.162 sec/iter\n",
      "Epoch: 326 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 326 | Batch: 006 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 326 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 326 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.642000 | 0.161 sec/iter\n",
      "Epoch: 326 | Batch: 009 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.616500 | 0.161 sec/iter\n",
      "Epoch: 326 | Batch: 010 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.634812 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 327 | Batch: 000 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.619500 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.618500 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.613500 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 005 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.657000 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 006 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.661000 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.650000 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 008 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.640000 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 009 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.659500 | 0.161 sec/iter\n",
      "Epoch: 327 | Batch: 010 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.662116 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 328 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.613500 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.607000 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.620000 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.638500 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.642500 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.641500 | 0.162 sec/iter\n",
      "Epoch: 328 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 328 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 328 | Batch: 009 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.655000 | 0.161 sec/iter\n",
      "Epoch: 328 | Batch: 010 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.645051 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 329 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.626000 | 0.162 sec/iter\n",
      "Epoch: 329 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.610000 | 0.162 sec/iter\n",
      "Epoch: 329 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.617500 | 0.162 sec/iter\n",
      "Epoch: 329 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 329 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.619500 | 0.162 sec/iter\n",
      "Epoch: 329 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.656500 | 0.161 sec/iter\n",
      "Epoch: 329 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 329 | Batch: 007 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 329 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.648500 | 0.161 sec/iter\n",
      "Epoch: 329 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.659000 | 0.161 sec/iter\n",
      "Epoch: 329 | Batch: 010 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.651877 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 330 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.615500 | 0.162 sec/iter\n",
      "Epoch: 330 | Batch: 001 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.602000 | 0.162 sec/iter\n",
      "Epoch: 330 | Batch: 002 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.605000 | 0.162 sec/iter\n",
      "Epoch: 330 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.632500 | 0.162 sec/iter\n",
      "Epoch: 330 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 330 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 330 | Batch: 006 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.654000 | 0.161 sec/iter\n",
      "Epoch: 330 | Batch: 007 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 330 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 330 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 330 | Batch: 010 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.621160 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 331 | Batch: 000 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.617500 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.612500 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.610000 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.609500 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 005 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 006 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.647500 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 331 | Batch: 010 / 011 | Total loss: 0.975 | Reg loss: 0.045 | Tree loss: 0.975 | Accuracy: 0.699659 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 332 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.609000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 002 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.612000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.605500 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.603000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.620500 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.657000 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.660500 | 0.161 sec/iter\n",
      "Epoch: 332 | Batch: 010 / 011 | Total loss: 0.956 | Reg loss: 0.045 | Tree loss: 0.956 | Accuracy: 0.692833 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 333 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.611000 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 001 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.599000 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 002 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 004 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.623000 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 333 | Batch: 006 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.613000 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 007 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.660500 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 009 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 333 | Batch: 010 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.679181 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 334 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.606000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 001 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.609500 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 002 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.619500 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 005 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 006 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 007 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.655000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 009 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.667000 | 0.161 sec/iter\n",
      "Epoch: 334 | Batch: 010 / 011 | Total loss: 0.968 | Reg loss: 0.045 | Tree loss: 0.968 | Accuracy: 0.689420 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 335 | Batch: 000 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.606500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 002 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.613500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.614500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 004 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.639500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 008 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 009 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 335 | Batch: 010 / 011 | Total loss: 0.980 | Reg loss: 0.045 | Tree loss: 0.980 | Accuracy: 0.672355 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 336 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.613500 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 002 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.648000 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 006 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.613500 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.624000 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 008 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.646000 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.647000 | 0.161 sec/iter\n",
      "Epoch: 336 | Batch: 010 / 011 | Total loss: 0.984 | Reg loss: 0.045 | Tree loss: 0.984 | Accuracy: 0.668942 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 337 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.609500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 001 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.606500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 002 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 005 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.597500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 007 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.644500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.648500 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.656000 | 0.161 sec/iter\n",
      "Epoch: 337 | Batch: 010 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.617747 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 338 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 001 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.621500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 003 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.652500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 004 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.627500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.650500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 007 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.647000 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.661500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.644500 | 0.161 sec/iter\n",
      "Epoch: 338 | Batch: 010 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.645051 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 339 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.620500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.618500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 005 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 007 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 339 | Batch: 010 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.645051 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 340 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 002 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.624000 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.647500 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.640000 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 007 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.642000 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 008 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 009 / 011 | Total loss: 0.989 | Reg loss: 0.045 | Tree loss: 0.989 | Accuracy: 0.653000 | 0.161 sec/iter\n",
      "Epoch: 340 | Batch: 010 / 011 | Total loss: 0.958 | Reg loss: 0.045 | Tree loss: 0.958 | Accuracy: 0.672355 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 341 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.620500 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.614000 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 002 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 004 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 005 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.658000 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.632000 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 009 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.645500 | 0.161 sec/iter\n",
      "Epoch: 341 | Batch: 010 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.627986 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 342 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.606000 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 003 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.661500 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 004 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 005 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.641500 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.650000 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 009 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.615000 | 0.161 sec/iter\n",
      "Epoch: 342 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.590444 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 343 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.639500 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.627500 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 007 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.609500 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 008 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.650000 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 343 | Batch: 010 / 011 | Total loss: 1.097 | Reg loss: 0.045 | Tree loss: 1.097 | Accuracy: 0.563140 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 344 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.617000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.637000 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 344 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.617000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.649000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 005 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.653500 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 008 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.650000 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 344 | Batch: 010 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.576792 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 345 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 001 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.616500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 002 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.621500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 004 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 005 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.655500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.644500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 345 | Batch: 010 / 011 | Total loss: 0.955 | Reg loss: 0.045 | Tree loss: 0.955 | Accuracy: 0.675768 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 346 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.616000 | 0.161 sec/iter\n",
      "Epoch: 346 | Batch: 001 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 346 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 346 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 006 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 007 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.650000 | 0.16 sec/iter\n",
      "Epoch: 346 | Batch: 010 / 011 | Total loss: 0.985 | Reg loss: 0.045 | Tree loss: 0.985 | Accuracy: 0.682594 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 347 | Batch: 000 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.622500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 003 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 004 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.651500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 006 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.651500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.647500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 008 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.616000 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 009 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.644500 | 0.16 sec/iter\n",
      "Epoch: 347 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.621160 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 348 | Batch: 000 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 002 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.605000 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.651500 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 005 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.653000 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.643500 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.650500 | 0.16 sec/iter\n",
      "Epoch: 348 | Batch: 010 / 011 | Total loss: 0.958 | Reg loss: 0.045 | Tree loss: 0.958 | Accuracy: 0.679181 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 349 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.611000 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 001 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.616000 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 002 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.607500 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.629500 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 004 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.656000 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.622500 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.632000 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 349 | Batch: 008 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 349 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.631399 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 350 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.608000 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.635000 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 004 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.651500 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.629500 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 007 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.640000 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 008 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.662000 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.634000 | 0.16 sec/iter\n",
      "Epoch: 350 | Batch: 010 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.614334 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 351 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.595500 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 001 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 004 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.647000 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 005 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.622000 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.647500 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.663500 | 0.16 sec/iter\n",
      "Epoch: 351 | Batch: 010 / 011 | Total loss: 0.985 | Reg loss: 0.045 | Tree loss: 0.985 | Accuracy: 0.668942 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 352 | Batch: 000 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.623000 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.605000 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 005 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 006 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.641000 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 009 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 352 | Batch: 010 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.655290 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 353 | Batch: 000 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.601500 | 0.161 sec/iter\n",
      "Epoch: 353 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 353 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.612000 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 004 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.651000 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 005 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 006 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.620500 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 009 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.638000 | 0.16 sec/iter\n",
      "Epoch: 353 | Batch: 010 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.638225 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 354 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.600500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.635000 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.655500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 005 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.668500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 008 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.616000 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 354 | Batch: 010 / 011 | Total loss: 0.950 | Reg loss: 0.045 | Tree loss: 0.950 | Accuracy: 0.655290 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 355 | Batch: 000 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.618000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.629500 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 003 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.643500 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.649000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.637000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.623000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 007 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.654000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 008 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 355 | Batch: 010 / 011 | Total loss: 0.978 | Reg loss: 0.045 | Tree loss: 0.978 | Accuracy: 0.672355 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 356 | Batch: 000 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.615500 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 003 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.641000 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.639000 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 009 / 011 | Total loss: 0.987 | Reg loss: 0.045 | Tree loss: 0.987 | Accuracy: 0.656500 | 0.16 sec/iter\n",
      "Epoch: 356 | Batch: 010 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.675768 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 357 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.622000 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.602000 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 002 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.629500 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.614500 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 006 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.638000 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 007 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.651000 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 008 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.639000 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 009 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 357 | Batch: 010 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.638225 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 358 | Batch: 000 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.604000 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.599500 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 002 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.645500 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.653000 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 006 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.642500 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.650000 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.655500 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 009 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 358 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.665529 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 359 | Batch: 000 / 011 | Total loss: 1.102 | Reg loss: 0.045 | Tree loss: 1.102 | Accuracy: 0.606000 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.627000 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 002 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.621500 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 007 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.646500 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.655000 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.648500 | 0.16 sec/iter\n",
      "Epoch: 359 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.634812 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 360 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.607500 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.597000 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.621000 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 004 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.621500 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.635000 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.647500 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.659500 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.668500 | 0.16 sec/iter\n",
      "Epoch: 360 | Batch: 010 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.696246 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 361 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.610500 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.627000 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.606000 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 006 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 007 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.647000 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.656000 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.662500 | 0.16 sec/iter\n",
      "Epoch: 361 | Batch: 010 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.675768 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 362 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.605500 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.613500 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.617500 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 004 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.625000 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.626000 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 007 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.655500 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 008 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.654000 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 362 | Batch: 010 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.624573 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 363 | Batch: 000 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 001 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.644500 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 002 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.641000 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 004 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.644500 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 007 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.627000 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 008 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 363 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.658703 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 364 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.613000 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 001 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 003 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.654500 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.634000 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.651000 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 364 | Batch: 010 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.682594 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 365 | Batch: 000 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.606000 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.625000 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 002 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.612500 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.626000 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 006 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 007 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.648000 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.663500 | 0.16 sec/iter\n",
      "Epoch: 365 | Batch: 010 / 011 | Total loss: 0.973 | Reg loss: 0.045 | Tree loss: 0.973 | Accuracy: 0.665529 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 366 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.626000 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.625500 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.647000 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.639000 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 006 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 007 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 008 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 366 | Batch: 010 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.648464 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 367 | Batch: 000 / 011 | Total loss: 1.099 | Reg loss: 0.045 | Tree loss: 1.099 | Accuracy: 0.597000 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 001 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.640500 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.634000 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.636500 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 367 | Batch: 010 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.668942 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 368 | Batch: 000 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 002 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 005 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.612000 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 007 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 008 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.641000 | 0.16 sec/iter\n",
      "Epoch: 368 | Batch: 010 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.679181 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 369 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.606500 | 0.16 sec/iter\n",
      "Epoch: 369 | Batch: 001 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.613500 | 0.16 sec/iter\n",
      "Epoch: 369 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.648000 | 0.16 sec/iter\n",
      "Epoch: 369 | Batch: 003 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 369 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.643000 | 0.159 sec/iter\n",
      "Epoch: 369 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.632500 | 0.159 sec/iter\n",
      "Epoch: 369 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.640000 | 0.159 sec/iter\n",
      "Epoch: 369 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.633500 | 0.159 sec/iter\n",
      "Epoch: 369 | Batch: 008 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.612500 | 0.159 sec/iter\n",
      "Epoch: 369 | Batch: 009 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.645500 | 0.159 sec/iter\n",
      "Epoch: 369 | Batch: 010 / 011 | Total loss: 0.985 | Reg loss: 0.045 | Tree loss: 0.985 | Accuracy: 0.648464 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 370 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.609000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 001 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.631500 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 003 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.624000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 005 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.638000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.620500 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.618000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 008 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.617000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 009 / 011 | Total loss: 0.987 | Reg loss: 0.045 | Tree loss: 0.987 | Accuracy: 0.656000 | 0.159 sec/iter\n",
      "Epoch: 370 | Batch: 010 / 011 | Total loss: 0.979 | Reg loss: 0.045 | Tree loss: 0.979 | Accuracy: 0.634812 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 371 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.612000 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 001 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.629000 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.631000 | 0.159 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 371 | Batch: 003 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.613500 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.643500 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.655500 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.630000 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 007 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.636000 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.644000 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.644000 | 0.159 sec/iter\n",
      "Epoch: 371 | Batch: 010 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.665529 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 372 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.616500 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 001 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.628000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.623500 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 003 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.637000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.631000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.631000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 006 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.643000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.617000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.651000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.625000 | 0.159 sec/iter\n",
      "Epoch: 372 | Batch: 010 / 011 | Total loss: 0.949 | Reg loss: 0.045 | Tree loss: 0.949 | Accuracy: 0.668942 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 373 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.612500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 001 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.641500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.628000 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.621500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.638500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.634500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.637500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.620000 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.643000 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 009 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.640500 | 0.159 sec/iter\n",
      "Epoch: 373 | Batch: 010 / 011 | Total loss: 0.968 | Reg loss: 0.045 | Tree loss: 0.968 | Accuracy: 0.658703 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 374 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.621500 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 002 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.606500 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.602000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.615000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 005 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.633000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.624500 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.625000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.663000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 009 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.678000 | 0.159 sec/iter\n",
      "Epoch: 374 | Batch: 010 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.686007 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 375 | Batch: 000 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.611000 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.631500 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.612500 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.640000 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.614000 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 005 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.627000 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.625500 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.633000 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.659500 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.662500 | 0.159 sec/iter\n",
      "Epoch: 375 | Batch: 010 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.638225 | 0.159 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 376 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 001 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 002 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.603000 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 004 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 005 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.613000 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.622000 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 007 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.636000 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 376 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.649000 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.650500 | 0.16 sec/iter\n",
      "Epoch: 376 | Batch: 010 / 011 | Total loss: 0.973 | Reg loss: 0.045 | Tree loss: 0.973 | Accuracy: 0.679181 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 377 | Batch: 000 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.619000 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 001 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.612000 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.611500 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.638500 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 005 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 006 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 007 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.624000 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 009 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.655000 | 0.16 sec/iter\n",
      "Epoch: 377 | Batch: 010 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.648464 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 378 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.626000 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 001 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.592000 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.637000 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 003 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.628500 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.614000 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 005 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.642500 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 007 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.654500 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 008 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.643500 | 0.16 sec/iter\n",
      "Epoch: 378 | Batch: 010 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.692833 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 379 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.610500 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.605500 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 002 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.618000 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.614500 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 004 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.640000 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 005 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.640000 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.663500 | 0.16 sec/iter\n",
      "Epoch: 379 | Batch: 010 / 011 | Total loss: 0.944 | Reg loss: 0.045 | Tree loss: 0.944 | Accuracy: 0.709898 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 380 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.607500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 001 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 004 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.629000 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.613500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.645500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.667500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.667500 | 0.16 sec/iter\n",
      "Epoch: 380 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.655290 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 381 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.627500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 002 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.616500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.619500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.625000 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 005 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.622500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 006 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.656000 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 007 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.660500 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 009 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.668000 | 0.16 sec/iter\n",
      "Epoch: 381 | Batch: 010 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.675768 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 382 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.605500 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.620500 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.654000 | 0.16 sec/iter\n",
      "Epoch: 382 | Batch: 010 / 011 | Total loss: 0.964 | Reg loss: 0.045 | Tree loss: 0.964 | Accuracy: 0.658703 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 383 | Batch: 000 / 011 | Total loss: 1.097 | Reg loss: 0.045 | Tree loss: 1.097 | Accuracy: 0.612500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.616500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.621500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.653500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 006 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.645500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.626000 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 008 / 011 | Total loss: 0.986 | Reg loss: 0.045 | Tree loss: 0.986 | Accuracy: 0.666000 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 009 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.664500 | 0.16 sec/iter\n",
      "Epoch: 383 | Batch: 010 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.672355 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 384 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.601000 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 001 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.645000 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 002 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.614500 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 005 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.643500 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.630500 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.659500 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.658000 | 0.16 sec/iter\n",
      "Epoch: 384 | Batch: 010 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.624573 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 385 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.611000 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 002 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.656500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.624000 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 004 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.633000 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.613500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.624500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.654500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 009 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.655500 | 0.16 sec/iter\n",
      "Epoch: 385 | Batch: 010 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.634812 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 386 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.605000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 003 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.613000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 004 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 005 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.652000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 007 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.656500 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 386 | Batch: 010 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.624573 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 387 | Batch: 000 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.618500 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 002 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.608500 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.620000 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 387 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 005 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.657500 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.624000 | 0.161 sec/iter\n",
      "Epoch: 387 | Batch: 010 / 011 | Total loss: 0.984 | Reg loss: 0.045 | Tree loss: 0.984 | Accuracy: 0.679181 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 388 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.616500 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.597500 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 002 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.607000 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 004 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.648000 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.639500 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 008 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.650500 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.656000 | 0.161 sec/iter\n",
      "Epoch: 388 | Batch: 010 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.682594 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 389 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.616500 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.620500 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 006 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.627500 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 389 | Batch: 010 / 011 | Total loss: 0.938 | Reg loss: 0.045 | Tree loss: 0.938 | Accuracy: 0.658703 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 390 | Batch: 000 / 011 | Total loss: 1.096 | Reg loss: 0.045 | Tree loss: 1.096 | Accuracy: 0.613000 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 001 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.606000 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.639500 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 004 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.643500 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 006 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 007 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 009 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.650500 | 0.161 sec/iter\n",
      "Epoch: 390 | Batch: 010 / 011 | Total loss: 0.953 | Reg loss: 0.045 | Tree loss: 0.953 | Accuracy: 0.699659 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 391 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.610000 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 003 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.643500 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 005 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 007 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 009 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.656500 | 0.161 sec/iter\n",
      "Epoch: 391 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.668942 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 392 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.607000 | 0.162 sec/iter\n",
      "Epoch: 392 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.611000 | 0.162 sec/iter\n",
      "Epoch: 392 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.625000 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 004 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 006 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.640000 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.636000 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 392 | Batch: 009 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.639500 | 0.161 sec/iter\n",
      "Epoch: 392 | Batch: 010 / 011 | Total loss: 0.989 | Reg loss: 0.045 | Tree loss: 0.989 | Accuracy: 0.641638 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 393 | Batch: 000 / 011 | Total loss: 1.096 | Reg loss: 0.045 | Tree loss: 1.096 | Accuracy: 0.613500 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.619500 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 002 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 003 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.646000 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 005 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.640500 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.618000 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.633000 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 008 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.653000 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 393 | Batch: 010 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.658703 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 394 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.602500 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 003 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 008 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 009 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.676000 | 0.162 sec/iter\n",
      "Epoch: 394 | Batch: 010 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.610922 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 395 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.609000 | 0.162 sec/iter\n",
      "Epoch: 395 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 395 | Batch: 002 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.631500 | 0.162 sec/iter\n",
      "Epoch: 395 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.606000 | 0.162 sec/iter\n",
      "Epoch: 395 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.645500 | 0.161 sec/iter\n",
      "Epoch: 395 | Batch: 005 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 395 | Batch: 006 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.632000 | 0.161 sec/iter\n",
      "Epoch: 395 | Batch: 007 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.665000 | 0.161 sec/iter\n",
      "Epoch: 395 | Batch: 008 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 395 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 395 | Batch: 010 / 011 | Total loss: 0.956 | Reg loss: 0.045 | Tree loss: 0.956 | Accuracy: 0.706485 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 396 | Batch: 000 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.627000 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.615000 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.625000 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.621500 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 005 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.643000 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.634500 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 007 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.623500 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.659000 | 0.162 sec/iter\n",
      "Epoch: 396 | Batch: 010 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.682594 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 397 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.613500 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.625000 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 002 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.637500 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.654000 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.627000 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.639000 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.630000 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.621500 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.656500 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 397 | Batch: 010 / 011 | Total loss: 0.927 | Reg loss: 0.045 | Tree loss: 0.927 | Accuracy: 0.716724 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 398 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.599000 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 002 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.652500 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 004 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.663500 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.635000 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 008 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.641500 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 009 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.637000 | 0.162 sec/iter\n",
      "Epoch: 398 | Batch: 010 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.658703 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 399 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.609000 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.631000 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.596000 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.616500 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.631500 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.628000 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 007 / 011 | Total loss: 0.973 | Reg loss: 0.045 | Tree loss: 0.973 | Accuracy: 0.661500 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.658000 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 009 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.655000 | 0.162 sec/iter\n",
      "Epoch: 399 | Batch: 010 / 011 | Total loss: 0.982 | Reg loss: 0.045 | Tree loss: 0.982 | Accuracy: 0.692833 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 400 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.603500 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.601000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.617500 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.649000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.647500 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 007 / 011 | Total loss: 0.981 | Reg loss: 0.045 | Tree loss: 0.981 | Accuracy: 0.663000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 009 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 400 | Batch: 010 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.655290 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 401 | Batch: 000 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.616000 | 0.163 sec/iter\n",
      "Epoch: 401 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.642000 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.613500 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 003 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.644000 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 005 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.638500 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 006 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.619000 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.642000 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.643000 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 401 | Batch: 010 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.627986 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 402 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.610000 | 0.163 sec/iter\n",
      "Epoch: 402 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.634000 | 0.163 sec/iter\n",
      "Epoch: 402 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.648500 | 0.163 sec/iter\n",
      "Epoch: 402 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.628500 | 0.163 sec/iter\n",
      "Epoch: 402 | Batch: 004 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.613000 | 0.163 sec/iter\n",
      "Epoch: 402 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.645000 | 0.163 sec/iter\n",
      "Epoch: 402 | Batch: 006 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 402 | Batch: 007 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.639000 | 0.162 sec/iter\n",
      "Epoch: 402 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.638500 | 0.162 sec/iter\n",
      "Epoch: 402 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.620000 | 0.162 sec/iter\n",
      "Epoch: 402 | Batch: 010 / 011 | Total loss: 0.951 | Reg loss: 0.045 | Tree loss: 0.951 | Accuracy: 0.692833 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 403 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.600000 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.634000 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.613000 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.650000 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.632500 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.647000 | 0.163 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 403 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.639000 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.628500 | 0.163 sec/iter\n",
      "Epoch: 403 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.659000 | 0.162 sec/iter\n",
      "Epoch: 403 | Batch: 010 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.617747 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 404 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.607000 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 002 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.645000 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.648500 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.648000 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.609500 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.622000 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.644500 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.649000 | 0.162 sec/iter\n",
      "Epoch: 404 | Batch: 010 / 011 | Total loss: 0.980 | Reg loss: 0.045 | Tree loss: 0.980 | Accuracy: 0.662116 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 405 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.605500 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.625000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 003 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.639000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.616500 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 005 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.644500 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.633000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.625000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.673000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 009 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 405 | Batch: 010 / 011 | Total loss: 0.973 | Reg loss: 0.045 | Tree loss: 0.973 | Accuracy: 0.662116 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 406 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.605500 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 002 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.631500 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.631000 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 005 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.662000 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 009 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.660000 | 0.162 sec/iter\n",
      "Epoch: 406 | Batch: 010 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.624573 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 407 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.605500 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.613000 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.615000 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 008 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.656000 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 009 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 407 | Batch: 010 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.641638 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 408 | Batch: 000 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.616000 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.606000 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 003 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 004 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.664500 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.665000 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 007 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.621000 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 009 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.643500 | 0.162 sec/iter\n",
      "Epoch: 408 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.583618 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 409 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.607500 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 002 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.608000 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.628000 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 004 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.653000 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 006 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 007 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.649500 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.646000 | 0.162 sec/iter\n",
      "Epoch: 409 | Batch: 010 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.668942 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 410 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.610500 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 001 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 002 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.633000 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 004 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.649000 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 005 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 006 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.653000 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.642000 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 008 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.668000 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.651500 | 0.162 sec/iter\n",
      "Epoch: 410 | Batch: 010 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.621160 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 411 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.616500 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 001 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.615000 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.620500 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.624500 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.617000 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 006 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.643000 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.642500 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 008 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.654500 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 411 | Batch: 010 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.648464 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 412 | Batch: 000 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.616500 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.626000 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.643000 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 003 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 004 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 006 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 007 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.646000 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.668500 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 412 | Batch: 010 / 011 | Total loss: 0.970 | Reg loss: 0.045 | Tree loss: 0.970 | Accuracy: 0.686007 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 413 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.612000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.621000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 002 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.597500 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 003 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.631000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.631000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.634000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 007 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.651000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 008 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.661000 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.647500 | 0.162 sec/iter\n",
      "Epoch: 413 | Batch: 010 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.610922 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 414 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.603000 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 001 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.637000 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.633000 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.633000 | 0.162 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 414 | Batch: 005 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.626000 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.640500 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.648500 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.655500 | 0.162 sec/iter\n",
      "Epoch: 414 | Batch: 010 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.634812 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 415 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.610500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 001 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.614500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 003 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.625500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.627000 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.609000 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.640500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.660000 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.649500 | 0.162 sec/iter\n",
      "Epoch: 415 | Batch: 010 / 011 | Total loss: 0.984 | Reg loss: 0.045 | Tree loss: 0.984 | Accuracy: 0.645051 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 416 | Batch: 000 / 011 | Total loss: 1.084 | Reg loss: 0.045 | Tree loss: 1.084 | Accuracy: 0.609500 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 001 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.608000 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 003 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.632500 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 005 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 006 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.599500 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.646500 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 009 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.648000 | 0.162 sec/iter\n",
      "Epoch: 416 | Batch: 010 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.675768 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 417 | Batch: 000 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.606000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.619000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.607500 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 003 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 004 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.642500 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 006 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.633000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.652000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 009 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.652000 | 0.162 sec/iter\n",
      "Epoch: 417 | Batch: 010 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.610922 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 418 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.622000 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 001 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.605500 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 002 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 003 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.641000 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.637500 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.640500 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 008 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.619000 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.633000 | 0.162 sec/iter\n",
      "Epoch: 418 | Batch: 010 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.641638 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 419 | Batch: 000 / 011 | Total loss: 1.094 | Reg loss: 0.045 | Tree loss: 1.094 | Accuracy: 0.605000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.609000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 002 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.646000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.631500 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 004 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.613000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.634000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.631000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.642500 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 008 / 011 | Total loss: 0.989 | Reg loss: 0.045 | Tree loss: 0.989 | Accuracy: 0.666500 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 009 / 011 | Total loss: 0.989 | Reg loss: 0.045 | Tree loss: 0.989 | Accuracy: 0.668000 | 0.162 sec/iter\n",
      "Epoch: 419 | Batch: 010 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.645051 | 0.162 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 420 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.612000 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 001 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.654500 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.620500 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.650500 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 005 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.638500 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.634500 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 008 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.651000 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 009 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.622000 | 0.162 sec/iter\n",
      "Epoch: 420 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.627986 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 421 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.635000 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 002 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 003 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 005 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.624500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 006 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.644500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.641000 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.639000 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.646500 | 0.162 sec/iter\n",
      "Epoch: 421 | Batch: 010 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.600683 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 422 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.045 | Tree loss: 1.089 | Accuracy: 0.601500 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.617000 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 002 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.613000 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.634500 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 004 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.646500 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.617500 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 006 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.619500 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.660500 | 0.162 sec/iter\n",
      "Epoch: 422 | Batch: 009 / 011 | Total loss: 0.989 | Reg loss: 0.045 | Tree loss: 0.989 | Accuracy: 0.667000 | 0.161 sec/iter\n",
      "Epoch: 422 | Batch: 010 / 011 | Total loss: 0.961 | Reg loss: 0.045 | Tree loss: 0.961 | Accuracy: 0.672355 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 423 | Batch: 000 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.632500 | 0.162 sec/iter\n",
      "Epoch: 423 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.606500 | 0.162 sec/iter\n",
      "Epoch: 423 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 003 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.636500 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 005 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 007 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.658000 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.644500 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 009 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.642000 | 0.161 sec/iter\n",
      "Epoch: 423 | Batch: 010 / 011 | Total loss: 0.986 | Reg loss: 0.045 | Tree loss: 0.986 | Accuracy: 0.655290 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 424 | Batch: 000 / 011 | Total loss: 1.102 | Reg loss: 0.045 | Tree loss: 1.102 | Accuracy: 0.599500 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 001 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.603500 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 002 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.619500 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.652000 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.654000 | 0.161 sec/iter\n",
      "Epoch: 424 | Batch: 010 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.604096 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 425 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.596500 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 002 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.654500 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 425 | Batch: 003 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.646000 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 006 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.625000 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.638500 | 0.161 sec/iter\n",
      "Epoch: 425 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.583618 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 426 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.605500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 004 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.621500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 006 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.653500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 007 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 426 | Batch: 010 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.672355 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 427 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.611500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 001 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.608500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 006 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.652500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.652500 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 427 | Batch: 010 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.645051 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 428 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.608000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 003 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.614500 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 004 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 005 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.624000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.656000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.661000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 428 | Batch: 010 / 011 | Total loss: 0.987 | Reg loss: 0.045 | Tree loss: 0.987 | Accuracy: 0.641638 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 429 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 002 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.621500 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 003 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.617000 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 005 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.611500 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 006 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 007 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.653500 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.647000 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.652500 | 0.161 sec/iter\n",
      "Epoch: 429 | Batch: 010 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.668942 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 430 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 001 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.609500 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 002 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.608000 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 006 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.657500 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 007 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.655500 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 430 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.647000 | 0.161 sec/iter\n",
      "Epoch: 430 | Batch: 010 / 011 | Total loss: 0.979 | Reg loss: 0.045 | Tree loss: 0.979 | Accuracy: 0.665529 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 431 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.627500 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 002 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.609500 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.614500 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.645000 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.650500 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.648000 | 0.161 sec/iter\n",
      "Epoch: 431 | Batch: 010 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.641638 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 432 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.601000 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 001 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.607000 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.617500 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 004 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.656500 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 005 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.649000 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 009 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.649500 | 0.161 sec/iter\n",
      "Epoch: 432 | Batch: 010 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.607509 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 433 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.615000 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 001 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.618000 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.619500 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 003 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.622000 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 005 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 006 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 007 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.648500 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.652000 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.660500 | 0.161 sec/iter\n",
      "Epoch: 433 | Batch: 010 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.641638 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 434 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.615500 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 002 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.610000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 003 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.617000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 006 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.632000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 008 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.645500 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.673000 | 0.161 sec/iter\n",
      "Epoch: 434 | Batch: 010 / 011 | Total loss: 0.969 | Reg loss: 0.045 | Tree loss: 0.969 | Accuracy: 0.713311 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 435 | Batch: 000 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.601500 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.614500 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.604000 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 003 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.603500 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 005 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.654000 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.620000 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 007 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.641500 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.657500 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 009 / 011 | Total loss: 0.969 | Reg loss: 0.045 | Tree loss: 0.969 | Accuracy: 0.693000 | 0.161 sec/iter\n",
      "Epoch: 435 | Batch: 010 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.658703 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 436 | Batch: 000 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.588000 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 436 | Batch: 001 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.611000 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.601000 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 004 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 006 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.650500 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.646000 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 009 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.664000 | 0.161 sec/iter\n",
      "Epoch: 436 | Batch: 010 / 011 | Total loss: 0.969 | Reg loss: 0.045 | Tree loss: 0.969 | Accuracy: 0.692833 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 437 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 001 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.606000 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.614000 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 005 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.606500 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.652000 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.646000 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.654000 | 0.161 sec/iter\n",
      "Epoch: 437 | Batch: 010 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.648464 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 438 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.614000 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.611000 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 003 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 004 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 005 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 007 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 008 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.631500 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 438 | Batch: 010 / 011 | Total loss: 0.945 | Reg loss: 0.045 | Tree loss: 0.945 | Accuracy: 0.706485 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 439 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.596000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 001 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.621000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 003 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 004 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 005 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.648000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 007 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.633500 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.643500 | 0.161 sec/iter\n",
      "Epoch: 439 | Batch: 010 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.689420 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 440 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.610000 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 001 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 002 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.620000 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.649500 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.618500 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 008 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.650000 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 440 | Batch: 010 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.648464 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 441 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 001 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.605500 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.614500 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 003 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.608000 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 005 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.657500 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.616500 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 441 | Batch: 007 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.659000 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.663500 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 009 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.654000 | 0.161 sec/iter\n",
      "Epoch: 441 | Batch: 010 / 011 | Total loss: 0.949 | Reg loss: 0.045 | Tree loss: 0.949 | Accuracy: 0.696246 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 442 | Batch: 000 / 011 | Total loss: 1.095 | Reg loss: 0.045 | Tree loss: 1.095 | Accuracy: 0.590000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.617000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 003 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.615500 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 004 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 005 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 006 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.642000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.664000 | 0.161 sec/iter\n",
      "Epoch: 442 | Batch: 010 / 011 | Total loss: 0.977 | Reg loss: 0.045 | Tree loss: 0.977 | Accuracy: 0.665529 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 443 | Batch: 000 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.614000 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 002 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 003 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.615500 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 004 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 006 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.649000 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 008 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 009 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.651500 | 0.161 sec/iter\n",
      "Epoch: 443 | Batch: 010 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.627986 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 444 | Batch: 000 / 011 | Total loss: 1.091 | Reg loss: 0.045 | Tree loss: 1.091 | Accuracy: 0.605000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 001 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 003 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.657000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 004 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 006 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.613000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 008 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.613500 | 0.161 sec/iter\n",
      "Epoch: 444 | Batch: 009 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.647500 | 0.16 sec/iter\n",
      "Epoch: 444 | Batch: 010 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.651877 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 445 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.603500 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 001 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.617000 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.649500 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.638500 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 007 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.662500 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.648500 | 0.161 sec/iter\n",
      "Epoch: 445 | Batch: 009 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.649000 | 0.16 sec/iter\n",
      "Epoch: 445 | Batch: 010 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.658703 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 446 | Batch: 000 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.604000 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.608500 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.651000 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 004 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.637000 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.633500 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.641500 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.637500 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.642000 | 0.16 sec/iter\n",
      "Epoch: 446 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.648464 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 447 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.620500 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 001 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.627000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.646000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 003 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.623000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 004 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.661000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.640000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.640000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 007 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.618500 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.623500 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 009 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 447 | Batch: 010 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.668942 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 448 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.615000 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 002 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 003 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 004 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.631500 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.622500 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.648500 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 007 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.614000 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 008 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.640500 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 009 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.644000 | 0.16 sec/iter\n",
      "Epoch: 448 | Batch: 010 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.641638 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 449 | Batch: 000 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.622500 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 001 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.632500 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 002 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.616500 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 004 / 011 | Total loss: 1.046 | Reg loss: 0.045 | Tree loss: 1.046 | Accuracy: 0.636000 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 005 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.651000 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.639500 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 008 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.640500 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.628000 | 0.16 sec/iter\n",
      "Epoch: 449 | Batch: 010 / 011 | Total loss: 0.990 | Reg loss: 0.045 | Tree loss: 0.990 | Accuracy: 0.658703 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 450 | Batch: 000 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.614000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.611000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 003 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.617000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.637000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.639000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 006 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.652500 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 007 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.640000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.635000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 009 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 450 | Batch: 010 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.634812 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 451 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 001 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.649500 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 002 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.610000 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.642500 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.620000 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 005 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.626500 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.608000 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 007 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.631000 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 008 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.632000 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 009 / 011 | Total loss: 0.988 | Reg loss: 0.045 | Tree loss: 0.988 | Accuracy: 0.661000 | 0.16 sec/iter\n",
      "Epoch: 451 | Batch: 010 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.655290 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 452 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.635500 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.606500 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.602000 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 004 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.624500 | 0.16 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 452 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.634500 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.617500 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.639000 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.643000 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 009 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.651000 | 0.16 sec/iter\n",
      "Epoch: 452 | Batch: 010 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.675768 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 453 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.607000 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 001 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 004 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.646500 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.638500 | 0.161 sec/iter\n",
      "Epoch: 453 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.630000 | 0.16 sec/iter\n",
      "Epoch: 453 | Batch: 010 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.648464 | 0.16 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 454 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.594000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.612000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 002 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 003 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.640000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 004 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.615500 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 006 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.642500 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 454 | Batch: 010 / 011 | Total loss: 0.956 | Reg loss: 0.045 | Tree loss: 0.956 | Accuracy: 0.658703 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 455 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.045 | Tree loss: 1.085 | Accuracy: 0.609000 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 001 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.619000 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.614500 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.609000 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 005 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 006 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.664000 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.649500 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 009 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 455 | Batch: 010 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.631399 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 456 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.612500 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 001 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.607000 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 002 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.638000 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 003 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.620500 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 004 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.639000 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.611000 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.611500 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 007 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 009 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.670500 | 0.161 sec/iter\n",
      "Epoch: 456 | Batch: 010 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.597270 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 457 | Batch: 000 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.624000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 001 / 011 | Total loss: 1.080 | Reg loss: 0.045 | Tree loss: 1.080 | Accuracy: 0.615000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 002 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.631000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 004 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 005 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.644500 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.624500 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 008 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.638500 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.652000 | 0.161 sec/iter\n",
      "Epoch: 457 | Batch: 010 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.621160 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 458 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.621500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 001 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.636500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 002 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.626000 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 005 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 006 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.643500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.641500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.639500 | 0.161 sec/iter\n",
      "Epoch: 458 | Batch: 010 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.665529 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 459 | Batch: 000 / 011 | Total loss: 1.086 | Reg loss: 0.045 | Tree loss: 1.086 | Accuracy: 0.616500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.640500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.634000 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.627000 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 008 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.629500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.652500 | 0.161 sec/iter\n",
      "Epoch: 459 | Batch: 010 / 011 | Total loss: 0.967 | Reg loss: 0.045 | Tree loss: 0.967 | Accuracy: 0.689420 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 460 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.615500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.622500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 003 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.645500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.643000 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.643500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.653500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 460 | Batch: 010 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.662116 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 461 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 001 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.629000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 003 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 004 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.642000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 005 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.623000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.644000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 007 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.635000 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.637500 | 0.161 sec/iter\n",
      "Epoch: 461 | Batch: 010 / 011 | Total loss: 0.965 | Reg loss: 0.045 | Tree loss: 0.965 | Accuracy: 0.668942 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 462 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.628500 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 001 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.641000 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 002 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.615500 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 004 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.634500 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 005 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.641500 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 007 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.664000 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.630000 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.635500 | 0.161 sec/iter\n",
      "Epoch: 462 | Batch: 010 / 011 | Total loss: 0.975 | Reg loss: 0.045 | Tree loss: 0.975 | Accuracy: 0.662116 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 463 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.615000 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 001 / 011 | Total loss: 1.048 | Reg loss: 0.045 | Tree loss: 1.048 | Accuracy: 0.642500 | 0.161 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 463 | Batch: 002 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.623500 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 004 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.616500 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.652500 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.648500 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 007 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 008 / 011 | Total loss: 0.987 | Reg loss: 0.045 | Tree loss: 0.987 | Accuracy: 0.651000 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.625500 | 0.161 sec/iter\n",
      "Epoch: 463 | Batch: 010 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.617747 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 464 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.624000 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.648500 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 003 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.637000 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 004 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.626500 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 005 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.633000 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 006 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.630500 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.628000 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 008 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.632500 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.636000 | 0.161 sec/iter\n",
      "Epoch: 464 | Batch: 010 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.648464 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 465 | Batch: 000 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.634500 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 002 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.619500 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.600000 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 004 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.611500 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 005 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.624000 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 006 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 008 / 011 | Total loss: 0.996 | Reg loss: 0.045 | Tree loss: 0.996 | Accuracy: 0.676500 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 009 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.650500 | 0.162 sec/iter\n",
      "Epoch: 465 | Batch: 010 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.672355 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 466 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.616000 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.616500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.622500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 003 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.629500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.634500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 005 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.611500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.643500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 007 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.648500 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.656000 | 0.162 sec/iter\n",
      "Epoch: 466 | Batch: 010 / 011 | Total loss: 0.969 | Reg loss: 0.045 | Tree loss: 0.969 | Accuracy: 0.668942 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 467 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.622500 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 002 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 003 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.617000 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 004 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.608000 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.642000 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.661000 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.646500 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.647000 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 467 | Batch: 010 / 011 | Total loss: 0.979 | Reg loss: 0.045 | Tree loss: 0.979 | Accuracy: 0.634812 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 468 | Batch: 000 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.616000 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.614000 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.603000 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 004 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.634500 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 006 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.640500 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 007 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.637000 | 0.162 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 468 | Batch: 008 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.660500 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 009 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 468 | Batch: 010 / 011 | Total loss: 0.941 | Reg loss: 0.045 | Tree loss: 0.941 | Accuracy: 0.706485 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 469 | Batch: 000 / 011 | Total loss: 1.081 | Reg loss: 0.045 | Tree loss: 1.081 | Accuracy: 0.610000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.616000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.604000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.611500 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 004 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.621500 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 005 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.621500 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 006 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.651000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 007 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.647000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.645000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.657000 | 0.162 sec/iter\n",
      "Epoch: 469 | Batch: 010 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.624573 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 470 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.619000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.627000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.645500 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 004 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 006 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.622500 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 007 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.620000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 008 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.645000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.635000 | 0.162 sec/iter\n",
      "Epoch: 470 | Batch: 010 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.617747 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 471 | Batch: 000 / 011 | Total loss: 1.104 | Reg loss: 0.045 | Tree loss: 1.104 | Accuracy: 0.602500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 001 / 011 | Total loss: 1.064 | Reg loss: 0.045 | Tree loss: 1.064 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 002 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.623500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 004 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 005 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.650000 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.620500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 008 / 011 | Total loss: 1.019 | Reg loss: 0.045 | Tree loss: 1.019 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.635500 | 0.162 sec/iter\n",
      "Epoch: 471 | Batch: 010 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.631399 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 472 | Batch: 000 / 011 | Total loss: 1.068 | Reg loss: 0.045 | Tree loss: 1.068 | Accuracy: 0.621000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.642000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 003 / 011 | Total loss: 1.056 | Reg loss: 0.045 | Tree loss: 1.056 | Accuracy: 0.621000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 004 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.653500 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.628000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.626500 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 007 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.643000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.635000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 009 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.639000 | 0.162 sec/iter\n",
      "Epoch: 472 | Batch: 010 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.627986 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 473 | Batch: 000 / 011 | Total loss: 1.087 | Reg loss: 0.045 | Tree loss: 1.087 | Accuracy: 0.599000 | 0.163 sec/iter\n",
      "Epoch: 473 | Batch: 001 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.632500 | 0.163 sec/iter\n",
      "Epoch: 473 | Batch: 002 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 473 | Batch: 003 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.641000 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 004 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.625500 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 006 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.631500 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 007 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.632000 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 473 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.614334 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 474 | Batch: 000 / 011 | Total loss: 1.070 | Reg loss: 0.045 | Tree loss: 1.070 | Accuracy: 0.619000 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 002 / 011 | Total loss: 1.050 | Reg loss: 0.045 | Tree loss: 1.050 | Accuracy: 0.634500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.641000 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 004 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.630500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.612500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 006 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.640500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 007 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.611500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 008 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.636500 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 009 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.637000 | 0.163 sec/iter\n",
      "Epoch: 474 | Batch: 010 / 011 | Total loss: 0.978 | Reg loss: 0.045 | Tree loss: 0.978 | Accuracy: 0.665529 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 475 | Batch: 000 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.610000 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 001 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.609000 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 002 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.619000 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 003 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.651500 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 004 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.636000 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 005 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.651500 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 006 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.626000 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.619500 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.642500 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 009 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.647000 | 0.163 sec/iter\n",
      "Epoch: 475 | Batch: 010 / 011 | Total loss: 0.959 | Reg loss: 0.045 | Tree loss: 0.959 | Accuracy: 0.686007 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 476 | Batch: 000 / 011 | Total loss: 1.092 | Reg loss: 0.045 | Tree loss: 1.092 | Accuracy: 0.595500 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.632000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.642500 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 003 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.650000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.634000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 005 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.611000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 007 / 011 | Total loss: 0.995 | Reg loss: 0.045 | Tree loss: 0.995 | Accuracy: 0.642000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 008 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.626000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 009 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.648000 | 0.163 sec/iter\n",
      "Epoch: 476 | Batch: 010 / 011 | Total loss: 0.985 | Reg loss: 0.045 | Tree loss: 0.985 | Accuracy: 0.675768 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 477 | Batch: 000 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.605500 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 001 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.625500 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 002 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.625000 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.638000 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 005 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.624500 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 006 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.629000 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 007 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.633000 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 008 / 011 | Total loss: 0.979 | Reg loss: 0.045 | Tree loss: 0.979 | Accuracy: 0.666500 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 009 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.659500 | 0.163 sec/iter\n",
      "Epoch: 477 | Batch: 010 / 011 | Total loss: 1.036 | Reg loss: 0.045 | Tree loss: 1.036 | Accuracy: 0.662116 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 478 | Batch: 000 / 011 | Total loss: 1.083 | Reg loss: 0.045 | Tree loss: 1.083 | Accuracy: 0.610000 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.624500 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.645000 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.637500 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 004 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.656500 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.623500 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.627500 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.626000 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 008 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.629000 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 009 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.624500 | 0.163 sec/iter\n",
      "Epoch: 478 | Batch: 010 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.600683 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 479 | Batch: 000 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.622500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.630500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.045 | Tree loss: 1.054 | Accuracy: 0.629500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 003 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.647500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 004 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.643500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 005 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.627500 | 0.163 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 479 | Batch: 006 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.632500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 007 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.645500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.618000 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.640500 | 0.163 sec/iter\n",
      "Epoch: 479 | Batch: 010 / 011 | Total loss: 0.984 | Reg loss: 0.045 | Tree loss: 0.984 | Accuracy: 0.689420 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 480 | Batch: 000 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.625000 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 001 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.639500 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.609500 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 003 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.648000 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.626500 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.621500 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.627000 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.630500 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 008 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.633000 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 009 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.633000 | 0.163 sec/iter\n",
      "Epoch: 480 | Batch: 010 / 011 | Total loss: 0.973 | Reg loss: 0.045 | Tree loss: 0.973 | Accuracy: 0.672355 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 481 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.615500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 001 / 011 | Total loss: 1.059 | Reg loss: 0.045 | Tree loss: 1.059 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 002 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.648500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.627500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 004 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.629500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 005 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 006 / 011 | Total loss: 0.993 | Reg loss: 0.045 | Tree loss: 0.993 | Accuracy: 0.641500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 007 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.637000 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.638500 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 009 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.643000 | 0.163 sec/iter\n",
      "Epoch: 481 | Batch: 010 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.655290 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 482 | Batch: 000 / 011 | Total loss: 1.062 | Reg loss: 0.045 | Tree loss: 1.062 | Accuracy: 0.625500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 001 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.624000 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 002 / 011 | Total loss: 1.060 | Reg loss: 0.045 | Tree loss: 1.060 | Accuracy: 0.631500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 003 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.640500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 004 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.647500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 005 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.647500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 006 / 011 | Total loss: 1.024 | Reg loss: 0.045 | Tree loss: 1.024 | Accuracy: 0.631500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 007 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.645000 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 008 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.623500 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 009 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.637000 | 0.163 sec/iter\n",
      "Epoch: 482 | Batch: 010 / 011 | Total loss: 0.936 | Reg loss: 0.045 | Tree loss: 0.936 | Accuracy: 0.651877 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 483 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.626500 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 001 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.604000 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 002 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.623500 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 003 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.641500 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 004 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.632000 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 005 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.623000 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 006 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.636000 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.640500 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 008 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.648000 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 009 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.638500 | 0.163 sec/iter\n",
      "Epoch: 483 | Batch: 010 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.621160 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 484 | Batch: 000 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.610500 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 001 / 011 | Total loss: 1.066 | Reg loss: 0.045 | Tree loss: 1.066 | Accuracy: 0.633000 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 002 / 011 | Total loss: 1.039 | Reg loss: 0.045 | Tree loss: 1.039 | Accuracy: 0.639500 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 003 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.648000 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 004 / 011 | Total loss: 1.026 | Reg loss: 0.045 | Tree loss: 1.026 | Accuracy: 0.647000 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 005 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.639500 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 006 / 011 | Total loss: 1.015 | Reg loss: 0.045 | Tree loss: 1.015 | Accuracy: 0.611500 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.614000 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 008 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.639500 | 0.163 sec/iter\n",
      "Epoch: 484 | Batch: 010 / 011 | Total loss: 1.011 | Reg loss: 0.045 | Tree loss: 1.011 | Accuracy: 0.651877 | 0.163 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 485 | Batch: 000 / 011 | Total loss: 1.088 | Reg loss: 0.045 | Tree loss: 1.088 | Accuracy: 0.608000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 001 / 011 | Total loss: 1.061 | Reg loss: 0.045 | Tree loss: 1.061 | Accuracy: 0.631500 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.638000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 003 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.637500 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 004 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.639000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.634000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 006 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.628000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.629500 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 008 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 009 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.639000 | 0.163 sec/iter\n",
      "Epoch: 485 | Batch: 010 / 011 | Total loss: 0.967 | Reg loss: 0.045 | Tree loss: 0.967 | Accuracy: 0.675768 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 486 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.607000 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 001 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.608500 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 002 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.636500 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 003 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.648500 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 004 / 011 | Total loss: 1.033 | Reg loss: 0.045 | Tree loss: 1.033 | Accuracy: 0.634500 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 006 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.638000 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 007 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.630500 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 008 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.638000 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 009 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 486 | Batch: 010 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.638225 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 487 | Batch: 000 / 011 | Total loss: 1.090 | Reg loss: 0.045 | Tree loss: 1.090 | Accuracy: 0.593000 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 001 / 011 | Total loss: 1.063 | Reg loss: 0.045 | Tree loss: 1.063 | Accuracy: 0.618500 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 002 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.623000 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.616500 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 004 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 005 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.641000 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 006 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 007 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.622000 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.647500 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 009 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.641500 | 0.163 sec/iter\n",
      "Epoch: 487 | Batch: 010 / 011 | Total loss: 0.965 | Reg loss: 0.045 | Tree loss: 0.965 | Accuracy: 0.682594 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 488 | Batch: 000 / 011 | Total loss: 1.098 | Reg loss: 0.045 | Tree loss: 1.098 | Accuracy: 0.582000 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.616500 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 002 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.619000 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 003 / 011 | Total loss: 1.035 | Reg loss: 0.045 | Tree loss: 1.035 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 004 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.628500 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 005 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.635500 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 006 / 011 | Total loss: 1.000 | Reg loss: 0.045 | Tree loss: 1.000 | Accuracy: 0.647000 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.635500 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 008 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.656000 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 009 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.660000 | 0.163 sec/iter\n",
      "Epoch: 488 | Batch: 010 / 011 | Total loss: 0.983 | Reg loss: 0.045 | Tree loss: 0.983 | Accuracy: 0.648464 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 489 | Batch: 000 / 011 | Total loss: 1.079 | Reg loss: 0.045 | Tree loss: 1.079 | Accuracy: 0.604000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 001 / 011 | Total loss: 1.067 | Reg loss: 0.045 | Tree loss: 1.067 | Accuracy: 0.611000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 002 / 011 | Total loss: 1.047 | Reg loss: 0.045 | Tree loss: 1.047 | Accuracy: 0.611500 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 003 / 011 | Total loss: 1.055 | Reg loss: 0.045 | Tree loss: 1.055 | Accuracy: 0.623000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 004 / 011 | Total loss: 0.998 | Reg loss: 0.045 | Tree loss: 0.998 | Accuracy: 0.650000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.624000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 006 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.632500 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 007 / 011 | Total loss: 1.021 | Reg loss: 0.045 | Tree loss: 1.021 | Accuracy: 0.624000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.644000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.663000 | 0.163 sec/iter\n",
      "Epoch: 489 | Batch: 010 / 011 | Total loss: 0.965 | Reg loss: 0.045 | Tree loss: 0.965 | Accuracy: 0.675768 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 490 | Batch: 000 / 011 | Total loss: 1.101 | Reg loss: 0.045 | Tree loss: 1.101 | Accuracy: 0.608500 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.045 | Tree loss: 1.065 | Accuracy: 0.628000 | 0.163 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 490 | Batch: 002 / 011 | Total loss: 1.045 | Reg loss: 0.045 | Tree loss: 1.045 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 003 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.655000 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 004 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.628000 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 005 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.620000 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.634500 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 007 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.632500 | 0.163 sec/iter\n",
      "Epoch: 490 | Batch: 008 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.640000 | 0.162 sec/iter\n",
      "Epoch: 490 | Batch: 009 / 011 | Total loss: 0.988 | Reg loss: 0.045 | Tree loss: 0.988 | Accuracy: 0.650500 | 0.162 sec/iter\n",
      "Epoch: 490 | Batch: 010 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.621160 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 491 | Batch: 000 / 011 | Total loss: 1.076 | Reg loss: 0.045 | Tree loss: 1.076 | Accuracy: 0.613000 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.639500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 002 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.636000 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.629500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 005 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.633500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 006 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.625500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.634500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 009 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.637500 | 0.163 sec/iter\n",
      "Epoch: 491 | Batch: 010 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.699659 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 492 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.626000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.607000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.045 | Tree loss: 1.051 | Accuracy: 0.613000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.622000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.603500 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 005 / 011 | Total loss: 1.007 | Reg loss: 0.045 | Tree loss: 1.007 | Accuracy: 0.647500 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 006 / 011 | Total loss: 1.031 | Reg loss: 0.045 | Tree loss: 1.031 | Accuracy: 0.610500 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 007 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.637000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 008 / 011 | Total loss: 0.997 | Reg loss: 0.045 | Tree loss: 0.997 | Accuracy: 0.657000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 009 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.658000 | 0.163 sec/iter\n",
      "Epoch: 492 | Batch: 010 / 011 | Total loss: 0.977 | Reg loss: 0.045 | Tree loss: 0.977 | Accuracy: 0.679181 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 493 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.624000 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 001 / 011 | Total loss: 1.074 | Reg loss: 0.045 | Tree loss: 1.074 | Accuracy: 0.616500 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 002 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.618000 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 003 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.620500 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 004 / 011 | Total loss: 1.013 | Reg loss: 0.045 | Tree loss: 1.013 | Accuracy: 0.655500 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 005 / 011 | Total loss: 1.012 | Reg loss: 0.045 | Tree loss: 1.012 | Accuracy: 0.627000 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 006 / 011 | Total loss: 1.002 | Reg loss: 0.045 | Tree loss: 1.002 | Accuracy: 0.635000 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 007 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.624000 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 008 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.619000 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 009 / 011 | Total loss: 0.991 | Reg loss: 0.045 | Tree loss: 0.991 | Accuracy: 0.664500 | 0.163 sec/iter\n",
      "Epoch: 493 | Batch: 010 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.624573 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 494 | Batch: 000 / 011 | Total loss: 1.075 | Reg loss: 0.045 | Tree loss: 1.075 | Accuracy: 0.605000 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.628000 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 002 / 011 | Total loss: 1.058 | Reg loss: 0.045 | Tree loss: 1.058 | Accuracy: 0.628500 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.639000 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 004 / 011 | Total loss: 1.042 | Reg loss: 0.045 | Tree loss: 1.042 | Accuracy: 0.631000 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 005 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.626500 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 006 / 011 | Total loss: 0.999 | Reg loss: 0.045 | Tree loss: 0.999 | Accuracy: 0.641500 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 007 / 011 | Total loss: 1.020 | Reg loss: 0.045 | Tree loss: 1.020 | Accuracy: 0.631500 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 008 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.656000 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 009 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.642500 | 0.163 sec/iter\n",
      "Epoch: 494 | Batch: 010 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.604096 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 495 | Batch: 000 / 011 | Total loss: 1.082 | Reg loss: 0.045 | Tree loss: 1.082 | Accuracy: 0.611500 | 0.163 sec/iter\n",
      "Epoch: 495 | Batch: 001 / 011 | Total loss: 1.071 | Reg loss: 0.045 | Tree loss: 1.071 | Accuracy: 0.616000 | 0.163 sec/iter\n",
      "Epoch: 495 | Batch: 002 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.599500 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 003 / 011 | Total loss: 1.040 | Reg loss: 0.045 | Tree loss: 1.040 | Accuracy: 0.619500 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 004 / 011 | Total loss: 1.023 | Reg loss: 0.045 | Tree loss: 1.023 | Accuracy: 0.642000 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 005 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 006 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.618500 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.656000 | 0.162 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 495 | Batch: 008 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.659500 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 009 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.653500 | 0.162 sec/iter\n",
      "Epoch: 495 | Batch: 010 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.631399 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 496 | Batch: 000 / 011 | Total loss: 1.069 | Reg loss: 0.045 | Tree loss: 1.069 | Accuracy: 0.626000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 001 / 011 | Total loss: 1.052 | Reg loss: 0.045 | Tree loss: 1.052 | Accuracy: 0.619500 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 002 / 011 | Total loss: 1.053 | Reg loss: 0.045 | Tree loss: 1.053 | Accuracy: 0.619000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 003 / 011 | Total loss: 1.043 | Reg loss: 0.045 | Tree loss: 1.043 | Accuracy: 0.609000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 004 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.621000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 005 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.623500 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 006 / 011 | Total loss: 1.022 | Reg loss: 0.045 | Tree loss: 1.022 | Accuracy: 0.619000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 007 / 011 | Total loss: 1.008 | Reg loss: 0.045 | Tree loss: 1.008 | Accuracy: 0.651000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 008 / 011 | Total loss: 1.003 | Reg loss: 0.045 | Tree loss: 1.003 | Accuracy: 0.649000 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.045 | Tree loss: 1.006 | Accuracy: 0.648500 | 0.162 sec/iter\n",
      "Epoch: 496 | Batch: 010 / 011 | Total loss: 1.028 | Reg loss: 0.045 | Tree loss: 1.028 | Accuracy: 0.645051 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 497 | Batch: 000 / 011 | Total loss: 1.073 | Reg loss: 0.045 | Tree loss: 1.073 | Accuracy: 0.613000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.611500 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 002 / 011 | Total loss: 1.030 | Reg loss: 0.045 | Tree loss: 1.030 | Accuracy: 0.629000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 003 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.639500 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 004 / 011 | Total loss: 1.009 | Reg loss: 0.045 | Tree loss: 1.009 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.623000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 006 / 011 | Total loss: 1.027 | Reg loss: 0.045 | Tree loss: 1.027 | Accuracy: 0.636000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 007 / 011 | Total loss: 1.010 | Reg loss: 0.045 | Tree loss: 1.010 | Accuracy: 0.638000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 008 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.635000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 009 / 011 | Total loss: 1.014 | Reg loss: 0.045 | Tree loss: 1.014 | Accuracy: 0.645000 | 0.162 sec/iter\n",
      "Epoch: 497 | Batch: 010 / 011 | Total loss: 1.034 | Reg loss: 0.045 | Tree loss: 1.034 | Accuracy: 0.668942 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 498 | Batch: 000 / 011 | Total loss: 1.078 | Reg loss: 0.045 | Tree loss: 1.078 | Accuracy: 0.614500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 001 / 011 | Total loss: 1.072 | Reg loss: 0.045 | Tree loss: 1.072 | Accuracy: 0.614000 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 002 / 011 | Total loss: 1.049 | Reg loss: 0.045 | Tree loss: 1.049 | Accuracy: 0.638500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 003 / 011 | Total loss: 1.037 | Reg loss: 0.045 | Tree loss: 1.037 | Accuracy: 0.617500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 004 / 011 | Total loss: 1.038 | Reg loss: 0.045 | Tree loss: 1.038 | Accuracy: 0.628500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.045 | Tree loss: 1.018 | Accuracy: 0.630500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 006 / 011 | Total loss: 0.992 | Reg loss: 0.045 | Tree loss: 0.992 | Accuracy: 0.647500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 007 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.642500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 008 / 011 | Total loss: 1.005 | Reg loss: 0.045 | Tree loss: 1.005 | Accuracy: 0.649000 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 009 / 011 | Total loss: 1.029 | Reg loss: 0.045 | Tree loss: 1.029 | Accuracy: 0.636500 | 0.162 sec/iter\n",
      "Epoch: 498 | Batch: 010 / 011 | Total loss: 1.004 | Reg loss: 0.045 | Tree loss: 1.004 | Accuracy: 0.624573 | 0.162 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 499 | Batch: 000 / 011 | Total loss: 1.077 | Reg loss: 0.045 | Tree loss: 1.077 | Accuracy: 0.618000 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 001 / 011 | Total loss: 1.057 | Reg loss: 0.045 | Tree loss: 1.057 | Accuracy: 0.615000 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 002 / 011 | Total loss: 1.044 | Reg loss: 0.045 | Tree loss: 1.044 | Accuracy: 0.633500 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 003 / 011 | Total loss: 1.041 | Reg loss: 0.045 | Tree loss: 1.041 | Accuracy: 0.616000 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 004 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.626000 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 005 / 011 | Total loss: 1.025 | Reg loss: 0.045 | Tree loss: 1.025 | Accuracy: 0.621000 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 006 / 011 | Total loss: 1.016 | Reg loss: 0.045 | Tree loss: 1.016 | Accuracy: 0.641500 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 007 / 011 | Total loss: 1.017 | Reg loss: 0.045 | Tree loss: 1.017 | Accuracy: 0.648500 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 008 / 011 | Total loss: 1.032 | Reg loss: 0.045 | Tree loss: 1.032 | Accuracy: 0.649000 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 009 / 011 | Total loss: 0.994 | Reg loss: 0.045 | Tree loss: 0.994 | Accuracy: 0.656500 | 0.162 sec/iter\n",
      "Epoch: 499 | Batch: 010 / 011 | Total loss: 1.001 | Reg loss: 0.045 | Tree loss: 1.001 | Accuracy: 0.651877 | 0.162 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 4.954545454545454\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 22\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'MLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/miniconda3/envs/rambo/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "============== Pattern 19 ==============\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "Average comprehensibility: 46.54545454545455\n"
     ]
    }
   ],
   "source": [
    "signal_names = dataset.dataset.all_signals\n",
    "normalizers = torch.tensor([])\n",
    "attr_names = []\n",
    "for signal_name in signal_names:\n",
    "    attr_names += [f\"T{i}.{signal_name}\" for i in range(sampled.shape[-1])]\n",
    "    sensor_norm = torch.tensor([torch.tensor(dataset.dataset.sensor_maxs[signal_name]) for _ in range(sampled.shape[-1])])\n",
    "    normalizers = torch.cat([normalizers, sensor_norm])\n",
    "    \n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    for cond in conds:\n",
    "        cond.weights = cond.weights / normalizers\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    sum_comprehensibility += sum([cond.comprehensibility for cond in conds])\n",
    "    \n",
    "print(f\"Average comprehensibility: {sum_comprehensibility / len(leaves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune_tree(tree, factor=1.5)\n",
    "correct = 0\n",
    "tree = tree.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = tree.forward(data)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.view(-1).data).sum()\n",
    "\n",
    "print(f\"Accuracy: {correct / len(tree_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sparseness: {sparseness(tree.inner_nodes.weight)}\")\n",
    "layer = 0\n",
    "sps = []\n",
    "for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "    cur_layer = np.floor(np.log2(i+1))\n",
    "    if cur_layer != layer:\n",
    "        print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "        sps = []\n",
    "        layer = cur_layer\n",
    "    \n",
    "    x_ = tree.inner_nodes.weight[i, :]\n",
    "    sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "    sps.append(sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tree.inner_nodes.weight.cpu().detach().numpy()\n",
    "for i in range(0, weights.shape[0], 20):\n",
    "    plt.figure()\n",
    "    weights_layer = weights[i, :]\n",
    "    plt.hist(weights_layer, bins=500)\n",
    "    weights_std = np.std(weights_layer)\n",
    "    weights_mean = np.mean(weights_layer)\n",
    "    plt.axvline(weights_mean + weights_std, color='r')\n",
    "    plt.axvline(weights_mean - weights_std, color='r')\n",
    "    plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\\n Kurtosis: {kurtosis(weights_layer)}\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the accuracy didn't change too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "tree_copy = tree_copy.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = tree_copy.forward(data)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.view(-1).data).sum()\n",
    "\n",
    "print(f\"Accuracy: {correct / len(tree_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tree_copy.inner_nodes.weight.cpu().detach().numpy()\n",
    "for i in range(0, weights.shape[0], 20):\n",
    "    plt.figure()\n",
    "    weights_layer = weights[i, :]\n",
    "    plt.hist(weights_layer, bins=500)\n",
    "    weights_std = np.std(weights_layer)\n",
    "    weights_mean = np.mean(weights_layer)\n",
    "    plt.axvline(weights_mean + weights_std, color='r')\n",
    "    plt.axvline(weights_mean - weights_std, color='r')\n",
    "    plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stack = LifoQueue()\n",
    "edge_stack = LifoQueue()\n",
    "stack.put(root)\n",
    "rule_counter = 0\n",
    "root.reset()\n",
    "while not stack.empty():\n",
    "    node = stack.get()\n",
    "    if node.is_leaf():\n",
    "        print(f\"============== Rule {rule_counter} ==============\")\n",
    "        for stack_node, cond in zip(stack.queue, edge_stack.queue[1:]):\n",
    "            print(repr(stack_node.get_condition(attr_names)) + cond)\n",
    "            print()\n",
    "        \n",
    "        rule_counter += 1\n",
    "        edge_stack.get()\n",
    "        continue\n",
    "          \n",
    "    if node.left is not None and not node.left.visited:\n",
    "        stack.put(node)\n",
    "        stack.put(node.left)\n",
    "        node.left.visited = True\n",
    "        edge_stack.put(' < 0')\n",
    "        continue\n",
    "        \n",
    "    if node.right is not None and not node.right.visited:\n",
    "        stack.put(node)\n",
    "        stack.put(node.right)\n",
    "        node.right.visited = True\n",
    "        edge_stack.put(' > 0')\n",
    "        continue\n",
    "        \n",
    "    if node is not root:\n",
    "        edge_stack.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
