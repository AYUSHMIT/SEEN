{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 16\n",
    "tree_depth = 8\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'/mnt/qnap/ekosman/mitbih_train.csv'\n",
    "test_data_path = r'/mnt/qnap/ekosman/mitbih_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.484518527984619 | KNN Loss: 5.702592849731445 | CLS Loss: 1.7819255590438843\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 4.918007850646973 | KNN Loss: 3.6306533813476562 | CLS Loss: 1.2873547077178955\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 4.060115814208984 | KNN Loss: 3.4252774715423584 | CLS Loss: 0.6348381042480469\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 4.008340835571289 | KNN Loss: 3.4107308387756348 | CLS Loss: 0.59760981798172\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 3.8298227787017822 | KNN Loss: 3.2591328620910645 | CLS Loss: 0.570689857006073\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 3.826385498046875 | KNN Loss: 3.267730951309204 | CLS Loss: 0.5586546659469604\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 3.7447385787963867 | KNN Loss: 3.226707696914673 | CLS Loss: 0.5180308222770691\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 3.7083966732025146 | KNN Loss: 3.2126309871673584 | CLS Loss: 0.49576571583747864\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 3.676419734954834 | KNN Loss: 3.2240939140319824 | CLS Loss: 0.4523259103298187\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 3.627716064453125 | KNN Loss: 3.225710391998291 | CLS Loss: 0.40200579166412354\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 3.6473636627197266 | KNN Loss: 3.1983351707458496 | CLS Loss: 0.4490284025669098\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 3.5776844024658203 | KNN Loss: 3.156540632247925 | CLS Loss: 0.42114368081092834\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 3.544100284576416 | KNN Loss: 3.1727211475372314 | CLS Loss: 0.37137916684150696\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 3.515429735183716 | KNN Loss: 3.1652145385742188 | CLS Loss: 0.35021522641181946\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 3.5429303646087646 | KNN Loss: 3.166003704071045 | CLS Loss: 0.3769267201423645\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 3.6277148723602295 | KNN Loss: 3.181874990463257 | CLS Loss: 0.44583988189697266\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 3.638571262359619 | KNN Loss: 3.135205030441284 | CLS Loss: 0.5033663511276245\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 3.543236017227173 | KNN Loss: 3.1762547492980957 | CLS Loss: 0.36698126792907715\n",
      "Epoch: 001, Loss: 3.8833, Train: 0.8927, Valid: 0.8916, Best: 0.8916\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 3.5474939346313477 | KNN Loss: 3.171445846557617 | CLS Loss: 0.37604817748069763\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 3.532928466796875 | KNN Loss: 3.167800188064575 | CLS Loss: 0.36512818932533264\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 3.472313642501831 | KNN Loss: 3.1412599086761475 | CLS Loss: 0.33105364441871643\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 3.5051803588867188 | KNN Loss: 3.1808409690856934 | CLS Loss: 0.3243393898010254\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 3.478119134902954 | KNN Loss: 3.1325347423553467 | CLS Loss: 0.3455843925476074\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 3.440662145614624 | KNN Loss: 3.185943365097046 | CLS Loss: 0.25471875071525574\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 3.4355733394622803 | KNN Loss: 3.1825666427612305 | CLS Loss: 0.25300663709640503\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 3.4558815956115723 | KNN Loss: 3.155858278274536 | CLS Loss: 0.30002331733703613\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 3.4621212482452393 | KNN Loss: 3.140129804611206 | CLS Loss: 0.32199153304100037\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 3.423126220703125 | KNN Loss: 3.154658794403076 | CLS Loss: 0.2684675455093384\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 3.4788928031921387 | KNN Loss: 3.200133800506592 | CLS Loss: 0.2787590026855469\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 3.4482264518737793 | KNN Loss: 3.148517608642578 | CLS Loss: 0.29970887303352356\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 3.362647533416748 | KNN Loss: 3.1238491535186768 | CLS Loss: 0.2387983351945877\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 3.4939188957214355 | KNN Loss: 3.1061863899230957 | CLS Loss: 0.38773253560066223\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 3.400240898132324 | KNN Loss: 3.127981662750244 | CLS Loss: 0.27225935459136963\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 3.396972179412842 | KNN Loss: 3.09032940864563 | CLS Loss: 0.3066428303718567\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 3.3258063793182373 | KNN Loss: 3.1573903560638428 | CLS Loss: 0.1684160828590393\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 3.349250316619873 | KNN Loss: 3.1282384395599365 | CLS Loss: 0.22101183235645294\n",
      "Epoch: 002, Loss: 3.4419, Train: 0.9410, Valid: 0.9401, Best: 0.9401\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 3.3087270259857178 | KNN Loss: 3.1264419555664062 | CLS Loss: 0.1822851449251175\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 3.3390207290649414 | KNN Loss: 3.1418981552124023 | CLS Loss: 0.1971224695444107\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 3.377309799194336 | KNN Loss: 3.131523847579956 | CLS Loss: 0.24578607082366943\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 3.3778998851776123 | KNN Loss: 3.080989360809326 | CLS Loss: 0.29691052436828613\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 3.36155104637146 | KNN Loss: 3.1053452491760254 | CLS Loss: 0.25620588660240173\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 3.3462908267974854 | KNN Loss: 3.103344202041626 | CLS Loss: 0.24294669926166534\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 3.3430392742156982 | KNN Loss: 3.15297794342041 | CLS Loss: 0.1900613009929657\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 3.314990282058716 | KNN Loss: 3.0582501888275146 | CLS Loss: 0.256740003824234\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 3.334001064300537 | KNN Loss: 3.109941244125366 | CLS Loss: 0.2240597903728485\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 3.3272500038146973 | KNN Loss: 3.141716957092285 | CLS Loss: 0.18553303182125092\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 3.2693300247192383 | KNN Loss: 3.097193717956543 | CLS Loss: 0.17213639616966248\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 3.226555824279785 | KNN Loss: 3.045698642730713 | CLS Loss: 0.18085722625255585\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 3.2706286907196045 | KNN Loss: 3.0900704860687256 | CLS Loss: 0.18055814504623413\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 3.268101692199707 | KNN Loss: 3.0750930309295654 | CLS Loss: 0.193008691072464\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 3.276766777038574 | KNN Loss: 3.098191022872925 | CLS Loss: 0.1785758137702942\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 3.336120128631592 | KNN Loss: 3.1169872283935547 | CLS Loss: 0.21913285553455353\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 3.2633161544799805 | KNN Loss: 3.074462652206421 | CLS Loss: 0.18885347247123718\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 3.223787546157837 | KNN Loss: 3.0620663166046143 | CLS Loss: 0.16172119975090027\n",
      "Epoch: 003, Loss: 3.3041, Train: 0.9511, Valid: 0.9511, Best: 0.9511\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 3.2007522583007812 | KNN Loss: 3.0892481803894043 | CLS Loss: 0.11150415241718292\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 3.2383196353912354 | KNN Loss: 3.0365655422210693 | CLS Loss: 0.2017541229724884\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 3.2805821895599365 | KNN Loss: 3.0753285884857178 | CLS Loss: 0.2052536904811859\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 3.2283718585968018 | KNN Loss: 3.0913922786712646 | CLS Loss: 0.13697952032089233\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 3.188291311264038 | KNN Loss: 3.058881998062134 | CLS Loss: 0.12940940260887146\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 3.254136085510254 | KNN Loss: 3.089836597442627 | CLS Loss: 0.1642993837594986\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 3.2678000926971436 | KNN Loss: 3.0689196586608887 | CLS Loss: 0.19888052344322205\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 3.2793357372283936 | KNN Loss: 3.138749122619629 | CLS Loss: 0.14058665931224823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 3.2201507091522217 | KNN Loss: 3.085808277130127 | CLS Loss: 0.1343424767255783\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 3.213165521621704 | KNN Loss: 3.0549569129943848 | CLS Loss: 0.15820854902267456\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 3.247746229171753 | KNN Loss: 3.077493667602539 | CLS Loss: 0.17025253176689148\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 3.2177517414093018 | KNN Loss: 3.061121702194214 | CLS Loss: 0.15662993490695953\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 3.2320189476013184 | KNN Loss: 3.052795648574829 | CLS Loss: 0.17922340333461761\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 3.2135558128356934 | KNN Loss: 3.049027442932129 | CLS Loss: 0.16452841460704803\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 3.2569992542266846 | KNN Loss: 3.077732801437378 | CLS Loss: 0.17926636338233948\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 3.2157771587371826 | KNN Loss: 3.091513156890869 | CLS Loss: 0.12426390498876572\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 3.274515151977539 | KNN Loss: 3.106173276901245 | CLS Loss: 0.16834186017513275\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 3.201657772064209 | KNN Loss: 3.0611331462860107 | CLS Loss: 0.14052467048168182\n",
      "Epoch: 004, Loss: 3.2300, Train: 0.9627, Valid: 0.9603, Best: 0.9603\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 3.2189598083496094 | KNN Loss: 3.0730907917022705 | CLS Loss: 0.14586913585662842\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 3.158698558807373 | KNN Loss: 3.0368921756744385 | CLS Loss: 0.121806301176548\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 3.241152763366699 | KNN Loss: 3.0867555141448975 | CLS Loss: 0.15439721941947937\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 3.2444233894348145 | KNN Loss: 3.0646309852600098 | CLS Loss: 0.1797923743724823\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 3.2031924724578857 | KNN Loss: 3.0413312911987305 | CLS Loss: 0.16186124086380005\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 3.22027325630188 | KNN Loss: 3.0750930309295654 | CLS Loss: 0.14518015086650848\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 3.179959774017334 | KNN Loss: 3.0959413051605225 | CLS Loss: 0.0840185135602951\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 3.175454616546631 | KNN Loss: 3.0484261512756348 | CLS Loss: 0.12702836096286774\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 3.217167377471924 | KNN Loss: 3.0581748485565186 | CLS Loss: 0.1589924544095993\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 3.177299737930298 | KNN Loss: 3.0185866355895996 | CLS Loss: 0.15871302783489227\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 3.2244527339935303 | KNN Loss: 3.0594711303710938 | CLS Loss: 0.1649816334247589\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 3.1388468742370605 | KNN Loss: 3.0304017066955566 | CLS Loss: 0.10844527930021286\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 3.2149107456207275 | KNN Loss: 3.069451332092285 | CLS Loss: 0.14545942842960358\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 3.187190055847168 | KNN Loss: 3.0286664962768555 | CLS Loss: 0.1585235595703125\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 3.1519508361816406 | KNN Loss: 3.0532708168029785 | CLS Loss: 0.09868010133504868\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 3.1629207134246826 | KNN Loss: 3.0857439041137695 | CLS Loss: 0.07717683911323547\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 3.154395818710327 | KNN Loss: 3.056483507156372 | CLS Loss: 0.0979122519493103\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 3.1986958980560303 | KNN Loss: 3.065661668777466 | CLS Loss: 0.13303428888320923\n",
      "Epoch: 005, Loss: 3.1967, Train: 0.9622, Valid: 0.9589, Best: 0.9603\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 3.1682305335998535 | KNN Loss: 3.078021764755249 | CLS Loss: 0.09020880609750748\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 3.1642332077026367 | KNN Loss: 3.0607008934020996 | CLS Loss: 0.10353231430053711\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 3.171513080596924 | KNN Loss: 3.0442779064178467 | CLS Loss: 0.1272352933883667\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 3.2075352668762207 | KNN Loss: 3.080904483795166 | CLS Loss: 0.12663084268569946\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 3.1555519104003906 | KNN Loss: 3.017714023590088 | CLS Loss: 0.13783791661262512\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 3.148829221725464 | KNN Loss: 3.045881986618042 | CLS Loss: 0.10294725000858307\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 3.178750991821289 | KNN Loss: 3.040186882019043 | CLS Loss: 0.1385641247034073\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 3.141326904296875 | KNN Loss: 3.032521963119507 | CLS Loss: 0.10880494862794876\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 3.150193214416504 | KNN Loss: 3.0189359188079834 | CLS Loss: 0.1312573254108429\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 3.217839002609253 | KNN Loss: 3.074708938598633 | CLS Loss: 0.14313004910945892\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 3.1380112171173096 | KNN Loss: 3.0644822120666504 | CLS Loss: 0.07352893799543381\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 3.125309705734253 | KNN Loss: 3.018627643585205 | CLS Loss: 0.10668203234672546\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 3.182945966720581 | KNN Loss: 3.04065203666687 | CLS Loss: 0.14229393005371094\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 3.1404526233673096 | KNN Loss: 3.049220323562622 | CLS Loss: 0.09123235195875168\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 3.18162202835083 | KNN Loss: 3.032106637954712 | CLS Loss: 0.14951540529727936\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 3.166807174682617 | KNN Loss: 3.0459673404693604 | CLS Loss: 0.12083994597196579\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 3.1237730979919434 | KNN Loss: 2.9743635654449463 | CLS Loss: 0.1494094580411911\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 3.1786675453186035 | KNN Loss: 3.049037456512451 | CLS Loss: 0.1296302080154419\n",
      "Epoch: 006, Loss: 3.1714, Train: 0.9694, Valid: 0.9667, Best: 0.9667\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 3.1998839378356934 | KNN Loss: 3.054358720779419 | CLS Loss: 0.1455252319574356\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 3.1430978775024414 | KNN Loss: 3.029486894607544 | CLS Loss: 0.11361110210418701\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 3.153564214706421 | KNN Loss: 3.0220704078674316 | CLS Loss: 0.1314937174320221\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 3.16853666305542 | KNN Loss: 3.033128023147583 | CLS Loss: 0.13540861010551453\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 3.121824264526367 | KNN Loss: 3.0161144733428955 | CLS Loss: 0.10570984333753586\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 3.1250743865966797 | KNN Loss: 3.0265939235687256 | CLS Loss: 0.09848038852214813\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 3.148411750793457 | KNN Loss: 3.072211503982544 | CLS Loss: 0.07620016485452652\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 3.134545087814331 | KNN Loss: 2.9989068508148193 | CLS Loss: 0.1356383115053177\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 3.187044620513916 | KNN Loss: 3.076943874359131 | CLS Loss: 0.1101006343960762\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 3.2153615951538086 | KNN Loss: 3.0609824657440186 | CLS Loss: 0.1543792337179184\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 3.1408610343933105 | KNN Loss: 3.0324931144714355 | CLS Loss: 0.10836794227361679\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 3.138498067855835 | KNN Loss: 3.043458938598633 | CLS Loss: 0.09503921866416931\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 3.133354663848877 | KNN Loss: 3.0192277431488037 | CLS Loss: 0.11412686854600906\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 3.15871524810791 | KNN Loss: 3.0436594486236572 | CLS Loss: 0.11505570262670517\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 3.1499369144439697 | KNN Loss: 3.0391223430633545 | CLS Loss: 0.11081456393003464\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 3.0737504959106445 | KNN Loss: 3.034048080444336 | CLS Loss: 0.039702340960502625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 3.1755993366241455 | KNN Loss: 3.0636112689971924 | CLS Loss: 0.11198803782463074\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 3.123162031173706 | KNN Loss: 3.0568337440490723 | CLS Loss: 0.06632837653160095\n",
      "Epoch: 007, Loss: 3.1496, Train: 0.9759, Valid: 0.9734, Best: 0.9734\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 3.136845350265503 | KNN Loss: 3.0463509559631348 | CLS Loss: 0.09049447625875473\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 3.0937507152557373 | KNN Loss: 3.0225329399108887 | CLS Loss: 0.07121770083904266\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 3.1500046253204346 | KNN Loss: 3.0523664951324463 | CLS Loss: 0.09763810783624649\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 3.1348865032196045 | KNN Loss: 3.016669750213623 | CLS Loss: 0.1182168573141098\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 3.156845808029175 | KNN Loss: 3.062957286834717 | CLS Loss: 0.0938885509967804\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 3.1577563285827637 | KNN Loss: 3.0452826023101807 | CLS Loss: 0.11247381567955017\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 3.1702771186828613 | KNN Loss: 3.0928826332092285 | CLS Loss: 0.07739453762769699\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 3.151754856109619 | KNN Loss: 3.026740550994873 | CLS Loss: 0.12501418590545654\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 3.150404930114746 | KNN Loss: 3.008831739425659 | CLS Loss: 0.1415732502937317\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 3.129911422729492 | KNN Loss: 3.0669729709625244 | CLS Loss: 0.06293842941522598\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 3.1217172145843506 | KNN Loss: 3.0408294200897217 | CLS Loss: 0.0808878242969513\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 3.1265525817871094 | KNN Loss: 3.0011708736419678 | CLS Loss: 0.12538166344165802\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 3.140951156616211 | KNN Loss: 3.04541015625 | CLS Loss: 0.09554099291563034\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 3.1717917919158936 | KNN Loss: 3.0371642112731934 | CLS Loss: 0.13462768495082855\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 3.1493420600891113 | KNN Loss: 3.033454418182373 | CLS Loss: 0.11588771641254425\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 3.1187093257904053 | KNN Loss: 3.002314329147339 | CLS Loss: 0.11639496684074402\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 3.125736713409424 | KNN Loss: 3.0556654930114746 | CLS Loss: 0.07007131725549698\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 3.176215648651123 | KNN Loss: 3.0522050857543945 | CLS Loss: 0.12401053309440613\n",
      "Epoch: 008, Loss: 3.1392, Train: 0.9760, Valid: 0.9728, Best: 0.9734\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 3.1465158462524414 | KNN Loss: 3.0367894172668457 | CLS Loss: 0.10972646623849869\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 3.1374621391296387 | KNN Loss: 3.0581607818603516 | CLS Loss: 0.07930143177509308\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 3.108020782470703 | KNN Loss: 3.0427544116973877 | CLS Loss: 0.06526642292737961\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 3.2005176544189453 | KNN Loss: 3.0322155952453613 | CLS Loss: 0.1683020293712616\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 3.162649631500244 | KNN Loss: 3.084752082824707 | CLS Loss: 0.07789751887321472\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 3.1232354640960693 | KNN Loss: 3.0111589431762695 | CLS Loss: 0.11207657307386398\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 3.0788443088531494 | KNN Loss: 3.0280916690826416 | CLS Loss: 0.050752609968185425\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 3.156353235244751 | KNN Loss: 3.096799850463867 | CLS Loss: 0.05955340713262558\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 3.112955093383789 | KNN Loss: 3.0004258155822754 | CLS Loss: 0.11252937465906143\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 3.100327253341675 | KNN Loss: 3.030383586883545 | CLS Loss: 0.06994367390871048\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 3.140913724899292 | KNN Loss: 3.030646562576294 | CLS Loss: 0.11026713252067566\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 3.1241648197174072 | KNN Loss: 3.062244176864624 | CLS Loss: 0.06192075088620186\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 3.1453909873962402 | KNN Loss: 3.0419044494628906 | CLS Loss: 0.10348646342754364\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 3.1084585189819336 | KNN Loss: 3.0322070121765137 | CLS Loss: 0.0762515664100647\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 3.159728765487671 | KNN Loss: 3.053925037384033 | CLS Loss: 0.10580367594957352\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 3.128783941268921 | KNN Loss: 3.057994842529297 | CLS Loss: 0.07078901678323746\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 3.0843849182128906 | KNN Loss: 3.02872896194458 | CLS Loss: 0.05565593019127846\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 3.1201913356781006 | KNN Loss: 3.038165807723999 | CLS Loss: 0.0820254236459732\n",
      "Epoch: 009, Loss: 3.1237, Train: 0.9791, Valid: 0.9758, Best: 0.9758\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 3.1158056259155273 | KNN Loss: 3.0544722080230713 | CLS Loss: 0.06133351847529411\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 3.0911881923675537 | KNN Loss: 3.0261950492858887 | CLS Loss: 0.0649932399392128\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 3.142760992050171 | KNN Loss: 3.0466268062591553 | CLS Loss: 0.09613420069217682\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 3.0874221324920654 | KNN Loss: 2.9957103729248047 | CLS Loss: 0.09171173721551895\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 3.0853779315948486 | KNN Loss: 3.0130789279937744 | CLS Loss: 0.07229911535978317\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 3.0664703845977783 | KNN Loss: 3.0131258964538574 | CLS Loss: 0.05334438756108284\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 3.1267588138580322 | KNN Loss: 3.01878023147583 | CLS Loss: 0.10797864198684692\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 3.1050920486450195 | KNN Loss: 3.0452823638916016 | CLS Loss: 0.05980970710515976\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 3.0712809562683105 | KNN Loss: 3.0248937606811523 | CLS Loss: 0.04638717323541641\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 3.1164257526397705 | KNN Loss: 3.0078179836273193 | CLS Loss: 0.10860772430896759\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 3.1808314323425293 | KNN Loss: 3.04106068611145 | CLS Loss: 0.13977064192295074\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 3.1350600719451904 | KNN Loss: 3.0252573490142822 | CLS Loss: 0.10980275273323059\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 3.1492810249328613 | KNN Loss: 3.014758825302124 | CLS Loss: 0.13452212512493134\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 3.1482863426208496 | KNN Loss: 3.062954902648926 | CLS Loss: 0.08533135801553726\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 3.1239044666290283 | KNN Loss: 3.069855213165283 | CLS Loss: 0.054049160331487656\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 3.129880905151367 | KNN Loss: 3.054126739501953 | CLS Loss: 0.07575405389070511\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 3.0806119441986084 | KNN Loss: 3.014343738555908 | CLS Loss: 0.06626814603805542\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 3.1469035148620605 | KNN Loss: 2.9787790775299072 | CLS Loss: 0.16812431812286377\n",
      "Epoch: 010, Loss: 3.1154, Train: 0.9801, Valid: 0.9774, Best: 0.9774\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 3.0841755867004395 | KNN Loss: 3.0099527835845947 | CLS Loss: 0.07422269880771637\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 3.1474087238311768 | KNN Loss: 3.046046733856201 | CLS Loss: 0.10136198997497559\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 3.0976736545562744 | KNN Loss: 3.024622917175293 | CLS Loss: 0.07305062562227249\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 3.108366012573242 | KNN Loss: 3.0313503742218018 | CLS Loss: 0.07701552659273148\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 3.1140804290771484 | KNN Loss: 3.0262222290039062 | CLS Loss: 0.08785827457904816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 3.0776071548461914 | KNN Loss: 3.000746726989746 | CLS Loss: 0.07686050236225128\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 3.085125684738159 | KNN Loss: 3.013312578201294 | CLS Loss: 0.07181314378976822\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 3.138761520385742 | KNN Loss: 3.053946018218994 | CLS Loss: 0.08481541275978088\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 3.1633753776550293 | KNN Loss: 3.0122034549713135 | CLS Loss: 0.15117180347442627\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 3.08711838722229 | KNN Loss: 3.022554874420166 | CLS Loss: 0.06456354260444641\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 3.127065896987915 | KNN Loss: 3.0565388202667236 | CLS Loss: 0.070527084171772\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 3.0992629528045654 | KNN Loss: 3.0368895530700684 | CLS Loss: 0.06237330287694931\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 3.086613655090332 | KNN Loss: 3.0493030548095703 | CLS Loss: 0.03731054440140724\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 3.0584235191345215 | KNN Loss: 2.9780349731445312 | CLS Loss: 0.080388642847538\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 3.1055145263671875 | KNN Loss: 3.0349998474121094 | CLS Loss: 0.07051461189985275\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 3.1037087440490723 | KNN Loss: 3.027017593383789 | CLS Loss: 0.07669106125831604\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 3.109764814376831 | KNN Loss: 3.03877854347229 | CLS Loss: 0.07098635286092758\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 3.0838825702667236 | KNN Loss: 2.9928293228149414 | CLS Loss: 0.09105321764945984\n",
      "Epoch: 011, Loss: 3.1073, Train: 0.9806, Valid: 0.9772, Best: 0.9774\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 3.077099323272705 | KNN Loss: 3.011873245239258 | CLS Loss: 0.06522605568170547\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 3.1074869632720947 | KNN Loss: 3.0558509826660156 | CLS Loss: 0.05163605511188507\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 3.08986759185791 | KNN Loss: 3.0156452655792236 | CLS Loss: 0.07422243803739548\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 3.1157243251800537 | KNN Loss: 3.024275779724121 | CLS Loss: 0.09144851565361023\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 3.126899003982544 | KNN Loss: 3.040987968444824 | CLS Loss: 0.08591094613075256\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 3.125755548477173 | KNN Loss: 3.0594699382781982 | CLS Loss: 0.06628554314374924\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 3.091623544692993 | KNN Loss: 3.000570297241211 | CLS Loss: 0.0910532996058464\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 3.120656967163086 | KNN Loss: 3.0224218368530273 | CLS Loss: 0.09823508560657501\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 3.1020052433013916 | KNN Loss: 2.9987950325012207 | CLS Loss: 0.1032102033495903\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 3.0542540550231934 | KNN Loss: 2.988975763320923 | CLS Loss: 0.06527825444936752\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 3.086968183517456 | KNN Loss: 3.0367918014526367 | CLS Loss: 0.05017641931772232\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 3.111689329147339 | KNN Loss: 3.0176961421966553 | CLS Loss: 0.09399321675300598\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 3.095731496810913 | KNN Loss: 3.047182083129883 | CLS Loss: 0.04854941368103027\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 3.113053560256958 | KNN Loss: 2.993128538131714 | CLS Loss: 0.11992499232292175\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 3.0706613063812256 | KNN Loss: 2.9952216148376465 | CLS Loss: 0.07543971389532089\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 3.099311590194702 | KNN Loss: 3.011880874633789 | CLS Loss: 0.08743064850568771\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 3.0865843296051025 | KNN Loss: 3.0068182945251465 | CLS Loss: 0.07976605743169785\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 3.102358818054199 | KNN Loss: 3.0275139808654785 | CLS Loss: 0.07484471797943115\n",
      "Epoch: 012, Loss: 3.1024, Train: 0.9797, Valid: 0.9765, Best: 0.9774\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 3.0893425941467285 | KNN Loss: 3.0526461601257324 | CLS Loss: 0.03669649735093117\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 3.139437437057495 | KNN Loss: 2.9973878860473633 | CLS Loss: 0.14204947650432587\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 3.0771677494049072 | KNN Loss: 2.9978647232055664 | CLS Loss: 0.07930310070514679\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 3.0823307037353516 | KNN Loss: 3.0085461139678955 | CLS Loss: 0.07378463447093964\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 3.0672905445098877 | KNN Loss: 2.996244192123413 | CLS Loss: 0.07104640454053879\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 3.1001758575439453 | KNN Loss: 3.0168120861053467 | CLS Loss: 0.08336388319730759\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 3.1337151527404785 | KNN Loss: 3.050990581512451 | CLS Loss: 0.08272460103034973\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 3.079014778137207 | KNN Loss: 3.006840944290161 | CLS Loss: 0.0721738263964653\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 3.09014892578125 | KNN Loss: 3.0018441677093506 | CLS Loss: 0.08830475807189941\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 3.0822157859802246 | KNN Loss: 3.020659923553467 | CLS Loss: 0.06155582144856453\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 3.090909719467163 | KNN Loss: 3.003169298171997 | CLS Loss: 0.08774041384458542\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 3.088439464569092 | KNN Loss: 3.0215890407562256 | CLS Loss: 0.06685049831867218\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 3.0859968662261963 | KNN Loss: 3.0183537006378174 | CLS Loss: 0.06764322519302368\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 3.1404175758361816 | KNN Loss: 3.028384208679199 | CLS Loss: 0.11203338950872421\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 3.0838634967803955 | KNN Loss: 2.9976983070373535 | CLS Loss: 0.08616512268781662\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 3.089294910430908 | KNN Loss: 2.994441032409668 | CLS Loss: 0.09485377371311188\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 3.050981044769287 | KNN Loss: 3.03222918510437 | CLS Loss: 0.018751926720142365\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 3.081390619277954 | KNN Loss: 3.0122549533843994 | CLS Loss: 0.06913571059703827\n",
      "Epoch: 013, Loss: 3.0977, Train: 0.9831, Valid: 0.9795, Best: 0.9795\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 3.0545268058776855 | KNN Loss: 2.998220205307007 | CLS Loss: 0.056306540966033936\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 3.089003801345825 | KNN Loss: 3.0270626544952393 | CLS Loss: 0.0619412399828434\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 3.083223581314087 | KNN Loss: 3.001725435256958 | CLS Loss: 0.08149824291467667\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 3.0741097927093506 | KNN Loss: 3.010528802871704 | CLS Loss: 0.06358105689287186\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 3.0767905712127686 | KNN Loss: 3.000964403152466 | CLS Loss: 0.07582609355449677\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 3.110325574874878 | KNN Loss: 3.0055134296417236 | CLS Loss: 0.10481225699186325\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 3.0565428733825684 | KNN Loss: 3.009416103363037 | CLS Loss: 0.047126732766628265\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 3.1149566173553467 | KNN Loss: 3.0027670860290527 | CLS Loss: 0.11218950152397156\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 3.069485664367676 | KNN Loss: 3.001662492752075 | CLS Loss: 0.0678231492638588\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 3.060927391052246 | KNN Loss: 3.005506992340088 | CLS Loss: 0.055420421063899994\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 3.0839481353759766 | KNN Loss: 3.024218797683716 | CLS Loss: 0.05972922593355179\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 3.0877373218536377 | KNN Loss: 3.0188465118408203 | CLS Loss: 0.06889073550701141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 3.096914768218994 | KNN Loss: 2.998443126678467 | CLS Loss: 0.09847155958414078\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 3.080664873123169 | KNN Loss: 3.0051023960113525 | CLS Loss: 0.07556237280368805\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 3.1227219104766846 | KNN Loss: 3.0508949756622314 | CLS Loss: 0.07182703167200089\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 3.1062474250793457 | KNN Loss: 2.973442554473877 | CLS Loss: 0.13280494511127472\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 3.072504758834839 | KNN Loss: 2.9906082153320312 | CLS Loss: 0.08189655095338821\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 3.080322027206421 | KNN Loss: 3.018167734146118 | CLS Loss: 0.06215440481901169\n",
      "Epoch: 014, Loss: 3.0915, Train: 0.9825, Valid: 0.9788, Best: 0.9795\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 3.092512845993042 | KNN Loss: 3.0173840522766113 | CLS Loss: 0.07512886822223663\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 3.075193405151367 | KNN Loss: 3.0128586292266846 | CLS Loss: 0.062334779649972916\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 3.093137264251709 | KNN Loss: 3.030851364135742 | CLS Loss: 0.0622858963906765\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 3.1064069271087646 | KNN Loss: 3.0271880626678467 | CLS Loss: 0.07921896874904633\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 3.080578327178955 | KNN Loss: 3.0314254760742188 | CLS Loss: 0.04915275424718857\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 3.056593894958496 | KNN Loss: 2.99747371673584 | CLS Loss: 0.05912017449736595\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 3.123389720916748 | KNN Loss: 3.0249922275543213 | CLS Loss: 0.09839760512113571\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 3.0897293090820312 | KNN Loss: 3.0217020511627197 | CLS Loss: 0.0680273249745369\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 3.1192121505737305 | KNN Loss: 3.0228216648101807 | CLS Loss: 0.09639055281877518\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 3.098501682281494 | KNN Loss: 3.0053813457489014 | CLS Loss: 0.09312044084072113\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 3.1240081787109375 | KNN Loss: 3.0559074878692627 | CLS Loss: 0.06810066103935242\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 3.108502149581909 | KNN Loss: 3.026205539703369 | CLS Loss: 0.0822967141866684\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 3.04689359664917 | KNN Loss: 2.9781081676483154 | CLS Loss: 0.06878546625375748\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 3.047577142715454 | KNN Loss: 2.9981846809387207 | CLS Loss: 0.04939242824912071\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 3.0773603916168213 | KNN Loss: 3.011992931365967 | CLS Loss: 0.06536746025085449\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 3.0605263710021973 | KNN Loss: 2.984445810317993 | CLS Loss: 0.07608044892549515\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 3.043017625808716 | KNN Loss: 2.983032703399658 | CLS Loss: 0.0599849633872509\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 3.087646722793579 | KNN Loss: 3.021355390548706 | CLS Loss: 0.06629126518964767\n",
      "Epoch: 015, Loss: 3.0897, Train: 0.9845, Valid: 0.9810, Best: 0.9810\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 3.0862414836883545 | KNN Loss: 3.0244317054748535 | CLS Loss: 0.06180981546640396\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 3.114422082901001 | KNN Loss: 3.0294463634490967 | CLS Loss: 0.0849756971001625\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 3.0575191974639893 | KNN Loss: 3.019578456878662 | CLS Loss: 0.03794072940945625\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 3.0804872512817383 | KNN Loss: 3.0248279571533203 | CLS Loss: 0.0556592121720314\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 3.113302230834961 | KNN Loss: 3.037095546722412 | CLS Loss: 0.07620670646429062\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 3.0598549842834473 | KNN Loss: 2.989086866378784 | CLS Loss: 0.07076817005872726\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 3.0804288387298584 | KNN Loss: 3.0048155784606934 | CLS Loss: 0.07561333477497101\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 3.066925048828125 | KNN Loss: 2.9898805618286133 | CLS Loss: 0.07704444229602814\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 3.0601439476013184 | KNN Loss: 2.9880096912384033 | CLS Loss: 0.07213423401117325\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 3.086038589477539 | KNN Loss: 2.984670639038086 | CLS Loss: 0.10136792808771133\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 3.128985643386841 | KNN Loss: 3.0452096462249756 | CLS Loss: 0.08377610146999359\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 3.055063486099243 | KNN Loss: 3.0024542808532715 | CLS Loss: 0.052609194070100784\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 3.0698440074920654 | KNN Loss: 3.0175838470458984 | CLS Loss: 0.05226009339094162\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 3.0865628719329834 | KNN Loss: 3.026902914047241 | CLS Loss: 0.05966003239154816\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 3.1029088497161865 | KNN Loss: 3.019413948059082 | CLS Loss: 0.08349494636058807\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 3.070521593093872 | KNN Loss: 3.0022647380828857 | CLS Loss: 0.06825678050518036\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 3.117203950881958 | KNN Loss: 3.0203857421875 | CLS Loss: 0.09681818634271622\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 3.078996419906616 | KNN Loss: 3.038179636001587 | CLS Loss: 0.04081686586141586\n",
      "Epoch: 016, Loss: 3.0818, Train: 0.9839, Valid: 0.9796, Best: 0.9810\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 3.105360984802246 | KNN Loss: 3.027820348739624 | CLS Loss: 0.07754073292016983\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 3.051008701324463 | KNN Loss: 3.0055248737335205 | CLS Loss: 0.04548391327261925\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 3.0773301124572754 | KNN Loss: 3.0255579948425293 | CLS Loss: 0.05177204683423042\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 3.1123099327087402 | KNN Loss: 3.041710615158081 | CLS Loss: 0.07059934735298157\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 3.0603134632110596 | KNN Loss: 2.9898171424865723 | CLS Loss: 0.07049624621868134\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 3.0623934268951416 | KNN Loss: 2.976184129714966 | CLS Loss: 0.08620931208133698\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 3.059877634048462 | KNN Loss: 3.0108516216278076 | CLS Loss: 0.04902598634362221\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 3.085557460784912 | KNN Loss: 3.0290985107421875 | CLS Loss: 0.05645899102091789\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 3.087296485900879 | KNN Loss: 3.0394625663757324 | CLS Loss: 0.04783397912979126\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 3.091453790664673 | KNN Loss: 2.988605260848999 | CLS Loss: 0.10284861922264099\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 3.0719964504241943 | KNN Loss: 3.0249078273773193 | CLS Loss: 0.047088682651519775\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 3.0721120834350586 | KNN Loss: 3.00787353515625 | CLS Loss: 0.06423863023519516\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 3.047611713409424 | KNN Loss: 3.003828525543213 | CLS Loss: 0.04378313571214676\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 3.124352216720581 | KNN Loss: 3.07194185256958 | CLS Loss: 0.05241039767861366\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 3.10150146484375 | KNN Loss: 3.052410364151001 | CLS Loss: 0.04909102991223335\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 3.0678493976593018 | KNN Loss: 2.999239921569824 | CLS Loss: 0.06860946863889694\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 3.128657817840576 | KNN Loss: 3.034614324569702 | CLS Loss: 0.09404340386390686\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 3.060357093811035 | KNN Loss: 3.0370702743530273 | CLS Loss: 0.023286867886781693\n",
      "Epoch: 017, Loss: 3.0854, Train: 0.9842, Valid: 0.9801, Best: 0.9810\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 3.068524122238159 | KNN Loss: 2.993513584136963 | CLS Loss: 0.0750105157494545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 3.1174850463867188 | KNN Loss: 3.0808298587799072 | CLS Loss: 0.03665507212281227\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 3.071300506591797 | KNN Loss: 3.0253753662109375 | CLS Loss: 0.0459250807762146\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 3.07586669921875 | KNN Loss: 3.048640489578247 | CLS Loss: 0.027226246893405914\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 3.13127064704895 | KNN Loss: 3.0248804092407227 | CLS Loss: 0.10639022290706635\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 3.0837440490722656 | KNN Loss: 3.005286455154419 | CLS Loss: 0.07845764607191086\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 3.0469810962677 | KNN Loss: 3.0123417377471924 | CLS Loss: 0.034639276564121246\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 3.058379888534546 | KNN Loss: 3.0104284286499023 | CLS Loss: 0.047951411455869675\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 3.136033058166504 | KNN Loss: 3.0550408363342285 | CLS Loss: 0.08099230378866196\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 3.050668239593506 | KNN Loss: 2.999577760696411 | CLS Loss: 0.05109037086367607\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 3.10992431640625 | KNN Loss: 3.0402281284332275 | CLS Loss: 0.06969618797302246\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 3.06378173828125 | KNN Loss: 3.0073320865631104 | CLS Loss: 0.05644974485039711\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 3.069260597229004 | KNN Loss: 3.001696825027466 | CLS Loss: 0.06756384670734406\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 3.056358575820923 | KNN Loss: 3.0030336380004883 | CLS Loss: 0.053325049579143524\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 3.08024263381958 | KNN Loss: 2.995130777359009 | CLS Loss: 0.08511187881231308\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 3.0669009685516357 | KNN Loss: 3.0247457027435303 | CLS Loss: 0.04215528070926666\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 3.0801126956939697 | KNN Loss: 3.029989242553711 | CLS Loss: 0.05012340471148491\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 3.0729353427886963 | KNN Loss: 3.0073516368865967 | CLS Loss: 0.0655837208032608\n",
      "Epoch: 018, Loss: 3.0833, Train: 0.9848, Valid: 0.9812, Best: 0.9812\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 3.084273099899292 | KNN Loss: 3.014134645462036 | CLS Loss: 0.0701383724808693\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 3.0797369480133057 | KNN Loss: 2.9995272159576416 | CLS Loss: 0.08020983636379242\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 3.0841290950775146 | KNN Loss: 3.027916669845581 | CLS Loss: 0.056212443858385086\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 3.0970194339752197 | KNN Loss: 3.0201101303100586 | CLS Loss: 0.07690935581922531\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 3.068406343460083 | KNN Loss: 3.032259225845337 | CLS Loss: 0.036147210747003555\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 3.0544803142547607 | KNN Loss: 3.0352702140808105 | CLS Loss: 0.019209986552596092\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 3.084465265274048 | KNN Loss: 3.0042154788970947 | CLS Loss: 0.08024979382753372\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 3.106536388397217 | KNN Loss: 3.0298283100128174 | CLS Loss: 0.07670807093381882\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 3.128161668777466 | KNN Loss: 3.035585880279541 | CLS Loss: 0.09257568418979645\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 3.0707156658172607 | KNN Loss: 2.987576961517334 | CLS Loss: 0.08313867449760437\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 3.0696237087249756 | KNN Loss: 2.996431350708008 | CLS Loss: 0.07319246232509613\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 3.086629867553711 | KNN Loss: 3.0184872150421143 | CLS Loss: 0.06814267486333847\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 3.097280979156494 | KNN Loss: 3.018400192260742 | CLS Loss: 0.0788806900382042\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 3.0808956623077393 | KNN Loss: 2.9835057258605957 | CLS Loss: 0.0973898321390152\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 3.1047465801239014 | KNN Loss: 3.018012523651123 | CLS Loss: 0.08673404157161713\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 3.1131319999694824 | KNN Loss: 3.082456350326538 | CLS Loss: 0.030675679445266724\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 3.0891525745391846 | KNN Loss: 3.0357398986816406 | CLS Loss: 0.05341270565986633\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 3.087475299835205 | KNN Loss: 3.0432968139648438 | CLS Loss: 0.044178564101457596\n",
      "Epoch: 019, Loss: 3.0832, Train: 0.9857, Valid: 0.9820, Best: 0.9820\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 3.1126763820648193 | KNN Loss: 3.053571939468384 | CLS Loss: 0.05910440534353256\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 3.0651726722717285 | KNN Loss: 3.034515857696533 | CLS Loss: 0.030656900256872177\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 3.1041462421417236 | KNN Loss: 3.0199763774871826 | CLS Loss: 0.0841698870062828\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 3.076111316680908 | KNN Loss: 3.016558885574341 | CLS Loss: 0.059552356600761414\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 3.051316976547241 | KNN Loss: 3.0014607906341553 | CLS Loss: 0.049856141209602356\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 3.0707321166992188 | KNN Loss: 3.0195930004119873 | CLS Loss: 0.05113912746310234\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 3.073349952697754 | KNN Loss: 3.0087528228759766 | CLS Loss: 0.06459703296422958\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 3.0753424167633057 | KNN Loss: 3.010669231414795 | CLS Loss: 0.0646732747554779\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 3.124884605407715 | KNN Loss: 3.0057458877563477 | CLS Loss: 0.11913871020078659\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 3.064694881439209 | KNN Loss: 3.0147740840911865 | CLS Loss: 0.04992068558931351\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 3.0953924655914307 | KNN Loss: 3.0333099365234375 | CLS Loss: 0.062082428485155106\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 3.0998520851135254 | KNN Loss: 3.043534517288208 | CLS Loss: 0.05631747096776962\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 3.0803871154785156 | KNN Loss: 2.9915671348571777 | CLS Loss: 0.08882001042366028\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 3.0537421703338623 | KNN Loss: 3.0187923908233643 | CLS Loss: 0.034949805587530136\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 3.123215913772583 | KNN Loss: 3.059908390045166 | CLS Loss: 0.06330742686986923\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 3.08325457572937 | KNN Loss: 2.999690294265747 | CLS Loss: 0.08356435596942902\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 3.047791004180908 | KNN Loss: 3.01157808303833 | CLS Loss: 0.03621295467019081\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 3.1107683181762695 | KNN Loss: 2.991364002227783 | CLS Loss: 0.11940421909093857\n",
      "Epoch: 020, Loss: 3.0745, Train: 0.9864, Valid: 0.9809, Best: 0.9820\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 3.101714611053467 | KNN Loss: 3.0489959716796875 | CLS Loss: 0.05271873250603676\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 3.056154251098633 | KNN Loss: 2.992069721221924 | CLS Loss: 0.06408445537090302\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 3.0807008743286133 | KNN Loss: 3.0099027156829834 | CLS Loss: 0.07079818844795227\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 3.0757997035980225 | KNN Loss: 3.0320396423339844 | CLS Loss: 0.04376010224223137\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 3.04935884475708 | KNN Loss: 3.0133554935455322 | CLS Loss: 0.036003392189741135\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 3.0793604850769043 | KNN Loss: 3.006356954574585 | CLS Loss: 0.07300354540348053\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 3.073946475982666 | KNN Loss: 2.996617078781128 | CLS Loss: 0.07732948660850525\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 3.0483336448669434 | KNN Loss: 3.0132052898406982 | CLS Loss: 0.0351283960044384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 3.072303533554077 | KNN Loss: 3.0304126739501953 | CLS Loss: 0.041890885680913925\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 3.106809139251709 | KNN Loss: 3.0574450492858887 | CLS Loss: 0.04936406761407852\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 3.0857889652252197 | KNN Loss: 2.992156505584717 | CLS Loss: 0.09363243728876114\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 3.0656545162200928 | KNN Loss: 3.009784460067749 | CLS Loss: 0.0558699406683445\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 3.1175971031188965 | KNN Loss: 3.027939558029175 | CLS Loss: 0.08965752273797989\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 3.1061408519744873 | KNN Loss: 3.034520387649536 | CLS Loss: 0.07162037491798401\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 3.078258752822876 | KNN Loss: 3.0179920196533203 | CLS Loss: 0.06026671081781387\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 3.096146821975708 | KNN Loss: 3.0368242263793945 | CLS Loss: 0.05932263657450676\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 3.120051145553589 | KNN Loss: 3.066002130508423 | CLS Loss: 0.05404894798994064\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 3.0392203330993652 | KNN Loss: 2.9902710914611816 | CLS Loss: 0.04894919693470001\n",
      "Epoch: 021, Loss: 3.0788, Train: 0.9867, Valid: 0.9820, Best: 0.9820\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 3.043883800506592 | KNN Loss: 2.9988553524017334 | CLS Loss: 0.045028507709503174\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 3.0905864238739014 | KNN Loss: 3.025312662124634 | CLS Loss: 0.06527379900217056\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 3.0044565200805664 | KNN Loss: 2.9601283073425293 | CLS Loss: 0.044328104704618454\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 3.0764219760894775 | KNN Loss: 3.042945623397827 | CLS Loss: 0.03347643464803696\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 3.061264991760254 | KNN Loss: 3.0064597129821777 | CLS Loss: 0.054805196821689606\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 3.036935806274414 | KNN Loss: 3.0027859210968018 | CLS Loss: 0.03414991497993469\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 3.0851902961730957 | KNN Loss: 3.0025389194488525 | CLS Loss: 0.08265142887830734\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 3.0811963081359863 | KNN Loss: 3.0379750728607178 | CLS Loss: 0.04322127625346184\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 3.0474460124969482 | KNN Loss: 3.0065042972564697 | CLS Loss: 0.04094167426228523\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 3.0926756858825684 | KNN Loss: 3.0317578315734863 | CLS Loss: 0.06091786548495293\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 3.0553038120269775 | KNN Loss: 2.973330020904541 | CLS Loss: 0.08197373151779175\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 3.107412099838257 | KNN Loss: 3.0558149814605713 | CLS Loss: 0.051597192883491516\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 3.0644519329071045 | KNN Loss: 2.992788791656494 | CLS Loss: 0.07166315615177155\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 3.050153970718384 | KNN Loss: 2.9727466106414795 | CLS Loss: 0.07740728557109833\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 3.0909347534179688 | KNN Loss: 2.9939608573913574 | CLS Loss: 0.09697383642196655\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 3.060591459274292 | KNN Loss: 2.9878225326538086 | CLS Loss: 0.07276886701583862\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 3.059173583984375 | KNN Loss: 3.0243732929229736 | CLS Loss: 0.03480037674307823\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 3.053464412689209 | KNN Loss: 2.9892544746398926 | CLS Loss: 0.06420990079641342\n",
      "Epoch: 022, Loss: 3.0712, Train: 0.9867, Valid: 0.9820, Best: 0.9820\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 3.031599998474121 | KNN Loss: 2.999501943588257 | CLS Loss: 0.03209799528121948\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 3.057729482650757 | KNN Loss: 3.023893356323242 | CLS Loss: 0.033836208283901215\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 3.026500940322876 | KNN Loss: 2.9656453132629395 | CLS Loss: 0.060855742543935776\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 3.0455360412597656 | KNN Loss: 2.9853873252868652 | CLS Loss: 0.06014874577522278\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 3.0981087684631348 | KNN Loss: 3.0139212608337402 | CLS Loss: 0.08418762683868408\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 3.062270402908325 | KNN Loss: 3.0129754543304443 | CLS Loss: 0.04929489269852638\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 3.081055164337158 | KNN Loss: 3.023820161819458 | CLS Loss: 0.057234980165958405\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 3.0713632106781006 | KNN Loss: 3.0129570960998535 | CLS Loss: 0.058406151831150055\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 3.072936534881592 | KNN Loss: 3.030914545059204 | CLS Loss: 0.04202210158109665\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 3.070729970932007 | KNN Loss: 2.988161087036133 | CLS Loss: 0.08256886899471283\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 3.105991840362549 | KNN Loss: 3.0562479496002197 | CLS Loss: 0.04974382743239403\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 3.075047492980957 | KNN Loss: 3.0388400554656982 | CLS Loss: 0.03620743751525879\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 3.1060574054718018 | KNN Loss: 2.99552583694458 | CLS Loss: 0.11053156852722168\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 3.1074471473693848 | KNN Loss: 3.038245916366577 | CLS Loss: 0.06920129060745239\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 3.0706279277801514 | KNN Loss: 3.0100064277648926 | CLS Loss: 0.060621537268161774\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 3.059429407119751 | KNN Loss: 2.987731456756592 | CLS Loss: 0.07169793546199799\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 3.110060453414917 | KNN Loss: 3.0452141761779785 | CLS Loss: 0.06484618037939072\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 3.0376081466674805 | KNN Loss: 3.001112699508667 | CLS Loss: 0.03649543970823288\n",
      "Epoch: 023, Loss: 3.0682, Train: 0.9866, Valid: 0.9819, Best: 0.9820\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 3.0447998046875 | KNN Loss: 3.021613359451294 | CLS Loss: 0.023186372593045235\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 3.0576062202453613 | KNN Loss: 2.983070135116577 | CLS Loss: 0.07453599572181702\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 3.06251859664917 | KNN Loss: 2.9886112213134766 | CLS Loss: 0.0739072784781456\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 3.0649869441986084 | KNN Loss: 3.021799087524414 | CLS Loss: 0.043187811970710754\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 3.0710439682006836 | KNN Loss: 3.0271847248077393 | CLS Loss: 0.04385929927229881\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 3.076046943664551 | KNN Loss: 3.0144081115722656 | CLS Loss: 0.06163882836699486\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 3.0717780590057373 | KNN Loss: 3.019108295440674 | CLS Loss: 0.05266968905925751\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 3.085808515548706 | KNN Loss: 3.051279306411743 | CLS Loss: 0.03452911972999573\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 3.0746278762817383 | KNN Loss: 3.0189504623413086 | CLS Loss: 0.05567752942442894\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 3.0616095066070557 | KNN Loss: 2.999279737472534 | CLS Loss: 0.062329720705747604\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 3.058694839477539 | KNN Loss: 2.9890897274017334 | CLS Loss: 0.06960510462522507\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 3.066321849822998 | KNN Loss: 3.033370018005371 | CLS Loss: 0.03295186534523964\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 3.0710320472717285 | KNN Loss: 3.0029993057250977 | CLS Loss: 0.06803280115127563\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 3.05094313621521 | KNN Loss: 3.0130436420440674 | CLS Loss: 0.03789940103888512\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 3.0725772380828857 | KNN Loss: 3.0165159702301025 | CLS Loss: 0.05606137961149216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 3.0880792140960693 | KNN Loss: 3.023932933807373 | CLS Loss: 0.06414623558521271\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 3.1041336059570312 | KNN Loss: 3.0562996864318848 | CLS Loss: 0.04783383384346962\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 3.0745058059692383 | KNN Loss: 3.0173163414001465 | CLS Loss: 0.05718955770134926\n",
      "Epoch: 024, Loss: 3.0675, Train: 0.9862, Valid: 0.9816, Best: 0.9820\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 3.1071107387542725 | KNN Loss: 3.054157257080078 | CLS Loss: 0.052953582257032394\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 3.078192710876465 | KNN Loss: 2.9919002056121826 | CLS Loss: 0.08629250526428223\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 3.0160980224609375 | KNN Loss: 2.994378089904785 | CLS Loss: 0.02171992138028145\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 3.053192138671875 | KNN Loss: 2.9841277599334717 | CLS Loss: 0.0690644159913063\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 3.046286106109619 | KNN Loss: 2.994567394256592 | CLS Loss: 0.051718663424253464\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 3.045553684234619 | KNN Loss: 3.0157957077026367 | CLS Loss: 0.029757868498563766\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 3.076409101486206 | KNN Loss: 3.0552594661712646 | CLS Loss: 0.021149713546037674\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 3.0886640548706055 | KNN Loss: 3.0297634601593018 | CLS Loss: 0.05890052020549774\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 3.074608087539673 | KNN Loss: 3.011245012283325 | CLS Loss: 0.06336310505867004\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 3.093024969100952 | KNN Loss: 3.0477492809295654 | CLS Loss: 0.04527575150132179\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 3.0950498580932617 | KNN Loss: 3.021866798400879 | CLS Loss: 0.07318302243947983\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 3.020610809326172 | KNN Loss: 2.990880012512207 | CLS Loss: 0.02973075397312641\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 3.0704567432403564 | KNN Loss: 3.0068519115448 | CLS Loss: 0.06360486894845963\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 3.088301181793213 | KNN Loss: 3.0461409091949463 | CLS Loss: 0.0421602688729763\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 3.081923246383667 | KNN Loss: 3.003422260284424 | CLS Loss: 0.07850103825330734\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 3.0463712215423584 | KNN Loss: 3.012813091278076 | CLS Loss: 0.03355801850557327\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 3.065964460372925 | KNN Loss: 3.041156768798828 | CLS Loss: 0.024807699024677277\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 3.0644915103912354 | KNN Loss: 3.0084762573242188 | CLS Loss: 0.05601527541875839\n",
      "Epoch: 025, Loss: 3.0653, Train: 0.9828, Valid: 0.9767, Best: 0.9820\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 3.0510404109954834 | KNN Loss: 3.0081593990325928 | CLS Loss: 0.04288109391927719\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 3.0798771381378174 | KNN Loss: 3.0159313678741455 | CLS Loss: 0.06394574046134949\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 3.091280221939087 | KNN Loss: 3.024280071258545 | CLS Loss: 0.06700015068054199\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 3.068136215209961 | KNN Loss: 3.0158965587615967 | CLS Loss: 0.052239611744880676\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 3.076871633529663 | KNN Loss: 3.033689498901367 | CLS Loss: 0.04318220540881157\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 3.0463201999664307 | KNN Loss: 3.021149158477783 | CLS Loss: 0.02517097070813179\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 3.0094962120056152 | KNN Loss: 2.9506146907806396 | CLS Loss: 0.0588814951479435\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 3.06772518157959 | KNN Loss: 3.016615867614746 | CLS Loss: 0.05110938847064972\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 3.0462822914123535 | KNN Loss: 2.9795215129852295 | CLS Loss: 0.0667608454823494\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 3.0706753730773926 | KNN Loss: 3.0230727195739746 | CLS Loss: 0.04760263115167618\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 3.0538125038146973 | KNN Loss: 3.0248730182647705 | CLS Loss: 0.028939390555024147\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 3.0467963218688965 | KNN Loss: 3.0126709938049316 | CLS Loss: 0.03412529081106186\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 3.0560481548309326 | KNN Loss: 3.0061798095703125 | CLS Loss: 0.049868352711200714\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 3.086782693862915 | KNN Loss: 3.0289087295532227 | CLS Loss: 0.057874035090208054\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 3.058377265930176 | KNN Loss: 2.983187437057495 | CLS Loss: 0.07518994808197021\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 3.042954206466675 | KNN Loss: 2.993204116821289 | CLS Loss: 0.04975007846951485\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 3.0627501010894775 | KNN Loss: 3.0260298252105713 | CLS Loss: 0.03672033175826073\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 3.031636953353882 | KNN Loss: 2.999715566635132 | CLS Loss: 0.03192131593823433\n",
      "Epoch: 026, Loss: 3.0632, Train: 0.9865, Valid: 0.9827, Best: 0.9827\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 3.067110300064087 | KNN Loss: 3.02409029006958 | CLS Loss: 0.04301992803812027\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 3.056015968322754 | KNN Loss: 3.0087811946868896 | CLS Loss: 0.04723484814167023\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 3.051725387573242 | KNN Loss: 3.012420177459717 | CLS Loss: 0.03930511698126793\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 3.076092004776001 | KNN Loss: 2.998891830444336 | CLS Loss: 0.07720020413398743\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 3.0880308151245117 | KNN Loss: 3.0638606548309326 | CLS Loss: 0.024170128628611565\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 3.0782175064086914 | KNN Loss: 3.027020215988159 | CLS Loss: 0.05119728296995163\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 3.044541120529175 | KNN Loss: 3.025973320007324 | CLS Loss: 0.018567794933915138\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 3.065084934234619 | KNN Loss: 3.049161672592163 | CLS Loss: 0.015923239290714264\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 3.0831832885742188 | KNN Loss: 3.0133960247039795 | CLS Loss: 0.0697871595621109\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 3.1018919944763184 | KNN Loss: 3.048424243927002 | CLS Loss: 0.053467757999897\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 3.048680543899536 | KNN Loss: 2.980151891708374 | CLS Loss: 0.06852869689464569\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 3.0867648124694824 | KNN Loss: 3.0218615531921387 | CLS Loss: 0.06490316987037659\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 3.085000991821289 | KNN Loss: 3.037181854248047 | CLS Loss: 0.047819189727306366\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 3.019104242324829 | KNN Loss: 2.9761464595794678 | CLS Loss: 0.042957715690135956\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 3.075468063354492 | KNN Loss: 3.0407984256744385 | CLS Loss: 0.03466964140534401\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 3.125000476837158 | KNN Loss: 3.0575084686279297 | CLS Loss: 0.0674920454621315\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 3.0588598251342773 | KNN Loss: 2.9858341217041016 | CLS Loss: 0.07302559167146683\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 3.0664565563201904 | KNN Loss: 3.007157802581787 | CLS Loss: 0.05929871276021004\n",
      "Epoch: 027, Loss: 3.0597, Train: 0.9867, Valid: 0.9809, Best: 0.9827\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 3.083631992340088 | KNN Loss: 3.034193754196167 | CLS Loss: 0.049438219517469406\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 3.07089900970459 | KNN Loss: 3.0292980670928955 | CLS Loss: 0.04160093143582344\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 3.058896780014038 | KNN Loss: 3.00412917137146 | CLS Loss: 0.054767586290836334\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 3.0394201278686523 | KNN Loss: 3.0020103454589844 | CLS Loss: 0.03740987181663513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 3.0965096950531006 | KNN Loss: 3.0548324584960938 | CLS Loss: 0.04167718440294266\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 3.076524496078491 | KNN Loss: 3.0198299884796143 | CLS Loss: 0.05669456720352173\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 3.093820095062256 | KNN Loss: 3.0308022499084473 | CLS Loss: 0.0630178153514862\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 3.044827461242676 | KNN Loss: 2.990917444229126 | CLS Loss: 0.05391012132167816\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 3.0495588779449463 | KNN Loss: 2.9970035552978516 | CLS Loss: 0.052555374801158905\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 3.11285400390625 | KNN Loss: 3.0553159713745117 | CLS Loss: 0.057538073509931564\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 3.0618841648101807 | KNN Loss: 2.994277238845825 | CLS Loss: 0.06760697811841965\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 3.0767714977264404 | KNN Loss: 3.0357248783111572 | CLS Loss: 0.041046708822250366\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 3.0226354598999023 | KNN Loss: 2.99918532371521 | CLS Loss: 0.023450054228305817\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 3.0720787048339844 | KNN Loss: 3.025726079940796 | CLS Loss: 0.04635263979434967\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 3.104907512664795 | KNN Loss: 3.062638998031616 | CLS Loss: 0.04226839542388916\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 3.0715763568878174 | KNN Loss: 3.0107929706573486 | CLS Loss: 0.06078328564763069\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 3.038266897201538 | KNN Loss: 3.000084161758423 | CLS Loss: 0.03818274289369583\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 3.0541000366210938 | KNN Loss: 3.023256301879883 | CLS Loss: 0.030843831598758698\n",
      "Epoch: 028, Loss: 3.0623, Train: 0.9854, Valid: 0.9810, Best: 0.9827\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 3.0663411617279053 | KNN Loss: 3.001505136489868 | CLS Loss: 0.0648360326886177\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 3.044135093688965 | KNN Loss: 3.0081982612609863 | CLS Loss: 0.0359368696808815\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 3.1055493354797363 | KNN Loss: 3.054145097732544 | CLS Loss: 0.05140417441725731\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 3.0616111755371094 | KNN Loss: 3.0394556522369385 | CLS Loss: 0.022155415266752243\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 3.0338540077209473 | KNN Loss: 3.00115966796875 | CLS Loss: 0.032694339752197266\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 3.078097343444824 | KNN Loss: 2.989689588546753 | CLS Loss: 0.08840785175561905\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 3.051586627960205 | KNN Loss: 2.9947972297668457 | CLS Loss: 0.056789331138134\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 3.0975563526153564 | KNN Loss: 3.0222954750061035 | CLS Loss: 0.07526078075170517\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 3.0726895332336426 | KNN Loss: 3.018474578857422 | CLS Loss: 0.054215021431446075\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 3.0635268688201904 | KNN Loss: 2.993558645248413 | CLS Loss: 0.06996822357177734\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 3.0909640789031982 | KNN Loss: 3.0087835788726807 | CLS Loss: 0.08218058943748474\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 3.0891690254211426 | KNN Loss: 3.031843662261963 | CLS Loss: 0.057325296103954315\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 3.0672576427459717 | KNN Loss: 3.0251355171203613 | CLS Loss: 0.04212218150496483\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 3.0584235191345215 | KNN Loss: 2.992666006088257 | CLS Loss: 0.06575747579336166\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 3.076669692993164 | KNN Loss: 3.0469534397125244 | CLS Loss: 0.029716255143284798\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 3.0220980644226074 | KNN Loss: 2.996159076690674 | CLS Loss: 0.02593901753425598\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 3.054394245147705 | KNN Loss: 3.0188403129577637 | CLS Loss: 0.0355539470911026\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 3.0629518032073975 | KNN Loss: 3.0271260738372803 | CLS Loss: 0.03582575544714928\n",
      "Epoch: 029, Loss: 3.0647, Train: 0.9893, Valid: 0.9836, Best: 0.9836\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 3.0644752979278564 | KNN Loss: 2.975715398788452 | CLS Loss: 0.08875986933708191\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 3.0577471256256104 | KNN Loss: 3.011951446533203 | CLS Loss: 0.045795734971761703\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 3.0449013710021973 | KNN Loss: 3.011598825454712 | CLS Loss: 0.03330262377858162\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 3.027848958969116 | KNN Loss: 2.996406316757202 | CLS Loss: 0.03144261986017227\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 3.0969109535217285 | KNN Loss: 3.0147969722747803 | CLS Loss: 0.08211388438940048\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 3.080796718597412 | KNN Loss: 3.0361993312835693 | CLS Loss: 0.04459736868739128\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 3.0889158248901367 | KNN Loss: 3.024041175842285 | CLS Loss: 0.0648745447397232\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 3.11449933052063 | KNN Loss: 3.0362861156463623 | CLS Loss: 0.0782131478190422\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 3.0428333282470703 | KNN Loss: 3.014348030090332 | CLS Loss: 0.028485218062996864\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 3.0332462787628174 | KNN Loss: 2.988992214202881 | CLS Loss: 0.044254135340452194\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 3.053584337234497 | KNN Loss: 3.0300471782684326 | CLS Loss: 0.0235371682792902\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 3.105436325073242 | KNN Loss: 3.0408079624176025 | CLS Loss: 0.06462831050157547\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 3.093108654022217 | KNN Loss: 3.037595748901367 | CLS Loss: 0.05551298335194588\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 3.0267810821533203 | KNN Loss: 2.994555711746216 | CLS Loss: 0.032225482165813446\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 3.0548956394195557 | KNN Loss: 3.030247211456299 | CLS Loss: 0.024648427963256836\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 3.0336949825286865 | KNN Loss: 2.9786722660064697 | CLS Loss: 0.0550227053463459\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 3.0506954193115234 | KNN Loss: 3.018289089202881 | CLS Loss: 0.03240644186735153\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 3.047238349914551 | KNN Loss: 2.9970285892486572 | CLS Loss: 0.050209708511829376\n",
      "Epoch: 030, Loss: 3.0567, Train: 0.9882, Valid: 0.9826, Best: 0.9836\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 3.0465097427368164 | KNN Loss: 3.0063822269439697 | CLS Loss: 0.04012740030884743\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 3.0885095596313477 | KNN Loss: 3.047671318054199 | CLS Loss: 0.04083814099431038\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 3.0500330924987793 | KNN Loss: 3.009438991546631 | CLS Loss: 0.040594153106212616\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 3.0722973346710205 | KNN Loss: 2.9909913539886475 | CLS Loss: 0.08130605518817902\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 3.0544826984405518 | KNN Loss: 3.020775079727173 | CLS Loss: 0.03370759263634682\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 3.0350823402404785 | KNN Loss: 3.0023794174194336 | CLS Loss: 0.03270300477743149\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 3.0589842796325684 | KNN Loss: 2.9743824005126953 | CLS Loss: 0.08460187166929245\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 3.090209484100342 | KNN Loss: 3.022831439971924 | CLS Loss: 0.06737799197435379\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 3.0556535720825195 | KNN Loss: 3.0331006050109863 | CLS Loss: 0.02255285531282425\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 3.034519910812378 | KNN Loss: 3.0118751525878906 | CLS Loss: 0.02264486253261566\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 3.056615114212036 | KNN Loss: 3.004617929458618 | CLS Loss: 0.05199712514877319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 3.030496120452881 | KNN Loss: 3.0028512477874756 | CLS Loss: 0.027644770219922066\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 3.0511116981506348 | KNN Loss: 3.0235025882720947 | CLS Loss: 0.027609193697571754\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 3.0730271339416504 | KNN Loss: 2.9977052211761475 | CLS Loss: 0.07532180100679398\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 3.1093688011169434 | KNN Loss: 3.0171923637390137 | CLS Loss: 0.09217637777328491\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 3.046893358230591 | KNN Loss: 3.0313942432403564 | CLS Loss: 0.015499157831072807\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 3.046731472015381 | KNN Loss: 3.0217323303222656 | CLS Loss: 0.02499902807176113\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 3.037355899810791 | KNN Loss: 2.9954833984375 | CLS Loss: 0.0418725460767746\n",
      "Epoch: 031, Loss: 3.0548, Train: 0.9901, Valid: 0.9840, Best: 0.9840\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 3.07254958152771 | KNN Loss: 3.0289599895477295 | CLS Loss: 0.043589480221271515\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 3.0924437046051025 | KNN Loss: 3.0453009605407715 | CLS Loss: 0.04714272916316986\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 3.01088809967041 | KNN Loss: 2.9845240116119385 | CLS Loss: 0.026364071294665337\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 3.050926923751831 | KNN Loss: 3.019864559173584 | CLS Loss: 0.03106245957314968\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 3.0380749702453613 | KNN Loss: 3.001319169998169 | CLS Loss: 0.03675584867596626\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 3.0201308727264404 | KNN Loss: 2.9837772846221924 | CLS Loss: 0.036353547126054764\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 3.0348916053771973 | KNN Loss: 2.981612205505371 | CLS Loss: 0.05327951908111572\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 3.03121018409729 | KNN Loss: 3.004192590713501 | CLS Loss: 0.02701757661998272\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 3.0180270671844482 | KNN Loss: 2.9850428104400635 | CLS Loss: 0.03298418968915939\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 3.030069351196289 | KNN Loss: 3.012883186340332 | CLS Loss: 0.017186187207698822\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 3.049870014190674 | KNN Loss: 3.0104360580444336 | CLS Loss: 0.03943402320146561\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 3.028423309326172 | KNN Loss: 2.97554087638855 | CLS Loss: 0.05288238823413849\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 3.073686361312866 | KNN Loss: 3.0094046592712402 | CLS Loss: 0.06428179889917374\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 3.020709991455078 | KNN Loss: 2.996782064437866 | CLS Loss: 0.023927943781018257\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 3.024651050567627 | KNN Loss: 2.961749315261841 | CLS Loss: 0.06290178000926971\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 3.0575358867645264 | KNN Loss: 3.0366439819335938 | CLS Loss: 0.02089192159473896\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 3.01839542388916 | KNN Loss: 2.980391025543213 | CLS Loss: 0.03800439089536667\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 3.0262913703918457 | KNN Loss: 2.9922518730163574 | CLS Loss: 0.034039512276649475\n",
      "Epoch: 032, Loss: 3.0547, Train: 0.9902, Valid: 0.9847, Best: 0.9847\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 3.049105167388916 | KNN Loss: 3.0001423358917236 | CLS Loss: 0.048962898552417755\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 3.056300640106201 | KNN Loss: 3.0092556476593018 | CLS Loss: 0.04704504460096359\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 2.9936420917510986 | KNN Loss: 2.9672107696533203 | CLS Loss: 0.026431318372488022\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 3.0670342445373535 | KNN Loss: 3.0237717628479004 | CLS Loss: 0.04326247051358223\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 3.0277910232543945 | KNN Loss: 3.009641647338867 | CLS Loss: 0.018149323761463165\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 3.0684621334075928 | KNN Loss: 3.0114247798919678 | CLS Loss: 0.057037368416786194\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 3.05107045173645 | KNN Loss: 3.020263433456421 | CLS Loss: 0.030807066708803177\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 3.0150418281555176 | KNN Loss: 2.983074426651001 | CLS Loss: 0.031967490911483765\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 3.0543665885925293 | KNN Loss: 3.028750419616699 | CLS Loss: 0.025616208091378212\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 3.0884933471679688 | KNN Loss: 3.032386064529419 | CLS Loss: 0.05610736459493637\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 3.022799491882324 | KNN Loss: 2.990504503250122 | CLS Loss: 0.03229496628046036\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 3.003857374191284 | KNN Loss: 2.9811229705810547 | CLS Loss: 0.022734470665454865\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 3.062812328338623 | KNN Loss: 3.0313243865966797 | CLS Loss: 0.03148799389600754\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 3.0517754554748535 | KNN Loss: 3.0140151977539062 | CLS Loss: 0.037760283797979355\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 3.0527143478393555 | KNN Loss: 3.01835298538208 | CLS Loss: 0.03436141461133957\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 3.0268149375915527 | KNN Loss: 2.985664129257202 | CLS Loss: 0.04115086793899536\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 3.0482277870178223 | KNN Loss: 3.0216801166534424 | CLS Loss: 0.026547720655798912\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 3.107731342315674 | KNN Loss: 3.08716082572937 | CLS Loss: 0.020570451393723488\n",
      "Epoch: 033, Loss: 3.0529, Train: 0.9894, Valid: 0.9839, Best: 0.9847\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 3.0199193954467773 | KNN Loss: 3.0104215145111084 | CLS Loss: 0.009497961960732937\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 3.0665650367736816 | KNN Loss: 3.0192129611968994 | CLS Loss: 0.047352004796266556\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 3.0489702224731445 | KNN Loss: 2.9642117023468018 | CLS Loss: 0.08475849777460098\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 3.0214340686798096 | KNN Loss: 3.0061089992523193 | CLS Loss: 0.015325099229812622\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 3.0438332557678223 | KNN Loss: 3.017778158187866 | CLS Loss: 0.026055211201310158\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 3.053065061569214 | KNN Loss: 3.021209716796875 | CLS Loss: 0.03185528889298439\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 3.0490570068359375 | KNN Loss: 2.9982969760894775 | CLS Loss: 0.05076000094413757\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 3.0588104724884033 | KNN Loss: 3.0346994400024414 | CLS Loss: 0.024111123755574226\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 3.054597854614258 | KNN Loss: 3.015964984893799 | CLS Loss: 0.03863277658820152\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 3.046168804168701 | KNN Loss: 2.960564613342285 | CLS Loss: 0.08560420572757721\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 3.054625988006592 | KNN Loss: 2.998847723007202 | CLS Loss: 0.05577836558222771\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 3.047206401824951 | KNN Loss: 3.009402275085449 | CLS Loss: 0.037804245948791504\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 3.055269956588745 | KNN Loss: 2.9803264141082764 | CLS Loss: 0.07494359463453293\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 3.0768792629241943 | KNN Loss: 3.061699867248535 | CLS Loss: 0.015179445967078209\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 3.070115089416504 | KNN Loss: 3.0209925174713135 | CLS Loss: 0.04912250488996506\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 3.0650880336761475 | KNN Loss: 3.0098166465759277 | CLS Loss: 0.05527133122086525\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 3.050030469894409 | KNN Loss: 3.01369571685791 | CLS Loss: 0.036334775388240814\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 3.0554556846618652 | KNN Loss: 2.991795539855957 | CLS Loss: 0.06366007775068283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 3.0544, Train: 0.9902, Valid: 0.9843, Best: 0.9847\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 3.002249002456665 | KNN Loss: 2.979762315750122 | CLS Loss: 0.022486748173832893\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 3.005972385406494 | KNN Loss: 2.9862120151519775 | CLS Loss: 0.01976034790277481\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 3.07405424118042 | KNN Loss: 3.065553903579712 | CLS Loss: 0.008500357158482075\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 3.0086770057678223 | KNN Loss: 2.958332061767578 | CLS Loss: 0.05034501478075981\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 3.0729494094848633 | KNN Loss: 3.030625820159912 | CLS Loss: 0.042323511093854904\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 3.0724589824676514 | KNN Loss: 2.9882192611694336 | CLS Loss: 0.08423981070518494\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 3.079284191131592 | KNN Loss: 3.0226094722747803 | CLS Loss: 0.05667470768094063\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 3.049956798553467 | KNN Loss: 3.0160186290740967 | CLS Loss: 0.03393810987472534\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 3.065404176712036 | KNN Loss: 3.007627248764038 | CLS Loss: 0.05777696147561073\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 3.0134966373443604 | KNN Loss: 2.993715524673462 | CLS Loss: 0.019781185314059258\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 3.037386417388916 | KNN Loss: 2.9897024631500244 | CLS Loss: 0.04768391698598862\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 3.0945773124694824 | KNN Loss: 3.062995433807373 | CLS Loss: 0.03158179298043251\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 3.1144027709960938 | KNN Loss: 3.0577104091644287 | CLS Loss: 0.056692395359277725\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 3.013861894607544 | KNN Loss: 2.967158794403076 | CLS Loss: 0.04670308157801628\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 3.0365612506866455 | KNN Loss: 2.999994993209839 | CLS Loss: 0.036566250026226044\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 3.030932664871216 | KNN Loss: 3.007744789123535 | CLS Loss: 0.023187829181551933\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 3.033092975616455 | KNN Loss: 3.0047202110290527 | CLS Loss: 0.02837272360920906\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 3.0382080078125 | KNN Loss: 3.016751289367676 | CLS Loss: 0.021456623449921608\n",
      "Epoch: 035, Loss: 3.0508, Train: 0.9896, Valid: 0.9839, Best: 0.9847\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 3.0392212867736816 | KNN Loss: 3.0033984184265137 | CLS Loss: 0.03582289069890976\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 3.068795919418335 | KNN Loss: 3.02290415763855 | CLS Loss: 0.04589179530739784\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 3.050506830215454 | KNN Loss: 3.0055441856384277 | CLS Loss: 0.04496268928050995\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 3.0471384525299072 | KNN Loss: 3.0072405338287354 | CLS Loss: 0.03989802300930023\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 3.0255584716796875 | KNN Loss: 2.9913737773895264 | CLS Loss: 0.03418457508087158\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 3.0363571643829346 | KNN Loss: 3.003052234649658 | CLS Loss: 0.0333048552274704\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 3.0816895961761475 | KNN Loss: 3.0335984230041504 | CLS Loss: 0.0480910949409008\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 3.068514347076416 | KNN Loss: 3.0488791465759277 | CLS Loss: 0.019635293632745743\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 3.0845630168914795 | KNN Loss: 3.0011484622955322 | CLS Loss: 0.08341459184885025\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 3.016563653945923 | KNN Loss: 2.9954164028167725 | CLS Loss: 0.02114715613424778\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 3.022169351577759 | KNN Loss: 2.981569528579712 | CLS Loss: 0.0405997708439827\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 3.080632448196411 | KNN Loss: 3.0188355445861816 | CLS Loss: 0.06179681047797203\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 3.0644378662109375 | KNN Loss: 2.9960110187530518 | CLS Loss: 0.06842672824859619\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 3.0633764266967773 | KNN Loss: 3.0362391471862793 | CLS Loss: 0.027137191966176033\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 3.0591766834259033 | KNN Loss: 3.028660297393799 | CLS Loss: 0.03051646798849106\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 3.02880597114563 | KNN Loss: 2.99955415725708 | CLS Loss: 0.029251722618937492\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 3.0561928749084473 | KNN Loss: 3.0017476081848145 | CLS Loss: 0.05444531887769699\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 3.0478248596191406 | KNN Loss: 3.0069549083709717 | CLS Loss: 0.040869902819395065\n",
      "Epoch: 036, Loss: 3.0527, Train: 0.9887, Valid: 0.9813, Best: 0.9847\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 3.021597385406494 | KNN Loss: 2.9781687259674072 | CLS Loss: 0.04342874139547348\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 3.039477586746216 | KNN Loss: 3.0188539028167725 | CLS Loss: 0.0206235870718956\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 3.046767473220825 | KNN Loss: 3.0307252407073975 | CLS Loss: 0.016042180359363556\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 3.061927556991577 | KNN Loss: 3.0171854496002197 | CLS Loss: 0.04474212974309921\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 3.0755162239074707 | KNN Loss: 3.045940637588501 | CLS Loss: 0.029575666412711143\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 3.0931742191314697 | KNN Loss: 3.0319221019744873 | CLS Loss: 0.061252083629369736\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 3.0360522270202637 | KNN Loss: 3.013605833053589 | CLS Loss: 0.022446442395448685\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 3.019134759902954 | KNN Loss: 2.996450901031494 | CLS Loss: 0.022683830931782722\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 3.039045572280884 | KNN Loss: 3.0229363441467285 | CLS Loss: 0.016109297052025795\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 3.0480306148529053 | KNN Loss: 3.0275356769561768 | CLS Loss: 0.020494917407631874\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 3.026805877685547 | KNN Loss: 2.999635696411133 | CLS Loss: 0.02717006392776966\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 3.024498701095581 | KNN Loss: 2.9918344020843506 | CLS Loss: 0.032664380967617035\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 3.0497405529022217 | KNN Loss: 2.989959716796875 | CLS Loss: 0.05978090688586235\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 3.0553462505340576 | KNN Loss: 3.0273654460906982 | CLS Loss: 0.027980878949165344\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 3.02480411529541 | KNN Loss: 2.983844757080078 | CLS Loss: 0.04095941781997681\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 3.039297342300415 | KNN Loss: 3.001676321029663 | CLS Loss: 0.03762108087539673\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 3.039353370666504 | KNN Loss: 3.015589714050293 | CLS Loss: 0.023763559758663177\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 3.0506508350372314 | KNN Loss: 3.015223741531372 | CLS Loss: 0.035427119582891464\n",
      "Epoch: 037, Loss: 3.0476, Train: 0.9911, Valid: 0.9849, Best: 0.9849\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 3.0465192794799805 | KNN Loss: 3.0216784477233887 | CLS Loss: 0.024840842932462692\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 3.0502188205718994 | KNN Loss: 3.01678729057312 | CLS Loss: 0.033431582152843475\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 3.060106039047241 | KNN Loss: 2.9989173412323 | CLS Loss: 0.06118860840797424\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 3.075561046600342 | KNN Loss: 3.03023099899292 | CLS Loss: 0.045329976826906204\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 3.1116347312927246 | KNN Loss: 3.073017120361328 | CLS Loss: 0.038617655634880066\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 3.102522611618042 | KNN Loss: 3.0900187492370605 | CLS Loss: 0.012503822334110737\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 3.040349006652832 | KNN Loss: 3.011244773864746 | CLS Loss: 0.029104145243763924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 3.0692670345306396 | KNN Loss: 3.0084216594696045 | CLS Loss: 0.06084538996219635\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 3.060638904571533 | KNN Loss: 3.014662027359009 | CLS Loss: 0.04597682133316994\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 3.050187587738037 | KNN Loss: 3.0145936012268066 | CLS Loss: 0.03559395670890808\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 3.0925381183624268 | KNN Loss: 3.0518741607666016 | CLS Loss: 0.040664032101631165\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 3.1179025173187256 | KNN Loss: 3.065650463104248 | CLS Loss: 0.052252147346735\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 3.0689852237701416 | KNN Loss: 3.0128448009490967 | CLS Loss: 0.0561404675245285\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 3.0371639728546143 | KNN Loss: 2.994481325149536 | CLS Loss: 0.042682696133852005\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 3.058029890060425 | KNN Loss: 3.0095770359039307 | CLS Loss: 0.04845287650823593\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 3.046347141265869 | KNN Loss: 2.978175640106201 | CLS Loss: 0.06817138940095901\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 3.0562100410461426 | KNN Loss: 3.010328531265259 | CLS Loss: 0.04588145390152931\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 3.049783945083618 | KNN Loss: 2.9986884593963623 | CLS Loss: 0.051095448434352875\n",
      "Epoch: 038, Loss: 3.0495, Train: 0.9909, Valid: 0.9844, Best: 0.9849\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 3.0212817192077637 | KNN Loss: 3.002452850341797 | CLS Loss: 0.01882895827293396\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 3.0606062412261963 | KNN Loss: 3.0496985912323 | CLS Loss: 0.010907759889960289\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 3.0514538288116455 | KNN Loss: 3.00361704826355 | CLS Loss: 0.047836706042289734\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 3.0693705081939697 | KNN Loss: 3.0378503799438477 | CLS Loss: 0.03152024373412132\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 3.0730180740356445 | KNN Loss: 3.0423598289489746 | CLS Loss: 0.030658315867185593\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 3.041116714477539 | KNN Loss: 2.987623929977417 | CLS Loss: 0.053492724895477295\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 2.9927802085876465 | KNN Loss: 2.964672803878784 | CLS Loss: 0.02810733951628208\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 3.067359209060669 | KNN Loss: 3.032215118408203 | CLS Loss: 0.035144031047821045\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 3.0097880363464355 | KNN Loss: 2.9906320571899414 | CLS Loss: 0.019155990332365036\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 3.0658326148986816 | KNN Loss: 3.031708240509033 | CLS Loss: 0.03412442281842232\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 3.0516257286071777 | KNN Loss: 3.0327649116516113 | CLS Loss: 0.018860777840018272\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 3.0619959831237793 | KNN Loss: 3.02838397026062 | CLS Loss: 0.03361201286315918\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 3.052029609680176 | KNN Loss: 3.0380899906158447 | CLS Loss: 0.013939661905169487\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 3.0734801292419434 | KNN Loss: 3.0272669792175293 | CLS Loss: 0.04621308669447899\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 3.092925786972046 | KNN Loss: 3.026268243789673 | CLS Loss: 0.06665748357772827\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 3.0320656299591064 | KNN Loss: 2.993101119995117 | CLS Loss: 0.03896450251340866\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 3.0723557472229004 | KNN Loss: 3.0284667015075684 | CLS Loss: 0.043889131397008896\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 3.0483968257904053 | KNN Loss: 3.0097551345825195 | CLS Loss: 0.03864166885614395\n",
      "Epoch: 039, Loss: 3.0463, Train: 0.9899, Valid: 0.9829, Best: 0.9849\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 3.080547332763672 | KNN Loss: 3.0306308269500732 | CLS Loss: 0.04991656914353371\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 3.0583271980285645 | KNN Loss: 3.039538860321045 | CLS Loss: 0.0187882911413908\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 3.034257411956787 | KNN Loss: 2.983651876449585 | CLS Loss: 0.05060553178191185\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 3.0525097846984863 | KNN Loss: 3.031445026397705 | CLS Loss: 0.02106464095413685\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 3.0613982677459717 | KNN Loss: 3.0108187198638916 | CLS Loss: 0.050579629838466644\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 3.0482585430145264 | KNN Loss: 2.995051860809326 | CLS Loss: 0.053206607699394226\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 3.0329325199127197 | KNN Loss: 3.0091640949249268 | CLS Loss: 0.023768410086631775\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 3.053523063659668 | KNN Loss: 3.0088582038879395 | CLS Loss: 0.044664908200502396\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 3.10353946685791 | KNN Loss: 3.025878429412842 | CLS Loss: 0.07766104489564896\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 3.018036127090454 | KNN Loss: 2.9922945499420166 | CLS Loss: 0.025741679593920708\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 3.0764055252075195 | KNN Loss: 3.0298337936401367 | CLS Loss: 0.04657163470983505\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 3.040879964828491 | KNN Loss: 2.9960267543792725 | CLS Loss: 0.04485321789979935\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 3.0337281227111816 | KNN Loss: 3.011869430541992 | CLS Loss: 0.021858597174286842\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 3.020860433578491 | KNN Loss: 2.9781653881073 | CLS Loss: 0.042694952338933945\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 3.0727944374084473 | KNN Loss: 3.0019569396972656 | CLS Loss: 0.07083737850189209\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 3.075845718383789 | KNN Loss: 3.033130645751953 | CLS Loss: 0.04271501302719116\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 3.0422191619873047 | KNN Loss: 3.0017449855804443 | CLS Loss: 0.04047410935163498\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 3.0596539974212646 | KNN Loss: 3.012286901473999 | CLS Loss: 0.04736720770597458\n",
      "Epoch: 040, Loss: 3.0464, Train: 0.9906, Valid: 0.9838, Best: 0.9849\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 3.0482187271118164 | KNN Loss: 3.029360771179199 | CLS Loss: 0.018858013674616814\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 3.020014524459839 | KNN Loss: 3.006685495376587 | CLS Loss: 0.01332913525402546\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 3.0459671020507812 | KNN Loss: 3.0077178478240967 | CLS Loss: 0.03824935480952263\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 3.07694935798645 | KNN Loss: 3.0007412433624268 | CLS Loss: 0.07620806246995926\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 3.0192642211914062 | KNN Loss: 3.002549648284912 | CLS Loss: 0.016714509576559067\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 3.0421719551086426 | KNN Loss: 2.9984214305877686 | CLS Loss: 0.04375063627958298\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 3.0607895851135254 | KNN Loss: 3.029604911804199 | CLS Loss: 0.031184561550617218\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 3.092376232147217 | KNN Loss: 3.0390729904174805 | CLS Loss: 0.05330314487218857\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 3.0350966453552246 | KNN Loss: 2.9994823932647705 | CLS Loss: 0.03561427444219589\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 3.0091540813446045 | KNN Loss: 2.986905574798584 | CLS Loss: 0.02224852330982685\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 3.073685884475708 | KNN Loss: 3.0498650074005127 | CLS Loss: 0.02382080815732479\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 3.0548949241638184 | KNN Loss: 3.0263092517852783 | CLS Loss: 0.028585562482476234\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 3.1189754009246826 | KNN Loss: 3.0576348304748535 | CLS Loss: 0.06134050711989403\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 3.080471992492676 | KNN Loss: 3.043670177459717 | CLS Loss: 0.036801815032958984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 3.04655122756958 | KNN Loss: 2.9815945625305176 | CLS Loss: 0.06495656818151474\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 3.021655321121216 | KNN Loss: 2.9990034103393555 | CLS Loss: 0.022651933133602142\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 3.0579395294189453 | KNN Loss: 3.010359525680542 | CLS Loss: 0.047580018639564514\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 3.0303218364715576 | KNN Loss: 3.0110747814178467 | CLS Loss: 0.019247055053710938\n",
      "Epoch: 041, Loss: 3.0479, Train: 0.9913, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 3.0330517292022705 | KNN Loss: 2.976486921310425 | CLS Loss: 0.05656488612294197\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 3.0319833755493164 | KNN Loss: 2.99629807472229 | CLS Loss: 0.03568527102470398\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 3.0837011337280273 | KNN Loss: 3.0506725311279297 | CLS Loss: 0.03302852064371109\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 3.0297346115112305 | KNN Loss: 3.0006520748138428 | CLS Loss: 0.02908242493867874\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 3.0471558570861816 | KNN Loss: 3.000697135925293 | CLS Loss: 0.04645867645740509\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 3.054800510406494 | KNN Loss: 3.0126519203186035 | CLS Loss: 0.04214848577976227\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 3.0450234413146973 | KNN Loss: 3.0092291831970215 | CLS Loss: 0.03579429164528847\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 3.070242166519165 | KNN Loss: 3.0470118522644043 | CLS Loss: 0.02323031611740589\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 3.066301107406616 | KNN Loss: 3.0014026165008545 | CLS Loss: 0.06489841639995575\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 3.0231077671051025 | KNN Loss: 3.0092201232910156 | CLS Loss: 0.013887702487409115\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 3.0799479484558105 | KNN Loss: 3.0273001194000244 | CLS Loss: 0.05264771729707718\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 3.076237678527832 | KNN Loss: 3.0444629192352295 | CLS Loss: 0.031774669885635376\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 3.051504135131836 | KNN Loss: 3.02112078666687 | CLS Loss: 0.030383406206965446\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 3.0681779384613037 | KNN Loss: 3.0384984016418457 | CLS Loss: 0.029679477214813232\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 3.0492613315582275 | KNN Loss: 3.0042266845703125 | CLS Loss: 0.045034702867269516\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 3.029468297958374 | KNN Loss: 3.0056159496307373 | CLS Loss: 0.023852387443184853\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 3.036447286605835 | KNN Loss: 3.01772141456604 | CLS Loss: 0.01872589997947216\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 3.0257210731506348 | KNN Loss: 3.0063419342041016 | CLS Loss: 0.01937909983098507\n",
      "Epoch: 042, Loss: 3.0491, Train: 0.9919, Valid: 0.9850, Best: 0.9860\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 3.0430819988250732 | KNN Loss: 3.00260329246521 | CLS Loss: 0.04047861695289612\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 3.0330071449279785 | KNN Loss: 2.9805827140808105 | CLS Loss: 0.05242443084716797\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 3.003417491912842 | KNN Loss: 2.9959716796875 | CLS Loss: 0.007445826660841703\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 3.061795711517334 | KNN Loss: 3.0431790351867676 | CLS Loss: 0.01861671172082424\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 3.0731699466705322 | KNN Loss: 3.0472848415374756 | CLS Loss: 0.025885144248604774\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 3.003840208053589 | KNN Loss: 2.9802310466766357 | CLS Loss: 0.023609234020113945\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 3.0955333709716797 | KNN Loss: 3.0513007640838623 | CLS Loss: 0.04423266649246216\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 3.066218376159668 | KNN Loss: 3.0362114906311035 | CLS Loss: 0.030007002875208855\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 3.0772716999053955 | KNN Loss: 3.057620048522949 | CLS Loss: 0.019651759415864944\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 3.0793216228485107 | KNN Loss: 3.036273956298828 | CLS Loss: 0.04304777830839157\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 3.0821473598480225 | KNN Loss: 3.009082317352295 | CLS Loss: 0.07306496798992157\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 3.064218044281006 | KNN Loss: 3.025629758834839 | CLS Loss: 0.038588181138038635\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 3.0321614742279053 | KNN Loss: 3.011582136154175 | CLS Loss: 0.020579447969794273\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 3.048588752746582 | KNN Loss: 3.0127058029174805 | CLS Loss: 0.03588306903839111\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 3.037119150161743 | KNN Loss: 3.0088469982147217 | CLS Loss: 0.02827209047973156\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 3.023380994796753 | KNN Loss: 2.9914968013763428 | CLS Loss: 0.03188418969511986\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 3.0490036010742188 | KNN Loss: 2.9981741905212402 | CLS Loss: 0.05082934349775314\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 3.02553391456604 | KNN Loss: 3.007780075073242 | CLS Loss: 0.01775384694337845\n",
      "Epoch: 043, Loss: 3.0435, Train: 0.9918, Valid: 0.9853, Best: 0.9860\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 2.9985511302948 | KNN Loss: 2.96768856048584 | CLS Loss: 0.03086266480386257\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 3.0249242782592773 | KNN Loss: 2.986234664916992 | CLS Loss: 0.03868969529867172\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 3.013371229171753 | KNN Loss: 3.0038437843322754 | CLS Loss: 0.009527347981929779\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 3.085930585861206 | KNN Loss: 3.0523135662078857 | CLS Loss: 0.0336170494556427\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 3.04931378364563 | KNN Loss: 3.0209975242614746 | CLS Loss: 0.02831631526350975\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 3.0385494232177734 | KNN Loss: 3.029048204421997 | CLS Loss: 0.009501240216195583\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 3.0661067962646484 | KNN Loss: 3.020003080368042 | CLS Loss: 0.0461038313806057\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 3.086355686187744 | KNN Loss: 3.020721912384033 | CLS Loss: 0.06563368439674377\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 3.011009454727173 | KNN Loss: 2.987694263458252 | CLS Loss: 0.023315144702792168\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 3.0366294384002686 | KNN Loss: 3.0163345336914062 | CLS Loss: 0.020294833928346634\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 3.0222036838531494 | KNN Loss: 3.0038743019104004 | CLS Loss: 0.018329355865716934\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 3.0268566608428955 | KNN Loss: 3.0068721771240234 | CLS Loss: 0.019984588027000427\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 2.9999067783355713 | KNN Loss: 2.9552884101867676 | CLS Loss: 0.04461841657757759\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 3.0283260345458984 | KNN Loss: 3.0031533241271973 | CLS Loss: 0.02517278492450714\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 3.024510145187378 | KNN Loss: 3.0158803462982178 | CLS Loss: 0.008629899471998215\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 3.0771238803863525 | KNN Loss: 3.042919874191284 | CLS Loss: 0.03420395404100418\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 3.068505048751831 | KNN Loss: 3.0377042293548584 | CLS Loss: 0.03080073930323124\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 3.0822510719299316 | KNN Loss: 3.046422243118286 | CLS Loss: 0.03582886606454849\n",
      "Epoch: 044, Loss: 3.0444, Train: 0.9907, Valid: 0.9841, Best: 0.9860\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 3.058506965637207 | KNN Loss: 3.0183184146881104 | CLS Loss: 0.04018864408135414\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 3.034519672393799 | KNN Loss: 3.0112099647521973 | CLS Loss: 0.023309793323278427\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 3.045466661453247 | KNN Loss: 3.021052122116089 | CLS Loss: 0.02441459521651268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 3.0256075859069824 | KNN Loss: 3.0115015506744385 | CLS Loss: 0.014105948619544506\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 3.079688310623169 | KNN Loss: 3.066108465194702 | CLS Loss: 0.013579923659563065\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 3.118647336959839 | KNN Loss: 3.092388868331909 | CLS Loss: 0.026258500292897224\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 3.034674644470215 | KNN Loss: 3.0099868774414062 | CLS Loss: 0.024687718600034714\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 3.0953006744384766 | KNN Loss: 3.0430116653442383 | CLS Loss: 0.052288953214883804\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 3.0714797973632812 | KNN Loss: 3.0464415550231934 | CLS Loss: 0.02503821812570095\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 3.0897979736328125 | KNN Loss: 3.0511820316314697 | CLS Loss: 0.038615882396698\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 3.0729310512542725 | KNN Loss: 3.035745859146118 | CLS Loss: 0.037185169756412506\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 3.07248592376709 | KNN Loss: 3.0468666553497314 | CLS Loss: 0.025619380176067352\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 3.027550458908081 | KNN Loss: 3.0005881786346436 | CLS Loss: 0.026962241157889366\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 3.0552306175231934 | KNN Loss: 3.0198800563812256 | CLS Loss: 0.03535051643848419\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 3.1205289363861084 | KNN Loss: 3.0681521892547607 | CLS Loss: 0.05237669497728348\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 3.0254359245300293 | KNN Loss: 3.0060505867004395 | CLS Loss: 0.01938534341752529\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 3.088655471801758 | KNN Loss: 3.021482467651367 | CLS Loss: 0.06717299669981003\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 3.0836377143859863 | KNN Loss: 3.055104970932007 | CLS Loss: 0.028532849624753\n",
      "Epoch: 045, Loss: 3.0591, Train: 0.9920, Valid: 0.9854, Best: 0.9860\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 3.052232265472412 | KNN Loss: 3.0313057899475098 | CLS Loss: 0.020926550030708313\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 3.0431647300720215 | KNN Loss: 3.035909414291382 | CLS Loss: 0.007255288772284985\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 3.07450270652771 | KNN Loss: 3.0659420490264893 | CLS Loss: 0.008560685440897942\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 3.0853185653686523 | KNN Loss: 3.0674102306365967 | CLS Loss: 0.01790822669863701\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 3.070781707763672 | KNN Loss: 3.054095506668091 | CLS Loss: 0.01668628863990307\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 3.1027212142944336 | KNN Loss: 3.057204246520996 | CLS Loss: 0.045516908168792725\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 3.0308995246887207 | KNN Loss: 3.009068250656128 | CLS Loss: 0.021831154823303223\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 3.0357956886291504 | KNN Loss: 2.989833354949951 | CLS Loss: 0.04596221446990967\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 3.0667479038238525 | KNN Loss: 3.0151729583740234 | CLS Loss: 0.05157500132918358\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 3.111724376678467 | KNN Loss: 3.0632777214050293 | CLS Loss: 0.048446618020534515\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 3.05549955368042 | KNN Loss: 3.038689374923706 | CLS Loss: 0.0168101005256176\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 3.1267294883728027 | KNN Loss: 3.0678935050964355 | CLS Loss: 0.05883605778217316\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 3.062284469604492 | KNN Loss: 3.037975311279297 | CLS Loss: 0.024309052154421806\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 3.0550994873046875 | KNN Loss: 3.0370914936065674 | CLS Loss: 0.01800801046192646\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 3.0164554119110107 | KNN Loss: 3.004883289337158 | CLS Loss: 0.011572161689400673\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 3.0550897121429443 | KNN Loss: 3.0319371223449707 | CLS Loss: 0.02315266616642475\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 3.045876979827881 | KNN Loss: 3.012636184692383 | CLS Loss: 0.0332409106194973\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 3.066026210784912 | KNN Loss: 3.0427584648132324 | CLS Loss: 0.023267855867743492\n",
      "Epoch: 046, Loss: 3.0638, Train: 0.9920, Valid: 0.9848, Best: 0.9860\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 3.027574300765991 | KNN Loss: 3.01122784614563 | CLS Loss: 0.016346538439393044\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 3.0274624824523926 | KNN Loss: 3.0131285190582275 | CLS Loss: 0.014333855360746384\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 3.037851333618164 | KNN Loss: 3.026981830596924 | CLS Loss: 0.010869450867176056\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 3.051711082458496 | KNN Loss: 3.0292725563049316 | CLS Loss: 0.02243848890066147\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 3.100804567337036 | KNN Loss: 3.081909418106079 | CLS Loss: 0.018895206972956657\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 3.04256010055542 | KNN Loss: 3.0037882328033447 | CLS Loss: 0.038771986961364746\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 3.0263726711273193 | KNN Loss: 2.9747114181518555 | CLS Loss: 0.05166132375597954\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 3.0580804347991943 | KNN Loss: 3.044374465942383 | CLS Loss: 0.013705993071198463\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 3.084862232208252 | KNN Loss: 3.0421488285064697 | CLS Loss: 0.042713284492492676\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 3.0686161518096924 | KNN Loss: 3.016824245452881 | CLS Loss: 0.05179189145565033\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 3.0216798782348633 | KNN Loss: 3.0026447772979736 | CLS Loss: 0.019035210832953453\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 3.0833022594451904 | KNN Loss: 3.046522617340088 | CLS Loss: 0.036779653280973434\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 3.069766044616699 | KNN Loss: 3.038743495941162 | CLS Loss: 0.031022489070892334\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 3.0706655979156494 | KNN Loss: 3.016967535018921 | CLS Loss: 0.05369817838072777\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 3.0726301670074463 | KNN Loss: 3.023736000061035 | CLS Loss: 0.04889405518770218\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 3.0458836555480957 | KNN Loss: 3.0261645317077637 | CLS Loss: 0.019719142466783524\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 3.06575083732605 | KNN Loss: 3.034165620803833 | CLS Loss: 0.031585175544023514\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 3.0692946910858154 | KNN Loss: 3.032604694366455 | CLS Loss: 0.03669005259871483\n",
      "Epoch: 047, Loss: 3.0611, Train: 0.9894, Valid: 0.9813, Best: 0.9860\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 3.104576587677002 | KNN Loss: 3.0552639961242676 | CLS Loss: 0.04931250214576721\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 3.0650877952575684 | KNN Loss: 3.0225205421447754 | CLS Loss: 0.042567264288663864\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 3.1339399814605713 | KNN Loss: 3.083406925201416 | CLS Loss: 0.05053295940160751\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 3.0566294193267822 | KNN Loss: 3.0215837955474854 | CLS Loss: 0.035045720636844635\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 3.0237538814544678 | KNN Loss: 3.004096031188965 | CLS Loss: 0.019657807424664497\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 3.0902161598205566 | KNN Loss: 3.0417728424072266 | CLS Loss: 0.04844329133629799\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 3.0518205165863037 | KNN Loss: 3.0211827754974365 | CLS Loss: 0.0306378286331892\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 3.0677690505981445 | KNN Loss: 3.0335772037506104 | CLS Loss: 0.03419184684753418\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 3.063838005065918 | KNN Loss: 3.0122179985046387 | CLS Loss: 0.05161990225315094\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 3.075608968734741 | KNN Loss: 3.0407443046569824 | CLS Loss: 0.034864749759435654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 3.1204707622528076 | KNN Loss: 3.106139659881592 | CLS Loss: 0.014330994337797165\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 3.1133551597595215 | KNN Loss: 3.0940017700195312 | CLS Loss: 0.019353380426764488\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 3.0735158920288086 | KNN Loss: 3.055389404296875 | CLS Loss: 0.018126413226127625\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 3.065485954284668 | KNN Loss: 3.0124359130859375 | CLS Loss: 0.053050052374601364\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 3.011496067047119 | KNN Loss: 2.9810543060302734 | CLS Loss: 0.03044179454445839\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 3.025641679763794 | KNN Loss: 2.999887704849243 | CLS Loss: 0.025753965601325035\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 3.072685718536377 | KNN Loss: 3.0468103885650635 | CLS Loss: 0.025875402614474297\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 3.0596275329589844 | KNN Loss: 3.0512616634368896 | CLS Loss: 0.008365918882191181\n",
      "Epoch: 048, Loss: 3.0612, Train: 0.9926, Valid: 0.9850, Best: 0.9860\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 3.0592851638793945 | KNN Loss: 3.0144314765930176 | CLS Loss: 0.04485375061631203\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 3.0434577465057373 | KNN Loss: 3.0276939868927 | CLS Loss: 0.015763746574521065\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 3.0392236709594727 | KNN Loss: 3.029057264328003 | CLS Loss: 0.010166309773921967\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 3.0601744651794434 | KNN Loss: 3.036885976791382 | CLS Loss: 0.02328849583864212\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 3.0628316402435303 | KNN Loss: 3.03937029838562 | CLS Loss: 0.02346126176416874\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 3.0330660343170166 | KNN Loss: 3.0027077198028564 | CLS Loss: 0.03035830520093441\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 3.069267749786377 | KNN Loss: 3.062188148498535 | CLS Loss: 0.007079681381583214\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 3.042356252670288 | KNN Loss: 3.023360252380371 | CLS Loss: 0.01899602636694908\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 3.0798535346984863 | KNN Loss: 3.0299081802368164 | CLS Loss: 0.049945320934057236\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
