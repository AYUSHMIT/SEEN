{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 32\n",
    "tree_depth = 10\n",
    "batch_size = 512\n",
    "device = 'cpu'\n",
    "train_data_path = r'F:\\Downloads\\archive\\mitbih_train.csv'\n",
    "test_data_path = r'F:\\Downloads\\archive\\mitbih_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.587115287780762 | KNN Loss: 5.718296527862549 | CLS Loss: 1.8688185214996338\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 5.539576053619385 | KNN Loss: 4.427477836608887 | CLS Loss: 1.1120980978012085\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 4.7229814529418945 | KNN Loss: 3.9933700561523438 | CLS Loss: 0.729611337184906\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 4.43195915222168 | KNN Loss: 3.8444793224334717 | CLS Loss: 0.5874797105789185\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 4.483575820922852 | KNN Loss: 3.8387410640716553 | CLS Loss: 0.6448348164558411\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 4.415455341339111 | KNN Loss: 3.8455843925476074 | CLS Loss: 0.5698708295822144\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 4.365846157073975 | KNN Loss: 3.7997422218322754 | CLS Loss: 0.5661040544509888\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.351258277893066 | KNN Loss: 3.831059455871582 | CLS Loss: 0.5201990604400635\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.344188690185547 | KNN Loss: 3.8305280208587646 | CLS Loss: 0.5136605501174927\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.163178443908691 | KNN Loss: 3.7648158073425293 | CLS Loss: 0.39836275577545166\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.240000247955322 | KNN Loss: 3.8052237033843994 | CLS Loss: 0.43477654457092285\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.166619777679443 | KNN Loss: 3.800272226333618 | CLS Loss: 0.3663475215435028\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.253102779388428 | KNN Loss: 3.8441452980041504 | CLS Loss: 0.4089573621749878\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.1462931632995605 | KNN Loss: 3.788522481918335 | CLS Loss: 0.3577706217765808\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.14475679397583 | KNN Loss: 3.803553819656372 | CLS Loss: 0.3412027657032013\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.0714545249938965 | KNN Loss: 3.776496171951294 | CLS Loss: 0.29495829343795776\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.109363555908203 | KNN Loss: 3.779381036758423 | CLS Loss: 0.3299826383590698\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.098536014556885 | KNN Loss: 3.787339448928833 | CLS Loss: 0.311196506023407\n",
      "Epoch: 001, Loss: 4.4587, Train: 0.9163, Valid: 0.9164, Best: 0.9164\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.094631195068359 | KNN Loss: 3.7972984313964844 | CLS Loss: 0.29733288288116455\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.093604564666748 | KNN Loss: 3.754631280899048 | CLS Loss: 0.3389734625816345\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.077555179595947 | KNN Loss: 3.7741496562957764 | CLS Loss: 0.3034055829048157\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 4.050523281097412 | KNN Loss: 3.782843828201294 | CLS Loss: 0.26767924427986145\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 4.013168811798096 | KNN Loss: 3.743349552154541 | CLS Loss: 0.269819438457489\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 4.040439128875732 | KNN Loss: 3.718820810317993 | CLS Loss: 0.32161810994148254\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 3.9941000938415527 | KNN Loss: 3.7379112243652344 | CLS Loss: 0.2561887502670288\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 4.081616401672363 | KNN Loss: 3.766035318374634 | CLS Loss: 0.3155812621116638\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 4.024146556854248 | KNN Loss: 3.780627965927124 | CLS Loss: 0.2435186207294464\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 4.023216247558594 | KNN Loss: 3.7710437774658203 | CLS Loss: 0.25217223167419434\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 3.93795108795166 | KNN Loss: 3.6782584190368652 | CLS Loss: 0.2596927881240845\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 3.9503378868103027 | KNN Loss: 3.704296588897705 | CLS Loss: 0.24604131281375885\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 3.960000991821289 | KNN Loss: 3.738719940185547 | CLS Loss: 0.22128106653690338\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 3.9505481719970703 | KNN Loss: 3.6978907585144043 | CLS Loss: 0.25265753269195557\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 4.00595760345459 | KNN Loss: 3.742614507675171 | CLS Loss: 0.26334288716316223\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 3.974616289138794 | KNN Loss: 3.753274440765381 | CLS Loss: 0.22134186327457428\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 3.9029457569122314 | KNN Loss: 3.7090399265289307 | CLS Loss: 0.19390586018562317\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 3.9364404678344727 | KNN Loss: 3.6912591457366943 | CLS Loss: 0.24518141150474548\n",
      "Epoch: 002, Loss: 4.0066, Train: 0.9451, Valid: 0.9444, Best: 0.9444\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 3.9507906436920166 | KNN Loss: 3.6929571628570557 | CLS Loss: 0.25783345103263855\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 3.8748672008514404 | KNN Loss: 3.7019591331481934 | CLS Loss: 0.17290815711021423\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 3.995238780975342 | KNN Loss: 3.725851058959961 | CLS Loss: 0.26938772201538086\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 3.9186854362487793 | KNN Loss: 3.7255465984344482 | CLS Loss: 0.19313885271549225\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 3.9932963848114014 | KNN Loss: 3.7379209995269775 | CLS Loss: 0.25537529587745667\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 3.919783592224121 | KNN Loss: 3.6847057342529297 | CLS Loss: 0.2350778430700302\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 3.910557985305786 | KNN Loss: 3.702392578125 | CLS Loss: 0.20816537737846375\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 3.8651533126831055 | KNN Loss: 3.7272512912750244 | CLS Loss: 0.13790199160575867\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 3.858229637145996 | KNN Loss: 3.6927549839019775 | CLS Loss: 0.16547469794750214\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 3.8263232707977295 | KNN Loss: 3.7008838653564453 | CLS Loss: 0.12543943524360657\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 3.8857343196868896 | KNN Loss: 3.7225759029388428 | CLS Loss: 0.16315852105617523\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 3.8238489627838135 | KNN Loss: 3.673720121383667 | CLS Loss: 0.1501288115978241\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 3.862837553024292 | KNN Loss: 3.7149271965026855 | CLS Loss: 0.1479102522134781\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 3.881671667098999 | KNN Loss: 3.697821617126465 | CLS Loss: 0.18384994566440582\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 3.8608267307281494 | KNN Loss: 3.6988728046417236 | CLS Loss: 0.16195400059223175\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 3.9029550552368164 | KNN Loss: 3.713430643081665 | CLS Loss: 0.18952438235282898\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 3.875997304916382 | KNN Loss: 3.6792356967926025 | CLS Loss: 0.1967616230249405\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 3.856097936630249 | KNN Loss: 3.6908061504364014 | CLS Loss: 0.165291890501976\n",
      "Epoch: 003, Loss: 3.8869, Train: 0.9615, Valid: 0.9589, Best: 0.9589\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 3.7884364128112793 | KNN Loss: 3.6610774993896484 | CLS Loss: 0.1273588240146637\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 3.831519365310669 | KNN Loss: 3.655280590057373 | CLS Loss: 0.17623871564865112\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 3.8704326152801514 | KNN Loss: 3.697252035140991 | CLS Loss: 0.17318063974380493\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 3.835463762283325 | KNN Loss: 3.6581943035125732 | CLS Loss: 0.1772693544626236\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 3.838656425476074 | KNN Loss: 3.6778688430786133 | CLS Loss: 0.1607874631881714\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 3.8137943744659424 | KNN Loss: 3.685899496078491 | CLS Loss: 0.12789490818977356\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 3.8119003772735596 | KNN Loss: 3.6869983673095703 | CLS Loss: 0.12490195780992508\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 3.8198821544647217 | KNN Loss: 3.7004940509796143 | CLS Loss: 0.11938802897930145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 3.8422582149505615 | KNN Loss: 3.6666877269744873 | CLS Loss: 0.17557038366794586\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 3.843769073486328 | KNN Loss: 3.654789686203003 | CLS Loss: 0.1889793574810028\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 3.826467990875244 | KNN Loss: 3.6591689586639404 | CLS Loss: 0.16729910671710968\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 3.8243889808654785 | KNN Loss: 3.6761441230773926 | CLS Loss: 0.1482449471950531\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 3.7941391468048096 | KNN Loss: 3.6541688442230225 | CLS Loss: 0.1399703025817871\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 3.7871880531311035 | KNN Loss: 3.6518688201904297 | CLS Loss: 0.13531926274299622\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 3.8234703540802 | KNN Loss: 3.676626443862915 | CLS Loss: 0.14684398472309113\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 3.854278326034546 | KNN Loss: 3.6757805347442627 | CLS Loss: 0.17849771678447723\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 3.826179027557373 | KNN Loss: 3.7182960510253906 | CLS Loss: 0.10788291692733765\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 3.8469316959381104 | KNN Loss: 3.6568398475646973 | CLS Loss: 0.19009174406528473\n",
      "Epoch: 004, Loss: 3.8337, Train: 0.9656, Valid: 0.9630, Best: 0.9630\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 3.8110861778259277 | KNN Loss: 3.690965175628662 | CLS Loss: 0.12012092024087906\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 3.7936153411865234 | KNN Loss: 3.6732425689697266 | CLS Loss: 0.12037273496389389\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 3.773527145385742 | KNN Loss: 3.67710018157959 | CLS Loss: 0.09642685204744339\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 3.786778450012207 | KNN Loss: 3.6609134674072266 | CLS Loss: 0.12586507201194763\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 3.8180665969848633 | KNN Loss: 3.6777870655059814 | CLS Loss: 0.14027944207191467\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 3.792210817337036 | KNN Loss: 3.6786575317382812 | CLS Loss: 0.11355334520339966\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 3.7781624794006348 | KNN Loss: 3.6399736404418945 | CLS Loss: 0.138188898563385\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 3.7640316486358643 | KNN Loss: 3.6270506381988525 | CLS Loss: 0.1369810402393341\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 3.7919869422912598 | KNN Loss: 3.6740713119506836 | CLS Loss: 0.11791563779115677\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 3.8388004302978516 | KNN Loss: 3.718675374984741 | CLS Loss: 0.1201251745223999\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 3.76851487159729 | KNN Loss: 3.6751530170440674 | CLS Loss: 0.09336183220148087\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 3.7712512016296387 | KNN Loss: 3.6669890880584717 | CLS Loss: 0.10426215082406998\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 3.8126871585845947 | KNN Loss: 3.680875062942505 | CLS Loss: 0.13181206583976746\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 3.7652533054351807 | KNN Loss: 3.6173033714294434 | CLS Loss: 0.14794987440109253\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 3.79323410987854 | KNN Loss: 3.6652419567108154 | CLS Loss: 0.12799206376075745\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 3.82694149017334 | KNN Loss: 3.6865665912628174 | CLS Loss: 0.14037488400936127\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 3.8221218585968018 | KNN Loss: 3.6615514755249023 | CLS Loss: 0.1605704426765442\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 3.791248083114624 | KNN Loss: 3.640316963195801 | CLS Loss: 0.1509312093257904\n",
      "Epoch: 005, Loss: 3.7945, Train: 0.9688, Valid: 0.9663, Best: 0.9663\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 3.728034734725952 | KNN Loss: 3.640406847000122 | CLS Loss: 0.0876278430223465\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 3.823322057723999 | KNN Loss: 3.70322847366333 | CLS Loss: 0.12009360641241074\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 3.7907071113586426 | KNN Loss: 3.6834096908569336 | CLS Loss: 0.1072973981499672\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 3.7740185260772705 | KNN Loss: 3.6726436614990234 | CLS Loss: 0.10137484967708588\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 3.7828688621520996 | KNN Loss: 3.657858371734619 | CLS Loss: 0.12501056492328644\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 3.7650129795074463 | KNN Loss: 3.638470411300659 | CLS Loss: 0.1265425682067871\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 3.812173843383789 | KNN Loss: 3.6614482402801514 | CLS Loss: 0.15072569251060486\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 3.769300699234009 | KNN Loss: 3.668870210647583 | CLS Loss: 0.10043048858642578\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 3.790529727935791 | KNN Loss: 3.6896767616271973 | CLS Loss: 0.10085295140743256\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 3.7708942890167236 | KNN Loss: 3.665816307067871 | CLS Loss: 0.10507798194885254\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 3.740571975708008 | KNN Loss: 3.6101274490356445 | CLS Loss: 0.13044454157352448\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 3.746324300765991 | KNN Loss: 3.622117280960083 | CLS Loss: 0.12420707941055298\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 3.728195905685425 | KNN Loss: 3.6238651275634766 | CLS Loss: 0.10433079302310944\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 3.8467156887054443 | KNN Loss: 3.6769862174987793 | CLS Loss: 0.169729545712471\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 3.7153258323669434 | KNN Loss: 3.6627166271209717 | CLS Loss: 0.05260919779539108\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 3.797043800354004 | KNN Loss: 3.6912970542907715 | CLS Loss: 0.10574668645858765\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 3.7490081787109375 | KNN Loss: 3.667310953140259 | CLS Loss: 0.08169716596603394\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 3.7310895919799805 | KNN Loss: 3.6469180583953857 | CLS Loss: 0.08417149633169174\n",
      "Epoch: 006, Loss: 3.7674, Train: 0.9730, Valid: 0.9696, Best: 0.9696\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 3.7462358474731445 | KNN Loss: 3.6644842624664307 | CLS Loss: 0.08175146579742432\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 3.736945390701294 | KNN Loss: 3.6402950286865234 | CLS Loss: 0.09665047377347946\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 3.773313522338867 | KNN Loss: 3.665850877761841 | CLS Loss: 0.10746259242296219\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 3.751964807510376 | KNN Loss: 3.6724321842193604 | CLS Loss: 0.07953266054391861\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 3.742673873901367 | KNN Loss: 3.645709991455078 | CLS Loss: 0.09696397185325623\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 3.7366321086883545 | KNN Loss: 3.6613118648529053 | CLS Loss: 0.07532021403312683\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 3.7222607135772705 | KNN Loss: 3.6452829837799072 | CLS Loss: 0.07697772979736328\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 3.781646251678467 | KNN Loss: 3.6857376098632812 | CLS Loss: 0.09590863436460495\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 3.7942490577697754 | KNN Loss: 3.6790013313293457 | CLS Loss: 0.11524783819913864\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 3.7590320110321045 | KNN Loss: 3.6904311180114746 | CLS Loss: 0.06860096752643585\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 3.769155740737915 | KNN Loss: 3.652282238006592 | CLS Loss: 0.11687350273132324\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 3.716525077819824 | KNN Loss: 3.638646364212036 | CLS Loss: 0.07787876576185226\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 3.72202730178833 | KNN Loss: 3.6453306674957275 | CLS Loss: 0.07669669389724731\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 3.7082459926605225 | KNN Loss: 3.626176118850708 | CLS Loss: 0.08206989616155624\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 3.717496395111084 | KNN Loss: 3.6644654273986816 | CLS Loss: 0.05303099378943443\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 3.793834686279297 | KNN Loss: 3.6226701736450195 | CLS Loss: 0.171164408326149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 3.7192060947418213 | KNN Loss: 3.6243038177490234 | CLS Loss: 0.09490218758583069\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 3.69795560836792 | KNN Loss: 3.6322481632232666 | CLS Loss: 0.06570734828710556\n",
      "Epoch: 007, Loss: 3.7457, Train: 0.9769, Valid: 0.9742, Best: 0.9742\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 3.70446515083313 | KNN Loss: 3.6155078411102295 | CLS Loss: 0.08895742148160934\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 3.734149217605591 | KNN Loss: 3.6574413776397705 | CLS Loss: 0.07670783251523972\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 3.722667694091797 | KNN Loss: 3.6310293674468994 | CLS Loss: 0.09163843840360641\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 3.700176477432251 | KNN Loss: 3.6133313179016113 | CLS Loss: 0.08684512227773666\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 3.714923620223999 | KNN Loss: 3.64667010307312 | CLS Loss: 0.06825359165668488\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 3.7988052368164062 | KNN Loss: 3.673018455505371 | CLS Loss: 0.12578675150871277\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 3.7052383422851562 | KNN Loss: 3.6216306686401367 | CLS Loss: 0.08360756933689117\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 3.7435431480407715 | KNN Loss: 3.6356616020202637 | CLS Loss: 0.10788146406412125\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 3.730285167694092 | KNN Loss: 3.6427173614501953 | CLS Loss: 0.08756773918867111\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 3.7424652576446533 | KNN Loss: 3.6272478103637695 | CLS Loss: 0.11521750688552856\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 3.7369208335876465 | KNN Loss: 3.6383392810821533 | CLS Loss: 0.09858151525259018\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 3.6792938709259033 | KNN Loss: 3.6159534454345703 | CLS Loss: 0.06334033608436584\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 3.701864719390869 | KNN Loss: 3.6099767684936523 | CLS Loss: 0.09188783168792725\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 3.7249605655670166 | KNN Loss: 3.6131794452667236 | CLS Loss: 0.11178102344274521\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 3.7676339149475098 | KNN Loss: 3.659346103668213 | CLS Loss: 0.10828778892755508\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 3.7225303649902344 | KNN Loss: 3.6592891216278076 | CLS Loss: 0.06324133276939392\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 3.7290048599243164 | KNN Loss: 3.6847429275512695 | CLS Loss: 0.04426202178001404\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 3.748149871826172 | KNN Loss: 3.6646971702575684 | CLS Loss: 0.0834527388215065\n",
      "Epoch: 008, Loss: 3.7304, Train: 0.9766, Valid: 0.9745, Best: 0.9745\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 3.726182699203491 | KNN Loss: 3.650251865386963 | CLS Loss: 0.07593082636594772\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 3.6753790378570557 | KNN Loss: 3.5682284832000732 | CLS Loss: 0.10715058445930481\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 3.7372994422912598 | KNN Loss: 3.6491281986236572 | CLS Loss: 0.08817128092050552\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 3.701320171356201 | KNN Loss: 3.630744695663452 | CLS Loss: 0.07057548314332962\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 3.7079923152923584 | KNN Loss: 3.6136715412139893 | CLS Loss: 0.0943208560347557\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 3.702280044555664 | KNN Loss: 3.6106066703796387 | CLS Loss: 0.09167328476905823\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 3.703583002090454 | KNN Loss: 3.6334421634674072 | CLS Loss: 0.07014086097478867\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 3.705303430557251 | KNN Loss: 3.6407217979431152 | CLS Loss: 0.06458170711994171\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 3.706073760986328 | KNN Loss: 3.6286375522613525 | CLS Loss: 0.07743629813194275\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 3.739471673965454 | KNN Loss: 3.6553237438201904 | CLS Loss: 0.08414799720048904\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 3.764946460723877 | KNN Loss: 3.6603190898895264 | CLS Loss: 0.1046273410320282\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 3.751108407974243 | KNN Loss: 3.6638195514678955 | CLS Loss: 0.08728887140750885\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 3.7531650066375732 | KNN Loss: 3.614563226699829 | CLS Loss: 0.13860182464122772\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 3.704547166824341 | KNN Loss: 3.640519142150879 | CLS Loss: 0.06402791291475296\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 3.7581522464752197 | KNN Loss: 3.66813325881958 | CLS Loss: 0.09001898765563965\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 3.7843644618988037 | KNN Loss: 3.6843385696411133 | CLS Loss: 0.10002581030130386\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 3.7072179317474365 | KNN Loss: 3.64201283454895 | CLS Loss: 0.0652051568031311\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 3.767228603363037 | KNN Loss: 3.6675474643707275 | CLS Loss: 0.099681057035923\n",
      "Epoch: 009, Loss: 3.7222, Train: 0.9809, Valid: 0.9778, Best: 0.9778\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 3.6862988471984863 | KNN Loss: 3.619020462036133 | CLS Loss: 0.06727829575538635\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 3.7081689834594727 | KNN Loss: 3.632876396179199 | CLS Loss: 0.07529249787330627\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 3.7289600372314453 | KNN Loss: 3.640843152999878 | CLS Loss: 0.08811700344085693\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 3.668001413345337 | KNN Loss: 3.6012754440307617 | CLS Loss: 0.06672598421573639\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 3.673750400543213 | KNN Loss: 3.5884957313537598 | CLS Loss: 0.08525460958480835\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 3.76587176322937 | KNN Loss: 3.6539411544799805 | CLS Loss: 0.11193053424358368\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 3.6640477180480957 | KNN Loss: 3.5855767726898193 | CLS Loss: 0.07847106456756592\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 3.7923498153686523 | KNN Loss: 3.6441221237182617 | CLS Loss: 0.14822769165039062\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 3.673032283782959 | KNN Loss: 3.6160669326782227 | CLS Loss: 0.056965410709381104\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 3.6540801525115967 | KNN Loss: 3.589501142501831 | CLS Loss: 0.06457892805337906\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 3.706303834915161 | KNN Loss: 3.624394416809082 | CLS Loss: 0.08190936595201492\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 3.715419054031372 | KNN Loss: 3.6321606636047363 | CLS Loss: 0.08325836807489395\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 3.7037546634674072 | KNN Loss: 3.6123785972595215 | CLS Loss: 0.09137610346078873\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 3.714078903198242 | KNN Loss: 3.6515583992004395 | CLS Loss: 0.06252048909664154\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 3.7172415256500244 | KNN Loss: 3.6682376861572266 | CLS Loss: 0.049003809690475464\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 3.7115912437438965 | KNN Loss: 3.623842477798462 | CLS Loss: 0.08774872869253159\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 3.732520818710327 | KNN Loss: 3.6544737815856934 | CLS Loss: 0.0780469998717308\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 3.665649890899658 | KNN Loss: 3.590646743774414 | CLS Loss: 0.07500302791595459\n",
      "Epoch: 010, Loss: 3.7100, Train: 0.9815, Valid: 0.9782, Best: 0.9782\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 3.6980292797088623 | KNN Loss: 3.597442626953125 | CLS Loss: 0.10058654099702835\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 3.6947720050811768 | KNN Loss: 3.6065993309020996 | CLS Loss: 0.0881727859377861\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 3.698971748352051 | KNN Loss: 3.6525375843048096 | CLS Loss: 0.04643407091498375\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 3.667386531829834 | KNN Loss: 3.611302137374878 | CLS Loss: 0.0560842826962471\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 3.7286617755889893 | KNN Loss: 3.642338514328003 | CLS Loss: 0.08632335066795349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 3.685824394226074 | KNN Loss: 3.596081018447876 | CLS Loss: 0.08974327892065048\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 3.7582485675811768 | KNN Loss: 3.6727967262268066 | CLS Loss: 0.08545186370611191\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 3.6923916339874268 | KNN Loss: 3.6167309284210205 | CLS Loss: 0.07566066086292267\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 3.669750213623047 | KNN Loss: 3.6241214275360107 | CLS Loss: 0.04562876373529434\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 3.686194658279419 | KNN Loss: 3.5548713207244873 | CLS Loss: 0.13132326304912567\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 3.7228708267211914 | KNN Loss: 3.6078102588653564 | CLS Loss: 0.11506067216396332\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 3.689363718032837 | KNN Loss: 3.6066689491271973 | CLS Loss: 0.08269474655389786\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 3.7255859375 | KNN Loss: 3.6391501426696777 | CLS Loss: 0.0864357277750969\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 3.722069263458252 | KNN Loss: 3.6250252723693848 | CLS Loss: 0.09704389423131943\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 3.7048285007476807 | KNN Loss: 3.6283676624298096 | CLS Loss: 0.07646087557077408\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 3.6830692291259766 | KNN Loss: 3.6067557334899902 | CLS Loss: 0.07631346583366394\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 3.6889326572418213 | KNN Loss: 3.604698419570923 | CLS Loss: 0.08423417806625366\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 3.6862258911132812 | KNN Loss: 3.6145713329315186 | CLS Loss: 0.07165449857711792\n",
      "Epoch: 011, Loss: 3.7045, Train: 0.9798, Valid: 0.9760, Best: 0.9782\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 3.6589419841766357 | KNN Loss: 3.581629991531372 | CLS Loss: 0.0773119255900383\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 3.750973701477051 | KNN Loss: 3.667249917984009 | CLS Loss: 0.0837237611413002\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 3.7149760723114014 | KNN Loss: 3.6190025806427 | CLS Loss: 0.09597346931695938\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 3.7041380405426025 | KNN Loss: 3.61958646774292 | CLS Loss: 0.08455168455839157\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 3.704479694366455 | KNN Loss: 3.6244444847106934 | CLS Loss: 0.08003531396389008\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 3.691701889038086 | KNN Loss: 3.624013662338257 | CLS Loss: 0.06768810749053955\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 3.7746846675872803 | KNN Loss: 3.6816585063934326 | CLS Loss: 0.09302611649036407\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 3.717829704284668 | KNN Loss: 3.6229465007781982 | CLS Loss: 0.09488313645124435\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 3.6738569736480713 | KNN Loss: 3.5918891429901123 | CLS Loss: 0.0819677859544754\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 3.6664350032806396 | KNN Loss: 3.605405330657959 | CLS Loss: 0.06102965399622917\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 3.6669018268585205 | KNN Loss: 3.626970052719116 | CLS Loss: 0.03993184119462967\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 3.716505289077759 | KNN Loss: 3.6134543418884277 | CLS Loss: 0.10305093973875046\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 3.683852195739746 | KNN Loss: 3.6272332668304443 | CLS Loss: 0.05661899968981743\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 3.683184862136841 | KNN Loss: 3.6153345108032227 | CLS Loss: 0.06785041838884354\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 3.6765518188476562 | KNN Loss: 3.622591495513916 | CLS Loss: 0.05396043509244919\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 3.675899028778076 | KNN Loss: 3.6184608936309814 | CLS Loss: 0.05743822827935219\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 3.657747268676758 | KNN Loss: 3.6093225479125977 | CLS Loss: 0.04842473939061165\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 3.7218940258026123 | KNN Loss: 3.6428020000457764 | CLS Loss: 0.07909213751554489\n",
      "Epoch: 012, Loss: 3.6947, Train: 0.9831, Valid: 0.9797, Best: 0.9797\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 3.687903642654419 | KNN Loss: 3.6064858436584473 | CLS Loss: 0.08141785115003586\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 3.710289478302002 | KNN Loss: 3.6350183486938477 | CLS Loss: 0.07527109235525131\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 3.675644874572754 | KNN Loss: 3.6263246536254883 | CLS Loss: 0.04932019114494324\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 3.674199342727661 | KNN Loss: 3.577852487564087 | CLS Loss: 0.09634681046009064\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 3.6471102237701416 | KNN Loss: 3.5723133087158203 | CLS Loss: 0.07479695975780487\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 3.7483482360839844 | KNN Loss: 3.6668388843536377 | CLS Loss: 0.08150937408208847\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 3.661646604537964 | KNN Loss: 3.61887788772583 | CLS Loss: 0.042768821120262146\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 3.717837333679199 | KNN Loss: 3.6401360034942627 | CLS Loss: 0.07770141959190369\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 3.6876766681671143 | KNN Loss: 3.6429269313812256 | CLS Loss: 0.04474978521466255\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 3.7288525104522705 | KNN Loss: 3.6505203247070312 | CLS Loss: 0.07833229005336761\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 3.658656358718872 | KNN Loss: 3.6170363426208496 | CLS Loss: 0.04162008315324783\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 3.695648193359375 | KNN Loss: 3.608670711517334 | CLS Loss: 0.08697743713855743\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 3.726400375366211 | KNN Loss: 3.629652738571167 | CLS Loss: 0.09674753993749619\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 3.6418392658233643 | KNN Loss: 3.6107006072998047 | CLS Loss: 0.031138738617300987\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 3.730550527572632 | KNN Loss: 3.68337345123291 | CLS Loss: 0.04717716947197914\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 3.6809370517730713 | KNN Loss: 3.617703437805176 | CLS Loss: 0.06323372572660446\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 3.719655990600586 | KNN Loss: 3.593369960784912 | CLS Loss: 0.12628591060638428\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 3.761880874633789 | KNN Loss: 3.6432957649230957 | CLS Loss: 0.11858504265546799\n",
      "Epoch: 013, Loss: 3.6923, Train: 0.9827, Valid: 0.9793, Best: 0.9797\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 3.7180263996124268 | KNN Loss: 3.6579620838165283 | CLS Loss: 0.060064297169446945\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 3.6957359313964844 | KNN Loss: 3.6331491470336914 | CLS Loss: 0.06258688122034073\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 3.7015092372894287 | KNN Loss: 3.6570913791656494 | CLS Loss: 0.044417932629585266\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 3.6400516033172607 | KNN Loss: 3.613591194152832 | CLS Loss: 0.026460306718945503\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 3.668663263320923 | KNN Loss: 3.5859031677246094 | CLS Loss: 0.08276011794805527\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 3.660574436187744 | KNN Loss: 3.6327931880950928 | CLS Loss: 0.02778114192187786\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 3.7121973037719727 | KNN Loss: 3.609149932861328 | CLS Loss: 0.10304737836122513\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 3.6552913188934326 | KNN Loss: 3.6164867877960205 | CLS Loss: 0.03880445286631584\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 3.673624277114868 | KNN Loss: 3.6179492473602295 | CLS Loss: 0.05567502602934837\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 3.665076732635498 | KNN Loss: 3.6133155822753906 | CLS Loss: 0.0517612099647522\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 3.701845407485962 | KNN Loss: 3.6419484615325928 | CLS Loss: 0.05989694595336914\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 3.631521224975586 | KNN Loss: 3.5916881561279297 | CLS Loss: 0.03983308747410774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 3.656766891479492 | KNN Loss: 3.604492425918579 | CLS Loss: 0.05227439105510712\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 3.6770365238189697 | KNN Loss: 3.6193835735321045 | CLS Loss: 0.05765296518802643\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 3.7052364349365234 | KNN Loss: 3.636918306350708 | CLS Loss: 0.06831815838813782\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 3.679098129272461 | KNN Loss: 3.6211349964141846 | CLS Loss: 0.057963162660598755\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 3.650550603866577 | KNN Loss: 3.6043601036071777 | CLS Loss: 0.04619060084223747\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 3.611435890197754 | KNN Loss: 3.586193084716797 | CLS Loss: 0.025242773815989494\n",
      "Epoch: 014, Loss: 3.6855, Train: 0.9826, Valid: 0.9795, Best: 0.9797\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 3.6574466228485107 | KNN Loss: 3.5909981727600098 | CLS Loss: 0.06644848734140396\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 3.6274983882904053 | KNN Loss: 3.5635297298431396 | CLS Loss: 0.06396874785423279\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 3.678091049194336 | KNN Loss: 3.609361410140991 | CLS Loss: 0.06872960180044174\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 3.6688826084136963 | KNN Loss: 3.5845232009887695 | CLS Loss: 0.084359310567379\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 3.6584055423736572 | KNN Loss: 3.6143910884857178 | CLS Loss: 0.044014353305101395\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 3.712339162826538 | KNN Loss: 3.625502347946167 | CLS Loss: 0.08683682233095169\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 3.681197166442871 | KNN Loss: 3.61974835395813 | CLS Loss: 0.06144879385828972\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 3.729949951171875 | KNN Loss: 3.654055595397949 | CLS Loss: 0.07589447498321533\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 3.66642165184021 | KNN Loss: 3.598118543624878 | CLS Loss: 0.0683031752705574\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 3.6855993270874023 | KNN Loss: 3.612818717956543 | CLS Loss: 0.07278049737215042\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 3.678002119064331 | KNN Loss: 3.631222724914551 | CLS Loss: 0.04677947238087654\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 3.649266242980957 | KNN Loss: 3.5999531745910645 | CLS Loss: 0.049313146620988846\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 3.664541006088257 | KNN Loss: 3.611593008041382 | CLS Loss: 0.052948061376810074\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 3.722247838973999 | KNN Loss: 3.6544456481933594 | CLS Loss: 0.06780213117599487\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 3.731502056121826 | KNN Loss: 3.667647123336792 | CLS Loss: 0.06385491043329239\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 3.6905760765075684 | KNN Loss: 3.609583854675293 | CLS Loss: 0.08099228143692017\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 3.6854934692382812 | KNN Loss: 3.613816976547241 | CLS Loss: 0.07167648524045944\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 3.7150697708129883 | KNN Loss: 3.6606433391571045 | CLS Loss: 0.054426517337560654\n",
      "Epoch: 015, Loss: 3.6794, Train: 0.9835, Valid: 0.9802, Best: 0.9802\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 3.707399368286133 | KNN Loss: 3.6206412315368652 | CLS Loss: 0.086758092045784\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 3.6775012016296387 | KNN Loss: 3.5983877182006836 | CLS Loss: 0.07911337912082672\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 3.700632333755493 | KNN Loss: 3.6463003158569336 | CLS Loss: 0.054332002997398376\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 3.6628613471984863 | KNN Loss: 3.5855846405029297 | CLS Loss: 0.07727672904729843\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 3.657438278198242 | KNN Loss: 3.5960803031921387 | CLS Loss: 0.061357952654361725\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 3.6668317317962646 | KNN Loss: 3.607038974761963 | CLS Loss: 0.05979282036423683\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 3.6794731616973877 | KNN Loss: 3.600708246231079 | CLS Loss: 0.07876496016979218\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 3.666605234146118 | KNN Loss: 3.6183910369873047 | CLS Loss: 0.048214141279459\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 3.6957359313964844 | KNN Loss: 3.655136823654175 | CLS Loss: 0.040599118918180466\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 3.6622474193573 | KNN Loss: 3.6041576862335205 | CLS Loss: 0.058089662343263626\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 3.674799680709839 | KNN Loss: 3.6220057010650635 | CLS Loss: 0.0527939610183239\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 3.6839375495910645 | KNN Loss: 3.641448974609375 | CLS Loss: 0.04248863086104393\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 3.6901073455810547 | KNN Loss: 3.6370797157287598 | CLS Loss: 0.053027570247650146\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 3.6494901180267334 | KNN Loss: 3.6266870498657227 | CLS Loss: 0.02280312031507492\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 3.65043306350708 | KNN Loss: 3.5831665992736816 | CLS Loss: 0.0672665610909462\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 3.6831817626953125 | KNN Loss: 3.629434108734131 | CLS Loss: 0.05374776944518089\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 3.686664581298828 | KNN Loss: 3.6375186443328857 | CLS Loss: 0.049146026372909546\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 3.632133960723877 | KNN Loss: 3.5750679969787598 | CLS Loss: 0.0570659339427948\n",
      "Epoch: 016, Loss: 3.6756, Train: 0.9847, Valid: 0.9810, Best: 0.9810\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 3.640791893005371 | KNN Loss: 3.5907652378082275 | CLS Loss: 0.05002659559249878\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 3.650377035140991 | KNN Loss: 3.601816177368164 | CLS Loss: 0.04856085777282715\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 3.6919057369232178 | KNN Loss: 3.6119658946990967 | CLS Loss: 0.07993980497121811\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 3.664398431777954 | KNN Loss: 3.613140344619751 | CLS Loss: 0.05125808343291283\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 3.7224249839782715 | KNN Loss: 3.6539463996887207 | CLS Loss: 0.06847868114709854\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 3.6853413581848145 | KNN Loss: 3.6252830028533936 | CLS Loss: 0.06005828082561493\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 3.6831657886505127 | KNN Loss: 3.6380414962768555 | CLS Loss: 0.04512437805533409\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 3.6893532276153564 | KNN Loss: 3.616889715194702 | CLS Loss: 0.07246362417936325\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 3.6344563961029053 | KNN Loss: 3.592745065689087 | CLS Loss: 0.041711315512657166\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 3.7114615440368652 | KNN Loss: 3.6416780948638916 | CLS Loss: 0.06978339701890945\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 3.6360533237457275 | KNN Loss: 3.597465753555298 | CLS Loss: 0.0385875329375267\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 3.6344354152679443 | KNN Loss: 3.5733838081359863 | CLS Loss: 0.06105165556073189\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 3.68595290184021 | KNN Loss: 3.6559886932373047 | CLS Loss: 0.029964325949549675\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 3.654172897338867 | KNN Loss: 3.5856494903564453 | CLS Loss: 0.06852329522371292\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 3.64898943901062 | KNN Loss: 3.5839059352874756 | CLS Loss: 0.06508342176675797\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 3.6730785369873047 | KNN Loss: 3.6040713787078857 | CLS Loss: 0.06900715827941895\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 3.6660215854644775 | KNN Loss: 3.5995283126831055 | CLS Loss: 0.06649317592382431\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 3.695011615753174 | KNN Loss: 3.6413261890411377 | CLS Loss: 0.05368531122803688\n",
      "Epoch: 017, Loss: 3.6716, Train: 0.9858, Valid: 0.9817, Best: 0.9817\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 3.6271169185638428 | KNN Loss: 3.599820375442505 | CLS Loss: 0.027296461164951324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 3.6598823070526123 | KNN Loss: 3.596204996109009 | CLS Loss: 0.06367722898721695\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 3.6729860305786133 | KNN Loss: 3.6223526000976562 | CLS Loss: 0.05063336342573166\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 3.730236053466797 | KNN Loss: 3.65004825592041 | CLS Loss: 0.08018787950277328\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 3.7101175785064697 | KNN Loss: 3.668700695037842 | CLS Loss: 0.04141680896282196\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 3.678621768951416 | KNN Loss: 3.6211235523223877 | CLS Loss: 0.057498227804899216\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 3.6612026691436768 | KNN Loss: 3.556119918823242 | CLS Loss: 0.10508272051811218\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 3.61236572265625 | KNN Loss: 3.5856475830078125 | CLS Loss: 0.026718031615018845\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 3.6716558933258057 | KNN Loss: 3.6072237491607666 | CLS Loss: 0.0644320398569107\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 3.724907159805298 | KNN Loss: 3.6427948474884033 | CLS Loss: 0.08211241662502289\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 3.696577548980713 | KNN Loss: 3.580876588821411 | CLS Loss: 0.11570095270872116\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 3.6304848194122314 | KNN Loss: 3.5808982849121094 | CLS Loss: 0.04958648979663849\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 3.6454880237579346 | KNN Loss: 3.61730694770813 | CLS Loss: 0.028181154280900955\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 3.7069058418273926 | KNN Loss: 3.660007953643799 | CLS Loss: 0.04689783975481987\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 3.666090488433838 | KNN Loss: 3.6057040691375732 | CLS Loss: 0.06038634851574898\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 3.6492526531219482 | KNN Loss: 3.6248819828033447 | CLS Loss: 0.02437078393995762\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 3.6564440727233887 | KNN Loss: 3.6040189266204834 | CLS Loss: 0.052425168454647064\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 3.641125202178955 | KNN Loss: 3.5753188133239746 | CLS Loss: 0.06580628454685211\n",
      "Epoch: 018, Loss: 3.6669, Train: 0.9857, Valid: 0.9814, Best: 0.9817\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 3.698887348175049 | KNN Loss: 3.62487530708313 | CLS Loss: 0.07401193678379059\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 3.6247565746307373 | KNN Loss: 3.5738444328308105 | CLS Loss: 0.05091211199760437\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 3.642838716506958 | KNN Loss: 3.604567527770996 | CLS Loss: 0.03827107325196266\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 3.6277904510498047 | KNN Loss: 3.604489326477051 | CLS Loss: 0.02330123633146286\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 3.681687355041504 | KNN Loss: 3.613675832748413 | CLS Loss: 0.06801164150238037\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 3.7001049518585205 | KNN Loss: 3.647460460662842 | CLS Loss: 0.05264458805322647\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 3.6695003509521484 | KNN Loss: 3.593271017074585 | CLS Loss: 0.07622934877872467\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 3.6541993618011475 | KNN Loss: 3.6169350147247314 | CLS Loss: 0.03726435825228691\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 3.641535997390747 | KNN Loss: 3.624652147293091 | CLS Loss: 0.016883941367268562\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 3.658257007598877 | KNN Loss: 3.5869579315185547 | CLS Loss: 0.07129903882741928\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 3.6864864826202393 | KNN Loss: 3.6165599822998047 | CLS Loss: 0.06992657482624054\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 3.6786351203918457 | KNN Loss: 3.616194009780884 | CLS Loss: 0.06244109570980072\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 3.627753973007202 | KNN Loss: 3.57961106300354 | CLS Loss: 0.048142969608306885\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 3.6618757247924805 | KNN Loss: 3.592393159866333 | CLS Loss: 0.0694824680685997\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 3.6501433849334717 | KNN Loss: 3.608588218688965 | CLS Loss: 0.04155508801341057\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 3.624838352203369 | KNN Loss: 3.585749387741089 | CLS Loss: 0.03908902034163475\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 3.6830334663391113 | KNN Loss: 3.6028590202331543 | CLS Loss: 0.0801745131611824\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 3.706038236618042 | KNN Loss: 3.623035430908203 | CLS Loss: 0.08300291746854782\n",
      "Epoch: 019, Loss: 3.6701, Train: 0.9835, Valid: 0.9793, Best: 0.9817\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 3.6589062213897705 | KNN Loss: 3.5987250804901123 | CLS Loss: 0.060181111097335815\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 3.6962578296661377 | KNN Loss: 3.6376149654388428 | CLS Loss: 0.05864286050200462\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 3.658055543899536 | KNN Loss: 3.6317789554595947 | CLS Loss: 0.02627662755548954\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 3.6416397094726562 | KNN Loss: 3.6082375049591064 | CLS Loss: 0.033402230590581894\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 3.65267014503479 | KNN Loss: 3.5959274768829346 | CLS Loss: 0.056742627173662186\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 3.637066602706909 | KNN Loss: 3.588217258453369 | CLS Loss: 0.048849426209926605\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 3.669450044631958 | KNN Loss: 3.6016852855682373 | CLS Loss: 0.06776486337184906\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 3.6880197525024414 | KNN Loss: 3.6448659896850586 | CLS Loss: 0.04315374419093132\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 3.622905969619751 | KNN Loss: 3.569213628768921 | CLS Loss: 0.05369236692786217\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 3.68575382232666 | KNN Loss: 3.620892286300659 | CLS Loss: 0.0648614689707756\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 3.6295218467712402 | KNN Loss: 3.57513689994812 | CLS Loss: 0.054384879767894745\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 3.660888671875 | KNN Loss: 3.604814291000366 | CLS Loss: 0.05607448145747185\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 3.6699349880218506 | KNN Loss: 3.591956853866577 | CLS Loss: 0.07797824591398239\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 3.635960340499878 | KNN Loss: 3.6065468788146973 | CLS Loss: 0.02941342443227768\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 3.6758925914764404 | KNN Loss: 3.636218547821045 | CLS Loss: 0.03967411071062088\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 3.6397030353546143 | KNN Loss: 3.590186834335327 | CLS Loss: 0.04951613396406174\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 3.6616995334625244 | KNN Loss: 3.600935935974121 | CLS Loss: 0.06076361984014511\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 3.6565632820129395 | KNN Loss: 3.602473735809326 | CLS Loss: 0.054089538753032684\n",
      "Epoch: 020, Loss: 3.6653, Train: 0.9867, Valid: 0.9818, Best: 0.9818\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 3.6401827335357666 | KNN Loss: 3.5765092372894287 | CLS Loss: 0.06367344409227371\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 3.633241891860962 | KNN Loss: 3.5829906463623047 | CLS Loss: 0.050251297652721405\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 3.6156492233276367 | KNN Loss: 3.5697498321533203 | CLS Loss: 0.04589928686618805\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 3.6112289428710938 | KNN Loss: 3.580378532409668 | CLS Loss: 0.03085031919181347\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 3.7033212184906006 | KNN Loss: 3.5674781799316406 | CLS Loss: 0.13584314286708832\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 3.6316843032836914 | KNN Loss: 3.58585524559021 | CLS Loss: 0.045828964561223984\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 3.6519064903259277 | KNN Loss: 3.6062252521514893 | CLS Loss: 0.04568130150437355\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 3.7054617404937744 | KNN Loss: 3.6306684017181396 | CLS Loss: 0.0747932642698288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 3.6628754138946533 | KNN Loss: 3.5964133739471436 | CLS Loss: 0.0664619579911232\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 3.6751885414123535 | KNN Loss: 3.6318159103393555 | CLS Loss: 0.04337269812822342\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 3.630153179168701 | KNN Loss: 3.597013235092163 | CLS Loss: 0.0331399068236351\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 3.6671855449676514 | KNN Loss: 3.6241397857666016 | CLS Loss: 0.04304575175046921\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 3.6547491550445557 | KNN Loss: 3.599541187286377 | CLS Loss: 0.05520789325237274\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 3.6733055114746094 | KNN Loss: 3.642901659011841 | CLS Loss: 0.030403781682252884\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 3.671067953109741 | KNN Loss: 3.6139323711395264 | CLS Loss: 0.0571356900036335\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 3.6647772789001465 | KNN Loss: 3.6442863941192627 | CLS Loss: 0.020490851253271103\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 3.690744638442993 | KNN Loss: 3.6024084091186523 | CLS Loss: 0.08833624422550201\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 3.701359272003174 | KNN Loss: 3.6058380603790283 | CLS Loss: 0.0955212414264679\n",
      "Epoch: 021, Loss: 3.6568, Train: 0.9850, Valid: 0.9812, Best: 0.9818\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 3.6953165531158447 | KNN Loss: 3.628214120864868 | CLS Loss: 0.06710241734981537\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 3.6460912227630615 | KNN Loss: 3.6054611206054688 | CLS Loss: 0.04063011333346367\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 3.673163414001465 | KNN Loss: 3.61415696144104 | CLS Loss: 0.05900639295578003\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 3.6646225452423096 | KNN Loss: 3.6141204833984375 | CLS Loss: 0.05050210282206535\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 3.646695613861084 | KNN Loss: 3.5825159549713135 | CLS Loss: 0.06417965143918991\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 3.677543878555298 | KNN Loss: 3.653926134109497 | CLS Loss: 0.023617783561348915\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 3.663602590560913 | KNN Loss: 3.6256041526794434 | CLS Loss: 0.03799832984805107\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 3.634860038757324 | KNN Loss: 3.58830189704895 | CLS Loss: 0.04655809327960014\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 3.627120018005371 | KNN Loss: 3.5869224071502686 | CLS Loss: 0.04019757732748985\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 3.6592793464660645 | KNN Loss: 3.607630968093872 | CLS Loss: 0.05164843797683716\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 3.6403229236602783 | KNN Loss: 3.5931954383850098 | CLS Loss: 0.04712749645113945\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 3.6854069232940674 | KNN Loss: 3.642862319946289 | CLS Loss: 0.0425446555018425\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 3.661562204360962 | KNN Loss: 3.5971169471740723 | CLS Loss: 0.06444534659385681\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 3.663983106613159 | KNN Loss: 3.5952699184417725 | CLS Loss: 0.06871321052312851\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 3.6200406551361084 | KNN Loss: 3.5933144092559814 | CLS Loss: 0.026726134121418\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 3.672523260116577 | KNN Loss: 3.6297831535339355 | CLS Loss: 0.042740046977996826\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 3.6437411308288574 | KNN Loss: 3.5825564861297607 | CLS Loss: 0.06118470057845116\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 3.7174761295318604 | KNN Loss: 3.605703592300415 | CLS Loss: 0.11177247762680054\n",
      "Epoch: 022, Loss: 3.6587, Train: 0.9864, Valid: 0.9821, Best: 0.9821\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 3.668210506439209 | KNN Loss: 3.6168577671051025 | CLS Loss: 0.051352642476558685\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 3.659222364425659 | KNN Loss: 3.6371915340423584 | CLS Loss: 0.0220309067517519\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 3.5997276306152344 | KNN Loss: 3.5552139282226562 | CLS Loss: 0.04451378807425499\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 3.6790523529052734 | KNN Loss: 3.638514280319214 | CLS Loss: 0.04053817689418793\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 3.640249490737915 | KNN Loss: 3.60026478767395 | CLS Loss: 0.03998459503054619\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 3.6784510612487793 | KNN Loss: 3.6380507946014404 | CLS Loss: 0.040400274097919464\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 3.6016781330108643 | KNN Loss: 3.5607662200927734 | CLS Loss: 0.040912024676799774\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 3.651038646697998 | KNN Loss: 3.5964601039886475 | CLS Loss: 0.05457855388522148\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 3.6598949432373047 | KNN Loss: 3.6370043754577637 | CLS Loss: 0.022890660911798477\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 3.6593358516693115 | KNN Loss: 3.631436347961426 | CLS Loss: 0.02789944037795067\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 3.704188346862793 | KNN Loss: 3.6095473766326904 | CLS Loss: 0.09464094042778015\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 3.623267650604248 | KNN Loss: 3.570725202560425 | CLS Loss: 0.05254238098859787\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 3.635885715484619 | KNN Loss: 3.5971992015838623 | CLS Loss: 0.03868654742836952\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 3.6617093086242676 | KNN Loss: 3.6009583473205566 | CLS Loss: 0.06075084209442139\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 3.7318027019500732 | KNN Loss: 3.6254682540893555 | CLS Loss: 0.10633455216884613\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 3.640933036804199 | KNN Loss: 3.613222360610962 | CLS Loss: 0.027710728347301483\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 3.6203715801239014 | KNN Loss: 3.5907225608825684 | CLS Loss: 0.029649116098880768\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 3.6355764865875244 | KNN Loss: 3.6211090087890625 | CLS Loss: 0.014467447996139526\n",
      "Epoch: 023, Loss: 3.6526, Train: 0.9876, Valid: 0.9829, Best: 0.9829\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 3.6898701190948486 | KNN Loss: 3.640172243118286 | CLS Loss: 0.04969796538352966\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 3.6590635776519775 | KNN Loss: 3.607224464416504 | CLS Loss: 0.05183904245495796\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 3.6670432090759277 | KNN Loss: 3.6220242977142334 | CLS Loss: 0.04501887038350105\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 3.612440586090088 | KNN Loss: 3.5879979133605957 | CLS Loss: 0.024442574009299278\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 3.6814262866973877 | KNN Loss: 3.61423921585083 | CLS Loss: 0.06718717515468597\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 3.6737334728240967 | KNN Loss: 3.6394166946411133 | CLS Loss: 0.03431672975420952\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 3.6380369663238525 | KNN Loss: 3.591787338256836 | CLS Loss: 0.046249546110630035\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 3.636343002319336 | KNN Loss: 3.6057372093200684 | CLS Loss: 0.030605776235461235\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 3.6311633586883545 | KNN Loss: 3.605074405670166 | CLS Loss: 0.026088986545801163\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 3.6974687576293945 | KNN Loss: 3.638552188873291 | CLS Loss: 0.05891667678952217\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 3.6513233184814453 | KNN Loss: 3.5847508907318115 | CLS Loss: 0.06657243520021439\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 3.7295825481414795 | KNN Loss: 3.6539151668548584 | CLS Loss: 0.07566743344068527\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 3.658942222595215 | KNN Loss: 3.599114418029785 | CLS Loss: 0.05982789769768715\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 3.6516783237457275 | KNN Loss: 3.6015546321868896 | CLS Loss: 0.050123732537031174\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 3.6178317070007324 | KNN Loss: 3.5876333713531494 | CLS Loss: 0.030198315158486366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 3.6529245376586914 | KNN Loss: 3.587357997894287 | CLS Loss: 0.06556656211614609\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 3.659420967102051 | KNN Loss: 3.624328136444092 | CLS Loss: 0.03509288281202316\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 3.6037163734436035 | KNN Loss: 3.5643045902252197 | CLS Loss: 0.03941170871257782\n",
      "Epoch: 024, Loss: 3.6496, Train: 0.9889, Valid: 0.9841, Best: 0.9841\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 3.5947272777557373 | KNN Loss: 3.570183515548706 | CLS Loss: 0.02454385533928871\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 3.5984323024749756 | KNN Loss: 3.5689890384674072 | CLS Loss: 0.02944316156208515\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 3.6254680156707764 | KNN Loss: 3.590101480484009 | CLS Loss: 0.035366423428058624\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 3.6293327808380127 | KNN Loss: 3.5626914501190186 | CLS Loss: 0.06664127856492996\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 3.6444270610809326 | KNN Loss: 3.6034302711486816 | CLS Loss: 0.0409967415034771\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 3.603797674179077 | KNN Loss: 3.5730361938476562 | CLS Loss: 0.030761467292904854\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 3.6497745513916016 | KNN Loss: 3.6070289611816406 | CLS Loss: 0.04274553433060646\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 3.6879286766052246 | KNN Loss: 3.626260995864868 | CLS Loss: 0.06166771799325943\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 3.6510324478149414 | KNN Loss: 3.5869345664978027 | CLS Loss: 0.06409778445959091\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 3.6557040214538574 | KNN Loss: 3.6130306720733643 | CLS Loss: 0.042673274874687195\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 3.6809921264648438 | KNN Loss: 3.612436294555664 | CLS Loss: 0.06855591386556625\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 3.6243975162506104 | KNN Loss: 3.607414484024048 | CLS Loss: 0.016983086243271828\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 3.6327195167541504 | KNN Loss: 3.5439300537109375 | CLS Loss: 0.08878937363624573\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 3.671961545944214 | KNN Loss: 3.5970637798309326 | CLS Loss: 0.07489773631095886\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 3.6816627979278564 | KNN Loss: 3.6035983562469482 | CLS Loss: 0.07806441187858582\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 3.6263844966888428 | KNN Loss: 3.577340602874756 | CLS Loss: 0.04904394969344139\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 3.6530847549438477 | KNN Loss: 3.583200454711914 | CLS Loss: 0.06988441944122314\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 3.660482168197632 | KNN Loss: 3.6256041526794434 | CLS Loss: 0.03487791493535042\n",
      "Epoch: 025, Loss: 3.6476, Train: 0.9880, Valid: 0.9828, Best: 0.9841\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 3.6524908542633057 | KNN Loss: 3.610938549041748 | CLS Loss: 0.04155222699046135\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 3.6367688179016113 | KNN Loss: 3.591251850128174 | CLS Loss: 0.045516856014728546\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 3.6776962280273438 | KNN Loss: 3.621129035949707 | CLS Loss: 0.05656707286834717\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 3.634634017944336 | KNN Loss: 3.596794366836548 | CLS Loss: 0.03783968463540077\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 3.5977540016174316 | KNN Loss: 3.5703399181365967 | CLS Loss: 0.027414055541157722\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 3.636216878890991 | KNN Loss: 3.5910141468048096 | CLS Loss: 0.0452028326690197\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 3.6546518802642822 | KNN Loss: 3.6033222675323486 | CLS Loss: 0.051329534500837326\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 3.636347532272339 | KNN Loss: 3.5956859588623047 | CLS Loss: 0.04066161438822746\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 3.6173133850097656 | KNN Loss: 3.575345277786255 | CLS Loss: 0.041968151926994324\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 3.6781346797943115 | KNN Loss: 3.6256678104400635 | CLS Loss: 0.05246691405773163\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 3.6241350173950195 | KNN Loss: 3.595757484436035 | CLS Loss: 0.028377454727888107\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 3.6083028316497803 | KNN Loss: 3.5712890625 | CLS Loss: 0.0370137058198452\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 3.725966691970825 | KNN Loss: 3.6809024810791016 | CLS Loss: 0.04506419226527214\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 3.6584725379943848 | KNN Loss: 3.5629541873931885 | CLS Loss: 0.0955183282494545\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 3.6377716064453125 | KNN Loss: 3.5714526176452637 | CLS Loss: 0.06631903350353241\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 3.6905782222747803 | KNN Loss: 3.6022677421569824 | CLS Loss: 0.0883105918765068\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 3.672941207885742 | KNN Loss: 3.595153331756592 | CLS Loss: 0.07778794318437576\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 3.665443181991577 | KNN Loss: 3.6287567615509033 | CLS Loss: 0.036686528474092484\n",
      "Epoch: 026, Loss: 3.6430, Train: 0.9875, Valid: 0.9832, Best: 0.9841\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 3.6181979179382324 | KNN Loss: 3.575371026992798 | CLS Loss: 0.042826827615499496\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 3.6493146419525146 | KNN Loss: 3.5744059085845947 | CLS Loss: 0.07490870356559753\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 3.6624538898468018 | KNN Loss: 3.608071804046631 | CLS Loss: 0.05438211187720299\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 3.675938129425049 | KNN Loss: 3.6044631004333496 | CLS Loss: 0.07147499173879623\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 3.693071126937866 | KNN Loss: 3.659946918487549 | CLS Loss: 0.03312410041689873\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 3.6359975337982178 | KNN Loss: 3.620553493499756 | CLS Loss: 0.015443947166204453\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 3.655380964279175 | KNN Loss: 3.629539966583252 | CLS Loss: 0.025841115042567253\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 3.6765899658203125 | KNN Loss: 3.641594409942627 | CLS Loss: 0.034995462745428085\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 3.693931818008423 | KNN Loss: 3.610273838043213 | CLS Loss: 0.08365808427333832\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 3.6648683547973633 | KNN Loss: 3.6132845878601074 | CLS Loss: 0.05158381909132004\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 3.6651110649108887 | KNN Loss: 3.6236908435821533 | CLS Loss: 0.04142014682292938\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 3.643920421600342 | KNN Loss: 3.599424123764038 | CLS Loss: 0.044496405869722366\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 3.6556239128112793 | KNN Loss: 3.627380609512329 | CLS Loss: 0.028243279084563255\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 3.648534059524536 | KNN Loss: 3.6190218925476074 | CLS Loss: 0.029512090608477592\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 3.5913093090057373 | KNN Loss: 3.5278971195220947 | CLS Loss: 0.06341216713190079\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 3.6452877521514893 | KNN Loss: 3.604928970336914 | CLS Loss: 0.040358759462833405\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 3.629209518432617 | KNN Loss: 3.603861093521118 | CLS Loss: 0.025348350405693054\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 3.6702990531921387 | KNN Loss: 3.640037775039673 | CLS Loss: 0.03026130422949791\n",
      "Epoch: 027, Loss: 3.6441, Train: 0.9882, Valid: 0.9831, Best: 0.9841\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 3.6707680225372314 | KNN Loss: 3.6316356658935547 | CLS Loss: 0.03913241624832153\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 3.6182384490966797 | KNN Loss: 3.5698769092559814 | CLS Loss: 0.04836151376366615\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 3.6431190967559814 | KNN Loss: 3.611964464187622 | CLS Loss: 0.031154589727520943\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 3.674837589263916 | KNN Loss: 3.626291036605835 | CLS Loss: 0.04854660853743553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 3.664663076400757 | KNN Loss: 3.621389389038086 | CLS Loss: 0.04327370598912239\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 3.6018247604370117 | KNN Loss: 3.5840976238250732 | CLS Loss: 0.017727019265294075\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 3.6275362968444824 | KNN Loss: 3.5626912117004395 | CLS Loss: 0.06484515219926834\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 3.6240897178649902 | KNN Loss: 3.5790674686431885 | CLS Loss: 0.04502223804593086\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 3.6949009895324707 | KNN Loss: 3.6034622192382812 | CLS Loss: 0.09143884479999542\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 3.6456689834594727 | KNN Loss: 3.5888876914978027 | CLS Loss: 0.05678130313754082\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 3.6619744300842285 | KNN Loss: 3.5994913578033447 | CLS Loss: 0.06248318403959274\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 3.6092026233673096 | KNN Loss: 3.586717367172241 | CLS Loss: 0.022485174238681793\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 3.6149423122406006 | KNN Loss: 3.5805275440216064 | CLS Loss: 0.03441482037305832\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 3.581825017929077 | KNN Loss: 3.552610397338867 | CLS Loss: 0.0292145274579525\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 3.6775381565093994 | KNN Loss: 3.640751838684082 | CLS Loss: 0.03678632527589798\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 3.683525800704956 | KNN Loss: 3.616366386413574 | CLS Loss: 0.06715937703847885\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 3.600968837738037 | KNN Loss: 3.5676331520080566 | CLS Loss: 0.033335693180561066\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 3.6908648014068604 | KNN Loss: 3.6509416103363037 | CLS Loss: 0.03992311283946037\n",
      "Epoch: 028, Loss: 3.6441, Train: 0.9900, Valid: 0.9838, Best: 0.9841\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 3.6300528049468994 | KNN Loss: 3.5805861949920654 | CLS Loss: 0.04946664720773697\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 3.624937057495117 | KNN Loss: 3.587700605392456 | CLS Loss: 0.03723647817969322\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 3.644801378250122 | KNN Loss: 3.6310832500457764 | CLS Loss: 0.013718039728701115\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 3.6427032947540283 | KNN Loss: 3.589177370071411 | CLS Loss: 0.05352601781487465\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 3.6102540493011475 | KNN Loss: 3.573587417602539 | CLS Loss: 0.03666657581925392\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 3.62605881690979 | KNN Loss: 3.5935757160186768 | CLS Loss: 0.03248303756117821\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 3.637601613998413 | KNN Loss: 3.5981388092041016 | CLS Loss: 0.03946268931031227\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 3.6149954795837402 | KNN Loss: 3.581972360610962 | CLS Loss: 0.03302306681871414\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 3.6480772495269775 | KNN Loss: 3.580744504928589 | CLS Loss: 0.0673326626420021\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 3.600131034851074 | KNN Loss: 3.5826222896575928 | CLS Loss: 0.01750880852341652\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 3.674189329147339 | KNN Loss: 3.580505132675171 | CLS Loss: 0.09368425607681274\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 3.6560826301574707 | KNN Loss: 3.6239442825317383 | CLS Loss: 0.0321384035050869\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 3.664591073989868 | KNN Loss: 3.5959036350250244 | CLS Loss: 0.06868741661310196\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 3.630856990814209 | KNN Loss: 3.5853488445281982 | CLS Loss: 0.04550809785723686\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 3.6585774421691895 | KNN Loss: 3.5967791080474854 | CLS Loss: 0.06179841607809067\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 3.6287169456481934 | KNN Loss: 3.5736303329467773 | CLS Loss: 0.0550866425037384\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 3.649698257446289 | KNN Loss: 3.619413375854492 | CLS Loss: 0.030284767970442772\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 3.6327672004699707 | KNN Loss: 3.6039559841156006 | CLS Loss: 0.028811251744627953\n",
      "Epoch: 029, Loss: 3.6404, Train: 0.9889, Valid: 0.9833, Best: 0.9841\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 3.650550365447998 | KNN Loss: 3.605837821960449 | CLS Loss: 0.044712651520967484\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 3.638017416000366 | KNN Loss: 3.6088528633117676 | CLS Loss: 0.02916455641388893\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 3.6154439449310303 | KNN Loss: 3.575870990753174 | CLS Loss: 0.03957286849617958\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 3.6135473251342773 | KNN Loss: 3.597285032272339 | CLS Loss: 0.016262298449873924\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 3.73159122467041 | KNN Loss: 3.6735427379608154 | CLS Loss: 0.05804859846830368\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 3.6322364807128906 | KNN Loss: 3.5851895809173584 | CLS Loss: 0.04704689607024193\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 3.6276743412017822 | KNN Loss: 3.5937910079956055 | CLS Loss: 0.033883437514305115\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 3.6325337886810303 | KNN Loss: 3.573335886001587 | CLS Loss: 0.05919786915183067\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 3.6424262523651123 | KNN Loss: 3.594440460205078 | CLS Loss: 0.047985874116420746\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 3.5893056392669678 | KNN Loss: 3.567549467086792 | CLS Loss: 0.02175610139966011\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 3.620480537414551 | KNN Loss: 3.5861806869506836 | CLS Loss: 0.03429976850748062\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 3.6682679653167725 | KNN Loss: 3.6066250801086426 | CLS Loss: 0.06164295971393585\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 3.691877841949463 | KNN Loss: 3.6448540687561035 | CLS Loss: 0.04702388495206833\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 3.588726282119751 | KNN Loss: 3.5397121906280518 | CLS Loss: 0.049014125019311905\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 3.6146137714385986 | KNN Loss: 3.561506986618042 | CLS Loss: 0.053106825798749924\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 3.6061043739318848 | KNN Loss: 3.5849406719207764 | CLS Loss: 0.021163754165172577\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 3.6237845420837402 | KNN Loss: 3.5919132232666016 | CLS Loss: 0.03187140077352524\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 3.675943613052368 | KNN Loss: 3.6429479122161865 | CLS Loss: 0.03299565240740776\n",
      "Epoch: 030, Loss: 3.6387, Train: 0.9877, Valid: 0.9824, Best: 0.9841\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 3.6770758628845215 | KNN Loss: 3.6271767616271973 | CLS Loss: 0.049899037927389145\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 3.653336763381958 | KNN Loss: 3.6177172660827637 | CLS Loss: 0.03561944514513016\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 3.6263797283172607 | KNN Loss: 3.586758613586426 | CLS Loss: 0.03962106630206108\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 3.634460210800171 | KNN Loss: 3.602226495742798 | CLS Loss: 0.03223372623324394\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 3.617406129837036 | KNN Loss: 3.5880863666534424 | CLS Loss: 0.02931980788707733\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 3.6250178813934326 | KNN Loss: 3.5789830684661865 | CLS Loss: 0.046034835278987885\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 3.6254045963287354 | KNN Loss: 3.5851807594299316 | CLS Loss: 0.040223926305770874\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 3.6230201721191406 | KNN Loss: 3.580613374710083 | CLS Loss: 0.0424068458378315\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 3.6285207271575928 | KNN Loss: 3.585615396499634 | CLS Loss: 0.042905401438474655\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 3.6246886253356934 | KNN Loss: 3.609510660171509 | CLS Loss: 0.015177860856056213\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 3.6646244525909424 | KNN Loss: 3.6150100231170654 | CLS Loss: 0.04961446672677994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 3.5875353813171387 | KNN Loss: 3.5693368911743164 | CLS Loss: 0.01819850690662861\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 3.6558549404144287 | KNN Loss: 3.6060428619384766 | CLS Loss: 0.04981211572885513\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 3.6491622924804688 | KNN Loss: 3.6076276302337646 | CLS Loss: 0.04153454676270485\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 3.6279120445251465 | KNN Loss: 3.5890257358551025 | CLS Loss: 0.03888633847236633\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 3.671757936477661 | KNN Loss: 3.6437039375305176 | CLS Loss: 0.028054043650627136\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 3.6417324542999268 | KNN Loss: 3.607290267944336 | CLS Loss: 0.03444208577275276\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 3.623818874359131 | KNN Loss: 3.59360933303833 | CLS Loss: 0.030209552496671677\n",
      "Epoch: 031, Loss: 3.6399, Train: 0.9895, Valid: 0.9843, Best: 0.9843\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 3.6086864471435547 | KNN Loss: 3.569575548171997 | CLS Loss: 0.03911081328988075\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 3.6840014457702637 | KNN Loss: 3.6691887378692627 | CLS Loss: 0.014812671579420567\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 3.6363065242767334 | KNN Loss: 3.5744006633758545 | CLS Loss: 0.06190589815378189\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 3.6018576622009277 | KNN Loss: 3.572873830795288 | CLS Loss: 0.028983715921640396\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 3.658174991607666 | KNN Loss: 3.598724126815796 | CLS Loss: 0.05945076793432236\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 3.640913963317871 | KNN Loss: 3.6011769771575928 | CLS Loss: 0.039736971259117126\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 3.5987069606781006 | KNN Loss: 3.572150945663452 | CLS Loss: 0.02655593305826187\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 3.6233832836151123 | KNN Loss: 3.5986907482147217 | CLS Loss: 0.024692533537745476\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 3.6784543991088867 | KNN Loss: 3.623385429382324 | CLS Loss: 0.055068887770175934\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 3.656045913696289 | KNN Loss: 3.6200971603393555 | CLS Loss: 0.03594866022467613\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 3.6153368949890137 | KNN Loss: 3.5716452598571777 | CLS Loss: 0.04369168356060982\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 3.7022430896759033 | KNN Loss: 3.6818654537200928 | CLS Loss: 0.020377539098262787\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 3.612621307373047 | KNN Loss: 3.5785701274871826 | CLS Loss: 0.034051213413476944\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 3.6262784004211426 | KNN Loss: 3.5950191020965576 | CLS Loss: 0.03125922381877899\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 3.665592908859253 | KNN Loss: 3.6092731952667236 | CLS Loss: 0.056319721043109894\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 3.6402463912963867 | KNN Loss: 3.5830302238464355 | CLS Loss: 0.05721607059240341\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 3.6566333770751953 | KNN Loss: 3.6216135025024414 | CLS Loss: 0.035019878298044205\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 3.655625820159912 | KNN Loss: 3.5977861881256104 | CLS Loss: 0.05783959478139877\n",
      "Epoch: 032, Loss: 3.6391, Train: 0.9863, Valid: 0.9788, Best: 0.9843\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 3.650085926055908 | KNN Loss: 3.6020500659942627 | CLS Loss: 0.048035889863967896\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 3.6145074367523193 | KNN Loss: 3.590528726577759 | CLS Loss: 0.023978766053915024\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 3.6236307621002197 | KNN Loss: 3.585491418838501 | CLS Loss: 0.038139306008815765\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 3.6345746517181396 | KNN Loss: 3.604377508163452 | CLS Loss: 0.030197136104106903\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 3.602593421936035 | KNN Loss: 3.5726616382598877 | CLS Loss: 0.029931819066405296\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 3.635892868041992 | KNN Loss: 3.5767905712127686 | CLS Loss: 0.05910227447748184\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 3.658186197280884 | KNN Loss: 3.6276416778564453 | CLS Loss: 0.03054451383650303\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 3.6028494834899902 | KNN Loss: 3.5493924617767334 | CLS Loss: 0.05345708131790161\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 3.6247730255126953 | KNN Loss: 3.590982675552368 | CLS Loss: 0.03379039838910103\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 3.665717363357544 | KNN Loss: 3.640936851501465 | CLS Loss: 0.024780428037047386\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 3.619706392288208 | KNN Loss: 3.5919222831726074 | CLS Loss: 0.02778414823114872\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 3.6105384826660156 | KNN Loss: 3.578524112701416 | CLS Loss: 0.03201437368988991\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 3.6345317363739014 | KNN Loss: 3.563642740249634 | CLS Loss: 0.07088909298181534\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 3.644479274749756 | KNN Loss: 3.594154119491577 | CLS Loss: 0.0503251813352108\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 3.6027331352233887 | KNN Loss: 3.5742509365081787 | CLS Loss: 0.02848225273191929\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 3.6855309009552 | KNN Loss: 3.6321310997009277 | CLS Loss: 0.05339990183711052\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 3.6622161865234375 | KNN Loss: 3.589094400405884 | CLS Loss: 0.07312167435884476\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 3.648277997970581 | KNN Loss: 3.612978458404541 | CLS Loss: 0.03529956564307213\n",
      "Epoch: 033, Loss: 3.6346, Train: 0.9903, Valid: 0.9850, Best: 0.9850\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 3.622490644454956 | KNN Loss: 3.587712049484253 | CLS Loss: 0.03477848693728447\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 3.601911783218384 | KNN Loss: 3.5667359828948975 | CLS Loss: 0.035175733268260956\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 3.610628128051758 | KNN Loss: 3.5896739959716797 | CLS Loss: 0.020954204723238945\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 3.5802676677703857 | KNN Loss: 3.571472406387329 | CLS Loss: 0.008795375935733318\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 3.6444482803344727 | KNN Loss: 3.6157970428466797 | CLS Loss: 0.028651315718889236\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 3.6651217937469482 | KNN Loss: 3.5879948139190674 | CLS Loss: 0.07712697237730026\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 3.6808583736419678 | KNN Loss: 3.665407657623291 | CLS Loss: 0.015450619161128998\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 3.62919545173645 | KNN Loss: 3.5861926078796387 | CLS Loss: 0.043002959340810776\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 3.6601853370666504 | KNN Loss: 3.5977680683135986 | CLS Loss: 0.06241734325885773\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 3.5994205474853516 | KNN Loss: 3.5698747634887695 | CLS Loss: 0.02954568713903427\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 3.6317026615142822 | KNN Loss: 3.604344367980957 | CLS Loss: 0.027358200401067734\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 3.6162683963775635 | KNN Loss: 3.580211877822876 | CLS Loss: 0.03605644777417183\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 3.6437745094299316 | KNN Loss: 3.6061971187591553 | CLS Loss: 0.03757743164896965\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 3.6218338012695312 | KNN Loss: 3.6027939319610596 | CLS Loss: 0.019039908424019814\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 3.642029047012329 | KNN Loss: 3.6210668087005615 | CLS Loss: 0.020962247624993324\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 3.5857136249542236 | KNN Loss: 3.5745291709899902 | CLS Loss: 0.01118447631597519\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 3.6495985984802246 | KNN Loss: 3.603377342224121 | CLS Loss: 0.04622131213545799\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 3.6127593517303467 | KNN Loss: 3.596360206604004 | CLS Loss: 0.016399221494793892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 3.6298, Train: 0.9903, Valid: 0.9842, Best: 0.9850\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 3.6459591388702393 | KNN Loss: 3.6063640117645264 | CLS Loss: 0.039595216512680054\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 3.648469924926758 | KNN Loss: 3.613757371902466 | CLS Loss: 0.034712616354227066\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 3.6075522899627686 | KNN Loss: 3.5999791622161865 | CLS Loss: 0.007573017850518227\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 3.614513635635376 | KNN Loss: 3.5567119121551514 | CLS Loss: 0.05780177190899849\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 3.63446044921875 | KNN Loss: 3.5775022506713867 | CLS Loss: 0.0569581463932991\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 3.6043877601623535 | KNN Loss: 3.5687026977539062 | CLS Loss: 0.03568503260612488\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 3.646314859390259 | KNN Loss: 3.589869260787964 | CLS Loss: 0.056445490568876266\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 3.611445903778076 | KNN Loss: 3.5544073581695557 | CLS Loss: 0.05703843757510185\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 3.6482412815093994 | KNN Loss: 3.612816572189331 | CLS Loss: 0.035424668341875076\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 3.655125856399536 | KNN Loss: 3.630465030670166 | CLS Loss: 0.02466072328388691\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 3.5724167823791504 | KNN Loss: 3.546518564224243 | CLS Loss: 0.02589811384677887\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 3.596879720687866 | KNN Loss: 3.5419843196868896 | CLS Loss: 0.05489549785852432\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 3.632906913757324 | KNN Loss: 3.616668701171875 | CLS Loss: 0.01623820699751377\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 3.6066415309906006 | KNN Loss: 3.573124885559082 | CLS Loss: 0.033516544848680496\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 3.6028859615325928 | KNN Loss: 3.5776896476745605 | CLS Loss: 0.025196285918354988\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 3.603864908218384 | KNN Loss: 3.578298807144165 | CLS Loss: 0.025566041469573975\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 3.612992286682129 | KNN Loss: 3.581040859222412 | CLS Loss: 0.03195139393210411\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 3.619628429412842 | KNN Loss: 3.5924205780029297 | CLS Loss: 0.027207793667912483\n",
      "Epoch: 035, Loss: 3.6307, Train: 0.9903, Valid: 0.9850, Best: 0.9850\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 3.625370740890503 | KNN Loss: 3.6073157787323 | CLS Loss: 0.018055066466331482\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 3.593724012374878 | KNN Loss: 3.5618653297424316 | CLS Loss: 0.03185872361063957\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 3.6734867095947266 | KNN Loss: 3.628596067428589 | CLS Loss: 0.04489074647426605\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 3.5690486431121826 | KNN Loss: 3.5418615341186523 | CLS Loss: 0.02718721516430378\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 3.643866539001465 | KNN Loss: 3.603494882583618 | CLS Loss: 0.04037175700068474\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 3.6360034942626953 | KNN Loss: 3.5991687774658203 | CLS Loss: 0.03683478385210037\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 3.6361148357391357 | KNN Loss: 3.5888330936431885 | CLS Loss: 0.04728172346949577\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 3.594371795654297 | KNN Loss: 3.5669727325439453 | CLS Loss: 0.027399105951189995\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 3.7061798572540283 | KNN Loss: 3.6751692295074463 | CLS Loss: 0.031010596081614494\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 3.635355234146118 | KNN Loss: 3.6089274883270264 | CLS Loss: 0.02642771229147911\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 3.609282970428467 | KNN Loss: 3.5728659629821777 | CLS Loss: 0.036417100578546524\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 3.6539969444274902 | KNN Loss: 3.607912540435791 | CLS Loss: 0.04608428478240967\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 3.5569417476654053 | KNN Loss: 3.5419297218322754 | CLS Loss: 0.015011915937066078\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 3.6565895080566406 | KNN Loss: 3.6178934574127197 | CLS Loss: 0.038695961236953735\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 3.688462972640991 | KNN Loss: 3.6469972133636475 | CLS Loss: 0.04146582633256912\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 3.604114055633545 | KNN Loss: 3.5712039470672607 | CLS Loss: 0.032910075038671494\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 3.66385555267334 | KNN Loss: 3.633073329925537 | CLS Loss: 0.030782142654061317\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 3.6389803886413574 | KNN Loss: 3.5915091037750244 | CLS Loss: 0.047471269965171814\n",
      "Epoch: 036, Loss: 3.6279, Train: 0.9908, Valid: 0.9841, Best: 0.9850\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 3.6225008964538574 | KNN Loss: 3.5831117630004883 | CLS Loss: 0.039389219135046005\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 3.6076464653015137 | KNN Loss: 3.591972827911377 | CLS Loss: 0.01567363739013672\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 3.6841506958007812 | KNN Loss: 3.6406514644622803 | CLS Loss: 0.0434991680085659\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 3.6308035850524902 | KNN Loss: 3.595256805419922 | CLS Loss: 0.03554670512676239\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 3.608196973800659 | KNN Loss: 3.5559298992156982 | CLS Loss: 0.052267175167798996\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 3.6333489418029785 | KNN Loss: 3.6252429485321045 | CLS Loss: 0.008105929009616375\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 3.615781784057617 | KNN Loss: 3.6036603450775146 | CLS Loss: 0.012121330015361309\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 3.623920440673828 | KNN Loss: 3.588992118835449 | CLS Loss: 0.0349283367395401\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 3.6506497859954834 | KNN Loss: 3.6038546562194824 | CLS Loss: 0.04679514840245247\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 3.6592319011688232 | KNN Loss: 3.617037296295166 | CLS Loss: 0.04219471290707588\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 3.6505184173583984 | KNN Loss: 3.5903968811035156 | CLS Loss: 0.06012164428830147\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 3.6142091751098633 | KNN Loss: 3.600111722946167 | CLS Loss: 0.014097435399889946\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 3.6057939529418945 | KNN Loss: 3.589820384979248 | CLS Loss: 0.015973467379808426\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 3.646963596343994 | KNN Loss: 3.596574068069458 | CLS Loss: 0.05038943141698837\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 3.608617067337036 | KNN Loss: 3.5722744464874268 | CLS Loss: 0.03634266182780266\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 3.6385838985443115 | KNN Loss: 3.584045886993408 | CLS Loss: 0.05453808605670929\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 3.6326591968536377 | KNN Loss: 3.619528293609619 | CLS Loss: 0.013130836188793182\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 3.645343065261841 | KNN Loss: 3.6173362731933594 | CLS Loss: 0.02800682745873928\n",
      "Epoch: 037, Loss: 3.6301, Train: 0.9901, Valid: 0.9839, Best: 0.9850\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 3.605069637298584 | KNN Loss: 3.5720407962799072 | CLS Loss: 0.033028800040483475\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 3.596957206726074 | KNN Loss: 3.5806989669799805 | CLS Loss: 0.016258230432868004\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 3.6489601135253906 | KNN Loss: 3.6177477836608887 | CLS Loss: 0.031212428584694862\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 3.6188220977783203 | KNN Loss: 3.5622541904449463 | CLS Loss: 0.0565679669380188\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 3.6072897911071777 | KNN Loss: 3.5866644382476807 | CLS Loss: 0.020625358447432518\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 3.611626148223877 | KNN Loss: 3.5947189331054688 | CLS Loss: 0.016907095909118652\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 3.6217405796051025 | KNN Loss: 3.575965642929077 | CLS Loss: 0.0457749105989933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 3.609412670135498 | KNN Loss: 3.5557339191436768 | CLS Loss: 0.05367881804704666\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 3.5950465202331543 | KNN Loss: 3.5797388553619385 | CLS Loss: 0.01530769094824791\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 3.6174142360687256 | KNN Loss: 3.601377010345459 | CLS Loss: 0.016037175431847572\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 3.609300374984741 | KNN Loss: 3.5839457511901855 | CLS Loss: 0.025354551151394844\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 3.618511915206909 | KNN Loss: 3.5956578254699707 | CLS Loss: 0.0228541512042284\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 3.6295716762542725 | KNN Loss: 3.608710765838623 | CLS Loss: 0.02086099237203598\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 3.6345434188842773 | KNN Loss: 3.6109437942504883 | CLS Loss: 0.023599542677402496\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 3.6151649951934814 | KNN Loss: 3.5774545669555664 | CLS Loss: 0.03771033138036728\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 3.648181200027466 | KNN Loss: 3.6157584190368652 | CLS Loss: 0.03242286667227745\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 3.6523613929748535 | KNN Loss: 3.6113038063049316 | CLS Loss: 0.041057560592889786\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 3.582271099090576 | KNN Loss: 3.5686190128326416 | CLS Loss: 0.01365216076374054\n",
      "Epoch: 038, Loss: 3.6307, Train: 0.9891, Valid: 0.9837, Best: 0.9850\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 3.660555601119995 | KNN Loss: 3.613711357116699 | CLS Loss: 0.04684418812394142\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 3.6700828075408936 | KNN Loss: 3.6163108348846436 | CLS Loss: 0.05377199873328209\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 3.6515724658966064 | KNN Loss: 3.6178460121154785 | CLS Loss: 0.03372642397880554\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 3.6059482097625732 | KNN Loss: 3.596524715423584 | CLS Loss: 0.009423392824828625\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 3.628429412841797 | KNN Loss: 3.5828137397766113 | CLS Loss: 0.04561561346054077\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 3.6284265518188477 | KNN Loss: 3.589160919189453 | CLS Loss: 0.039265651255846024\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 3.656583309173584 | KNN Loss: 3.626371383666992 | CLS Loss: 0.030211852863430977\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 3.651994466781616 | KNN Loss: 3.626889228820801 | CLS Loss: 0.02510525844991207\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 3.605729818344116 | KNN Loss: 3.5595650672912598 | CLS Loss: 0.04616468399763107\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 3.6161692142486572 | KNN Loss: 3.557929277420044 | CLS Loss: 0.058239832520484924\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 3.6258907318115234 | KNN Loss: 3.5808751583099365 | CLS Loss: 0.045015599578619\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 3.615915536880493 | KNN Loss: 3.5784573554992676 | CLS Loss: 0.03745821490883827\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 3.6418263912200928 | KNN Loss: 3.603851556777954 | CLS Loss: 0.03797489032149315\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 3.6285088062286377 | KNN Loss: 3.5833449363708496 | CLS Loss: 0.045163847506046295\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 3.6173629760742188 | KNN Loss: 3.5840537548065186 | CLS Loss: 0.03330925107002258\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 3.6062772274017334 | KNN Loss: 3.5815799236297607 | CLS Loss: 0.02469734288752079\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 3.698678970336914 | KNN Loss: 3.660520553588867 | CLS Loss: 0.038158442825078964\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 3.6411314010620117 | KNN Loss: 3.595428466796875 | CLS Loss: 0.04570293053984642\n",
      "Epoch: 039, Loss: 3.6302, Train: 0.9911, Valid: 0.9846, Best: 0.9850\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 3.6281204223632812 | KNN Loss: 3.6140053272247314 | CLS Loss: 0.014115197584033012\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 3.6053576469421387 | KNN Loss: 3.5924153327941895 | CLS Loss: 0.012942343950271606\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 3.653048276901245 | KNN Loss: 3.6188721656799316 | CLS Loss: 0.03417610749602318\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 3.6648523807525635 | KNN Loss: 3.6175315380096436 | CLS Loss: 0.047320883721113205\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 3.6323676109313965 | KNN Loss: 3.596101999282837 | CLS Loss: 0.03626571595668793\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 3.600468873977661 | KNN Loss: 3.574169635772705 | CLS Loss: 0.02629929780960083\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 3.6058788299560547 | KNN Loss: 3.578064203262329 | CLS Loss: 0.027814527973532677\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 3.5829830169677734 | KNN Loss: 3.566253662109375 | CLS Loss: 0.016729241237044334\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 3.620678186416626 | KNN Loss: 3.567716360092163 | CLS Loss: 0.05296174809336662\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 3.6560115814208984 | KNN Loss: 3.619617223739624 | CLS Loss: 0.036394305527210236\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 3.6199376583099365 | KNN Loss: 3.5920658111572266 | CLS Loss: 0.02787184715270996\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 3.6262946128845215 | KNN Loss: 3.586089611053467 | CLS Loss: 0.04020493105053902\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 3.6546804904937744 | KNN Loss: 3.623323440551758 | CLS Loss: 0.03135702759027481\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 3.639613389968872 | KNN Loss: 3.60990309715271 | CLS Loss: 0.029710253700613976\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 3.5907680988311768 | KNN Loss: 3.5463414192199707 | CLS Loss: 0.04442663490772247\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 3.6404032707214355 | KNN Loss: 3.6095502376556396 | CLS Loss: 0.03085307963192463\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 3.5862064361572266 | KNN Loss: 3.5563220977783203 | CLS Loss: 0.02988435886800289\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 3.623568058013916 | KNN Loss: 3.5933597087860107 | CLS Loss: 0.03020845539867878\n",
      "Epoch: 040, Loss: 3.6252, Train: 0.9906, Valid: 0.9846, Best: 0.9850\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 3.673377752304077 | KNN Loss: 3.652663230895996 | CLS Loss: 0.020714616402983665\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 3.6323955059051514 | KNN Loss: 3.5774974822998047 | CLS Loss: 0.05489801615476608\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 3.6995832920074463 | KNN Loss: 3.6387484073638916 | CLS Loss: 0.06083477661013603\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 3.636974811553955 | KNN Loss: 3.606691598892212 | CLS Loss: 0.03028322197496891\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 3.579392910003662 | KNN Loss: 3.56522536277771 | CLS Loss: 0.014167544431984425\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 3.60628080368042 | KNN Loss: 3.584259271621704 | CLS Loss: 0.022021451964974403\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 3.613370656967163 | KNN Loss: 3.572986602783203 | CLS Loss: 0.04038400575518608\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 3.5967016220092773 | KNN Loss: 3.564002275466919 | CLS Loss: 0.0326993353664875\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 3.620591402053833 | KNN Loss: 3.599597454071045 | CLS Loss: 0.020993847399950027\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 3.6036646366119385 | KNN Loss: 3.5740067958831787 | CLS Loss: 0.029657846316695213\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 3.654052257537842 | KNN Loss: 3.5804762840270996 | CLS Loss: 0.07357607036828995\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 3.5993499755859375 | KNN Loss: 3.5774922370910645 | CLS Loss: 0.021857623010873795\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 3.6108171939849854 | KNN Loss: 3.5964157581329346 | CLS Loss: 0.014401334337890148\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 3.616305351257324 | KNN Loss: 3.597996473312378 | CLS Loss: 0.018308760598301888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 3.7036964893341064 | KNN Loss: 3.643734931945801 | CLS Loss: 0.059961605817079544\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 3.6348960399627686 | KNN Loss: 3.6005005836486816 | CLS Loss: 0.03439541906118393\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 3.6818277835845947 | KNN Loss: 3.632594108581543 | CLS Loss: 0.049233578145504\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 3.6594271659851074 | KNN Loss: 3.6432623863220215 | CLS Loss: 0.01616472564637661\n",
      "Epoch: 041, Loss: 3.6296, Train: 0.9896, Valid: 0.9846, Best: 0.9850\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 3.6760714054107666 | KNN Loss: 3.644674301147461 | CLS Loss: 0.0313970111310482\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 3.6073074340820312 | KNN Loss: 3.5931053161621094 | CLS Loss: 0.014202069491147995\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 3.6203484535217285 | KNN Loss: 3.5867741107940674 | CLS Loss: 0.033574458211660385\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 3.6613359451293945 | KNN Loss: 3.627840042114258 | CLS Loss: 0.03349592909216881\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 3.6270322799682617 | KNN Loss: 3.5976080894470215 | CLS Loss: 0.029424285516142845\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 3.6178643703460693 | KNN Loss: 3.609626054763794 | CLS Loss: 0.008238385431468487\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 3.5858728885650635 | KNN Loss: 3.5638179779052734 | CLS Loss: 0.022054893895983696\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 3.629634380340576 | KNN Loss: 3.595658540725708 | CLS Loss: 0.03397582098841667\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 3.6516225337982178 | KNN Loss: 3.587831497192383 | CLS Loss: 0.06379114836454391\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 3.655426502227783 | KNN Loss: 3.6090266704559326 | CLS Loss: 0.046399835497140884\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 3.6009273529052734 | KNN Loss: 3.572105646133423 | CLS Loss: 0.02882176823914051\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 3.6679883003234863 | KNN Loss: 3.6181414127349854 | CLS Loss: 0.049846868962049484\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 3.6746504306793213 | KNN Loss: 3.636059045791626 | CLS Loss: 0.03859138488769531\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 3.681891441345215 | KNN Loss: 3.653615713119507 | CLS Loss: 0.02827565185725689\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 3.6455676555633545 | KNN Loss: 3.6149864196777344 | CLS Loss: 0.030581220984458923\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 3.624884605407715 | KNN Loss: 3.598047971725464 | CLS Loss: 0.026836561039090157\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 3.602067232131958 | KNN Loss: 3.5639145374298096 | CLS Loss: 0.038152746856212616\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 3.58656644821167 | KNN Loss: 3.5640451908111572 | CLS Loss: 0.022521276026964188\n",
      "Epoch: 042, Loss: 3.6387, Train: 0.9903, Valid: 0.9831, Best: 0.9850\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 3.716136932373047 | KNN Loss: 3.64465594291687 | CLS Loss: 0.07148102670907974\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 3.6031179428100586 | KNN Loss: 3.589573621749878 | CLS Loss: 0.013544334098696709\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 3.6526565551757812 | KNN Loss: 3.6282894611358643 | CLS Loss: 0.02436700090765953\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 3.6041810512542725 | KNN Loss: 3.586286783218384 | CLS Loss: 0.01789417676627636\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 3.6678366661071777 | KNN Loss: 3.621950626373291 | CLS Loss: 0.04588596150279045\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 3.7262537479400635 | KNN Loss: 3.6332318782806396 | CLS Loss: 0.09302178770303726\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 3.66591215133667 | KNN Loss: 3.6559574604034424 | CLS Loss: 0.009954729117453098\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 3.6988978385925293 | KNN Loss: 3.639592409133911 | CLS Loss: 0.05930547043681145\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 3.665294885635376 | KNN Loss: 3.6374402046203613 | CLS Loss: 0.02785458229482174\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 3.6417930126190186 | KNN Loss: 3.5963854789733887 | CLS Loss: 0.0454074889421463\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 3.6400020122528076 | KNN Loss: 3.5854978561401367 | CLS Loss: 0.05450419709086418\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 3.6967837810516357 | KNN Loss: 3.6578221321105957 | CLS Loss: 0.03896157070994377\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 3.6143569946289062 | KNN Loss: 3.58528470993042 | CLS Loss: 0.029072318226099014\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 3.6205179691314697 | KNN Loss: 3.5853335857391357 | CLS Loss: 0.035184357315301895\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 3.599275827407837 | KNN Loss: 3.5700066089630127 | CLS Loss: 0.029269220307469368\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 3.63942551612854 | KNN Loss: 3.603121519088745 | CLS Loss: 0.036303963512182236\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 3.6333017349243164 | KNN Loss: 3.6028635501861572 | CLS Loss: 0.030438069254159927\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 3.6426312923431396 | KNN Loss: 3.6121115684509277 | CLS Loss: 0.03051970899105072\n",
      "Epoch: 043, Loss: 3.6369, Train: 0.9907, Valid: 0.9847, Best: 0.9850\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 3.613215923309326 | KNN Loss: 3.6001603603363037 | CLS Loss: 0.013055597431957722\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 3.5970370769500732 | KNN Loss: 3.583866834640503 | CLS Loss: 0.013170165941119194\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 3.6498475074768066 | KNN Loss: 3.5958549976348877 | CLS Loss: 0.05399256572127342\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 3.718815803527832 | KNN Loss: 3.6590869426727295 | CLS Loss: 0.059728819876909256\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 3.627312183380127 | KNN Loss: 3.6078174114227295 | CLS Loss: 0.019494881853461266\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 3.6037468910217285 | KNN Loss: 3.5819528102874756 | CLS Loss: 0.02179419808089733\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 3.6895759105682373 | KNN Loss: 3.613252878189087 | CLS Loss: 0.07632305473089218\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 3.6506049633026123 | KNN Loss: 3.588379144668579 | CLS Loss: 0.06222584471106529\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 3.6666643619537354 | KNN Loss: 3.626617193222046 | CLS Loss: 0.04004718363285065\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 3.589696168899536 | KNN Loss: 3.562775135040283 | CLS Loss: 0.02692112885415554\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 3.6821377277374268 | KNN Loss: 3.63899302482605 | CLS Loss: 0.04314475134015083\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 3.6956958770751953 | KNN Loss: 3.60306978225708 | CLS Loss: 0.0926261618733406\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 3.6219146251678467 | KNN Loss: 3.5920448303222656 | CLS Loss: 0.029869763180613518\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 3.7086398601531982 | KNN Loss: 3.674675464630127 | CLS Loss: 0.03396446257829666\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 3.667912721633911 | KNN Loss: 3.638427257537842 | CLS Loss: 0.029485421255230904\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 3.599910259246826 | KNN Loss: 3.5637929439544678 | CLS Loss: 0.03611738234758377\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 3.6126692295074463 | KNN Loss: 3.5935659408569336 | CLS Loss: 0.019103333353996277\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 3.6042771339416504 | KNN Loss: 3.5885777473449707 | CLS Loss: 0.015699436888098717\n",
      "Epoch: 044, Loss: 3.6352, Train: 0.9917, Valid: 0.9839, Best: 0.9850\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 3.647864580154419 | KNN Loss: 3.6169424057006836 | CLS Loss: 0.03092222660779953\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 3.634974956512451 | KNN Loss: 3.6232657432556152 | CLS Loss: 0.011709288693964481\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 3.6233978271484375 | KNN Loss: 3.5902116298675537 | CLS Loss: 0.03318627551198006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 3.672511577606201 | KNN Loss: 3.6472835540771484 | CLS Loss: 0.02522796392440796\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 3.6237564086914062 | KNN Loss: 3.585114002227783 | CLS Loss: 0.03864250332117081\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 3.6537187099456787 | KNN Loss: 3.617685079574585 | CLS Loss: 0.03603354096412659\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 3.6815381050109863 | KNN Loss: 3.640855312347412 | CLS Loss: 0.04068271815776825\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 3.6332342624664307 | KNN Loss: 3.6071860790252686 | CLS Loss: 0.02604827843606472\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 3.597831964492798 | KNN Loss: 3.568232536315918 | CLS Loss: 0.029599417001008987\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 3.58534836769104 | KNN Loss: 3.564540147781372 | CLS Loss: 0.020808208733797073\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 3.6304054260253906 | KNN Loss: 3.618264675140381 | CLS Loss: 0.012140728533267975\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 3.6336777210235596 | KNN Loss: 3.563263416290283 | CLS Loss: 0.07041434198617935\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 3.6097605228424072 | KNN Loss: 3.58469557762146 | CLS Loss: 0.025065062567591667\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 3.631336212158203 | KNN Loss: 3.597815752029419 | CLS Loss: 0.033520545810461044\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 3.570204973220825 | KNN Loss: 3.542746067047119 | CLS Loss: 0.02745886892080307\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 3.6144793033599854 | KNN Loss: 3.5761632919311523 | CLS Loss: 0.03831595182418823\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 3.6300816535949707 | KNN Loss: 3.581051826477051 | CLS Loss: 0.049029771238565445\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 3.6017649173736572 | KNN Loss: 3.565922737121582 | CLS Loss: 0.03584213927388191\n",
      "Epoch: 045, Loss: 3.6349, Train: 0.9923, Valid: 0.9858, Best: 0.9858\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 3.594012498855591 | KNN Loss: 3.55621075630188 | CLS Loss: 0.037801846861839294\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 3.5988240242004395 | KNN Loss: 3.5853285789489746 | CLS Loss: 0.013495518825948238\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 3.6114301681518555 | KNN Loss: 3.5543837547302246 | CLS Loss: 0.05704643204808235\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 3.6110780239105225 | KNN Loss: 3.57719349861145 | CLS Loss: 0.033884547650814056\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 3.6183724403381348 | KNN Loss: 3.596508741378784 | CLS Loss: 0.021863652393221855\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 3.6175220012664795 | KNN Loss: 3.612703561782837 | CLS Loss: 0.004818453919142485\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 3.6396987438201904 | KNN Loss: 3.617143154144287 | CLS Loss: 0.022555524483323097\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 3.648930549621582 | KNN Loss: 3.6057634353637695 | CLS Loss: 0.04316718131303787\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 3.6536409854888916 | KNN Loss: 3.6050918102264404 | CLS Loss: 0.04854918271303177\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 3.604788064956665 | KNN Loss: 3.5822932720184326 | CLS Loss: 0.022494908422231674\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 3.652132034301758 | KNN Loss: 3.622789144515991 | CLS Loss: 0.029342984780669212\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 3.648120880126953 | KNN Loss: 3.6259312629699707 | CLS Loss: 0.022189704701304436\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 3.623410224914551 | KNN Loss: 3.5823349952697754 | CLS Loss: 0.04107515513896942\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 3.607436418533325 | KNN Loss: 3.5929172039031982 | CLS Loss: 0.01451928075402975\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 3.6162312030792236 | KNN Loss: 3.592074394226074 | CLS Loss: 0.02415669895708561\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 3.5711634159088135 | KNN Loss: 3.546860933303833 | CLS Loss: 0.024302370846271515\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 3.6372005939483643 | KNN Loss: 3.586822271347046 | CLS Loss: 0.05037835240364075\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 3.639531135559082 | KNN Loss: 3.5997283458709717 | CLS Loss: 0.0398029088973999\n",
      "Epoch: 046, Loss: 3.6271, Train: 0.9892, Valid: 0.9831, Best: 0.9858\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 3.626925230026245 | KNN Loss: 3.603135585784912 | CLS Loss: 0.02378969080746174\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 3.642500638961792 | KNN Loss: 3.613158941268921 | CLS Loss: 0.02934163063764572\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 3.6478259563446045 | KNN Loss: 3.6335301399230957 | CLS Loss: 0.014295739121735096\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 3.6546809673309326 | KNN Loss: 3.639833688735962 | CLS Loss: 0.014847295358777046\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 3.621528387069702 | KNN Loss: 3.5755763053894043 | CLS Loss: 0.045951973646879196\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 3.627687692642212 | KNN Loss: 3.598583698272705 | CLS Loss: 0.029103953391313553\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 3.5890398025512695 | KNN Loss: 3.5504558086395264 | CLS Loss: 0.03858405724167824\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 3.633019208908081 | KNN Loss: 3.5864102840423584 | CLS Loss: 0.04660892114043236\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 3.667431592941284 | KNN Loss: 3.638437032699585 | CLS Loss: 0.028994474560022354\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 3.610718250274658 | KNN Loss: 3.5897955894470215 | CLS Loss: 0.020922565832734108\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 3.5957539081573486 | KNN Loss: 3.5666604042053223 | CLS Loss: 0.029093461111187935\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 3.6492607593536377 | KNN Loss: 3.6217575073242188 | CLS Loss: 0.027503343299031258\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 3.60494065284729 | KNN Loss: 3.581362009048462 | CLS Loss: 0.023578569293022156\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 3.6246337890625 | KNN Loss: 3.6105825901031494 | CLS Loss: 0.014051300473511219\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 3.6014153957366943 | KNN Loss: 3.5564932823181152 | CLS Loss: 0.04492199793457985\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 3.627480983734131 | KNN Loss: 3.604686737060547 | CLS Loss: 0.022794226184487343\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 3.6150076389312744 | KNN Loss: 3.59725284576416 | CLS Loss: 0.01775471121072769\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 3.644775390625 | KNN Loss: 3.5962438583374023 | CLS Loss: 0.04853144288063049\n",
      "Epoch: 047, Loss: 3.6266, Train: 0.9918, Valid: 0.9839, Best: 0.9858\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 3.600808620452881 | KNN Loss: 3.573406219482422 | CLS Loss: 0.027402464300394058\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 3.6474311351776123 | KNN Loss: 3.6200263500213623 | CLS Loss: 0.027404705062508583\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 3.6180295944213867 | KNN Loss: 3.58406662940979 | CLS Loss: 0.0339629203081131\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 3.5806708335876465 | KNN Loss: 3.560633420944214 | CLS Loss: 0.020037297159433365\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 3.6513750553131104 | KNN Loss: 3.6257808208465576 | CLS Loss: 0.025594349950551987\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 3.6007509231567383 | KNN Loss: 3.576214075088501 | CLS Loss: 0.024536849930882454\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 3.6310715675354004 | KNN Loss: 3.592041254043579 | CLS Loss: 0.039030373096466064\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 3.66371488571167 | KNN Loss: 3.6376962661743164 | CLS Loss: 0.026018725708127022\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 3.6034300327301025 | KNN Loss: 3.571500778198242 | CLS Loss: 0.03192925825715065\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 3.6121537685394287 | KNN Loss: 3.551309823989868 | CLS Loss: 0.060843903571367264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 3.6072285175323486 | KNN Loss: 3.5588467121124268 | CLS Loss: 0.04838176444172859\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 3.626706600189209 | KNN Loss: 3.5956313610076904 | CLS Loss: 0.031075267121195793\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 3.610544443130493 | KNN Loss: 3.5900862216949463 | CLS Loss: 0.020458189770579338\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 3.641087055206299 | KNN Loss: 3.5824134349823 | CLS Loss: 0.05867372080683708\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 3.593996286392212 | KNN Loss: 3.5709331035614014 | CLS Loss: 0.023063167929649353\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 3.5676443576812744 | KNN Loss: 3.5578088760375977 | CLS Loss: 0.009835569187998772\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 3.625774383544922 | KNN Loss: 3.592315196990967 | CLS Loss: 0.033459294587373734\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 3.6116888523101807 | KNN Loss: 3.601877212524414 | CLS Loss: 0.009811708703637123\n",
      "Epoch: 048, Loss: 3.6300, Train: 0.9928, Valid: 0.9853, Best: 0.9858\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 3.5925939083099365 | KNN Loss: 3.5656814575195312 | CLS Loss: 0.026912527158856392\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 3.6054224967956543 | KNN Loss: 3.5766870975494385 | CLS Loss: 0.02873542532324791\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 3.63631534576416 | KNN Loss: 3.6227900981903076 | CLS Loss: 0.013525251299142838\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 3.600459098815918 | KNN Loss: 3.5941336154937744 | CLS Loss: 0.006325527094304562\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 3.620936870574951 | KNN Loss: 3.5995638370513916 | CLS Loss: 0.02137291431427002\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 3.6003835201263428 | KNN Loss: 3.585376739501953 | CLS Loss: 0.015006701461970806\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 3.7101168632507324 | KNN Loss: 3.6754515171051025 | CLS Loss: 0.03466542810201645\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 3.63346266746521 | KNN Loss: 3.6202499866485596 | CLS Loss: 0.013212727382779121\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 3.57908296585083 | KNN Loss: 3.5651514530181885 | CLS Loss: 0.013931597582995892\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 3.6053569316864014 | KNN Loss: 3.596876382827759 | CLS Loss: 0.00848053302615881\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 3.6167044639587402 | KNN Loss: 3.5803725719451904 | CLS Loss: 0.03633184731006622\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 3.6416780948638916 | KNN Loss: 3.602121591567993 | CLS Loss: 0.03955661877989769\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 3.6462481021881104 | KNN Loss: 3.5956778526306152 | CLS Loss: 0.050570208579301834\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 3.6191182136535645 | KNN Loss: 3.5993661880493164 | CLS Loss: 0.019751979038119316\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 3.6085076332092285 | KNN Loss: 3.581958293914795 | CLS Loss: 0.026549413800239563\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 3.6372759342193604 | KNN Loss: 3.6131973266601562 | CLS Loss: 0.024078600108623505\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 3.613081932067871 | KNN Loss: 3.5771732330322266 | CLS Loss: 0.03590875118970871\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 3.6399879455566406 | KNN Loss: 3.6183464527130127 | CLS Loss: 0.021641410887241364\n",
      "Epoch: 049, Loss: 3.6284, Train: 0.9932, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 3.629214286804199 | KNN Loss: 3.602309226989746 | CLS Loss: 0.02690514177083969\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 3.587582588195801 | KNN Loss: 3.5742714405059814 | CLS Loss: 0.013311152346432209\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 3.6054677963256836 | KNN Loss: 3.587996244430542 | CLS Loss: 0.01747160032391548\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 3.5855138301849365 | KNN Loss: 3.5799686908721924 | CLS Loss: 0.005545062944293022\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 3.6007730960845947 | KNN Loss: 3.589552164077759 | CLS Loss: 0.011221031658351421\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 3.616551637649536 | KNN Loss: 3.557910919189453 | CLS Loss: 0.05864070728421211\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 3.6230669021606445 | KNN Loss: 3.5770061016082764 | CLS Loss: 0.0460607185959816\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 3.711610794067383 | KNN Loss: 3.666539192199707 | CLS Loss: 0.045071519911289215\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 3.6196115016937256 | KNN Loss: 3.5803611278533936 | CLS Loss: 0.03925033286213875\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 3.64652419090271 | KNN Loss: 3.6171061992645264 | CLS Loss: 0.029417965561151505\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 3.644655227661133 | KNN Loss: 3.6060118675231934 | CLS Loss: 0.03864327818155289\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 3.7172162532806396 | KNN Loss: 3.6868879795074463 | CLS Loss: 0.030328214168548584\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 3.675327777862549 | KNN Loss: 3.640321731567383 | CLS Loss: 0.035006050020456314\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 3.677201986312866 | KNN Loss: 3.6381068229675293 | CLS Loss: 0.039095159620046616\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 3.723353147506714 | KNN Loss: 3.6830813884735107 | CLS Loss: 0.04027171432971954\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 3.6652872562408447 | KNN Loss: 3.6307432651519775 | CLS Loss: 0.034544069319963455\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 3.674913167953491 | KNN Loss: 3.64805269241333 | CLS Loss: 0.026860538870096207\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 3.6243691444396973 | KNN Loss: 3.596200466156006 | CLS Loss: 0.02816862426698208\n",
      "Epoch: 050, Loss: 3.6353, Train: 0.9926, Valid: 0.9856, Best: 0.9860\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 3.6142356395721436 | KNN Loss: 3.5915560722351074 | CLS Loss: 0.02267950028181076\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 3.626157522201538 | KNN Loss: 3.577176094055176 | CLS Loss: 0.04898140951991081\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 3.659783363342285 | KNN Loss: 3.633606433868408 | CLS Loss: 0.026176948100328445\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 3.6472723484039307 | KNN Loss: 3.594273567199707 | CLS Loss: 0.05299878865480423\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 3.6965372562408447 | KNN Loss: 3.6541295051574707 | CLS Loss: 0.04240770265460014\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 3.6210570335388184 | KNN Loss: 3.5815587043762207 | CLS Loss: 0.03949831798672676\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 3.646228790283203 | KNN Loss: 3.6132774353027344 | CLS Loss: 0.03295125812292099\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 3.6081974506378174 | KNN Loss: 3.585486650466919 | CLS Loss: 0.022710762917995453\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 3.6479880809783936 | KNN Loss: 3.627412796020508 | CLS Loss: 0.02057528868317604\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 3.6128783226013184 | KNN Loss: 3.586045980453491 | CLS Loss: 0.02683239057660103\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 3.635427236557007 | KNN Loss: 3.6211633682250977 | CLS Loss: 0.014263899996876717\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 3.6020400524139404 | KNN Loss: 3.5923819541931152 | CLS Loss: 0.00965800043195486\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 3.6083078384399414 | KNN Loss: 3.585314989089966 | CLS Loss: 0.022992756217718124\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 3.6137049198150635 | KNN Loss: 3.595526695251465 | CLS Loss: 0.018178120255470276\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 3.598370313644409 | KNN Loss: 3.593395233154297 | CLS Loss: 0.004974978510290384\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 3.619239330291748 | KNN Loss: 3.590637683868408 | CLS Loss: 0.02860165201127529\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 3.6438937187194824 | KNN Loss: 3.6153125762939453 | CLS Loss: 0.028581151738762856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 3.6032204627990723 | KNN Loss: 3.5726003646850586 | CLS Loss: 0.030620137229561806\n",
      "Epoch: 051, Loss: 3.6266, Train: 0.9920, Valid: 0.9852, Best: 0.9860\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 3.613009214401245 | KNN Loss: 3.583034038543701 | CLS Loss: 0.02997509576380253\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 3.6173224449157715 | KNN Loss: 3.57765531539917 | CLS Loss: 0.03966708108782768\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 3.6434085369110107 | KNN Loss: 3.6217548847198486 | CLS Loss: 0.02165362238883972\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 3.6049838066101074 | KNN Loss: 3.5747838020324707 | CLS Loss: 0.03020007535815239\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 3.6127684116363525 | KNN Loss: 3.59572434425354 | CLS Loss: 0.017044078558683395\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 3.580366849899292 | KNN Loss: 3.5657854080200195 | CLS Loss: 0.014581328257918358\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 3.6198465824127197 | KNN Loss: 3.582292318344116 | CLS Loss: 0.037554264068603516\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 3.56938099861145 | KNN Loss: 3.5539188385009766 | CLS Loss: 0.015462061390280724\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 3.648806095123291 | KNN Loss: 3.608851194381714 | CLS Loss: 0.03995498642325401\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 3.63978910446167 | KNN Loss: 3.5826404094696045 | CLS Loss: 0.05714860558509827\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 3.5853841304779053 | KNN Loss: 3.5610995292663574 | CLS Loss: 0.024284565821290016\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 3.5957658290863037 | KNN Loss: 3.5876123905181885 | CLS Loss: 0.00815337523818016\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 3.621516227722168 | KNN Loss: 3.615410566329956 | CLS Loss: 0.006105633918195963\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 3.606027126312256 | KNN Loss: 3.5821692943573 | CLS Loss: 0.023857824504375458\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 3.6345913410186768 | KNN Loss: 3.621691942214966 | CLS Loss: 0.012899351306259632\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 3.618511199951172 | KNN Loss: 3.599238634109497 | CLS Loss: 0.019272468984127045\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 3.610511541366577 | KNN Loss: 3.586036205291748 | CLS Loss: 0.024475224316120148\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 3.607877492904663 | KNN Loss: 3.589627265930176 | CLS Loss: 0.018250130116939545\n",
      "Epoch: 052, Loss: 3.6277, Train: 0.9931, Valid: 0.9857, Best: 0.9860\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 3.5434367656707764 | KNN Loss: 3.5161519050598145 | CLS Loss: 0.027284977957606316\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 3.588343858718872 | KNN Loss: 3.540518283843994 | CLS Loss: 0.047825660556554794\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 3.610633134841919 | KNN Loss: 3.560257911682129 | CLS Loss: 0.050375260412693024\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 3.596318006515503 | KNN Loss: 3.5760459899902344 | CLS Loss: 0.02027212455868721\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 3.621630907058716 | KNN Loss: 3.5948774814605713 | CLS Loss: 0.026753386482596397\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 3.630410671234131 | KNN Loss: 3.6071629524230957 | CLS Loss: 0.02324768714606762\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 3.621238946914673 | KNN Loss: 3.597607135772705 | CLS Loss: 0.023631880059838295\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 3.5792152881622314 | KNN Loss: 3.5735185146331787 | CLS Loss: 0.005696866661310196\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 3.6579854488372803 | KNN Loss: 3.6379382610321045 | CLS Loss: 0.0200472641736269\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 3.596341848373413 | KNN Loss: 3.561288595199585 | CLS Loss: 0.03505320101976395\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 3.6709907054901123 | KNN Loss: 3.646697998046875 | CLS Loss: 0.02429273910820484\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 3.643960952758789 | KNN Loss: 3.6270530223846436 | CLS Loss: 0.016907919198274612\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 3.618875503540039 | KNN Loss: 3.59224534034729 | CLS Loss: 0.02663009986281395\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 3.648466110229492 | KNN Loss: 3.62126088142395 | CLS Loss: 0.027205199003219604\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 3.6813712120056152 | KNN Loss: 3.591810703277588 | CLS Loss: 0.0895606130361557\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 3.67350172996521 | KNN Loss: 3.6172635555267334 | CLS Loss: 0.056238286197185516\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 3.5943477153778076 | KNN Loss: 3.57292103767395 | CLS Loss: 0.0214267298579216\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 3.6268889904022217 | KNN Loss: 3.592188596725464 | CLS Loss: 0.034700386226177216\n",
      "Epoch: 053, Loss: 3.6208, Train: 0.9935, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 3.5943782329559326 | KNN Loss: 3.5651698112487793 | CLS Loss: 0.029208537191152573\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 3.6151466369628906 | KNN Loss: 3.589113473892212 | CLS Loss: 0.02603314444422722\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 3.577254056930542 | KNN Loss: 3.5277931690216064 | CLS Loss: 0.049460917711257935\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 3.5688419342041016 | KNN Loss: 3.5615673065185547 | CLS Loss: 0.007274651434272528\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 3.605013608932495 | KNN Loss: 3.5965323448181152 | CLS Loss: 0.00848137866705656\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 3.62699556350708 | KNN Loss: 3.5995841026306152 | CLS Loss: 0.027411509305238724\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 3.6108150482177734 | KNN Loss: 3.5771119594573975 | CLS Loss: 0.033703092485666275\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 3.620802640914917 | KNN Loss: 3.6005680561065674 | CLS Loss: 0.020234573632478714\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 3.6103570461273193 | KNN Loss: 3.590711832046509 | CLS Loss: 0.019645264372229576\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 3.605146646499634 | KNN Loss: 3.5783939361572266 | CLS Loss: 0.02675282023847103\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 3.6732637882232666 | KNN Loss: 3.6515114307403564 | CLS Loss: 0.021752336993813515\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 3.6331307888031006 | KNN Loss: 3.604367256164551 | CLS Loss: 0.028763508424162865\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 3.6183197498321533 | KNN Loss: 3.5962164402008057 | CLS Loss: 0.022103339433670044\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 3.6420071125030518 | KNN Loss: 3.5852713584899902 | CLS Loss: 0.056735653430223465\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 3.5676281452178955 | KNN Loss: 3.555781364440918 | CLS Loss: 0.01184688787907362\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 3.59399676322937 | KNN Loss: 3.5523812770843506 | CLS Loss: 0.041615501046180725\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 3.6181223392486572 | KNN Loss: 3.5916833877563477 | CLS Loss: 0.026438839733600616\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 3.6178805828094482 | KNN Loss: 3.583934783935547 | CLS Loss: 0.03394569829106331\n",
      "Epoch: 054, Loss: 3.6214, Train: 0.9926, Valid: 0.9858, Best: 0.9861\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 3.653090238571167 | KNN Loss: 3.6210927963256836 | CLS Loss: 0.03199740871787071\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 3.6097512245178223 | KNN Loss: 3.5652804374694824 | CLS Loss: 0.044470712542533875\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 3.640092134475708 | KNN Loss: 3.59525728225708 | CLS Loss: 0.04483482614159584\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 3.6593432426452637 | KNN Loss: 3.6460118293762207 | CLS Loss: 0.013331295922398567\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 3.6804754734039307 | KNN Loss: 3.6262621879577637 | CLS Loss: 0.05421319976449013\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 3.6064608097076416 | KNN Loss: 3.5960466861724854 | CLS Loss: 0.010414204560220242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 3.6295175552368164 | KNN Loss: 3.593012809753418 | CLS Loss: 0.036504726856946945\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 3.632831573486328 | KNN Loss: 3.596482992172241 | CLS Loss: 0.03634863346815109\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 3.5897128582000732 | KNN Loss: 3.57761812210083 | CLS Loss: 0.012094796635210514\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 3.6397511959075928 | KNN Loss: 3.6111011505126953 | CLS Loss: 0.028650090098381042\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 3.6083717346191406 | KNN Loss: 3.5765533447265625 | CLS Loss: 0.031818389892578125\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 3.624729633331299 | KNN Loss: 3.599191904067993 | CLS Loss: 0.02553783357143402\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 3.656813144683838 | KNN Loss: 3.6471805572509766 | CLS Loss: 0.009632624685764313\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 3.5841877460479736 | KNN Loss: 3.543743133544922 | CLS Loss: 0.040444664657115936\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 3.626276731491089 | KNN Loss: 3.5726935863494873 | CLS Loss: 0.05358311906456947\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 3.6012513637542725 | KNN Loss: 3.576319932937622 | CLS Loss: 0.024931402876973152\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 3.7008674144744873 | KNN Loss: 3.663482904434204 | CLS Loss: 0.0373845249414444\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 3.5953457355499268 | KNN Loss: 3.5543758869171143 | CLS Loss: 0.04096990078687668\n",
      "Epoch: 055, Loss: 3.6248, Train: 0.9934, Valid: 0.9856, Best: 0.9861\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 3.5643653869628906 | KNN Loss: 3.5490453243255615 | CLS Loss: 0.015320061706006527\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 3.614687204360962 | KNN Loss: 3.600944757461548 | CLS Loss: 0.013742390088737011\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 3.685697078704834 | KNN Loss: 3.634833812713623 | CLS Loss: 0.05086334049701691\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 3.5738916397094727 | KNN Loss: 3.564213752746582 | CLS Loss: 0.009677842259407043\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 3.6171650886535645 | KNN Loss: 3.6112821102142334 | CLS Loss: 0.005882889032363892\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 3.545128107070923 | KNN Loss: 3.536735773086548 | CLS Loss: 0.008392270654439926\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 3.65238094329834 | KNN Loss: 3.6003835201263428 | CLS Loss: 0.05199749022722244\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 3.6298882961273193 | KNN Loss: 3.6070406436920166 | CLS Loss: 0.022847553715109825\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 3.6617560386657715 | KNN Loss: 3.6312124729156494 | CLS Loss: 0.03054351732134819\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 3.6024420261383057 | KNN Loss: 3.58707857131958 | CLS Loss: 0.015363423153758049\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 3.6344854831695557 | KNN Loss: 3.5899524688720703 | CLS Loss: 0.04453311860561371\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 3.5710248947143555 | KNN Loss: 3.561694383621216 | CLS Loss: 0.00933050736784935\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 3.763810634613037 | KNN Loss: 3.7124545574188232 | CLS Loss: 0.051355991512537\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 3.6014461517333984 | KNN Loss: 3.569499969482422 | CLS Loss: 0.03194624185562134\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 3.689539670944214 | KNN Loss: 3.627286434173584 | CLS Loss: 0.06225331127643585\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 3.6139111518859863 | KNN Loss: 3.575809955596924 | CLS Loss: 0.03810129314661026\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 3.663313627243042 | KNN Loss: 3.650629997253418 | CLS Loss: 0.012683719396591187\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 3.6483113765716553 | KNN Loss: 3.620279550552368 | CLS Loss: 0.02803187072277069\n",
      "Epoch: 056, Loss: 3.6216, Train: 0.9945, Valid: 0.9865, Best: 0.9865\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 3.615286111831665 | KNN Loss: 3.6105546951293945 | CLS Loss: 0.004731465131044388\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 3.650932550430298 | KNN Loss: 3.633094310760498 | CLS Loss: 0.01783834770321846\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 3.638882875442505 | KNN Loss: 3.611602306365967 | CLS Loss: 0.02728063426911831\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 3.6618528366088867 | KNN Loss: 3.64420485496521 | CLS Loss: 0.01764795370399952\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 3.6075403690338135 | KNN Loss: 3.5844857692718506 | CLS Loss: 0.023054571822285652\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 3.6283392906188965 | KNN Loss: 3.6004295349121094 | CLS Loss: 0.027909796684980392\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 3.679265022277832 | KNN Loss: 3.6521172523498535 | CLS Loss: 0.027147723361849785\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 3.6373744010925293 | KNN Loss: 3.624561309814453 | CLS Loss: 0.012813185341656208\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 3.603240728378296 | KNN Loss: 3.584023952484131 | CLS Loss: 0.019216859713196754\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 3.6140990257263184 | KNN Loss: 3.587080478668213 | CLS Loss: 0.02701857127249241\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 3.6016364097595215 | KNN Loss: 3.5768463611602783 | CLS Loss: 0.024790139868855476\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 3.627767562866211 | KNN Loss: 3.60800838470459 | CLS Loss: 0.019759098067879677\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 3.6352057456970215 | KNN Loss: 3.619777202606201 | CLS Loss: 0.015428469516336918\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 3.6424667835235596 | KNN Loss: 3.6297731399536133 | CLS Loss: 0.012693628668785095\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 3.6235196590423584 | KNN Loss: 3.5887088775634766 | CLS Loss: 0.03481085225939751\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 3.611213207244873 | KNN Loss: 3.597583770751953 | CLS Loss: 0.0136294886469841\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 3.668102502822876 | KNN Loss: 3.6147518157958984 | CLS Loss: 0.053350675851106644\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 3.600755453109741 | KNN Loss: 3.5822205543518066 | CLS Loss: 0.01853497512638569\n",
      "Epoch: 057, Loss: 3.6237, Train: 0.9913, Valid: 0.9831, Best: 0.9865\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 3.635329484939575 | KNN Loss: 3.6030147075653076 | CLS Loss: 0.032314661890268326\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 3.6131317615509033 | KNN Loss: 3.576301336288452 | CLS Loss: 0.036830440163612366\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 3.6022448539733887 | KNN Loss: 3.553640365600586 | CLS Loss: 0.04860444739460945\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 3.586650848388672 | KNN Loss: 3.571226119995117 | CLS Loss: 0.015424665063619614\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 3.640705108642578 | KNN Loss: 3.6253774166107178 | CLS Loss: 0.01532770972698927\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 3.647162914276123 | KNN Loss: 3.632023334503174 | CLS Loss: 0.015139460563659668\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 3.6316747665405273 | KNN Loss: 3.5982789993286133 | CLS Loss: 0.03339588642120361\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 3.6029138565063477 | KNN Loss: 3.5802581310272217 | CLS Loss: 0.022655723616480827\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 3.6093826293945312 | KNN Loss: 3.5965311527252197 | CLS Loss: 0.012851583771407604\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 3.5804390907287598 | KNN Loss: 3.5542991161346436 | CLS Loss: 0.02614002116024494\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 3.656550168991089 | KNN Loss: 3.6178267002105713 | CLS Loss: 0.038723383098840714\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 3.6084065437316895 | KNN Loss: 3.5810906887054443 | CLS Loss: 0.027315907180309296\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 3.674893617630005 | KNN Loss: 3.628051280975342 | CLS Loss: 0.04684225842356682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 3.630267381668091 | KNN Loss: 3.6204400062561035 | CLS Loss: 0.009827465750277042\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 3.5875704288482666 | KNN Loss: 3.5773775577545166 | CLS Loss: 0.010192761197686195\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 3.6248230934143066 | KNN Loss: 3.606240749359131 | CLS Loss: 0.018582366406917572\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 3.5821385383605957 | KNN Loss: 3.5691964626312256 | CLS Loss: 0.012941958382725716\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 3.61069917678833 | KNN Loss: 3.595754623413086 | CLS Loss: 0.014944599941372871\n",
      "Epoch: 058, Loss: 3.6247, Train: 0.9931, Valid: 0.9860, Best: 0.9865\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 3.642448902130127 | KNN Loss: 3.619199275970459 | CLS Loss: 0.02324952557682991\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 3.6042840480804443 | KNN Loss: 3.559816598892212 | CLS Loss: 0.04446745663881302\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 3.61568546295166 | KNN Loss: 3.593721628189087 | CLS Loss: 0.02196374721825123\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 3.7156553268432617 | KNN Loss: 3.6967430114746094 | CLS Loss: 0.018912404775619507\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 3.6451170444488525 | KNN Loss: 3.6223700046539307 | CLS Loss: 0.02274709939956665\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 3.5754599571228027 | KNN Loss: 3.5541539192199707 | CLS Loss: 0.021306132897734642\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 3.611562490463257 | KNN Loss: 3.584463119506836 | CLS Loss: 0.027099471539258957\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 3.64729642868042 | KNN Loss: 3.6321609020233154 | CLS Loss: 0.01513545960187912\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 3.6159491539001465 | KNN Loss: 3.5950522422790527 | CLS Loss: 0.020896881818771362\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 3.6990180015563965 | KNN Loss: 3.645533323287964 | CLS Loss: 0.05348468944430351\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 3.6470539569854736 | KNN Loss: 3.61092472076416 | CLS Loss: 0.0361291877925396\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 3.5931198596954346 | KNN Loss: 3.5619025230407715 | CLS Loss: 0.031217452138662338\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 3.6724853515625 | KNN Loss: 3.66302490234375 | CLS Loss: 0.009460341185331345\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 3.634054183959961 | KNN Loss: 3.597640037536621 | CLS Loss: 0.036414165049791336\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 3.664414882659912 | KNN Loss: 3.636535167694092 | CLS Loss: 0.027879634872078896\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 3.6072797775268555 | KNN Loss: 3.5836009979248047 | CLS Loss: 0.023678816854953766\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 3.644613742828369 | KNN Loss: 3.63584303855896 | CLS Loss: 0.008770672604441643\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 3.676640033721924 | KNN Loss: 3.640298366546631 | CLS Loss: 0.036341629922389984\n",
      "Epoch: 059, Loss: 3.6213, Train: 0.9943, Valid: 0.9865, Best: 0.9865\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 3.586379289627075 | KNN Loss: 3.56382155418396 | CLS Loss: 0.022557664662599564\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 3.589787244796753 | KNN Loss: 3.5812885761260986 | CLS Loss: 0.008498553186655045\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 3.595818042755127 | KNN Loss: 3.5791823863983154 | CLS Loss: 0.01663575880229473\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 3.6461029052734375 | KNN Loss: 3.633812189102173 | CLS Loss: 0.01229076273739338\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 3.6448862552642822 | KNN Loss: 3.6355204582214355 | CLS Loss: 0.009365788660943508\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 3.593534469604492 | KNN Loss: 3.566175937652588 | CLS Loss: 0.02735855244100094\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 3.623464584350586 | KNN Loss: 3.6103551387786865 | CLS Loss: 0.013109522871673107\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 3.6155717372894287 | KNN Loss: 3.572251796722412 | CLS Loss: 0.043320007622241974\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 3.616425037384033 | KNN Loss: 3.574061155319214 | CLS Loss: 0.04236388951539993\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 3.6188247203826904 | KNN Loss: 3.5808651447296143 | CLS Loss: 0.03795962780714035\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 3.5907914638519287 | KNN Loss: 3.579404354095459 | CLS Loss: 0.011387011036276817\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 3.650514841079712 | KNN Loss: 3.6350440979003906 | CLS Loss: 0.015470646321773529\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 3.5814056396484375 | KNN Loss: 3.5675625801086426 | CLS Loss: 0.013842959888279438\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 3.590590476989746 | KNN Loss: 3.580266237258911 | CLS Loss: 0.010324250906705856\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 3.61494517326355 | KNN Loss: 3.5981626510620117 | CLS Loss: 0.016782589256763458\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 3.5973763465881348 | KNN Loss: 3.58557391166687 | CLS Loss: 0.011802404187619686\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 3.605177879333496 | KNN Loss: 3.575371265411377 | CLS Loss: 0.02980664372444153\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 3.639666795730591 | KNN Loss: 3.595449209213257 | CLS Loss: 0.04421747848391533\n",
      "Epoch: 060, Loss: 3.6167, Train: 0.9931, Valid: 0.9836, Best: 0.9865\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 3.6002259254455566 | KNN Loss: 3.5797948837280273 | CLS Loss: 0.02043108642101288\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 3.6900129318237305 | KNN Loss: 3.651068925857544 | CLS Loss: 0.03894411399960518\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 3.649165391921997 | KNN Loss: 3.633748769760132 | CLS Loss: 0.015416685491800308\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 3.6436245441436768 | KNN Loss: 3.631950616836548 | CLS Loss: 0.011674032546579838\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 3.6699471473693848 | KNN Loss: 3.650254249572754 | CLS Loss: 0.019692949950695038\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 3.669459581375122 | KNN Loss: 3.6184771060943604 | CLS Loss: 0.05098247528076172\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 3.6811184883117676 | KNN Loss: 3.667430877685547 | CLS Loss: 0.013687612488865852\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 3.6551942825317383 | KNN Loss: 3.630849599838257 | CLS Loss: 0.024344662204384804\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 3.6242427825927734 | KNN Loss: 3.6032838821411133 | CLS Loss: 0.020958982408046722\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 3.6345977783203125 | KNN Loss: 3.6181607246398926 | CLS Loss: 0.01643712818622589\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 3.7054271697998047 | KNN Loss: 3.6576545238494873 | CLS Loss: 0.04777253046631813\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 3.581400156021118 | KNN Loss: 3.5696451663970947 | CLS Loss: 0.011755031533539295\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 3.6184744834899902 | KNN Loss: 3.5913350582122803 | CLS Loss: 0.027139510959386826\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 3.56978178024292 | KNN Loss: 3.54758358001709 | CLS Loss: 0.022198112681508064\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 3.565377950668335 | KNN Loss: 3.54441499710083 | CLS Loss: 0.020962925627827644\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 3.6386053562164307 | KNN Loss: 3.6051652431488037 | CLS Loss: 0.03344003111124039\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 3.5917344093322754 | KNN Loss: 3.5842864513397217 | CLS Loss: 0.007448036223649979\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 3.6494369506835938 | KNN Loss: 3.6102514266967773 | CLS Loss: 0.03918555751442909\n",
      "Epoch: 061, Loss: 3.6257, Train: 0.9942, Valid: 0.9859, Best: 0.9865\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 3.6620495319366455 | KNN Loss: 3.645606279373169 | CLS Loss: 0.016443271189928055\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 3.587874412536621 | KNN Loss: 3.559152364730835 | CLS Loss: 0.028722131624817848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 3.637253761291504 | KNN Loss: 3.631664752960205 | CLS Loss: 0.00558896828442812\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 3.5965261459350586 | KNN Loss: 3.5670018196105957 | CLS Loss: 0.029524315148591995\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 3.673548460006714 | KNN Loss: 3.6577529907226562 | CLS Loss: 0.01579555869102478\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 3.6438748836517334 | KNN Loss: 3.636187791824341 | CLS Loss: 0.00768704991787672\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 3.607801675796509 | KNN Loss: 3.567981004714966 | CLS Loss: 0.0398206003010273\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 3.581993579864502 | KNN Loss: 3.574312686920166 | CLS Loss: 0.007680797018110752\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 3.646906852722168 | KNN Loss: 3.637376308441162 | CLS Loss: 0.009530573152005672\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 3.5848042964935303 | KNN Loss: 3.5721447467803955 | CLS Loss: 0.012659618631005287\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 3.6068356037139893 | KNN Loss: 3.5785067081451416 | CLS Loss: 0.028328804299235344\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 3.6403491497039795 | KNN Loss: 3.590318202972412 | CLS Loss: 0.05003094673156738\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 3.615480899810791 | KNN Loss: 3.585289716720581 | CLS Loss: 0.030191075056791306\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 3.629136800765991 | KNN Loss: 3.605848789215088 | CLS Loss: 0.02328789420425892\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 3.6054201126098633 | KNN Loss: 3.5862932205200195 | CLS Loss: 0.01912694424390793\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 3.5950634479522705 | KNN Loss: 3.582411050796509 | CLS Loss: 0.012652496807277203\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 3.6815848350524902 | KNN Loss: 3.6278209686279297 | CLS Loss: 0.05376392602920532\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 3.6201741695404053 | KNN Loss: 3.57021427154541 | CLS Loss: 0.049959924072027206\n",
      "Epoch: 062, Loss: 3.6238, Train: 0.9933, Valid: 0.9859, Best: 0.9865\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 3.59659481048584 | KNN Loss: 3.574747323989868 | CLS Loss: 0.021847596392035484\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 3.5741748809814453 | KNN Loss: 3.554623603820801 | CLS Loss: 0.019551336765289307\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 3.600160837173462 | KNN Loss: 3.5853991508483887 | CLS Loss: 0.014761626720428467\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 3.6151905059814453 | KNN Loss: 3.5863606929779053 | CLS Loss: 0.02882981486618519\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 3.620520830154419 | KNN Loss: 3.6125967502593994 | CLS Loss: 0.007924031466245651\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 3.6104776859283447 | KNN Loss: 3.589611053466797 | CLS Loss: 0.02086671255528927\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 3.593015193939209 | KNN Loss: 3.578695058822632 | CLS Loss: 0.014320041052997112\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 3.627126932144165 | KNN Loss: 3.5931427478790283 | CLS Loss: 0.03398424759507179\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 3.62185001373291 | KNN Loss: 3.5846500396728516 | CLS Loss: 0.03720005974173546\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 3.5991764068603516 | KNN Loss: 3.5581352710723877 | CLS Loss: 0.04104103520512581\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 3.6289610862731934 | KNN Loss: 3.6117541790008545 | CLS Loss: 0.017206866294145584\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 3.6536478996276855 | KNN Loss: 3.6323137283325195 | CLS Loss: 0.02133427932858467\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 3.606614112854004 | KNN Loss: 3.574312686920166 | CLS Loss: 0.03230149671435356\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 3.6159908771514893 | KNN Loss: 3.581052303314209 | CLS Loss: 0.03493855148553848\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 3.650362253189087 | KNN Loss: 3.6094863414764404 | CLS Loss: 0.04087594151496887\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 3.5736958980560303 | KNN Loss: 3.5621137619018555 | CLS Loss: 0.011582085862755775\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 3.6079013347625732 | KNN Loss: 3.5819406509399414 | CLS Loss: 0.025960609316825867\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 3.665510416030884 | KNN Loss: 3.6118171215057373 | CLS Loss: 0.053693272173404694\n",
      "Epoch: 063, Loss: 3.6180, Train: 0.9948, Valid: 0.9864, Best: 0.9865\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 3.63204026222229 | KNN Loss: 3.621643543243408 | CLS Loss: 0.010396622121334076\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 3.616469144821167 | KNN Loss: 3.5942399501800537 | CLS Loss: 0.022229081019759178\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 3.5755107402801514 | KNN Loss: 3.5720973014831543 | CLS Loss: 0.0034134634770452976\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 3.5959622859954834 | KNN Loss: 3.5790910720825195 | CLS Loss: 0.01687111333012581\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 3.629279136657715 | KNN Loss: 3.612123489379883 | CLS Loss: 0.01715560257434845\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 3.647303581237793 | KNN Loss: 3.6398134231567383 | CLS Loss: 0.007490159012377262\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 3.595059394836426 | KNN Loss: 3.5756657123565674 | CLS Loss: 0.019393764436244965\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 3.5934200286865234 | KNN Loss: 3.5840232372283936 | CLS Loss: 0.00939673651009798\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 3.6113219261169434 | KNN Loss: 3.5702574253082275 | CLS Loss: 0.041064511984586716\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 3.6133480072021484 | KNN Loss: 3.595580577850342 | CLS Loss: 0.017767462879419327\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 3.610610008239746 | KNN Loss: 3.5905725955963135 | CLS Loss: 0.020037509500980377\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 3.5662848949432373 | KNN Loss: 3.561816930770874 | CLS Loss: 0.004467983264476061\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 3.6015467643737793 | KNN Loss: 3.5926852226257324 | CLS Loss: 0.008861444890499115\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 3.604512929916382 | KNN Loss: 3.58663272857666 | CLS Loss: 0.017880093306303024\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 3.599172830581665 | KNN Loss: 3.5664637088775635 | CLS Loss: 0.03270907700061798\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 3.61320161819458 | KNN Loss: 3.6011977195739746 | CLS Loss: 0.0120038827881217\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 3.6322546005249023 | KNN Loss: 3.5987601280212402 | CLS Loss: 0.03349445015192032\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 3.593958616256714 | KNN Loss: 3.58052659034729 | CLS Loss: 0.01343210507184267\n",
      "Epoch: 064, Loss: 3.6160, Train: 0.9946, Valid: 0.9852, Best: 0.9865\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 3.6201393604278564 | KNN Loss: 3.5763955116271973 | CLS Loss: 0.0437438040971756\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 3.5997085571289062 | KNN Loss: 3.5797510147094727 | CLS Loss: 0.019957544282078743\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 3.6792712211608887 | KNN Loss: 3.6471152305603027 | CLS Loss: 0.03215605765581131\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 3.604876756668091 | KNN Loss: 3.5965042114257812 | CLS Loss: 0.00837252289056778\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 3.6128201484680176 | KNN Loss: 3.585681676864624 | CLS Loss: 0.027138425037264824\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 3.612107992172241 | KNN Loss: 3.5777857303619385 | CLS Loss: 0.034322358667850494\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 3.6164064407348633 | KNN Loss: 3.5835838317871094 | CLS Loss: 0.032822564244270325\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 3.599980592727661 | KNN Loss: 3.5712778568267822 | CLS Loss: 0.02870265208184719\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 3.5903329849243164 | KNN Loss: 3.573248863220215 | CLS Loss: 0.01708412542939186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 3.6567087173461914 | KNN Loss: 3.6498827934265137 | CLS Loss: 0.006825863849371672\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 3.609076738357544 | KNN Loss: 3.5919992923736572 | CLS Loss: 0.017077390104532242\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 3.594413995742798 | KNN Loss: 3.565845489501953 | CLS Loss: 0.028568435460329056\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 3.665515661239624 | KNN Loss: 3.625492572784424 | CLS Loss: 0.04002310335636139\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 3.574702024459839 | KNN Loss: 3.562844753265381 | CLS Loss: 0.011857302859425545\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 3.5914602279663086 | KNN Loss: 3.5712389945983887 | CLS Loss: 0.020221326500177383\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 3.6661250591278076 | KNN Loss: 3.630819320678711 | CLS Loss: 0.035305704921483994\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 3.5855720043182373 | KNN Loss: 3.576005458831787 | CLS Loss: 0.009566454216837883\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 3.6133878231048584 | KNN Loss: 3.5771963596343994 | CLS Loss: 0.03619135171175003\n",
      "Epoch: 065, Loss: 3.6137, Train: 0.9942, Valid: 0.9857, Best: 0.9865\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 3.58996319770813 | KNN Loss: 3.5800797939300537 | CLS Loss: 0.009883362799882889\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 3.6421616077423096 | KNN Loss: 3.6098852157592773 | CLS Loss: 0.032276302576065063\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 3.6076250076293945 | KNN Loss: 3.5932583808898926 | CLS Loss: 0.014366574585437775\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 3.581153154373169 | KNN Loss: 3.567093849182129 | CLS Loss: 0.014059280976653099\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 3.5845234394073486 | KNN Loss: 3.5774455070495605 | CLS Loss: 0.0070778438821434975\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 3.640094041824341 | KNN Loss: 3.5930235385894775 | CLS Loss: 0.04707061126828194\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 3.638712167739868 | KNN Loss: 3.609172821044922 | CLS Loss: 0.029539357870817184\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 3.630985736846924 | KNN Loss: 3.6015586853027344 | CLS Loss: 0.029427066445350647\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 3.6327178478240967 | KNN Loss: 3.6168935298919678 | CLS Loss: 0.01582425646483898\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 3.6093082427978516 | KNN Loss: 3.5926051139831543 | CLS Loss: 0.016703233122825623\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 3.6322100162506104 | KNN Loss: 3.6147375106811523 | CLS Loss: 0.01747259870171547\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 3.635401964187622 | KNN Loss: 3.59836745262146 | CLS Loss: 0.03703441098332405\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 3.57947039604187 | KNN Loss: 3.569066286087036 | CLS Loss: 0.010404019616544247\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 3.6545634269714355 | KNN Loss: 3.634523868560791 | CLS Loss: 0.0200396366417408\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 3.6257805824279785 | KNN Loss: 3.5693604946136475 | CLS Loss: 0.05642000213265419\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 3.60302472114563 | KNN Loss: 3.5756707191467285 | CLS Loss: 0.027353985235095024\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 3.6323978900909424 | KNN Loss: 3.603210926055908 | CLS Loss: 0.029186967760324478\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 3.6346898078918457 | KNN Loss: 3.6080033779144287 | CLS Loss: 0.02668638899922371\n",
      "Epoch: 066, Loss: 3.6154, Train: 0.9946, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 3.6349143981933594 | KNN Loss: 3.5871880054473877 | CLS Loss: 0.0477263368666172\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 3.563701868057251 | KNN Loss: 3.5565664768218994 | CLS Loss: 0.007135491818189621\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 3.654448986053467 | KNN Loss: 3.6238458156585693 | CLS Loss: 0.030603140592575073\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 3.6083598136901855 | KNN Loss: 3.58817458152771 | CLS Loss: 0.02018534392118454\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 3.5660619735717773 | KNN Loss: 3.5559022426605225 | CLS Loss: 0.010159739293158054\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 3.57914400100708 | KNN Loss: 3.5747263431549072 | CLS Loss: 0.0044176047667860985\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 3.596827983856201 | KNN Loss: 3.5774497985839844 | CLS Loss: 0.019378235563635826\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 3.6578030586242676 | KNN Loss: 3.6335623264312744 | CLS Loss: 0.024240724742412567\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 3.5701286792755127 | KNN Loss: 3.5530357360839844 | CLS Loss: 0.01709289662539959\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 3.5683603286743164 | KNN Loss: 3.560706377029419 | CLS Loss: 0.0076539176516234875\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 3.6811628341674805 | KNN Loss: 3.643979549407959 | CLS Loss: 0.037183213979005814\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 3.668508768081665 | KNN Loss: 3.627652645111084 | CLS Loss: 0.04085609316825867\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 3.596627950668335 | KNN Loss: 3.562732458114624 | CLS Loss: 0.03389541804790497\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 3.641535758972168 | KNN Loss: 3.619105815887451 | CLS Loss: 0.022430002689361572\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 3.621915340423584 | KNN Loss: 3.5920310020446777 | CLS Loss: 0.029884301126003265\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 3.624631643295288 | KNN Loss: 3.5678064823150635 | CLS Loss: 0.056825123727321625\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 3.620424270629883 | KNN Loss: 3.5806069374084473 | CLS Loss: 0.039817407727241516\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 3.5737006664276123 | KNN Loss: 3.5676157474517822 | CLS Loss: 0.0060849180445075035\n",
      "Epoch: 067, Loss: 3.6111, Train: 0.9946, Valid: 0.9865, Best: 0.9866\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 3.5772783756256104 | KNN Loss: 3.554692029953003 | CLS Loss: 0.022586315870285034\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 3.5865895748138428 | KNN Loss: 3.5683624744415283 | CLS Loss: 0.018227117136120796\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 3.6302146911621094 | KNN Loss: 3.6188764572143555 | CLS Loss: 0.01133828517049551\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 3.6210970878601074 | KNN Loss: 3.5916249752044678 | CLS Loss: 0.029472196474671364\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 3.600365161895752 | KNN Loss: 3.574767589569092 | CLS Loss: 0.02559753879904747\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 3.626836061477661 | KNN Loss: 3.5938398838043213 | CLS Loss: 0.032996077090501785\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 3.6307239532470703 | KNN Loss: 3.5968565940856934 | CLS Loss: 0.03386731445789337\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 3.593816041946411 | KNN Loss: 3.565011739730835 | CLS Loss: 0.028804341331124306\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 3.6180806159973145 | KNN Loss: 3.598423480987549 | CLS Loss: 0.019657069817185402\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 3.5937740802764893 | KNN Loss: 3.58655047416687 | CLS Loss: 0.007223682943731546\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 3.5751967430114746 | KNN Loss: 3.562314748764038 | CLS Loss: 0.012881952337920666\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 3.6345574855804443 | KNN Loss: 3.612049102783203 | CLS Loss: 0.022508488968014717\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 3.61979603767395 | KNN Loss: 3.5999813079833984 | CLS Loss: 0.019814826548099518\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 3.6811907291412354 | KNN Loss: 3.655519962310791 | CLS Loss: 0.025670774281024933\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 3.651885986328125 | KNN Loss: 3.6291263103485107 | CLS Loss: 0.02275973930954933\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 3.652127504348755 | KNN Loss: 3.6411237716674805 | CLS Loss: 0.011003758758306503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 3.603968620300293 | KNN Loss: 3.5870862007141113 | CLS Loss: 0.01688249409198761\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 3.6074318885803223 | KNN Loss: 3.600886106491089 | CLS Loss: 0.006545674055814743\n",
      "Epoch: 068, Loss: 3.6204, Train: 0.9939, Valid: 0.9855, Best: 0.9866\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 3.542783498764038 | KNN Loss: 3.5305745601654053 | CLS Loss: 0.012208975851535797\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 3.607537031173706 | KNN Loss: 3.6018497943878174 | CLS Loss: 0.005687124561518431\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 3.631160020828247 | KNN Loss: 3.60326886177063 | CLS Loss: 0.027891084551811218\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 3.617069721221924 | KNN Loss: 3.5854134559631348 | CLS Loss: 0.031656187027692795\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 3.569350242614746 | KNN Loss: 3.5433928966522217 | CLS Loss: 0.025957411155104637\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 3.596595048904419 | KNN Loss: 3.5822622776031494 | CLS Loss: 0.014332885853946209\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 3.603308916091919 | KNN Loss: 3.5885841846466064 | CLS Loss: 0.014724764041602612\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 3.5839757919311523 | KNN Loss: 3.558753252029419 | CLS Loss: 0.0252226535230875\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 3.620882987976074 | KNN Loss: 3.5750820636749268 | CLS Loss: 0.04580084607005119\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 3.6319589614868164 | KNN Loss: 3.5770175457000732 | CLS Loss: 0.05494152382016182\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 3.5919976234436035 | KNN Loss: 3.567873954772949 | CLS Loss: 0.0241236574947834\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 3.6057894229888916 | KNN Loss: 3.5804684162139893 | CLS Loss: 0.025321118533611298\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 3.5845396518707275 | KNN Loss: 3.5619733333587646 | CLS Loss: 0.02256622724235058\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 3.575788974761963 | KNN Loss: 3.562624931335449 | CLS Loss: 0.013164052739739418\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 3.591533899307251 | KNN Loss: 3.5756847858428955 | CLS Loss: 0.015849027782678604\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 3.6411798000335693 | KNN Loss: 3.622748613357544 | CLS Loss: 0.018431203439831734\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 3.559899091720581 | KNN Loss: 3.540947914123535 | CLS Loss: 0.018951186910271645\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 3.621858835220337 | KNN Loss: 3.602574586868286 | CLS Loss: 0.019284356385469437\n",
      "Epoch: 069, Loss: 3.6115, Train: 0.9952, Valid: 0.9869, Best: 0.9869\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 3.5787432193756104 | KNN Loss: 3.5482513904571533 | CLS Loss: 0.03049190528690815\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 3.6142735481262207 | KNN Loss: 3.5976290702819824 | CLS Loss: 0.016644470393657684\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 3.6166486740112305 | KNN Loss: 3.5785939693450928 | CLS Loss: 0.03805460035800934\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 3.6154346466064453 | KNN Loss: 3.608041286468506 | CLS Loss: 0.007393408566713333\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 3.628413438796997 | KNN Loss: 3.6137468814849854 | CLS Loss: 0.01466666255146265\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 3.6180078983306885 | KNN Loss: 3.611278772354126 | CLS Loss: 0.006729193963110447\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 3.5975358486175537 | KNN Loss: 3.5753769874572754 | CLS Loss: 0.02215888351202011\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 3.608035087585449 | KNN Loss: 3.5892012119293213 | CLS Loss: 0.018833884969353676\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 3.639054775238037 | KNN Loss: 3.588876247406006 | CLS Loss: 0.05017847567796707\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 3.6355838775634766 | KNN Loss: 3.543712854385376 | CLS Loss: 0.09187113493680954\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 3.5985374450683594 | KNN Loss: 3.578572988510132 | CLS Loss: 0.01996440812945366\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 3.5696282386779785 | KNN Loss: 3.543311834335327 | CLS Loss: 0.02631642296910286\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 3.6156270503997803 | KNN Loss: 3.5602669715881348 | CLS Loss: 0.055360082536935806\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 3.644357204437256 | KNN Loss: 3.628932476043701 | CLS Loss: 0.01542474702000618\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 3.5874273777008057 | KNN Loss: 3.554705858230591 | CLS Loss: 0.03272153437137604\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 3.5852649211883545 | KNN Loss: 3.5669384002685547 | CLS Loss: 0.01832648552954197\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 3.6269795894622803 | KNN Loss: 3.580793619155884 | CLS Loss: 0.04618602618575096\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 3.5829904079437256 | KNN Loss: 3.563629388809204 | CLS Loss: 0.01936095580458641\n",
      "Epoch: 070, Loss: 3.6103, Train: 0.9959, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 3.590522050857544 | KNN Loss: 3.5782737731933594 | CLS Loss: 0.012248235754668713\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 3.597562074661255 | KNN Loss: 3.5497825145721436 | CLS Loss: 0.047779571264982224\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 3.584185838699341 | KNN Loss: 3.569265127182007 | CLS Loss: 0.014920610003173351\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 3.597139358520508 | KNN Loss: 3.591730833053589 | CLS Loss: 0.005408602766692638\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 3.6401259899139404 | KNN Loss: 3.5835163593292236 | CLS Loss: 0.05660954490303993\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 3.594569683074951 | KNN Loss: 3.584167242050171 | CLS Loss: 0.010402354411780834\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 3.672992706298828 | KNN Loss: 3.6609137058258057 | CLS Loss: 0.012079049833118916\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 3.575662851333618 | KNN Loss: 3.555312156677246 | CLS Loss: 0.020350607112050056\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 3.631725311279297 | KNN Loss: 3.6160826683044434 | CLS Loss: 0.015642624348402023\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 3.588557720184326 | KNN Loss: 3.5614800453186035 | CLS Loss: 0.02707771770656109\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 3.5965142250061035 | KNN Loss: 3.575655460357666 | CLS Loss: 0.020858822390437126\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 3.6540420055389404 | KNN Loss: 3.6140143871307373 | CLS Loss: 0.04002755507826805\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 3.5954315662384033 | KNN Loss: 3.584038019180298 | CLS Loss: 0.011393541470170021\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 3.5848159790039062 | KNN Loss: 3.576158285140991 | CLS Loss: 0.008657705038785934\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 3.607583999633789 | KNN Loss: 3.5973594188690186 | CLS Loss: 0.010224593803286552\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 3.662158966064453 | KNN Loss: 3.6136906147003174 | CLS Loss: 0.04846841096878052\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 3.711759090423584 | KNN Loss: 3.685995578765869 | CLS Loss: 0.02576342597603798\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 3.5958447456359863 | KNN Loss: 3.5762295722961426 | CLS Loss: 0.0196151752024889\n",
      "Epoch: 071, Loss: 3.6108, Train: 0.9948, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 3.6018905639648438 | KNN Loss: 3.5800399780273438 | CLS Loss: 0.021850626915693283\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 3.5938265323638916 | KNN Loss: 3.5867602825164795 | CLS Loss: 0.007066152989864349\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 3.613740921020508 | KNN Loss: 3.587268590927124 | CLS Loss: 0.02647225372493267\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 3.620884895324707 | KNN Loss: 3.597670078277588 | CLS Loss: 0.023214848712086678\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 3.5836541652679443 | KNN Loss: 3.5590455532073975 | CLS Loss: 0.02460862696170807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 3.595602035522461 | KNN Loss: 3.565916061401367 | CLS Loss: 0.02968592569231987\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 3.6294562816619873 | KNN Loss: 3.608227491378784 | CLS Loss: 0.021228674799203873\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 3.567329168319702 | KNN Loss: 3.559237480163574 | CLS Loss: 0.008091665804386139\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 3.6053998470306396 | KNN Loss: 3.5969083309173584 | CLS Loss: 0.008491543121635914\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 3.624803066253662 | KNN Loss: 3.6117005348205566 | CLS Loss: 0.013102540746331215\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 3.631629228591919 | KNN Loss: 3.6225013732910156 | CLS Loss: 0.00912792794406414\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 3.6003642082214355 | KNN Loss: 3.5710885524749756 | CLS Loss: 0.029275698587298393\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 3.6126856803894043 | KNN Loss: 3.6035940647125244 | CLS Loss: 0.009091547690331936\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 3.592036008834839 | KNN Loss: 3.5652859210968018 | CLS Loss: 0.0267499852925539\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 3.6386170387268066 | KNN Loss: 3.6095712184906006 | CLS Loss: 0.029045917093753815\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 3.6189937591552734 | KNN Loss: 3.5792059898376465 | CLS Loss: 0.039787713438272476\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 3.568779706954956 | KNN Loss: 3.5644283294677734 | CLS Loss: 0.00435129227116704\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 3.6089279651641846 | KNN Loss: 3.5527453422546387 | CLS Loss: 0.056182682514190674\n",
      "Epoch: 072, Loss: 3.6151, Train: 0.9938, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 3.5744950771331787 | KNN Loss: 3.5596587657928467 | CLS Loss: 0.014836277812719345\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 3.6911935806274414 | KNN Loss: 3.654420852661133 | CLS Loss: 0.036772772669792175\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 3.602837562561035 | KNN Loss: 3.5712172985076904 | CLS Loss: 0.031620144844055176\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 3.5957424640655518 | KNN Loss: 3.5867323875427246 | CLS Loss: 0.009010180830955505\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 3.601284980773926 | KNN Loss: 3.598637342453003 | CLS Loss: 0.0026477533392608166\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 3.599008798599243 | KNN Loss: 3.5734784603118896 | CLS Loss: 0.025530224665999413\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 3.614515542984009 | KNN Loss: 3.59948468208313 | CLS Loss: 0.01503097452223301\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 3.6731326580047607 | KNN Loss: 3.668771266937256 | CLS Loss: 0.004361298400908709\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 3.632937431335449 | KNN Loss: 3.6145200729370117 | CLS Loss: 0.01841738633811474\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 3.6008851528167725 | KNN Loss: 3.5910842418670654 | CLS Loss: 0.009800953790545464\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 3.6041934490203857 | KNN Loss: 3.57857346534729 | CLS Loss: 0.025620071217417717\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 3.5793802738189697 | KNN Loss: 3.562718629837036 | CLS Loss: 0.016661755740642548\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 3.602851390838623 | KNN Loss: 3.571672201156616 | CLS Loss: 0.031179115176200867\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 3.6876420974731445 | KNN Loss: 3.6308751106262207 | CLS Loss: 0.05676700174808502\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 3.5772740840911865 | KNN Loss: 3.5438477993011475 | CLS Loss: 0.033426232635974884\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 3.614530086517334 | KNN Loss: 3.606527328491211 | CLS Loss: 0.008002834394574165\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 3.588069438934326 | KNN Loss: 3.569082498550415 | CLS Loss: 0.018986888229846954\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 3.6372406482696533 | KNN Loss: 3.6333720684051514 | CLS Loss: 0.0038685102481395006\n",
      "Epoch: 073, Loss: 3.6125, Train: 0.9950, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 3.5993916988372803 | KNN Loss: 3.575338125228882 | CLS Loss: 0.024053510278463364\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 3.6304001808166504 | KNN Loss: 3.622857093811035 | CLS Loss: 0.007543098647147417\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 3.5702924728393555 | KNN Loss: 3.550438404083252 | CLS Loss: 0.01985401287674904\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 3.5868895053863525 | KNN Loss: 3.5642952919006348 | CLS Loss: 0.022594179958105087\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 3.615175247192383 | KNN Loss: 3.6044962406158447 | CLS Loss: 0.010678893886506557\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 3.606614112854004 | KNN Loss: 3.5820963382720947 | CLS Loss: 0.024517733603715897\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 3.589444398880005 | KNN Loss: 3.5635602474212646 | CLS Loss: 0.02588406391441822\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 3.5876805782318115 | KNN Loss: 3.5635716915130615 | CLS Loss: 0.024108823388814926\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 3.606790065765381 | KNN Loss: 3.596557140350342 | CLS Loss: 0.010232826694846153\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 3.6563773155212402 | KNN Loss: 3.6449148654937744 | CLS Loss: 0.011462364345788956\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 3.6318519115448 | KNN Loss: 3.6270158290863037 | CLS Loss: 0.004836093168705702\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 3.577641725540161 | KNN Loss: 3.5653223991394043 | CLS Loss: 0.012319247238337994\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 3.631211280822754 | KNN Loss: 3.6191365718841553 | CLS Loss: 0.012074770405888557\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 3.593747854232788 | KNN Loss: 3.586111068725586 | CLS Loss: 0.007636681664735079\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 3.608405828475952 | KNN Loss: 3.5664548873901367 | CLS Loss: 0.04195092245936394\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 3.651555061340332 | KNN Loss: 3.625758409500122 | CLS Loss: 0.025796590372920036\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 3.6143150329589844 | KNN Loss: 3.604794979095459 | CLS Loss: 0.009520171210169792\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 3.583163022994995 | KNN Loss: 3.5382680892944336 | CLS Loss: 0.044894907623529434\n",
      "Epoch: 074, Loss: 3.6066, Train: 0.9944, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 3.6021814346313477 | KNN Loss: 3.590898036956787 | CLS Loss: 0.011283346451818943\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 3.5979580879211426 | KNN Loss: 3.5834150314331055 | CLS Loss: 0.014543167315423489\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 3.597642660140991 | KNN Loss: 3.573437452316284 | CLS Loss: 0.02420528046786785\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 3.589846134185791 | KNN Loss: 3.574988842010498 | CLS Loss: 0.01485732477158308\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 3.6400856971740723 | KNN Loss: 3.6004014015197754 | CLS Loss: 0.03968435898423195\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 3.5804197788238525 | KNN Loss: 3.5726778507232666 | CLS Loss: 0.007742011919617653\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 3.615279197692871 | KNN Loss: 3.5798370838165283 | CLS Loss: 0.03544219583272934\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 3.5638883113861084 | KNN Loss: 3.5567872524261475 | CLS Loss: 0.007100950926542282\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 3.572453260421753 | KNN Loss: 3.537853717803955 | CLS Loss: 0.034599658101797104\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 3.626457929611206 | KNN Loss: 3.6102774143218994 | CLS Loss: 0.016180478036403656\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 3.5692315101623535 | KNN Loss: 3.5459678173065186 | CLS Loss: 0.02326361835002899\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 3.6594743728637695 | KNN Loss: 3.630831480026245 | CLS Loss: 0.028642794117331505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 3.588238000869751 | KNN Loss: 3.5727734565734863 | CLS Loss: 0.01546463929116726\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 3.618821620941162 | KNN Loss: 3.5987560749053955 | CLS Loss: 0.02006547339260578\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 3.615615129470825 | KNN Loss: 3.606846570968628 | CLS Loss: 0.008768527768552303\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 3.6212635040283203 | KNN Loss: 3.603041410446167 | CLS Loss: 0.01822216622531414\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 3.596771001815796 | KNN Loss: 3.5731301307678223 | CLS Loss: 0.023640954867005348\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 3.5844931602478027 | KNN Loss: 3.5729644298553467 | CLS Loss: 0.01152863260358572\n",
      "Epoch: 075, Loss: 3.6129, Train: 0.9935, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 3.5972414016723633 | KNN Loss: 3.5787317752838135 | CLS Loss: 0.018509624525904655\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 3.580399990081787 | KNN Loss: 3.56274151802063 | CLS Loss: 0.017658516764640808\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 3.682549476623535 | KNN Loss: 3.6708366870880127 | CLS Loss: 0.01171281561255455\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 3.576085329055786 | KNN Loss: 3.5599851608276367 | CLS Loss: 0.0161000844091177\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 3.5912108421325684 | KNN Loss: 3.5817153453826904 | CLS Loss: 0.009495576843619347\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 3.6459860801696777 | KNN Loss: 3.6316447257995605 | CLS Loss: 0.014341253787279129\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 3.642564058303833 | KNN Loss: 3.5890016555786133 | CLS Loss: 0.05356249585747719\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 3.6318421363830566 | KNN Loss: 3.6218838691711426 | CLS Loss: 0.009958175010979176\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 3.575716733932495 | KNN Loss: 3.5607659816741943 | CLS Loss: 0.01495072990655899\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 3.5776822566986084 | KNN Loss: 3.566500186920166 | CLS Loss: 0.011182148940861225\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 3.577208995819092 | KNN Loss: 3.5692930221557617 | CLS Loss: 0.007915991358458996\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 3.5740833282470703 | KNN Loss: 3.5635039806365967 | CLS Loss: 0.010579435154795647\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 3.552319049835205 | KNN Loss: 3.548158645629883 | CLS Loss: 0.004160476848483086\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 3.619159460067749 | KNN Loss: 3.581251859664917 | CLS Loss: 0.03790769726037979\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 3.5772705078125 | KNN Loss: 3.5430123805999756 | CLS Loss: 0.03425811976194382\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 3.606553316116333 | KNN Loss: 3.563964366912842 | CLS Loss: 0.04258904233574867\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 3.5776216983795166 | KNN Loss: 3.567460060119629 | CLS Loss: 0.010161724872887135\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 3.625865936279297 | KNN Loss: 3.6097540855407715 | CLS Loss: 0.016111945733428\n",
      "Epoch: 076, Loss: 3.6103, Train: 0.9953, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 3.5819461345672607 | KNN Loss: 3.563122510910034 | CLS Loss: 0.01882358454167843\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 3.575230121612549 | KNN Loss: 3.57135272026062 | CLS Loss: 0.0038773128762841225\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 3.609748125076294 | KNN Loss: 3.5856428146362305 | CLS Loss: 0.024105316027998924\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 3.581486225128174 | KNN Loss: 3.549273729324341 | CLS Loss: 0.03221239894628525\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 3.5987966060638428 | KNN Loss: 3.57558274269104 | CLS Loss: 0.023213747888803482\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 3.576537609100342 | KNN Loss: 3.5564815998077393 | CLS Loss: 0.020055975764989853\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 3.6227920055389404 | KNN Loss: 3.606145143508911 | CLS Loss: 0.01664688065648079\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 3.6173903942108154 | KNN Loss: 3.5917999744415283 | CLS Loss: 0.025590399280190468\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 3.600191116333008 | KNN Loss: 3.5918962955474854 | CLS Loss: 0.00829473789781332\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 3.577362298965454 | KNN Loss: 3.565516233444214 | CLS Loss: 0.011846015229821205\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 3.6183276176452637 | KNN Loss: 3.595538854598999 | CLS Loss: 0.02278883196413517\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 3.6245672702789307 | KNN Loss: 3.6019318103790283 | CLS Loss: 0.022635577246546745\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 3.600456476211548 | KNN Loss: 3.5782642364501953 | CLS Loss: 0.02219218946993351\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 3.657233715057373 | KNN Loss: 3.64107608795166 | CLS Loss: 0.016157617792487144\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 3.5868940353393555 | KNN Loss: 3.5739905834198 | CLS Loss: 0.012903556227684021\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 3.5867221355438232 | KNN Loss: 3.569965362548828 | CLS Loss: 0.016756728291511536\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 3.592726230621338 | KNN Loss: 3.5719821453094482 | CLS Loss: 0.020743975415825844\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 3.5854246616363525 | KNN Loss: 3.5768063068389893 | CLS Loss: 0.008618381805717945\n",
      "Epoch: 077, Loss: 3.6071, Train: 0.9948, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 3.6403844356536865 | KNN Loss: 3.6097495555877686 | CLS Loss: 0.03063480369746685\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 3.627194881439209 | KNN Loss: 3.5927627086639404 | CLS Loss: 0.03443219140172005\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 3.6369240283966064 | KNN Loss: 3.6235477924346924 | CLS Loss: 0.013376119546592236\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 3.5723860263824463 | KNN Loss: 3.5654730796813965 | CLS Loss: 0.006912990938872099\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 3.593775749206543 | KNN Loss: 3.5718472003936768 | CLS Loss: 0.02192847430706024\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 3.6333584785461426 | KNN Loss: 3.5937676429748535 | CLS Loss: 0.039590802043676376\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 3.6011416912078857 | KNN Loss: 3.588266134262085 | CLS Loss: 0.012875627726316452\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 3.663614273071289 | KNN Loss: 3.6505351066589355 | CLS Loss: 0.013079285621643066\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 3.64607310295105 | KNN Loss: 3.6275107860565186 | CLS Loss: 0.018562238663434982\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 3.572299003601074 | KNN Loss: 3.5547678470611572 | CLS Loss: 0.017531074583530426\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 3.607175827026367 | KNN Loss: 3.588829278945923 | CLS Loss: 0.018346622586250305\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 3.606335401535034 | KNN Loss: 3.6023006439208984 | CLS Loss: 0.004034794867038727\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 3.615342855453491 | KNN Loss: 3.611248016357422 | CLS Loss: 0.004094828851521015\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 3.5815787315368652 | KNN Loss: 3.5664865970611572 | CLS Loss: 0.015092204324901104\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 3.6145105361938477 | KNN Loss: 3.5920357704162598 | CLS Loss: 0.02247481606900692\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 3.54744029045105 | KNN Loss: 3.50140380859375 | CLS Loss: 0.04603651911020279\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 3.5873160362243652 | KNN Loss: 3.5794763565063477 | CLS Loss: 0.007839790545403957\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 3.633782386779785 | KNN Loss: 3.6110827922821045 | CLS Loss: 0.022699493914842606\n",
      "Epoch: 078, Loss: 3.6039, Train: 0.9938, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 3.573674440383911 | KNN Loss: 3.558810234069824 | CLS Loss: 0.014864299446344376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 3.5795435905456543 | KNN Loss: 3.574016809463501 | CLS Loss: 0.005526815541088581\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 3.611707925796509 | KNN Loss: 3.597028970718384 | CLS Loss: 0.014678975567221642\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 3.65199613571167 | KNN Loss: 3.626490592956543 | CLS Loss: 0.025505470111966133\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 3.601844310760498 | KNN Loss: 3.587657928466797 | CLS Loss: 0.014186344109475613\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 3.585623025894165 | KNN Loss: 3.5665955543518066 | CLS Loss: 0.01902754418551922\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 3.6452815532684326 | KNN Loss: 3.634308099746704 | CLS Loss: 0.01097337156534195\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 3.5722925662994385 | KNN Loss: 3.569079875946045 | CLS Loss: 0.0032126158475875854\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 3.6039657592773438 | KNN Loss: 3.585740327835083 | CLS Loss: 0.018225515261292458\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 3.569634199142456 | KNN Loss: 3.560361385345459 | CLS Loss: 0.009272807277739048\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 3.587967872619629 | KNN Loss: 3.5581891536712646 | CLS Loss: 0.029778823256492615\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 3.588106155395508 | KNN Loss: 3.5725739002227783 | CLS Loss: 0.01553223468363285\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 3.5936813354492188 | KNN Loss: 3.5828020572662354 | CLS Loss: 0.010879363864660263\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 3.605048656463623 | KNN Loss: 3.5695629119873047 | CLS Loss: 0.03548578545451164\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 3.615549325942993 | KNN Loss: 3.581756114959717 | CLS Loss: 0.03379310667514801\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 3.6172711849212646 | KNN Loss: 3.5516083240509033 | CLS Loss: 0.06566289812326431\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 3.6310112476348877 | KNN Loss: 3.6159520149230957 | CLS Loss: 0.015059147961437702\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 3.681574583053589 | KNN Loss: 3.6490817070007324 | CLS Loss: 0.03249288350343704\n",
      "Epoch: 079, Loss: 3.6114, Train: 0.9943, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 3.628906726837158 | KNN Loss: 3.617743968963623 | CLS Loss: 0.011162850074470043\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 3.601346731185913 | KNN Loss: 3.5777101516723633 | CLS Loss: 0.023636622354388237\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 3.5732009410858154 | KNN Loss: 3.562551259994507 | CLS Loss: 0.010649723932147026\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 3.604201316833496 | KNN Loss: 3.5882294178009033 | CLS Loss: 0.01597181335091591\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 3.618791341781616 | KNN Loss: 3.6104538440704346 | CLS Loss: 0.008337493054568768\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 3.5795276165008545 | KNN Loss: 3.574312686920166 | CLS Loss: 0.005214986857026815\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 3.635716676712036 | KNN Loss: 3.6100964546203613 | CLS Loss: 0.025620155036449432\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 3.6070120334625244 | KNN Loss: 3.6000730991363525 | CLS Loss: 0.00693900603801012\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 3.627422571182251 | KNN Loss: 3.6063613891601562 | CLS Loss: 0.02106110006570816\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 3.5822198390960693 | KNN Loss: 3.569817543029785 | CLS Loss: 0.012402246706187725\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 3.6414525508880615 | KNN Loss: 3.628305673599243 | CLS Loss: 0.013146825134754181\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 3.5779225826263428 | KNN Loss: 3.5545499324798584 | CLS Loss: 0.023372653871774673\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 3.6106019020080566 | KNN Loss: 3.5872271060943604 | CLS Loss: 0.02337481640279293\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 3.580763816833496 | KNN Loss: 3.555802583694458 | CLS Loss: 0.02496124431490898\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 3.620041847229004 | KNN Loss: 3.575531244277954 | CLS Loss: 0.04451065510511398\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 3.5983636379241943 | KNN Loss: 3.5749635696411133 | CLS Loss: 0.02340015396475792\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 3.6183230876922607 | KNN Loss: 3.607616662979126 | CLS Loss: 0.010706485249102116\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 3.6053144931793213 | KNN Loss: 3.600571632385254 | CLS Loss: 0.0047429585829377174\n",
      "Epoch: 080, Loss: 3.6102, Train: 0.9951, Valid: 0.9870, Best: 0.9873\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 3.665825366973877 | KNN Loss: 3.62416410446167 | CLS Loss: 0.04166127368807793\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 3.650864362716675 | KNN Loss: 3.6260242462158203 | CLS Loss: 0.024840068072080612\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 3.633868455886841 | KNN Loss: 3.6293437480926514 | CLS Loss: 0.004524631425738335\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 3.6317176818847656 | KNN Loss: 3.6210012435913086 | CLS Loss: 0.010716415010392666\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 3.620546579360962 | KNN Loss: 3.594977617263794 | CLS Loss: 0.025568921118974686\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 3.6027719974517822 | KNN Loss: 3.599384307861328 | CLS Loss: 0.003387642093002796\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 3.6214821338653564 | KNN Loss: 3.596491813659668 | CLS Loss: 0.02499028667807579\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 3.634922504425049 | KNN Loss: 3.6248202323913574 | CLS Loss: 0.010102173313498497\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 3.6471076011657715 | KNN Loss: 3.640160322189331 | CLS Loss: 0.006947339978069067\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 3.601010322570801 | KNN Loss: 3.559277057647705 | CLS Loss: 0.041733331978321075\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 3.6151316165924072 | KNN Loss: 3.5951595306396484 | CLS Loss: 0.019972052425146103\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 3.592207670211792 | KNN Loss: 3.585003137588501 | CLS Loss: 0.0072046020068228245\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 3.6482560634613037 | KNN Loss: 3.6254796981811523 | CLS Loss: 0.022776372730731964\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 3.644002676010132 | KNN Loss: 3.6160969734191895 | CLS Loss: 0.027905626222491264\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 3.6427226066589355 | KNN Loss: 3.6201608180999756 | CLS Loss: 0.022561749443411827\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 3.5950305461883545 | KNN Loss: 3.5817623138427734 | CLS Loss: 0.013268208131194115\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 3.688976526260376 | KNN Loss: 3.647048234939575 | CLS Loss: 0.04192836955189705\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 3.6231281757354736 | KNN Loss: 3.5935239791870117 | CLS Loss: 0.029604176059365273\n",
      "Epoch: 081, Loss: 3.6085, Train: 0.9958, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 3.582385540008545 | KNN Loss: 3.5668835639953613 | CLS Loss: 0.015501909889280796\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 3.6496570110321045 | KNN Loss: 3.6457555294036865 | CLS Loss: 0.003901389194652438\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 3.611053466796875 | KNN Loss: 3.6027746200561523 | CLS Loss: 0.008278774097561836\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 3.6405792236328125 | KNN Loss: 3.6187844276428223 | CLS Loss: 0.02179490402340889\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 3.625354290008545 | KNN Loss: 3.6031174659729004 | CLS Loss: 0.022236889228224754\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 3.5900492668151855 | KNN Loss: 3.5598649978637695 | CLS Loss: 0.030184289440512657\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 3.5899791717529297 | KNN Loss: 3.5510222911834717 | CLS Loss: 0.03895694017410278\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 3.602137565612793 | KNN Loss: 3.5925345420837402 | CLS Loss: 0.009603134356439114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 3.6057262420654297 | KNN Loss: 3.595538377761841 | CLS Loss: 0.010187924839556217\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 3.643526315689087 | KNN Loss: 3.612896203994751 | CLS Loss: 0.03063000552356243\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 3.6049020290374756 | KNN Loss: 3.59982967376709 | CLS Loss: 0.005072413478046656\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 3.595329523086548 | KNN Loss: 3.5910658836364746 | CLS Loss: 0.004263700917363167\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 3.5860626697540283 | KNN Loss: 3.5682106018066406 | CLS Loss: 0.017852067947387695\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 3.6055381298065186 | KNN Loss: 3.590984582901001 | CLS Loss: 0.014553564600646496\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 3.5788862705230713 | KNN Loss: 3.566373109817505 | CLS Loss: 0.012513046152889729\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 3.6350977420806885 | KNN Loss: 3.6163763999938965 | CLS Loss: 0.018721237778663635\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 3.597895860671997 | KNN Loss: 3.5864250659942627 | CLS Loss: 0.011470715515315533\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 3.6565282344818115 | KNN Loss: 3.640960931777954 | CLS Loss: 0.01556731853634119\n",
      "Epoch: 082, Loss: 3.6069, Train: 0.9947, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 3.6099119186401367 | KNN Loss: 3.587005615234375 | CLS Loss: 0.022906381636857986\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 3.653353452682495 | KNN Loss: 3.631052255630493 | CLS Loss: 0.022301269695162773\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 3.5902600288391113 | KNN Loss: 3.5869555473327637 | CLS Loss: 0.003304441459476948\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 3.525367021560669 | KNN Loss: 3.522381067276001 | CLS Loss: 0.0029860318172723055\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 3.5998692512512207 | KNN Loss: 3.574068546295166 | CLS Loss: 0.02580081671476364\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 3.613126516342163 | KNN Loss: 3.592061996459961 | CLS Loss: 0.02106456272304058\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 3.573303461074829 | KNN Loss: 3.5638267993927 | CLS Loss: 0.009476724080741405\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 3.5906691551208496 | KNN Loss: 3.563767194747925 | CLS Loss: 0.026901917532086372\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 3.610762357711792 | KNN Loss: 3.582181215286255 | CLS Loss: 0.028581060469150543\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 3.5790812969207764 | KNN Loss: 3.5666284561157227 | CLS Loss: 0.012452843599021435\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 3.679461717605591 | KNN Loss: 3.630901575088501 | CLS Loss: 0.04856015369296074\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 3.5539138317108154 | KNN Loss: 3.539668083190918 | CLS Loss: 0.014245652593672276\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 3.6151282787323 | KNN Loss: 3.5879647731781006 | CLS Loss: 0.027163460850715637\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 3.601963996887207 | KNN Loss: 3.5787506103515625 | CLS Loss: 0.02321336790919304\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 3.602562665939331 | KNN Loss: 3.5695552825927734 | CLS Loss: 0.033007364720106125\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 3.5944387912750244 | KNN Loss: 3.5854101181030273 | CLS Loss: 0.009028630331158638\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 3.5954689979553223 | KNN Loss: 3.5655629634857178 | CLS Loss: 0.02990591712296009\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 3.5755772590637207 | KNN Loss: 3.5676238536834717 | CLS Loss: 0.00795341283082962\n",
      "Epoch: 083, Loss: 3.6098, Train: 0.9949, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 3.5777440071105957 | KNN Loss: 3.5489683151245117 | CLS Loss: 0.02877562679350376\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 3.6034700870513916 | KNN Loss: 3.5911855697631836 | CLS Loss: 0.012284531258046627\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 3.6015374660491943 | KNN Loss: 3.586764097213745 | CLS Loss: 0.0147734135389328\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 3.5792837142944336 | KNN Loss: 3.555553674697876 | CLS Loss: 0.023729965090751648\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 3.658651351928711 | KNN Loss: 3.6301932334899902 | CLS Loss: 0.028458088636398315\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 3.6264162063598633 | KNN Loss: 3.6038947105407715 | CLS Loss: 0.022521594539284706\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 3.6778295040130615 | KNN Loss: 3.635056734085083 | CLS Loss: 0.04277273267507553\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 3.5711798667907715 | KNN Loss: 3.549677610397339 | CLS Loss: 0.021502356976270676\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 3.6103062629699707 | KNN Loss: 3.586179494857788 | CLS Loss: 0.02412674017250538\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 3.6211025714874268 | KNN Loss: 3.6129469871520996 | CLS Loss: 0.008155540563166142\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 3.653745174407959 | KNN Loss: 3.621021032333374 | CLS Loss: 0.0327240452170372\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 3.600579261779785 | KNN Loss: 3.5836942195892334 | CLS Loss: 0.01688515581190586\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 3.5974485874176025 | KNN Loss: 3.579824209213257 | CLS Loss: 0.017624352127313614\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 3.597853899002075 | KNN Loss: 3.568467378616333 | CLS Loss: 0.029386600479483604\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 3.5867700576782227 | KNN Loss: 3.556013822555542 | CLS Loss: 0.030756333842873573\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 3.7193543910980225 | KNN Loss: 3.695280075073242 | CLS Loss: 0.02407420240342617\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 3.657951831817627 | KNN Loss: 3.6258389949798584 | CLS Loss: 0.032112784683704376\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 3.583591938018799 | KNN Loss: 3.5579278469085693 | CLS Loss: 0.02566405013203621\n",
      "Epoch: 084, Loss: 3.6147, Train: 0.9954, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 3.5877203941345215 | KNN Loss: 3.5762648582458496 | CLS Loss: 0.011455542407929897\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 3.6536855697631836 | KNN Loss: 3.648533821105957 | CLS Loss: 0.005151781719177961\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 3.6461448669433594 | KNN Loss: 3.621138572692871 | CLS Loss: 0.02500627376139164\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 3.573870897293091 | KNN Loss: 3.559377908706665 | CLS Loss: 0.014492927119135857\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 3.6649277210235596 | KNN Loss: 3.633617401123047 | CLS Loss: 0.031310342252254486\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 3.6052348613739014 | KNN Loss: 3.5944137573242188 | CLS Loss: 0.010821015574038029\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 3.564819097518921 | KNN Loss: 3.5504417419433594 | CLS Loss: 0.014377309940755367\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 3.597362518310547 | KNN Loss: 3.5809695720672607 | CLS Loss: 0.016392983496189117\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 3.6829028129577637 | KNN Loss: 3.6490745544433594 | CLS Loss: 0.03382830694317818\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 3.6182172298431396 | KNN Loss: 3.6114730834960938 | CLS Loss: 0.006744253449141979\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 3.615220785140991 | KNN Loss: 3.582900047302246 | CLS Loss: 0.032320789992809296\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 3.662693500518799 | KNN Loss: 3.6329026222229004 | CLS Loss: 0.02979082055389881\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 3.615062952041626 | KNN Loss: 3.5903522968292236 | CLS Loss: 0.024710623547434807\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 3.6395180225372314 | KNN Loss: 3.615955114364624 | CLS Loss: 0.02356298640370369\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 3.6268913745880127 | KNN Loss: 3.576930522918701 | CLS Loss: 0.049960967153310776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 3.612131357192993 | KNN Loss: 3.581892728805542 | CLS Loss: 0.030238624662160873\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 3.578245162963867 | KNN Loss: 3.5351645946502686 | CLS Loss: 0.043080586940050125\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 3.5763943195343018 | KNN Loss: 3.556379556655884 | CLS Loss: 0.020014654844999313\n",
      "Epoch: 085, Loss: 3.6088, Train: 0.9956, Valid: 0.9875, Best: 0.9875\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 3.5819389820098877 | KNN Loss: 3.5481066703796387 | CLS Loss: 0.03383241221308708\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 3.6101012229919434 | KNN Loss: 3.5839273929595947 | CLS Loss: 0.026173725724220276\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 3.592787027359009 | KNN Loss: 3.57601261138916 | CLS Loss: 0.016774320974946022\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 3.6169490814208984 | KNN Loss: 3.5953681468963623 | CLS Loss: 0.02158096246421337\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 3.575674057006836 | KNN Loss: 3.569603681564331 | CLS Loss: 0.006070432718843222\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 3.5797953605651855 | KNN Loss: 3.5625174045562744 | CLS Loss: 0.01727784425020218\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 3.5634043216705322 | KNN Loss: 3.56184983253479 | CLS Loss: 0.0015544670168310404\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 3.5893795490264893 | KNN Loss: 3.5837912559509277 | CLS Loss: 0.005588213913142681\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 3.664323568344116 | KNN Loss: 3.6123008728027344 | CLS Loss: 0.05202273279428482\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 3.62286114692688 | KNN Loss: 3.605715274810791 | CLS Loss: 0.017145907506346703\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 3.616903781890869 | KNN Loss: 3.603766441345215 | CLS Loss: 0.0131372744217515\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 3.618203639984131 | KNN Loss: 3.600247621536255 | CLS Loss: 0.017956065014004707\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 3.627948522567749 | KNN Loss: 3.616122245788574 | CLS Loss: 0.011826317757368088\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 3.6411759853363037 | KNN Loss: 3.629923105239868 | CLS Loss: 0.011252813041210175\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 3.6406030654907227 | KNN Loss: 3.611490249633789 | CLS Loss: 0.02911275252699852\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 3.649723529815674 | KNN Loss: 3.6350278854370117 | CLS Loss: 0.01469558198004961\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 3.652392864227295 | KNN Loss: 3.641874074935913 | CLS Loss: 0.010518824681639671\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 3.6149234771728516 | KNN Loss: 3.606055498123169 | CLS Loss: 0.008868088945746422\n",
      "Epoch: 086, Loss: 3.6176, Train: 0.9959, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 3.6096243858337402 | KNN Loss: 3.590522050857544 | CLS Loss: 0.019102301448583603\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 3.620591878890991 | KNN Loss: 3.60064435005188 | CLS Loss: 0.019947489723563194\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 3.6002085208892822 | KNN Loss: 3.5970165729522705 | CLS Loss: 0.0031918787863105536\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 3.595799207687378 | KNN Loss: 3.5707292556762695 | CLS Loss: 0.025070032104849815\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 3.6166248321533203 | KNN Loss: 3.608693838119507 | CLS Loss: 0.00793107133358717\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 3.5994369983673096 | KNN Loss: 3.589839220046997 | CLS Loss: 0.009597660973668098\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 3.5776774883270264 | KNN Loss: 3.5751118659973145 | CLS Loss: 0.002565530128777027\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 3.5885794162750244 | KNN Loss: 3.5855650901794434 | CLS Loss: 0.0030143135227262974\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 3.6809475421905518 | KNN Loss: 3.6482646465301514 | CLS Loss: 0.03268285095691681\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 3.6416749954223633 | KNN Loss: 3.6180479526519775 | CLS Loss: 0.023627158254384995\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 3.6464414596557617 | KNN Loss: 3.6018881797790527 | CLS Loss: 0.044553183019161224\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 3.6175150871276855 | KNN Loss: 3.605193614959717 | CLS Loss: 0.012321357615292072\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 3.637148857116699 | KNN Loss: 3.610584020614624 | CLS Loss: 0.026564788073301315\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 3.610668420791626 | KNN Loss: 3.5810959339141846 | CLS Loss: 0.02957247942686081\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 3.692849636077881 | KNN Loss: 3.6759793758392334 | CLS Loss: 0.01687033660709858\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 3.6579654216766357 | KNN Loss: 3.630462884902954 | CLS Loss: 0.027502553537487984\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 3.66892147064209 | KNN Loss: 3.6522216796875 | CLS Loss: 0.016699688509106636\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 3.5704171657562256 | KNN Loss: 3.5642807483673096 | CLS Loss: 0.006136516109108925\n",
      "Epoch: 087, Loss: 3.6245, Train: 0.9945, Valid: 0.9863, Best: 0.9875\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 3.6577916145324707 | KNN Loss: 3.6459643840789795 | CLS Loss: 0.01182730495929718\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 3.662027597427368 | KNN Loss: 3.6502609252929688 | CLS Loss: 0.011766783893108368\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 3.5871219635009766 | KNN Loss: 3.5771443843841553 | CLS Loss: 0.00997756328433752\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 3.7004880905151367 | KNN Loss: 3.6781082153320312 | CLS Loss: 0.02237982489168644\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 3.6693930625915527 | KNN Loss: 3.635195255279541 | CLS Loss: 0.03419770300388336\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 3.5896124839782715 | KNN Loss: 3.583980083465576 | CLS Loss: 0.005632410291582346\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 3.5869245529174805 | KNN Loss: 3.5825953483581543 | CLS Loss: 0.0043292539194226265\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 3.6511669158935547 | KNN Loss: 3.632951259613037 | CLS Loss: 0.01821560598909855\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 3.6146316528320312 | KNN Loss: 3.5946309566497803 | CLS Loss: 0.020000671967864037\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 3.605595111846924 | KNN Loss: 3.5757663249969482 | CLS Loss: 0.029828816652297974\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 3.6583991050720215 | KNN Loss: 3.642688512802124 | CLS Loss: 0.01571047306060791\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 3.589172601699829 | KNN Loss: 3.571934938430786 | CLS Loss: 0.017237719148397446\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 3.615246057510376 | KNN Loss: 3.6038601398468018 | CLS Loss: 0.011385882273316383\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 3.6179823875427246 | KNN Loss: 3.611281394958496 | CLS Loss: 0.006701022852212191\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 3.6049458980560303 | KNN Loss: 3.590548276901245 | CLS Loss: 0.014397531747817993\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 3.6653778553009033 | KNN Loss: 3.636838912963867 | CLS Loss: 0.02853890135884285\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 3.6241304874420166 | KNN Loss: 3.599472761154175 | CLS Loss: 0.02465769462287426\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 3.63834547996521 | KNN Loss: 3.6143240928649902 | CLS Loss: 0.024021346122026443\n",
      "Epoch: 088, Loss: 3.6248, Train: 0.9953, Valid: 0.9860, Best: 0.9875\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 3.664825201034546 | KNN Loss: 3.643165349960327 | CLS Loss: 0.02165979892015457\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 3.575711250305176 | KNN Loss: 3.565176486968994 | CLS Loss: 0.010534694418311119\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 3.5966694355010986 | KNN Loss: 3.571061611175537 | CLS Loss: 0.02560780569911003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 3.6409811973571777 | KNN Loss: 3.6046719551086426 | CLS Loss: 0.03630915656685829\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 3.6155614852905273 | KNN Loss: 3.608588218688965 | CLS Loss: 0.006973337382078171\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 3.6152987480163574 | KNN Loss: 3.580678701400757 | CLS Loss: 0.03462015837430954\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 3.607699394226074 | KNN Loss: 3.5945327281951904 | CLS Loss: 0.013166782446205616\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 3.649501323699951 | KNN Loss: 3.6113343238830566 | CLS Loss: 0.0381670817732811\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 3.6177093982696533 | KNN Loss: 3.5968685150146484 | CLS Loss: 0.0208408385515213\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 3.6179189682006836 | KNN Loss: 3.601796865463257 | CLS Loss: 0.016122013330459595\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 3.610335111618042 | KNN Loss: 3.6043946743011475 | CLS Loss: 0.005940377712249756\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 3.610090732574463 | KNN Loss: 3.587092638015747 | CLS Loss: 0.022998105734586716\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 3.5984859466552734 | KNN Loss: 3.5805697441101074 | CLS Loss: 0.01791626214981079\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 3.6193692684173584 | KNN Loss: 3.589113473892212 | CLS Loss: 0.030255792662501335\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 3.6208035945892334 | KNN Loss: 3.612955093383789 | CLS Loss: 0.007848395965993404\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 3.6127631664276123 | KNN Loss: 3.5874736309051514 | CLS Loss: 0.02528943121433258\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 3.624115228652954 | KNN Loss: 3.6060755252838135 | CLS Loss: 0.018039625138044357\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 3.6415584087371826 | KNN Loss: 3.6105635166168213 | CLS Loss: 0.030994879081845284\n",
      "Epoch: 089, Loss: 3.6243, Train: 0.9960, Valid: 0.9869, Best: 0.9875\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 3.5805885791778564 | KNN Loss: 3.5688652992248535 | CLS Loss: 0.011723366566002369\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 3.653780221939087 | KNN Loss: 3.644035816192627 | CLS Loss: 0.009744386188685894\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 3.6833906173706055 | KNN Loss: 3.659712314605713 | CLS Loss: 0.02367827482521534\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 3.6923422813415527 | KNN Loss: 3.6745800971984863 | CLS Loss: 0.017762215808033943\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 3.6562612056732178 | KNN Loss: 3.631542682647705 | CLS Loss: 0.024718493223190308\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 3.6343460083007812 | KNN Loss: 3.60776424407959 | CLS Loss: 0.026581715792417526\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 3.5983715057373047 | KNN Loss: 3.5706725120544434 | CLS Loss: 0.02769904024899006\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 3.6004581451416016 | KNN Loss: 3.5902020931243896 | CLS Loss: 0.01025612186640501\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 3.6771929264068604 | KNN Loss: 3.6653926372528076 | CLS Loss: 0.011800308711826801\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 3.6688036918640137 | KNN Loss: 3.6255500316619873 | CLS Loss: 0.0432535782456398\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 3.6361796855926514 | KNN Loss: 3.6083977222442627 | CLS Loss: 0.027781939134001732\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 3.6249942779541016 | KNN Loss: 3.6154634952545166 | CLS Loss: 0.00953072402626276\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 3.5748090744018555 | KNN Loss: 3.5565335750579834 | CLS Loss: 0.01827554777264595\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 3.6525073051452637 | KNN Loss: 3.6267035007476807 | CLS Loss: 0.02580389752984047\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 3.6956369876861572 | KNN Loss: 3.6615779399871826 | CLS Loss: 0.034058958292007446\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 3.613691806793213 | KNN Loss: 3.5950515270233154 | CLS Loss: 0.0186403039842844\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 3.601724863052368 | KNN Loss: 3.5818302631378174 | CLS Loss: 0.019894598051905632\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 3.671807050704956 | KNN Loss: 3.633380889892578 | CLS Loss: 0.03842617943882942\n",
      "Epoch: 090, Loss: 3.6254, Train: 0.9955, Valid: 0.9859, Best: 0.9875\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 3.599365472793579 | KNN Loss: 3.5793142318725586 | CLS Loss: 0.020051246508955956\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 3.6070237159729004 | KNN Loss: 3.599869966506958 | CLS Loss: 0.007153660524636507\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 3.5982894897460938 | KNN Loss: 3.581639289855957 | CLS Loss: 0.016650274395942688\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 3.596065044403076 | KNN Loss: 3.593618154525757 | CLS Loss: 0.0024468994233757257\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 3.616215944290161 | KNN Loss: 3.585273504257202 | CLS Loss: 0.030942507088184357\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 3.6268622875213623 | KNN Loss: 3.5970869064331055 | CLS Loss: 0.02977541834115982\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 3.604588508605957 | KNN Loss: 3.5842106342315674 | CLS Loss: 0.020377827808260918\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 3.5888330936431885 | KNN Loss: 3.583740711212158 | CLS Loss: 0.005092273466289043\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 3.6126182079315186 | KNN Loss: 3.6068789958953857 | CLS Loss: 0.005739317275583744\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 3.618907928466797 | KNN Loss: 3.5984256267547607 | CLS Loss: 0.020482320338487625\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 3.5958681106567383 | KNN Loss: 3.58370041847229 | CLS Loss: 0.012167738750576973\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 3.6167736053466797 | KNN Loss: 3.6057493686676025 | CLS Loss: 0.011024253442883492\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 3.6474084854125977 | KNN Loss: 3.6129813194274902 | CLS Loss: 0.034427061676979065\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 3.629793405532837 | KNN Loss: 3.6096444129943848 | CLS Loss: 0.020149001851677895\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 3.5968735218048096 | KNN Loss: 3.57662034034729 | CLS Loss: 0.02025309018790722\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 3.658553123474121 | KNN Loss: 3.6089565753936768 | CLS Loss: 0.04959645867347717\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 3.6195008754730225 | KNN Loss: 3.5975584983825684 | CLS Loss: 0.02194238267838955\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 3.6038670539855957 | KNN Loss: 3.5617332458496094 | CLS Loss: 0.04213378578424454\n",
      "Epoch: 091, Loss: 3.6214, Train: 0.9960, Valid: 0.9868, Best: 0.9875\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 3.658511161804199 | KNN Loss: 3.646284818649292 | CLS Loss: 0.012226257473230362\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 3.65425705909729 | KNN Loss: 3.6412203311920166 | CLS Loss: 0.013036786578595638\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 3.691032886505127 | KNN Loss: 3.683488607406616 | CLS Loss: 0.007544232998043299\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 3.619859457015991 | KNN Loss: 3.601072072982788 | CLS Loss: 0.01878729648888111\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 3.6099963188171387 | KNN Loss: 3.594815731048584 | CLS Loss: 0.015180474147200584\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 3.6216514110565186 | KNN Loss: 3.590067148208618 | CLS Loss: 0.031584352254867554\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 3.587719678878784 | KNN Loss: 3.5675408840179443 | CLS Loss: 0.020178847014904022\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 3.6215429306030273 | KNN Loss: 3.608180046081543 | CLS Loss: 0.013362991623580456\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 3.5924692153930664 | KNN Loss: 3.5898072719573975 | CLS Loss: 0.0026618638075888157\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 3.628821849822998 | KNN Loss: 3.624943494796753 | CLS Loss: 0.0038784474600106478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 3.6637511253356934 | KNN Loss: 3.635371208190918 | CLS Loss: 0.0283798985183239\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 3.6254169940948486 | KNN Loss: 3.604728937149048 | CLS Loss: 0.02068793959915638\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 3.658700942993164 | KNN Loss: 3.6387224197387695 | CLS Loss: 0.01997850462794304\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 3.6086857318878174 | KNN Loss: 3.58693528175354 | CLS Loss: 0.0217505544424057\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 3.6589272022247314 | KNN Loss: 3.6508240699768066 | CLS Loss: 0.00810316763818264\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 3.6004223823547363 | KNN Loss: 3.5737216472625732 | CLS Loss: 0.026700809597969055\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 3.649937629699707 | KNN Loss: 3.6400482654571533 | CLS Loss: 0.0098893903195858\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 3.64971923828125 | KNN Loss: 3.637726068496704 | CLS Loss: 0.011993183754384518\n",
      "Epoch: 092, Loss: 3.6249, Train: 0.9958, Valid: 0.9868, Best: 0.9875\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 3.5915677547454834 | KNN Loss: 3.581932544708252 | CLS Loss: 0.009635180234909058\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 3.6220788955688477 | KNN Loss: 3.6147632598876953 | CLS Loss: 0.007315727882087231\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 3.638789176940918 | KNN Loss: 3.6169512271881104 | CLS Loss: 0.021838000044226646\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 3.5840001106262207 | KNN Loss: 3.5806026458740234 | CLS Loss: 0.003397485939785838\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 3.5937130451202393 | KNN Loss: 3.5693864822387695 | CLS Loss: 0.024326497688889503\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 3.6652278900146484 | KNN Loss: 3.6326920986175537 | CLS Loss: 0.03253582864999771\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 3.6124472618103027 | KNN Loss: 3.582202434539795 | CLS Loss: 0.030244795605540276\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 3.615838050842285 | KNN Loss: 3.577188014984131 | CLS Loss: 0.03865009546279907\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 3.6049630641937256 | KNN Loss: 3.5820579528808594 | CLS Loss: 0.022905072197318077\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 3.5984184741973877 | KNN Loss: 3.5722057819366455 | CLS Loss: 0.0262127872556448\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 3.6128451824188232 | KNN Loss: 3.582702875137329 | CLS Loss: 0.03014225699007511\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 3.6035571098327637 | KNN Loss: 3.581907033920288 | CLS Loss: 0.021649977192282677\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 3.634925127029419 | KNN Loss: 3.6284821033477783 | CLS Loss: 0.0064430246129632\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 3.627204656600952 | KNN Loss: 3.608079195022583 | CLS Loss: 0.019125357270240784\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 3.6753625869750977 | KNN Loss: 3.653343915939331 | CLS Loss: 0.02201860398054123\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 3.6392884254455566 | KNN Loss: 3.61212158203125 | CLS Loss: 0.02716680057346821\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 3.5904130935668945 | KNN Loss: 3.573397159576416 | CLS Loss: 0.017015865072607994\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 3.623680353164673 | KNN Loss: 3.597029685974121 | CLS Loss: 0.026650642976164818\n",
      "Epoch: 093, Loss: 3.6240, Train: 0.9931, Valid: 0.9839, Best: 0.9875\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 3.639887571334839 | KNN Loss: 3.607438564300537 | CLS Loss: 0.03244896978139877\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 3.605045795440674 | KNN Loss: 3.5820205211639404 | CLS Loss: 0.023025372996926308\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 3.6583943367004395 | KNN Loss: 3.6342477798461914 | CLS Loss: 0.02414656989276409\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 3.6064579486846924 | KNN Loss: 3.562361001968384 | CLS Loss: 0.044097013771533966\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 3.6198582649230957 | KNN Loss: 3.6002137660980225 | CLS Loss: 0.019644547253847122\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 3.69817852973938 | KNN Loss: 3.688547372817993 | CLS Loss: 0.009631051681935787\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 3.6291425228118896 | KNN Loss: 3.593921422958374 | CLS Loss: 0.0352211631834507\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 3.629180908203125 | KNN Loss: 3.6165261268615723 | CLS Loss: 0.01265476644039154\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 3.6183362007141113 | KNN Loss: 3.6023292541503906 | CLS Loss: 0.016006948426365852\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 3.5924479961395264 | KNN Loss: 3.576981782913208 | CLS Loss: 0.015466218814253807\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 3.5915277004241943 | KNN Loss: 3.5860812664031982 | CLS Loss: 0.0054465425200760365\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 3.623859405517578 | KNN Loss: 3.610687494277954 | CLS Loss: 0.013171876780688763\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 3.6084060668945312 | KNN Loss: 3.6028592586517334 | CLS Loss: 0.0055468021892011166\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 3.6039774417877197 | KNN Loss: 3.5970611572265625 | CLS Loss: 0.00691625801846385\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 3.596782922744751 | KNN Loss: 3.565547227859497 | CLS Loss: 0.03123580850660801\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 3.622220516204834 | KNN Loss: 3.594447135925293 | CLS Loss: 0.027773350477218628\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 3.6210825443267822 | KNN Loss: 3.593076705932617 | CLS Loss: 0.02800595387816429\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 3.6061437129974365 | KNN Loss: 3.571320056915283 | CLS Loss: 0.03482365608215332\n",
      "Epoch: 094, Loss: 3.6235, Train: 0.9953, Valid: 0.9870, Best: 0.9875\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 3.587475538253784 | KNN Loss: 3.5795340538024902 | CLS Loss: 0.007941515184938908\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 3.654576063156128 | KNN Loss: 3.6456072330474854 | CLS Loss: 0.008968818001449108\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 3.656611442565918 | KNN Loss: 3.648127794265747 | CLS Loss: 0.0084837032482028\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 3.6184630393981934 | KNN Loss: 3.604785919189453 | CLS Loss: 0.013677118346095085\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 3.5774221420288086 | KNN Loss: 3.56687593460083 | CLS Loss: 0.010546242818236351\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 3.597224235534668 | KNN Loss: 3.589510917663574 | CLS Loss: 0.007713250815868378\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 3.624993324279785 | KNN Loss: 3.6042890548706055 | CLS Loss: 0.020704373717308044\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 3.636648654937744 | KNN Loss: 3.616914749145508 | CLS Loss: 0.01973399892449379\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 3.590646982192993 | KNN Loss: 3.5755481719970703 | CLS Loss: 0.01509890053421259\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 3.6522109508514404 | KNN Loss: 3.611117124557495 | CLS Loss: 0.04109383746981621\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 3.597853899002075 | KNN Loss: 3.5851786136627197 | CLS Loss: 0.012675324454903603\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 3.627223253250122 | KNN Loss: 3.605938196182251 | CLS Loss: 0.021285003051161766\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 3.6125779151916504 | KNN Loss: 3.599372386932373 | CLS Loss: 0.013205572962760925\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 3.7154793739318848 | KNN Loss: 3.691028356552124 | CLS Loss: 0.02445112355053425\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 3.6377406120300293 | KNN Loss: 3.6306886672973633 | CLS Loss: 0.007051960099488497\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 3.6748647689819336 | KNN Loss: 3.66615629196167 | CLS Loss: 0.008708544075489044\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 3.653447151184082 | KNN Loss: 3.6435508728027344 | CLS Loss: 0.009896159172058105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 3.6290297508239746 | KNN Loss: 3.622307777404785 | CLS Loss: 0.006721979007124901\n",
      "Epoch: 095, Loss: 3.6244, Train: 0.9954, Valid: 0.9863, Best: 0.9875\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 3.6155080795288086 | KNN Loss: 3.6072757244110107 | CLS Loss: 0.008232351392507553\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 3.61220121383667 | KNN Loss: 3.6019012928009033 | CLS Loss: 0.010299992747604847\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 3.6252317428588867 | KNN Loss: 3.614065647125244 | CLS Loss: 0.01116605568677187\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 3.630497455596924 | KNN Loss: 3.6249401569366455 | CLS Loss: 0.00555720878764987\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 3.6307482719421387 | KNN Loss: 3.6112895011901855 | CLS Loss: 0.019458767026662827\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 3.6126651763916016 | KNN Loss: 3.5999324321746826 | CLS Loss: 0.012732641771435738\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 3.610875368118286 | KNN Loss: 3.59403133392334 | CLS Loss: 0.016844023019075394\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 3.704383373260498 | KNN Loss: 3.6911022663116455 | CLS Loss: 0.013281052000820637\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 3.650062322616577 | KNN Loss: 3.6022896766662598 | CLS Loss: 0.047772571444511414\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 3.6049928665161133 | KNN Loss: 3.5991761684417725 | CLS Loss: 0.005816600751131773\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 3.6232950687408447 | KNN Loss: 3.6068503856658936 | CLS Loss: 0.016444656997919083\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 3.64440655708313 | KNN Loss: 3.6284639835357666 | CLS Loss: 0.01594245620071888\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 3.604625940322876 | KNN Loss: 3.595076084136963 | CLS Loss: 0.009549827314913273\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 3.6380465030670166 | KNN Loss: 3.616851806640625 | CLS Loss: 0.02119458094239235\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 3.602632522583008 | KNN Loss: 3.6013035774230957 | CLS Loss: 0.0013289636699482799\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 3.6175594329833984 | KNN Loss: 3.59026837348938 | CLS Loss: 0.02729099802672863\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 3.589348316192627 | KNN Loss: 3.5807924270629883 | CLS Loss: 0.008555984124541283\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 3.6583714485168457 | KNN Loss: 3.6380412578582764 | CLS Loss: 0.020330265164375305\n",
      "Epoch: 096, Loss: 3.6169, Train: 0.9956, Valid: 0.9874, Best: 0.9875\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 3.5732805728912354 | KNN Loss: 3.5644679069519043 | CLS Loss: 0.008812572807073593\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 3.581247568130493 | KNN Loss: 3.5706019401550293 | CLS Loss: 0.010645510628819466\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 3.653916120529175 | KNN Loss: 3.6427407264709473 | CLS Loss: 0.01117531955242157\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 3.5806422233581543 | KNN Loss: 3.5768165588378906 | CLS Loss: 0.003825689433142543\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 3.6313164234161377 | KNN Loss: 3.6273396015167236 | CLS Loss: 0.003976847510784864\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 3.5916526317596436 | KNN Loss: 3.5835938453674316 | CLS Loss: 0.008058817125856876\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 3.6385409832000732 | KNN Loss: 3.6134378910064697 | CLS Loss: 0.02510300651192665\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 3.617894411087036 | KNN Loss: 3.5948100090026855 | CLS Loss: 0.023084519430994987\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 3.681058645248413 | KNN Loss: 3.666518449783325 | CLS Loss: 0.014540313743054867\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 3.6326639652252197 | KNN Loss: 3.6125166416168213 | CLS Loss: 0.020147379487752914\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 3.580429792404175 | KNN Loss: 3.561116933822632 | CLS Loss: 0.019312815740704536\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 3.597381591796875 | KNN Loss: 3.582185983657837 | CLS Loss: 0.015195607207715511\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 3.610898017883301 | KNN Loss: 3.5883431434631348 | CLS Loss: 0.022554822266101837\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 3.6972432136535645 | KNN Loss: 3.6826889514923096 | CLS Loss: 0.01455430407077074\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 3.6225836277008057 | KNN Loss: 3.612577438354492 | CLS Loss: 0.010006088763475418\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 3.639352560043335 | KNN Loss: 3.604335308074951 | CLS Loss: 0.03501731902360916\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 3.671057939529419 | KNN Loss: 3.635672092437744 | CLS Loss: 0.03538576886057854\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 3.620452642440796 | KNN Loss: 3.604957342147827 | CLS Loss: 0.01549532637000084\n",
      "Epoch: 097, Loss: 3.6186, Train: 0.9958, Valid: 0.9872, Best: 0.9875\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 3.6512181758880615 | KNN Loss: 3.6215882301330566 | CLS Loss: 0.029629990458488464\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 3.6494977474212646 | KNN Loss: 3.642122745513916 | CLS Loss: 0.007375056389719248\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 3.620968818664551 | KNN Loss: 3.5920729637145996 | CLS Loss: 0.028895778581500053\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 3.588963508605957 | KNN Loss: 3.5848395824432373 | CLS Loss: 0.004123867489397526\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 3.624831199645996 | KNN Loss: 3.605959892272949 | CLS Loss: 0.018871231004595757\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 3.5948715209960938 | KNN Loss: 3.569488525390625 | CLS Loss: 0.02538304403424263\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 3.5982003211975098 | KNN Loss: 3.5779480934143066 | CLS Loss: 0.020252292975783348\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 3.6395506858825684 | KNN Loss: 3.631021738052368 | CLS Loss: 0.00852900743484497\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 3.6538944244384766 | KNN Loss: 3.6480977535247803 | CLS Loss: 0.005796725396066904\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 3.6444084644317627 | KNN Loss: 3.6221320629119873 | CLS Loss: 0.022276397794485092\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 3.6580259799957275 | KNN Loss: 3.6288485527038574 | CLS Loss: 0.029177401214838028\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 3.570798635482788 | KNN Loss: 3.5625839233398438 | CLS Loss: 0.008214720524847507\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 3.6708757877349854 | KNN Loss: 3.657648801803589 | CLS Loss: 0.013226989656686783\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 3.6229984760284424 | KNN Loss: 3.6114258766174316 | CLS Loss: 0.011572591960430145\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 3.6080844402313232 | KNN Loss: 3.588533401489258 | CLS Loss: 0.019551092758774757\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 3.5876810550689697 | KNN Loss: 3.576665163040161 | CLS Loss: 0.011015810072422028\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 3.592097520828247 | KNN Loss: 3.5714290142059326 | CLS Loss: 0.02066858485341072\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 3.6519861221313477 | KNN Loss: 3.632457971572876 | CLS Loss: 0.019528256729245186\n",
      "Epoch: 098, Loss: 3.6177, Train: 0.9955, Valid: 0.9871, Best: 0.9875\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 3.612367630004883 | KNN Loss: 3.587338924407959 | CLS Loss: 0.02502872794866562\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 3.6223349571228027 | KNN Loss: 3.6064462661743164 | CLS Loss: 0.015888692811131477\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 3.5919911861419678 | KNN Loss: 3.5591511726379395 | CLS Loss: 0.03284010291099548\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 3.592726469039917 | KNN Loss: 3.5798425674438477 | CLS Loss: 0.012883954681456089\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 3.62760591506958 | KNN Loss: 3.6225647926330566 | CLS Loss: 0.0050410558469593525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 3.670285940170288 | KNN Loss: 3.656085252761841 | CLS Loss: 0.014200570061802864\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 3.6393704414367676 | KNN Loss: 3.6265666484832764 | CLS Loss: 0.012803874909877777\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 3.616502523422241 | KNN Loss: 3.606290817260742 | CLS Loss: 0.010211811400949955\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 3.609179735183716 | KNN Loss: 3.600865125656128 | CLS Loss: 0.008314545266330242\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 3.6458022594451904 | KNN Loss: 3.634718894958496 | CLS Loss: 0.011083351448178291\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 3.6333556175231934 | KNN Loss: 3.6135127544403076 | CLS Loss: 0.019842753186821938\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 3.5879669189453125 | KNN Loss: 3.5675997734069824 | CLS Loss: 0.0203670933842659\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 3.6800918579101562 | KNN Loss: 3.6643381118774414 | CLS Loss: 0.015753749758005142\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 3.6302106380462646 | KNN Loss: 3.576896905899048 | CLS Loss: 0.05331365019083023\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 3.591618537902832 | KNN Loss: 3.5714406967163086 | CLS Loss: 0.020177915692329407\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 3.6025755405426025 | KNN Loss: 3.571376323699951 | CLS Loss: 0.03119914047420025\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 3.6301801204681396 | KNN Loss: 3.6121768951416016 | CLS Loss: 0.0180031917989254\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 3.5867226123809814 | KNN Loss: 3.5737850666046143 | CLS Loss: 0.012937513180077076\n",
      "Epoch: 099, Loss: 3.6208, Train: 0.9964, Valid: 0.9868, Best: 0.9875\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 3.683777093887329 | KNN Loss: 3.6487538814544678 | CLS Loss: 0.03502311185002327\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 3.5728795528411865 | KNN Loss: 3.5626277923583984 | CLS Loss: 0.010251789353787899\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 3.6261613368988037 | KNN Loss: 3.612687349319458 | CLS Loss: 0.013474098406732082\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 3.6078720092773438 | KNN Loss: 3.587538957595825 | CLS Loss: 0.020333044230937958\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 3.6449570655822754 | KNN Loss: 3.634199857711792 | CLS Loss: 0.010757286101579666\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 3.595092535018921 | KNN Loss: 3.5749142169952393 | CLS Loss: 0.020178264006972313\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 3.6007769107818604 | KNN Loss: 3.5927910804748535 | CLS Loss: 0.007985739037394524\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 3.639446973800659 | KNN Loss: 3.604149103164673 | CLS Loss: 0.035297941416502\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 3.639075517654419 | KNN Loss: 3.6215038299560547 | CLS Loss: 0.017571769654750824\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 3.6505048274993896 | KNN Loss: 3.6402266025543213 | CLS Loss: 0.010278269648551941\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 3.621565103530884 | KNN Loss: 3.6071128845214844 | CLS Loss: 0.01445211935788393\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 3.6190404891967773 | KNN Loss: 3.6131248474121094 | CLS Loss: 0.005915525369346142\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 3.6055748462677 | KNN Loss: 3.6016178131103516 | CLS Loss: 0.0039571067318320274\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 3.5879156589508057 | KNN Loss: 3.574043035507202 | CLS Loss: 0.013872681185603142\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 3.575648784637451 | KNN Loss: 3.5725390911102295 | CLS Loss: 0.00310960179194808\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 3.6039986610412598 | KNN Loss: 3.5906481742858887 | CLS Loss: 0.01335041131824255\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 3.588904857635498 | KNN Loss: 3.567991256713867 | CLS Loss: 0.020913666114211082\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 3.617920398712158 | KNN Loss: 3.60657000541687 | CLS Loss: 0.01135045476257801\n",
      "Epoch: 100, Loss: 3.6225, Train: 0.9964, Valid: 0.9868, Best: 0.9875\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 3.6128437519073486 | KNN Loss: 3.593606948852539 | CLS Loss: 0.019236791878938675\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 3.6202120780944824 | KNN Loss: 3.608124256134033 | CLS Loss: 0.012087785638868809\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 3.5957932472229004 | KNN Loss: 3.5792222023010254 | CLS Loss: 0.016571136191487312\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 3.637685537338257 | KNN Loss: 3.6113266944885254 | CLS Loss: 0.02635892480611801\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 3.5982913970947266 | KNN Loss: 3.5688374042510986 | CLS Loss: 0.029454022645950317\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 3.5822665691375732 | KNN Loss: 3.575881242752075 | CLS Loss: 0.006385407410562038\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 3.625539541244507 | KNN Loss: 3.6130964756011963 | CLS Loss: 0.012443157844245434\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 3.584476947784424 | KNN Loss: 3.571345090866089 | CLS Loss: 0.013131951913237572\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 3.635892391204834 | KNN Loss: 3.6259255409240723 | CLS Loss: 0.009966901503503323\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 3.5778703689575195 | KNN Loss: 3.5590567588806152 | CLS Loss: 0.018813729286193848\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 3.6038296222686768 | KNN Loss: 3.5934314727783203 | CLS Loss: 0.010398144833743572\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 3.623098611831665 | KNN Loss: 3.6030948162078857 | CLS Loss: 0.020003877580165863\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 3.679910898208618 | KNN Loss: 3.6195878982543945 | CLS Loss: 0.06032299995422363\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 3.6098134517669678 | KNN Loss: 3.5840702056884766 | CLS Loss: 0.02574327401816845\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 3.6314897537231445 | KNN Loss: 3.592076539993286 | CLS Loss: 0.039413221180438995\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 3.6069250106811523 | KNN Loss: 3.598515272140503 | CLS Loss: 0.008409692905843258\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 3.643355369567871 | KNN Loss: 3.623997926712036 | CLS Loss: 0.019357431679964066\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 3.6979427337646484 | KNN Loss: 3.682905435562134 | CLS Loss: 0.015037194825708866\n",
      "Epoch: 101, Loss: 3.6149, Train: 0.9952, Valid: 0.9865, Best: 0.9875\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 3.5991203784942627 | KNN Loss: 3.5906896591186523 | CLS Loss: 0.00843071285635233\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 3.6540801525115967 | KNN Loss: 3.628875494003296 | CLS Loss: 0.025204746052622795\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 3.6270999908447266 | KNN Loss: 3.5927937030792236 | CLS Loss: 0.034306369721889496\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 3.5706686973571777 | KNN Loss: 3.551015853881836 | CLS Loss: 0.01965278573334217\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 3.6192564964294434 | KNN Loss: 3.5948612689971924 | CLS Loss: 0.0243952926248312\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 3.641982316970825 | KNN Loss: 3.6160426139831543 | CLS Loss: 0.02593975141644478\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 3.5957038402557373 | KNN Loss: 3.582561492919922 | CLS Loss: 0.013142363168299198\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 3.5942814350128174 | KNN Loss: 3.5767440795898438 | CLS Loss: 0.017537280917167664\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 3.6225385665893555 | KNN Loss: 3.6170713901519775 | CLS Loss: 0.005467157810926437\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 3.576228618621826 | KNN Loss: 3.572464942932129 | CLS Loss: 0.0037636947818100452\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 3.6146223545074463 | KNN Loss: 3.5990867614746094 | CLS Loss: 0.015535526908934116\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 3.657443046569824 | KNN Loss: 3.596656560897827 | CLS Loss: 0.060786567628383636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 3.6326003074645996 | KNN Loss: 3.626147985458374 | CLS Loss: 0.006452325265854597\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 3.5986056327819824 | KNN Loss: 3.575068712234497 | CLS Loss: 0.023536834865808487\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 3.6016316413879395 | KNN Loss: 3.5974018573760986 | CLS Loss: 0.004229837097227573\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 3.6811420917510986 | KNN Loss: 3.674394130706787 | CLS Loss: 0.00674797035753727\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 3.6441943645477295 | KNN Loss: 3.6273746490478516 | CLS Loss: 0.016819771379232407\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 3.6239867210388184 | KNN Loss: 3.6141674518585205 | CLS Loss: 0.009819337166845798\n",
      "Epoch: 102, Loss: 3.6124, Train: 0.9968, Valid: 0.9868, Best: 0.9875\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 3.5726523399353027 | KNN Loss: 3.5694966316223145 | CLS Loss: 0.003155715996399522\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 3.6341769695281982 | KNN Loss: 3.6259050369262695 | CLS Loss: 0.008272010833024979\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 3.6351428031921387 | KNN Loss: 3.6210830211639404 | CLS Loss: 0.014059776440262794\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 3.5842926502227783 | KNN Loss: 3.5821850299835205 | CLS Loss: 0.0021076174452900887\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 3.6087636947631836 | KNN Loss: 3.583028554916382 | CLS Loss: 0.025735223665833473\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 3.5789830684661865 | KNN Loss: 3.5604443550109863 | CLS Loss: 0.0185388196259737\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 3.5774433612823486 | KNN Loss: 3.5576369762420654 | CLS Loss: 0.019806452095508575\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 3.636063575744629 | KNN Loss: 3.630373954772949 | CLS Loss: 0.00568968104198575\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 3.593745231628418 | KNN Loss: 3.571855068206787 | CLS Loss: 0.021890273317694664\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 3.623114585876465 | KNN Loss: 3.6196746826171875 | CLS Loss: 0.0034399176947772503\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 3.6114766597747803 | KNN Loss: 3.594203233718872 | CLS Loss: 0.017273450270295143\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 3.597224235534668 | KNN Loss: 3.594923496246338 | CLS Loss: 0.002300806110724807\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 3.583756923675537 | KNN Loss: 3.572922945022583 | CLS Loss: 0.010833974927663803\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 3.6227049827575684 | KNN Loss: 3.5882508754730225 | CLS Loss: 0.034454066306352615\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 3.644331932067871 | KNN Loss: 3.622356414794922 | CLS Loss: 0.021975576877593994\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 3.593244791030884 | KNN Loss: 3.5837697982788086 | CLS Loss: 0.009475094266235828\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 3.6314423084259033 | KNN Loss: 3.6235010623931885 | CLS Loss: 0.007941302843391895\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 3.6150779724121094 | KNN Loss: 3.589853048324585 | CLS Loss: 0.025225015357136726\n",
      "Epoch: 103, Loss: 3.6187, Train: 0.9958, Valid: 0.9859, Best: 0.9875\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 3.6107430458068848 | KNN Loss: 3.6005237102508545 | CLS Loss: 0.010219424031674862\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 3.587460994720459 | KNN Loss: 3.581515312194824 | CLS Loss: 0.005945789627730846\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 3.6078901290893555 | KNN Loss: 3.5862138271331787 | CLS Loss: 0.021676354110240936\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 3.637138843536377 | KNN Loss: 3.616145133972168 | CLS Loss: 0.02099369280040264\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 3.624027967453003 | KNN Loss: 3.608785629272461 | CLS Loss: 0.015242417342960835\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 3.622164249420166 | KNN Loss: 3.6057090759277344 | CLS Loss: 0.016455210745334625\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 3.613806962966919 | KNN Loss: 3.603342294692993 | CLS Loss: 0.01046461146324873\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 3.6818795204162598 | KNN Loss: 3.6409618854522705 | CLS Loss: 0.04091774672269821\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 3.6480188369750977 | KNN Loss: 3.6364433765411377 | CLS Loss: 0.011575519107282162\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 3.60532808303833 | KNN Loss: 3.577340602874756 | CLS Loss: 0.027987590059638023\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 3.5779898166656494 | KNN Loss: 3.5745832920074463 | CLS Loss: 0.00340662756934762\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 3.624523878097534 | KNN Loss: 3.5995781421661377 | CLS Loss: 0.024945847690105438\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 3.6549644470214844 | KNN Loss: 3.6431264877319336 | CLS Loss: 0.01183802168816328\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 3.589038610458374 | KNN Loss: 3.5805230140686035 | CLS Loss: 0.008515671826899052\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 3.5818331241607666 | KNN Loss: 3.574737310409546 | CLS Loss: 0.007095915265381336\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 3.611426591873169 | KNN Loss: 3.601637840270996 | CLS Loss: 0.00978872086852789\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 3.679807424545288 | KNN Loss: 3.6612772941589355 | CLS Loss: 0.01853015087544918\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 3.691246509552002 | KNN Loss: 3.665787935256958 | CLS Loss: 0.0254585649818182\n",
      "Epoch: 104, Loss: 3.6154, Train: 0.9956, Valid: 0.9859, Best: 0.9875\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 3.591587543487549 | KNN Loss: 3.5759687423706055 | CLS Loss: 0.01561871636658907\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 3.5994160175323486 | KNN Loss: 3.571920156478882 | CLS Loss: 0.02749595418572426\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 3.604552745819092 | KNN Loss: 3.5826125144958496 | CLS Loss: 0.021940335631370544\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 3.603595018386841 | KNN Loss: 3.6011040210723877 | CLS Loss: 0.0024909069761633873\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 3.6028695106506348 | KNN Loss: 3.579341411590576 | CLS Loss: 0.02352810464799404\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 3.590209484100342 | KNN Loss: 3.569756507873535 | CLS Loss: 0.02045293338596821\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 3.613039493560791 | KNN Loss: 3.601726531982422 | CLS Loss: 0.011312928982079029\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 3.59672212600708 | KNN Loss: 3.5852210521698 | CLS Loss: 0.011501016095280647\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 3.6038877964019775 | KNN Loss: 3.5874216556549072 | CLS Loss: 0.016466235741972923\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 3.584486246109009 | KNN Loss: 3.5662360191345215 | CLS Loss: 0.018250323832035065\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 3.632901191711426 | KNN Loss: 3.6092278957366943 | CLS Loss: 0.023673253133893013\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 3.597649097442627 | KNN Loss: 3.5871856212615967 | CLS Loss: 0.0104635925963521\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 3.6150319576263428 | KNN Loss: 3.6080482006073 | CLS Loss: 0.006983733270317316\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 3.615591287612915 | KNN Loss: 3.604966640472412 | CLS Loss: 0.010624665766954422\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 3.599813938140869 | KNN Loss: 3.5916311740875244 | CLS Loss: 0.008182738907635212\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 3.6172854900360107 | KNN Loss: 3.6154403686523438 | CLS Loss: 0.001845134305767715\n",
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 3.599379777908325 | KNN Loss: 3.5968234539031982 | CLS Loss: 0.0025562311057001352\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 3.636944532394409 | KNN Loss: 3.6242568492889404 | CLS Loss: 0.012687630951404572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105, Loss: 3.6099, Train: 0.9966, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 3.588693857192993 | KNN Loss: 3.579767942428589 | CLS Loss: 0.008925908245146275\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 3.6000139713287354 | KNN Loss: 3.5821282863616943 | CLS Loss: 0.017885761335492134\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 3.5936825275421143 | KNN Loss: 3.5896706581115723 | CLS Loss: 0.004011890850961208\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 3.5753836631774902 | KNN Loss: 3.5697450637817383 | CLS Loss: 0.0056386590003967285\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 3.6065213680267334 | KNN Loss: 3.5842292308807373 | CLS Loss: 0.02229221910238266\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 3.6030256748199463 | KNN Loss: 3.593996524810791 | CLS Loss: 0.00902919378131628\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 3.59574031829834 | KNN Loss: 3.5622966289520264 | CLS Loss: 0.033443599939346313\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 3.6280603408813477 | KNN Loss: 3.597458600997925 | CLS Loss: 0.030601659789681435\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 3.6085050106048584 | KNN Loss: 3.599369764328003 | CLS Loss: 0.009135141968727112\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 3.6053457260131836 | KNN Loss: 3.5853195190429688 | CLS Loss: 0.020026247948408127\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 3.610111713409424 | KNN Loss: 3.6007189750671387 | CLS Loss: 0.009392788633704185\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 3.636930465698242 | KNN Loss: 3.618812322616577 | CLS Loss: 0.018118174746632576\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 3.6278738975524902 | KNN Loss: 3.5871381759643555 | CLS Loss: 0.04073561355471611\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 3.6025807857513428 | KNN Loss: 3.5833194255828857 | CLS Loss: 0.019261376932263374\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 3.600285053253174 | KNN Loss: 3.576307535171509 | CLS Loss: 0.023977486416697502\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 3.591857671737671 | KNN Loss: 3.585645914077759 | CLS Loss: 0.006211677100509405\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 3.645214796066284 | KNN Loss: 3.63032865524292 | CLS Loss: 0.014886201359331608\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 3.6007609367370605 | KNN Loss: 3.588181257247925 | CLS Loss: 0.012579643167555332\n",
      "Epoch: 106, Loss: 3.6182, Train: 0.9954, Valid: 0.9859, Best: 0.9875\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 3.604064702987671 | KNN Loss: 3.591923952102661 | CLS Loss: 0.012140801176428795\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 3.60325288772583 | KNN Loss: 3.5745699405670166 | CLS Loss: 0.028682885691523552\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 3.605147361755371 | KNN Loss: 3.6027944087982178 | CLS Loss: 0.0023529757745563984\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 3.618720769882202 | KNN Loss: 3.612393617630005 | CLS Loss: 0.0063272686675190926\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 3.595069646835327 | KNN Loss: 3.5669736862182617 | CLS Loss: 0.02809591218829155\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 3.5832624435424805 | KNN Loss: 3.5736382007598877 | CLS Loss: 0.009624190628528595\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 3.617957353591919 | KNN Loss: 3.5991575717926025 | CLS Loss: 0.018799863755702972\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 3.616617202758789 | KNN Loss: 3.6055049896240234 | CLS Loss: 0.011112150736153126\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 3.666212320327759 | KNN Loss: 3.6495614051818848 | CLS Loss: 0.01665090024471283\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 3.633589029312134 | KNN Loss: 3.627626419067383 | CLS Loss: 0.00596261490136385\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 3.6117706298828125 | KNN Loss: 3.587059259414673 | CLS Loss: 0.024711398407816887\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 3.6008143424987793 | KNN Loss: 3.597282648086548 | CLS Loss: 0.003531635506078601\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 3.6658310890197754 | KNN Loss: 3.661724805831909 | CLS Loss: 0.004106296692043543\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 3.643437385559082 | KNN Loss: 3.6331663131713867 | CLS Loss: 0.010271153412759304\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 3.601639986038208 | KNN Loss: 3.5989861488342285 | CLS Loss: 0.002653718926012516\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 3.692791700363159 | KNN Loss: 3.675034523010254 | CLS Loss: 0.017757253721356392\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 3.636509895324707 | KNN Loss: 3.631197214126587 | CLS Loss: 0.005312650464475155\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 3.645664930343628 | KNN Loss: 3.640634536743164 | CLS Loss: 0.005030348431318998\n",
      "Epoch: 107, Loss: 3.6193, Train: 0.9967, Valid: 0.9865, Best: 0.9875\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 3.632331132888794 | KNN Loss: 3.6089699268341064 | CLS Loss: 0.023361189290881157\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 3.6047909259796143 | KNN Loss: 3.5926673412323 | CLS Loss: 0.012123611755669117\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 3.649209976196289 | KNN Loss: 3.638970375061035 | CLS Loss: 0.010239574126899242\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 3.581223726272583 | KNN Loss: 3.575197696685791 | CLS Loss: 0.006026132497936487\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 3.6634511947631836 | KNN Loss: 3.632096767425537 | CLS Loss: 0.03135433793067932\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 3.6344082355499268 | KNN Loss: 3.622605323791504 | CLS Loss: 0.011802949011325836\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 3.6043872833251953 | KNN Loss: 3.5954842567443848 | CLS Loss: 0.008902940899133682\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 3.6007273197174072 | KNN Loss: 3.5900185108184814 | CLS Loss: 0.010708754882216454\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 3.591352939605713 | KNN Loss: 3.5613608360290527 | CLS Loss: 0.029992131516337395\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 3.5759222507476807 | KNN Loss: 3.57395076751709 | CLS Loss: 0.0019714345689862967\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 3.6293394565582275 | KNN Loss: 3.619767665863037 | CLS Loss: 0.009571907110512257\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 3.6422698497772217 | KNN Loss: 3.6342761516571045 | CLS Loss: 0.007993637584149837\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 3.6356256008148193 | KNN Loss: 3.616957187652588 | CLS Loss: 0.018668361008167267\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 3.590916872024536 | KNN Loss: 3.573868751525879 | CLS Loss: 0.017048221081495285\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 3.573324680328369 | KNN Loss: 3.5659303665161133 | CLS Loss: 0.007394284009933472\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 3.563992500305176 | KNN Loss: 3.5582356452941895 | CLS Loss: 0.005756966769695282\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 3.699289560317993 | KNN Loss: 3.688164710998535 | CLS Loss: 0.011124767363071442\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 3.606966972351074 | KNN Loss: 3.5968494415283203 | CLS Loss: 0.010117421858012676\n",
      "Epoch: 108, Loss: 3.6121, Train: 0.9952, Valid: 0.9868, Best: 0.9875\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 3.5992627143859863 | KNN Loss: 3.587635040283203 | CLS Loss: 0.011627770960330963\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 3.6529016494750977 | KNN Loss: 3.6316704750061035 | CLS Loss: 0.021231265738606453\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 3.6373047828674316 | KNN Loss: 3.6323611736297607 | CLS Loss: 0.004943583160638809\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 3.6044909954071045 | KNN Loss: 3.5954837799072266 | CLS Loss: 0.009007103741168976\n",
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 3.6210074424743652 | KNN Loss: 3.612105369567871 | CLS Loss: 0.008902044966816902\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 3.600297689437866 | KNN Loss: 3.596312999725342 | CLS Loss: 0.0039847977459430695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 3.6601572036743164 | KNN Loss: 3.632415294647217 | CLS Loss: 0.027741989120841026\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 3.6308915615081787 | KNN Loss: 3.6178839206695557 | CLS Loss: 0.013007537461817265\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 3.621035575866699 | KNN Loss: 3.601595640182495 | CLS Loss: 0.01943988725543022\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 3.573359251022339 | KNN Loss: 3.560431480407715 | CLS Loss: 0.012927884235978127\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 3.6564619541168213 | KNN Loss: 3.6409859657287598 | CLS Loss: 0.015475952066481113\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 3.6041371822357178 | KNN Loss: 3.5755436420440674 | CLS Loss: 0.02859349548816681\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 3.685354471206665 | KNN Loss: 3.671964168548584 | CLS Loss: 0.013390250504016876\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 3.6072723865509033 | KNN Loss: 3.5942487716674805 | CLS Loss: 0.01302355621010065\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 3.6192281246185303 | KNN Loss: 3.609041929244995 | CLS Loss: 0.010186120867729187\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 3.5826733112335205 | KNN Loss: 3.571758270263672 | CLS Loss: 0.010915109887719154\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 3.662376880645752 | KNN Loss: 3.638519287109375 | CLS Loss: 0.02385766990482807\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 3.633558750152588 | KNN Loss: 3.6178019046783447 | CLS Loss: 0.01575683429837227\n",
      "Epoch: 109, Loss: 3.6205, Train: 0.9957, Valid: 0.9863, Best: 0.9875\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 3.621288537979126 | KNN Loss: 3.6071014404296875 | CLS Loss: 0.014187182299792767\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 3.614647388458252 | KNN Loss: 3.6099588871002197 | CLS Loss: 0.004688390530645847\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 3.667956590652466 | KNN Loss: 3.6432998180389404 | CLS Loss: 0.024656731635332108\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 3.6867992877960205 | KNN Loss: 3.668959379196167 | CLS Loss: 0.017839934676885605\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 3.60927152633667 | KNN Loss: 3.599729061126709 | CLS Loss: 0.009542396292090416\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 3.589604377746582 | KNN Loss: 3.5733237266540527 | CLS Loss: 0.016280647367239\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 3.6547799110412598 | KNN Loss: 3.6492321491241455 | CLS Loss: 0.005547758657485247\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 3.630868673324585 | KNN Loss: 3.6238296031951904 | CLS Loss: 0.007039124611765146\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 3.611415147781372 | KNN Loss: 3.5829474925994873 | CLS Loss: 0.028467772528529167\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 3.57212233543396 | KNN Loss: 3.5679361820220947 | CLS Loss: 0.0041860551573336124\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 3.635044574737549 | KNN Loss: 3.6266989707946777 | CLS Loss: 0.0083455890417099\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 3.596395492553711 | KNN Loss: 3.5914270877838135 | CLS Loss: 0.0049683451652526855\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 3.603954553604126 | KNN Loss: 3.5967016220092773 | CLS Loss: 0.007252954412251711\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 3.613710641860962 | KNN Loss: 3.6010477542877197 | CLS Loss: 0.012662984430789948\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 3.610382556915283 | KNN Loss: 3.5883092880249023 | CLS Loss: 0.02207329124212265\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 3.6041407585144043 | KNN Loss: 3.5768463611602783 | CLS Loss: 0.02729448676109314\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 3.608168125152588 | KNN Loss: 3.6016900539398193 | CLS Loss: 0.006478163879364729\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 3.6048595905303955 | KNN Loss: 3.5968165397644043 | CLS Loss: 0.008042982779443264\n",
      "Epoch: 110, Loss: 3.6251, Train: 0.9954, Valid: 0.9861, Best: 0.9875\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 3.6442909240722656 | KNN Loss: 3.6297178268432617 | CLS Loss: 0.014573105610907078\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 3.5911171436309814 | KNN Loss: 3.576767683029175 | CLS Loss: 0.014349574223160744\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 3.6566624641418457 | KNN Loss: 3.6311397552490234 | CLS Loss: 0.025522708892822266\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 3.6253252029418945 | KNN Loss: 3.6026766300201416 | CLS Loss: 0.022648505866527557\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 3.614584445953369 | KNN Loss: 3.607374668121338 | CLS Loss: 0.007209842558950186\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 3.5964736938476562 | KNN Loss: 3.5921852588653564 | CLS Loss: 0.004288527183234692\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 3.5868022441864014 | KNN Loss: 3.564253330230713 | CLS Loss: 0.022548874840140343\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 3.5900938510894775 | KNN Loss: 3.5727217197418213 | CLS Loss: 0.017372196540236473\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 3.5947465896606445 | KNN Loss: 3.573640823364258 | CLS Loss: 0.021105840802192688\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 3.5780632495880127 | KNN Loss: 3.5622034072875977 | CLS Loss: 0.015859799459576607\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 3.6279702186584473 | KNN Loss: 3.6088192462921143 | CLS Loss: 0.019150910899043083\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 3.601010799407959 | KNN Loss: 3.5763120651245117 | CLS Loss: 0.02469862438738346\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 3.5899085998535156 | KNN Loss: 3.5744969844818115 | CLS Loss: 0.015411732718348503\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 3.5848186016082764 | KNN Loss: 3.5664432048797607 | CLS Loss: 0.018375346437096596\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 3.565460443496704 | KNN Loss: 3.5629305839538574 | CLS Loss: 0.002529833232983947\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 3.622386932373047 | KNN Loss: 3.611936569213867 | CLS Loss: 0.010450454428792\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 3.631720542907715 | KNN Loss: 3.605604887008667 | CLS Loss: 0.026115668937563896\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 3.6038637161254883 | KNN Loss: 3.5933828353881836 | CLS Loss: 0.010480792261660099\n",
      "Epoch: 111, Loss: 3.6196, Train: 0.9963, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 3.610934019088745 | KNN Loss: 3.587681770324707 | CLS Loss: 0.023252177983522415\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 3.593513250350952 | KNN Loss: 3.5836215019226074 | CLS Loss: 0.009891660884022713\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 3.5785014629364014 | KNN Loss: 3.57055926322937 | CLS Loss: 0.007942191325128078\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 3.5957610607147217 | KNN Loss: 3.5881431102752686 | CLS Loss: 0.007618037983775139\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 3.605330228805542 | KNN Loss: 3.59063458442688 | CLS Loss: 0.014695648103952408\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 3.6162805557250977 | KNN Loss: 3.6062679290771484 | CLS Loss: 0.010012653656303883\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 3.594665050506592 | KNN Loss: 3.5713608264923096 | CLS Loss: 0.023304181173443794\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 3.5811405181884766 | KNN Loss: 3.5750129222869873 | CLS Loss: 0.006127479951828718\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 3.6427927017211914 | KNN Loss: 3.626347780227661 | CLS Loss: 0.016444863751530647\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 3.6419737339019775 | KNN Loss: 3.6203835010528564 | CLS Loss: 0.021590298041701317\n",
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 3.5918474197387695 | KNN Loss: 3.5877768993377686 | CLS Loss: 0.004070628434419632\n",
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 3.5976898670196533 | KNN Loss: 3.593723773956299 | CLS Loss: 0.003966158255934715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 3.622364044189453 | KNN Loss: 3.6030898094177246 | CLS Loss: 0.019274236634373665\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 3.6354804039001465 | KNN Loss: 3.628413677215576 | CLS Loss: 0.007066616788506508\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 3.6217353343963623 | KNN Loss: 3.6079416275024414 | CLS Loss: 0.013793774880468845\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 3.657914638519287 | KNN Loss: 3.6376898288726807 | CLS Loss: 0.020224811509251595\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 3.6453847885131836 | KNN Loss: 3.6207504272460938 | CLS Loss: 0.024634359404444695\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 3.582343101501465 | KNN Loss: 3.575068950653076 | CLS Loss: 0.007274136412888765\n",
      "Epoch: 112, Loss: 3.6163, Train: 0.9938, Valid: 0.9852, Best: 0.9875\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 3.6486217975616455 | KNN Loss: 3.5922060012817383 | CLS Loss: 0.056415870785713196\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 3.6290454864501953 | KNN Loss: 3.611320734024048 | CLS Loss: 0.01772480458021164\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 3.597102642059326 | KNN Loss: 3.595456600189209 | CLS Loss: 0.0016460806364193559\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 3.6482155323028564 | KNN Loss: 3.6377248764038086 | CLS Loss: 0.010490618646144867\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 3.5817651748657227 | KNN Loss: 3.5686872005462646 | CLS Loss: 0.013077947311103344\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 3.662670612335205 | KNN Loss: 3.6430411338806152 | CLS Loss: 0.01962951011955738\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 3.5741324424743652 | KNN Loss: 3.5678601264953613 | CLS Loss: 0.006272283848375082\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 3.5996501445770264 | KNN Loss: 3.5861334800720215 | CLS Loss: 0.013516576029360294\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 3.5755317211151123 | KNN Loss: 3.562255859375 | CLS Loss: 0.01327577792108059\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 3.6540064811706543 | KNN Loss: 3.631253719329834 | CLS Loss: 0.022752709686756134\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 3.583319664001465 | KNN Loss: 3.570568084716797 | CLS Loss: 0.012751634232699871\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 3.666877269744873 | KNN Loss: 3.624171733856201 | CLS Loss: 0.0427054762840271\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 3.5995466709136963 | KNN Loss: 3.56237530708313 | CLS Loss: 0.03717142343521118\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 3.6491482257843018 | KNN Loss: 3.6233530044555664 | CLS Loss: 0.02579517662525177\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 3.6023597717285156 | KNN Loss: 3.5912516117095947 | CLS Loss: 0.011108244769275188\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 3.5968892574310303 | KNN Loss: 3.5759775638580322 | CLS Loss: 0.020911796018481255\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 3.596402168273926 | KNN Loss: 3.593719244003296 | CLS Loss: 0.0026828451082110405\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 3.6144142150878906 | KNN Loss: 3.593693971633911 | CLS Loss: 0.02072024717926979\n",
      "Epoch: 113, Loss: 3.6185, Train: 0.9959, Valid: 0.9862, Best: 0.9875\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 3.5966451168060303 | KNN Loss: 3.5880849361419678 | CLS Loss: 0.008560161106288433\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 3.6525464057922363 | KNN Loss: 3.6370036602020264 | CLS Loss: 0.015542713925242424\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 3.5964841842651367 | KNN Loss: 3.589339017868042 | CLS Loss: 0.00714519340544939\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 3.5938785076141357 | KNN Loss: 3.5812582969665527 | CLS Loss: 0.012620148248970509\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 3.572988271713257 | KNN Loss: 3.5690290927886963 | CLS Loss: 0.003959132824093103\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 3.638418674468994 | KNN Loss: 3.608812093734741 | CLS Loss: 0.029606670141220093\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 3.6057209968566895 | KNN Loss: 3.5716609954833984 | CLS Loss: 0.03406006470322609\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 3.6116323471069336 | KNN Loss: 3.5876142978668213 | CLS Loss: 0.02401793748140335\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 3.6427102088928223 | KNN Loss: 3.624366521835327 | CLS Loss: 0.018343713134527206\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 3.614132881164551 | KNN Loss: 3.5967164039611816 | CLS Loss: 0.01741637848317623\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 3.607870101928711 | KNN Loss: 3.5904037952423096 | CLS Loss: 0.017466265708208084\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 3.611367702484131 | KNN Loss: 3.6020662784576416 | CLS Loss: 0.009301376529037952\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 3.565298318862915 | KNN Loss: 3.5591506958007812 | CLS Loss: 0.006147656124085188\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 3.597548484802246 | KNN Loss: 3.583533525466919 | CLS Loss: 0.014015011489391327\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 3.6568660736083984 | KNN Loss: 3.631044864654541 | CLS Loss: 0.025821276009082794\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 3.629696846008301 | KNN Loss: 3.616603374481201 | CLS Loss: 0.013093432411551476\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 3.6279220581054688 | KNN Loss: 3.601470470428467 | CLS Loss: 0.02645164169371128\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 3.600578784942627 | KNN Loss: 3.5961947441101074 | CLS Loss: 0.0043840110301971436\n",
      "Epoch: 114, Loss: 3.6106, Train: 0.9969, Valid: 0.9877, Best: 0.9877\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 3.592726945877075 | KNN Loss: 3.589338541030884 | CLS Loss: 0.0033884739968925714\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 3.575685977935791 | KNN Loss: 3.5738630294799805 | CLS Loss: 0.0018230213318020105\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 3.5838959217071533 | KNN Loss: 3.5765702724456787 | CLS Loss: 0.00732570281252265\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 3.6111843585968018 | KNN Loss: 3.607264518737793 | CLS Loss: 0.003919947426766157\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 3.622567892074585 | KNN Loss: 3.6036055088043213 | CLS Loss: 0.018962286412715912\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 3.6430490016937256 | KNN Loss: 3.634063243865967 | CLS Loss: 0.008985733613371849\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 3.586207389831543 | KNN Loss: 3.5700459480285645 | CLS Loss: 0.016161488369107246\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 3.6242480278015137 | KNN Loss: 3.608111619949341 | CLS Loss: 0.01613638922572136\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 3.600069284439087 | KNN Loss: 3.597006320953369 | CLS Loss: 0.0030629930552095175\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 3.5827629566192627 | KNN Loss: 3.5758986473083496 | CLS Loss: 0.006864393595606089\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 3.610471248626709 | KNN Loss: 3.6010665893554688 | CLS Loss: 0.009404642507433891\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 3.5887675285339355 | KNN Loss: 3.5829508304595947 | CLS Loss: 0.005816635210067034\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 3.5851922035217285 | KNN Loss: 3.57920503616333 | CLS Loss: 0.005987182259559631\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 3.600283622741699 | KNN Loss: 3.5865583419799805 | CLS Loss: 0.013725332915782928\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 3.625620126724243 | KNN Loss: 3.6105518341064453 | CLS Loss: 0.015068250708281994\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 3.5827245712280273 | KNN Loss: 3.574368715286255 | CLS Loss: 0.008355970494449139\n",
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 3.663412570953369 | KNN Loss: 3.6551308631896973 | CLS Loss: 0.00828163605183363\n",
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 3.6162831783294678 | KNN Loss: 3.6002578735351562 | CLS Loss: 0.016025200486183167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115, Loss: 3.6127, Train: 0.9965, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 3.6561129093170166 | KNN Loss: 3.6365363597869873 | CLS Loss: 0.019576620310544968\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 3.638606071472168 | KNN Loss: 3.6319005489349365 | CLS Loss: 0.006705405190587044\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 3.5630295276641846 | KNN Loss: 3.542226552963257 | CLS Loss: 0.02080288715660572\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 3.705322027206421 | KNN Loss: 3.668548345565796 | CLS Loss: 0.03677358105778694\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 3.5994927883148193 | KNN Loss: 3.591642379760742 | CLS Loss: 0.00785032194107771\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 3.600027322769165 | KNN Loss: 3.594968795776367 | CLS Loss: 0.005058483220636845\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 3.6387765407562256 | KNN Loss: 3.626321792602539 | CLS Loss: 0.012454641051590443\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 3.6165273189544678 | KNN Loss: 3.614161968231201 | CLS Loss: 0.002365285065025091\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 3.597398042678833 | KNN Loss: 3.5798115730285645 | CLS Loss: 0.017586497589945793\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 3.586884021759033 | KNN Loss: 3.5773158073425293 | CLS Loss: 0.00956813246011734\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 3.620851516723633 | KNN Loss: 3.592947006225586 | CLS Loss: 0.027904482558369637\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 3.619081735610962 | KNN Loss: 3.612745523452759 | CLS Loss: 0.006336106453090906\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 3.601144313812256 | KNN Loss: 3.5906283855438232 | CLS Loss: 0.010515986010432243\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 3.5926260948181152 | KNN Loss: 3.582461357116699 | CLS Loss: 0.010164621286094189\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 3.6047072410583496 | KNN Loss: 3.5634074211120605 | CLS Loss: 0.04129975661635399\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 3.6165525913238525 | KNN Loss: 3.6128506660461426 | CLS Loss: 0.0037019713781774044\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 3.648707151412964 | KNN Loss: 3.618379831314087 | CLS Loss: 0.030327262356877327\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 3.5900156497955322 | KNN Loss: 3.582852602005005 | CLS Loss: 0.0071631078608334064\n",
      "Epoch: 116, Loss: 3.6159, Train: 0.9968, Valid: 0.9870, Best: 0.9877\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 3.6185646057128906 | KNN Loss: 3.6012253761291504 | CLS Loss: 0.017339326441287994\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 3.620786666870117 | KNN Loss: 3.61863112449646 | CLS Loss: 0.002155578462406993\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 3.600208282470703 | KNN Loss: 3.5799129009246826 | CLS Loss: 0.020295264199376106\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 3.60854434967041 | KNN Loss: 3.6030659675598145 | CLS Loss: 0.005478438921272755\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 3.597526788711548 | KNN Loss: 3.5865771770477295 | CLS Loss: 0.010949557647109032\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 3.6167075634002686 | KNN Loss: 3.5972933769226074 | CLS Loss: 0.019414294511079788\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 3.592289686203003 | KNN Loss: 3.5581140518188477 | CLS Loss: 0.034175530076026917\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 3.629730701446533 | KNN Loss: 3.627385139465332 | CLS Loss: 0.0023455354385077953\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 3.5849485397338867 | KNN Loss: 3.5658488273620605 | CLS Loss: 0.019099682569503784\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 3.6382246017456055 | KNN Loss: 3.6155357360839844 | CLS Loss: 0.02268880605697632\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 3.6761186122894287 | KNN Loss: 3.646611452102661 | CLS Loss: 0.029507052153348923\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 3.5908586978912354 | KNN Loss: 3.578439474105835 | CLS Loss: 0.012419290840625763\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 3.6035871505737305 | KNN Loss: 3.5973095893859863 | CLS Loss: 0.006277464795857668\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 3.5724565982818604 | KNN Loss: 3.556546449661255 | CLS Loss: 0.01591009460389614\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 3.6230432987213135 | KNN Loss: 3.617729663848877 | CLS Loss: 0.0053135668858885765\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 3.6423277854919434 | KNN Loss: 3.618088722229004 | CLS Loss: 0.024239035323262215\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 3.593796968460083 | KNN Loss: 3.5884714126586914 | CLS Loss: 0.0053254892118275166\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 3.645848035812378 | KNN Loss: 3.6381168365478516 | CLS Loss: 0.007731302175670862\n",
      "Epoch: 117, Loss: 3.6203, Train: 0.9949, Valid: 0.9849, Best: 0.9877\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 3.668076992034912 | KNN Loss: 3.653534173965454 | CLS Loss: 0.01454270537942648\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 3.5783803462982178 | KNN Loss: 3.5726492404937744 | CLS Loss: 0.005731157027184963\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 3.6552131175994873 | KNN Loss: 3.6090784072875977 | CLS Loss: 0.04613474756479263\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 3.5621819496154785 | KNN Loss: 3.547023057937622 | CLS Loss: 0.015158929862082005\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 3.6172075271606445 | KNN Loss: 3.608492374420166 | CLS Loss: 0.008715220727026463\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 3.5974838733673096 | KNN Loss: 3.5768322944641113 | CLS Loss: 0.02065166085958481\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 3.6305692195892334 | KNN Loss: 3.6246938705444336 | CLS Loss: 0.005875434260815382\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 3.678809404373169 | KNN Loss: 3.6375253200531006 | CLS Loss: 0.04128419607877731\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 3.6407763957977295 | KNN Loss: 3.630129337310791 | CLS Loss: 0.010647115297615528\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 3.5729923248291016 | KNN Loss: 3.558824300765991 | CLS Loss: 0.014168083667755127\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 3.5821330547332764 | KNN Loss: 3.5573761463165283 | CLS Loss: 0.02475687861442566\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 3.6294498443603516 | KNN Loss: 3.5930190086364746 | CLS Loss: 0.03643093630671501\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 3.592681407928467 | KNN Loss: 3.5864059925079346 | CLS Loss: 0.00627541309222579\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 3.6029627323150635 | KNN Loss: 3.5933573246002197 | CLS Loss: 0.009605331346392632\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 3.593348979949951 | KNN Loss: 3.579824209213257 | CLS Loss: 0.013524660840630531\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 3.594607353210449 | KNN Loss: 3.580044746398926 | CLS Loss: 0.014562518335878849\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 3.627225637435913 | KNN Loss: 3.6107349395751953 | CLS Loss: 0.016490798443555832\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 3.5743300914764404 | KNN Loss: 3.5486114025115967 | CLS Loss: 0.02571864239871502\n",
      "Epoch: 118, Loss: 3.6135, Train: 0.9965, Valid: 0.9872, Best: 0.9877\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 3.578969717025757 | KNN Loss: 3.575347423553467 | CLS Loss: 0.0036222657654434443\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 3.5979790687561035 | KNN Loss: 3.590428113937378 | CLS Loss: 0.007551036309450865\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 3.5935137271881104 | KNN Loss: 3.5895142555236816 | CLS Loss: 0.0039995755068957806\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 3.5991768836975098 | KNN Loss: 3.5804696083068848 | CLS Loss: 0.018707269802689552\n",
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 3.6254310607910156 | KNN Loss: 3.6156246662139893 | CLS Loss: 0.0098063750192523\n",
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 3.6087803840637207 | KNN Loss: 3.6056900024414062 | CLS Loss: 0.0030904496088624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 3.6527762413024902 | KNN Loss: 3.616206645965576 | CLS Loss: 0.036569613963365555\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 3.6106479167938232 | KNN Loss: 3.591291904449463 | CLS Loss: 0.01935601606965065\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 3.583786725997925 | KNN Loss: 3.5602989196777344 | CLS Loss: 0.023487897589802742\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 3.5860371589660645 | KNN Loss: 3.57378888130188 | CLS Loss: 0.01224822923541069\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 3.641547203063965 | KNN Loss: 3.6205272674560547 | CLS Loss: 0.02101999707520008\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 3.5877671241760254 | KNN Loss: 3.569577932357788 | CLS Loss: 0.018189137801527977\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 3.5822908878326416 | KNN Loss: 3.559713125228882 | CLS Loss: 0.022577764466404915\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 3.685929775238037 | KNN Loss: 3.660444736480713 | CLS Loss: 0.02548498846590519\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 3.604175567626953 | KNN Loss: 3.5851666927337646 | CLS Loss: 0.019008956849575043\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 3.6248955726623535 | KNN Loss: 3.620513916015625 | CLS Loss: 0.004381596110761166\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 3.6030468940734863 | KNN Loss: 3.594543218612671 | CLS Loss: 0.008503688499331474\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 3.5802552700042725 | KNN Loss: 3.5738210678100586 | CLS Loss: 0.006434236653149128\n",
      "Epoch: 119, Loss: 3.6155, Train: 0.9962, Valid: 0.9866, Best: 0.9877\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 3.5882205963134766 | KNN Loss: 3.5834732055664062 | CLS Loss: 0.00474731856957078\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 3.677854299545288 | KNN Loss: 3.6595773696899414 | CLS Loss: 0.018276963382959366\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 3.6448936462402344 | KNN Loss: 3.622986316680908 | CLS Loss: 0.021907251328229904\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 3.6234548091888428 | KNN Loss: 3.6107494831085205 | CLS Loss: 0.012705432251095772\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 3.5906007289886475 | KNN Loss: 3.5807392597198486 | CLS Loss: 0.009861528873443604\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 3.6254124641418457 | KNN Loss: 3.613314151763916 | CLS Loss: 0.012098265811800957\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 3.658921241760254 | KNN Loss: 3.6252682209014893 | CLS Loss: 0.033652983605861664\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 3.6252329349517822 | KNN Loss: 3.586852788925171 | CLS Loss: 0.038380153477191925\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 3.594094753265381 | KNN Loss: 3.591275930404663 | CLS Loss: 0.0028187723364681005\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 3.599273920059204 | KNN Loss: 3.578486919403076 | CLS Loss: 0.020787013694643974\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 3.6567461490631104 | KNN Loss: 3.6328861713409424 | CLS Loss: 0.023859888315200806\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 3.5778632164001465 | KNN Loss: 3.5725820064544678 | CLS Loss: 0.00528126722201705\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 3.671780586242676 | KNN Loss: 3.6547906398773193 | CLS Loss: 0.016989830881357193\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 3.598757266998291 | KNN Loss: 3.586824655532837 | CLS Loss: 0.011932650581002235\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 3.690500497817993 | KNN Loss: 3.6734654903411865 | CLS Loss: 0.017034990713000298\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 3.5997350215911865 | KNN Loss: 3.586988925933838 | CLS Loss: 0.012746160849928856\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 3.595834732055664 | KNN Loss: 3.5932295322418213 | CLS Loss: 0.0026052328757941723\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 3.5876383781433105 | KNN Loss: 3.5755889415740967 | CLS Loss: 0.012049511075019836\n",
      "Epoch: 120, Loss: 3.6205, Train: 0.9964, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 3.560213804244995 | KNN Loss: 3.554535150527954 | CLS Loss: 0.005678587593138218\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 3.5810468196868896 | KNN Loss: 3.5776264667510986 | CLS Loss: 0.0034202798269689083\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 3.5534896850585938 | KNN Loss: 3.5477612018585205 | CLS Loss: 0.005728399381041527\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 3.600886106491089 | KNN Loss: 3.589911937713623 | CLS Loss: 0.010974221862852573\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 3.594940185546875 | KNN Loss: 3.587512731552124 | CLS Loss: 0.007427549455314875\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 3.5949764251708984 | KNN Loss: 3.5787301063537598 | CLS Loss: 0.01624620147049427\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 3.560724973678589 | KNN Loss: 3.551914930343628 | CLS Loss: 0.00881011039018631\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 3.67585825920105 | KNN Loss: 3.6610920429229736 | CLS Loss: 0.014766117557883263\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 3.62845516204834 | KNN Loss: 3.5959360599517822 | CLS Loss: 0.032519008964300156\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 3.5866613388061523 | KNN Loss: 3.568305730819702 | CLS Loss: 0.01835549622774124\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 3.5948801040649414 | KNN Loss: 3.587923049926758 | CLS Loss: 0.006957121193408966\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 3.6151890754699707 | KNN Loss: 3.6023988723754883 | CLS Loss: 0.012790252454578876\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 3.5709903240203857 | KNN Loss: 3.551144599914551 | CLS Loss: 0.019845619797706604\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 3.622243881225586 | KNN Loss: 3.6137428283691406 | CLS Loss: 0.008501021191477776\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 3.6292715072631836 | KNN Loss: 3.604304075241089 | CLS Loss: 0.024967478588223457\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 3.616823673248291 | KNN Loss: 3.6014013290405273 | CLS Loss: 0.015422404743731022\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 3.6511237621307373 | KNN Loss: 3.6250362396240234 | CLS Loss: 0.026087520644068718\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 3.6088500022888184 | KNN Loss: 3.6065726280212402 | CLS Loss: 0.002277286956086755\n",
      "Epoch: 121, Loss: 3.6080, Train: 0.9966, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 3.5850703716278076 | KNN Loss: 3.5793721675872803 | CLS Loss: 0.005698281805962324\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 3.6001598834991455 | KNN Loss: 3.5963850021362305 | CLS Loss: 0.0037748233880847692\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 3.6025612354278564 | KNN Loss: 3.598022222518921 | CLS Loss: 0.004539095796644688\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 3.606825351715088 | KNN Loss: 3.6001040935516357 | CLS Loss: 0.006721204146742821\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 3.5797622203826904 | KNN Loss: 3.5704586505889893 | CLS Loss: 0.009303675964474678\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 3.5705440044403076 | KNN Loss: 3.5532922744750977 | CLS Loss: 0.017251675948500633\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 3.6163170337677 | KNN Loss: 3.594144344329834 | CLS Loss: 0.02217257395386696\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 3.57913875579834 | KNN Loss: 3.5753090381622314 | CLS Loss: 0.003829612862318754\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 3.5855660438537598 | KNN Loss: 3.5575647354125977 | CLS Loss: 0.02800123393535614\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 3.6058127880096436 | KNN Loss: 3.5903451442718506 | CLS Loss: 0.015467559918761253\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 3.6463470458984375 | KNN Loss: 3.6335062980651855 | CLS Loss: 0.012840840965509415\n",
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 3.6005654335021973 | KNN Loss: 3.5765457153320312 | CLS Loss: 0.024019645527005196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 3.6100127696990967 | KNN Loss: 3.5973424911499023 | CLS Loss: 0.012670342810451984\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 3.573925733566284 | KNN Loss: 3.5707552433013916 | CLS Loss: 0.0031705701258033514\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 3.644120931625366 | KNN Loss: 3.6242971420288086 | CLS Loss: 0.019823750481009483\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 3.5831189155578613 | KNN Loss: 3.5766780376434326 | CLS Loss: 0.006440938916057348\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 3.5909249782562256 | KNN Loss: 3.5724759101867676 | CLS Loss: 0.018449164927005768\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 3.6484649181365967 | KNN Loss: 3.6397483348846436 | CLS Loss: 0.008716619573533535\n",
      "Epoch: 122, Loss: 3.6143, Train: 0.9949, Valid: 0.9844, Best: 0.9877\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 3.5803630352020264 | KNN Loss: 3.5702266693115234 | CLS Loss: 0.010136437602341175\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 3.5878405570983887 | KNN Loss: 3.5834295749664307 | CLS Loss: 0.004410888999700546\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 3.5898475646972656 | KNN Loss: 3.5841665267944336 | CLS Loss: 0.005680963397026062\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 3.593371868133545 | KNN Loss: 3.5854926109313965 | CLS Loss: 0.007879231125116348\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 3.627664566040039 | KNN Loss: 3.607903003692627 | CLS Loss: 0.019761662930250168\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 3.598391532897949 | KNN Loss: 3.5713882446289062 | CLS Loss: 0.027003170922398567\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 3.589905261993408 | KNN Loss: 3.5713932514190674 | CLS Loss: 0.018512025475502014\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 3.647313117980957 | KNN Loss: 3.6294825077056885 | CLS Loss: 0.017830606549978256\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 3.590331792831421 | KNN Loss: 3.5777952671051025 | CLS Loss: 0.012536426074802876\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 3.5686845779418945 | KNN Loss: 3.5670149326324463 | CLS Loss: 0.0016696242382749915\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 3.560511350631714 | KNN Loss: 3.5461270809173584 | CLS Loss: 0.01438421942293644\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 3.633162498474121 | KNN Loss: 3.6219077110290527 | CLS Loss: 0.011254770681262016\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 3.64048433303833 | KNN Loss: 3.612678289413452 | CLS Loss: 0.027806028723716736\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 3.5965781211853027 | KNN Loss: 3.5769577026367188 | CLS Loss: 0.019620472565293312\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 3.6044414043426514 | KNN Loss: 3.5940537452697754 | CLS Loss: 0.010387551039457321\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 3.652085542678833 | KNN Loss: 3.6447198390960693 | CLS Loss: 0.00736560532823205\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 3.6513843536376953 | KNN Loss: 3.6275925636291504 | CLS Loss: 0.023791883140802383\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 3.623739242553711 | KNN Loss: 3.6082663536071777 | CLS Loss: 0.01547299511730671\n",
      "Epoch: 123, Loss: 3.6135, Train: 0.9963, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 3.5801661014556885 | KNN Loss: 3.5756077766418457 | CLS Loss: 0.004558276850730181\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 3.617870569229126 | KNN Loss: 3.592116355895996 | CLS Loss: 0.025754310190677643\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 3.6039397716522217 | KNN Loss: 3.5835680961608887 | CLS Loss: 0.020371627062559128\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 3.597447156906128 | KNN Loss: 3.5920417308807373 | CLS Loss: 0.005405494477599859\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 3.595992088317871 | KNN Loss: 3.5755631923675537 | CLS Loss: 0.020428812131285667\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 3.64894437789917 | KNN Loss: 3.6321709156036377 | CLS Loss: 0.01677345111966133\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 3.622424602508545 | KNN Loss: 3.6022791862487793 | CLS Loss: 0.020145358517766\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 3.598010778427124 | KNN Loss: 3.5714030265808105 | CLS Loss: 0.02660783752799034\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 3.632169485092163 | KNN Loss: 3.6019630432128906 | CLS Loss: 0.030206410214304924\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 3.681271553039551 | KNN Loss: 3.6598892211914062 | CLS Loss: 0.021382395178079605\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 3.582247018814087 | KNN Loss: 3.5757932662963867 | CLS Loss: 0.006453725043684244\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 3.6013975143432617 | KNN Loss: 3.5768208503723145 | CLS Loss: 0.02457674965262413\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 3.6144182682037354 | KNN Loss: 3.5987234115600586 | CLS Loss: 0.015694759786128998\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 3.604868173599243 | KNN Loss: 3.5780770778656006 | CLS Loss: 0.026791026815772057\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 3.611577272415161 | KNN Loss: 3.603477954864502 | CLS Loss: 0.008099268190562725\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 3.6043105125427246 | KNN Loss: 3.5966498851776123 | CLS Loss: 0.0076606362126767635\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 3.613996982574463 | KNN Loss: 3.598820686340332 | CLS Loss: 0.015176281332969666\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 3.6212685108184814 | KNN Loss: 3.592599630355835 | CLS Loss: 0.02866888977587223\n",
      "Epoch: 124, Loss: 3.6175, Train: 0.9964, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 3.6364102363586426 | KNN Loss: 3.6286513805389404 | CLS Loss: 0.007758777588605881\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 3.5959036350250244 | KNN Loss: 3.5649585723876953 | CLS Loss: 0.03094514273107052\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 3.6136457920074463 | KNN Loss: 3.6046972274780273 | CLS Loss: 0.008948465809226036\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 3.6058106422424316 | KNN Loss: 3.598813533782959 | CLS Loss: 0.006997030694037676\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 3.630986213684082 | KNN Loss: 3.5880093574523926 | CLS Loss: 0.04297681897878647\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 3.591082811355591 | KNN Loss: 3.5728585720062256 | CLS Loss: 0.018224326893687248\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 3.616405487060547 | KNN Loss: 3.605942487716675 | CLS Loss: 0.010463026352226734\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 3.5921874046325684 | KNN Loss: 3.5884439945220947 | CLS Loss: 0.0037434936966747046\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 3.604266405105591 | KNN Loss: 3.5951156616210938 | CLS Loss: 0.009150746278464794\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 3.6266870498657227 | KNN Loss: 3.6240906715393066 | CLS Loss: 0.002596392994746566\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 3.6394426822662354 | KNN Loss: 3.6334242820739746 | CLS Loss: 0.006018450949341059\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 3.6091091632843018 | KNN Loss: 3.6023099422454834 | CLS Loss: 0.00679923826828599\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 3.609952688217163 | KNN Loss: 3.5829362869262695 | CLS Loss: 0.02701636217534542\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 3.66753888130188 | KNN Loss: 3.644622325897217 | CLS Loss: 0.022916492074728012\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 3.606125593185425 | KNN Loss: 3.5644030570983887 | CLS Loss: 0.04172256588935852\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 3.6273491382598877 | KNN Loss: 3.60170316696167 | CLS Loss: 0.025645911693572998\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 3.5896551609039307 | KNN Loss: 3.580264091491699 | CLS Loss: 0.00939097534865141\n",
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 3.5963058471679688 | KNN Loss: 3.553779363632202 | CLS Loss: 0.04252644628286362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125, Loss: 3.6164, Train: 0.9963, Valid: 0.9866, Best: 0.9877\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 3.5924618244171143 | KNN Loss: 3.575559139251709 | CLS Loss: 0.016902752220630646\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 3.598458766937256 | KNN Loss: 3.582456350326538 | CLS Loss: 0.01600247249007225\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 3.594820737838745 | KNN Loss: 3.584144115447998 | CLS Loss: 0.010676519013941288\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 3.5910470485687256 | KNN Loss: 3.5745248794555664 | CLS Loss: 0.01652228645980358\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 3.579653739929199 | KNN Loss: 3.5648913383483887 | CLS Loss: 0.014762460254132748\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 3.574450731277466 | KNN Loss: 3.5623207092285156 | CLS Loss: 0.012129954993724823\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 3.6342904567718506 | KNN Loss: 3.6186904907226562 | CLS Loss: 0.015599938109517097\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 3.621595859527588 | KNN Loss: 3.6176388263702393 | CLS Loss: 0.003957142122089863\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 3.5843889713287354 | KNN Loss: 3.5785160064697266 | CLS Loss: 0.005872874055057764\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 3.5949761867523193 | KNN Loss: 3.5847480297088623 | CLS Loss: 0.010228161700069904\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 3.6314752101898193 | KNN Loss: 3.6096742153167725 | CLS Loss: 0.02180088311433792\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 3.615473508834839 | KNN Loss: 3.58782958984375 | CLS Loss: 0.027643851935863495\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 3.619210958480835 | KNN Loss: 3.593024730682373 | CLS Loss: 0.026186294853687286\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 3.5810706615448 | KNN Loss: 3.557812213897705 | CLS Loss: 0.023258410394191742\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 3.6121418476104736 | KNN Loss: 3.592982292175293 | CLS Loss: 0.019159458577632904\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 3.6708967685699463 | KNN Loss: 3.665593385696411 | CLS Loss: 0.0053034513257443905\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 3.646390676498413 | KNN Loss: 3.6284866333007812 | CLS Loss: 0.017904052510857582\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 3.6085803508758545 | KNN Loss: 3.6050608158111572 | CLS Loss: 0.0035195164382457733\n",
      "Epoch: 126, Loss: 3.6160, Train: 0.9969, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 3.588296890258789 | KNN Loss: 3.5738351345062256 | CLS Loss: 0.014461696147918701\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 3.5956075191497803 | KNN Loss: 3.581970691680908 | CLS Loss: 0.013636940158903599\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 3.567046642303467 | KNN Loss: 3.5594303607940674 | CLS Loss: 0.007616362068802118\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 3.5845699310302734 | KNN Loss: 3.570875406265259 | CLS Loss: 0.01369456946849823\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 3.6201560497283936 | KNN Loss: 3.6117284297943115 | CLS Loss: 0.00842768419533968\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 3.664325714111328 | KNN Loss: 3.6594512462615967 | CLS Loss: 0.004874572157859802\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 3.574552536010742 | KNN Loss: 3.55564284324646 | CLS Loss: 0.018909724429249763\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 3.6292850971221924 | KNN Loss: 3.628166913986206 | CLS Loss: 0.0011180788278579712\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 3.609677791595459 | KNN Loss: 3.5810675621032715 | CLS Loss: 0.02861032821238041\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 3.613208770751953 | KNN Loss: 3.58575439453125 | CLS Loss: 0.027454424649477005\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 3.5675606727600098 | KNN Loss: 3.5616447925567627 | CLS Loss: 0.005915800109505653\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 3.6184847354888916 | KNN Loss: 3.604771852493286 | CLS Loss: 0.013712780550122261\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 3.6352221965789795 | KNN Loss: 3.5927481651306152 | CLS Loss: 0.04247403144836426\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 3.608651638031006 | KNN Loss: 3.567784070968628 | CLS Loss: 0.040867630392313004\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 3.576328992843628 | KNN Loss: 3.5731301307678223 | CLS Loss: 0.003198769176378846\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 3.597311019897461 | KNN Loss: 3.5950868129730225 | CLS Loss: 0.0022241296246647835\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 3.622063398361206 | KNN Loss: 3.6140217781066895 | CLS Loss: 0.008041635155677795\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 3.624175548553467 | KNN Loss: 3.6140947341918945 | CLS Loss: 0.010080793872475624\n",
      "Epoch: 127, Loss: 3.6081, Train: 0.9956, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 3.584108352661133 | KNN Loss: 3.5796868801116943 | CLS Loss: 0.004421405028551817\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 3.5597116947174072 | KNN Loss: 3.5503671169281006 | CLS Loss: 0.009344459511339664\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 3.5851850509643555 | KNN Loss: 3.579345226287842 | CLS Loss: 0.005839845631271601\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 3.6076953411102295 | KNN Loss: 3.5956151485443115 | CLS Loss: 0.012080102227628231\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 3.6452600955963135 | KNN Loss: 3.628347635269165 | CLS Loss: 0.016912495717406273\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 3.6126184463500977 | KNN Loss: 3.5828232765197754 | CLS Loss: 0.029795274138450623\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 3.604966163635254 | KNN Loss: 3.600078821182251 | CLS Loss: 0.004887372255325317\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 3.6300160884857178 | KNN Loss: 3.574793815612793 | CLS Loss: 0.055222246795892715\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 3.5986950397491455 | KNN Loss: 3.583798885345459 | CLS Loss: 0.014896092936396599\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 3.5845532417297363 | KNN Loss: 3.578278064727783 | CLS Loss: 0.006275290623307228\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 3.61618709564209 | KNN Loss: 3.585008144378662 | CLS Loss: 0.03117886744439602\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 3.677605628967285 | KNN Loss: 3.654973030090332 | CLS Loss: 0.022632485255599022\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 3.614980459213257 | KNN Loss: 3.6064164638519287 | CLS Loss: 0.008563943207263947\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 3.6195461750030518 | KNN Loss: 3.6081395149230957 | CLS Loss: 0.011406747624278069\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 3.590139865875244 | KNN Loss: 3.5821962356567383 | CLS Loss: 0.007943530566990376\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 3.608435869216919 | KNN Loss: 3.5807912349700928 | CLS Loss: 0.02764471247792244\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 3.6141860485076904 | KNN Loss: 3.6008994579315186 | CLS Loss: 0.013286489993333817\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 3.5735504627227783 | KNN Loss: 3.5684218406677246 | CLS Loss: 0.005128568038344383\n",
      "Epoch: 128, Loss: 3.6145, Train: 0.9968, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 3.6012613773345947 | KNN Loss: 3.5937886238098145 | CLS Loss: 0.007472708355635405\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 3.6046557426452637 | KNN Loss: 3.5980441570281982 | CLS Loss: 0.006611562799662352\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 3.605536937713623 | KNN Loss: 3.5981171131134033 | CLS Loss: 0.007419813424348831\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 3.6009421348571777 | KNN Loss: 3.586740016937256 | CLS Loss: 0.014202152378857136\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 3.5831966400146484 | KNN Loss: 3.5737240314483643 | CLS Loss: 0.009472490288317204\n",
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 3.5718090534210205 | KNN Loss: 3.560483932495117 | CLS Loss: 0.011325053870677948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 3.5673868656158447 | KNN Loss: 3.561445713043213 | CLS Loss: 0.005941166076809168\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 3.6052794456481934 | KNN Loss: 3.601505756378174 | CLS Loss: 0.0037736310623586178\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 3.6172239780426025 | KNN Loss: 3.6154584884643555 | CLS Loss: 0.0017655410338193178\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 3.5998589992523193 | KNN Loss: 3.5767412185668945 | CLS Loss: 0.023117845878005028\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 3.630061626434326 | KNN Loss: 3.6064648628234863 | CLS Loss: 0.02359664998948574\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 3.624075412750244 | KNN Loss: 3.611659526824951 | CLS Loss: 0.01241578720510006\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 3.594989538192749 | KNN Loss: 3.583191156387329 | CLS Loss: 0.011798477731645107\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 3.6117427349090576 | KNN Loss: 3.6038460731506348 | CLS Loss: 0.007896663621068\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 3.558436393737793 | KNN Loss: 3.550584554672241 | CLS Loss: 0.007851872593164444\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 3.591938018798828 | KNN Loss: 3.57767391204834 | CLS Loss: 0.014264092780649662\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 3.61428165435791 | KNN Loss: 3.590424060821533 | CLS Loss: 0.02385748364031315\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 3.616821050643921 | KNN Loss: 3.5822486877441406 | CLS Loss: 0.03457225486636162\n",
      "Epoch: 129, Loss: 3.6103, Train: 0.9963, Valid: 0.9866, Best: 0.9877\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 3.613640546798706 | KNN Loss: 3.604050874710083 | CLS Loss: 0.00958956778049469\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 3.6214771270751953 | KNN Loss: 3.6068532466888428 | CLS Loss: 0.014623885974287987\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 3.5816259384155273 | KNN Loss: 3.5611860752105713 | CLS Loss: 0.02043979987502098\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 3.577763557434082 | KNN Loss: 3.5752100944519043 | CLS Loss: 0.002553545404225588\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 3.644906997680664 | KNN Loss: 3.6381759643554688 | CLS Loss: 0.006730955559760332\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 3.633584976196289 | KNN Loss: 3.6213765144348145 | CLS Loss: 0.01220841333270073\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 3.596022367477417 | KNN Loss: 3.5927367210388184 | CLS Loss: 0.0032857630867511034\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 3.6184616088867188 | KNN Loss: 3.612197160720825 | CLS Loss: 0.006264545954763889\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 3.6680164337158203 | KNN Loss: 3.660572052001953 | CLS Loss: 0.007444399408996105\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 3.590920925140381 | KNN Loss: 3.575383186340332 | CLS Loss: 0.015537707135081291\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 3.601182460784912 | KNN Loss: 3.590437889099121 | CLS Loss: 0.010744462721049786\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 3.662686824798584 | KNN Loss: 3.655982255935669 | CLS Loss: 0.006704600993543863\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 3.581024646759033 | KNN Loss: 3.570782423019409 | CLS Loss: 0.010242296382784843\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 3.6168558597564697 | KNN Loss: 3.6137607097625732 | CLS Loss: 0.003095032414421439\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 3.619569778442383 | KNN Loss: 3.5835063457489014 | CLS Loss: 0.03606351837515831\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 3.6133968830108643 | KNN Loss: 3.5858891010284424 | CLS Loss: 0.02750779688358307\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 3.6274547576904297 | KNN Loss: 3.61541485786438 | CLS Loss: 0.012040012516081333\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 3.579308271408081 | KNN Loss: 3.569944143295288 | CLS Loss: 0.009364081546664238\n",
      "Epoch: 130, Loss: 3.6143, Train: 0.9961, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 3.6251919269561768 | KNN Loss: 3.621919631958008 | CLS Loss: 0.0032723303884267807\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 3.598947286605835 | KNN Loss: 3.577700138092041 | CLS Loss: 0.021247033029794693\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 3.6449451446533203 | KNN Loss: 3.6312990188598633 | CLS Loss: 0.013646045699715614\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 3.6256182193756104 | KNN Loss: 3.606276750564575 | CLS Loss: 0.019341491162776947\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 3.6729772090911865 | KNN Loss: 3.652035713195801 | CLS Loss: 0.020941495895385742\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 3.6107354164123535 | KNN Loss: 3.604093074798584 | CLS Loss: 0.006642436143010855\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 3.555696725845337 | KNN Loss: 3.5498833656311035 | CLS Loss: 0.005813449155539274\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 3.673647880554199 | KNN Loss: 3.647491216659546 | CLS Loss: 0.026156680658459663\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 3.6213483810424805 | KNN Loss: 3.61806583404541 | CLS Loss: 0.0032824964728206396\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 3.601383924484253 | KNN Loss: 3.583690881729126 | CLS Loss: 0.017692962661385536\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 3.579843282699585 | KNN Loss: 3.568453550338745 | CLS Loss: 0.011389662511646748\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 3.574662685394287 | KNN Loss: 3.5655088424682617 | CLS Loss: 0.009153778664767742\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 3.611124038696289 | KNN Loss: 3.5950100421905518 | CLS Loss: 0.01611395552754402\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 3.6100265979766846 | KNN Loss: 3.5856640338897705 | CLS Loss: 0.02436251752078533\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 3.6019983291625977 | KNN Loss: 3.5991322994232178 | CLS Loss: 0.0028661435935646296\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 3.6508727073669434 | KNN Loss: 3.6425130367279053 | CLS Loss: 0.008359760046005249\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 3.5878074169158936 | KNN Loss: 3.5587635040283203 | CLS Loss: 0.02904392220079899\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 3.595442771911621 | KNN Loss: 3.5759541988372803 | CLS Loss: 0.019488532096147537\n",
      "Epoch: 131, Loss: 3.6155, Train: 0.9960, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 3.575561285018921 | KNN Loss: 3.566126823425293 | CLS Loss: 0.009434521198272705\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 3.607726812362671 | KNN Loss: 3.6046767234802246 | CLS Loss: 0.003050148021429777\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 3.5992705821990967 | KNN Loss: 3.5836331844329834 | CLS Loss: 0.015637511387467384\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 3.5869240760803223 | KNN Loss: 3.572033643722534 | CLS Loss: 0.0148903364315629\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 3.563467502593994 | KNN Loss: 3.543468952178955 | CLS Loss: 0.019998466596007347\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 3.5873749256134033 | KNN Loss: 3.5698354244232178 | CLS Loss: 0.017539404332637787\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 3.607774019241333 | KNN Loss: 3.6039788722991943 | CLS Loss: 0.0037951236590743065\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 3.600926637649536 | KNN Loss: 3.5757365226745605 | CLS Loss: 0.025190046057105064\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 3.6280107498168945 | KNN Loss: 3.602748394012451 | CLS Loss: 0.025262394919991493\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 3.6243717670440674 | KNN Loss: 3.5999093055725098 | CLS Loss: 0.024462362751364708\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 3.61793851852417 | KNN Loss: 3.6097874641418457 | CLS Loss: 0.008151152171194553\n",
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 3.587702512741089 | KNN Loss: 3.572510242462158 | CLS Loss: 0.015192294493317604\n",
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 3.5901341438293457 | KNN Loss: 3.5742719173431396 | CLS Loss: 0.01586216315627098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 3.6130335330963135 | KNN Loss: 3.6087419986724854 | CLS Loss: 0.004291596356779337\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 3.589982748031616 | KNN Loss: 3.584198474884033 | CLS Loss: 0.005784334149211645\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 3.584033727645874 | KNN Loss: 3.5796096324920654 | CLS Loss: 0.004424158949404955\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 3.59462308883667 | KNN Loss: 3.567808151245117 | CLS Loss: 0.0268148984760046\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 3.6687536239624023 | KNN Loss: 3.6445584297180176 | CLS Loss: 0.024195225909352303\n",
      "Epoch: 132, Loss: 3.6076, Train: 0.9958, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 3.6357345581054688 | KNN Loss: 3.6161179542541504 | CLS Loss: 0.019616615027189255\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 3.5950515270233154 | KNN Loss: 3.586660385131836 | CLS Loss: 0.00839118380099535\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 3.5609421730041504 | KNN Loss: 3.5550692081451416 | CLS Loss: 0.005872853100299835\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 3.586738348007202 | KNN Loss: 3.5771915912628174 | CLS Loss: 0.00954677164554596\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 3.6967222690582275 | KNN Loss: 3.682175397872925 | CLS Loss: 0.014546876773238182\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 3.6077322959899902 | KNN Loss: 3.588212728500366 | CLS Loss: 0.019519612193107605\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 3.5689949989318848 | KNN Loss: 3.566960573196411 | CLS Loss: 0.0020344324875622988\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 3.5912797451019287 | KNN Loss: 3.5832526683807373 | CLS Loss: 0.008027194999158382\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 3.6430470943450928 | KNN Loss: 3.621565103530884 | CLS Loss: 0.021481966599822044\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 3.5912132263183594 | KNN Loss: 3.5807995796203613 | CLS Loss: 0.01041356660425663\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 3.6064515113830566 | KNN Loss: 3.5940535068511963 | CLS Loss: 0.012398002669215202\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 3.6230645179748535 | KNN Loss: 3.602905035018921 | CLS Loss: 0.020159434527158737\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 3.6188178062438965 | KNN Loss: 3.6030843257904053 | CLS Loss: 0.01573336310684681\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 3.57450008392334 | KNN Loss: 3.5618510246276855 | CLS Loss: 0.012649090960621834\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 3.5962040424346924 | KNN Loss: 3.5859758853912354 | CLS Loss: 0.010228094644844532\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 3.6126937866210938 | KNN Loss: 3.6027345657348633 | CLS Loss: 0.009959190152585506\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 3.594621181488037 | KNN Loss: 3.572418689727783 | CLS Loss: 0.02220255322754383\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 3.583773136138916 | KNN Loss: 3.568342924118042 | CLS Loss: 0.015430224128067493\n",
      "Epoch: 133, Loss: 3.6159, Train: 0.9963, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 3.598292827606201 | KNN Loss: 3.5885238647460938 | CLS Loss: 0.009769062511622906\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 3.589820384979248 | KNN Loss: 3.5786097049713135 | CLS Loss: 0.011210687458515167\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 3.593647003173828 | KNN Loss: 3.584500312805176 | CLS Loss: 0.009146638214588165\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 3.5957865715026855 | KNN Loss: 3.5816800594329834 | CLS Loss: 0.01410655677318573\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 3.5790278911590576 | KNN Loss: 3.5742509365081787 | CLS Loss: 0.004776869900524616\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 3.6068100929260254 | KNN Loss: 3.5890331268310547 | CLS Loss: 0.017776871100068092\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 3.592228412628174 | KNN Loss: 3.587137222290039 | CLS Loss: 0.005091135855764151\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 3.5886740684509277 | KNN Loss: 3.5725367069244385 | CLS Loss: 0.016137247905135155\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 3.6247167587280273 | KNN Loss: 3.6144466400146484 | CLS Loss: 0.010270228609442711\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 3.596651792526245 | KNN Loss: 3.585132122039795 | CLS Loss: 0.011519668623805046\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 3.604703903198242 | KNN Loss: 3.5960724353790283 | CLS Loss: 0.008631352335214615\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 3.560760021209717 | KNN Loss: 3.5516602993011475 | CLS Loss: 0.00909971259534359\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 3.616406202316284 | KNN Loss: 3.596041202545166 | CLS Loss: 0.02036495879292488\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 3.6304547786712646 | KNN Loss: 3.620882749557495 | CLS Loss: 0.009572038426995277\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 3.6451966762542725 | KNN Loss: 3.6344025135040283 | CLS Loss: 0.01079423725605011\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 3.58595871925354 | KNN Loss: 3.562044858932495 | CLS Loss: 0.023913806304335594\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 3.6391308307647705 | KNN Loss: 3.596156358718872 | CLS Loss: 0.042974457144737244\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 3.602829933166504 | KNN Loss: 3.5830812454223633 | CLS Loss: 0.019748691469430923\n",
      "Epoch: 134, Loss: 3.6067, Train: 0.9961, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 3.5765578746795654 | KNN Loss: 3.570359468460083 | CLS Loss: 0.006198384333401918\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 3.6260757446289062 | KNN Loss: 3.624373435974121 | CLS Loss: 0.001702345791272819\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 3.622051239013672 | KNN Loss: 3.594496488571167 | CLS Loss: 0.02755485661327839\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 3.631108283996582 | KNN Loss: 3.6219303607940674 | CLS Loss: 0.009177938103675842\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 3.58988881111145 | KNN Loss: 3.5864763259887695 | CLS Loss: 0.003412424586713314\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 3.6122288703918457 | KNN Loss: 3.603490114212036 | CLS Loss: 0.008738839067518711\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 3.63032603263855 | KNN Loss: 3.616602897644043 | CLS Loss: 0.013723055832087994\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 3.6453020572662354 | KNN Loss: 3.6082212924957275 | CLS Loss: 0.03708076849579811\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 3.646913766860962 | KNN Loss: 3.6368865966796875 | CLS Loss: 0.010027146898210049\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 3.6742477416992188 | KNN Loss: 3.641409397125244 | CLS Loss: 0.032838232815265656\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 3.577363967895508 | KNN Loss: 3.574483871459961 | CLS Loss: 0.00288016558624804\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 3.600343704223633 | KNN Loss: 3.5935699939727783 | CLS Loss: 0.0067736562341451645\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 3.6397488117218018 | KNN Loss: 3.6214663982391357 | CLS Loss: 0.018282325938344002\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 3.5629708766937256 | KNN Loss: 3.5571584701538086 | CLS Loss: 0.005812468938529491\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 3.5972719192504883 | KNN Loss: 3.5942301750183105 | CLS Loss: 0.003041735850274563\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 3.5646347999572754 | KNN Loss: 3.550330400466919 | CLS Loss: 0.01430441252887249\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 3.5945653915405273 | KNN Loss: 3.585663080215454 | CLS Loss: 0.008902380242943764\n",
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 3.593764305114746 | KNN Loss: 3.5831217765808105 | CLS Loss: 0.010642576031386852\n",
      "Epoch: 135, Loss: 3.6137, Train: 0.9967, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 3.618558168411255 | KNN Loss: 3.60678768157959 | CLS Loss: 0.011770443990826607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 3.5610289573669434 | KNN Loss: 3.5594146251678467 | CLS Loss: 0.0016144179971888661\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 3.6158742904663086 | KNN Loss: 3.6068971157073975 | CLS Loss: 0.00897705927491188\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 3.6829161643981934 | KNN Loss: 3.66926908493042 | CLS Loss: 0.01364714652299881\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 3.6661744117736816 | KNN Loss: 3.6549806594848633 | CLS Loss: 0.01119375042617321\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 3.5809338092803955 | KNN Loss: 3.5691380500793457 | CLS Loss: 0.011795686557888985\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 3.574237823486328 | KNN Loss: 3.566317319869995 | CLS Loss: 0.00792052410542965\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 3.6133646965026855 | KNN Loss: 3.600616693496704 | CLS Loss: 0.012748093344271183\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 3.6210227012634277 | KNN Loss: 3.6007883548736572 | CLS Loss: 0.020234381780028343\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 3.578684091567993 | KNN Loss: 3.564235210418701 | CLS Loss: 0.014448927715420723\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 3.731208562850952 | KNN Loss: 3.7261900901794434 | CLS Loss: 0.005018386524170637\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 3.6365909576416016 | KNN Loss: 3.6233341693878174 | CLS Loss: 0.01325672771781683\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 3.585425853729248 | KNN Loss: 3.5817465782165527 | CLS Loss: 0.0036792634055018425\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 3.6035079956054688 | KNN Loss: 3.5900068283081055 | CLS Loss: 0.013501149602234364\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 3.6270787715911865 | KNN Loss: 3.5996527671813965 | CLS Loss: 0.027426069602370262\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 3.6812965869903564 | KNN Loss: 3.67177414894104 | CLS Loss: 0.009522329084575176\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 3.6519877910614014 | KNN Loss: 3.6423518657684326 | CLS Loss: 0.009635997004806995\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 3.650970220565796 | KNN Loss: 3.6389522552490234 | CLS Loss: 0.012017931789159775\n",
      "Epoch: 136, Loss: 3.6145, Train: 0.9957, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 3.5987095832824707 | KNN Loss: 3.5730743408203125 | CLS Loss: 0.02563534490764141\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 3.6314127445220947 | KNN Loss: 3.6133670806884766 | CLS Loss: 0.01804555021226406\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 3.576215982437134 | KNN Loss: 3.551657199859619 | CLS Loss: 0.024558857083320618\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 3.56612229347229 | KNN Loss: 3.5578198432922363 | CLS Loss: 0.008302521891891956\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 3.56434965133667 | KNN Loss: 3.558791399002075 | CLS Loss: 0.005558256059885025\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 3.6212449073791504 | KNN Loss: 3.615337610244751 | CLS Loss: 0.0059073553420603275\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 3.6228442192077637 | KNN Loss: 3.620103597640991 | CLS Loss: 0.002740667201578617\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 3.5912973880767822 | KNN Loss: 3.589611768722534 | CLS Loss: 0.001685709343291819\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 3.601808547973633 | KNN Loss: 3.59037446975708 | CLS Loss: 0.01143405307084322\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 3.661299228668213 | KNN Loss: 3.649784564971924 | CLS Loss: 0.011514774523675442\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 3.5482192039489746 | KNN Loss: 3.5464749336242676 | CLS Loss: 0.0017442315584048629\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 3.5935287475585938 | KNN Loss: 3.58933687210083 | CLS Loss: 0.004191892221570015\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 3.6187899112701416 | KNN Loss: 3.604578971862793 | CLS Loss: 0.014210890978574753\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 3.6049258708953857 | KNN Loss: 3.5830576419830322 | CLS Loss: 0.021868184208869934\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 3.5824482440948486 | KNN Loss: 3.579512357711792 | CLS Loss: 0.0029359464533627033\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 3.599500894546509 | KNN Loss: 3.5790746212005615 | CLS Loss: 0.020426388829946518\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 3.603563070297241 | KNN Loss: 3.5887463092803955 | CLS Loss: 0.014816757291555405\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 3.5984091758728027 | KNN Loss: 3.5889742374420166 | CLS Loss: 0.009434985928237438\n",
      "Epoch: 137, Loss: 3.6071, Train: 0.9967, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 3.6369099617004395 | KNN Loss: 3.6310336589813232 | CLS Loss: 0.005876348819583654\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 3.5924503803253174 | KNN Loss: 3.586043357849121 | CLS Loss: 0.0064069791696965694\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 3.6533353328704834 | KNN Loss: 3.6284823417663574 | CLS Loss: 0.024852950125932693\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 3.6254079341888428 | KNN Loss: 3.6177706718444824 | CLS Loss: 0.007637339178472757\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 3.5777597427368164 | KNN Loss: 3.5696160793304443 | CLS Loss: 0.008143751882016659\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 3.5949416160583496 | KNN Loss: 3.5901143550872803 | CLS Loss: 0.004827182274311781\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 3.640413284301758 | KNN Loss: 3.626838207244873 | CLS Loss: 0.013575106859207153\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 3.6287901401519775 | KNN Loss: 3.601754903793335 | CLS Loss: 0.027035269886255264\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 3.6498301029205322 | KNN Loss: 3.6339166164398193 | CLS Loss: 0.015913449227809906\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 3.575087070465088 | KNN Loss: 3.56486177444458 | CLS Loss: 0.010225209407508373\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 3.590898036956787 | KNN Loss: 3.583712339401245 | CLS Loss: 0.007185807917267084\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 3.587700843811035 | KNN Loss: 3.5851755142211914 | CLS Loss: 0.0025254073552787304\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 3.5746073722839355 | KNN Loss: 3.5687777996063232 | CLS Loss: 0.005829502362757921\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 3.5858724117279053 | KNN Loss: 3.580434799194336 | CLS Loss: 0.005437654443085194\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 3.5864686965942383 | KNN Loss: 3.5793402194976807 | CLS Loss: 0.007128491997718811\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 3.6165411472320557 | KNN Loss: 3.612828016281128 | CLS Loss: 0.003713053883984685\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 3.5612826347351074 | KNN Loss: 3.556753158569336 | CLS Loss: 0.004529379308223724\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 3.600799322128296 | KNN Loss: 3.5562469959259033 | CLS Loss: 0.04455241933465004\n",
      "Epoch: 138, Loss: 3.6062, Train: 0.9960, Valid: 0.9858, Best: 0.9877\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 3.551971912384033 | KNN Loss: 3.54180645942688 | CLS Loss: 0.010165506973862648\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 3.5791358947753906 | KNN Loss: 3.572089672088623 | CLS Loss: 0.007046231999993324\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 3.5979835987091064 | KNN Loss: 3.5842535495758057 | CLS Loss: 0.013729971833527088\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 3.606668472290039 | KNN Loss: 3.5712409019470215 | CLS Loss: 0.03542763367295265\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 3.5877692699432373 | KNN Loss: 3.570080041885376 | CLS Loss: 0.017689112573862076\n",
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 3.621793031692505 | KNN Loss: 3.6180953979492188 | CLS Loss: 0.0036975631956011057\n",
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 3.5755763053894043 | KNN Loss: 3.5712995529174805 | CLS Loss: 0.004276854917407036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 3.58958101272583 | KNN Loss: 3.5708680152893066 | CLS Loss: 0.018713073804974556\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 3.5985968112945557 | KNN Loss: 3.5779452323913574 | CLS Loss: 0.020651696249842644\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 3.6102895736694336 | KNN Loss: 3.5998618602752686 | CLS Loss: 0.010427772998809814\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 3.550642967224121 | KNN Loss: 3.536332368850708 | CLS Loss: 0.014310515485703945\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 3.5837700366973877 | KNN Loss: 3.580122709274292 | CLS Loss: 0.0036474394146353006\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 3.6114580631256104 | KNN Loss: 3.6008615493774414 | CLS Loss: 0.01059652492403984\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 3.6001102924346924 | KNN Loss: 3.5706570148468018 | CLS Loss: 0.029453160241246223\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 3.5963149070739746 | KNN Loss: 3.579319477081299 | CLS Loss: 0.01699543371796608\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 3.590357542037964 | KNN Loss: 3.5812740325927734 | CLS Loss: 0.009083438664674759\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 3.5827808380126953 | KNN Loss: 3.565707206726074 | CLS Loss: 0.017073679715394974\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 3.6167819499969482 | KNN Loss: 3.5830650329589844 | CLS Loss: 0.03371695801615715\n",
      "Epoch: 139, Loss: 3.6051, Train: 0.9955, Valid: 0.9852, Best: 0.9877\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 3.6249403953552246 | KNN Loss: 3.6145358085632324 | CLS Loss: 0.010404608212411404\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 3.6869614124298096 | KNN Loss: 3.6679675579071045 | CLS Loss: 0.018993869423866272\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 3.61144757270813 | KNN Loss: 3.602569341659546 | CLS Loss: 0.008878310211002827\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 3.6775989532470703 | KNN Loss: 3.660414457321167 | CLS Loss: 0.017184576019644737\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 3.584479331970215 | KNN Loss: 3.5776185989379883 | CLS Loss: 0.006860614754259586\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 3.5703251361846924 | KNN Loss: 3.5604934692382812 | CLS Loss: 0.009831723757088184\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 3.612666606903076 | KNN Loss: 3.5969274044036865 | CLS Loss: 0.015739258378744125\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 3.5715930461883545 | KNN Loss: 3.5575110912323 | CLS Loss: 0.014081944711506367\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 3.610950469970703 | KNN Loss: 3.5959854125976562 | CLS Loss: 0.014965049922466278\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 3.617321252822876 | KNN Loss: 3.592445135116577 | CLS Loss: 0.02487601526081562\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 3.603543281555176 | KNN Loss: 3.5997366905212402 | CLS Loss: 0.0038066492415964603\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 3.5619263648986816 | KNN Loss: 3.5603134632110596 | CLS Loss: 0.001612875610589981\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 3.5984907150268555 | KNN Loss: 3.579893112182617 | CLS Loss: 0.018597692251205444\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 3.6113855838775635 | KNN Loss: 3.5899791717529297 | CLS Loss: 0.02140645869076252\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 3.655675172805786 | KNN Loss: 3.63179349899292 | CLS Loss: 0.023881705477833748\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 3.603634834289551 | KNN Loss: 3.5797858238220215 | CLS Loss: 0.023848947137594223\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 3.6652135848999023 | KNN Loss: 3.6563215255737305 | CLS Loss: 0.00889206025749445\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 3.622023820877075 | KNN Loss: 3.608157157897949 | CLS Loss: 0.01386676263064146\n",
      "Epoch: 140, Loss: 3.6155, Train: 0.9972, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 3.5897505283355713 | KNN Loss: 3.580564498901367 | CLS Loss: 0.009185988456010818\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 3.548109769821167 | KNN Loss: 3.54197359085083 | CLS Loss: 0.0061361598782241344\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 3.598839044570923 | KNN Loss: 3.5796992778778076 | CLS Loss: 0.019139884039759636\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 3.584181785583496 | KNN Loss: 3.57712984085083 | CLS Loss: 0.0070520550943911076\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 3.589158535003662 | KNN Loss: 3.5750224590301514 | CLS Loss: 0.014136102981865406\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 3.6867868900299072 | KNN Loss: 3.6692748069763184 | CLS Loss: 0.017512068152427673\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 3.583284378051758 | KNN Loss: 3.5785529613494873 | CLS Loss: 0.004731437191367149\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 3.6071386337280273 | KNN Loss: 3.582507848739624 | CLS Loss: 0.02463086135685444\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 3.5891597270965576 | KNN Loss: 3.5864880084991455 | CLS Loss: 0.0026718061417341232\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 3.578824043273926 | KNN Loss: 3.5595450401306152 | CLS Loss: 0.019279111176729202\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 3.5678789615631104 | KNN Loss: 3.550203323364258 | CLS Loss: 0.017675522714853287\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 3.5911340713500977 | KNN Loss: 3.575812816619873 | CLS Loss: 0.015321196056902409\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 3.6400246620178223 | KNN Loss: 3.6371219158172607 | CLS Loss: 0.0029026970732957125\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 3.5998318195343018 | KNN Loss: 3.5632762908935547 | CLS Loss: 0.036555610597133636\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 3.604684591293335 | KNN Loss: 3.595592498779297 | CLS Loss: 0.009092198684811592\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 3.6154251098632812 | KNN Loss: 3.610306978225708 | CLS Loss: 0.005118189379572868\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 3.586115598678589 | KNN Loss: 3.580660581588745 | CLS Loss: 0.005455043166875839\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 3.6305460929870605 | KNN Loss: 3.6197304725646973 | CLS Loss: 0.010815511457622051\n",
      "Epoch: 141, Loss: 3.6037, Train: 0.9969, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 3.620098114013672 | KNN Loss: 3.6108577251434326 | CLS Loss: 0.009240283630788326\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 3.630479335784912 | KNN Loss: 3.6194612979888916 | CLS Loss: 0.011018105782568455\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 3.6562533378601074 | KNN Loss: 3.630563735961914 | CLS Loss: 0.02568967640399933\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 3.6050350666046143 | KNN Loss: 3.5977847576141357 | CLS Loss: 0.0072503462433815\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 3.579019784927368 | KNN Loss: 3.568394899368286 | CLS Loss: 0.010624988935887814\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 3.674084186553955 | KNN Loss: 3.6553735733032227 | CLS Loss: 0.018710503354668617\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 3.605524778366089 | KNN Loss: 3.6047277450561523 | CLS Loss: 0.0007970032747834921\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 3.5639612674713135 | KNN Loss: 3.5581326484680176 | CLS Loss: 0.005828558001667261\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 3.6600887775421143 | KNN Loss: 3.6518547534942627 | CLS Loss: 0.008233929984271526\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 3.599705696105957 | KNN Loss: 3.5716705322265625 | CLS Loss: 0.028035148978233337\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 3.6130385398864746 | KNN Loss: 3.591447114944458 | CLS Loss: 0.021591514348983765\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 3.6608707904815674 | KNN Loss: 3.648869514465332 | CLS Loss: 0.01200133841484785\n",
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 3.594440460205078 | KNN Loss: 3.5867977142333984 | CLS Loss: 0.007642811164259911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 3.5890674591064453 | KNN Loss: 3.565585136413574 | CLS Loss: 0.02348233386874199\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 3.61161470413208 | KNN Loss: 3.581075429916382 | CLS Loss: 0.030539188534021378\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 3.6062328815460205 | KNN Loss: 3.5816354751586914 | CLS Loss: 0.02459731511771679\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 3.6792173385620117 | KNN Loss: 3.6246109008789062 | CLS Loss: 0.05460640788078308\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 3.651214122772217 | KNN Loss: 3.605290174484253 | CLS Loss: 0.04592403396964073\n",
      "Epoch: 142, Loss: 3.6130, Train: 0.9965, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 3.573319673538208 | KNN Loss: 3.5469679832458496 | CLS Loss: 0.026351701468229294\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 3.559103488922119 | KNN Loss: 3.5551562309265137 | CLS Loss: 0.003947185818105936\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 3.6058406829833984 | KNN Loss: 3.5947837829589844 | CLS Loss: 0.011056805960834026\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 3.5607614517211914 | KNN Loss: 3.556779146194458 | CLS Loss: 0.003982330672442913\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 3.5867085456848145 | KNN Loss: 3.5708084106445312 | CLS Loss: 0.015900196507573128\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 3.59309983253479 | KNN Loss: 3.5747315883636475 | CLS Loss: 0.018368151038885117\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 3.686943769454956 | KNN Loss: 3.6589784622192383 | CLS Loss: 0.027965333312749863\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 3.600364923477173 | KNN Loss: 3.5869667530059814 | CLS Loss: 0.013398283161222935\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 3.641878128051758 | KNN Loss: 3.625467300415039 | CLS Loss: 0.016410840675234795\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 3.632658004760742 | KNN Loss: 3.6222825050354004 | CLS Loss: 0.01037539355456829\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 3.570504665374756 | KNN Loss: 3.552703857421875 | CLS Loss: 0.017800744622945786\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 3.581559658050537 | KNN Loss: 3.57077956199646 | CLS Loss: 0.010780193842947483\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 3.5925679206848145 | KNN Loss: 3.5830633640289307 | CLS Loss: 0.00950466375797987\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 3.559314489364624 | KNN Loss: 3.552760124206543 | CLS Loss: 0.006554407067596912\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 3.576164722442627 | KNN Loss: 3.5607492923736572 | CLS Loss: 0.015415393747389317\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 3.5917649269104004 | KNN Loss: 3.5868868827819824 | CLS Loss: 0.004878005478531122\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 3.631105899810791 | KNN Loss: 3.620662212371826 | CLS Loss: 0.01044380571693182\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 3.655578136444092 | KNN Loss: 3.645505428314209 | CLS Loss: 0.010072663426399231\n",
      "Epoch: 143, Loss: 3.6094, Train: 0.9971, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 3.6003305912017822 | KNN Loss: 3.595409393310547 | CLS Loss: 0.004921299871057272\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 3.651533365249634 | KNN Loss: 3.6439647674560547 | CLS Loss: 0.007568599656224251\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 3.6300957202911377 | KNN Loss: 3.618532419204712 | CLS Loss: 0.01156336534768343\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 3.5840964317321777 | KNN Loss: 3.57554030418396 | CLS Loss: 0.008556008338928223\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 3.5680415630340576 | KNN Loss: 3.565751314163208 | CLS Loss: 0.002290355274453759\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 3.604084014892578 | KNN Loss: 3.602356195449829 | CLS Loss: 0.0017277698498219252\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 3.6308557987213135 | KNN Loss: 3.6179358959198 | CLS Loss: 0.01291992049664259\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 3.5814874172210693 | KNN Loss: 3.568613052368164 | CLS Loss: 0.012874280102550983\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 3.5984785556793213 | KNN Loss: 3.583179235458374 | CLS Loss: 0.015299336984753609\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 3.6089494228363037 | KNN Loss: 3.5838708877563477 | CLS Loss: 0.02507859840989113\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 3.650810718536377 | KNN Loss: 3.6301956176757812 | CLS Loss: 0.020615067332983017\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 3.5922446250915527 | KNN Loss: 3.5865421295166016 | CLS Loss: 0.005702557507902384\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 3.614057779312134 | KNN Loss: 3.594489097595215 | CLS Loss: 0.019568664953112602\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 3.5767314434051514 | KNN Loss: 3.563809633255005 | CLS Loss: 0.0129217728972435\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 3.589625120162964 | KNN Loss: 3.5806829929351807 | CLS Loss: 0.008942210115492344\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 3.570369243621826 | KNN Loss: 3.5686776638031006 | CLS Loss: 0.0016916027525439858\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 3.5660336017608643 | KNN Loss: 3.560333490371704 | CLS Loss: 0.005700122565031052\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 3.5916123390197754 | KNN Loss: 3.56609845161438 | CLS Loss: 0.02551385574042797\n",
      "Epoch: 144, Loss: 3.6096, Train: 0.9966, Valid: 0.9866, Best: 0.9877\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 3.60160493850708 | KNN Loss: 3.579336643218994 | CLS Loss: 0.022268248721957207\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 3.622285842895508 | KNN Loss: 3.6098270416259766 | CLS Loss: 0.012458682991564274\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 3.6103947162628174 | KNN Loss: 3.5907652378082275 | CLS Loss: 0.019629590213298798\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 3.6112334728240967 | KNN Loss: 3.602238655090332 | CLS Loss: 0.008994828909635544\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 3.587009906768799 | KNN Loss: 3.5733273029327393 | CLS Loss: 0.013682501390576363\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 3.562457799911499 | KNN Loss: 3.5582828521728516 | CLS Loss: 0.004174927715212107\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 3.58540940284729 | KNN Loss: 3.570923328399658 | CLS Loss: 0.014486103318631649\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 3.6187570095062256 | KNN Loss: 3.591533899307251 | CLS Loss: 0.027223117649555206\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 3.6269047260284424 | KNN Loss: 3.617030382156372 | CLS Loss: 0.009874432347714901\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 3.663688898086548 | KNN Loss: 3.6545846462249756 | CLS Loss: 0.0091043496504426\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 3.608795166015625 | KNN Loss: 3.599313497543335 | CLS Loss: 0.009481689892709255\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 3.691525936126709 | KNN Loss: 3.6764347553253174 | CLS Loss: 0.015091225504875183\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 3.607025146484375 | KNN Loss: 3.5933666229248047 | CLS Loss: 0.013658442534506321\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 3.5997326374053955 | KNN Loss: 3.5849854946136475 | CLS Loss: 0.014747231267392635\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 3.732140064239502 | KNN Loss: 3.6935060024261475 | CLS Loss: 0.038634009659290314\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 3.656925678253174 | KNN Loss: 3.6523327827453613 | CLS Loss: 0.004592825658619404\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 3.6106131076812744 | KNN Loss: 3.5828819274902344 | CLS Loss: 0.02773117460310459\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 3.586672782897949 | KNN Loss: 3.5547547340393066 | CLS Loss: 0.031918153166770935\n",
      "Epoch: 145, Loss: 3.6150, Train: 0.9956, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 3.649691343307495 | KNN Loss: 3.642695426940918 | CLS Loss: 0.006995969917625189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 3.5896432399749756 | KNN Loss: 3.5823323726654053 | CLS Loss: 0.0073108673095703125\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 3.581458330154419 | KNN Loss: 3.5765645503997803 | CLS Loss: 0.004893822595477104\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 3.6006951332092285 | KNN Loss: 3.5832879543304443 | CLS Loss: 0.017407283186912537\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 3.5913913249969482 | KNN Loss: 3.573756217956543 | CLS Loss: 0.017635134980082512\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 3.6220993995666504 | KNN Loss: 3.6197056770324707 | CLS Loss: 0.0023938361555337906\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 3.6426050662994385 | KNN Loss: 3.613386392593384 | CLS Loss: 0.02921857312321663\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 3.6541919708251953 | KNN Loss: 3.6353280544281006 | CLS Loss: 0.018863823264837265\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 3.677936315536499 | KNN Loss: 3.656780481338501 | CLS Loss: 0.021155785769224167\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 3.6067569255828857 | KNN Loss: 3.5814995765686035 | CLS Loss: 0.025257378816604614\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 3.675879955291748 | KNN Loss: 3.6557631492614746 | CLS Loss: 0.02011687494814396\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 3.6477115154266357 | KNN Loss: 3.637402296066284 | CLS Loss: 0.010309278033673763\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 3.6384265422821045 | KNN Loss: 3.631131410598755 | CLS Loss: 0.007295086048543453\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 3.636672258377075 | KNN Loss: 3.6154065132141113 | CLS Loss: 0.021265694871544838\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 3.5875887870788574 | KNN Loss: 3.582630157470703 | CLS Loss: 0.004958555102348328\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 3.575101375579834 | KNN Loss: 3.57270884513855 | CLS Loss: 0.0023924480192363262\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 3.6057443618774414 | KNN Loss: 3.595362663269043 | CLS Loss: 0.010381641797721386\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 3.6158270835876465 | KNN Loss: 3.607726812362671 | CLS Loss: 0.00810024980455637\n",
      "Epoch: 146, Loss: 3.6166, Train: 0.9964, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 3.593970537185669 | KNN Loss: 3.5734338760375977 | CLS Loss: 0.020536746829748154\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 3.619633197784424 | KNN Loss: 3.611508846282959 | CLS Loss: 0.008124396204948425\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 3.5651087760925293 | KNN Loss: 3.5616791248321533 | CLS Loss: 0.0034295893274247646\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 3.614964485168457 | KNN Loss: 3.610140562057495 | CLS Loss: 0.004823856987059116\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 3.5629661083221436 | KNN Loss: 3.547623634338379 | CLS Loss: 0.01534246001392603\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 3.595689058303833 | KNN Loss: 3.590845823287964 | CLS Loss: 0.004843233618885279\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 3.5771329402923584 | KNN Loss: 3.573131561279297 | CLS Loss: 0.00400145910680294\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 3.6047868728637695 | KNN Loss: 3.5959739685058594 | CLS Loss: 0.00881284661591053\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 3.6464474201202393 | KNN Loss: 3.6377439498901367 | CLS Loss: 0.008703530766069889\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 3.6342241764068604 | KNN Loss: 3.6066064834594727 | CLS Loss: 0.027617668733000755\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 3.6407322883605957 | KNN Loss: 3.621248722076416 | CLS Loss: 0.019483473151922226\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 3.588322877883911 | KNN Loss: 3.5630557537078857 | CLS Loss: 0.025267068296670914\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 3.6298158168792725 | KNN Loss: 3.603482961654663 | CLS Loss: 0.02633274719119072\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 3.6339073181152344 | KNN Loss: 3.616580009460449 | CLS Loss: 0.017327288165688515\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 3.645479917526245 | KNN Loss: 3.6344332695007324 | CLS Loss: 0.01104653999209404\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 3.5967249870300293 | KNN Loss: 3.5957090854644775 | CLS Loss: 0.0010159516241401434\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 3.713222026824951 | KNN Loss: 3.705422878265381 | CLS Loss: 0.00779903307557106\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 3.6337294578552246 | KNN Loss: 3.626103401184082 | CLS Loss: 0.007626034785062075\n",
      "Epoch: 147, Loss: 3.6108, Train: 0.9963, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 3.604616165161133 | KNN Loss: 3.589648962020874 | CLS Loss: 0.014967294409871101\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 3.6587045192718506 | KNN Loss: 3.6462810039520264 | CLS Loss: 0.012423505075275898\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 3.682697057723999 | KNN Loss: 3.6608083248138428 | CLS Loss: 0.02188883163034916\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 3.577148199081421 | KNN Loss: 3.572154998779297 | CLS Loss: 0.004993137437850237\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 3.5890870094299316 | KNN Loss: 3.5653984546661377 | CLS Loss: 0.02368844673037529\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 3.6204545497894287 | KNN Loss: 3.6124110221862793 | CLS Loss: 0.008043593727052212\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 3.6236538887023926 | KNN Loss: 3.6197283267974854 | CLS Loss: 0.00392563221976161\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 3.6108591556549072 | KNN Loss: 3.5928099155426025 | CLS Loss: 0.01804918609559536\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 3.6005642414093018 | KNN Loss: 3.5940933227539062 | CLS Loss: 0.00647097360342741\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 3.5908992290496826 | KNN Loss: 3.581188201904297 | CLS Loss: 0.00971101876348257\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 3.5808050632476807 | KNN Loss: 3.5694594383239746 | CLS Loss: 0.011345620267093182\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 3.6312999725341797 | KNN Loss: 3.620497226715088 | CLS Loss: 0.010802852921187878\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 3.667111396789551 | KNN Loss: 3.6619620323181152 | CLS Loss: 0.005149388685822487\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 3.6415295600891113 | KNN Loss: 3.631298065185547 | CLS Loss: 0.010231499560177326\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 3.6148014068603516 | KNN Loss: 3.607541561126709 | CLS Loss: 0.007259732112288475\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 3.5920677185058594 | KNN Loss: 3.5640206336975098 | CLS Loss: 0.028047198429703712\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 3.6544008255004883 | KNN Loss: 3.6268670558929443 | CLS Loss: 0.027533728629350662\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 3.6050503253936768 | KNN Loss: 3.5973334312438965 | CLS Loss: 0.007716790772974491\n",
      "Epoch: 148, Loss: 3.6068, Train: 0.9970, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 3.6347389221191406 | KNN Loss: 3.6184000968933105 | CLS Loss: 0.016338737681508064\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 3.629185914993286 | KNN Loss: 3.6219332218170166 | CLS Loss: 0.007252809125930071\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 3.6313772201538086 | KNN Loss: 3.630483627319336 | CLS Loss: 0.0008935392834246159\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 3.62748384475708 | KNN Loss: 3.624127149581909 | CLS Loss: 0.0033567454665899277\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 3.5845730304718018 | KNN Loss: 3.5749197006225586 | CLS Loss: 0.009653258137404919\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 3.608518600463867 | KNN Loss: 3.588376522064209 | CLS Loss: 0.02014213800430298\n",
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 3.6323258876800537 | KNN Loss: 3.622816562652588 | CLS Loss: 0.009509327821433544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 3.667750597000122 | KNN Loss: 3.657876491546631 | CLS Loss: 0.009874027222394943\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 3.5609798431396484 | KNN Loss: 3.5565030574798584 | CLS Loss: 0.004476810339838266\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 3.589830160140991 | KNN Loss: 3.5805208683013916 | CLS Loss: 0.009309304878115654\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 3.6372735500335693 | KNN Loss: 3.6219236850738525 | CLS Loss: 0.01534995436668396\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 3.590461254119873 | KNN Loss: 3.56977915763855 | CLS Loss: 0.020682021975517273\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 3.6229746341705322 | KNN Loss: 3.6078553199768066 | CLS Loss: 0.015119382180273533\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 3.554780960083008 | KNN Loss: 3.5528335571289062 | CLS Loss: 0.0019473781576380134\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 3.579723834991455 | KNN Loss: 3.571714162826538 | CLS Loss: 0.008009648881852627\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 3.6053965091705322 | KNN Loss: 3.5941367149353027 | CLS Loss: 0.01125968899577856\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 3.633404493331909 | KNN Loss: 3.593097686767578 | CLS Loss: 0.040306899696588516\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 3.580664873123169 | KNN Loss: 3.5598504543304443 | CLS Loss: 0.0208144411444664\n",
      "Epoch: 149, Loss: 3.6125, Train: 0.9962, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 3.5999481678009033 | KNN Loss: 3.57886004447937 | CLS Loss: 0.021088093519210815\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 3.549325466156006 | KNN Loss: 3.5473341941833496 | CLS Loss: 0.001991166267544031\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 3.584325075149536 | KNN Loss: 3.565882444381714 | CLS Loss: 0.018442654982209206\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 3.692854404449463 | KNN Loss: 3.6670994758605957 | CLS Loss: 0.025754977017641068\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 3.6405999660491943 | KNN Loss: 3.623575210571289 | CLS Loss: 0.017024822533130646\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 3.610617160797119 | KNN Loss: 3.5975332260131836 | CLS Loss: 0.01308397389948368\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 3.5902950763702393 | KNN Loss: 3.573117971420288 | CLS Loss: 0.017177091911435127\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 3.6186885833740234 | KNN Loss: 3.599055290222168 | CLS Loss: 0.01963326893746853\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 3.6476709842681885 | KNN Loss: 3.641712188720703 | CLS Loss: 0.0059586805291473866\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 3.5820064544677734 | KNN Loss: 3.5791664123535156 | CLS Loss: 0.0028399473521858454\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 3.6136231422424316 | KNN Loss: 3.6115007400512695 | CLS Loss: 0.0021223288495093584\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 3.6517155170440674 | KNN Loss: 3.6178641319274902 | CLS Loss: 0.033851273357868195\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 3.6171207427978516 | KNN Loss: 3.6077473163604736 | CLS Loss: 0.00937349908053875\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 3.5855019092559814 | KNN Loss: 3.5623645782470703 | CLS Loss: 0.02313721366226673\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 3.6218936443328857 | KNN Loss: 3.5795211791992188 | CLS Loss: 0.04237246513366699\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 3.675534963607788 | KNN Loss: 3.6483240127563477 | CLS Loss: 0.027211027219891548\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 3.5983121395111084 | KNN Loss: 3.5892958641052246 | CLS Loss: 0.009016240015625954\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 3.618999481201172 | KNN Loss: 3.610511064529419 | CLS Loss: 0.008488420397043228\n",
      "Epoch: 150, Loss: 3.6113, Train: 0.9960, Valid: 0.9856, Best: 0.9877\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 3.6136956214904785 | KNN Loss: 3.6079983711242676 | CLS Loss: 0.005697142798453569\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 3.6215295791625977 | KNN Loss: 3.605694055557251 | CLS Loss: 0.01583564095199108\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 3.576720952987671 | KNN Loss: 3.5752201080322266 | CLS Loss: 0.0015008101472631097\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 3.585164785385132 | KNN Loss: 3.561002016067505 | CLS Loss: 0.02416272461414337\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 3.584556818008423 | KNN Loss: 3.55692458152771 | CLS Loss: 0.027632346376776695\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 3.667327880859375 | KNN Loss: 3.6576590538024902 | CLS Loss: 0.009668842889368534\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 3.582364559173584 | KNN Loss: 3.574838399887085 | CLS Loss: 0.007526237051934004\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 3.6537880897521973 | KNN Loss: 3.628321409225464 | CLS Loss: 0.02546663209795952\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 3.610942840576172 | KNN Loss: 3.597687244415283 | CLS Loss: 0.013255715370178223\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 3.586888074874878 | KNN Loss: 3.5735480785369873 | CLS Loss: 0.013340020552277565\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 3.6103098392486572 | KNN Loss: 3.5986735820770264 | CLS Loss: 0.011636233888566494\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 3.6034176349639893 | KNN Loss: 3.587899684906006 | CLS Loss: 0.015517933294177055\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 3.6359097957611084 | KNN Loss: 3.6297123432159424 | CLS Loss: 0.006197367329150438\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 3.62454891204834 | KNN Loss: 3.605555772781372 | CLS Loss: 0.01899305358529091\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 3.5992114543914795 | KNN Loss: 3.5971837043762207 | CLS Loss: 0.0020278270822018385\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 3.645378351211548 | KNN Loss: 3.6226141452789307 | CLS Loss: 0.02276410162448883\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 3.578436851501465 | KNN Loss: 3.5690042972564697 | CLS Loss: 0.009432577528059483\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 3.6248135566711426 | KNN Loss: 3.6113266944885254 | CLS Loss: 0.013486925512552261\n",
      "Epoch: 151, Loss: 3.6031, Train: 0.9948, Valid: 0.9849, Best: 0.9877\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 3.5945053100585938 | KNN Loss: 3.590756416320801 | CLS Loss: 0.0037489701062440872\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 3.586535930633545 | KNN Loss: 3.579241991043091 | CLS Loss: 0.007293881382793188\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 3.6320927143096924 | KNN Loss: 3.6278011798858643 | CLS Loss: 0.004291587974876165\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 3.5932257175445557 | KNN Loss: 3.591970682144165 | CLS Loss: 0.0012550392420962453\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 3.6107921600341797 | KNN Loss: 3.590327501296997 | CLS Loss: 0.02046458050608635\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 3.614612102508545 | KNN Loss: 3.6025609970092773 | CLS Loss: 0.012051109224557877\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 3.5950112342834473 | KNN Loss: 3.5837721824645996 | CLS Loss: 0.01123914122581482\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 3.5898776054382324 | KNN Loss: 3.5751595497131348 | CLS Loss: 0.014718158170580864\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 3.612729787826538 | KNN Loss: 3.5993340015411377 | CLS Loss: 0.013395750895142555\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 3.6479225158691406 | KNN Loss: 3.6131250858306885 | CLS Loss: 0.03479740396142006\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 3.60408616065979 | KNN Loss: 3.589021921157837 | CLS Loss: 0.015064168721437454\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 3.5968034267425537 | KNN Loss: 3.593698740005493 | CLS Loss: 0.003104656469076872\n",
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 3.6850883960723877 | KNN Loss: 3.6706907749176025 | CLS Loss: 0.014397706836462021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 3.6103904247283936 | KNN Loss: 3.600930690765381 | CLS Loss: 0.009459781460464\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 3.619649648666382 | KNN Loss: 3.592257499694824 | CLS Loss: 0.027392050251364708\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 3.6176135540008545 | KNN Loss: 3.5943808555603027 | CLS Loss: 0.02323276549577713\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 3.5575950145721436 | KNN Loss: 3.548957347869873 | CLS Loss: 0.008637731894850731\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 3.6263792514801025 | KNN Loss: 3.601743221282959 | CLS Loss: 0.024636147543787956\n",
      "Epoch: 152, Loss: 3.6114, Train: 0.9971, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 3.6297600269317627 | KNN Loss: 3.609898567199707 | CLS Loss: 0.019861385226249695\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 3.625674247741699 | KNN Loss: 3.60467791557312 | CLS Loss: 0.020996246486902237\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 3.6363272666931152 | KNN Loss: 3.6216647624969482 | CLS Loss: 0.014662612229585648\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 3.5895421504974365 | KNN Loss: 3.5851175785064697 | CLS Loss: 0.004424459300935268\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 3.5866827964782715 | KNN Loss: 3.5793118476867676 | CLS Loss: 0.007371057290583849\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 3.6263744831085205 | KNN Loss: 3.610043525695801 | CLS Loss: 0.016330908983945847\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 3.6429855823516846 | KNN Loss: 3.637676239013672 | CLS Loss: 0.0053094532340765\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 3.6004531383514404 | KNN Loss: 3.5940065383911133 | CLS Loss: 0.0064466604962944984\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 3.615204334259033 | KNN Loss: 3.598446846008301 | CLS Loss: 0.016757551580667496\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 3.5820508003234863 | KNN Loss: 3.573399305343628 | CLS Loss: 0.00865146704018116\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 3.587111234664917 | KNN Loss: 3.571135997772217 | CLS Loss: 0.015975134447216988\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 3.616478681564331 | KNN Loss: 3.608898401260376 | CLS Loss: 0.007580253761261702\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 3.5919387340545654 | KNN Loss: 3.5802128314971924 | CLS Loss: 0.011726017110049725\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 3.6251814365386963 | KNN Loss: 3.608642339706421 | CLS Loss: 0.016539020463824272\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 3.619041919708252 | KNN Loss: 3.600064516067505 | CLS Loss: 0.01897745206952095\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 3.5968925952911377 | KNN Loss: 3.5607073307037354 | CLS Loss: 0.036185186356306076\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 3.6484010219573975 | KNN Loss: 3.6210591793060303 | CLS Loss: 0.027341866865754128\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 3.588757038116455 | KNN Loss: 3.5848989486694336 | CLS Loss: 0.003858163021504879\n",
      "Epoch: 153, Loss: 3.6062, Train: 0.9963, Valid: 0.9861, Best: 0.9877\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 3.6119420528411865 | KNN Loss: 3.6072731018066406 | CLS Loss: 0.004668843001127243\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 3.6035149097442627 | KNN Loss: 3.598113775253296 | CLS Loss: 0.005401178263127804\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 3.5966899394989014 | KNN Loss: 3.5846519470214844 | CLS Loss: 0.012037915177643299\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 3.584368944168091 | KNN Loss: 3.57127046585083 | CLS Loss: 0.013098428025841713\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 3.6070029735565186 | KNN Loss: 3.6028201580047607 | CLS Loss: 0.004182895179837942\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 3.6103649139404297 | KNN Loss: 3.59749436378479 | CLS Loss: 0.012870450504124165\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 3.6149213314056396 | KNN Loss: 3.610031843185425 | CLS Loss: 0.004889446310698986\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 3.620182752609253 | KNN Loss: 3.604976177215576 | CLS Loss: 0.015206520445644855\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 3.61515212059021 | KNN Loss: 3.5877771377563477 | CLS Loss: 0.02737502008676529\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 3.669349431991577 | KNN Loss: 3.6582415103912354 | CLS Loss: 0.01110798865556717\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 3.5804450511932373 | KNN Loss: 3.565657615661621 | CLS Loss: 0.014787494204938412\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 3.569365978240967 | KNN Loss: 3.5556797981262207 | CLS Loss: 0.013686204329133034\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 3.5608015060424805 | KNN Loss: 3.555634021759033 | CLS Loss: 0.005167457275092602\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 3.577669858932495 | KNN Loss: 3.570460796356201 | CLS Loss: 0.007209073752164841\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 3.5763602256774902 | KNN Loss: 3.5673928260803223 | CLS Loss: 0.008967502042651176\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 3.6086277961730957 | KNN Loss: 3.601043939590454 | CLS Loss: 0.0075837839394807816\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 3.6013331413269043 | KNN Loss: 3.592393159866333 | CLS Loss: 0.008939889259636402\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 3.617293357849121 | KNN Loss: 3.6049046516418457 | CLS Loss: 0.012388767674565315\n",
      "Epoch: 154, Loss: 3.6054, Train: 0.9972, Valid: 0.9873, Best: 0.9877\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 3.620027780532837 | KNN Loss: 3.6165833473205566 | CLS Loss: 0.0034444096963852644\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 3.667397975921631 | KNN Loss: 3.652848243713379 | CLS Loss: 0.01454983651638031\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 3.5981767177581787 | KNN Loss: 3.5912246704101562 | CLS Loss: 0.006952071562409401\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 3.5958213806152344 | KNN Loss: 3.5835118293762207 | CLS Loss: 0.012309647165238857\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 3.5925073623657227 | KNN Loss: 3.584453582763672 | CLS Loss: 0.008053716272115707\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 3.6171722412109375 | KNN Loss: 3.604301691055298 | CLS Loss: 0.012870638631284237\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 3.586240768432617 | KNN Loss: 3.5815539360046387 | CLS Loss: 0.004686886444687843\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 3.642345428466797 | KNN Loss: 3.6282453536987305 | CLS Loss: 0.014099996536970139\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 3.5792977809906006 | KNN Loss: 3.578646659851074 | CLS Loss: 0.0006511443643830717\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 3.5827720165252686 | KNN Loss: 3.5755019187927246 | CLS Loss: 0.007270165719091892\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 3.6251983642578125 | KNN Loss: 3.6234560012817383 | CLS Loss: 0.0017422923119738698\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 3.5907013416290283 | KNN Loss: 3.5801849365234375 | CLS Loss: 0.010516389273107052\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 3.608278274536133 | KNN Loss: 3.586592197418213 | CLS Loss: 0.02168610319495201\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 3.6291556358337402 | KNN Loss: 3.6206512451171875 | CLS Loss: 0.00850431527942419\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 3.6003119945526123 | KNN Loss: 3.5864920616149902 | CLS Loss: 0.013819947838783264\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 3.5990328788757324 | KNN Loss: 3.590754270553589 | CLS Loss: 0.008278703317046165\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 3.5946614742279053 | KNN Loss: 3.5877625942230225 | CLS Loss: 0.006898926105350256\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 3.6171247959136963 | KNN Loss: 3.61299467086792 | CLS Loss: 0.004130238201469183\n",
      "Epoch: 155, Loss: 3.6054, Train: 0.9974, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 3.587275981903076 | KNN Loss: 3.582566738128662 | CLS Loss: 0.004709234461188316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 3.592717170715332 | KNN Loss: 3.590681552886963 | CLS Loss: 0.0020356278400868177\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 3.571916103363037 | KNN Loss: 3.563425302505493 | CLS Loss: 0.008490857668220997\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 3.5947558879852295 | KNN Loss: 3.5844175815582275 | CLS Loss: 0.010338193736970425\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 3.6217103004455566 | KNN Loss: 3.6191670894622803 | CLS Loss: 0.0025432920083403587\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 3.6377947330474854 | KNN Loss: 3.612751007080078 | CLS Loss: 0.02504374459385872\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 3.571620464324951 | KNN Loss: 3.560326099395752 | CLS Loss: 0.01129437331110239\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 3.586012125015259 | KNN Loss: 3.5716958045959473 | CLS Loss: 0.014316221699118614\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 3.653892755508423 | KNN Loss: 3.6417124271392822 | CLS Loss: 0.012180250138044357\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 3.600311040878296 | KNN Loss: 3.5974466800689697 | CLS Loss: 0.002864414593204856\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 3.6260743141174316 | KNN Loss: 3.6172804832458496 | CLS Loss: 0.008793920278549194\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 3.6169726848602295 | KNN Loss: 3.6029417514801025 | CLS Loss: 0.01403090264648199\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 3.6704695224761963 | KNN Loss: 3.657301664352417 | CLS Loss: 0.013167740777134895\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 3.613830804824829 | KNN Loss: 3.6127676963806152 | CLS Loss: 0.0010630916804075241\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 3.638152837753296 | KNN Loss: 3.6151318550109863 | CLS Loss: 0.023020891472697258\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 3.5663533210754395 | KNN Loss: 3.5595412254333496 | CLS Loss: 0.006811988074332476\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 3.6327970027923584 | KNN Loss: 3.614332914352417 | CLS Loss: 0.01846400648355484\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 3.605194568634033 | KNN Loss: 3.574636936187744 | CLS Loss: 0.030557604506611824\n",
      "Epoch: 156, Loss: 3.6082, Train: 0.9967, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 3.612895965576172 | KNN Loss: 3.5916171073913574 | CLS Loss: 0.021278956905007362\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 3.615589141845703 | KNN Loss: 3.611898899078369 | CLS Loss: 0.003690179670229554\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 3.569110155105591 | KNN Loss: 3.5560834407806396 | CLS Loss: 0.013026787899434566\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 3.6303117275238037 | KNN Loss: 3.606853723526001 | CLS Loss: 0.023457972332835197\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 3.607517957687378 | KNN Loss: 3.5845887660980225 | CLS Loss: 0.02292916551232338\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 3.598419427871704 | KNN Loss: 3.5961577892303467 | CLS Loss: 0.0022616663482040167\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 3.6043636798858643 | KNN Loss: 3.598644971847534 | CLS Loss: 0.005718692671507597\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 3.614614248275757 | KNN Loss: 3.6048166751861572 | CLS Loss: 0.009797544218599796\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 3.5768544673919678 | KNN Loss: 3.5702381134033203 | CLS Loss: 0.006616455968469381\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 3.592935085296631 | KNN Loss: 3.5796453952789307 | CLS Loss: 0.01328976359218359\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 3.6252851486206055 | KNN Loss: 3.6146023273468018 | CLS Loss: 0.010682841762900352\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 3.609307289123535 | KNN Loss: 3.5961594581604004 | CLS Loss: 0.013147764839231968\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 3.584425687789917 | KNN Loss: 3.5617756843566895 | CLS Loss: 0.022649934515357018\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 3.622107744216919 | KNN Loss: 3.596331834793091 | CLS Loss: 0.02577599510550499\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 3.6126058101654053 | KNN Loss: 3.590672016143799 | CLS Loss: 0.021933909505605698\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 3.6072704792022705 | KNN Loss: 3.5823047161102295 | CLS Loss: 0.024965662509202957\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 3.6004717350006104 | KNN Loss: 3.593740463256836 | CLS Loss: 0.006731285713613033\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 3.5991501808166504 | KNN Loss: 3.5682220458984375 | CLS Loss: 0.030928142368793488\n",
      "Epoch: 157, Loss: 3.6050, Train: 0.9968, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 3.590738534927368 | KNN Loss: 3.5774335861206055 | CLS Loss: 0.013304982334375381\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 3.5616848468780518 | KNN Loss: 3.5590875148773193 | CLS Loss: 0.0025972926523536444\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 3.597409963607788 | KNN Loss: 3.5888354778289795 | CLS Loss: 0.00857454352080822\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 3.646953821182251 | KNN Loss: 3.6294987201690674 | CLS Loss: 0.017455032095313072\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 3.569432497024536 | KNN Loss: 3.564033269882202 | CLS Loss: 0.0053992061875760555\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 3.5827579498291016 | KNN Loss: 3.567166805267334 | CLS Loss: 0.015591160394251347\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 3.5999374389648438 | KNN Loss: 3.5834462642669678 | CLS Loss: 0.016491074115037918\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 3.6043193340301514 | KNN Loss: 3.5990872383117676 | CLS Loss: 0.0052321311086416245\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 3.6078085899353027 | KNN Loss: 3.606008768081665 | CLS Loss: 0.0017999104456976056\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 3.615893602371216 | KNN Loss: 3.600757122039795 | CLS Loss: 0.0151364766061306\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 3.5767855644226074 | KNN Loss: 3.5663177967071533 | CLS Loss: 0.01046783197671175\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 3.56618070602417 | KNN Loss: 3.5610241889953613 | CLS Loss: 0.005156613886356354\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 3.559485673904419 | KNN Loss: 3.5559301376342773 | CLS Loss: 0.0035555968061089516\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 3.5914642810821533 | KNN Loss: 3.5827672481536865 | CLS Loss: 0.008696956560015678\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 3.6185083389282227 | KNN Loss: 3.60174560546875 | CLS Loss: 0.01676284708082676\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 3.5578620433807373 | KNN Loss: 3.5487735271453857 | CLS Loss: 0.009088459424674511\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 3.6038851737976074 | KNN Loss: 3.5985889434814453 | CLS Loss: 0.005296175368130207\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 3.58307147026062 | KNN Loss: 3.5599570274353027 | CLS Loss: 0.023114535957574844\n",
      "Epoch: 158, Loss: 3.6036, Train: 0.9966, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 3.614237070083618 | KNN Loss: 3.6063458919525146 | CLS Loss: 0.007891274988651276\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 3.611772298812866 | KNN Loss: 3.6051480770111084 | CLS Loss: 0.006624121218919754\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 3.5703446865081787 | KNN Loss: 3.5623035430908203 | CLS Loss: 0.008041173219680786\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 3.5926458835601807 | KNN Loss: 3.5811607837677 | CLS Loss: 0.011485136114060879\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 3.5842173099517822 | KNN Loss: 3.563760757446289 | CLS Loss: 0.020456481724977493\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 3.5631489753723145 | KNN Loss: 3.542994737625122 | CLS Loss: 0.020154356956481934\n",
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 3.6026458740234375 | KNN Loss: 3.600259780883789 | CLS Loss: 0.002385974396020174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 3.5892202854156494 | KNN Loss: 3.5673866271972656 | CLS Loss: 0.021833760663866997\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 3.623215675354004 | KNN Loss: 3.6153366565704346 | CLS Loss: 0.007879078388214111\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 3.6845314502716064 | KNN Loss: 3.6749908924102783 | CLS Loss: 0.009540514089167118\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 3.65633225440979 | KNN Loss: 3.6339476108551025 | CLS Loss: 0.022384658455848694\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 3.6059606075286865 | KNN Loss: 3.5956501960754395 | CLS Loss: 0.010310517624020576\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 3.6664841175079346 | KNN Loss: 3.6341187953948975 | CLS Loss: 0.032365210354328156\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 3.5950911045074463 | KNN Loss: 3.572720766067505 | CLS Loss: 0.022370368242263794\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 3.5922768115997314 | KNN Loss: 3.5870490074157715 | CLS Loss: 0.005227783694863319\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 3.608496904373169 | KNN Loss: 3.6048758029937744 | CLS Loss: 0.0036211193073540926\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 3.6230971813201904 | KNN Loss: 3.6090009212493896 | CLS Loss: 0.014096364378929138\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 3.577148675918579 | KNN Loss: 3.5600266456604004 | CLS Loss: 0.01712193340063095\n",
      "Epoch: 159, Loss: 3.6060, Train: 0.9959, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 3.5710055828094482 | KNN Loss: 3.564525842666626 | CLS Loss: 0.00647982582449913\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 3.5930538177490234 | KNN Loss: 3.5909976959228516 | CLS Loss: 0.002056158147752285\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 3.5807712078094482 | KNN Loss: 3.5740554332733154 | CLS Loss: 0.006715765222907066\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 3.639176845550537 | KNN Loss: 3.6368465423583984 | CLS Loss: 0.0023302233312278986\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 3.6266114711761475 | KNN Loss: 3.618943214416504 | CLS Loss: 0.007668366190046072\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 3.5892605781555176 | KNN Loss: 3.581925392150879 | CLS Loss: 0.007335221394896507\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 3.618772506713867 | KNN Loss: 3.6144211292266846 | CLS Loss: 0.004351346753537655\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 3.5719358921051025 | KNN Loss: 3.564255714416504 | CLS Loss: 0.0076800622045993805\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 3.672166585922241 | KNN Loss: 3.6474990844726562 | CLS Loss: 0.02466750517487526\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 3.6357600688934326 | KNN Loss: 3.6201364994049072 | CLS Loss: 0.015623468905687332\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 3.5992379188537598 | KNN Loss: 3.581956148147583 | CLS Loss: 0.01728178560733795\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 3.6104753017425537 | KNN Loss: 3.5882208347320557 | CLS Loss: 0.022254474461078644\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 3.627659797668457 | KNN Loss: 3.6184329986572266 | CLS Loss: 0.00922677107155323\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 3.6030373573303223 | KNN Loss: 3.5998733043670654 | CLS Loss: 0.003164026653394103\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 3.6020610332489014 | KNN Loss: 3.5836706161499023 | CLS Loss: 0.018390322104096413\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 3.61392879486084 | KNN Loss: 3.5764660835266113 | CLS Loss: 0.03746270388364792\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 3.5759897232055664 | KNN Loss: 3.573563575744629 | CLS Loss: 0.002426259918138385\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 3.6170108318328857 | KNN Loss: 3.591871500015259 | CLS Loss: 0.025139251723885536\n",
      "Epoch: 160, Loss: 3.6106, Train: 0.9962, Valid: 0.9858, Best: 0.9877\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 3.581862688064575 | KNN Loss: 3.5776071548461914 | CLS Loss: 0.0042555262334644794\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 3.606959342956543 | KNN Loss: 3.5927658081054688 | CLS Loss: 0.014193517155945301\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 3.593172788619995 | KNN Loss: 3.5678882598876953 | CLS Loss: 0.02528451196849346\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 3.6098644733428955 | KNN Loss: 3.599135398864746 | CLS Loss: 0.01072901301085949\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 3.5976345539093018 | KNN Loss: 3.592468023300171 | CLS Loss: 0.0051664747297763824\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 3.604379177093506 | KNN Loss: 3.591843605041504 | CLS Loss: 0.012535566464066505\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 3.612701892852783 | KNN Loss: 3.5926311016082764 | CLS Loss: 0.02007083222270012\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 3.5715384483337402 | KNN Loss: 3.550581216812134 | CLS Loss: 0.0209572222083807\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 3.6153783798217773 | KNN Loss: 3.60854172706604 | CLS Loss: 0.006836769171059132\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 3.6022095680236816 | KNN Loss: 3.578463315963745 | CLS Loss: 0.023746279999613762\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 3.646078109741211 | KNN Loss: 3.6311862468719482 | CLS Loss: 0.014891781844198704\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 3.569026231765747 | KNN Loss: 3.5520308017730713 | CLS Loss: 0.01699542999267578\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 3.6150662899017334 | KNN Loss: 3.595128297805786 | CLS Loss: 0.019938021898269653\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 3.5810599327087402 | KNN Loss: 3.578996181488037 | CLS Loss: 0.0020638001151382923\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 3.574031114578247 | KNN Loss: 3.569551706314087 | CLS Loss: 0.0044793677516281605\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 3.6025283336639404 | KNN Loss: 3.5810446739196777 | CLS Loss: 0.021483752876520157\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 3.6076924800872803 | KNN Loss: 3.581437826156616 | CLS Loss: 0.026254745200276375\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 3.61138653755188 | KNN Loss: 3.5973641872406006 | CLS Loss: 0.014022307470440865\n",
      "Epoch: 161, Loss: 3.6105, Train: 0.9961, Valid: 0.9869, Best: 0.9877\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 3.580469846725464 | KNN Loss: 3.5653040409088135 | CLS Loss: 0.015165772289037704\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 3.551321268081665 | KNN Loss: 3.5475974082946777 | CLS Loss: 0.0037238840013742447\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 3.5689079761505127 | KNN Loss: 3.555664300918579 | CLS Loss: 0.01324359979480505\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 3.578752040863037 | KNN Loss: 3.5769808292388916 | CLS Loss: 0.0017711588880047202\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 3.677021026611328 | KNN Loss: 3.6647422313690186 | CLS Loss: 0.012278759852051735\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 3.5930986404418945 | KNN Loss: 3.5898168087005615 | CLS Loss: 0.003281831508502364\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 3.6120736598968506 | KNN Loss: 3.598536491394043 | CLS Loss: 0.013537229970097542\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 3.619427442550659 | KNN Loss: 3.612861394882202 | CLS Loss: 0.0065659573301672935\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 3.6075360774993896 | KNN Loss: 3.5921895503997803 | CLS Loss: 0.015346602536737919\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 3.5870394706726074 | KNN Loss: 3.5719027519226074 | CLS Loss: 0.015136679634451866\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 3.614509344100952 | KNN Loss: 3.598541736602783 | CLS Loss: 0.01596750319004059\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 3.5763206481933594 | KNN Loss: 3.571641445159912 | CLS Loss: 0.004679214209318161\n",
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 3.6098880767822266 | KNN Loss: 3.5904955863952637 | CLS Loss: 0.019392598420381546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 3.561610460281372 | KNN Loss: 3.5555505752563477 | CLS Loss: 0.006059957202523947\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 3.6036105155944824 | KNN Loss: 3.5765738487243652 | CLS Loss: 0.027036620303988457\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 3.5745978355407715 | KNN Loss: 3.571420192718506 | CLS Loss: 0.00317764631472528\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 3.631453275680542 | KNN Loss: 3.6268575191497803 | CLS Loss: 0.0045957970432937145\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 3.6564853191375732 | KNN Loss: 3.650585651397705 | CLS Loss: 0.005899720825254917\n",
      "Epoch: 162, Loss: 3.6073, Train: 0.9972, Valid: 0.9870, Best: 0.9877\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 3.58699631690979 | KNN Loss: 3.5810065269470215 | CLS Loss: 0.005989685654640198\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 3.6058897972106934 | KNN Loss: 3.595282793045044 | CLS Loss: 0.010607009753584862\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 3.6775765419006348 | KNN Loss: 3.6720309257507324 | CLS Loss: 0.005545685533434153\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 3.640779495239258 | KNN Loss: 3.6291022300720215 | CLS Loss: 0.011677377857267857\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 3.6477138996124268 | KNN Loss: 3.631208658218384 | CLS Loss: 0.016505179926753044\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 3.5996437072753906 | KNN Loss: 3.586956024169922 | CLS Loss: 0.012687641195952892\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 3.611337184906006 | KNN Loss: 3.6086950302124023 | CLS Loss: 0.002642075764015317\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 3.6162798404693604 | KNN Loss: 3.5925559997558594 | CLS Loss: 0.0237239021807909\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 3.6043970584869385 | KNN Loss: 3.5969722270965576 | CLS Loss: 0.007424850948154926\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 3.591306447982788 | KNN Loss: 3.552487373352051 | CLS Loss: 0.0388190820813179\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 3.6628150939941406 | KNN Loss: 3.6465415954589844 | CLS Loss: 0.016273390501737595\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 3.597598075866699 | KNN Loss: 3.5714597702026367 | CLS Loss: 0.02613832801580429\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 3.6601152420043945 | KNN Loss: 3.645550489425659 | CLS Loss: 0.01456479076296091\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 3.598006248474121 | KNN Loss: 3.591945171356201 | CLS Loss: 0.006061112973839045\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 3.6631977558135986 | KNN Loss: 3.6373610496520996 | CLS Loss: 0.025836700573563576\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 3.6817879676818848 | KNN Loss: 3.6650497913360596 | CLS Loss: 0.01673826016485691\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 3.618640899658203 | KNN Loss: 3.605877637863159 | CLS Loss: 0.012763313949108124\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 3.5782017707824707 | KNN Loss: 3.5670950412750244 | CLS Loss: 0.01110663078725338\n",
      "Epoch: 163, Loss: 3.6159, Train: 0.9962, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 3.567984104156494 | KNN Loss: 3.5438661575317383 | CLS Loss: 0.024117879569530487\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 3.6004178524017334 | KNN Loss: 3.5930557250976562 | CLS Loss: 0.007362060714513063\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 3.6215922832489014 | KNN Loss: 3.609152317047119 | CLS Loss: 0.01244007982313633\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 3.636300563812256 | KNN Loss: 3.614924430847168 | CLS Loss: 0.021376116201281548\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 3.56998872756958 | KNN Loss: 3.5651564598083496 | CLS Loss: 0.004832299426198006\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 3.6167595386505127 | KNN Loss: 3.6030681133270264 | CLS Loss: 0.013691453263163567\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 3.6042046546936035 | KNN Loss: 3.5577802658081055 | CLS Loss: 0.04642432928085327\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 3.6221368312835693 | KNN Loss: 3.5981199741363525 | CLS Loss: 0.024016819894313812\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 3.5647518634796143 | KNN Loss: 3.54158616065979 | CLS Loss: 0.023165589198470116\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 3.687791347503662 | KNN Loss: 3.660264015197754 | CLS Loss: 0.027527322992682457\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 3.6736090183258057 | KNN Loss: 3.667515993118286 | CLS Loss: 0.006092987023293972\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 3.6412205696105957 | KNN Loss: 3.608401298522949 | CLS Loss: 0.03281937912106514\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 3.594492197036743 | KNN Loss: 3.5855157375335693 | CLS Loss: 0.008976401761174202\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 3.5688037872314453 | KNN Loss: 3.5669329166412354 | CLS Loss: 0.001870849751867354\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 3.5667808055877686 | KNN Loss: 3.5642385482788086 | CLS Loss: 0.0025421997997909784\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 3.6389317512512207 | KNN Loss: 3.6292977333068848 | CLS Loss: 0.009633976966142654\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 3.622631788253784 | KNN Loss: 3.5943186283111572 | CLS Loss: 0.02831314317882061\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 3.578835964202881 | KNN Loss: 3.574584484100342 | CLS Loss: 0.004251465667039156\n",
      "Epoch: 164, Loss: 3.6077, Train: 0.9968, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 3.6072466373443604 | KNN Loss: 3.603017807006836 | CLS Loss: 0.0042288037948310375\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 3.6163809299468994 | KNN Loss: 3.6074767112731934 | CLS Loss: 0.008904246613383293\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 3.6454548835754395 | KNN Loss: 3.6208577156066895 | CLS Loss: 0.02459721267223358\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 3.6501924991607666 | KNN Loss: 3.6309714317321777 | CLS Loss: 0.019221018999814987\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 3.734344244003296 | KNN Loss: 3.676645040512085 | CLS Loss: 0.057699237018823624\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 3.584038496017456 | KNN Loss: 3.573585271835327 | CLS Loss: 0.010453280992805958\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 3.6060147285461426 | KNN Loss: 3.600564479827881 | CLS Loss: 0.005450352560728788\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 3.6429572105407715 | KNN Loss: 3.6310954093933105 | CLS Loss: 0.01186185609549284\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 3.641110420227051 | KNN Loss: 3.6234734058380127 | CLS Loss: 0.017637019976973534\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 3.584594964981079 | KNN Loss: 3.5595853328704834 | CLS Loss: 0.02500971220433712\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 3.601539134979248 | KNN Loss: 3.5949394702911377 | CLS Loss: 0.006599649786949158\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 3.5813043117523193 | KNN Loss: 3.5676681995391846 | CLS Loss: 0.013636049814522266\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 3.6111345291137695 | KNN Loss: 3.5880894660949707 | CLS Loss: 0.023045046254992485\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 3.563427448272705 | KNN Loss: 3.5485405921936035 | CLS Loss: 0.014886865392327309\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 3.6291394233703613 | KNN Loss: 3.607975959777832 | CLS Loss: 0.02116352878510952\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 3.626387119293213 | KNN Loss: 3.614764451980591 | CLS Loss: 0.01162266917526722\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 3.5909485816955566 | KNN Loss: 3.5868465900421143 | CLS Loss: 0.004102041013538837\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 3.5938520431518555 | KNN Loss: 3.5901682376861572 | CLS Loss: 0.0036836983636021614\n",
      "Epoch: 165, Loss: 3.6178, Train: 0.9967, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 3.5718252658843994 | KNN Loss: 3.5636279582977295 | CLS Loss: 0.008197343908250332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 3.610295295715332 | KNN Loss: 3.599414587020874 | CLS Loss: 0.010880750603973866\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 3.600490093231201 | KNN Loss: 3.5959813594818115 | CLS Loss: 0.004508644342422485\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 3.6041746139526367 | KNN Loss: 3.590022087097168 | CLS Loss: 0.01415251474827528\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 3.6109721660614014 | KNN Loss: 3.5998878479003906 | CLS Loss: 0.011084415018558502\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 3.6076087951660156 | KNN Loss: 3.5857436656951904 | CLS Loss: 0.0218652430921793\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 3.612952709197998 | KNN Loss: 3.600865125656128 | CLS Loss: 0.012087572365999222\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 3.6187756061553955 | KNN Loss: 3.599456548690796 | CLS Loss: 0.01931903511285782\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 3.6160459518432617 | KNN Loss: 3.608914613723755 | CLS Loss: 0.007131369784474373\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 3.6857059001922607 | KNN Loss: 3.672316789627075 | CLS Loss: 0.013389119878411293\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 3.6131365299224854 | KNN Loss: 3.600933074951172 | CLS Loss: 0.012203378602862358\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 3.606097459793091 | KNN Loss: 3.5914149284362793 | CLS Loss: 0.014682522974908352\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 3.597342014312744 | KNN Loss: 3.594923496246338 | CLS Loss: 0.002418607473373413\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 3.618831157684326 | KNN Loss: 3.6075103282928467 | CLS Loss: 0.011320923455059528\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 3.635108232498169 | KNN Loss: 3.621760845184326 | CLS Loss: 0.013347340747714043\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 3.619232177734375 | KNN Loss: 3.5897648334503174 | CLS Loss: 0.029467452317476273\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 3.613369941711426 | KNN Loss: 3.592985153198242 | CLS Loss: 0.020384764298796654\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 3.6827163696289062 | KNN Loss: 3.676665782928467 | CLS Loss: 0.006050578318536282\n",
      "Epoch: 166, Loss: 3.6144, Train: 0.9964, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 3.6906168460845947 | KNN Loss: 3.673062324523926 | CLS Loss: 0.01755456067621708\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 3.5941972732543945 | KNN Loss: 3.5852296352386475 | CLS Loss: 0.008967691101133823\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 3.58994197845459 | KNN Loss: 3.5770440101623535 | CLS Loss: 0.012898005545139313\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 3.5647079944610596 | KNN Loss: 3.5598933696746826 | CLS Loss: 0.004814736545085907\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 3.5657496452331543 | KNN Loss: 3.559605598449707 | CLS Loss: 0.006144037935882807\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 3.6159892082214355 | KNN Loss: 3.6083126068115234 | CLS Loss: 0.007676613982766867\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 3.6270482540130615 | KNN Loss: 3.620619297027588 | CLS Loss: 0.006429016124457121\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 3.639510154724121 | KNN Loss: 3.634033679962158 | CLS Loss: 0.005476510152220726\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 3.5765926837921143 | KNN Loss: 3.570392370223999 | CLS Loss: 0.006200292147696018\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 3.5863654613494873 | KNN Loss: 3.5744524002075195 | CLS Loss: 0.011913090944290161\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 3.627419948577881 | KNN Loss: 3.6189122200012207 | CLS Loss: 0.008507754653692245\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 3.5821306705474854 | KNN Loss: 3.575634241104126 | CLS Loss: 0.006496426649391651\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 3.5996713638305664 | KNN Loss: 3.595689535140991 | CLS Loss: 0.00398183474317193\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 3.5708744525909424 | KNN Loss: 3.561828851699829 | CLS Loss: 0.009045508690178394\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 3.5574843883514404 | KNN Loss: 3.5502817630767822 | CLS Loss: 0.007202724926173687\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 3.572998046875 | KNN Loss: 3.5675301551818848 | CLS Loss: 0.00546778691932559\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 3.6643564701080322 | KNN Loss: 3.6273558139801025 | CLS Loss: 0.03700055554509163\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 3.607515573501587 | KNN Loss: 3.593522787094116 | CLS Loss: 0.013992681168019772\n",
      "Epoch: 167, Loss: 3.6034, Train: 0.9972, Valid: 0.9872, Best: 0.9877\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 3.577457904815674 | KNN Loss: 3.5729684829711914 | CLS Loss: 0.004489453975111246\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 3.656278133392334 | KNN Loss: 3.6259758472442627 | CLS Loss: 0.03030233643949032\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 3.653238534927368 | KNN Loss: 3.6400089263916016 | CLS Loss: 0.013229568488895893\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 3.585545778274536 | KNN Loss: 3.5815157890319824 | CLS Loss: 0.0040299720130860806\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 3.6120688915252686 | KNN Loss: 3.5814173221588135 | CLS Loss: 0.030651496723294258\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 3.6544604301452637 | KNN Loss: 3.6488869190216064 | CLS Loss: 0.0055735413916409016\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 3.5978400707244873 | KNN Loss: 3.582455635070801 | CLS Loss: 0.015384343452751637\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 3.6244609355926514 | KNN Loss: 3.60508394241333 | CLS Loss: 0.019376903772354126\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 3.601105213165283 | KNN Loss: 3.5962233543395996 | CLS Loss: 0.004881778731942177\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 3.5953550338745117 | KNN Loss: 3.5897059440612793 | CLS Loss: 0.005649141501635313\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 3.638861656188965 | KNN Loss: 3.61470103263855 | CLS Loss: 0.024160556495189667\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 3.6459035873413086 | KNN Loss: 3.611952543258667 | CLS Loss: 0.033950962126255035\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 3.6024816036224365 | KNN Loss: 3.5748403072357178 | CLS Loss: 0.027641266584396362\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 3.601583480834961 | KNN Loss: 3.591106653213501 | CLS Loss: 0.01047684159129858\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 3.5988049507141113 | KNN Loss: 3.5897703170776367 | CLS Loss: 0.009034598246216774\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 3.5647928714752197 | KNN Loss: 3.561647415161133 | CLS Loss: 0.0031455347780138254\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 3.6370766162872314 | KNN Loss: 3.6195716857910156 | CLS Loss: 0.01750481314957142\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 3.5899064540863037 | KNN Loss: 3.5796396732330322 | CLS Loss: 0.010266803205013275\n",
      "Epoch: 168, Loss: 3.6099, Train: 0.9970, Valid: 0.9869, Best: 0.9877\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 3.612276077270508 | KNN Loss: 3.6011600494384766 | CLS Loss: 0.011116023175418377\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 3.699911594390869 | KNN Loss: 3.693657398223877 | CLS Loss: 0.006254273932427168\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 3.5710980892181396 | KNN Loss: 3.5600502490997314 | CLS Loss: 0.011047868989408016\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 3.626617670059204 | KNN Loss: 3.6008384227752686 | CLS Loss: 0.025779137387871742\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 3.631009340286255 | KNN Loss: 3.6221883296966553 | CLS Loss: 0.008821070194244385\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 3.609485149383545 | KNN Loss: 3.5954394340515137 | CLS Loss: 0.014045655727386475\n",
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 3.6015920639038086 | KNN Loss: 3.5937507152557373 | CLS Loss: 0.007841452024877071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 3.619835376739502 | KNN Loss: 3.614124298095703 | CLS Loss: 0.0057111261412501335\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 3.659003257751465 | KNN Loss: 3.6524784564971924 | CLS Loss: 0.006524842232465744\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 3.674769163131714 | KNN Loss: 3.6512980461120605 | CLS Loss: 0.023471098393201828\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 3.6432082653045654 | KNN Loss: 3.6216230392456055 | CLS Loss: 0.021585343405604362\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 3.587221145629883 | KNN Loss: 3.576486110687256 | CLS Loss: 0.010734958574175835\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 3.6051242351531982 | KNN Loss: 3.6006057262420654 | CLS Loss: 0.004518571309745312\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 3.5958802700042725 | KNN Loss: 3.586392879486084 | CLS Loss: 0.00948740728199482\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 3.615892171859741 | KNN Loss: 3.604015350341797 | CLS Loss: 0.011876855045557022\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 3.6032238006591797 | KNN Loss: 3.5822229385375977 | CLS Loss: 0.021000975742936134\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 3.5847511291503906 | KNN Loss: 3.574143648147583 | CLS Loss: 0.01060745120048523\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 3.641871690750122 | KNN Loss: 3.6382665634155273 | CLS Loss: 0.0036051867064088583\n",
      "Epoch: 169, Loss: 3.6093, Train: 0.9978, Valid: 0.9885, Best: 0.9885\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 3.5710339546203613 | KNN Loss: 3.566262722015381 | CLS Loss: 0.004771243780851364\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 3.5818116664886475 | KNN Loss: 3.575209617614746 | CLS Loss: 0.006602078676223755\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 3.680931806564331 | KNN Loss: 3.672081232070923 | CLS Loss: 0.008850640617311\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 3.627072334289551 | KNN Loss: 3.6043283939361572 | CLS Loss: 0.022743944078683853\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 3.6329140663146973 | KNN Loss: 3.621689796447754 | CLS Loss: 0.011224322952330112\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 3.546488046646118 | KNN Loss: 3.5423479080200195 | CLS Loss: 0.004140120465308428\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 3.595182180404663 | KNN Loss: 3.581585645675659 | CLS Loss: 0.013596544042229652\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 3.5694522857666016 | KNN Loss: 3.5622293949127197 | CLS Loss: 0.0072229839861392975\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 3.6576526165008545 | KNN Loss: 3.643423080444336 | CLS Loss: 0.014229652471840382\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 3.59051775932312 | KNN Loss: 3.5746281147003174 | CLS Loss: 0.01588970236480236\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 3.590263843536377 | KNN Loss: 3.5699195861816406 | CLS Loss: 0.020344171673059464\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 3.628413677215576 | KNN Loss: 3.616060495376587 | CLS Loss: 0.012353179045021534\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 3.589216470718384 | KNN Loss: 3.5871787071228027 | CLS Loss: 0.0020377226173877716\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 3.6450507640838623 | KNN Loss: 3.6309244632720947 | CLS Loss: 0.01412635762244463\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 3.6077284812927246 | KNN Loss: 3.572557210922241 | CLS Loss: 0.03517136350274086\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 3.6237802505493164 | KNN Loss: 3.616990804672241 | CLS Loss: 0.006789468228816986\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 3.6047561168670654 | KNN Loss: 3.5702927112579346 | CLS Loss: 0.03446345403790474\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 3.640232563018799 | KNN Loss: 3.6329691410064697 | CLS Loss: 0.007263483479619026\n",
      "Epoch: 170, Loss: 3.6092, Train: 0.9960, Valid: 0.9864, Best: 0.9885\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 3.615415573120117 | KNN Loss: 3.5797812938690186 | CLS Loss: 0.03563431277871132\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 3.6271185874938965 | KNN Loss: 3.6125504970550537 | CLS Loss: 0.014568191953003407\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 3.6231980323791504 | KNN Loss: 3.596298933029175 | CLS Loss: 0.02689916454255581\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 3.611348867416382 | KNN Loss: 3.600548505783081 | CLS Loss: 0.010800473392009735\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 3.5870795249938965 | KNN Loss: 3.5644800662994385 | CLS Loss: 0.022599363699555397\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 3.6494550704956055 | KNN Loss: 3.6118996143341064 | CLS Loss: 0.037555452436208725\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 3.603860855102539 | KNN Loss: 3.598806381225586 | CLS Loss: 0.005054559092968702\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 3.5705230236053467 | KNN Loss: 3.556506633758545 | CLS Loss: 0.014016316272318363\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 3.634544849395752 | KNN Loss: 3.6160147190093994 | CLS Loss: 0.01853024959564209\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 3.5674664974212646 | KNN Loss: 3.552776336669922 | CLS Loss: 0.014690101146697998\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 3.5811328887939453 | KNN Loss: 3.579550266265869 | CLS Loss: 0.0015825291629880667\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 3.582064390182495 | KNN Loss: 3.5606589317321777 | CLS Loss: 0.021405352279543877\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 3.569493532180786 | KNN Loss: 3.5573134422302246 | CLS Loss: 0.01218006107956171\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 3.618802547454834 | KNN Loss: 3.576289653778076 | CLS Loss: 0.04251297935843468\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 3.5968358516693115 | KNN Loss: 3.584237575531006 | CLS Loss: 0.012598246335983276\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 3.6017940044403076 | KNN Loss: 3.5652265548706055 | CLS Loss: 0.03656740114092827\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 3.6021223068237305 | KNN Loss: 3.591630697250366 | CLS Loss: 0.010491625405848026\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 3.6230387687683105 | KNN Loss: 3.6181468963623047 | CLS Loss: 0.004891825839877129\n",
      "Epoch: 171, Loss: 3.6068, Train: 0.9958, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 3.645777940750122 | KNN Loss: 3.640007257461548 | CLS Loss: 0.0057706148363649845\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 3.6403040885925293 | KNN Loss: 3.6294875144958496 | CLS Loss: 0.01081667747348547\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 3.5936837196350098 | KNN Loss: 3.582763910293579 | CLS Loss: 0.010919740423560143\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 3.6076154708862305 | KNN Loss: 3.5700340270996094 | CLS Loss: 0.037581343203783035\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 3.6596431732177734 | KNN Loss: 3.639010190963745 | CLS Loss: 0.020633015781641006\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 3.5825517177581787 | KNN Loss: 3.5705249309539795 | CLS Loss: 0.012026801705360413\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 3.571319103240967 | KNN Loss: 3.5582642555236816 | CLS Loss: 0.0130548607558012\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 3.5740602016448975 | KNN Loss: 3.557551622390747 | CLS Loss: 0.016508523374795914\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 3.627980947494507 | KNN Loss: 3.609259843826294 | CLS Loss: 0.018721148371696472\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 3.5799012184143066 | KNN Loss: 3.573850154876709 | CLS Loss: 0.006051101256161928\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 3.6054248809814453 | KNN Loss: 3.5943851470947266 | CLS Loss: 0.011039730161428452\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 3.6299004554748535 | KNN Loss: 3.6145083904266357 | CLS Loss: 0.015392044559121132\n",
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 3.6584177017211914 | KNN Loss: 3.636775493621826 | CLS Loss: 0.021642228588461876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 3.6051454544067383 | KNN Loss: 3.5983338356018066 | CLS Loss: 0.006811695639044046\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 3.595937967300415 | KNN Loss: 3.583299160003662 | CLS Loss: 0.012638726271688938\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 3.6070070266723633 | KNN Loss: 3.5919599533081055 | CLS Loss: 0.015047064982354641\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 3.668304920196533 | KNN Loss: 3.660273551940918 | CLS Loss: 0.008031333796679974\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 3.6334006786346436 | KNN Loss: 3.622349977493286 | CLS Loss: 0.01105080172419548\n",
      "Epoch: 172, Loss: 3.6123, Train: 0.9956, Valid: 0.9863, Best: 0.9885\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 3.6683459281921387 | KNN Loss: 3.640483856201172 | CLS Loss: 0.02786218374967575\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 3.585043430328369 | KNN Loss: 3.5653820037841797 | CLS Loss: 0.019661331549286842\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 3.6170523166656494 | KNN Loss: 3.613548755645752 | CLS Loss: 0.003503484185785055\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 3.6020169258117676 | KNN Loss: 3.587163209915161 | CLS Loss: 0.014853759668767452\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 3.628004312515259 | KNN Loss: 3.6147778034210205 | CLS Loss: 0.013226528652012348\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 3.5894155502319336 | KNN Loss: 3.5771312713623047 | CLS Loss: 0.012284292839467525\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 3.603734016418457 | KNN Loss: 3.5816102027893066 | CLS Loss: 0.022123778238892555\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 3.5785703659057617 | KNN Loss: 3.5699422359466553 | CLS Loss: 0.008628174662590027\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 3.6005101203918457 | KNN Loss: 3.576023578643799 | CLS Loss: 0.02448642998933792\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 3.685421943664551 | KNN Loss: 3.679983377456665 | CLS Loss: 0.005438646767288446\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 3.680346965789795 | KNN Loss: 3.64849853515625 | CLS Loss: 0.031848542392253876\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 3.6633992195129395 | KNN Loss: 3.6496806144714355 | CLS Loss: 0.013718580827116966\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 3.6369423866271973 | KNN Loss: 3.6235949993133545 | CLS Loss: 0.013347465544939041\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 3.5851190090179443 | KNN Loss: 3.559892416000366 | CLS Loss: 0.025226706638932228\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 3.617316246032715 | KNN Loss: 3.6055281162261963 | CLS Loss: 0.01178824808448553\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 3.623702049255371 | KNN Loss: 3.6042816638946533 | CLS Loss: 0.019420327618718147\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 3.6737165451049805 | KNN Loss: 3.6416521072387695 | CLS Loss: 0.03206431865692139\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 3.6265342235565186 | KNN Loss: 3.6116464138031006 | CLS Loss: 0.014887816272675991\n",
      "Epoch: 173, Loss: 3.6158, Train: 0.9961, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 3.6221566200256348 | KNN Loss: 3.615140199661255 | CLS Loss: 0.007016466930508614\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 3.5783488750457764 | KNN Loss: 3.575477123260498 | CLS Loss: 0.0028718505054712296\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 3.6032297611236572 | KNN Loss: 3.583120107650757 | CLS Loss: 0.020109742879867554\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 3.563668727874756 | KNN Loss: 3.56038236618042 | CLS Loss: 0.0032864203676581383\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 3.6324691772460938 | KNN Loss: 3.6187422275543213 | CLS Loss: 0.013726875185966492\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 3.5672767162323 | KNN Loss: 3.557875871658325 | CLS Loss: 0.009400790557265282\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 3.6153905391693115 | KNN Loss: 3.6060447692871094 | CLS Loss: 0.0093457056209445\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 3.5681955814361572 | KNN Loss: 3.563999652862549 | CLS Loss: 0.004195912275463343\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 3.5679075717926025 | KNN Loss: 3.563479423522949 | CLS Loss: 0.004428078420460224\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 3.5611114501953125 | KNN Loss: 3.5458438396453857 | CLS Loss: 0.015267675742506981\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 3.565580368041992 | KNN Loss: 3.5611917972564697 | CLS Loss: 0.004388511646538973\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 3.6221275329589844 | KNN Loss: 3.612825632095337 | CLS Loss: 0.009301900863647461\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 3.568075656890869 | KNN Loss: 3.5498931407928467 | CLS Loss: 0.018182439729571342\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 3.557321310043335 | KNN Loss: 3.5505049228668213 | CLS Loss: 0.006816321983933449\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 3.6323230266571045 | KNN Loss: 3.622077226638794 | CLS Loss: 0.010245821438729763\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 3.5834062099456787 | KNN Loss: 3.566105365753174 | CLS Loss: 0.017300857231020927\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 3.591400146484375 | KNN Loss: 3.5786569118499756 | CLS Loss: 0.012743145227432251\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 3.596721887588501 | KNN Loss: 3.5919158458709717 | CLS Loss: 0.004806126933544874\n",
      "Epoch: 174, Loss: 3.6007, Train: 0.9966, Valid: 0.9863, Best: 0.9885\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 3.5830371379852295 | KNN Loss: 3.5757267475128174 | CLS Loss: 0.007310398388653994\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 3.586662530899048 | KNN Loss: 3.5690948963165283 | CLS Loss: 0.01756756380200386\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 3.558807611465454 | KNN Loss: 3.5557966232299805 | CLS Loss: 0.0030110476072877645\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 3.619307279586792 | KNN Loss: 3.58534574508667 | CLS Loss: 0.03396147862076759\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 3.5965158939361572 | KNN Loss: 3.592294692993164 | CLS Loss: 0.004221318289637566\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 3.6113734245300293 | KNN Loss: 3.6026601791381836 | CLS Loss: 0.008713224902749062\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 3.648552179336548 | KNN Loss: 3.6435024738311768 | CLS Loss: 0.005049721337854862\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 3.6078524589538574 | KNN Loss: 3.5923380851745605 | CLS Loss: 0.015514449216425419\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 3.6071836948394775 | KNN Loss: 3.603609323501587 | CLS Loss: 0.003574270522221923\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 3.5728747844696045 | KNN Loss: 3.553895950317383 | CLS Loss: 0.018978897482156754\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 3.6112120151519775 | KNN Loss: 3.607074022293091 | CLS Loss: 0.004137996584177017\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 3.5870072841644287 | KNN Loss: 3.557485580444336 | CLS Loss: 0.029521595686674118\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 3.5792489051818848 | KNN Loss: 3.569483518600464 | CLS Loss: 0.009765361435711384\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 3.5810272693634033 | KNN Loss: 3.57881498336792 | CLS Loss: 0.0022122696973383427\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 3.595913887023926 | KNN Loss: 3.592238664627075 | CLS Loss: 0.0036753066815435886\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 3.6428825855255127 | KNN Loss: 3.6394169330596924 | CLS Loss: 0.003465702524408698\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 3.7044787406921387 | KNN Loss: 3.69134521484375 | CLS Loss: 0.013133514672517776\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 3.5764455795288086 | KNN Loss: 3.5718026161193848 | CLS Loss: 0.004642870277166367\n",
      "Epoch: 175, Loss: 3.6079, Train: 0.9959, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 3.597062587738037 | KNN Loss: 3.592784881591797 | CLS Loss: 0.004277675878256559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 3.5862302780151367 | KNN Loss: 3.569478988647461 | CLS Loss: 0.016751373186707497\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 3.5696170330047607 | KNN Loss: 3.563492774963379 | CLS Loss: 0.00612422963604331\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 3.5802314281463623 | KNN Loss: 3.572284460067749 | CLS Loss: 0.007946949452161789\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 3.575937271118164 | KNN Loss: 3.5668232440948486 | CLS Loss: 0.009114140644669533\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 3.6394729614257812 | KNN Loss: 3.6343910694122314 | CLS Loss: 0.005081782117486\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 3.6693246364593506 | KNN Loss: 3.650700569152832 | CLS Loss: 0.01862398535013199\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 3.5968399047851562 | KNN Loss: 3.5809834003448486 | CLS Loss: 0.01585659757256508\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 3.5746941566467285 | KNN Loss: 3.5732407569885254 | CLS Loss: 0.0014533019857481122\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 3.5817160606384277 | KNN Loss: 3.5723748207092285 | CLS Loss: 0.00934113934636116\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 3.5632998943328857 | KNN Loss: 3.5550296306610107 | CLS Loss: 0.00827016495168209\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 3.615565061569214 | KNN Loss: 3.5996835231781006 | CLS Loss: 0.015881605446338654\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 3.6144421100616455 | KNN Loss: 3.603696823120117 | CLS Loss: 0.010745291598141193\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 3.5857105255126953 | KNN Loss: 3.5441901683807373 | CLS Loss: 0.04152039438486099\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 3.636713981628418 | KNN Loss: 3.5828444957733154 | CLS Loss: 0.05386944115161896\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 3.5841963291168213 | KNN Loss: 3.560659170150757 | CLS Loss: 0.023537078872323036\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 3.7389442920684814 | KNN Loss: 3.7038958072662354 | CLS Loss: 0.035048484802246094\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 3.624539852142334 | KNN Loss: 3.6113784313201904 | CLS Loss: 0.013161426410079002\n",
      "Epoch: 176, Loss: 3.6081, Train: 0.9970, Valid: 0.9876, Best: 0.9885\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 3.6171340942382812 | KNN Loss: 3.6075620651245117 | CLS Loss: 0.009571961127221584\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 3.6408791542053223 | KNN Loss: 3.6262753009796143 | CLS Loss: 0.014603805728256702\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 3.5653693675994873 | KNN Loss: 3.5535495281219482 | CLS Loss: 0.011819778941571712\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 3.5560452938079834 | KNN Loss: 3.5548553466796875 | CLS Loss: 0.0011898381635546684\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 3.5671439170837402 | KNN Loss: 3.557138681411743 | CLS Loss: 0.010005163960158825\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 3.570523262023926 | KNN Loss: 3.5666615962982178 | CLS Loss: 0.003861610312014818\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 3.593045949935913 | KNN Loss: 3.590250253677368 | CLS Loss: 0.002795698819682002\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 3.5925514698028564 | KNN Loss: 3.557605266571045 | CLS Loss: 0.0349462553858757\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 3.603316068649292 | KNN Loss: 3.5819883346557617 | CLS Loss: 0.021327819675207138\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 3.593597173690796 | KNN Loss: 3.5850846767425537 | CLS Loss: 0.008512464351952076\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 3.580465316772461 | KNN Loss: 3.5616254806518555 | CLS Loss: 0.018839936703443527\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 3.591583728790283 | KNN Loss: 3.581758499145508 | CLS Loss: 0.009825323708355427\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 3.5558032989501953 | KNN Loss: 3.552424907684326 | CLS Loss: 0.0033784753177314997\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 3.6165266036987305 | KNN Loss: 3.6099085807800293 | CLS Loss: 0.00661794887855649\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 3.615579128265381 | KNN Loss: 3.6129989624023438 | CLS Loss: 0.002580126980319619\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 3.6073639392852783 | KNN Loss: 3.6042046546936035 | CLS Loss: 0.0031591986771672964\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 3.5557363033294678 | KNN Loss: 3.5357518196105957 | CLS Loss: 0.019984446465969086\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 3.6007418632507324 | KNN Loss: 3.5941734313964844 | CLS Loss: 0.006568530574440956\n",
      "Epoch: 177, Loss: 3.6049, Train: 0.9964, Valid: 0.9852, Best: 0.9885\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 3.625643491744995 | KNN Loss: 3.603689670562744 | CLS Loss: 0.021953830495476723\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 3.5801117420196533 | KNN Loss: 3.563528060913086 | CLS Loss: 0.016583656892180443\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 3.6082072257995605 | KNN Loss: 3.6020209789276123 | CLS Loss: 0.006186338607221842\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 3.5825867652893066 | KNN Loss: 3.5726208686828613 | CLS Loss: 0.009965913370251656\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 3.6083638668060303 | KNN Loss: 3.5806233882904053 | CLS Loss: 0.02774043008685112\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 3.6630373001098633 | KNN Loss: 3.65598201751709 | CLS Loss: 0.007055386900901794\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 3.584038496017456 | KNN Loss: 3.581603765487671 | CLS Loss: 0.002434766385704279\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 3.571791172027588 | KNN Loss: 3.5551183223724365 | CLS Loss: 0.01667286455631256\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 3.623903512954712 | KNN Loss: 3.618011236190796 | CLS Loss: 0.005892361514270306\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 3.563318967819214 | KNN Loss: 3.5494272708892822 | CLS Loss: 0.013891763053834438\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 3.5775303840637207 | KNN Loss: 3.5758323669433594 | CLS Loss: 0.0016981272492557764\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 3.583409070968628 | KNN Loss: 3.563131809234619 | CLS Loss: 0.02027723751962185\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 3.5769667625427246 | KNN Loss: 3.5656683444976807 | CLS Loss: 0.011298366822302341\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 3.6322176456451416 | KNN Loss: 3.621896743774414 | CLS Loss: 0.010320872068405151\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 3.632789373397827 | KNN Loss: 3.618933916091919 | CLS Loss: 0.01385556161403656\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 3.6351261138916016 | KNN Loss: 3.6227002143859863 | CLS Loss: 0.012425814755260944\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 3.5895016193389893 | KNN Loss: 3.5834505558013916 | CLS Loss: 0.006051060277968645\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 3.6329731941223145 | KNN Loss: 3.6114931106567383 | CLS Loss: 0.02148018404841423\n",
      "Epoch: 178, Loss: 3.6053, Train: 0.9970, Valid: 0.9873, Best: 0.9885\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 3.618440866470337 | KNN Loss: 3.6129300594329834 | CLS Loss: 0.005510798655450344\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 3.5957016944885254 | KNN Loss: 3.5896406173706055 | CLS Loss: 0.006061123684048653\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 3.568218946456909 | KNN Loss: 3.5666611194610596 | CLS Loss: 0.001557753304950893\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 3.574681043624878 | KNN Loss: 3.569553852081299 | CLS Loss: 0.005127291660755873\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 3.5533640384674072 | KNN Loss: 3.55076003074646 | CLS Loss: 0.0026039297226816416\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 3.560127019882202 | KNN Loss: 3.545822858810425 | CLS Loss: 0.014304245822131634\n",
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 3.5985121726989746 | KNN Loss: 3.5690064430236816 | CLS Loss: 0.029505670070648193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 3.608278512954712 | KNN Loss: 3.591878890991211 | CLS Loss: 0.016399675980210304\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 3.629469156265259 | KNN Loss: 3.6031579971313477 | CLS Loss: 0.02631116472184658\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 3.5785350799560547 | KNN Loss: 3.573194980621338 | CLS Loss: 0.005340203642845154\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 3.6118016242980957 | KNN Loss: 3.601712226867676 | CLS Loss: 0.010089440271258354\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 3.6131718158721924 | KNN Loss: 3.5885632038116455 | CLS Loss: 0.024608612060546875\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 3.6418910026550293 | KNN Loss: 3.6226749420166016 | CLS Loss: 0.019216017797589302\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 3.5918469429016113 | KNN Loss: 3.5655362606048584 | CLS Loss: 0.026310762390494347\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 3.613361358642578 | KNN Loss: 3.58186411857605 | CLS Loss: 0.031497277319431305\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 3.557523488998413 | KNN Loss: 3.555386543273926 | CLS Loss: 0.0021368293091654778\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 3.6049110889434814 | KNN Loss: 3.6021203994750977 | CLS Loss: 0.0027906347531825304\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 3.640660047531128 | KNN Loss: 3.638838052749634 | CLS Loss: 0.0018220256315544248\n",
      "Epoch: 179, Loss: 3.6053, Train: 0.9969, Valid: 0.9869, Best: 0.9885\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 3.654358148574829 | KNN Loss: 3.6368491649627686 | CLS Loss: 0.01750905252993107\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 3.6413753032684326 | KNN Loss: 3.6250522136688232 | CLS Loss: 0.016323000192642212\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 3.6220343112945557 | KNN Loss: 3.61728835105896 | CLS Loss: 0.004746012855321169\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 3.5839736461639404 | KNN Loss: 3.5734663009643555 | CLS Loss: 0.010507408529520035\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 3.571599006652832 | KNN Loss: 3.5679163932800293 | CLS Loss: 0.003682501846924424\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 3.6145882606506348 | KNN Loss: 3.603804111480713 | CLS Loss: 0.01078405138105154\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 3.6284072399139404 | KNN Loss: 3.6210410594940186 | CLS Loss: 0.007366149686276913\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 3.5879621505737305 | KNN Loss: 3.582549571990967 | CLS Loss: 0.00541264284402132\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 3.6137847900390625 | KNN Loss: 3.6120340824127197 | CLS Loss: 0.0017506962176412344\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 3.583493709564209 | KNN Loss: 3.559920072555542 | CLS Loss: 0.023573577404022217\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 3.617464303970337 | KNN Loss: 3.615008592605591 | CLS Loss: 0.002455673413351178\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 3.5875632762908936 | KNN Loss: 3.575667381286621 | CLS Loss: 0.011895991861820221\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 3.650559186935425 | KNN Loss: 3.6381607055664062 | CLS Loss: 0.012398368678987026\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 3.6327154636383057 | KNN Loss: 3.6128690242767334 | CLS Loss: 0.019846389070153236\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 3.5589659214019775 | KNN Loss: 3.5402629375457764 | CLS Loss: 0.018702920526266098\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 3.6131699085235596 | KNN Loss: 3.608581066131592 | CLS Loss: 0.004588820971548557\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 3.6157190799713135 | KNN Loss: 3.5958869457244873 | CLS Loss: 0.019832134246826172\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 3.5696237087249756 | KNN Loss: 3.5659499168395996 | CLS Loss: 0.003673811675980687\n",
      "Epoch: 180, Loss: 3.6069, Train: 0.9970, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 3.61405611038208 | KNN Loss: 3.611461877822876 | CLS Loss: 0.0025941841304302216\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 3.5689525604248047 | KNN Loss: 3.565215587615967 | CLS Loss: 0.003737058024853468\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 3.6325738430023193 | KNN Loss: 3.6250596046447754 | CLS Loss: 0.00751431193202734\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 3.5933165550231934 | KNN Loss: 3.589707136154175 | CLS Loss: 0.0036093262024223804\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 3.6202375888824463 | KNN Loss: 3.6180474758148193 | CLS Loss: 0.0021900804713368416\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 3.56187105178833 | KNN Loss: 3.5566458702087402 | CLS Loss: 0.005225180182605982\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 3.643921375274658 | KNN Loss: 3.6214687824249268 | CLS Loss: 0.022452514618635178\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 3.5430126190185547 | KNN Loss: 3.5421814918518066 | CLS Loss: 0.0008310727425850928\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 3.589203357696533 | KNN Loss: 3.5860061645507812 | CLS Loss: 0.003197306767106056\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 3.619028091430664 | KNN Loss: 3.609038829803467 | CLS Loss: 0.009989256970584393\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 3.593219041824341 | KNN Loss: 3.5843698978424072 | CLS Loss: 0.008849046193063259\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 3.6657557487487793 | KNN Loss: 3.6295502185821533 | CLS Loss: 0.03620555251836777\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 3.6239843368530273 | KNN Loss: 3.609088182449341 | CLS Loss: 0.014896036125719547\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 3.632824420928955 | KNN Loss: 3.6190035343170166 | CLS Loss: 0.013820946216583252\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 3.5694451332092285 | KNN Loss: 3.564870834350586 | CLS Loss: 0.004574293736368418\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 3.62465238571167 | KNN Loss: 3.5993099212646484 | CLS Loss: 0.025342529639601707\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 3.61810302734375 | KNN Loss: 3.6025614738464355 | CLS Loss: 0.015541482716798782\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 3.6310315132141113 | KNN Loss: 3.618901491165161 | CLS Loss: 0.01213013380765915\n",
      "Epoch: 181, Loss: 3.6055, Train: 0.9970, Valid: 0.9878, Best: 0.9885\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 3.579075336456299 | KNN Loss: 3.573779821395874 | CLS Loss: 0.005295623559504747\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 3.584465503692627 | KNN Loss: 3.5830273628234863 | CLS Loss: 0.0014382591471076012\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 3.611126661300659 | KNN Loss: 3.585975408554077 | CLS Loss: 0.02515132911503315\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 3.6364846229553223 | KNN Loss: 3.6323134899139404 | CLS Loss: 0.004171017091721296\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 3.6125199794769287 | KNN Loss: 3.5949223041534424 | CLS Loss: 0.0175976250320673\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 3.6486904621124268 | KNN Loss: 3.633270263671875 | CLS Loss: 0.015420115552842617\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 3.573664665222168 | KNN Loss: 3.552717924118042 | CLS Loss: 0.02094663679599762\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 3.631228446960449 | KNN Loss: 3.592275857925415 | CLS Loss: 0.03895266726613045\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 3.6200551986694336 | KNN Loss: 3.599950075149536 | CLS Loss: 0.0201050266623497\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 3.646228790283203 | KNN Loss: 3.6365435123443604 | CLS Loss: 0.009685240685939789\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 3.6590638160705566 | KNN Loss: 3.6534159183502197 | CLS Loss: 0.005647944286465645\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 3.6279516220092773 | KNN Loss: 3.6222410202026367 | CLS Loss: 0.005710584577172995\n",
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 3.664379119873047 | KNN Loss: 3.6434707641601562 | CLS Loss: 0.020908297970891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 3.652622938156128 | KNN Loss: 3.6363136768341064 | CLS Loss: 0.01630914770066738\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 3.5854251384735107 | KNN Loss: 3.582097291946411 | CLS Loss: 0.0033279391936957836\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 3.6310925483703613 | KNN Loss: 3.627176284790039 | CLS Loss: 0.0039161862805485725\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 3.628720760345459 | KNN Loss: 3.601499557495117 | CLS Loss: 0.0272213164716959\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 3.613668203353882 | KNN Loss: 3.6050148010253906 | CLS Loss: 0.008653485216200352\n",
      "Epoch: 182, Loss: 3.6052, Train: 0.9967, Valid: 0.9869, Best: 0.9885\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 3.586686134338379 | KNN Loss: 3.5837438106536865 | CLS Loss: 0.002942229388281703\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 3.640517234802246 | KNN Loss: 3.6372783184051514 | CLS Loss: 0.003238936886191368\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 3.6064372062683105 | KNN Loss: 3.590362787246704 | CLS Loss: 0.016074299812316895\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 3.6190345287323 | KNN Loss: 3.6024041175842285 | CLS Loss: 0.016630465164780617\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 3.6165788173675537 | KNN Loss: 3.6149327754974365 | CLS Loss: 0.0016459617763757706\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 3.5492453575134277 | KNN Loss: 3.546107053756714 | CLS Loss: 0.003138401545584202\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 3.572774887084961 | KNN Loss: 3.5688679218292236 | CLS Loss: 0.003906986676156521\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 3.6063828468322754 | KNN Loss: 3.5932023525238037 | CLS Loss: 0.013180432841181755\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 3.6331605911254883 | KNN Loss: 3.6053638458251953 | CLS Loss: 0.027796674519777298\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 3.6026675701141357 | KNN Loss: 3.5916857719421387 | CLS Loss: 0.010981723666191101\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 3.5860705375671387 | KNN Loss: 3.5817055702209473 | CLS Loss: 0.004364873748272657\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 3.5928990840911865 | KNN Loss: 3.57814884185791 | CLS Loss: 0.014750305563211441\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 3.6661832332611084 | KNN Loss: 3.6605639457702637 | CLS Loss: 0.0056193070486187935\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 3.597184419631958 | KNN Loss: 3.577259063720703 | CLS Loss: 0.019925329834222794\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 3.6171326637268066 | KNN Loss: 3.588719606399536 | CLS Loss: 0.02841312810778618\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 3.5552453994750977 | KNN Loss: 3.5439436435699463 | CLS Loss: 0.011301754973828793\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 3.636401414871216 | KNN Loss: 3.622450590133667 | CLS Loss: 0.013950706459581852\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 3.578611373901367 | KNN Loss: 3.5716638565063477 | CLS Loss: 0.006947565823793411\n",
      "Epoch: 183, Loss: 3.6073, Train: 0.9973, Valid: 0.9874, Best: 0.9885\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 3.6137754917144775 | KNN Loss: 3.597959518432617 | CLS Loss: 0.015816058963537216\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 3.6061415672302246 | KNN Loss: 3.5968217849731445 | CLS Loss: 0.009319746866822243\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 3.6446077823638916 | KNN Loss: 3.630513906478882 | CLS Loss: 0.014093765057623386\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 3.6182661056518555 | KNN Loss: 3.5911056995391846 | CLS Loss: 0.02716033160686493\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 3.6109421253204346 | KNN Loss: 3.6044750213623047 | CLS Loss: 0.006466994062066078\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 3.6518452167510986 | KNN Loss: 3.63206148147583 | CLS Loss: 0.019783684983849525\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 3.6131956577301025 | KNN Loss: 3.6079883575439453 | CLS Loss: 0.0052072517573833466\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 3.5673725605010986 | KNN Loss: 3.5514633655548096 | CLS Loss: 0.01590917445719242\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 3.571850538253784 | KNN Loss: 3.565988302230835 | CLS Loss: 0.005862311460077763\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 3.5961813926696777 | KNN Loss: 3.5922553539276123 | CLS Loss: 0.003926130477339029\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 3.612793207168579 | KNN Loss: 3.5942001342773438 | CLS Loss: 0.018593119457364082\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 3.5594067573547363 | KNN Loss: 3.5525617599487305 | CLS Loss: 0.006844913121312857\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 3.56805419921875 | KNN Loss: 3.5587220191955566 | CLS Loss: 0.009332163259387016\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 3.5523059368133545 | KNN Loss: 3.536971092224121 | CLS Loss: 0.01533489115536213\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 3.5701587200164795 | KNN Loss: 3.5671546459198 | CLS Loss: 0.0030041271820664406\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 3.6251564025878906 | KNN Loss: 3.6051323413848877 | CLS Loss: 0.020024100318551064\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 3.6016883850097656 | KNN Loss: 3.581321954727173 | CLS Loss: 0.02036653645336628\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 3.601367712020874 | KNN Loss: 3.5837202072143555 | CLS Loss: 0.017647413536906242\n",
      "Epoch: 184, Loss: 3.6040, Train: 0.9948, Valid: 0.9840, Best: 0.9885\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 3.623744010925293 | KNN Loss: 3.5922691822052 | CLS Loss: 0.03147486224770546\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 3.6890981197357178 | KNN Loss: 3.6737618446350098 | CLS Loss: 0.01533631980419159\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 3.5845372676849365 | KNN Loss: 3.5721848011016846 | CLS Loss: 0.012352455407381058\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 3.6602623462677 | KNN Loss: 3.6484220027923584 | CLS Loss: 0.011840336956083775\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 3.6260628700256348 | KNN Loss: 3.615093946456909 | CLS Loss: 0.010968975722789764\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 3.5862104892730713 | KNN Loss: 3.5794119834899902 | CLS Loss: 0.006798449903726578\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 3.5883140563964844 | KNN Loss: 3.5752148628234863 | CLS Loss: 0.013099227100610733\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 3.617903709411621 | KNN Loss: 3.6019203662872314 | CLS Loss: 0.015983417630195618\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 3.7089686393737793 | KNN Loss: 3.702885866165161 | CLS Loss: 0.006082886829972267\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 3.6187875270843506 | KNN Loss: 3.61191725730896 | CLS Loss: 0.006870333105325699\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 3.5970237255096436 | KNN Loss: 3.5760955810546875 | CLS Loss: 0.02092810347676277\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 3.601621150970459 | KNN Loss: 3.5908203125 | CLS Loss: 0.010800763964653015\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 3.581925392150879 | KNN Loss: 3.5806429386138916 | CLS Loss: 0.001282369950786233\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 3.5747945308685303 | KNN Loss: 3.5652518272399902 | CLS Loss: 0.00954266358166933\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 3.605137586593628 | KNN Loss: 3.5990679264068604 | CLS Loss: 0.006069720722734928\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 3.6657934188842773 | KNN Loss: 3.610973834991455 | CLS Loss: 0.054819490760564804\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 3.6734976768493652 | KNN Loss: 3.6544806957244873 | CLS Loss: 0.019016971811652184\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 3.585698366165161 | KNN Loss: 3.5749847888946533 | CLS Loss: 0.010713654570281506\n",
      "Epoch: 185, Loss: 3.6070, Train: 0.9973, Valid: 0.9880, Best: 0.9885\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 3.5769224166870117 | KNN Loss: 3.575533628463745 | CLS Loss: 0.001388860633596778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 3.5789926052093506 | KNN Loss: 3.5747244358062744 | CLS Loss: 0.004268075339496136\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 3.6802499294281006 | KNN Loss: 3.6704108715057373 | CLS Loss: 0.009839098900556564\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 3.640944242477417 | KNN Loss: 3.633958339691162 | CLS Loss: 0.006985971704125404\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 3.641639471054077 | KNN Loss: 3.6195478439331055 | CLS Loss: 0.02209164947271347\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 3.5816233158111572 | KNN Loss: 3.578193426132202 | CLS Loss: 0.0034298275131732225\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 3.5820138454437256 | KNN Loss: 3.576108932495117 | CLS Loss: 0.005904989317059517\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 3.6609060764312744 | KNN Loss: 3.656869888305664 | CLS Loss: 0.004036185797303915\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 3.5614418983459473 | KNN Loss: 3.5536398887634277 | CLS Loss: 0.0078020161017775536\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 3.5662169456481934 | KNN Loss: 3.552929401397705 | CLS Loss: 0.013287466950714588\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 3.6171340942382812 | KNN Loss: 3.5947983264923096 | CLS Loss: 0.022335778921842575\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 3.592339277267456 | KNN Loss: 3.5812559127807617 | CLS Loss: 0.01108328066766262\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 3.5595972537994385 | KNN Loss: 3.5528056621551514 | CLS Loss: 0.006791687570512295\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 3.5860447883605957 | KNN Loss: 3.566666841506958 | CLS Loss: 0.019377849996089935\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 3.556943655014038 | KNN Loss: 3.5534355640411377 | CLS Loss: 0.0035080686211586\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 3.5749030113220215 | KNN Loss: 3.5589206218719482 | CLS Loss: 0.015982452780008316\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 3.5990657806396484 | KNN Loss: 3.5928003787994385 | CLS Loss: 0.006265520118176937\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 3.614811420440674 | KNN Loss: 3.591937303543091 | CLS Loss: 0.022874077782034874\n",
      "Epoch: 186, Loss: 3.6055, Train: 0.9959, Valid: 0.9863, Best: 0.9885\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 3.6312291622161865 | KNN Loss: 3.6210482120513916 | CLS Loss: 0.010181068442761898\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 3.6011273860931396 | KNN Loss: 3.592378616333008 | CLS Loss: 0.008748656138777733\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 3.703303575515747 | KNN Loss: 3.6938793659210205 | CLS Loss: 0.009424152784049511\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 3.626427173614502 | KNN Loss: 3.6217658519744873 | CLS Loss: 0.004661279730498791\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 3.6037282943725586 | KNN Loss: 3.600346803665161 | CLS Loss: 0.003381415270268917\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 3.579526901245117 | KNN Loss: 3.5749611854553223 | CLS Loss: 0.004565711598843336\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 3.5923352241516113 | KNN Loss: 3.5806546211242676 | CLS Loss: 0.011680537834763527\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 3.615475654602051 | KNN Loss: 3.6070075035095215 | CLS Loss: 0.00846804492175579\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 3.6304829120635986 | KNN Loss: 3.617438793182373 | CLS Loss: 0.013044103980064392\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 3.60695219039917 | KNN Loss: 3.5952608585357666 | CLS Loss: 0.011691322550177574\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 3.64275860786438 | KNN Loss: 3.6276819705963135 | CLS Loss: 0.015076533891260624\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 3.642491340637207 | KNN Loss: 3.6173288822174072 | CLS Loss: 0.02516240067780018\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 3.5532960891723633 | KNN Loss: 3.551933526992798 | CLS Loss: 0.001362611074000597\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 3.6035971641540527 | KNN Loss: 3.5916898250579834 | CLS Loss: 0.011907441541552544\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 3.596722364425659 | KNN Loss: 3.5849900245666504 | CLS Loss: 0.011732423678040504\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 3.648103713989258 | KNN Loss: 3.626181125640869 | CLS Loss: 0.021922660991549492\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 3.6240224838256836 | KNN Loss: 3.6074392795562744 | CLS Loss: 0.016583232209086418\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 3.6167218685150146 | KNN Loss: 3.593414068222046 | CLS Loss: 0.023307910189032555\n",
      "Epoch: 187, Loss: 3.6051, Train: 0.9956, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 3.6048898696899414 | KNN Loss: 3.585672378540039 | CLS Loss: 0.01921740546822548\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 3.6257734298706055 | KNN Loss: 3.619689702987671 | CLS Loss: 0.006083706393837929\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 3.563633918762207 | KNN Loss: 3.5612783432006836 | CLS Loss: 0.002355476375669241\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 3.585069179534912 | KNN Loss: 3.579878091812134 | CLS Loss: 0.005191148724406958\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 3.5916285514831543 | KNN Loss: 3.5783305168151855 | CLS Loss: 0.013298114761710167\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 3.6024394035339355 | KNN Loss: 3.583066940307617 | CLS Loss: 0.019372548907995224\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 3.6132304668426514 | KNN Loss: 3.607044219970703 | CLS Loss: 0.006186335813254118\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 3.593546152114868 | KNN Loss: 3.5868375301361084 | CLS Loss: 0.006708584725856781\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 3.5961802005767822 | KNN Loss: 3.562584161758423 | CLS Loss: 0.033596016466617584\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 3.5825791358947754 | KNN Loss: 3.5628585815429688 | CLS Loss: 0.01972062513232231\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 3.613034963607788 | KNN Loss: 3.58950138092041 | CLS Loss: 0.02353350818157196\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 3.6140458583831787 | KNN Loss: 3.5989270210266113 | CLS Loss: 0.015118916518986225\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 3.5946526527404785 | KNN Loss: 3.5789616107940674 | CLS Loss: 0.01569104567170143\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 3.6432414054870605 | KNN Loss: 3.638284206390381 | CLS Loss: 0.00495725404471159\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 3.595097303390503 | KNN Loss: 3.575901985168457 | CLS Loss: 0.01919524557888508\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 3.5958824157714844 | KNN Loss: 3.5848476886749268 | CLS Loss: 0.0110347094014287\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 3.6051981449127197 | KNN Loss: 3.5971474647521973 | CLS Loss: 0.008050695061683655\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 3.606468439102173 | KNN Loss: 3.5904059410095215 | CLS Loss: 0.01606244221329689\n",
      "Epoch: 188, Loss: 3.6103, Train: 0.9966, Valid: 0.9876, Best: 0.9885\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 3.640702962875366 | KNN Loss: 3.6313891410827637 | CLS Loss: 0.009313737042248249\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 3.563969135284424 | KNN Loss: 3.559414863586426 | CLS Loss: 0.004554262384772301\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 3.5527706146240234 | KNN Loss: 3.549647569656372 | CLS Loss: 0.0031231583561748266\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 3.646453380584717 | KNN Loss: 3.6341092586517334 | CLS Loss: 0.012344182468950748\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 3.6126513481140137 | KNN Loss: 3.6117122173309326 | CLS Loss: 0.0009392318315804005\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 3.557218074798584 | KNN Loss: 3.5539755821228027 | CLS Loss: 0.003242578823119402\n",
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 3.574934482574463 | KNN Loss: 3.5645439624786377 | CLS Loss: 0.010390578769147396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 3.600261926651001 | KNN Loss: 3.5846450328826904 | CLS Loss: 0.015616881661117077\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 3.6257970333099365 | KNN Loss: 3.6098709106445312 | CLS Loss: 0.015926232561469078\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 3.6277945041656494 | KNN Loss: 3.61649489402771 | CLS Loss: 0.01129960548132658\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 3.6359384059906006 | KNN Loss: 3.6051104068756104 | CLS Loss: 0.03082795813679695\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 3.627716302871704 | KNN Loss: 3.6101317405700684 | CLS Loss: 0.017584552988409996\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 3.651902914047241 | KNN Loss: 3.629162549972534 | CLS Loss: 0.022740429267287254\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 3.6467716693878174 | KNN Loss: 3.6378331184387207 | CLS Loss: 0.008938651531934738\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 3.625596046447754 | KNN Loss: 3.605513095855713 | CLS Loss: 0.020082887262105942\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 3.6085827350616455 | KNN Loss: 3.595487356185913 | CLS Loss: 0.013095390051603317\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 3.5776851177215576 | KNN Loss: 3.5677199363708496 | CLS Loss: 0.009965299628674984\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 3.5900940895080566 | KNN Loss: 3.585047960281372 | CLS Loss: 0.005046072416007519\n",
      "Epoch: 189, Loss: 3.6020, Train: 0.9976, Valid: 0.9880, Best: 0.9885\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 3.5933220386505127 | KNN Loss: 3.570117235183716 | CLS Loss: 0.02320476807653904\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 3.623241901397705 | KNN Loss: 3.6080029010772705 | CLS Loss: 0.015238898806273937\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 3.605520725250244 | KNN Loss: 3.599626064300537 | CLS Loss: 0.005894680507481098\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 3.596567153930664 | KNN Loss: 3.5878355503082275 | CLS Loss: 0.00873162318021059\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 3.5746991634368896 | KNN Loss: 3.568382978439331 | CLS Loss: 0.006316296756267548\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 3.6234915256500244 | KNN Loss: 3.614881753921509 | CLS Loss: 0.008609755896031857\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 3.581138849258423 | KNN Loss: 3.57476806640625 | CLS Loss: 0.00637077959254384\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 3.602722406387329 | KNN Loss: 3.593794345855713 | CLS Loss: 0.0089280279353261\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 3.5795392990112305 | KNN Loss: 3.568218231201172 | CLS Loss: 0.011321082711219788\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 3.5683510303497314 | KNN Loss: 3.5559303760528564 | CLS Loss: 0.012420681305229664\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 3.631100654602051 | KNN Loss: 3.6267337799072266 | CLS Loss: 0.004366977605968714\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 3.5873799324035645 | KNN Loss: 3.5721683502197266 | CLS Loss: 0.015211602672934532\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 3.609156370162964 | KNN Loss: 3.5924978256225586 | CLS Loss: 0.016658466309309006\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 3.6322014331817627 | KNN Loss: 3.567887306213379 | CLS Loss: 0.06431423872709274\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 3.5509579181671143 | KNN Loss: 3.5467875003814697 | CLS Loss: 0.004170403350144625\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 3.6246438026428223 | KNN Loss: 3.6175031661987305 | CLS Loss: 0.007140695117413998\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 3.5925562381744385 | KNN Loss: 3.573793888092041 | CLS Loss: 0.01876235194504261\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 3.6375019550323486 | KNN Loss: 3.6263906955718994 | CLS Loss: 0.011111159808933735\n",
      "Epoch: 190, Loss: 3.6027, Train: 0.9968, Valid: 0.9876, Best: 0.9885\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 3.608222246170044 | KNN Loss: 3.6059679985046387 | CLS Loss: 0.002254130318760872\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 3.5877792835235596 | KNN Loss: 3.5745415687561035 | CLS Loss: 0.013237668201327324\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 3.6037700176239014 | KNN Loss: 3.5927891731262207 | CLS Loss: 0.010980847291648388\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 3.645237684249878 | KNN Loss: 3.643869400024414 | CLS Loss: 0.0013683474389836192\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 3.599818706512451 | KNN Loss: 3.579662561416626 | CLS Loss: 0.020156262442469597\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 3.622772455215454 | KNN Loss: 3.6179678440093994 | CLS Loss: 0.004804502706974745\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 3.5941214561462402 | KNN Loss: 3.5901856422424316 | CLS Loss: 0.003935736604034901\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 3.678889751434326 | KNN Loss: 3.6678431034088135 | CLS Loss: 0.01104652974754572\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 3.5796918869018555 | KNN Loss: 3.564484119415283 | CLS Loss: 0.01520767156034708\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 3.622398614883423 | KNN Loss: 3.614039421081543 | CLS Loss: 0.00835917703807354\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 3.648353338241577 | KNN Loss: 3.6428253650665283 | CLS Loss: 0.005527900531888008\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 3.5922274589538574 | KNN Loss: 3.566925048828125 | CLS Loss: 0.025302350521087646\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 3.5880753993988037 | KNN Loss: 3.5640532970428467 | CLS Loss: 0.024022020399570465\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 3.5747034549713135 | KNN Loss: 3.568756341934204 | CLS Loss: 0.0059471228159964085\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 3.5852580070495605 | KNN Loss: 3.5826995372772217 | CLS Loss: 0.0025584534741938114\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 3.6071932315826416 | KNN Loss: 3.5867104530334473 | CLS Loss: 0.020482761785387993\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 3.6104044914245605 | KNN Loss: 3.6006968021392822 | CLS Loss: 0.009707609191536903\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 3.6444616317749023 | KNN Loss: 3.613589286804199 | CLS Loss: 0.03087233193218708\n",
      "Epoch: 191, Loss: 3.6035, Train: 0.9966, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 3.5794620513916016 | KNN Loss: 3.575338363647461 | CLS Loss: 0.004123682621866465\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 3.621004104614258 | KNN Loss: 3.5931434631347656 | CLS Loss: 0.027860693633556366\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 3.593809127807617 | KNN Loss: 3.5849769115448 | CLS Loss: 0.00883212685585022\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 3.5601353645324707 | KNN Loss: 3.554783821105957 | CLS Loss: 0.00535151781514287\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 3.5607078075408936 | KNN Loss: 3.5586085319519043 | CLS Loss: 0.0020992252975702286\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 3.6368868350982666 | KNN Loss: 3.6221625804901123 | CLS Loss: 0.014724234119057655\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 3.565948486328125 | KNN Loss: 3.556708812713623 | CLS Loss: 0.009239688515663147\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 3.5460779666900635 | KNN Loss: 3.544224977493286 | CLS Loss: 0.0018529834924265742\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 3.558265209197998 | KNN Loss: 3.550363540649414 | CLS Loss: 0.007901773788034916\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 3.608142375946045 | KNN Loss: 3.5976243019104004 | CLS Loss: 0.01051811221987009\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 3.610170841217041 | KNN Loss: 3.606799840927124 | CLS Loss: 0.0033709488343447447\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 3.5881545543670654 | KNN Loss: 3.584806203842163 | CLS Loss: 0.003348251339048147\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 3.616726875305176 | KNN Loss: 3.610318422317505 | CLS Loss: 0.0064084893092513084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 3.605968475341797 | KNN Loss: 3.589134454727173 | CLS Loss: 0.01683402806520462\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 3.5807862281799316 | KNN Loss: 3.576380729675293 | CLS Loss: 0.0044055818580091\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 3.5892229080200195 | KNN Loss: 3.5634138584136963 | CLS Loss: 0.02580908313393593\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 3.624157667160034 | KNN Loss: 3.6008410453796387 | CLS Loss: 0.023316603153944016\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 3.6173601150512695 | KNN Loss: 3.596792697906494 | CLS Loss: 0.020567480474710464\n",
      "Epoch: 192, Loss: 3.6088, Train: 0.9963, Valid: 0.9871, Best: 0.9885\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 3.617873191833496 | KNN Loss: 3.600017547607422 | CLS Loss: 0.017855700105428696\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 3.620344877243042 | KNN Loss: 3.585192918777466 | CLS Loss: 0.03515198081731796\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 3.5826821327209473 | KNN Loss: 3.559220314025879 | CLS Loss: 0.023461736738681793\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 3.557422161102295 | KNN Loss: 3.55330753326416 | CLS Loss: 0.00411459943279624\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 3.60329532623291 | KNN Loss: 3.580249071121216 | CLS Loss: 0.02304619736969471\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 3.5949666500091553 | KNN Loss: 3.5886642932891846 | CLS Loss: 0.006302298977971077\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 3.6239895820617676 | KNN Loss: 3.609168529510498 | CLS Loss: 0.014821006916463375\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 3.576443910598755 | KNN Loss: 3.53767466545105 | CLS Loss: 0.03876936063170433\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 3.58927583694458 | KNN Loss: 3.556417226791382 | CLS Loss: 0.03285859525203705\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 3.5686769485473633 | KNN Loss: 3.5635740756988525 | CLS Loss: 0.005102972500026226\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 3.6199147701263428 | KNN Loss: 3.607271909713745 | CLS Loss: 0.012642931193113327\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 3.582852363586426 | KNN Loss: 3.5802652835845947 | CLS Loss: 0.0025870015379041433\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 3.5746405124664307 | KNN Loss: 3.5647828578948975 | CLS Loss: 0.009857711382210255\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 3.629284620285034 | KNN Loss: 3.622993230819702 | CLS Loss: 0.0062913247384130955\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 3.5654139518737793 | KNN Loss: 3.5519673824310303 | CLS Loss: 0.01344661321491003\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 3.6252901554107666 | KNN Loss: 3.596144914627075 | CLS Loss: 0.02914532460272312\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 3.639522075653076 | KNN Loss: 3.6117067337036133 | CLS Loss: 0.027815276756882668\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 3.637315273284912 | KNN Loss: 3.6164114475250244 | CLS Loss: 0.02090391516685486\n",
      "Epoch: 193, Loss: 3.6086, Train: 0.9966, Valid: 0.9878, Best: 0.9885\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 3.5827879905700684 | KNN Loss: 3.57057523727417 | CLS Loss: 0.012212813831865788\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 3.5843043327331543 | KNN Loss: 3.575225591659546 | CLS Loss: 0.009078660979866982\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 3.6150710582733154 | KNN Loss: 3.6101560592651367 | CLS Loss: 0.004914887249469757\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 3.6252570152282715 | KNN Loss: 3.6157143115997314 | CLS Loss: 0.00954266544431448\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 3.5895955562591553 | KNN Loss: 3.585343360900879 | CLS Loss: 0.0042521716095507145\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 3.601923942565918 | KNN Loss: 3.592966079711914 | CLS Loss: 0.008957880549132824\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 3.5821352005004883 | KNN Loss: 3.5699615478515625 | CLS Loss: 0.012173734605312347\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 3.5675885677337646 | KNN Loss: 3.561384677886963 | CLS Loss: 0.00620390335097909\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 3.573911190032959 | KNN Loss: 3.5550146102905273 | CLS Loss: 0.018896635621786118\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 3.5822277069091797 | KNN Loss: 3.5658562183380127 | CLS Loss: 0.01637142524123192\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 3.6164960861206055 | KNN Loss: 3.610267400741577 | CLS Loss: 0.006228678859770298\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 3.585808753967285 | KNN Loss: 3.5766475200653076 | CLS Loss: 0.009161217138171196\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 3.7163875102996826 | KNN Loss: 3.690087080001831 | CLS Loss: 0.026300333440303802\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 3.584275722503662 | KNN Loss: 3.5745415687561035 | CLS Loss: 0.009734110906720161\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 3.579803228378296 | KNN Loss: 3.571530818939209 | CLS Loss: 0.008272519335150719\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 3.6823177337646484 | KNN Loss: 3.634727954864502 | CLS Loss: 0.04758971929550171\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 3.616046667098999 | KNN Loss: 3.596730947494507 | CLS Loss: 0.019315656274557114\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 3.620877504348755 | KNN Loss: 3.6061131954193115 | CLS Loss: 0.014764313586056232\n",
      "Epoch: 194, Loss: 3.6101, Train: 0.9965, Valid: 0.9868, Best: 0.9885\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 3.6560816764831543 | KNN Loss: 3.650446653366089 | CLS Loss: 0.005635051988065243\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 3.6085994243621826 | KNN Loss: 3.5969135761260986 | CLS Loss: 0.011685951612889767\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 3.600964069366455 | KNN Loss: 3.596932888031006 | CLS Loss: 0.004031288903206587\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 3.5832908153533936 | KNN Loss: 3.5705671310424805 | CLS Loss: 0.012723750434815884\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 3.6036007404327393 | KNN Loss: 3.591059923171997 | CLS Loss: 0.012540725991129875\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 3.59629225730896 | KNN Loss: 3.575706720352173 | CLS Loss: 0.02058549039065838\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 3.641420364379883 | KNN Loss: 3.606252431869507 | CLS Loss: 0.03516795486211777\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 3.649951457977295 | KNN Loss: 3.637827157974243 | CLS Loss: 0.012124331668019295\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 3.5750811100006104 | KNN Loss: 3.5584609508514404 | CLS Loss: 0.016620222479104996\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 3.6549439430236816 | KNN Loss: 3.6467747688293457 | CLS Loss: 0.008169134147465229\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 3.598898410797119 | KNN Loss: 3.5869829654693604 | CLS Loss: 0.011915395967662334\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 3.55141282081604 | KNN Loss: 3.5500526428222656 | CLS Loss: 0.001360096619464457\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 3.6517882347106934 | KNN Loss: 3.6261167526245117 | CLS Loss: 0.02567148767411709\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 3.5666391849517822 | KNN Loss: 3.557610273361206 | CLS Loss: 0.009028829634189606\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 3.5717227458953857 | KNN Loss: 3.5537405014038086 | CLS Loss: 0.017982246354222298\n",
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 3.595395088195801 | KNN Loss: 3.5880205631256104 | CLS Loss: 0.007374409586191177\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 3.583610773086548 | KNN Loss: 3.580388069152832 | CLS Loss: 0.003222718834877014\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 3.602187156677246 | KNN Loss: 3.5961477756500244 | CLS Loss: 0.0060394261963665485\n",
      "Epoch: 195, Loss: 3.6076, Train: 0.9972, Valid: 0.9877, Best: 0.9885\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 3.6595587730407715 | KNN Loss: 3.6451339721679688 | CLS Loss: 0.014424731023609638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 3.56596040725708 | KNN Loss: 3.5565896034240723 | CLS Loss: 0.009370706044137478\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 3.569096565246582 | KNN Loss: 3.5610709190368652 | CLS Loss: 0.00802560430020094\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 3.7674403190612793 | KNN Loss: 3.7329766750335693 | CLS Loss: 0.034463535994291306\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 3.6068832874298096 | KNN Loss: 3.5955653190612793 | CLS Loss: 0.011317950673401356\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 3.605165481567383 | KNN Loss: 3.593226432800293 | CLS Loss: 0.011938974261283875\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 3.58068585395813 | KNN Loss: 3.57743501663208 | CLS Loss: 0.003250734182074666\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 3.6278390884399414 | KNN Loss: 3.586243152618408 | CLS Loss: 0.041595980525016785\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 3.6637308597564697 | KNN Loss: 3.6115081310272217 | CLS Loss: 0.05222277715802193\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 3.6137943267822266 | KNN Loss: 3.603576183319092 | CLS Loss: 0.010218050330877304\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 3.6265461444854736 | KNN Loss: 3.607809066772461 | CLS Loss: 0.018737023696303368\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 3.615866184234619 | KNN Loss: 3.612492322921753 | CLS Loss: 0.003373934654518962\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 3.6469926834106445 | KNN Loss: 3.624718189239502 | CLS Loss: 0.02227439545094967\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 3.689943313598633 | KNN Loss: 3.67051100730896 | CLS Loss: 0.01943228766322136\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 3.6065244674682617 | KNN Loss: 3.6016411781311035 | CLS Loss: 0.004883193876594305\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 3.5952272415161133 | KNN Loss: 3.584156036376953 | CLS Loss: 0.011071278713643551\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 3.596367597579956 | KNN Loss: 3.5723137855529785 | CLS Loss: 0.024053772911429405\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 3.608999490737915 | KNN Loss: 3.5928380489349365 | CLS Loss: 0.016161464154720306\n",
      "Epoch: 196, Loss: 3.6159, Train: 0.9946, Valid: 0.9857, Best: 0.9885\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 3.5964479446411133 | KNN Loss: 3.5800702571868896 | CLS Loss: 0.016377637162804604\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 3.6573750972747803 | KNN Loss: 3.6040310859680176 | CLS Loss: 0.05334390699863434\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 3.5950217247009277 | KNN Loss: 3.5851404666900635 | CLS Loss: 0.009881176985800266\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 3.5838427543640137 | KNN Loss: 3.5677590370178223 | CLS Loss: 0.01608363538980484\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 3.560556650161743 | KNN Loss: 3.556605577468872 | CLS Loss: 0.003951176069676876\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 3.580807685852051 | KNN Loss: 3.558617115020752 | CLS Loss: 0.022190455347299576\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 3.628281593322754 | KNN Loss: 3.621507406234741 | CLS Loss: 0.006774142384529114\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 3.5987801551818848 | KNN Loss: 3.573784351348877 | CLS Loss: 0.024995753541588783\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 3.576697587966919 | KNN Loss: 3.565946578979492 | CLS Loss: 0.010750912129878998\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 3.5721487998962402 | KNN Loss: 3.5642523765563965 | CLS Loss: 0.007896503433585167\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 3.597747802734375 | KNN Loss: 3.581533193588257 | CLS Loss: 0.0162146408110857\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 3.60520601272583 | KNN Loss: 3.601260185241699 | CLS Loss: 0.0039457399398088455\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 3.578383684158325 | KNN Loss: 3.573608636856079 | CLS Loss: 0.00477498397231102\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 3.626033306121826 | KNN Loss: 3.6204991340637207 | CLS Loss: 0.005534270312637091\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 3.616701602935791 | KNN Loss: 3.607334852218628 | CLS Loss: 0.009366701357066631\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 3.6036593914031982 | KNN Loss: 3.6012234687805176 | CLS Loss: 0.0024359039962291718\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 3.61143159866333 | KNN Loss: 3.590254783630371 | CLS Loss: 0.021176829934120178\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 3.651644229888916 | KNN Loss: 3.6423940658569336 | CLS Loss: 0.00925024040043354\n",
      "Epoch: 197, Loss: 3.6014, Train: 0.9958, Valid: 0.9863, Best: 0.9885\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 3.597569465637207 | KNN Loss: 3.57104754447937 | CLS Loss: 0.026521828025579453\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 3.598468542098999 | KNN Loss: 3.5934460163116455 | CLS Loss: 0.005022528115659952\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 3.638648271560669 | KNN Loss: 3.624826192855835 | CLS Loss: 0.013821963220834732\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 3.6341121196746826 | KNN Loss: 3.5967445373535156 | CLS Loss: 0.03736767917871475\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 3.6018528938293457 | KNN Loss: 3.5935025215148926 | CLS Loss: 0.008350464515388012\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 3.594698190689087 | KNN Loss: 3.591387987136841 | CLS Loss: 0.003310169791802764\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 3.5777087211608887 | KNN Loss: 3.564946413040161 | CLS Loss: 0.012762271799147129\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 3.572233200073242 | KNN Loss: 3.5700151920318604 | CLS Loss: 0.002217917935922742\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 3.651062250137329 | KNN Loss: 3.6117660999298096 | CLS Loss: 0.0392962209880352\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 3.627140522003174 | KNN Loss: 3.613633632659912 | CLS Loss: 0.013506855815649033\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 3.7380998134613037 | KNN Loss: 3.717833995819092 | CLS Loss: 0.020265867933630943\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 3.604919195175171 | KNN Loss: 3.592008590698242 | CLS Loss: 0.012910694815218449\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 3.5771689414978027 | KNN Loss: 3.557727813720703 | CLS Loss: 0.01944107376039028\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 3.6274304389953613 | KNN Loss: 3.61602783203125 | CLS Loss: 0.011402718722820282\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 3.5960206985473633 | KNN Loss: 3.592564105987549 | CLS Loss: 0.0034565464593470097\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 3.5931508541107178 | KNN Loss: 3.5716288089752197 | CLS Loss: 0.021522006019949913\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 3.600292444229126 | KNN Loss: 3.596012830734253 | CLS Loss: 0.00427953340113163\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 3.5979056358337402 | KNN Loss: 3.5925776958465576 | CLS Loss: 0.005327867344021797\n",
      "Epoch: 198, Loss: 3.6022, Train: 0.9975, Valid: 0.9871, Best: 0.9885\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 3.5673210620880127 | KNN Loss: 3.5654702186584473 | CLS Loss: 0.001850730855949223\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 3.6510820388793945 | KNN Loss: 3.640284776687622 | CLS Loss: 0.010797232389450073\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 3.5706467628479004 | KNN Loss: 3.5676326751708984 | CLS Loss: 0.0030139724258333445\n",
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 3.5903024673461914 | KNN Loss: 3.587676525115967 | CLS Loss: 0.002625952707603574\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 3.5649211406707764 | KNN Loss: 3.5481812953948975 | CLS Loss: 0.016739781945943832\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 3.6105189323425293 | KNN Loss: 3.6022000312805176 | CLS Loss: 0.008319009095430374\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 3.620253562927246 | KNN Loss: 3.6120009422302246 | CLS Loss: 0.008252720348536968\n",
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 3.582399606704712 | KNN Loss: 3.5775985717773438 | CLS Loss: 0.004801001399755478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 3.5880959033966064 | KNN Loss: 3.5725131034851074 | CLS Loss: 0.015582882799208164\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 3.620037078857422 | KNN Loss: 3.5903987884521484 | CLS Loss: 0.029638340696692467\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 3.633448362350464 | KNN Loss: 3.6003639698028564 | CLS Loss: 0.03308449313044548\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 3.605926513671875 | KNN Loss: 3.601919174194336 | CLS Loss: 0.004007227253168821\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 3.648345708847046 | KNN Loss: 3.6371028423309326 | CLS Loss: 0.011242974549531937\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 3.5967555046081543 | KNN Loss: 3.5879805088043213 | CLS Loss: 0.00877506285905838\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 3.622724771499634 | KNN Loss: 3.608492374420166 | CLS Loss: 0.014232449233531952\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 3.6114444732666016 | KNN Loss: 3.570113182067871 | CLS Loss: 0.0413312092423439\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 3.578416109085083 | KNN Loss: 3.5729458332061768 | CLS Loss: 0.005470349919050932\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 3.609870672225952 | KNN Loss: 3.593688488006592 | CLS Loss: 0.016182074323296547\n",
      "Epoch: 199, Loss: 3.6024, Train: 0.9967, Valid: 0.9872, Best: 0.9885\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 3.6497936248779297 | KNN Loss: 3.641031265258789 | CLS Loss: 0.008762453682720661\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 3.6096839904785156 | KNN Loss: 3.608339548110962 | CLS Loss: 0.0013444223441183567\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 3.6238584518432617 | KNN Loss: 3.6166250705718994 | CLS Loss: 0.007233422715216875\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 3.609189987182617 | KNN Loss: 3.6078622341156006 | CLS Loss: 0.001327849691733718\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 3.565791606903076 | KNN Loss: 3.556596279144287 | CLS Loss: 0.009195269085466862\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 3.624225378036499 | KNN Loss: 3.621717691421509 | CLS Loss: 0.002507684985175729\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 3.6115078926086426 | KNN Loss: 3.607487201690674 | CLS Loss: 0.0040207416750490665\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 3.601421356201172 | KNN Loss: 3.5887510776519775 | CLS Loss: 0.01267023105174303\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 3.626748561859131 | KNN Loss: 3.6098792552948 | CLS Loss: 0.01686936803162098\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 3.5987343788146973 | KNN Loss: 3.5935943126678467 | CLS Loss: 0.005140159744769335\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 3.592898368835449 | KNN Loss: 3.568358898162842 | CLS Loss: 0.02453945018351078\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 3.5663464069366455 | KNN Loss: 3.5613698959350586 | CLS Loss: 0.004976594354957342\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 3.590850830078125 | KNN Loss: 3.5785584449768066 | CLS Loss: 0.012292366474866867\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 3.5772955417633057 | KNN Loss: 3.5737128257751465 | CLS Loss: 0.003582634264603257\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 3.598541736602783 | KNN Loss: 3.5946006774902344 | CLS Loss: 0.003941070754081011\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 3.651515245437622 | KNN Loss: 3.6342923641204834 | CLS Loss: 0.017222780734300613\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 3.592592477798462 | KNN Loss: 3.589799642562866 | CLS Loss: 0.002792928135022521\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 3.55825138092041 | KNN Loss: 3.555891275405884 | CLS Loss: 0.002360109006986022\n",
      "Epoch: 200, Loss: 3.6006, Train: 0.9963, Valid: 0.9865, Best: 0.9885\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9865)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdedaa2d5c747009819ca395b79bef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0909368e4c4648989548eed9e8bee5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e731413e0a49848c28b4db4ae5599a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=43.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379b576fd0ad43a2aa14a692ad29d365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e2aab539ff4b45b3a1540e1cfbb90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.618564706957197\n",
      "Number of inliers: 0.6916084235530583\n",
      "Number of inliers: 0.7413548947055868\n",
      "Number of inliers: 0.7792243387693573\n",
      "Number of inliers: 0.8090996299849254\n",
      "Number of inliers: 0.8321227901877484\n",
      "Number of inliers: 0.8487506281120095\n",
      "Number of inliers: 0.865743913023617\n",
      "Number of inliers: 0.881138367365584\n",
      "Number of inliers: 0.8950710337581654\n",
      "Number of inliers: 0.9076332739481979\n",
      "Number of inliers: 0.9195103010369559\n",
      "Number of inliers: 0.9304737106573477\n",
      "Number of inliers: 0.939792608834681\n",
      "Number of inliers: 0.9477867616828833\n",
      "Number of inliers: 0.9554154675437394\n",
      "Number of inliers: 0.9634096203919419\n",
      "Number of inliers: 0.9691197295692293\n",
      "Number of inliers: 0.9738705404047325\n",
      "Number of inliers: 0.9789411173541638\n",
      "Number of inliers: 0.9821387784934448\n",
      "Number of inliers: 0.9841944177972682\n",
      "Number of inliers: 0.9866155040884381\n",
      "Number of inliers: 0.9886711433922617\n",
      "Number of inliers: 0.990407016582157\n",
      "Number of inliers: 0.9923712941391439\n",
      "Number of inliers: 0.9936960394682747\n",
      "Number of inliers: 0.9950664656708236\n",
      "Number of inliers: 0.9958887213923531\n",
      "Number of inliers: 0.9967566579873007\n",
      "Number of inliers: 0.9971221049746471\n",
      "Number of inliers: 0.9978073180759216\n",
      "Number of inliers: 0.9980814033164314\n",
      "Number of inliers: 0.998309807683523\n",
      "Number of inliers: 0.9984468503037778\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in np.arange(0.5, 4, 0.1):\n",
    "    clusters = DBSCAN(eps=i, min_samples=10).fit_predict(projections)\n",
    "    print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")\n",
    "    res.append(sum(clusters != -1) / len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb78148d5d994b29af68fc8505204e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(0.5, 4, 0.1), res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=1.5, min_samples=25).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.8923758622264858\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1353678aa2e42978296b04440269b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 10\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "Epoch: 00 | Batch: 000 / 039 | Total loss: 2.504 | Reg loss: 0.011 | Tree loss: 2.504 | Accuracy: 0.027344 | 7.191 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 039 | Total loss: 2.358 | Reg loss: 0.012 | Tree loss: 2.358 | Accuracy: 0.179688 | 6.568 sec/iter\n",
      "Epoch: 00 | Batch: 020 / 039 | Total loss: 2.228 | Reg loss: 0.014 | Tree loss: 2.228 | Accuracy: 0.298828 | 6.546 sec/iter\n",
      "Epoch: 00 | Batch: 030 / 039 | Total loss: 2.087 | Reg loss: 0.018 | Tree loss: 2.087 | Accuracy: 0.404297 | 6.471 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 01 | Batch: 000 / 039 | Total loss: 2.493 | Reg loss: 0.004 | Tree loss: 2.493 | Accuracy: 0.080078 | 6.287 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 039 | Total loss: 2.345 | Reg loss: 0.008 | Tree loss: 2.345 | Accuracy: 0.187500 | 6.37 sec/iter\n",
      "Epoch: 01 | Batch: 020 / 039 | Total loss: 2.198 | Reg loss: 0.013 | Tree loss: 2.198 | Accuracy: 0.265625 | 6.39 sec/iter\n",
      "Epoch: 01 | Batch: 030 / 039 | Total loss: 1.986 | Reg loss: 0.017 | Tree loss: 1.986 | Accuracy: 0.455078 | 6.464 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 02 | Batch: 000 / 039 | Total loss: 2.493 | Reg loss: 0.005 | Tree loss: 2.493 | Accuracy: 0.099609 | 6.332 sec/iter\n",
      "Epoch: 02 | Batch: 010 / 039 | Total loss: 2.331 | Reg loss: 0.008 | Tree loss: 2.331 | Accuracy: 0.267578 | 6.337 sec/iter\n",
      "Epoch: 02 | Batch: 020 / 039 | Total loss: 2.120 | Reg loss: 0.013 | Tree loss: 2.120 | Accuracy: 0.263672 | 6.331 sec/iter\n",
      "Epoch: 02 | Batch: 030 / 039 | Total loss: 1.959 | Reg loss: 0.017 | Tree loss: 1.959 | Accuracy: 0.447266 | 6.322 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 03 | Batch: 000 / 039 | Total loss: 2.490 | Reg loss: 0.006 | Tree loss: 2.490 | Accuracy: 0.164062 | 6.279 sec/iter\n",
      "Epoch: 03 | Batch: 010 / 039 | Total loss: 2.341 | Reg loss: 0.009 | Tree loss: 2.341 | Accuracy: 0.183594 | 6.295 sec/iter\n",
      "Epoch: 03 | Batch: 020 / 039 | Total loss: 2.121 | Reg loss: 0.013 | Tree loss: 2.121 | Accuracy: 0.304688 | 6.371 sec/iter\n",
      "Epoch: 03 | Batch: 030 / 039 | Total loss: 1.942 | Reg loss: 0.017 | Tree loss: 1.942 | Accuracy: 0.406250 | 6.428 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 04 | Batch: 000 / 039 | Total loss: 2.489 | Reg loss: 0.007 | Tree loss: 2.489 | Accuracy: 0.171875 | 6.407 sec/iter\n",
      "Epoch: 04 | Batch: 010 / 039 | Total loss: 2.366 | Reg loss: 0.009 | Tree loss: 2.366 | Accuracy: 0.158203 | 6.403 sec/iter\n",
      "Epoch: 04 | Batch: 020 / 039 | Total loss: 2.130 | Reg loss: 0.013 | Tree loss: 2.130 | Accuracy: 0.304688 | 6.393 sec/iter\n",
      "Epoch: 04 | Batch: 030 / 039 | Total loss: 1.887 | Reg loss: 0.016 | Tree loss: 1.887 | Accuracy: 0.396484 | 6.385 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 05 | Batch: 000 / 039 | Total loss: 2.486 | Reg loss: 0.007 | Tree loss: 2.486 | Accuracy: 0.173828 | 6.392 sec/iter\n",
      "Epoch: 05 | Batch: 010 / 039 | Total loss: 2.367 | Reg loss: 0.010 | Tree loss: 2.367 | Accuracy: 0.154297 | 6.392 sec/iter\n",
      "Epoch: 05 | Batch: 020 / 039 | Total loss: 2.085 | Reg loss: 0.014 | Tree loss: 2.085 | Accuracy: 0.357422 | 6.395 sec/iter\n",
      "Epoch: 05 | Batch: 030 / 039 | Total loss: 1.840 | Reg loss: 0.017 | Tree loss: 1.840 | Accuracy: 0.390625 | 6.378 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 06 | Batch: 000 / 039 | Total loss: 2.486 | Reg loss: 0.008 | Tree loss: 2.486 | Accuracy: 0.134766 | 6.344 sec/iter\n",
      "Epoch: 06 | Batch: 010 / 039 | Total loss: 2.294 | Reg loss: 0.010 | Tree loss: 2.294 | Accuracy: 0.177734 | 6.344 sec/iter\n",
      "Epoch: 06 | Batch: 020 / 039 | Total loss: 2.052 | Reg loss: 0.013 | Tree loss: 2.052 | Accuracy: 0.353516 | 6.327 sec/iter\n",
      "Epoch: 06 | Batch: 030 / 039 | Total loss: 1.908 | Reg loss: 0.016 | Tree loss: 1.908 | Accuracy: 0.359375 | 6.313 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 07 | Batch: 000 / 039 | Total loss: 2.483 | Reg loss: 0.008 | Tree loss: 2.483 | Accuracy: 0.183594 | 6.283 sec/iter\n",
      "Epoch: 07 | Batch: 010 / 039 | Total loss: 2.346 | Reg loss: 0.011 | Tree loss: 2.346 | Accuracy: 0.146484 | 6.29 sec/iter\n",
      "Epoch: 07 | Batch: 020 / 039 | Total loss: 1.970 | Reg loss: 0.014 | Tree loss: 1.970 | Accuracy: 0.423828 | 6.281 sec/iter\n",
      "Epoch: 07 | Batch: 030 / 039 | Total loss: 1.791 | Reg loss: 0.016 | Tree loss: 1.791 | Accuracy: 0.416016 | 6.281 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 08 | Batch: 000 / 039 | Total loss: 2.476 | Reg loss: 0.009 | Tree loss: 2.476 | Accuracy: 0.218750 | 6.256 sec/iter\n",
      "Epoch: 08 | Batch: 010 / 039 | Total loss: 2.249 | Reg loss: 0.011 | Tree loss: 2.249 | Accuracy: 0.218750 | 6.257 sec/iter\n",
      "Epoch: 08 | Batch: 020 / 039 | Total loss: 1.990 | Reg loss: 0.014 | Tree loss: 1.990 | Accuracy: 0.361328 | 6.255 sec/iter\n",
      "Epoch: 08 | Batch: 030 / 039 | Total loss: 1.803 | Reg loss: 0.016 | Tree loss: 1.803 | Accuracy: 0.394531 | 6.252 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 09 | Batch: 000 / 039 | Total loss: 2.479 | Reg loss: 0.009 | Tree loss: 2.479 | Accuracy: 0.142578 | 6.244 sec/iter\n",
      "Epoch: 09 | Batch: 010 / 039 | Total loss: 2.224 | Reg loss: 0.011 | Tree loss: 2.224 | Accuracy: 0.224609 | 6.249 sec/iter\n",
      "Epoch: 09 | Batch: 020 / 039 | Total loss: 1.976 | Reg loss: 0.014 | Tree loss: 1.976 | Accuracy: 0.367188 | 6.26 sec/iter\n",
      "Epoch: 09 | Batch: 030 / 039 | Total loss: 1.814 | Reg loss: 0.017 | Tree loss: 1.814 | Accuracy: 0.408203 | 6.271 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 10 | Batch: 000 / 039 | Total loss: 2.477 | Reg loss: 0.010 | Tree loss: 2.477 | Accuracy: 0.146484 | 6.263 sec/iter\n",
      "Epoch: 10 | Batch: 010 / 039 | Total loss: 2.257 | Reg loss: 0.012 | Tree loss: 2.257 | Accuracy: 0.160156 | 6.259 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Batch: 020 / 039 | Total loss: 1.993 | Reg loss: 0.014 | Tree loss: 1.993 | Accuracy: 0.398438 | 6.256 sec/iter\n",
      "Epoch: 10 | Batch: 030 / 039 | Total loss: 1.799 | Reg loss: 0.017 | Tree loss: 1.799 | Accuracy: 0.400391 | 6.258 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 11 | Batch: 000 / 039 | Total loss: 2.474 | Reg loss: 0.010 | Tree loss: 2.474 | Accuracy: 0.146484 | 6.245 sec/iter\n",
      "Epoch: 11 | Batch: 010 / 039 | Total loss: 2.243 | Reg loss: 0.012 | Tree loss: 2.243 | Accuracy: 0.199219 | 6.242 sec/iter\n",
      "Epoch: 11 | Batch: 020 / 039 | Total loss: 1.965 | Reg loss: 0.015 | Tree loss: 1.965 | Accuracy: 0.402344 | 6.248 sec/iter\n",
      "Epoch: 11 | Batch: 030 / 039 | Total loss: 1.733 | Reg loss: 0.017 | Tree loss: 1.733 | Accuracy: 0.460938 | 6.241 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 12 | Batch: 000 / 039 | Total loss: 2.471 | Reg loss: 0.011 | Tree loss: 2.471 | Accuracy: 0.169922 | 6.236 sec/iter\n",
      "Epoch: 12 | Batch: 010 / 039 | Total loss: 2.204 | Reg loss: 0.012 | Tree loss: 2.204 | Accuracy: 0.210938 | 6.23 sec/iter\n",
      "Epoch: 12 | Batch: 020 / 039 | Total loss: 1.908 | Reg loss: 0.015 | Tree loss: 1.908 | Accuracy: 0.421875 | 6.226 sec/iter\n",
      "Epoch: 12 | Batch: 030 / 039 | Total loss: 1.649 | Reg loss: 0.017 | Tree loss: 1.649 | Accuracy: 0.443359 | 6.224 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 13 | Batch: 000 / 039 | Total loss: 2.466 | Reg loss: 0.011 | Tree loss: 2.466 | Accuracy: 0.183594 | 6.24 sec/iter\n",
      "Epoch: 13 | Batch: 010 / 039 | Total loss: 2.219 | Reg loss: 0.012 | Tree loss: 2.219 | Accuracy: 0.226562 | 6.254 sec/iter\n",
      "Epoch: 13 | Batch: 020 / 039 | Total loss: 1.905 | Reg loss: 0.015 | Tree loss: 1.905 | Accuracy: 0.472656 | 6.25 sec/iter\n",
      "Epoch: 13 | Batch: 030 / 039 | Total loss: 1.695 | Reg loss: 0.017 | Tree loss: 1.695 | Accuracy: 0.486328 | 6.249 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 14 | Batch: 000 / 039 | Total loss: 2.463 | Reg loss: 0.011 | Tree loss: 2.463 | Accuracy: 0.207031 | 6.24 sec/iter\n",
      "Epoch: 14 | Batch: 010 / 039 | Total loss: 2.194 | Reg loss: 0.013 | Tree loss: 2.194 | Accuracy: 0.183594 | 6.234 sec/iter\n",
      "Epoch: 14 | Batch: 020 / 039 | Total loss: 1.945 | Reg loss: 0.015 | Tree loss: 1.945 | Accuracy: 0.425781 | 6.24 sec/iter\n",
      "Epoch: 14 | Batch: 030 / 039 | Total loss: 1.627 | Reg loss: 0.017 | Tree loss: 1.627 | Accuracy: 0.488281 | 6.252 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 15 | Batch: 000 / 039 | Total loss: 2.464 | Reg loss: 0.012 | Tree loss: 2.464 | Accuracy: 0.162109 | 6.254 sec/iter\n",
      "Epoch: 15 | Batch: 010 / 039 | Total loss: 2.175 | Reg loss: 0.013 | Tree loss: 2.175 | Accuracy: 0.208984 | 6.281 sec/iter\n",
      "Epoch: 15 | Batch: 020 / 039 | Total loss: 1.866 | Reg loss: 0.015 | Tree loss: 1.866 | Accuracy: 0.439453 | 6.28 sec/iter\n",
      "Epoch: 15 | Batch: 030 / 039 | Total loss: 1.721 | Reg loss: 0.017 | Tree loss: 1.721 | Accuracy: 0.435547 | 6.283 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 16 | Batch: 000 / 039 | Total loss: 2.460 | Reg loss: 0.012 | Tree loss: 2.460 | Accuracy: 0.228516 | 6.269 sec/iter\n",
      "Epoch: 16 | Batch: 010 / 039 | Total loss: 2.145 | Reg loss: 0.013 | Tree loss: 2.145 | Accuracy: 0.193359 | 6.263 sec/iter\n",
      "Epoch: 16 | Batch: 020 / 039 | Total loss: 1.845 | Reg loss: 0.016 | Tree loss: 1.845 | Accuracy: 0.458984 | 6.258 sec/iter\n",
      "Epoch: 16 | Batch: 030 / 039 | Total loss: 1.690 | Reg loss: 0.017 | Tree loss: 1.690 | Accuracy: 0.439453 | 6.252 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 17 | Batch: 000 / 039 | Total loss: 2.461 | Reg loss: 0.012 | Tree loss: 2.461 | Accuracy: 0.224609 | 6.241 sec/iter\n",
      "Epoch: 17 | Batch: 010 / 039 | Total loss: 2.150 | Reg loss: 0.013 | Tree loss: 2.150 | Accuracy: 0.220703 | 6.237 sec/iter\n",
      "Epoch: 17 | Batch: 020 / 039 | Total loss: 1.800 | Reg loss: 0.016 | Tree loss: 1.800 | Accuracy: 0.501953 | 6.234 sec/iter\n",
      "Epoch: 17 | Batch: 030 / 039 | Total loss: 1.642 | Reg loss: 0.017 | Tree loss: 1.642 | Accuracy: 0.464844 | 6.231 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 18 | Batch: 000 / 039 | Total loss: 2.458 | Reg loss: 0.013 | Tree loss: 2.458 | Accuracy: 0.224609 | 6.22 sec/iter\n",
      "Epoch: 18 | Batch: 010 / 039 | Total loss: 2.101 | Reg loss: 0.014 | Tree loss: 2.101 | Accuracy: 0.253906 | 6.216 sec/iter\n",
      "Epoch: 18 | Batch: 020 / 039 | Total loss: 1.814 | Reg loss: 0.016 | Tree loss: 1.814 | Accuracy: 0.480469 | 6.213 sec/iter\n",
      "Epoch: 18 | Batch: 030 / 039 | Total loss: 1.684 | Reg loss: 0.018 | Tree loss: 1.684 | Accuracy: 0.482422 | 6.215 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 19 | Batch: 000 / 039 | Total loss: 2.457 | Reg loss: 0.013 | Tree loss: 2.457 | Accuracy: 0.234375 | 6.211 sec/iter\n",
      "Epoch: 19 | Batch: 010 / 039 | Total loss: 2.123 | Reg loss: 0.014 | Tree loss: 2.123 | Accuracy: 0.242188 | 6.217 sec/iter\n",
      "Epoch: 19 | Batch: 020 / 039 | Total loss: 1.826 | Reg loss: 0.016 | Tree loss: 1.826 | Accuracy: 0.451172 | 6.217 sec/iter\n",
      "Epoch: 19 | Batch: 030 / 039 | Total loss: 1.656 | Reg loss: 0.018 | Tree loss: 1.656 | Accuracy: 0.453125 | 6.212 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 20 | Batch: 000 / 039 | Total loss: 2.453 | Reg loss: 0.013 | Tree loss: 2.453 | Accuracy: 0.271484 | 6.202 sec/iter\n",
      "Epoch: 20 | Batch: 010 / 039 | Total loss: 2.135 | Reg loss: 0.014 | Tree loss: 2.135 | Accuracy: 0.234375 | 6.197 sec/iter\n",
      "Epoch: 20 | Batch: 020 / 039 | Total loss: 1.753 | Reg loss: 0.016 | Tree loss: 1.753 | Accuracy: 0.474609 | 6.195 sec/iter\n",
      "Epoch: 20 | Batch: 030 / 039 | Total loss: 1.614 | Reg loss: 0.018 | Tree loss: 1.614 | Accuracy: 0.507812 | 6.197 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Batch: 000 / 039 | Total loss: 2.450 | Reg loss: 0.013 | Tree loss: 2.450 | Accuracy: 0.294922 | 6.206 sec/iter\n",
      "Epoch: 21 | Batch: 010 / 039 | Total loss: 2.071 | Reg loss: 0.015 | Tree loss: 2.071 | Accuracy: 0.357422 | 6.21 sec/iter\n",
      "Epoch: 21 | Batch: 020 / 039 | Total loss: 1.765 | Reg loss: 0.017 | Tree loss: 1.765 | Accuracy: 0.476562 | 6.208 sec/iter\n",
      "Epoch: 21 | Batch: 030 / 039 | Total loss: 1.646 | Reg loss: 0.019 | Tree loss: 1.646 | Accuracy: 0.458984 | 6.207 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 22 | Batch: 000 / 039 | Total loss: 2.451 | Reg loss: 0.014 | Tree loss: 2.451 | Accuracy: 0.250000 | 6.199 sec/iter\n",
      "Epoch: 22 | Batch: 010 / 039 | Total loss: 2.093 | Reg loss: 0.015 | Tree loss: 2.093 | Accuracy: 0.291016 | 6.198 sec/iter\n",
      "Epoch: 22 | Batch: 020 / 039 | Total loss: 1.729 | Reg loss: 0.017 | Tree loss: 1.729 | Accuracy: 0.494141 | 6.199 sec/iter\n",
      "Epoch: 22 | Batch: 030 / 039 | Total loss: 1.562 | Reg loss: 0.019 | Tree loss: 1.562 | Accuracy: 0.496094 | 6.197 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 23 | Batch: 000 / 039 | Total loss: 2.442 | Reg loss: 0.014 | Tree loss: 2.442 | Accuracy: 0.300781 | 6.189 sec/iter\n",
      "Epoch: 23 | Batch: 010 / 039 | Total loss: 2.028 | Reg loss: 0.015 | Tree loss: 2.028 | Accuracy: 0.414062 | 6.187 sec/iter\n",
      "Epoch: 23 | Batch: 020 / 039 | Total loss: 1.809 | Reg loss: 0.017 | Tree loss: 1.809 | Accuracy: 0.421875 | 6.184 sec/iter\n",
      "Epoch: 23 | Batch: 030 / 039 | Total loss: 1.579 | Reg loss: 0.019 | Tree loss: 1.579 | Accuracy: 0.470703 | 6.186 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 24 | Batch: 000 / 039 | Total loss: 2.447 | Reg loss: 0.014 | Tree loss: 2.447 | Accuracy: 0.292969 | 6.179 sec/iter\n",
      "Epoch: 24 | Batch: 010 / 039 | Total loss: 2.086 | Reg loss: 0.015 | Tree loss: 2.086 | Accuracy: 0.326172 | 6.178 sec/iter\n",
      "Epoch: 24 | Batch: 020 / 039 | Total loss: 1.707 | Reg loss: 0.018 | Tree loss: 1.707 | Accuracy: 0.482422 | 6.176 sec/iter\n",
      "Epoch: 24 | Batch: 030 / 039 | Total loss: 1.590 | Reg loss: 0.019 | Tree loss: 1.590 | Accuracy: 0.460938 | 6.174 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 25 | Batch: 000 / 039 | Total loss: 2.443 | Reg loss: 0.014 | Tree loss: 2.443 | Accuracy: 0.271484 | 6.169 sec/iter\n",
      "Epoch: 25 | Batch: 010 / 039 | Total loss: 2.059 | Reg loss: 0.016 | Tree loss: 2.059 | Accuracy: 0.296875 | 6.169 sec/iter\n",
      "Epoch: 25 | Batch: 020 / 039 | Total loss: 1.740 | Reg loss: 0.018 | Tree loss: 1.740 | Accuracy: 0.439453 | 6.17 sec/iter\n",
      "Epoch: 25 | Batch: 030 / 039 | Total loss: 1.537 | Reg loss: 0.020 | Tree loss: 1.537 | Accuracy: 0.525391 | 6.17 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 26 | Batch: 000 / 039 | Total loss: 2.444 | Reg loss: 0.015 | Tree loss: 2.444 | Accuracy: 0.251953 | 6.165 sec/iter\n",
      "Epoch: 26 | Batch: 010 / 039 | Total loss: 2.057 | Reg loss: 0.016 | Tree loss: 2.057 | Accuracy: 0.390625 | 6.165 sec/iter\n",
      "Epoch: 26 | Batch: 020 / 039 | Total loss: 1.705 | Reg loss: 0.018 | Tree loss: 1.705 | Accuracy: 0.443359 | 6.165 sec/iter\n",
      "Epoch: 26 | Batch: 030 / 039 | Total loss: 1.490 | Reg loss: 0.020 | Tree loss: 1.490 | Accuracy: 0.482422 | 6.164 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 27 | Batch: 000 / 039 | Total loss: 2.437 | Reg loss: 0.015 | Tree loss: 2.437 | Accuracy: 0.298828 | 6.157 sec/iter\n",
      "Epoch: 27 | Batch: 010 / 039 | Total loss: 2.003 | Reg loss: 0.016 | Tree loss: 2.003 | Accuracy: 0.429688 | 6.157 sec/iter\n",
      "Epoch: 27 | Batch: 020 / 039 | Total loss: 1.715 | Reg loss: 0.018 | Tree loss: 1.715 | Accuracy: 0.462891 | 6.158 sec/iter\n",
      "Epoch: 27 | Batch: 030 / 039 | Total loss: 1.543 | Reg loss: 0.020 | Tree loss: 1.543 | Accuracy: 0.455078 | 6.158 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 28 | Batch: 000 / 039 | Total loss: 2.438 | Reg loss: 0.015 | Tree loss: 2.438 | Accuracy: 0.326172 | 6.153 sec/iter\n",
      "Epoch: 28 | Batch: 010 / 039 | Total loss: 2.026 | Reg loss: 0.016 | Tree loss: 2.026 | Accuracy: 0.429688 | 6.153 sec/iter\n",
      "Epoch: 28 | Batch: 020 / 039 | Total loss: 1.694 | Reg loss: 0.018 | Tree loss: 1.694 | Accuracy: 0.480469 | 6.153 sec/iter\n",
      "Epoch: 28 | Batch: 030 / 039 | Total loss: 1.490 | Reg loss: 0.020 | Tree loss: 1.490 | Accuracy: 0.498047 | 6.153 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 29 | Batch: 000 / 039 | Total loss: 2.438 | Reg loss: 0.015 | Tree loss: 2.438 | Accuracy: 0.294922 | 6.149 sec/iter\n",
      "Epoch: 29 | Batch: 010 / 039 | Total loss: 2.056 | Reg loss: 0.016 | Tree loss: 2.056 | Accuracy: 0.310547 | 6.149 sec/iter\n",
      "Epoch: 29 | Batch: 020 / 039 | Total loss: 1.671 | Reg loss: 0.018 | Tree loss: 1.671 | Accuracy: 0.484375 | 6.149 sec/iter\n",
      "Epoch: 29 | Batch: 030 / 039 | Total loss: 1.546 | Reg loss: 0.020 | Tree loss: 1.546 | Accuracy: 0.474609 | 6.15 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 30 | Batch: 000 / 039 | Total loss: 2.432 | Reg loss: 0.016 | Tree loss: 2.432 | Accuracy: 0.302734 | 6.145 sec/iter\n",
      "Epoch: 30 | Batch: 010 / 039 | Total loss: 1.982 | Reg loss: 0.017 | Tree loss: 1.982 | Accuracy: 0.449219 | 6.148 sec/iter\n",
      "Epoch: 30 | Batch: 020 / 039 | Total loss: 1.675 | Reg loss: 0.019 | Tree loss: 1.675 | Accuracy: 0.496094 | 6.145 sec/iter\n",
      "Epoch: 30 | Batch: 030 / 039 | Total loss: 1.468 | Reg loss: 0.021 | Tree loss: 1.468 | Accuracy: 0.486328 | 6.143 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 31 | Batch: 000 / 039 | Total loss: 2.428 | Reg loss: 0.016 | Tree loss: 2.428 | Accuracy: 0.318359 | 6.137 sec/iter\n",
      "Epoch: 31 | Batch: 010 / 039 | Total loss: 2.073 | Reg loss: 0.017 | Tree loss: 2.073 | Accuracy: 0.351562 | 6.134 sec/iter\n",
      "Epoch: 31 | Batch: 020 / 039 | Total loss: 1.724 | Reg loss: 0.019 | Tree loss: 1.724 | Accuracy: 0.468750 | 6.132 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Batch: 030 / 039 | Total loss: 1.556 | Reg loss: 0.021 | Tree loss: 1.556 | Accuracy: 0.435547 | 6.129 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 32 | Batch: 000 / 039 | Total loss: 2.427 | Reg loss: 0.016 | Tree loss: 2.427 | Accuracy: 0.312500 | 6.123 sec/iter\n",
      "Epoch: 32 | Batch: 010 / 039 | Total loss: 2.059 | Reg loss: 0.017 | Tree loss: 2.059 | Accuracy: 0.433594 | 6.12 sec/iter\n",
      "Epoch: 32 | Batch: 020 / 039 | Total loss: 1.698 | Reg loss: 0.019 | Tree loss: 1.698 | Accuracy: 0.474609 | 6.118 sec/iter\n",
      "Epoch: 32 | Batch: 030 / 039 | Total loss: 1.488 | Reg loss: 0.021 | Tree loss: 1.488 | Accuracy: 0.496094 | 6.115 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 33 | Batch: 000 / 039 | Total loss: 2.431 | Reg loss: 0.017 | Tree loss: 2.431 | Accuracy: 0.304688 | 6.109 sec/iter\n",
      "Epoch: 33 | Batch: 010 / 039 | Total loss: 2.047 | Reg loss: 0.018 | Tree loss: 2.047 | Accuracy: 0.414062 | 6.106 sec/iter\n",
      "Epoch: 33 | Batch: 020 / 039 | Total loss: 1.650 | Reg loss: 0.019 | Tree loss: 1.650 | Accuracy: 0.498047 | 6.105 sec/iter\n",
      "Epoch: 33 | Batch: 030 / 039 | Total loss: 1.492 | Reg loss: 0.021 | Tree loss: 1.492 | Accuracy: 0.542969 | 6.103 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 34 | Batch: 000 / 039 | Total loss: 2.429 | Reg loss: 0.017 | Tree loss: 2.429 | Accuracy: 0.277344 | 6.096 sec/iter\n",
      "Epoch: 34 | Batch: 010 / 039 | Total loss: 2.070 | Reg loss: 0.018 | Tree loss: 2.070 | Accuracy: 0.406250 | 6.094 sec/iter\n",
      "Epoch: 34 | Batch: 020 / 039 | Total loss: 1.623 | Reg loss: 0.020 | Tree loss: 1.623 | Accuracy: 0.515625 | 6.092 sec/iter\n",
      "Epoch: 34 | Batch: 030 / 039 | Total loss: 1.430 | Reg loss: 0.021 | Tree loss: 1.430 | Accuracy: 0.564453 | 6.09 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 35 | Batch: 000 / 039 | Total loss: 2.424 | Reg loss: 0.017 | Tree loss: 2.424 | Accuracy: 0.298828 | 6.086 sec/iter\n",
      "Epoch: 35 | Batch: 010 / 039 | Total loss: 2.042 | Reg loss: 0.018 | Tree loss: 2.042 | Accuracy: 0.414062 | 6.083 sec/iter\n",
      "Epoch: 35 | Batch: 020 / 039 | Total loss: 1.597 | Reg loss: 0.020 | Tree loss: 1.597 | Accuracy: 0.527344 | 6.08 sec/iter\n",
      "Epoch: 35 | Batch: 030 / 039 | Total loss: 1.483 | Reg loss: 0.022 | Tree loss: 1.483 | Accuracy: 0.523438 | 6.076 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 36 | Batch: 000 / 039 | Total loss: 2.424 | Reg loss: 0.017 | Tree loss: 2.424 | Accuracy: 0.308594 | 6.07 sec/iter\n",
      "Epoch: 36 | Batch: 010 / 039 | Total loss: 2.016 | Reg loss: 0.018 | Tree loss: 2.016 | Accuracy: 0.447266 | 6.068 sec/iter\n",
      "Epoch: 36 | Batch: 020 / 039 | Total loss: 1.625 | Reg loss: 0.020 | Tree loss: 1.625 | Accuracy: 0.492188 | 6.065 sec/iter\n",
      "Epoch: 36 | Batch: 030 / 039 | Total loss: 1.479 | Reg loss: 0.022 | Tree loss: 1.479 | Accuracy: 0.513672 | 6.062 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 37 | Batch: 000 / 039 | Total loss: 2.433 | Reg loss: 0.018 | Tree loss: 2.433 | Accuracy: 0.255859 | 6.056 sec/iter\n",
      "Epoch: 37 | Batch: 010 / 039 | Total loss: 2.013 | Reg loss: 0.018 | Tree loss: 2.013 | Accuracy: 0.427734 | 6.056 sec/iter\n",
      "Epoch: 37 | Batch: 020 / 039 | Total loss: 1.663 | Reg loss: 0.020 | Tree loss: 1.663 | Accuracy: 0.449219 | 6.056 sec/iter\n",
      "Epoch: 37 | Batch: 030 / 039 | Total loss: 1.489 | Reg loss: 0.022 | Tree loss: 1.489 | Accuracy: 0.515625 | 6.055 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 38 | Batch: 000 / 039 | Total loss: 2.428 | Reg loss: 0.018 | Tree loss: 2.428 | Accuracy: 0.302734 | 6.051 sec/iter\n",
      "Epoch: 38 | Batch: 010 / 039 | Total loss: 2.031 | Reg loss: 0.018 | Tree loss: 2.031 | Accuracy: 0.398438 | 6.05 sec/iter\n",
      "Epoch: 38 | Batch: 020 / 039 | Total loss: 1.669 | Reg loss: 0.020 | Tree loss: 1.669 | Accuracy: 0.500000 | 6.049 sec/iter\n",
      "Epoch: 38 | Batch: 030 / 039 | Total loss: 1.550 | Reg loss: 0.022 | Tree loss: 1.550 | Accuracy: 0.472656 | 6.049 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 39 | Batch: 000 / 039 | Total loss: 2.425 | Reg loss: 0.018 | Tree loss: 2.425 | Accuracy: 0.298828 | 6.045 sec/iter\n",
      "Epoch: 39 | Batch: 010 / 039 | Total loss: 2.092 | Reg loss: 0.019 | Tree loss: 2.092 | Accuracy: 0.351562 | 6.044 sec/iter\n",
      "Epoch: 39 | Batch: 020 / 039 | Total loss: 1.665 | Reg loss: 0.020 | Tree loss: 1.665 | Accuracy: 0.464844 | 6.043 sec/iter\n",
      "Epoch: 39 | Batch: 030 / 039 | Total loss: 1.534 | Reg loss: 0.022 | Tree loss: 1.534 | Accuracy: 0.501953 | 6.045 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 40 | Batch: 000 / 039 | Total loss: 2.429 | Reg loss: 0.018 | Tree loss: 2.429 | Accuracy: 0.257812 | 6.044 sec/iter\n",
      "Epoch: 40 | Batch: 010 / 039 | Total loss: 1.996 | Reg loss: 0.019 | Tree loss: 1.996 | Accuracy: 0.445312 | 6.046 sec/iter\n",
      "Epoch: 40 | Batch: 020 / 039 | Total loss: 1.626 | Reg loss: 0.020 | Tree loss: 1.626 | Accuracy: 0.501953 | 6.047 sec/iter\n",
      "Epoch: 40 | Batch: 030 / 039 | Total loss: 1.510 | Reg loss: 0.022 | Tree loss: 1.510 | Accuracy: 0.529297 | 6.049 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 41 | Batch: 000 / 039 | Total loss: 2.424 | Reg loss: 0.018 | Tree loss: 2.424 | Accuracy: 0.306641 | 6.046 sec/iter\n",
      "Epoch: 41 | Batch: 010 / 039 | Total loss: 2.028 | Reg loss: 0.019 | Tree loss: 2.028 | Accuracy: 0.431641 | 6.047 sec/iter\n",
      "Epoch: 41 | Batch: 020 / 039 | Total loss: 1.648 | Reg loss: 0.021 | Tree loss: 1.648 | Accuracy: 0.462891 | 6.049 sec/iter\n",
      "Epoch: 41 | Batch: 030 / 039 | Total loss: 1.532 | Reg loss: 0.022 | Tree loss: 1.532 | Accuracy: 0.500000 | 6.05 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Batch: 000 / 039 | Total loss: 2.421 | Reg loss: 0.018 | Tree loss: 2.421 | Accuracy: 0.300781 | 6.048 sec/iter\n",
      "Epoch: 42 | Batch: 010 / 039 | Total loss: 1.988 | Reg loss: 0.019 | Tree loss: 1.988 | Accuracy: 0.484375 | 6.05 sec/iter\n",
      "Epoch: 42 | Batch: 020 / 039 | Total loss: 1.661 | Reg loss: 0.021 | Tree loss: 1.661 | Accuracy: 0.468750 | 6.051 sec/iter\n",
      "Epoch: 42 | Batch: 030 / 039 | Total loss: 1.453 | Reg loss: 0.023 | Tree loss: 1.453 | Accuracy: 0.501953 | 6.052 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 43 | Batch: 000 / 039 | Total loss: 2.424 | Reg loss: 0.019 | Tree loss: 2.424 | Accuracy: 0.257812 | 6.05 sec/iter\n",
      "Epoch: 43 | Batch: 010 / 039 | Total loss: 2.026 | Reg loss: 0.019 | Tree loss: 2.026 | Accuracy: 0.410156 | 6.051 sec/iter\n",
      "Epoch: 43 | Batch: 020 / 039 | Total loss: 1.658 | Reg loss: 0.021 | Tree loss: 1.658 | Accuracy: 0.490234 | 6.053 sec/iter\n",
      "Epoch: 43 | Batch: 030 / 039 | Total loss: 1.485 | Reg loss: 0.023 | Tree loss: 1.485 | Accuracy: 0.537109 | 6.053 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 44 | Batch: 000 / 039 | Total loss: 2.418 | Reg loss: 0.019 | Tree loss: 2.418 | Accuracy: 0.265625 | 6.051 sec/iter\n",
      "Epoch: 44 | Batch: 010 / 039 | Total loss: 1.982 | Reg loss: 0.019 | Tree loss: 1.982 | Accuracy: 0.437500 | 6.052 sec/iter\n",
      "Epoch: 44 | Batch: 020 / 039 | Total loss: 1.659 | Reg loss: 0.021 | Tree loss: 1.659 | Accuracy: 0.460938 | 6.053 sec/iter\n",
      "Epoch: 44 | Batch: 030 / 039 | Total loss: 1.501 | Reg loss: 0.023 | Tree loss: 1.501 | Accuracy: 0.509766 | 6.055 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 45 | Batch: 000 / 039 | Total loss: 2.415 | Reg loss: 0.019 | Tree loss: 2.415 | Accuracy: 0.271484 | 6.053 sec/iter\n",
      "Epoch: 45 | Batch: 010 / 039 | Total loss: 1.999 | Reg loss: 0.020 | Tree loss: 1.999 | Accuracy: 0.478516 | 6.054 sec/iter\n",
      "Epoch: 45 | Batch: 020 / 039 | Total loss: 1.640 | Reg loss: 0.021 | Tree loss: 1.640 | Accuracy: 0.457031 | 6.055 sec/iter\n",
      "Epoch: 45 | Batch: 030 / 039 | Total loss: 1.404 | Reg loss: 0.023 | Tree loss: 1.404 | Accuracy: 0.544922 | 6.056 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 46 | Batch: 000 / 039 | Total loss: 2.408 | Reg loss: 0.019 | Tree loss: 2.408 | Accuracy: 0.296875 | 6.053 sec/iter\n",
      "Epoch: 46 | Batch: 010 / 039 | Total loss: 1.984 | Reg loss: 0.020 | Tree loss: 1.984 | Accuracy: 0.468750 | 6.055 sec/iter\n",
      "Epoch: 46 | Batch: 020 / 039 | Total loss: 1.650 | Reg loss: 0.021 | Tree loss: 1.650 | Accuracy: 0.486328 | 6.054 sec/iter\n",
      "Epoch: 46 | Batch: 030 / 039 | Total loss: 1.476 | Reg loss: 0.023 | Tree loss: 1.476 | Accuracy: 0.503906 | 6.054 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 47 | Batch: 000 / 039 | Total loss: 2.408 | Reg loss: 0.019 | Tree loss: 2.408 | Accuracy: 0.312500 | 6.051 sec/iter\n",
      "Epoch: 47 | Batch: 010 / 039 | Total loss: 1.989 | Reg loss: 0.020 | Tree loss: 1.989 | Accuracy: 0.453125 | 6.05 sec/iter\n",
      "Epoch: 47 | Batch: 020 / 039 | Total loss: 1.562 | Reg loss: 0.022 | Tree loss: 1.562 | Accuracy: 0.525391 | 6.049 sec/iter\n",
      "Epoch: 47 | Batch: 030 / 039 | Total loss: 1.477 | Reg loss: 0.023 | Tree loss: 1.477 | Accuracy: 0.519531 | 6.049 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 48 | Batch: 000 / 039 | Total loss: 2.413 | Reg loss: 0.019 | Tree loss: 2.413 | Accuracy: 0.263672 | 6.045 sec/iter\n",
      "Epoch: 48 | Batch: 010 / 039 | Total loss: 1.960 | Reg loss: 0.020 | Tree loss: 1.960 | Accuracy: 0.435547 | 6.045 sec/iter\n",
      "Epoch: 48 | Batch: 020 / 039 | Total loss: 1.601 | Reg loss: 0.022 | Tree loss: 1.601 | Accuracy: 0.472656 | 6.044 sec/iter\n",
      "Epoch: 48 | Batch: 030 / 039 | Total loss: 1.427 | Reg loss: 0.023 | Tree loss: 1.427 | Accuracy: 0.533203 | 6.043 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 49 | Batch: 000 / 039 | Total loss: 2.409 | Reg loss: 0.020 | Tree loss: 2.409 | Accuracy: 0.294922 | 6.04 sec/iter\n",
      "Epoch: 49 | Batch: 010 / 039 | Total loss: 1.904 | Reg loss: 0.020 | Tree loss: 1.904 | Accuracy: 0.527344 | 6.039 sec/iter\n",
      "Epoch: 49 | Batch: 020 / 039 | Total loss: 1.663 | Reg loss: 0.022 | Tree loss: 1.663 | Accuracy: 0.441406 | 6.038 sec/iter\n",
      "Epoch: 49 | Batch: 030 / 039 | Total loss: 1.490 | Reg loss: 0.023 | Tree loss: 1.490 | Accuracy: 0.500000 | 6.038 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 50 | Batch: 000 / 039 | Total loss: 2.412 | Reg loss: 0.020 | Tree loss: 2.412 | Accuracy: 0.236328 | 6.035 sec/iter\n",
      "Epoch: 50 | Batch: 010 / 039 | Total loss: 1.967 | Reg loss: 0.020 | Tree loss: 1.967 | Accuracy: 0.429688 | 6.035 sec/iter\n",
      "Epoch: 50 | Batch: 020 / 039 | Total loss: 1.674 | Reg loss: 0.022 | Tree loss: 1.674 | Accuracy: 0.453125 | 6.034 sec/iter\n",
      "Epoch: 50 | Batch: 030 / 039 | Total loss: 1.448 | Reg loss: 0.023 | Tree loss: 1.448 | Accuracy: 0.542969 | 6.033 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 51 | Batch: 000 / 039 | Total loss: 2.403 | Reg loss: 0.020 | Tree loss: 2.403 | Accuracy: 0.273438 | 6.029 sec/iter\n",
      "Epoch: 51 | Batch: 010 / 039 | Total loss: 1.946 | Reg loss: 0.020 | Tree loss: 1.946 | Accuracy: 0.484375 | 6.027 sec/iter\n",
      "Epoch: 51 | Batch: 020 / 039 | Total loss: 1.669 | Reg loss: 0.022 | Tree loss: 1.669 | Accuracy: 0.437500 | 6.025 sec/iter\n",
      "Epoch: 51 | Batch: 030 / 039 | Total loss: 1.428 | Reg loss: 0.024 | Tree loss: 1.428 | Accuracy: 0.544922 | 6.026 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 52 | Batch: 000 / 039 | Total loss: 2.406 | Reg loss: 0.020 | Tree loss: 2.406 | Accuracy: 0.277344 | 6.025 sec/iter\n",
      "Epoch: 52 | Batch: 010 / 039 | Total loss: 1.928 | Reg loss: 0.021 | Tree loss: 1.928 | Accuracy: 0.458984 | 6.028 sec/iter\n",
      "Epoch: 52 | Batch: 020 / 039 | Total loss: 1.586 | Reg loss: 0.022 | Tree loss: 1.586 | Accuracy: 0.505859 | 6.038 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | Batch: 030 / 039 | Total loss: 1.470 | Reg loss: 0.024 | Tree loss: 1.470 | Accuracy: 0.539062 | 6.045 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 53 | Batch: 000 / 039 | Total loss: 2.399 | Reg loss: 0.020 | Tree loss: 2.399 | Accuracy: 0.281250 | 6.048 sec/iter\n",
      "Epoch: 53 | Batch: 010 / 039 | Total loss: 1.923 | Reg loss: 0.021 | Tree loss: 1.923 | Accuracy: 0.466797 | 6.049 sec/iter\n",
      "Epoch: 53 | Batch: 020 / 039 | Total loss: 1.624 | Reg loss: 0.022 | Tree loss: 1.624 | Accuracy: 0.494141 | 6.052 sec/iter\n",
      "Epoch: 53 | Batch: 030 / 039 | Total loss: 1.413 | Reg loss: 0.024 | Tree loss: 1.413 | Accuracy: 0.533203 | 6.053 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 54 | Batch: 000 / 039 | Total loss: 2.396 | Reg loss: 0.020 | Tree loss: 2.396 | Accuracy: 0.281250 | 6.055 sec/iter\n",
      "Epoch: 54 | Batch: 010 / 039 | Total loss: 1.969 | Reg loss: 0.021 | Tree loss: 1.969 | Accuracy: 0.458984 | 6.06 sec/iter\n",
      "Epoch: 54 | Batch: 020 / 039 | Total loss: 1.636 | Reg loss: 0.022 | Tree loss: 1.636 | Accuracy: 0.460938 | 6.062 sec/iter\n",
      "Epoch: 54 | Batch: 030 / 039 | Total loss: 1.434 | Reg loss: 0.024 | Tree loss: 1.434 | Accuracy: 0.529297 | 6.062 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 55 | Batch: 000 / 039 | Total loss: 2.396 | Reg loss: 0.020 | Tree loss: 2.396 | Accuracy: 0.302734 | 6.06 sec/iter\n",
      "Epoch: 55 | Batch: 010 / 039 | Total loss: 1.940 | Reg loss: 0.021 | Tree loss: 1.940 | Accuracy: 0.468750 | 6.06 sec/iter\n",
      "Epoch: 55 | Batch: 020 / 039 | Total loss: 1.597 | Reg loss: 0.023 | Tree loss: 1.597 | Accuracy: 0.480469 | 6.06 sec/iter\n",
      "Epoch: 55 | Batch: 030 / 039 | Total loss: 1.446 | Reg loss: 0.024 | Tree loss: 1.446 | Accuracy: 0.537109 | 6.06 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 56 | Batch: 000 / 039 | Total loss: 2.396 | Reg loss: 0.020 | Tree loss: 2.396 | Accuracy: 0.269531 | 6.058 sec/iter\n",
      "Epoch: 56 | Batch: 010 / 039 | Total loss: 1.921 | Reg loss: 0.021 | Tree loss: 1.921 | Accuracy: 0.468750 | 6.059 sec/iter\n",
      "Epoch: 56 | Batch: 020 / 039 | Total loss: 1.618 | Reg loss: 0.023 | Tree loss: 1.618 | Accuracy: 0.486328 | 6.059 sec/iter\n",
      "Epoch: 56 | Batch: 030 / 039 | Total loss: 1.439 | Reg loss: 0.024 | Tree loss: 1.439 | Accuracy: 0.552734 | 6.065 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 57 | Batch: 000 / 039 | Total loss: 2.390 | Reg loss: 0.021 | Tree loss: 2.390 | Accuracy: 0.320312 | 6.066 sec/iter\n",
      "Epoch: 57 | Batch: 010 / 039 | Total loss: 1.941 | Reg loss: 0.021 | Tree loss: 1.941 | Accuracy: 0.474609 | 6.071 sec/iter\n",
      "Epoch: 57 | Batch: 020 / 039 | Total loss: 1.577 | Reg loss: 0.023 | Tree loss: 1.577 | Accuracy: 0.503906 | 6.073 sec/iter\n",
      "Epoch: 57 | Batch: 030 / 039 | Total loss: 1.485 | Reg loss: 0.024 | Tree loss: 1.485 | Accuracy: 0.492188 | 6.075 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 58 | Batch: 000 / 039 | Total loss: 2.399 | Reg loss: 0.021 | Tree loss: 2.399 | Accuracy: 0.257812 | 6.076 sec/iter\n",
      "Epoch: 58 | Batch: 010 / 039 | Total loss: 1.913 | Reg loss: 0.021 | Tree loss: 1.913 | Accuracy: 0.482422 | 6.077 sec/iter\n",
      "Epoch: 58 | Batch: 020 / 039 | Total loss: 1.587 | Reg loss: 0.023 | Tree loss: 1.587 | Accuracy: 0.482422 | 6.077 sec/iter\n",
      "Epoch: 58 | Batch: 030 / 039 | Total loss: 1.459 | Reg loss: 0.024 | Tree loss: 1.459 | Accuracy: 0.486328 | 6.076 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 59 | Batch: 000 / 039 | Total loss: 2.388 | Reg loss: 0.021 | Tree loss: 2.388 | Accuracy: 0.279297 | 6.074 sec/iter\n",
      "Epoch: 59 | Batch: 010 / 039 | Total loss: 1.914 | Reg loss: 0.021 | Tree loss: 1.914 | Accuracy: 0.476562 | 6.073 sec/iter\n",
      "Epoch: 59 | Batch: 020 / 039 | Total loss: 1.616 | Reg loss: 0.023 | Tree loss: 1.616 | Accuracy: 0.464844 | 6.074 sec/iter\n",
      "Epoch: 59 | Batch: 030 / 039 | Total loss: 1.531 | Reg loss: 0.024 | Tree loss: 1.531 | Accuracy: 0.482422 | 6.075 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 60 | Batch: 000 / 039 | Total loss: 2.392 | Reg loss: 0.021 | Tree loss: 2.392 | Accuracy: 0.275391 | 6.072 sec/iter\n",
      "Epoch: 60 | Batch: 010 / 039 | Total loss: 1.948 | Reg loss: 0.021 | Tree loss: 1.948 | Accuracy: 0.460938 | 6.072 sec/iter\n",
      "Epoch: 60 | Batch: 020 / 039 | Total loss: 1.605 | Reg loss: 0.023 | Tree loss: 1.605 | Accuracy: 0.464844 | 6.071 sec/iter\n",
      "Epoch: 60 | Batch: 030 / 039 | Total loss: 1.436 | Reg loss: 0.024 | Tree loss: 1.436 | Accuracy: 0.550781 | 6.07 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 61 | Batch: 000 / 039 | Total loss: 2.395 | Reg loss: 0.021 | Tree loss: 2.395 | Accuracy: 0.246094 | 6.068 sec/iter\n",
      "Epoch: 61 | Batch: 010 / 039 | Total loss: 1.921 | Reg loss: 0.021 | Tree loss: 1.921 | Accuracy: 0.488281 | 6.067 sec/iter\n",
      "Epoch: 61 | Batch: 020 / 039 | Total loss: 1.546 | Reg loss: 0.023 | Tree loss: 1.546 | Accuracy: 0.494141 | 6.067 sec/iter\n",
      "Epoch: 61 | Batch: 030 / 039 | Total loss: 1.435 | Reg loss: 0.024 | Tree loss: 1.435 | Accuracy: 0.505859 | 6.066 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 62 | Batch: 000 / 039 | Total loss: 2.389 | Reg loss: 0.021 | Tree loss: 2.389 | Accuracy: 0.285156 | 6.065 sec/iter\n",
      "Epoch: 62 | Batch: 010 / 039 | Total loss: 1.946 | Reg loss: 0.021 | Tree loss: 1.946 | Accuracy: 0.437500 | 6.066 sec/iter\n",
      "Epoch: 62 | Batch: 020 / 039 | Total loss: 1.612 | Reg loss: 0.023 | Tree loss: 1.612 | Accuracy: 0.492188 | 6.068 sec/iter\n",
      "Epoch: 62 | Batch: 030 / 039 | Total loss: 1.477 | Reg loss: 0.024 | Tree loss: 1.477 | Accuracy: 0.511719 | 6.07 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 | Batch: 000 / 039 | Total loss: 2.388 | Reg loss: 0.021 | Tree loss: 2.388 | Accuracy: 0.273438 | 6.07 sec/iter\n",
      "Epoch: 63 | Batch: 010 / 039 | Total loss: 1.956 | Reg loss: 0.021 | Tree loss: 1.956 | Accuracy: 0.464844 | 6.072 sec/iter\n",
      "Epoch: 63 | Batch: 020 / 039 | Total loss: 1.588 | Reg loss: 0.023 | Tree loss: 1.588 | Accuracy: 0.458984 | 6.075 sec/iter\n",
      "Epoch: 63 | Batch: 030 / 039 | Total loss: 1.414 | Reg loss: 0.024 | Tree loss: 1.414 | Accuracy: 0.531250 | 6.075 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 64 | Batch: 000 / 039 | Total loss: 2.402 | Reg loss: 0.021 | Tree loss: 2.402 | Accuracy: 0.238281 | 6.073 sec/iter\n",
      "Epoch: 64 | Batch: 010 / 039 | Total loss: 1.958 | Reg loss: 0.022 | Tree loss: 1.958 | Accuracy: 0.451172 | 6.072 sec/iter\n",
      "Epoch: 64 | Batch: 020 / 039 | Total loss: 1.588 | Reg loss: 0.023 | Tree loss: 1.588 | Accuracy: 0.468750 | 6.074 sec/iter\n",
      "Epoch: 64 | Batch: 030 / 039 | Total loss: 1.473 | Reg loss: 0.024 | Tree loss: 1.473 | Accuracy: 0.513672 | 6.077 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 65 | Batch: 000 / 039 | Total loss: 2.393 | Reg loss: 0.021 | Tree loss: 2.393 | Accuracy: 0.308594 | 6.077 sec/iter\n",
      "Epoch: 65 | Batch: 010 / 039 | Total loss: 1.924 | Reg loss: 0.022 | Tree loss: 1.924 | Accuracy: 0.482422 | 6.082 sec/iter\n",
      "Epoch: 65 | Batch: 020 / 039 | Total loss: 1.575 | Reg loss: 0.023 | Tree loss: 1.575 | Accuracy: 0.478516 | 6.084 sec/iter\n",
      "Epoch: 65 | Batch: 030 / 039 | Total loss: 1.441 | Reg loss: 0.025 | Tree loss: 1.441 | Accuracy: 0.533203 | 6.085 sec/iter\n",
      "Average sparseness: 0.9946808510638298\n",
      "layer 0: 0.9946808510638298\n",
      "layer 1: 0.9946808510638298\n",
      "layer 2: 0.9946808510638298\n",
      "layer 3: 0.9946808510638298\n",
      "layer 4: 0.9946808510638298\n",
      "layer 5: 0.9946808510638298\n",
      "layer 6: 0.9946808510638298\n",
      "layer 7: 0.9946808510638298\n",
      "layer 8: 0.9946808510638298\n",
      "Epoch: 66 | Batch: 000 / 039 | Total loss: 2.394 | Reg loss: 0.021 | Tree loss: 2.394 | Accuracy: 0.253906 | 6.085 sec/iter\n",
      "Epoch: 66 | Batch: 010 / 039 | Total loss: 1.912 | Reg loss: 0.022 | Tree loss: 1.912 | Accuracy: 0.458984 | 6.088 sec/iter\n",
      "Epoch: 66 | Batch: 020 / 039 | Total loss: 1.584 | Reg loss: 0.023 | Tree loss: 1.584 | Accuracy: 0.511719 | 6.089 sec/iter\n",
      "Epoch: 66 | Batch: 030 / 039 | Total loss: 1.432 | Reg loss: 0.025 | Tree loss: 1.432 | Accuracy: 0.515625 | 6.091 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = dataset.items\n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
