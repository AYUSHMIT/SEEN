{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 16\n",
    "tree_depth = 6\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.353687286376953 | KNN Loss: 5.5526628494262695 | CLS Loss: 1.8010241985321045\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 4.729332447052002 | KNN Loss: 3.8576250076293945 | CLS Loss: 0.871707558631897\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 4.0940260887146 | KNN Loss: 3.309173583984375 | CLS Loss: 0.7848523259162903\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 3.8650264739990234 | KNN Loss: 3.2776787281036377 | CLS Loss: 0.5873478651046753\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 3.8695287704467773 | KNN Loss: 3.2394747734069824 | CLS Loss: 0.6300539970397949\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 3.7488129138946533 | KNN Loss: 3.197767734527588 | CLS Loss: 0.5510451793670654\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 3.756903886795044 | KNN Loss: 3.245512008666992 | CLS Loss: 0.5113918781280518\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 3.7646336555480957 | KNN Loss: 3.2590463161468506 | CLS Loss: 0.5055873394012451\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 3.714940071105957 | KNN Loss: 3.2178800106048584 | CLS Loss: 0.49706006050109863\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 3.6725404262542725 | KNN Loss: 3.260803461074829 | CLS Loss: 0.41173702478408813\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 3.644587278366089 | KNN Loss: 3.2433440685272217 | CLS Loss: 0.40124329924583435\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 3.604635715484619 | KNN Loss: 3.2502434253692627 | CLS Loss: 0.3543921709060669\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 3.5703301429748535 | KNN Loss: 3.2291343212127686 | CLS Loss: 0.34119585156440735\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 3.5953683853149414 | KNN Loss: 3.271080493927002 | CLS Loss: 0.32428789138793945\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 3.564680337905884 | KNN Loss: 3.2359025478363037 | CLS Loss: 0.32877781987190247\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 3.6154215335845947 | KNN Loss: 3.218388319015503 | CLS Loss: 0.39703330397605896\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 3.530700206756592 | KNN Loss: 3.196638822555542 | CLS Loss: 0.33406147360801697\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 3.511622667312622 | KNN Loss: 3.172931432723999 | CLS Loss: 0.3386911451816559\n",
      "Epoch: 001, Loss: 3.8893, Train: 0.9153, Valid: 0.9163, Best: 0.9163\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 3.4688527584075928 | KNN Loss: 3.214508295059204 | CLS Loss: 0.2543443739414215\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 3.455064296722412 | KNN Loss: 3.2041845321655273 | CLS Loss: 0.25087982416152954\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 3.464972972869873 | KNN Loss: 3.170118570327759 | CLS Loss: 0.2948545217514038\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 3.446937322616577 | KNN Loss: 3.1882128715515137 | CLS Loss: 0.2587244510650635\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 3.45868182182312 | KNN Loss: 3.1757283210754395 | CLS Loss: 0.2829534411430359\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 3.4578425884246826 | KNN Loss: 3.1950085163116455 | CLS Loss: 0.2628341317176819\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 3.495253562927246 | KNN Loss: 3.2084319591522217 | CLS Loss: 0.28682148456573486\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 3.4919145107269287 | KNN Loss: 3.170095443725586 | CLS Loss: 0.32181912660598755\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 3.428224563598633 | KNN Loss: 3.1800756454467773 | CLS Loss: 0.24814894795417786\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 3.395294427871704 | KNN Loss: 3.154986619949341 | CLS Loss: 0.2403077632188797\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 3.396064519882202 | KNN Loss: 3.1293649673461914 | CLS Loss: 0.26669958233833313\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 3.371429443359375 | KNN Loss: 3.109083890914917 | CLS Loss: 0.2623455226421356\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 3.3581290245056152 | KNN Loss: 3.15586256980896 | CLS Loss: 0.20226642489433289\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 3.3920035362243652 | KNN Loss: 3.190220355987549 | CLS Loss: 0.2017831802368164\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 3.345041275024414 | KNN Loss: 3.1294407844543457 | CLS Loss: 0.21560044586658478\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 3.362767457962036 | KNN Loss: 3.131012201309204 | CLS Loss: 0.2317553013563156\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 3.331590175628662 | KNN Loss: 3.139557361602783 | CLS Loss: 0.19203270971775055\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 3.3839786052703857 | KNN Loss: 3.163483142852783 | CLS Loss: 0.22049549221992493\n",
      "Epoch: 002, Loss: 3.4313, Train: 0.9393, Valid: 0.9389, Best: 0.9389\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 3.3956215381622314 | KNN Loss: 3.112246036529541 | CLS Loss: 0.28337547183036804\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 3.356692314147949 | KNN Loss: 3.1268582344055176 | CLS Loss: 0.22983413934707642\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 3.3213415145874023 | KNN Loss: 3.075977087020874 | CLS Loss: 0.2453644722700119\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 3.3140223026275635 | KNN Loss: 3.1234493255615234 | CLS Loss: 0.19057300686836243\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 3.2823634147644043 | KNN Loss: 3.1387217044830322 | CLS Loss: 0.14364178478717804\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 3.283107280731201 | KNN Loss: 3.120968818664551 | CLS Loss: 0.16213847696781158\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 3.3583931922912598 | KNN Loss: 3.151931047439575 | CLS Loss: 0.20646211504936218\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 3.279090404510498 | KNN Loss: 3.141383647918701 | CLS Loss: 0.13770683109760284\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 3.298971176147461 | KNN Loss: 3.1092069149017334 | CLS Loss: 0.18976418673992157\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 3.328734874725342 | KNN Loss: 3.1310477256774902 | CLS Loss: 0.19768710434436798\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 3.318981885910034 | KNN Loss: 3.157140016555786 | CLS Loss: 0.16184192895889282\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 3.3233890533447266 | KNN Loss: 3.145657777786255 | CLS Loss: 0.17773115634918213\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 3.2498269081115723 | KNN Loss: 3.0761191844940186 | CLS Loss: 0.17370763421058655\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 3.3275816440582275 | KNN Loss: 3.1559290885925293 | CLS Loss: 0.17165255546569824\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 3.3112566471099854 | KNN Loss: 3.127218723297119 | CLS Loss: 0.18403801321983337\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 3.277480125427246 | KNN Loss: 3.1109960079193115 | CLS Loss: 0.16648416221141815\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 3.290670156478882 | KNN Loss: 3.1167960166931152 | CLS Loss: 0.17387409508228302\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 3.2631051540374756 | KNN Loss: 3.1252968311309814 | CLS Loss: 0.13780832290649414\n",
      "Epoch: 003, Loss: 3.3078, Train: 0.9628, Valid: 0.9609, Best: 0.9609\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 3.269705057144165 | KNN Loss: 3.0973217487335205 | CLS Loss: 0.17238333821296692\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 3.21058988571167 | KNN Loss: 3.097816228866577 | CLS Loss: 0.11277355998754501\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 3.264796018600464 | KNN Loss: 3.1035327911376953 | CLS Loss: 0.16126321256160736\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 3.240474224090576 | KNN Loss: 3.120664596557617 | CLS Loss: 0.11980969458818436\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 3.26813006401062 | KNN Loss: 3.110975980758667 | CLS Loss: 0.15715406835079193\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 3.2746810913085938 | KNN Loss: 3.1225593090057373 | CLS Loss: 0.15212170779705048\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 3.3067448139190674 | KNN Loss: 3.119250535964966 | CLS Loss: 0.1874941736459732\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 3.2856411933898926 | KNN Loss: 3.117360830307007 | CLS Loss: 0.16828030347824097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 3.2076327800750732 | KNN Loss: 3.086923122406006 | CLS Loss: 0.12070959806442261\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 3.250946521759033 | KNN Loss: 3.111034870147705 | CLS Loss: 0.1399116963148117\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 3.2041304111480713 | KNN Loss: 3.0966131687164307 | CLS Loss: 0.10751722007989883\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 3.210449457168579 | KNN Loss: 3.0962560176849365 | CLS Loss: 0.11419354379177094\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 3.218536376953125 | KNN Loss: 3.087359666824341 | CLS Loss: 0.13117672502994537\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 3.2078328132629395 | KNN Loss: 3.118234872817993 | CLS Loss: 0.08959782868623734\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 3.2393791675567627 | KNN Loss: 3.111973762512207 | CLS Loss: 0.12740540504455566\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 3.246518611907959 | KNN Loss: 3.1082305908203125 | CLS Loss: 0.13828809559345245\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 3.2451417446136475 | KNN Loss: 3.1423842906951904 | CLS Loss: 0.10275745391845703\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 3.2250630855560303 | KNN Loss: 3.1198208332061768 | CLS Loss: 0.10524220019578934\n",
      "Epoch: 004, Loss: 3.2433, Train: 0.9687, Valid: 0.9678, Best: 0.9678\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 3.1996893882751465 | KNN Loss: 3.1172351837158203 | CLS Loss: 0.0824541300535202\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 3.2428669929504395 | KNN Loss: 3.1239945888519287 | CLS Loss: 0.1188725084066391\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 3.2799887657165527 | KNN Loss: 3.0740585327148438 | CLS Loss: 0.2059302031993866\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 3.1777901649475098 | KNN Loss: 3.0768399238586426 | CLS Loss: 0.10095017403364182\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 3.2230005264282227 | KNN Loss: 3.107572555541992 | CLS Loss: 0.11542801558971405\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 3.2063710689544678 | KNN Loss: 3.1268110275268555 | CLS Loss: 0.07956014573574066\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 3.2020814418792725 | KNN Loss: 3.10017728805542 | CLS Loss: 0.1019042432308197\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 3.2652359008789062 | KNN Loss: 3.124521017074585 | CLS Loss: 0.14071495831012726\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 3.1531901359558105 | KNN Loss: 3.065131187438965 | CLS Loss: 0.08805902302265167\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 3.1993446350097656 | KNN Loss: 3.096194267272949 | CLS Loss: 0.10315041989088058\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 3.2076220512390137 | KNN Loss: 3.0641236305236816 | CLS Loss: 0.1434985101222992\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 3.2123336791992188 | KNN Loss: 3.1644415855407715 | CLS Loss: 0.04789213091135025\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 3.2333970069885254 | KNN Loss: 3.103863477706909 | CLS Loss: 0.1295335292816162\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 3.1661527156829834 | KNN Loss: 3.058772087097168 | CLS Loss: 0.10738060623407364\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 3.1747217178344727 | KNN Loss: 3.0756444931030273 | CLS Loss: 0.0990772619843483\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 3.1400115489959717 | KNN Loss: 3.091007947921753 | CLS Loss: 0.04900350794196129\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 3.1754579544067383 | KNN Loss: 3.0803487300872803 | CLS Loss: 0.09510921686887741\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 3.2052128314971924 | KNN Loss: 3.084033966064453 | CLS Loss: 0.12117878347635269\n",
      "Epoch: 005, Loss: 3.2087, Train: 0.9726, Valid: 0.9703, Best: 0.9703\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 3.1862058639526367 | KNN Loss: 3.0788655281066895 | CLS Loss: 0.10734021663665771\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 3.1731584072113037 | KNN Loss: 3.068371295928955 | CLS Loss: 0.10478705912828445\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 3.199915647506714 | KNN Loss: 3.101081132888794 | CLS Loss: 0.09883449971675873\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 3.237666606903076 | KNN Loss: 3.0962862968444824 | CLS Loss: 0.1413803994655609\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 3.1912388801574707 | KNN Loss: 3.086181402206421 | CLS Loss: 0.1050574779510498\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 3.196633815765381 | KNN Loss: 3.076991081237793 | CLS Loss: 0.11964280158281326\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 3.180480480194092 | KNN Loss: 3.072455644607544 | CLS Loss: 0.10802493989467621\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 3.174848794937134 | KNN Loss: 3.0741240978240967 | CLS Loss: 0.10072464495897293\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 3.124852418899536 | KNN Loss: 3.0479679107666016 | CLS Loss: 0.07688453048467636\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 3.1389899253845215 | KNN Loss: 3.0756208896636963 | CLS Loss: 0.06336906552314758\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 3.2153499126434326 | KNN Loss: 3.0759048461914062 | CLS Loss: 0.13944512605667114\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 3.147062301635742 | KNN Loss: 3.0630786418914795 | CLS Loss: 0.08398372679948807\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 3.1852223873138428 | KNN Loss: 3.0567750930786133 | CLS Loss: 0.12844720482826233\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 3.1459333896636963 | KNN Loss: 3.066556215286255 | CLS Loss: 0.07937706261873245\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 3.1312434673309326 | KNN Loss: 3.068361759185791 | CLS Loss: 0.06288179010152817\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 3.1978514194488525 | KNN Loss: 3.108046054840088 | CLS Loss: 0.08980528265237808\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 3.1677358150482178 | KNN Loss: 3.0741686820983887 | CLS Loss: 0.09356710314750671\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 3.1623616218566895 | KNN Loss: 3.052393913269043 | CLS Loss: 0.10996758937835693\n",
      "Epoch: 006, Loss: 3.1816, Train: 0.9765, Valid: 0.9729, Best: 0.9729\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 3.184615135192871 | KNN Loss: 3.0711588859558105 | CLS Loss: 0.11345621943473816\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 3.126321792602539 | KNN Loss: 3.033928394317627 | CLS Loss: 0.09239334613084793\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 3.199411392211914 | KNN Loss: 3.0635979175567627 | CLS Loss: 0.13581351935863495\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 3.191258430480957 | KNN Loss: 3.063281536102295 | CLS Loss: 0.12797683477401733\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 3.1277761459350586 | KNN Loss: 3.06775164604187 | CLS Loss: 0.06002460792660713\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 3.272773265838623 | KNN Loss: 3.1378180980682373 | CLS Loss: 0.13495506346225739\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 3.150390863418579 | KNN Loss: 3.0867550373077393 | CLS Loss: 0.0636359304189682\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 3.1416563987731934 | KNN Loss: 3.067363977432251 | CLS Loss: 0.07429231703281403\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 3.155146360397339 | KNN Loss: 3.0752925872802734 | CLS Loss: 0.07985373586416245\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 3.1466305255889893 | KNN Loss: 3.059692621231079 | CLS Loss: 0.08693793416023254\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 3.195611000061035 | KNN Loss: 3.090073585510254 | CLS Loss: 0.10553745180368423\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 3.1787025928497314 | KNN Loss: 3.0694828033447266 | CLS Loss: 0.10921990126371384\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 3.1644155979156494 | KNN Loss: 3.079878807067871 | CLS Loss: 0.08453679829835892\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 3.148305892944336 | KNN Loss: 3.05600643157959 | CLS Loss: 0.09229936450719833\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 3.1494996547698975 | KNN Loss: 3.083266258239746 | CLS Loss: 0.06623345613479614\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 3.2025678157806396 | KNN Loss: 3.0946543216705322 | CLS Loss: 0.10791356861591339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 3.1732869148254395 | KNN Loss: 3.0635108947753906 | CLS Loss: 0.10977602750062943\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 3.163022994995117 | KNN Loss: 3.0696487426757812 | CLS Loss: 0.09337416291236877\n",
      "Epoch: 007, Loss: 3.1678, Train: 0.9715, Valid: 0.9696, Best: 0.9729\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 3.1693410873413086 | KNN Loss: 3.1077771186828613 | CLS Loss: 0.061564043164253235\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 3.1543514728546143 | KNN Loss: 3.0508298873901367 | CLS Loss: 0.1035216823220253\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 3.1989665031433105 | KNN Loss: 3.0559260845184326 | CLS Loss: 0.14304044842720032\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 3.1524837017059326 | KNN Loss: 3.0671067237854004 | CLS Loss: 0.08537698537111282\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 3.168806552886963 | KNN Loss: 3.038391351699829 | CLS Loss: 0.13041509687900543\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 3.161609649658203 | KNN Loss: 3.0919928550720215 | CLS Loss: 0.06961669027805328\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 3.1416962146759033 | KNN Loss: 3.0904014110565186 | CLS Loss: 0.051294825971126556\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 3.1502504348754883 | KNN Loss: 3.0750772953033447 | CLS Loss: 0.07517316192388535\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 3.1403095722198486 | KNN Loss: 3.0575344562530518 | CLS Loss: 0.08277514576911926\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 3.1657304763793945 | KNN Loss: 3.0600857734680176 | CLS Loss: 0.105644591152668\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 3.1285204887390137 | KNN Loss: 3.0732905864715576 | CLS Loss: 0.05522986501455307\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 3.145810127258301 | KNN Loss: 3.0724937915802 | CLS Loss: 0.07331644743680954\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 3.084141492843628 | KNN Loss: 3.0321929454803467 | CLS Loss: 0.051948558539152145\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 3.155787944793701 | KNN Loss: 3.056596517562866 | CLS Loss: 0.09919144213199615\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 3.1577844619750977 | KNN Loss: 3.0796725749969482 | CLS Loss: 0.07811194658279419\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 3.1694302558898926 | KNN Loss: 3.0388991832733154 | CLS Loss: 0.13053104281425476\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 3.154971122741699 | KNN Loss: 3.068131923675537 | CLS Loss: 0.08683930337429047\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 3.1074647903442383 | KNN Loss: 3.020432949066162 | CLS Loss: 0.08703173696994781\n",
      "Epoch: 008, Loss: 3.1476, Train: 0.9798, Valid: 0.9773, Best: 0.9773\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 3.133382558822632 | KNN Loss: 3.0696496963500977 | CLS Loss: 0.06373288482427597\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 3.1138010025024414 | KNN Loss: 3.036914587020874 | CLS Loss: 0.07688643038272858\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 3.095529317855835 | KNN Loss: 3.0526626110076904 | CLS Loss: 0.042866602540016174\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 3.137315273284912 | KNN Loss: 3.028946876525879 | CLS Loss: 0.1083683893084526\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 3.1827168464660645 | KNN Loss: 3.0822036266326904 | CLS Loss: 0.10051322728395462\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 3.1398067474365234 | KNN Loss: 3.102915048599243 | CLS Loss: 0.036891646683216095\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 3.1592979431152344 | KNN Loss: 3.0961062908172607 | CLS Loss: 0.06319168955087662\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 3.1317267417907715 | KNN Loss: 3.0417704582214355 | CLS Loss: 0.08995627611875534\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 3.129412889480591 | KNN Loss: 3.0606191158294678 | CLS Loss: 0.06879378110170364\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 3.092978000640869 | KNN Loss: 3.017216920852661 | CLS Loss: 0.07576100528240204\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 3.1030032634735107 | KNN Loss: 3.009556531906128 | CLS Loss: 0.09344681352376938\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 3.123020648956299 | KNN Loss: 3.034289598464966 | CLS Loss: 0.0887310653924942\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 3.1492867469787598 | KNN Loss: 3.028470277786255 | CLS Loss: 0.1208164393901825\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 3.1688055992126465 | KNN Loss: 3.0557522773742676 | CLS Loss: 0.11305329203605652\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 3.1018242835998535 | KNN Loss: 3.042924642562866 | CLS Loss: 0.058899641036987305\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 3.152493953704834 | KNN Loss: 3.0594725608825684 | CLS Loss: 0.09302129596471786\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 3.125643014907837 | KNN Loss: 3.052609443664551 | CLS Loss: 0.0730336457490921\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 3.1541619300842285 | KNN Loss: 3.07320237159729 | CLS Loss: 0.08095955848693848\n",
      "Epoch: 009, Loss: 3.1345, Train: 0.9808, Valid: 0.9776, Best: 0.9776\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 3.103548049926758 | KNN Loss: 3.0452721118927 | CLS Loss: 0.058275990188121796\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 3.1331634521484375 | KNN Loss: 3.0625054836273193 | CLS Loss: 0.07065799087285995\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 3.1259682178497314 | KNN Loss: 3.0412027835845947 | CLS Loss: 0.08476544916629791\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 3.1232519149780273 | KNN Loss: 2.9978058338165283 | CLS Loss: 0.12544597685337067\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 3.1338748931884766 | KNN Loss: 3.078348398208618 | CLS Loss: 0.05552645027637482\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 3.146374464035034 | KNN Loss: 3.0512421131134033 | CLS Loss: 0.09513244777917862\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 3.1457815170288086 | KNN Loss: 3.0475802421569824 | CLS Loss: 0.09820135682821274\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 3.127747058868408 | KNN Loss: 3.0121209621429443 | CLS Loss: 0.11562619358301163\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 3.112675905227661 | KNN Loss: 3.043567657470703 | CLS Loss: 0.06910829246044159\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 3.1213839054107666 | KNN Loss: 3.0600881576538086 | CLS Loss: 0.061295732855796814\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 3.188343048095703 | KNN Loss: 3.0578880310058594 | CLS Loss: 0.1304551362991333\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 3.1225736141204834 | KNN Loss: 3.0571558475494385 | CLS Loss: 0.06541786342859268\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 3.0957632064819336 | KNN Loss: 3.0154671669006348 | CLS Loss: 0.080296091735363\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 3.104135513305664 | KNN Loss: 3.0417749881744385 | CLS Loss: 0.062360480427742004\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 3.1123836040496826 | KNN Loss: 3.042926073074341 | CLS Loss: 0.06945761293172836\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 3.1334726810455322 | KNN Loss: 3.022512912750244 | CLS Loss: 0.11095967143774033\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 3.0961883068084717 | KNN Loss: 3.042935848236084 | CLS Loss: 0.05325253680348396\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 3.1228086948394775 | KNN Loss: 3.0583889484405518 | CLS Loss: 0.06441965699195862\n",
      "Epoch: 010, Loss: 3.1292, Train: 0.9812, Valid: 0.9775, Best: 0.9776\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 3.105771541595459 | KNN Loss: 3.0252363681793213 | CLS Loss: 0.08053526282310486\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 3.1213901042938232 | KNN Loss: 3.028520107269287 | CLS Loss: 0.09286990016698837\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 3.123847246170044 | KNN Loss: 3.037834405899048 | CLS Loss: 0.08601287752389908\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 3.065622329711914 | KNN Loss: 2.989537477493286 | CLS Loss: 0.07608480751514435\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 3.092186689376831 | KNN Loss: 3.032565116882324 | CLS Loss: 0.05962147191166878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 3.130671977996826 | KNN Loss: 3.0627493858337402 | CLS Loss: 0.06792263686656952\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 3.185950517654419 | KNN Loss: 3.0498311519622803 | CLS Loss: 0.13611933588981628\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 3.0878138542175293 | KNN Loss: 3.0351450443267822 | CLS Loss: 0.05266888067126274\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 3.1192784309387207 | KNN Loss: 3.0429582595825195 | CLS Loss: 0.07632014155387878\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 3.143902540206909 | KNN Loss: 3.044109582901001 | CLS Loss: 0.09979291260242462\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 3.086247205734253 | KNN Loss: 3.0325021743774414 | CLS Loss: 0.053745001554489136\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 3.1076831817626953 | KNN Loss: 3.050908327102661 | CLS Loss: 0.05677477642893791\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 3.09683895111084 | KNN Loss: 3.035231590270996 | CLS Loss: 0.06160729378461838\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 3.103200912475586 | KNN Loss: 3.042318820953369 | CLS Loss: 0.06088203564286232\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 3.125432014465332 | KNN Loss: 3.040290594100952 | CLS Loss: 0.0851413905620575\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 3.0863966941833496 | KNN Loss: 3.03777813911438 | CLS Loss: 0.048618655651807785\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 3.1027348041534424 | KNN Loss: 3.0353260040283203 | CLS Loss: 0.06740870326757431\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 3.1233513355255127 | KNN Loss: 3.0580666065216064 | CLS Loss: 0.06528478860855103\n",
      "Epoch: 011, Loss: 3.1180, Train: 0.9817, Valid: 0.9779, Best: 0.9779\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 3.1092371940612793 | KNN Loss: 3.0403404235839844 | CLS Loss: 0.06889687478542328\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 3.094327926635742 | KNN Loss: 3.0294182300567627 | CLS Loss: 0.06490971148014069\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 3.1166622638702393 | KNN Loss: 3.049696207046509 | CLS Loss: 0.06696611642837524\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 3.097806930541992 | KNN Loss: 3.0588455200195312 | CLS Loss: 0.038961347192525864\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 3.089879035949707 | KNN Loss: 3.0446789264678955 | CLS Loss: 0.045200128108263016\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 3.080949306488037 | KNN Loss: 3.030864953994751 | CLS Loss: 0.05008426681160927\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 3.11370587348938 | KNN Loss: 3.064608097076416 | CLS Loss: 0.049097876995801926\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 3.1304028034210205 | KNN Loss: 3.0610034465789795 | CLS Loss: 0.06939928233623505\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 3.1176230907440186 | KNN Loss: 3.057663679122925 | CLS Loss: 0.05995950847864151\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 3.1313507556915283 | KNN Loss: 3.0433268547058105 | CLS Loss: 0.08802394568920135\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 3.113215446472168 | KNN Loss: 3.020465135574341 | CLS Loss: 0.09275030344724655\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 3.116990804672241 | KNN Loss: 3.0488414764404297 | CLS Loss: 0.06814927607774734\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 3.107658863067627 | KNN Loss: 3.0639283657073975 | CLS Loss: 0.043730586767196655\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 3.1109185218811035 | KNN Loss: 3.0299692153930664 | CLS Loss: 0.08094922453165054\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 3.126194953918457 | KNN Loss: 3.0197770595550537 | CLS Loss: 0.10641786456108093\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 3.147029161453247 | KNN Loss: 3.0754101276397705 | CLS Loss: 0.07161910831928253\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 3.1233041286468506 | KNN Loss: 3.051724672317505 | CLS Loss: 0.07157941162586212\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 3.1330466270446777 | KNN Loss: 3.0634238719940186 | CLS Loss: 0.06962273269891739\n",
      "Epoch: 012, Loss: 3.1097, Train: 0.9830, Valid: 0.9804, Best: 0.9804\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 3.1362247467041016 | KNN Loss: 3.0787084102630615 | CLS Loss: 0.05751630663871765\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 3.103656530380249 | KNN Loss: 3.0305914878845215 | CLS Loss: 0.07306493073701859\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 3.090911388397217 | KNN Loss: 3.027623414993286 | CLS Loss: 0.06328792124986649\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 3.1201772689819336 | KNN Loss: 3.0508885383605957 | CLS Loss: 0.06928863376379013\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 3.041173219680786 | KNN Loss: 2.9985084533691406 | CLS Loss: 0.04266470670700073\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 3.068826675415039 | KNN Loss: 3.001607656478882 | CLS Loss: 0.06721910089254379\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 3.0776870250701904 | KNN Loss: 3.018489122390747 | CLS Loss: 0.05919792875647545\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 3.1125872135162354 | KNN Loss: 3.0447402000427246 | CLS Loss: 0.0678471177816391\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 3.0959744453430176 | KNN Loss: 3.024531364440918 | CLS Loss: 0.07144315540790558\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 3.1208012104034424 | KNN Loss: 3.0396366119384766 | CLS Loss: 0.08116462081670761\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 3.0816802978515625 | KNN Loss: 3.0073771476745605 | CLS Loss: 0.07430307567119598\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 3.062077045440674 | KNN Loss: 3.0365586280822754 | CLS Loss: 0.02551840804517269\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 3.0910396575927734 | KNN Loss: 3.0342636108398438 | CLS Loss: 0.05677603930234909\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 3.1186723709106445 | KNN Loss: 3.0428409576416016 | CLS Loss: 0.07583144307136536\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 3.1373791694641113 | KNN Loss: 3.0312819480895996 | CLS Loss: 0.10609716176986694\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 3.067788600921631 | KNN Loss: 2.9903171062469482 | CLS Loss: 0.07747141271829605\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 3.096846342086792 | KNN Loss: 3.048754930496216 | CLS Loss: 0.048091333359479904\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 3.1010520458221436 | KNN Loss: 3.046290397644043 | CLS Loss: 0.05476169288158417\n",
      "Epoch: 013, Loss: 3.1028, Train: 0.9844, Valid: 0.9798, Best: 0.9804\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 3.105219602584839 | KNN Loss: 3.049283504486084 | CLS Loss: 0.0559360571205616\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 3.0914573669433594 | KNN Loss: 3.0502665042877197 | CLS Loss: 0.0411909818649292\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 3.096381664276123 | KNN Loss: 3.039257526397705 | CLS Loss: 0.05712402984499931\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 3.088484287261963 | KNN Loss: 3.0122084617614746 | CLS Loss: 0.0762757658958435\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 3.0938796997070312 | KNN Loss: 3.0278260707855225 | CLS Loss: 0.06605351716279984\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 3.0917272567749023 | KNN Loss: 3.0072543621063232 | CLS Loss: 0.08447282761335373\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 3.1122469902038574 | KNN Loss: 3.069779396057129 | CLS Loss: 0.042467664927244186\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 3.0827033519744873 | KNN Loss: 3.0092947483062744 | CLS Loss: 0.07340867817401886\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 3.110386848449707 | KNN Loss: 3.0388214588165283 | CLS Loss: 0.07156546413898468\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 3.059598684310913 | KNN Loss: 3.010631799697876 | CLS Loss: 0.048966847360134125\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 3.114248752593994 | KNN Loss: 3.045278549194336 | CLS Loss: 0.06897017359733582\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 3.078903913497925 | KNN Loss: 3.0399019718170166 | CLS Loss: 0.03900204598903656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 3.0749526023864746 | KNN Loss: 2.9884390830993652 | CLS Loss: 0.08651348948478699\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 3.064164638519287 | KNN Loss: 3.0101206302642822 | CLS Loss: 0.0540439635515213\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 3.1232993602752686 | KNN Loss: 3.0588908195495605 | CLS Loss: 0.06440845131874084\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 3.2020256519317627 | KNN Loss: 3.119720458984375 | CLS Loss: 0.08230522274971008\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 3.095851182937622 | KNN Loss: 3.0164060592651367 | CLS Loss: 0.07944509387016296\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 3.0927488803863525 | KNN Loss: 3.040519952774048 | CLS Loss: 0.05222897604107857\n",
      "Epoch: 014, Loss: 3.1010, Train: 0.9832, Valid: 0.9806, Best: 0.9806\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 3.084994077682495 | KNN Loss: 3.068641185760498 | CLS Loss: 0.016352981328964233\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 3.113649845123291 | KNN Loss: 3.0338423252105713 | CLS Loss: 0.07980746775865555\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 3.0729260444641113 | KNN Loss: 3.0440633296966553 | CLS Loss: 0.028862811625003815\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 3.077711343765259 | KNN Loss: 3.0395290851593018 | CLS Loss: 0.03818216919898987\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 3.0575625896453857 | KNN Loss: 3.0106894969940186 | CLS Loss: 0.046873025596141815\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 3.1867454051971436 | KNN Loss: 3.052776575088501 | CLS Loss: 0.13396881520748138\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 3.128307819366455 | KNN Loss: 3.060936689376831 | CLS Loss: 0.06737112253904343\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 3.1435372829437256 | KNN Loss: 3.0747368335723877 | CLS Loss: 0.06880044937133789\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 3.0638134479522705 | KNN Loss: 3.0308923721313477 | CLS Loss: 0.03292114660143852\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 3.0831212997436523 | KNN Loss: 3.0146515369415283 | CLS Loss: 0.06846985965967178\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 3.0864815711975098 | KNN Loss: 3.0310184955596924 | CLS Loss: 0.05546317994594574\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 3.0811026096343994 | KNN Loss: 3.012214422225952 | CLS Loss: 0.06888823211193085\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 3.1168341636657715 | KNN Loss: 3.0895330905914307 | CLS Loss: 0.027301089838147163\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 3.101755380630493 | KNN Loss: 3.052375555038452 | CLS Loss: 0.04937976226210594\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 3.0703132152557373 | KNN Loss: 3.0389721393585205 | CLS Loss: 0.031341079622507095\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 3.1006860733032227 | KNN Loss: 3.0360350608825684 | CLS Loss: 0.06465093046426773\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 3.0859601497650146 | KNN Loss: 3.0263893604278564 | CLS Loss: 0.059570759534835815\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 3.080564260482788 | KNN Loss: 3.0362966060638428 | CLS Loss: 0.044267687946558\n",
      "Epoch: 015, Loss: 3.0960, Train: 0.9842, Valid: 0.9808, Best: 0.9808\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 3.103172779083252 | KNN Loss: 3.0470030307769775 | CLS Loss: 0.05616968497633934\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 3.0798397064208984 | KNN Loss: 3.0175087451934814 | CLS Loss: 0.06233096495270729\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 3.1240389347076416 | KNN Loss: 3.0428361892700195 | CLS Loss: 0.08120264112949371\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 3.091928243637085 | KNN Loss: 3.029519557952881 | CLS Loss: 0.06240863353013992\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 3.0800678730010986 | KNN Loss: 3.043421983718872 | CLS Loss: 0.03664584085345268\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 3.0966737270355225 | KNN Loss: 2.9989373683929443 | CLS Loss: 0.09773630648851395\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 3.1076929569244385 | KNN Loss: 3.0391716957092285 | CLS Loss: 0.0685211718082428\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 3.087006092071533 | KNN Loss: 3.0115673542022705 | CLS Loss: 0.07543885707855225\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 3.047541618347168 | KNN Loss: 3.018843650817871 | CLS Loss: 0.028697961941361427\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 3.0565454959869385 | KNN Loss: 3.012624502182007 | CLS Loss: 0.043921101838350296\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 3.105475425720215 | KNN Loss: 3.039060354232788 | CLS Loss: 0.06641501933336258\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 3.125105142593384 | KNN Loss: 3.0443429946899414 | CLS Loss: 0.08076222240924835\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 3.0915560722351074 | KNN Loss: 3.0312180519104004 | CLS Loss: 0.060337942093610764\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 3.062958002090454 | KNN Loss: 2.9997308254241943 | CLS Loss: 0.06322720646858215\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 3.081555128097534 | KNN Loss: 3.032876968383789 | CLS Loss: 0.04867827519774437\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 3.1227471828460693 | KNN Loss: 3.0465071201324463 | CLS Loss: 0.0762401595711708\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 3.109182119369507 | KNN Loss: 3.073760747909546 | CLS Loss: 0.0354214645922184\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 3.1063714027404785 | KNN Loss: 3.0202739238739014 | CLS Loss: 0.0860975906252861\n",
      "Epoch: 016, Loss: 3.0882, Train: 0.9857, Valid: 0.9808, Best: 0.9808\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 3.1030595302581787 | KNN Loss: 3.0400168895721436 | CLS Loss: 0.06304262578487396\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 3.056788682937622 | KNN Loss: 2.99468994140625 | CLS Loss: 0.062098778784275055\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 3.0829169750213623 | KNN Loss: 3.0369246006011963 | CLS Loss: 0.0459924042224884\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 3.0969746112823486 | KNN Loss: 3.020597457885742 | CLS Loss: 0.07637707144021988\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 3.1064083576202393 | KNN Loss: 3.031406879425049 | CLS Loss: 0.07500142604112625\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 3.066399097442627 | KNN Loss: 3.0188846588134766 | CLS Loss: 0.047514330595731735\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 3.0566110610961914 | KNN Loss: 3.0408172607421875 | CLS Loss: 0.015793856233358383\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 3.0892491340637207 | KNN Loss: 3.014824390411377 | CLS Loss: 0.07442474365234375\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 3.0449306964874268 | KNN Loss: 2.996803045272827 | CLS Loss: 0.0481276772916317\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 3.1277172565460205 | KNN Loss: 3.0553760528564453 | CLS Loss: 0.07234125584363937\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 3.0864124298095703 | KNN Loss: 3.018326759338379 | CLS Loss: 0.06808555871248245\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 3.1168997287750244 | KNN Loss: 3.052706003189087 | CLS Loss: 0.06419361382722855\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 3.109128713607788 | KNN Loss: 3.0197341442108154 | CLS Loss: 0.0893944725394249\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 3.084961175918579 | KNN Loss: 3.0479419231414795 | CLS Loss: 0.03701921924948692\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 3.067265272140503 | KNN Loss: 3.0297484397888184 | CLS Loss: 0.03751673176884651\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 3.1037864685058594 | KNN Loss: 3.060589551925659 | CLS Loss: 0.04319687932729721\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 3.087341547012329 | KNN Loss: 3.0430212020874023 | CLS Loss: 0.04432038590312004\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 3.046189785003662 | KNN Loss: 3.0227410793304443 | CLS Loss: 0.023448606953024864\n",
      "Epoch: 017, Loss: 3.0868, Train: 0.9860, Valid: 0.9815, Best: 0.9815\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 3.0617170333862305 | KNN Loss: 3.0382332801818848 | CLS Loss: 0.023483706638216972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 3.0767881870269775 | KNN Loss: 3.0437984466552734 | CLS Loss: 0.032989781349897385\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 3.096275806427002 | KNN Loss: 3.0341508388519287 | CLS Loss: 0.062124885618686676\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 3.0932607650756836 | KNN Loss: 3.053999185562134 | CLS Loss: 0.03926166892051697\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 3.065483808517456 | KNN Loss: 3.0170743465423584 | CLS Loss: 0.048409461975097656\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 3.0908892154693604 | KNN Loss: 3.0193703174591064 | CLS Loss: 0.07151887565851212\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 3.0691111087799072 | KNN Loss: 3.0328140258789062 | CLS Loss: 0.03629716858267784\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 3.093935251235962 | KNN Loss: 3.0395166873931885 | CLS Loss: 0.054418548941612244\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 3.05326247215271 | KNN Loss: 3.00386381149292 | CLS Loss: 0.04939870908856392\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 3.098785400390625 | KNN Loss: 3.039482831954956 | CLS Loss: 0.059302669018507004\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 3.0878772735595703 | KNN Loss: 3.0476953983306885 | CLS Loss: 0.04018193855881691\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 3.0988705158233643 | KNN Loss: 3.0480878353118896 | CLS Loss: 0.050782784819602966\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 3.090134382247925 | KNN Loss: 3.023455858230591 | CLS Loss: 0.06667856127023697\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 3.078464984893799 | KNN Loss: 3.034113883972168 | CLS Loss: 0.044351134449243546\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 3.0725338459014893 | KNN Loss: 3.0185773372650146 | CLS Loss: 0.05395655706524849\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 3.027691125869751 | KNN Loss: 3.0007753372192383 | CLS Loss: 0.02691575698554516\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 3.0548274517059326 | KNN Loss: 3.0264124870300293 | CLS Loss: 0.02841491438448429\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 3.0932092666625977 | KNN Loss: 3.031947135925293 | CLS Loss: 0.06126224994659424\n",
      "Epoch: 018, Loss: 3.0870, Train: 0.9876, Valid: 0.9826, Best: 0.9826\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 3.076946973800659 | KNN Loss: 3.019329071044922 | CLS Loss: 0.05761798098683357\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 3.0705623626708984 | KNN Loss: 3.0264511108398438 | CLS Loss: 0.04411114752292633\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 3.073714017868042 | KNN Loss: 3.0358567237854004 | CLS Loss: 0.037857405841350555\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 3.080279588699341 | KNN Loss: 3.0462517738342285 | CLS Loss: 0.034027907997369766\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 3.0598363876342773 | KNN Loss: 3.0377111434936523 | CLS Loss: 0.02212516777217388\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 3.0818309783935547 | KNN Loss: 3.004951000213623 | CLS Loss: 0.07687994092702866\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 3.0458426475524902 | KNN Loss: 3.0238561630249023 | CLS Loss: 0.02198660373687744\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 3.068086862564087 | KNN Loss: 3.045832633972168 | CLS Loss: 0.02225428633391857\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 3.078467845916748 | KNN Loss: 3.0254862308502197 | CLS Loss: 0.05298151448369026\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 3.0780181884765625 | KNN Loss: 3.0327200889587402 | CLS Loss: 0.045298025012016296\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 3.07564640045166 | KNN Loss: 3.034895420074463 | CLS Loss: 0.04075109586119652\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 3.05829119682312 | KNN Loss: 3.0123772621154785 | CLS Loss: 0.045913927257061005\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 3.0738682746887207 | KNN Loss: 3.0126216411590576 | CLS Loss: 0.06124672666192055\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 3.085157632827759 | KNN Loss: 3.035196304321289 | CLS Loss: 0.0499613918364048\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 3.0868515968322754 | KNN Loss: 3.0460681915283203 | CLS Loss: 0.040783341974020004\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 3.0880560874938965 | KNN Loss: 3.035461187362671 | CLS Loss: 0.05259481817483902\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 3.0990025997161865 | KNN Loss: 3.044421911239624 | CLS Loss: 0.05458075553178787\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 3.1239967346191406 | KNN Loss: 3.0460407733917236 | CLS Loss: 0.07795608043670654\n",
      "Epoch: 019, Loss: 3.0824, Train: 0.9882, Valid: 0.9834, Best: 0.9834\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 3.0971736907958984 | KNN Loss: 3.0531976222991943 | CLS Loss: 0.0439760722219944\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 3.120574474334717 | KNN Loss: 3.032320261001587 | CLS Loss: 0.08825422078371048\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 3.053396224975586 | KNN Loss: 3.0029726028442383 | CLS Loss: 0.05042373389005661\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 3.0596723556518555 | KNN Loss: 3.008068561553955 | CLS Loss: 0.0516037791967392\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 3.1106996536254883 | KNN Loss: 3.033149242401123 | CLS Loss: 0.07755051553249359\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 3.046542167663574 | KNN Loss: 3.0163650512695312 | CLS Loss: 0.03017713874578476\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 3.084533214569092 | KNN Loss: 3.0430748462677 | CLS Loss: 0.04145846515893936\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 3.0961668491363525 | KNN Loss: 3.0585057735443115 | CLS Loss: 0.03766102343797684\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 3.0293679237365723 | KNN Loss: 2.9828009605407715 | CLS Loss: 0.04656696692109108\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 3.069552421569824 | KNN Loss: 3.025930404663086 | CLS Loss: 0.04362212494015694\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 3.0797784328460693 | KNN Loss: 3.013589382171631 | CLS Loss: 0.06618910282850266\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 3.0607011318206787 | KNN Loss: 3.0260324478149414 | CLS Loss: 0.03466857969760895\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 3.081796646118164 | KNN Loss: 3.036039113998413 | CLS Loss: 0.04575752466917038\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 3.039794683456421 | KNN Loss: 3.0143439769744873 | CLS Loss: 0.025450795888900757\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 3.0901527404785156 | KNN Loss: 3.0509989261627197 | CLS Loss: 0.0391538068652153\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 3.1064939498901367 | KNN Loss: 3.068082571029663 | CLS Loss: 0.038411304354667664\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 3.0564441680908203 | KNN Loss: 3.0193610191345215 | CLS Loss: 0.037083081901073456\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 3.0925159454345703 | KNN Loss: 3.054967164993286 | CLS Loss: 0.03754870966076851\n",
      "Epoch: 020, Loss: 3.0811, Train: 0.9858, Valid: 0.9819, Best: 0.9834\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 3.1149327754974365 | KNN Loss: 3.0471742153167725 | CLS Loss: 0.06775854527950287\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 3.0733397006988525 | KNN Loss: 3.0425496101379395 | CLS Loss: 0.030790109187364578\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 3.1515777111053467 | KNN Loss: 3.0822529792785645 | CLS Loss: 0.06932467967271805\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 3.1045081615448 | KNN Loss: 3.0688440799713135 | CLS Loss: 0.03566401079297066\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 3.066124200820923 | KNN Loss: 3.022984027862549 | CLS Loss: 0.043140169233083725\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 3.100374698638916 | KNN Loss: 3.0604608058929443 | CLS Loss: 0.039913780987262726\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 3.0503768920898438 | KNN Loss: 3.007955312728882 | CLS Loss: 0.042421646416187286\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 3.0942063331604004 | KNN Loss: 3.0422186851501465 | CLS Loss: 0.051987748593091965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 3.122095823287964 | KNN Loss: 3.0830843448638916 | CLS Loss: 0.03901158273220062\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 3.1017069816589355 | KNN Loss: 3.062173366546631 | CLS Loss: 0.03953363746404648\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 3.0794382095336914 | KNN Loss: 3.034637451171875 | CLS Loss: 0.044800758361816406\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 3.1042065620422363 | KNN Loss: 3.0651865005493164 | CLS Loss: 0.03902009502053261\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 3.08304762840271 | KNN Loss: 3.026240110397339 | CLS Loss: 0.056807611137628555\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 3.0790364742279053 | KNN Loss: 3.0486650466918945 | CLS Loss: 0.0303714070469141\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 3.102686882019043 | KNN Loss: 3.0604677200317383 | CLS Loss: 0.04221905395388603\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 3.101654052734375 | KNN Loss: 3.058877468109131 | CLS Loss: 0.04277648776769638\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 3.098707437515259 | KNN Loss: 3.0528085231781006 | CLS Loss: 0.045898910611867905\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 3.0827510356903076 | KNN Loss: 3.044341802597046 | CLS Loss: 0.038409274071455\n",
      "Epoch: 021, Loss: 3.0928, Train: 0.9879, Valid: 0.9833, Best: 0.9834\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 3.065753221511841 | KNN Loss: 3.0462965965270996 | CLS Loss: 0.019456716254353523\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 3.0866384506225586 | KNN Loss: 3.0675926208496094 | CLS Loss: 0.019045893102884293\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 3.071506977081299 | KNN Loss: 3.0290162563323975 | CLS Loss: 0.04249075427651405\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 3.0770809650421143 | KNN Loss: 3.0372045040130615 | CLS Loss: 0.03987642005085945\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 3.0612688064575195 | KNN Loss: 3.0161526203155518 | CLS Loss: 0.04511616751551628\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 3.079136848449707 | KNN Loss: 3.0469791889190674 | CLS Loss: 0.03215771168470383\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 3.1310532093048096 | KNN Loss: 3.0497138500213623 | CLS Loss: 0.08133934438228607\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 3.0784785747528076 | KNN Loss: 3.043818950653076 | CLS Loss: 0.03465951606631279\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 3.074786424636841 | KNN Loss: 3.024442195892334 | CLS Loss: 0.050344306975603104\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 3.0548789501190186 | KNN Loss: 3.019901990890503 | CLS Loss: 0.03497684746980667\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 3.100431203842163 | KNN Loss: 3.0411322116851807 | CLS Loss: 0.059298980981111526\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 3.082841396331787 | KNN Loss: 3.031419277191162 | CLS Loss: 0.051422011107206345\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 3.1265711784362793 | KNN Loss: 3.0620734691619873 | CLS Loss: 0.06449779123067856\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 3.115701198577881 | KNN Loss: 3.086097478866577 | CLS Loss: 0.029603654518723488\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 3.0787789821624756 | KNN Loss: 3.055835008621216 | CLS Loss: 0.022943979129195213\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 3.0803542137145996 | KNN Loss: 3.034780979156494 | CLS Loss: 0.04557313397526741\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 3.1241400241851807 | KNN Loss: 3.0719141960144043 | CLS Loss: 0.052225831896066666\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 3.1037988662719727 | KNN Loss: 3.054542064666748 | CLS Loss: 0.049256812781095505\n",
      "Epoch: 022, Loss: 3.0890, Train: 0.9884, Valid: 0.9828, Best: 0.9834\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 3.0836963653564453 | KNN Loss: 3.0352542400360107 | CLS Loss: 0.04844213277101517\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 3.090031385421753 | KNN Loss: 3.0378365516662598 | CLS Loss: 0.05219482257962227\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 3.1060259342193604 | KNN Loss: 3.0371129512786865 | CLS Loss: 0.0689130499958992\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 3.084968328475952 | KNN Loss: 3.0336575508117676 | CLS Loss: 0.05131079629063606\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 3.07619047164917 | KNN Loss: 3.0384421348571777 | CLS Loss: 0.03774835169315338\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 3.1035149097442627 | KNN Loss: 3.0491271018981934 | CLS Loss: 0.05438773334026337\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 3.0999035835266113 | KNN Loss: 3.0562798976898193 | CLS Loss: 0.043623775243759155\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 3.087960958480835 | KNN Loss: 3.038472890853882 | CLS Loss: 0.04948802292346954\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 3.1042256355285645 | KNN Loss: 3.0665640830993652 | CLS Loss: 0.037661612033843994\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 3.071798801422119 | KNN Loss: 3.02899432182312 | CLS Loss: 0.04280455410480499\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 3.088059186935425 | KNN Loss: 3.0350842475891113 | CLS Loss: 0.05297483876347542\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 3.0637869834899902 | KNN Loss: 3.042872428894043 | CLS Loss: 0.020914478227496147\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 3.065683603286743 | KNN Loss: 3.0065176486968994 | CLS Loss: 0.059166017919778824\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 3.091048002243042 | KNN Loss: 3.026073932647705 | CLS Loss: 0.06497413665056229\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 3.083099603652954 | KNN Loss: 3.049325466156006 | CLS Loss: 0.033774204552173615\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 3.066744804382324 | KNN Loss: 3.039874792098999 | CLS Loss: 0.026870112866163254\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 3.051621437072754 | KNN Loss: 3.0247700214385986 | CLS Loss: 0.026851480826735497\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 3.0585403442382812 | KNN Loss: 3.030958414077759 | CLS Loss: 0.02758193388581276\n",
      "Epoch: 023, Loss: 3.0867, Train: 0.9879, Valid: 0.9829, Best: 0.9834\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 3.0890040397644043 | KNN Loss: 3.039496898651123 | CLS Loss: 0.04950719699263573\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 3.045835256576538 | KNN Loss: 3.0168046951293945 | CLS Loss: 0.029030518606305122\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 3.0756306648254395 | KNN Loss: 3.0280375480651855 | CLS Loss: 0.04759304225444794\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 3.0606226921081543 | KNN Loss: 3.0207326412200928 | CLS Loss: 0.03989003598690033\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 3.063112497329712 | KNN Loss: 3.009948253631592 | CLS Loss: 0.05316421389579773\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 3.0480659008026123 | KNN Loss: 3.0170392990112305 | CLS Loss: 0.031026532873511314\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 3.0860133171081543 | KNN Loss: 3.0120792388916016 | CLS Loss: 0.07393419742584229\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 3.0703089237213135 | KNN Loss: 3.0523948669433594 | CLS Loss: 0.017914045602083206\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 3.073023557662964 | KNN Loss: 3.0378010272979736 | CLS Loss: 0.03522254899144173\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 3.087110757827759 | KNN Loss: 3.066037178039551 | CLS Loss: 0.021073590964078903\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 3.068772315979004 | KNN Loss: 3.0269906520843506 | CLS Loss: 0.041781723499298096\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 3.0534470081329346 | KNN Loss: 3.0188510417938232 | CLS Loss: 0.034595973789691925\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 3.1008002758026123 | KNN Loss: 3.0497944355010986 | CLS Loss: 0.05100585147738457\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 3.0834596157073975 | KNN Loss: 3.027952194213867 | CLS Loss: 0.05550742149353027\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 3.112417221069336 | KNN Loss: 3.0309159755706787 | CLS Loss: 0.08150136470794678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 3.1193597316741943 | KNN Loss: 3.0528275966644287 | CLS Loss: 0.0665321946144104\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 3.0882351398468018 | KNN Loss: 3.049344301223755 | CLS Loss: 0.038890860974788666\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 3.0932209491729736 | KNN Loss: 3.0585403442382812 | CLS Loss: 0.03468066081404686\n",
      "Epoch: 024, Loss: 3.0838, Train: 0.9872, Valid: 0.9813, Best: 0.9834\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 3.0578863620758057 | KNN Loss: 3.0292866230010986 | CLS Loss: 0.028599683195352554\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 3.1232593059539795 | KNN Loss: 3.0471243858337402 | CLS Loss: 0.0761348083615303\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 3.058932065963745 | KNN Loss: 3.0318615436553955 | CLS Loss: 0.02707044780254364\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 3.0941250324249268 | KNN Loss: 3.0421202182769775 | CLS Loss: 0.052004843950271606\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 3.0659451484680176 | KNN Loss: 3.04036808013916 | CLS Loss: 0.025577081367373466\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 3.081432819366455 | KNN Loss: 3.0515644550323486 | CLS Loss: 0.029868269339203835\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 3.0839855670928955 | KNN Loss: 3.0225019454956055 | CLS Loss: 0.06148366630077362\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 3.0890729427337646 | KNN Loss: 3.065141439437866 | CLS Loss: 0.02393156848847866\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 3.0729734897613525 | KNN Loss: 3.0471370220184326 | CLS Loss: 0.025836555287241936\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 3.0898165702819824 | KNN Loss: 3.0567786693573 | CLS Loss: 0.03303796797990799\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 3.1357243061065674 | KNN Loss: 3.0750834941864014 | CLS Loss: 0.06064087897539139\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 3.095369338989258 | KNN Loss: 3.0550243854522705 | CLS Loss: 0.04034501314163208\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 3.0900089740753174 | KNN Loss: 3.033247470855713 | CLS Loss: 0.056761547923088074\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 3.052664041519165 | KNN Loss: 3.013460159301758 | CLS Loss: 0.039203938096761703\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 3.0786941051483154 | KNN Loss: 3.047086715698242 | CLS Loss: 0.03160734102129936\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 3.0798380374908447 | KNN Loss: 3.0566036701202393 | CLS Loss: 0.023234382271766663\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 3.064131498336792 | KNN Loss: 3.0257976055145264 | CLS Loss: 0.038333792239427567\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 3.113814353942871 | KNN Loss: 3.052744150161743 | CLS Loss: 0.061070192605257034\n",
      "Epoch: 025, Loss: 3.0815, Train: 0.9887, Valid: 0.9821, Best: 0.9834\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 3.065504312515259 | KNN Loss: 3.034467935562134 | CLS Loss: 0.031036382541060448\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 3.057616710662842 | KNN Loss: 3.012939453125 | CLS Loss: 0.0446772538125515\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 3.0352516174316406 | KNN Loss: 2.995124340057373 | CLS Loss: 0.04012737050652504\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 3.075113534927368 | KNN Loss: 3.0417158603668213 | CLS Loss: 0.03339764475822449\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 3.082948923110962 | KNN Loss: 3.0372860431671143 | CLS Loss: 0.04566286504268646\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 3.103358268737793 | KNN Loss: 3.0702567100524902 | CLS Loss: 0.033101506531238556\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 3.1012983322143555 | KNN Loss: 3.0560173988342285 | CLS Loss: 0.04528095945715904\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 3.0548312664031982 | KNN Loss: 3.0178682804107666 | CLS Loss: 0.036963049322366714\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 3.0966546535491943 | KNN Loss: 3.069673538208008 | CLS Loss: 0.026981042698025703\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 3.0742199420928955 | KNN Loss: 3.0201425552368164 | CLS Loss: 0.05407739803195\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 3.09944486618042 | KNN Loss: 3.0551979541778564 | CLS Loss: 0.0442468635737896\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 3.072282552719116 | KNN Loss: 3.0191664695739746 | CLS Loss: 0.0531160794198513\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 3.101647138595581 | KNN Loss: 3.0341336727142334 | CLS Loss: 0.0675133690237999\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 3.0400168895721436 | KNN Loss: 3.02327036857605 | CLS Loss: 0.01674654893577099\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 3.0712883472442627 | KNN Loss: 3.0355775356292725 | CLS Loss: 0.03571072220802307\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 3.0639588832855225 | KNN Loss: 3.025132417678833 | CLS Loss: 0.03882636874914169\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 3.07759690284729 | KNN Loss: 3.0374810695648193 | CLS Loss: 0.040115851908922195\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 3.081780433654785 | KNN Loss: 3.020630121231079 | CLS Loss: 0.06115031987428665\n",
      "Epoch: 026, Loss: 3.0790, Train: 0.9906, Valid: 0.9855, Best: 0.9855\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 3.0407047271728516 | KNN Loss: 3.0221221446990967 | CLS Loss: 0.018582476302981377\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 3.0922188758850098 | KNN Loss: 3.0511295795440674 | CLS Loss: 0.04108939692378044\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 3.121856927871704 | KNN Loss: 3.0965867042541504 | CLS Loss: 0.02527022548019886\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 3.046863079071045 | KNN Loss: 3.0241856575012207 | CLS Loss: 0.022677449509501457\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 3.0526702404022217 | KNN Loss: 3.0015993118286133 | CLS Loss: 0.0510709211230278\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 3.108797311782837 | KNN Loss: 3.049213171005249 | CLS Loss: 0.059584084898233414\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 3.074151039123535 | KNN Loss: 3.0506110191345215 | CLS Loss: 0.02354002743959427\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 3.0833723545074463 | KNN Loss: 3.0583691596984863 | CLS Loss: 0.02500329539179802\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 3.036914587020874 | KNN Loss: 3.003157615661621 | CLS Loss: 0.03375706449151039\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 3.0682084560394287 | KNN Loss: 3.0425281524658203 | CLS Loss: 0.02568037249147892\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 3.0494797229766846 | KNN Loss: 3.028981924057007 | CLS Loss: 0.020497886463999748\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 3.087315797805786 | KNN Loss: 3.0487518310546875 | CLS Loss: 0.03856406360864639\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 3.1156675815582275 | KNN Loss: 3.077343463897705 | CLS Loss: 0.03832417353987694\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 3.061647891998291 | KNN Loss: 3.012787342071533 | CLS Loss: 0.04886055365204811\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 3.0847740173339844 | KNN Loss: 3.0137650966644287 | CLS Loss: 0.07100886851549149\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 3.020271062850952 | KNN Loss: 2.986816883087158 | CLS Loss: 0.03345423936843872\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 3.0880701541900635 | KNN Loss: 3.028812885284424 | CLS Loss: 0.05925736948847771\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 3.037376880645752 | KNN Loss: 3.015730619430542 | CLS Loss: 0.021646277979016304\n",
      "Epoch: 027, Loss: 3.0738, Train: 0.9897, Valid: 0.9832, Best: 0.9855\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 3.068675994873047 | KNN Loss: 3.0191569328308105 | CLS Loss: 0.04951908439397812\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 3.058120012283325 | KNN Loss: 3.0334625244140625 | CLS Loss: 0.02465755119919777\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 3.0492889881134033 | KNN Loss: 2.995629072189331 | CLS Loss: 0.05366000905632973\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 3.042949914932251 | KNN Loss: 3.0313706398010254 | CLS Loss: 0.011579356156289577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 3.0628809928894043 | KNN Loss: 3.0260109901428223 | CLS Loss: 0.036869898438453674\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 3.0731210708618164 | KNN Loss: 3.0232818126678467 | CLS Loss: 0.049839284271001816\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 3.1361403465270996 | KNN Loss: 3.0624918937683105 | CLS Loss: 0.07364853471517563\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 3.044420003890991 | KNN Loss: 3.0236783027648926 | CLS Loss: 0.020741663873195648\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 3.0636415481567383 | KNN Loss: 3.033003330230713 | CLS Loss: 0.030638156458735466\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 3.0811164379119873 | KNN Loss: 3.052544116973877 | CLS Loss: 0.028572436422109604\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 3.0675675868988037 | KNN Loss: 3.023331880569458 | CLS Loss: 0.04423559457063675\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 3.0429530143737793 | KNN Loss: 3.0154199600219727 | CLS Loss: 0.027533115819096565\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 3.055302143096924 | KNN Loss: 3.026519775390625 | CLS Loss: 0.028782248497009277\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 3.048207998275757 | KNN Loss: 3.0241332054138184 | CLS Loss: 0.02407483570277691\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 3.046535015106201 | KNN Loss: 3.0294768810272217 | CLS Loss: 0.017058219760656357\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 3.0975561141967773 | KNN Loss: 3.04245662689209 | CLS Loss: 0.05509952828288078\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 3.100053310394287 | KNN Loss: 3.0366175174713135 | CLS Loss: 0.06343582272529602\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 3.1066513061523438 | KNN Loss: 3.048478364944458 | CLS Loss: 0.058173052966594696\n",
      "Epoch: 028, Loss: 3.0745, Train: 0.9885, Valid: 0.9825, Best: 0.9855\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 3.101029396057129 | KNN Loss: 3.032381057739258 | CLS Loss: 0.06864845007658005\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 3.1007018089294434 | KNN Loss: 3.052351474761963 | CLS Loss: 0.0483502559363842\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 3.0809593200683594 | KNN Loss: 3.0406696796417236 | CLS Loss: 0.04028971120715141\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 3.0704305171966553 | KNN Loss: 3.043735980987549 | CLS Loss: 0.02669462375342846\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 3.0931572914123535 | KNN Loss: 3.044976234436035 | CLS Loss: 0.04818112030625343\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 3.0737380981445312 | KNN Loss: 3.034126043319702 | CLS Loss: 0.03961201384663582\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 3.1256470680236816 | KNN Loss: 3.057398557662964 | CLS Loss: 0.06824842840433121\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 3.13016414642334 | KNN Loss: 3.102534532546997 | CLS Loss: 0.027629535645246506\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 3.1209611892700195 | KNN Loss: 3.037381410598755 | CLS Loss: 0.0835798978805542\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 3.035234212875366 | KNN Loss: 3.0136301517486572 | CLS Loss: 0.02160395309329033\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 3.1350045204162598 | KNN Loss: 3.084341049194336 | CLS Loss: 0.050663385540246964\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 3.056041955947876 | KNN Loss: 3.038684844970703 | CLS Loss: 0.01735704205930233\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 3.090528964996338 | KNN Loss: 3.0527567863464355 | CLS Loss: 0.037772245705127716\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 3.0442352294921875 | KNN Loss: 3.015363931655884 | CLS Loss: 0.028871413320302963\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 3.0747339725494385 | KNN Loss: 3.0483624935150146 | CLS Loss: 0.026371445506811142\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 3.0742483139038086 | KNN Loss: 3.0349462032318115 | CLS Loss: 0.03930201008915901\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 3.065908670425415 | KNN Loss: 3.0362370014190674 | CLS Loss: 0.029671685770154\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 3.0540707111358643 | KNN Loss: 3.004180431365967 | CLS Loss: 0.049890290945768356\n",
      "Epoch: 029, Loss: 3.0738, Train: 0.9900, Valid: 0.9847, Best: 0.9855\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 3.0524001121520996 | KNN Loss: 3.0331404209136963 | CLS Loss: 0.019259696826338768\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 3.074070930480957 | KNN Loss: 3.0362296104431152 | CLS Loss: 0.0378413088619709\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 3.0635271072387695 | KNN Loss: 3.023797035217285 | CLS Loss: 0.03973007947206497\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 3.0813193321228027 | KNN Loss: 3.039916753768921 | CLS Loss: 0.04140253737568855\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 3.0790836811065674 | KNN Loss: 3.050468683242798 | CLS Loss: 0.028615068644285202\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 3.059438943862915 | KNN Loss: 3.034933567047119 | CLS Loss: 0.02450527995824814\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 3.0650553703308105 | KNN Loss: 3.0288727283477783 | CLS Loss: 0.036182645708322525\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 3.092865467071533 | KNN Loss: 3.0470964908599854 | CLS Loss: 0.045768968760967255\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 3.0594077110290527 | KNN Loss: 3.0288352966308594 | CLS Loss: 0.030572466552257538\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 3.040904998779297 | KNN Loss: 3.0189766883850098 | CLS Loss: 0.021928338333964348\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 3.0616660118103027 | KNN Loss: 3.009014129638672 | CLS Loss: 0.05265187472105026\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 3.07254958152771 | KNN Loss: 3.0306248664855957 | CLS Loss: 0.04192478582262993\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 3.1054205894470215 | KNN Loss: 3.064789056777954 | CLS Loss: 0.04063156992197037\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 3.0667965412139893 | KNN Loss: 3.0271763801574707 | CLS Loss: 0.03962023928761482\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 3.048790693283081 | KNN Loss: 3.0153748989105225 | CLS Loss: 0.03341582790017128\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 3.0643362998962402 | KNN Loss: 3.023597240447998 | CLS Loss: 0.04073915258049965\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 3.0758719444274902 | KNN Loss: 3.031002998352051 | CLS Loss: 0.04486900568008423\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 3.109832286834717 | KNN Loss: 3.065136671066284 | CLS Loss: 0.04469560459256172\n",
      "Epoch: 030, Loss: 3.0717, Train: 0.9916, Valid: 0.9855, Best: 0.9855\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 3.05136775970459 | KNN Loss: 3.0326662063598633 | CLS Loss: 0.018701516091823578\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 3.064487934112549 | KNN Loss: 3.0340588092803955 | CLS Loss: 0.03042917512357235\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 3.046534776687622 | KNN Loss: 3.0090060234069824 | CLS Loss: 0.03752884268760681\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 3.0958361625671387 | KNN Loss: 3.0510175228118896 | CLS Loss: 0.04481864348053932\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 3.0894227027893066 | KNN Loss: 3.0529470443725586 | CLS Loss: 0.03647560998797417\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 3.0858442783355713 | KNN Loss: 3.0517499446868896 | CLS Loss: 0.03409435227513313\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 3.112417697906494 | KNN Loss: 3.084348678588867 | CLS Loss: 0.02806895785033703\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 3.0260469913482666 | KNN Loss: 3.0042126178741455 | CLS Loss: 0.021834343671798706\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 3.0655858516693115 | KNN Loss: 3.02862286567688 | CLS Loss: 0.03696305677294731\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 3.0710818767547607 | KNN Loss: 3.040843963623047 | CLS Loss: 0.03023798204958439\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 3.0354321002960205 | KNN Loss: 2.9951488971710205 | CLS Loss: 0.040283095091581345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 3.077326536178589 | KNN Loss: 3.043952703475952 | CLS Loss: 0.03337394818663597\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 3.0239179134368896 | KNN Loss: 3.0152881145477295 | CLS Loss: 0.008629754185676575\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 3.0556178092956543 | KNN Loss: 3.0303359031677246 | CLS Loss: 0.025281798094511032\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 3.118743658065796 | KNN Loss: 3.040374994277954 | CLS Loss: 0.0783686414361\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 3.041203498840332 | KNN Loss: 3.009995222091675 | CLS Loss: 0.031208310276269913\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 3.073951244354248 | KNN Loss: 3.0235228538513184 | CLS Loss: 0.05042850971221924\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 3.0446395874023438 | KNN Loss: 3.0161476135253906 | CLS Loss: 0.0284919124096632\n",
      "Epoch: 031, Loss: 3.0694, Train: 0.9906, Valid: 0.9837, Best: 0.9855\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 3.0596439838409424 | KNN Loss: 3.0293221473693848 | CLS Loss: 0.030321748927235603\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 3.116384744644165 | KNN Loss: 3.0708532333374023 | CLS Loss: 0.04553139954805374\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 3.044207811355591 | KNN Loss: 2.9923152923583984 | CLS Loss: 0.05189250782132149\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 3.0423495769500732 | KNN Loss: 3.009568691253662 | CLS Loss: 0.03278077393770218\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 3.048705816268921 | KNN Loss: 3.005403757095337 | CLS Loss: 0.04330213740468025\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 3.060532331466675 | KNN Loss: 3.01928973197937 | CLS Loss: 0.04124259948730469\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 3.063917398452759 | KNN Loss: 3.0198416709899902 | CLS Loss: 0.04407569766044617\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 3.079986572265625 | KNN Loss: 3.0301198959350586 | CLS Loss: 0.04986665025353432\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 3.0557847023010254 | KNN Loss: 3.016273260116577 | CLS Loss: 0.03951149433851242\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 3.094406843185425 | KNN Loss: 3.0373544692993164 | CLS Loss: 0.05705232545733452\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 3.064525604248047 | KNN Loss: 3.0116231441497803 | CLS Loss: 0.05290251597762108\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 3.07088565826416 | KNN Loss: 3.0579352378845215 | CLS Loss: 0.012950537726283073\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 3.0840566158294678 | KNN Loss: 3.0450072288513184 | CLS Loss: 0.03904944658279419\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 3.096867561340332 | KNN Loss: 3.045644998550415 | CLS Loss: 0.05122259631752968\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 3.0641212463378906 | KNN Loss: 2.993025779724121 | CLS Loss: 0.07109534740447998\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 3.0584068298339844 | KNN Loss: 3.032707452774048 | CLS Loss: 0.025699276477098465\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 3.1066441535949707 | KNN Loss: 3.0597548484802246 | CLS Loss: 0.04688934609293938\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 3.065692901611328 | KNN Loss: 3.0463943481445312 | CLS Loss: 0.01929861307144165\n",
      "Epoch: 032, Loss: 3.0687, Train: 0.9921, Valid: 0.9854, Best: 0.9855\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 3.0582520961761475 | KNN Loss: 3.030012369155884 | CLS Loss: 0.02823961339890957\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 3.0584323406219482 | KNN Loss: 3.030130624771118 | CLS Loss: 0.028301680460572243\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 3.021458387374878 | KNN Loss: 2.9983279705047607 | CLS Loss: 0.023130446672439575\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 3.0420215129852295 | KNN Loss: 3.01523494720459 | CLS Loss: 0.026786668226122856\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 3.097368001937866 | KNN Loss: 3.0452325344085693 | CLS Loss: 0.0521354153752327\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 3.0642502307891846 | KNN Loss: 3.0358939170837402 | CLS Loss: 0.02835630066692829\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 3.0650601387023926 | KNN Loss: 3.04317569732666 | CLS Loss: 0.021884402260184288\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 3.034372568130493 | KNN Loss: 3.0089545249938965 | CLS Loss: 0.02541794255375862\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 3.027282953262329 | KNN Loss: 3.0074069499969482 | CLS Loss: 0.019876064732670784\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 3.0640974044799805 | KNN Loss: 3.0328876972198486 | CLS Loss: 0.031209688633680344\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 3.058598279953003 | KNN Loss: 3.038878917694092 | CLS Loss: 0.019719257950782776\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 3.068669080734253 | KNN Loss: 3.0248749256134033 | CLS Loss: 0.043794117867946625\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 3.128467321395874 | KNN Loss: 3.085537910461426 | CLS Loss: 0.04292938485741615\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 3.039841651916504 | KNN Loss: 3.009559392929077 | CLS Loss: 0.030282313004136086\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 3.0286645889282227 | KNN Loss: 3.0150415897369385 | CLS Loss: 0.013622947968542576\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 3.0688109397888184 | KNN Loss: 3.034294366836548 | CLS Loss: 0.034516528248786926\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 3.0401506423950195 | KNN Loss: 3.0171892642974854 | CLS Loss: 0.02296130359172821\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 3.072650194168091 | KNN Loss: 3.0436654090881348 | CLS Loss: 0.028984755277633667\n",
      "Epoch: 033, Loss: 3.0627, Train: 0.9919, Valid: 0.9852, Best: 0.9855\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 3.047476053237915 | KNN Loss: 3.004625082015991 | CLS Loss: 0.04285086318850517\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 3.064039468765259 | KNN Loss: 3.0207648277282715 | CLS Loss: 0.04327469319105148\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 3.06364369392395 | KNN Loss: 3.0408051013946533 | CLS Loss: 0.022838568314909935\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 3.0695178508758545 | KNN Loss: 3.0311920642852783 | CLS Loss: 0.03832574933767319\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 3.052644729614258 | KNN Loss: 3.0179007053375244 | CLS Loss: 0.03474408760666847\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 3.0434765815734863 | KNN Loss: 3.0268056392669678 | CLS Loss: 0.01667090132832527\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 3.1091768741607666 | KNN Loss: 3.0546863079071045 | CLS Loss: 0.054490625858306885\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 3.1172711849212646 | KNN Loss: 3.0519561767578125 | CLS Loss: 0.06531493365764618\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 3.104753017425537 | KNN Loss: 3.0583431720733643 | CLS Loss: 0.04640992730855942\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 3.036942958831787 | KNN Loss: 3.0226705074310303 | CLS Loss: 0.014272402040660381\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 3.114989995956421 | KNN Loss: 3.0507090091705322 | CLS Loss: 0.06428107619285583\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 3.111250877380371 | KNN Loss: 3.064175605773926 | CLS Loss: 0.04707515984773636\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 3.122860908508301 | KNN Loss: 3.0832502841949463 | CLS Loss: 0.039610687643289566\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 3.0651028156280518 | KNN Loss: 3.036691427230835 | CLS Loss: 0.02841145172715187\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 3.061753034591675 | KNN Loss: 3.029514789581299 | CLS Loss: 0.03223824128508568\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 3.0836806297302246 | KNN Loss: 3.063699245452881 | CLS Loss: 0.01998148299753666\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 3.031522512435913 | KNN Loss: 3.002530813217163 | CLS Loss: 0.028991742059588432\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 3.1080210208892822 | KNN Loss: 3.05623459815979 | CLS Loss: 0.05178649351000786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 3.0667, Train: 0.9914, Valid: 0.9848, Best: 0.9855\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 3.0662121772766113 | KNN Loss: 3.0217669010162354 | CLS Loss: 0.04444516450166702\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 3.057434320449829 | KNN Loss: 3.0277421474456787 | CLS Loss: 0.02969209849834442\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 3.105956792831421 | KNN Loss: 3.0287537574768066 | CLS Loss: 0.07720306515693665\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 3.0673296451568604 | KNN Loss: 3.013756036758423 | CLS Loss: 0.0535736046731472\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 3.0966765880584717 | KNN Loss: 3.0470833778381348 | CLS Loss: 0.049593228846788406\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 3.0387303829193115 | KNN Loss: 3.026477098464966 | CLS Loss: 0.01225337851792574\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 3.0685648918151855 | KNN Loss: 3.0463814735412598 | CLS Loss: 0.022183511406183243\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 3.0840272903442383 | KNN Loss: 3.0478968620300293 | CLS Loss: 0.03613043576478958\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 3.0186493396759033 | KNN Loss: 2.987302303314209 | CLS Loss: 0.03134703263640404\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 3.023345708847046 | KNN Loss: 2.9989802837371826 | CLS Loss: 0.024365536868572235\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 3.042524814605713 | KNN Loss: 3.0010905265808105 | CLS Loss: 0.04143436625599861\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 3.103018045425415 | KNN Loss: 3.054199695587158 | CLS Loss: 0.0488184317946434\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 3.0413694381713867 | KNN Loss: 3.0216615200042725 | CLS Loss: 0.01970803365111351\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 3.080986499786377 | KNN Loss: 3.0144054889678955 | CLS Loss: 0.06658109277486801\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 3.057934284210205 | KNN Loss: 3.042006731033325 | CLS Loss: 0.015927499160170555\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 3.0579006671905518 | KNN Loss: 3.0355074405670166 | CLS Loss: 0.022393157705664635\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 3.033733367919922 | KNN Loss: 3.0138907432556152 | CLS Loss: 0.019842542707920074\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 3.0567433834075928 | KNN Loss: 3.0203757286071777 | CLS Loss: 0.036367595195770264\n",
      "Epoch: 035, Loss: 3.0632, Train: 0.9927, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 3.0437865257263184 | KNN Loss: 3.0340490341186523 | CLS Loss: 0.009737486951053143\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 3.0293824672698975 | KNN Loss: 3.0066592693328857 | CLS Loss: 0.02272311970591545\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 3.0770061016082764 | KNN Loss: 3.03216552734375 | CLS Loss: 0.04484046623110771\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 3.0847971439361572 | KNN Loss: 3.030087471008301 | CLS Loss: 0.054709646850824356\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 3.0463950634002686 | KNN Loss: 3.014172077178955 | CLS Loss: 0.03222299739718437\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 3.0541369915008545 | KNN Loss: 3.033599853515625 | CLS Loss: 0.02053721435368061\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 3.0477373600006104 | KNN Loss: 3.0320844650268555 | CLS Loss: 0.015652846544981003\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 3.0837740898132324 | KNN Loss: 3.0546514987945557 | CLS Loss: 0.029122505336999893\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 3.086442470550537 | KNN Loss: 3.0528368949890137 | CLS Loss: 0.03360554575920105\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 3.123265266418457 | KNN Loss: 3.1051900386810303 | CLS Loss: 0.0180751234292984\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 3.149718761444092 | KNN Loss: 3.1161866188049316 | CLS Loss: 0.0335320346057415\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 3.0812723636627197 | KNN Loss: 3.0683865547180176 | CLS Loss: 0.012885771691799164\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 3.0558784008026123 | KNN Loss: 3.0443549156188965 | CLS Loss: 0.011523399502038956\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 3.0855824947357178 | KNN Loss: 3.0533299446105957 | CLS Loss: 0.03225255757570267\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 3.047093152999878 | KNN Loss: 3.0259311199188232 | CLS Loss: 0.021162008866667747\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 3.0917251110076904 | KNN Loss: 3.0459144115448 | CLS Loss: 0.04581073299050331\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 3.0761072635650635 | KNN Loss: 3.0501372814178467 | CLS Loss: 0.02597007155418396\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 3.0518758296966553 | KNN Loss: 3.025893211364746 | CLS Loss: 0.025982579216361046\n",
      "Epoch: 036, Loss: 3.0754, Train: 0.9915, Valid: 0.9851, Best: 0.9861\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 3.120347738265991 | KNN Loss: 3.0644538402557373 | CLS Loss: 0.055893853306770325\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 3.0726711750030518 | KNN Loss: 3.0421271324157715 | CLS Loss: 0.03054407797753811\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 3.115701913833618 | KNN Loss: 3.075134515762329 | CLS Loss: 0.040567442774772644\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 3.083822011947632 | KNN Loss: 3.071481704711914 | CLS Loss: 0.01234025415033102\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 3.0640156269073486 | KNN Loss: 3.036616325378418 | CLS Loss: 0.027399368584156036\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 3.095062017440796 | KNN Loss: 3.0663211345672607 | CLS Loss: 0.0287408959120512\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 3.078507423400879 | KNN Loss: 3.016676664352417 | CLS Loss: 0.061830874532461166\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 3.055434465408325 | KNN Loss: 3.0259361267089844 | CLS Loss: 0.029498282819986343\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 3.1235432624816895 | KNN Loss: 3.087029218673706 | CLS Loss: 0.03651415929198265\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 3.073690176010132 | KNN Loss: 3.0410053730010986 | CLS Loss: 0.03268472105264664\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 3.073604106903076 | KNN Loss: 3.059201717376709 | CLS Loss: 0.014402281492948532\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 3.100595474243164 | KNN Loss: 3.0643444061279297 | CLS Loss: 0.036250948905944824\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 3.0683088302612305 | KNN Loss: 3.063004732131958 | CLS Loss: 0.005304194521158934\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 3.045408248901367 | KNN Loss: 3.032822608947754 | CLS Loss: 0.012585630640387535\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 3.065666437149048 | KNN Loss: 3.0186731815338135 | CLS Loss: 0.04699331521987915\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 3.089658260345459 | KNN Loss: 3.0676238536834717 | CLS Loss: 0.022034484893083572\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 3.0833001136779785 | KNN Loss: 3.049206256866455 | CLS Loss: 0.0340939462184906\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 3.068652629852295 | KNN Loss: 3.040574550628662 | CLS Loss: 0.028078196570277214\n",
      "Epoch: 037, Loss: 3.0744, Train: 0.9921, Valid: 0.9855, Best: 0.9861\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 3.0906102657318115 | KNN Loss: 3.067206382751465 | CLS Loss: 0.023403894156217575\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 3.0787291526794434 | KNN Loss: 3.0376832485198975 | CLS Loss: 0.041045889258384705\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 3.0519790649414062 | KNN Loss: 3.0263712406158447 | CLS Loss: 0.025607943534851074\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 3.0383567810058594 | KNN Loss: 3.0227458477020264 | CLS Loss: 0.015610969625413418\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 3.0946152210235596 | KNN Loss: 3.0806236267089844 | CLS Loss: 0.013991658575832844\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 3.0798447132110596 | KNN Loss: 3.034423828125 | CLS Loss: 0.04542097821831703\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 3.040522336959839 | KNN Loss: 3.0242176055908203 | CLS Loss: 0.016304805874824524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 3.07731032371521 | KNN Loss: 3.0510125160217285 | CLS Loss: 0.02629787102341652\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 3.0772719383239746 | KNN Loss: 3.038449287414551 | CLS Loss: 0.03882255405187607\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 3.067284107208252 | KNN Loss: 3.0135114192962646 | CLS Loss: 0.05377264320850372\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 3.0744316577911377 | KNN Loss: 3.0536653995513916 | CLS Loss: 0.0207663644105196\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 3.0269172191619873 | KNN Loss: 3.016000747680664 | CLS Loss: 0.010916439816355705\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 3.076125144958496 | KNN Loss: 3.053071975708008 | CLS Loss: 0.02305307239294052\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 3.0688095092773438 | KNN Loss: 3.0349771976470947 | CLS Loss: 0.03383226692676544\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 3.09177827835083 | KNN Loss: 3.0498831272125244 | CLS Loss: 0.04189519211649895\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 3.059908151626587 | KNN Loss: 3.035198450088501 | CLS Loss: 0.024709735065698624\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 3.080235481262207 | KNN Loss: 3.0479257106781006 | CLS Loss: 0.0323098860681057\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 3.0951778888702393 | KNN Loss: 3.067220449447632 | CLS Loss: 0.027957329526543617\n",
      "Epoch: 038, Loss: 3.0718, Train: 0.9928, Valid: 0.9853, Best: 0.9861\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 3.0772595405578613 | KNN Loss: 3.062784194946289 | CLS Loss: 0.0144753223285079\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 3.0710020065307617 | KNN Loss: 3.0336921215057373 | CLS Loss: 0.037309881299734116\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 3.1067116260528564 | KNN Loss: 3.065617799758911 | CLS Loss: 0.041093792766332626\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 3.0408220291137695 | KNN Loss: 3.0363235473632812 | CLS Loss: 0.004498577676713467\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 3.136507749557495 | KNN Loss: 3.075352668762207 | CLS Loss: 0.061155155301094055\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 3.065661668777466 | KNN Loss: 3.024358034133911 | CLS Loss: 0.04130369797348976\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 3.0692594051361084 | KNN Loss: 3.0287845134735107 | CLS Loss: 0.040474895387887955\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 3.0704145431518555 | KNN Loss: 3.047096014022827 | CLS Loss: 0.023318497464060783\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 3.058931350708008 | KNN Loss: 3.028444528579712 | CLS Loss: 0.03048689104616642\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 3.0750558376312256 | KNN Loss: 3.0149261951446533 | CLS Loss: 0.06012957915663719\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 3.1143698692321777 | KNN Loss: 3.0836021900177 | CLS Loss: 0.030767591670155525\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 3.097208023071289 | KNN Loss: 3.0456626415252686 | CLS Loss: 0.05154549703001976\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 3.038879156112671 | KNN Loss: 3.0160281658172607 | CLS Loss: 0.02285095863044262\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 3.0752291679382324 | KNN Loss: 3.061738967895508 | CLS Loss: 0.013490164652466774\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 3.1139776706695557 | KNN Loss: 3.058647871017456 | CLS Loss: 0.05532979592680931\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 3.089931011199951 | KNN Loss: 3.049999237060547 | CLS Loss: 0.039931852370500565\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 3.053739070892334 | KNN Loss: 3.04124116897583 | CLS Loss: 0.01249787863343954\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 3.0997703075408936 | KNN Loss: 3.067887783050537 | CLS Loss: 0.031882453709840775\n",
      "Epoch: 039, Loss: 3.0705, Train: 0.9924, Valid: 0.9845, Best: 0.9861\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 3.0749247074127197 | KNN Loss: 3.036343574523926 | CLS Loss: 0.03858122602105141\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 3.0802736282348633 | KNN Loss: 3.066434860229492 | CLS Loss: 0.013838769868016243\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 3.1226871013641357 | KNN Loss: 3.1005589962005615 | CLS Loss: 0.022127987816929817\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 3.058776617050171 | KNN Loss: 3.0156452655792236 | CLS Loss: 0.04313134774565697\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 3.092313528060913 | KNN Loss: 3.076849937438965 | CLS Loss: 0.015463591553270817\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 3.0838911533355713 | KNN Loss: 3.0643022060394287 | CLS Loss: 0.019588831812143326\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 3.0798850059509277 | KNN Loss: 3.038057804107666 | CLS Loss: 0.04182726889848709\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 3.0543429851531982 | KNN Loss: 3.0391652584075928 | CLS Loss: 0.015177799388766289\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 3.03957462310791 | KNN Loss: 3.0126535892486572 | CLS Loss: 0.026921002194285393\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 3.065622568130493 | KNN Loss: 3.00219988822937 | CLS Loss: 0.0634227842092514\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 3.029660701751709 | KNN Loss: 3.0208756923675537 | CLS Loss: 0.00878490973263979\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 3.0791916847229004 | KNN Loss: 3.0529065132141113 | CLS Loss: 0.026285190135240555\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 3.0607073307037354 | KNN Loss: 3.017625093460083 | CLS Loss: 0.0430823490023613\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 3.104595422744751 | KNN Loss: 3.0428311824798584 | CLS Loss: 0.06176432967185974\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 3.038376569747925 | KNN Loss: 3.008305788040161 | CLS Loss: 0.030070731416344643\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 3.074784994125366 | KNN Loss: 3.0556721687316895 | CLS Loss: 0.01911272667348385\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 3.065473794937134 | KNN Loss: 3.01706862449646 | CLS Loss: 0.04840521514415741\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 3.0667757987976074 | KNN Loss: 3.0437724590301514 | CLS Loss: 0.023003440350294113\n",
      "Epoch: 040, Loss: 3.0694, Train: 0.9921, Valid: 0.9853, Best: 0.9861\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 3.024717092514038 | KNN Loss: 3.014223575592041 | CLS Loss: 0.010493628680706024\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 3.110740900039673 | KNN Loss: 3.0571954250335693 | CLS Loss: 0.05354539677500725\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 3.045377731323242 | KNN Loss: 3.0256879329681396 | CLS Loss: 0.019689753651618958\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 3.0670247077941895 | KNN Loss: 3.010005474090576 | CLS Loss: 0.05701927840709686\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 3.0253398418426514 | KNN Loss: 3.003556251525879 | CLS Loss: 0.02178354002535343\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 3.0873262882232666 | KNN Loss: 3.05684232711792 | CLS Loss: 0.030483851209282875\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 3.0621488094329834 | KNN Loss: 3.05329966545105 | CLS Loss: 0.008849120698869228\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 3.0131561756134033 | KNN Loss: 3.003425121307373 | CLS Loss: 0.009731044992804527\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 3.035022497177124 | KNN Loss: 3.0295963287353516 | CLS Loss: 0.005426156334578991\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 3.088959217071533 | KNN Loss: 3.0617640018463135 | CLS Loss: 0.02719532698392868\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 3.0494840145111084 | KNN Loss: 3.030592679977417 | CLS Loss: 0.018891235813498497\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 3.0385591983795166 | KNN Loss: 2.9994418621063232 | CLS Loss: 0.03911738842725754\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 3.0833096504211426 | KNN Loss: 3.067251205444336 | CLS Loss: 0.016058405861258507\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 3.0550315380096436 | KNN Loss: 3.037261486053467 | CLS Loss: 0.01777016371488571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 3.0545618534088135 | KNN Loss: 3.036682605743408 | CLS Loss: 0.017879270017147064\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 3.0807571411132812 | KNN Loss: 3.055466413497925 | CLS Loss: 0.025290826335549355\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 3.0504586696624756 | KNN Loss: 3.0375969409942627 | CLS Loss: 0.012861755676567554\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 3.037323236465454 | KNN Loss: 3.0189735889434814 | CLS Loss: 0.018349716439843178\n",
      "Epoch: 041, Loss: 3.0644, Train: 0.9935, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 3.068254232406616 | KNN Loss: 3.0339410305023193 | CLS Loss: 0.03431329131126404\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 3.017998218536377 | KNN Loss: 3.000027894973755 | CLS Loss: 0.017970234155654907\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 3.08732008934021 | KNN Loss: 3.0662381649017334 | CLS Loss: 0.021081941202282906\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 3.03227162361145 | KNN Loss: 3.0263450145721436 | CLS Loss: 0.0059264968149363995\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 3.0508415699005127 | KNN Loss: 3.019507646560669 | CLS Loss: 0.031333986669778824\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 3.0723438262939453 | KNN Loss: 3.0445706844329834 | CLS Loss: 0.02777319960296154\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 3.067505121231079 | KNN Loss: 3.0406038761138916 | CLS Loss: 0.026901161298155785\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 3.069472074508667 | KNN Loss: 3.0328750610351562 | CLS Loss: 0.03659709915518761\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 3.107299327850342 | KNN Loss: 3.0763251781463623 | CLS Loss: 0.030974144116044044\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 3.0554566383361816 | KNN Loss: 3.0219364166259766 | CLS Loss: 0.033520229160785675\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 3.027724504470825 | KNN Loss: 3.01436448097229 | CLS Loss: 0.013359968550503254\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 3.0660476684570312 | KNN Loss: 2.9995977878570557 | CLS Loss: 0.06644997000694275\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 3.051344394683838 | KNN Loss: 3.022333860397339 | CLS Loss: 0.02901063859462738\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 3.079084634780884 | KNN Loss: 3.0668041706085205 | CLS Loss: 0.012280379422008991\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 3.114931344985962 | KNN Loss: 3.0803961753845215 | CLS Loss: 0.03453509137034416\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 3.1144659519195557 | KNN Loss: 3.0735244750976562 | CLS Loss: 0.040941450744867325\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 3.0627622604370117 | KNN Loss: 3.024888277053833 | CLS Loss: 0.03787395730614662\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 3.0169870853424072 | KNN Loss: 3.0112626552581787 | CLS Loss: 0.005724339745938778\n",
      "Epoch: 042, Loss: 3.0646, Train: 0.9936, Valid: 0.9849, Best: 0.9861\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 3.049846649169922 | KNN Loss: 3.0354063510894775 | CLS Loss: 0.014440334402024746\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 3.0750820636749268 | KNN Loss: 3.0345969200134277 | CLS Loss: 0.04048508033156395\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 3.0631637573242188 | KNN Loss: 3.028047800064087 | CLS Loss: 0.035115908831357956\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 3.0242905616760254 | KNN Loss: 2.9916884899139404 | CLS Loss: 0.03260206803679466\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 3.078362464904785 | KNN Loss: 3.0611720085144043 | CLS Loss: 0.017190441489219666\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 3.038166046142578 | KNN Loss: 3.00538969039917 | CLS Loss: 0.03277638927102089\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 3.1187336444854736 | KNN Loss: 3.0735321044921875 | CLS Loss: 0.0452016144990921\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 3.041006565093994 | KNN Loss: 3.0179646015167236 | CLS Loss: 0.023041950538754463\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 3.0693161487579346 | KNN Loss: 3.0282442569732666 | CLS Loss: 0.04107189550995827\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 3.0705912113189697 | KNN Loss: 3.040990114212036 | CLS Loss: 0.029601125046610832\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 3.063044309616089 | KNN Loss: 3.017085313796997 | CLS Loss: 0.045959070324897766\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 3.0407443046569824 | KNN Loss: 3.031238555908203 | CLS Loss: 0.00950576551258564\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 3.0199215412139893 | KNN Loss: 3.010166645050049 | CLS Loss: 0.009754803031682968\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 3.0584876537323 | KNN Loss: 3.0271432399749756 | CLS Loss: 0.03134435415267944\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 3.0684709548950195 | KNN Loss: 3.0392706394195557 | CLS Loss: 0.029200345277786255\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 3.0371437072753906 | KNN Loss: 3.0039761066436768 | CLS Loss: 0.033167652785778046\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 3.0846176147460938 | KNN Loss: 3.07989764213562 | CLS Loss: 0.0047200885601341724\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 3.0700385570526123 | KNN Loss: 3.046761989593506 | CLS Loss: 0.023276561871170998\n",
      "Epoch: 043, Loss: 3.0650, Train: 0.9934, Valid: 0.9865, Best: 0.9865\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 3.0553622245788574 | KNN Loss: 3.0091254711151123 | CLS Loss: 0.046236857771873474\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 3.0430967807769775 | KNN Loss: 3.0266530513763428 | CLS Loss: 0.016443682834506035\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 3.0850303173065186 | KNN Loss: 3.0545499324798584 | CLS Loss: 0.030480384826660156\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 3.033392906188965 | KNN Loss: 3.0143611431121826 | CLS Loss: 0.019031735137104988\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 3.052311420440674 | KNN Loss: 3.0365395545959473 | CLS Loss: 0.015771780163049698\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 3.051919937133789 | KNN Loss: 3.0316247940063477 | CLS Loss: 0.020295150578022003\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 3.0898709297180176 | KNN Loss: 3.0570292472839355 | CLS Loss: 0.03284164145588875\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 3.085423707962036 | KNN Loss: 3.0640006065368652 | CLS Loss: 0.0214230976998806\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 3.0735795497894287 | KNN Loss: 3.0534865856170654 | CLS Loss: 0.020092902705073357\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 3.0681843757629395 | KNN Loss: 3.0564064979553223 | CLS Loss: 0.011777934618294239\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 3.0424113273620605 | KNN Loss: 3.021641969680786 | CLS Loss: 0.020769469439983368\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 3.0685203075408936 | KNN Loss: 3.0408291816711426 | CLS Loss: 0.02769111841917038\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 3.020049810409546 | KNN Loss: 2.998077630996704 | CLS Loss: 0.021972263231873512\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 3.102933406829834 | KNN Loss: 3.0787603855133057 | CLS Loss: 0.024173108860850334\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 3.135111093521118 | KNN Loss: 3.0920357704162598 | CLS Loss: 0.043075256049633026\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 3.0306835174560547 | KNN Loss: 3.0165679454803467 | CLS Loss: 0.014115596190094948\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 3.059148073196411 | KNN Loss: 3.0391156673431396 | CLS Loss: 0.02003243751823902\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 3.080648899078369 | KNN Loss: 3.0518860816955566 | CLS Loss: 0.028762809932231903\n",
      "Epoch: 044, Loss: 3.0612, Train: 0.9939, Valid: 0.9861, Best: 0.9865\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 3.074641466140747 | KNN Loss: 3.0289952754974365 | CLS Loss: 0.045646123588085175\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 3.077057123184204 | KNN Loss: 3.0576090812683105 | CLS Loss: 0.019448159262537956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 3.074091911315918 | KNN Loss: 3.0496726036071777 | CLS Loss: 0.024419333785772324\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 3.0453028678894043 | KNN Loss: 3.0247385501861572 | CLS Loss: 0.020564377307891846\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 3.0892131328582764 | KNN Loss: 3.0515530109405518 | CLS Loss: 0.037660181522369385\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 3.1034021377563477 | KNN Loss: 3.0607082843780518 | CLS Loss: 0.042693767696619034\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 3.0539324283599854 | KNN Loss: 3.0289993286132812 | CLS Loss: 0.024933211505413055\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 3.053934335708618 | KNN Loss: 3.0283241271972656 | CLS Loss: 0.025610176846385002\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 3.0325820446014404 | KNN Loss: 3.0124928951263428 | CLS Loss: 0.02008924074470997\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 3.1002657413482666 | KNN Loss: 3.0695223808288574 | CLS Loss: 0.030743256211280823\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 3.0445680618286133 | KNN Loss: 3.03659987449646 | CLS Loss: 0.007968069054186344\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 3.0865845680236816 | KNN Loss: 3.058600664138794 | CLS Loss: 0.027983907610177994\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 3.083491563796997 | KNN Loss: 3.0595946311950684 | CLS Loss: 0.023896949365735054\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 3.078333854675293 | KNN Loss: 3.0385868549346924 | CLS Loss: 0.03974692523479462\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 3.063721179962158 | KNN Loss: 3.020308017730713 | CLS Loss: 0.043413084000349045\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 3.0581302642822266 | KNN Loss: 3.0372965335845947 | CLS Loss: 0.020833831280469894\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 3.050518751144409 | KNN Loss: 2.9992785453796387 | CLS Loss: 0.05124013125896454\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 3.1072092056274414 | KNN Loss: 3.0907065868377686 | CLS Loss: 0.016502676531672478\n",
      "Epoch: 045, Loss: 3.0598, Train: 0.9939, Valid: 0.9865, Best: 0.9865\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 3.0563039779663086 | KNN Loss: 3.0445711612701416 | CLS Loss: 0.011732910759747028\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 3.055943489074707 | KNN Loss: 3.0308005809783936 | CLS Loss: 0.025142833590507507\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 3.0196988582611084 | KNN Loss: 2.996554136276245 | CLS Loss: 0.023144826292991638\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 3.0476014614105225 | KNN Loss: 3.016392946243286 | CLS Loss: 0.031208449974656105\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 3.0743439197540283 | KNN Loss: 3.0571460723876953 | CLS Loss: 0.017197800800204277\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 3.0591588020324707 | KNN Loss: 3.0290493965148926 | CLS Loss: 0.03010941855609417\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 3.0419857501983643 | KNN Loss: 3.0262646675109863 | CLS Loss: 0.015721024945378304\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 3.0647177696228027 | KNN Loss: 3.0457165241241455 | CLS Loss: 0.019001204520463943\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 3.047114849090576 | KNN Loss: 3.041897773742676 | CLS Loss: 0.005217097233980894\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 3.068220376968384 | KNN Loss: 3.0531232357025146 | CLS Loss: 0.015097049064934254\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 3.0380287170410156 | KNN Loss: 3.0002121925354004 | CLS Loss: 0.03781662508845329\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 3.0665032863616943 | KNN Loss: 3.0576326847076416 | CLS Loss: 0.008870516903698444\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 3.0708045959472656 | KNN Loss: 3.0315847396850586 | CLS Loss: 0.03921979293227196\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 3.0864694118499756 | KNN Loss: 3.0533783435821533 | CLS Loss: 0.03309112414717674\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 3.0353622436523438 | KNN Loss: 3.0200114250183105 | CLS Loss: 0.015350746922194958\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 3.055227518081665 | KNN Loss: 3.0334579944610596 | CLS Loss: 0.02176956832408905\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 3.0397579669952393 | KNN Loss: 3.0144155025482178 | CLS Loss: 0.025342551991343498\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 3.0689899921417236 | KNN Loss: 3.052983045578003 | CLS Loss: 0.016006873920559883\n",
      "Epoch: 046, Loss: 3.0601, Train: 0.9934, Valid: 0.9854, Best: 0.9865\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 3.065653085708618 | KNN Loss: 3.0463390350341797 | CLS Loss: 0.019314005970954895\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 3.032831907272339 | KNN Loss: 3.023267984390259 | CLS Loss: 0.009563960134983063\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 3.040004014968872 | KNN Loss: 3.0237600803375244 | CLS Loss: 0.01624401845037937\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 3.057516574859619 | KNN Loss: 3.049647569656372 | CLS Loss: 0.007868897169828415\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 3.0653765201568604 | KNN Loss: 3.042327880859375 | CLS Loss: 0.023048648610711098\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 3.0521271228790283 | KNN Loss: 3.042881488800049 | CLS Loss: 0.009245631285011768\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 3.051457405090332 | KNN Loss: 3.0141801834106445 | CLS Loss: 0.037277206778526306\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 3.092637062072754 | KNN Loss: 3.0717971324920654 | CLS Loss: 0.020839860662817955\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 3.0417940616607666 | KNN Loss: 3.0251951217651367 | CLS Loss: 0.016599008813500404\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 3.049525737762451 | KNN Loss: 3.0346405506134033 | CLS Loss: 0.014885171316564083\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 3.0374319553375244 | KNN Loss: 3.015270709991455 | CLS Loss: 0.022161317989230156\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 3.06064772605896 | KNN Loss: 3.023181200027466 | CLS Loss: 0.0374666303396225\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 3.041719913482666 | KNN Loss: 3.034553289413452 | CLS Loss: 0.007166649680584669\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 3.0468506813049316 | KNN Loss: 3.020756244659424 | CLS Loss: 0.026094412431120872\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 3.1038124561309814 | KNN Loss: 3.0612123012542725 | CLS Loss: 0.04260021448135376\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 3.047527551651001 | KNN Loss: 3.0242342948913574 | CLS Loss: 0.023293163627386093\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 3.0560173988342285 | KNN Loss: 3.0367703437805176 | CLS Loss: 0.0192471444606781\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 3.043867588043213 | KNN Loss: 3.0314528942108154 | CLS Loss: 0.012414783239364624\n",
      "Epoch: 047, Loss: 3.0554, Train: 0.9945, Valid: 0.9862, Best: 0.9865\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 3.0408618450164795 | KNN Loss: 3.024905204772949 | CLS Loss: 0.015956612303853035\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 3.0492734909057617 | KNN Loss: 3.024808168411255 | CLS Loss: 0.024465207010507584\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 3.0855395793914795 | KNN Loss: 3.0748291015625 | CLS Loss: 0.010710492730140686\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 3.0323116779327393 | KNN Loss: 3.0155227184295654 | CLS Loss: 0.016789043322205544\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 3.030069351196289 | KNN Loss: 3.0201737880706787 | CLS Loss: 0.009895452298223972\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 3.103241205215454 | KNN Loss: 3.071486473083496 | CLS Loss: 0.03175467997789383\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 3.0300021171569824 | KNN Loss: 3.0074915885925293 | CLS Loss: 0.022510575130581856\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 3.0396616458892822 | KNN Loss: 3.0167863368988037 | CLS Loss: 0.022875377908349037\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 3.0282630920410156 | KNN Loss: 3.0081539154052734 | CLS Loss: 0.020109206438064575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 3.049514055252075 | KNN Loss: 3.0313374996185303 | CLS Loss: 0.01817660965025425\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 3.0612144470214844 | KNN Loss: 3.016990900039673 | CLS Loss: 0.04422348365187645\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 3.06685209274292 | KNN Loss: 3.0268375873565674 | CLS Loss: 0.04001457989215851\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 3.0710856914520264 | KNN Loss: 3.0409178733825684 | CLS Loss: 0.030167710036039352\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 3.051100015640259 | KNN Loss: 3.0374083518981934 | CLS Loss: 0.01369160134345293\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 3.0074405670166016 | KNN Loss: 2.9995031356811523 | CLS Loss: 0.007937494665384293\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 3.0776443481445312 | KNN Loss: 3.0624711513519287 | CLS Loss: 0.015173304826021194\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 3.0729422569274902 | KNN Loss: 3.036365270614624 | CLS Loss: 0.036577098071575165\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 3.085792064666748 | KNN Loss: 3.0510377883911133 | CLS Loss: 0.03475427255034447\n",
      "Epoch: 048, Loss: 3.0581, Train: 0.9940, Valid: 0.9849, Best: 0.9865\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 3.041917324066162 | KNN Loss: 3.0223581790924072 | CLS Loss: 0.019559131935238838\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 3.050607681274414 | KNN Loss: 3.034038543701172 | CLS Loss: 0.0165691114962101\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 3.0744447708129883 | KNN Loss: 3.0587527751922607 | CLS Loss: 0.015691911801695824\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 3.068601131439209 | KNN Loss: 3.041417121887207 | CLS Loss: 0.02718397229909897\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 3.0759031772613525 | KNN Loss: 3.047135591506958 | CLS Loss: 0.02876758947968483\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 3.075068473815918 | KNN Loss: 3.0613410472869873 | CLS Loss: 0.013727379962801933\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 3.050797939300537 | KNN Loss: 3.0038905143737793 | CLS Loss: 0.04690731316804886\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 3.038390636444092 | KNN Loss: 3.0255110263824463 | CLS Loss: 0.012879719026386738\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 3.0248851776123047 | KNN Loss: 3.005645751953125 | CLS Loss: 0.019239529967308044\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 3.017756938934326 | KNN Loss: 3.011092185974121 | CLS Loss: 0.006664763670414686\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 3.0348634719848633 | KNN Loss: 3.0246236324310303 | CLS Loss: 0.010239722207188606\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 3.061162233352661 | KNN Loss: 3.0581743717193604 | CLS Loss: 0.002987809246405959\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 3.1000421047210693 | KNN Loss: 3.086571455001831 | CLS Loss: 0.013470545411109924\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 3.0492734909057617 | KNN Loss: 3.0144731998443604 | CLS Loss: 0.034800201654434204\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 3.0198614597320557 | KNN Loss: 3.0064315795898438 | CLS Loss: 0.013429795391857624\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 3.062485933303833 | KNN Loss: 3.0448412895202637 | CLS Loss: 0.017644528299570084\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 3.0516562461853027 | KNN Loss: 3.034019708633423 | CLS Loss: 0.01763647422194481\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 3.0599405765533447 | KNN Loss: 3.042304039001465 | CLS Loss: 0.017636483535170555\n",
      "Epoch: 049, Loss: 3.0584, Train: 0.9918, Valid: 0.9843, Best: 0.9865\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 3.094858169555664 | KNN Loss: 3.068239688873291 | CLS Loss: 0.02661857195198536\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 3.1090970039367676 | KNN Loss: 3.071855306625366 | CLS Loss: 0.03724164888262749\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 3.0470759868621826 | KNN Loss: 3.033325672149658 | CLS Loss: 0.013750243932008743\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 3.0451629161834717 | KNN Loss: 3.018338203430176 | CLS Loss: 0.026824776083230972\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 3.0681004524230957 | KNN Loss: 3.0429623126983643 | CLS Loss: 0.025138238444924355\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 3.0602052211761475 | KNN Loss: 3.0441699028015137 | CLS Loss: 0.016035206615924835\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 3.0616049766540527 | KNN Loss: 3.0491445064544678 | CLS Loss: 0.012460515834391117\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 3.049208164215088 | KNN Loss: 3.030409574508667 | CLS Loss: 0.01879853382706642\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 3.041607618331909 | KNN Loss: 3.001880407333374 | CLS Loss: 0.03972712159156799\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 3.0533530712127686 | KNN Loss: 3.0250353813171387 | CLS Loss: 0.02831767499446869\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 3.0744876861572266 | KNN Loss: 3.0478131771087646 | CLS Loss: 0.02667446993291378\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 3.0366241931915283 | KNN Loss: 3.019650459289551 | CLS Loss: 0.01697370409965515\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 3.037327527999878 | KNN Loss: 3.0125250816345215 | CLS Loss: 0.02480238676071167\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 3.0506975650787354 | KNN Loss: 3.014544725418091 | CLS Loss: 0.036152735352516174\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 3.053395986557007 | KNN Loss: 3.039341688156128 | CLS Loss: 0.014054187573492527\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 3.0240213871002197 | KNN Loss: 3.0099635124206543 | CLS Loss: 0.0140577657148242\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 3.0209503173828125 | KNN Loss: 3.0022895336151123 | CLS Loss: 0.018660783767700195\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 3.0370287895202637 | KNN Loss: 3.019477128982544 | CLS Loss: 0.01755162887275219\n",
      "Epoch: 050, Loss: 3.0600, Train: 0.9940, Valid: 0.9857, Best: 0.9865\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 3.0446081161499023 | KNN Loss: 3.016869068145752 | CLS Loss: 0.027739008888602257\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 3.0355324745178223 | KNN Loss: 3.0183746814727783 | CLS Loss: 0.017157886177301407\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 3.0545308589935303 | KNN Loss: 3.032360553741455 | CLS Loss: 0.022170206531882286\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 3.0430915355682373 | KNN Loss: 3.034799337387085 | CLS Loss: 0.008292216807603836\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 3.0507891178131104 | KNN Loss: 3.0285873413085938 | CLS Loss: 0.02220172807574272\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 3.045785665512085 | KNN Loss: 3.022829294204712 | CLS Loss: 0.022956358268857002\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 3.0351264476776123 | KNN Loss: 3.021353006362915 | CLS Loss: 0.013773327693343163\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 3.0418522357940674 | KNN Loss: 3.025322914123535 | CLS Loss: 0.01652929186820984\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 3.0648419857025146 | KNN Loss: 3.052140235900879 | CLS Loss: 0.012701849453151226\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 3.0666728019714355 | KNN Loss: 3.052745819091797 | CLS Loss: 0.013927042484283447\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 3.039036512374878 | KNN Loss: 3.023616313934326 | CLS Loss: 0.0154200978577137\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 3.0531833171844482 | KNN Loss: 3.033745527267456 | CLS Loss: 0.019437894225120544\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 3.029989242553711 | KNN Loss: 2.9971184730529785 | CLS Loss: 0.03287076577544212\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 3.059756278991699 | KNN Loss: 3.0415563583374023 | CLS Loss: 0.01819981262087822\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 3.058781862258911 | KNN Loss: 3.0409457683563232 | CLS Loss: 0.017836155369877815\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 3.040587902069092 | KNN Loss: 3.0233535766601562 | CLS Loss: 0.017234444618225098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 3.0424156188964844 | KNN Loss: 3.018876314163208 | CLS Loss: 0.023539185523986816\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 3.046872138977051 | KNN Loss: 3.0347771644592285 | CLS Loss: 0.01209485623985529\n",
      "Epoch: 051, Loss: 3.0575, Train: 0.9944, Valid: 0.9868, Best: 0.9868\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 3.0674281120300293 | KNN Loss: 3.050729274749756 | CLS Loss: 0.01669878326356411\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 3.0257301330566406 | KNN Loss: 3.005274534225464 | CLS Loss: 0.020455611869692802\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 3.0424771308898926 | KNN Loss: 3.0224692821502686 | CLS Loss: 0.020007802173495293\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 3.0345957279205322 | KNN Loss: 3.022479295730591 | CLS Loss: 0.012116420082747936\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 3.0512828826904297 | KNN Loss: 3.0302734375 | CLS Loss: 0.021009420976042747\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 3.0405261516571045 | KNN Loss: 3.0210394859313965 | CLS Loss: 0.019486676901578903\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 3.030087471008301 | KNN Loss: 3.016153335571289 | CLS Loss: 0.013934103772044182\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 3.1010775566101074 | KNN Loss: 3.0958945751190186 | CLS Loss: 0.00518291350454092\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 3.0392918586730957 | KNN Loss: 3.0254485607147217 | CLS Loss: 0.013843235559761524\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 3.049978017807007 | KNN Loss: 3.035278797149658 | CLS Loss: 0.01469912938773632\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 3.0716328620910645 | KNN Loss: 3.050644874572754 | CLS Loss: 0.02098793536424637\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 3.046452522277832 | KNN Loss: 3.0009992122650146 | CLS Loss: 0.04545320197939873\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 3.0625417232513428 | KNN Loss: 3.0269734859466553 | CLS Loss: 0.03556814789772034\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 3.081514835357666 | KNN Loss: 3.0496480464935303 | CLS Loss: 0.03186680004000664\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 3.0651636123657227 | KNN Loss: 3.0325663089752197 | CLS Loss: 0.03259731084108353\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 3.0607948303222656 | KNN Loss: 3.0264439582824707 | CLS Loss: 0.03435085713863373\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 3.025449514389038 | KNN Loss: 3.0110421180725098 | CLS Loss: 0.014407292939722538\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 3.052896022796631 | KNN Loss: 3.026963472366333 | CLS Loss: 0.025932464748620987\n",
      "Epoch: 052, Loss: 3.0577, Train: 0.9934, Valid: 0.9855, Best: 0.9868\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 3.051499605178833 | KNN Loss: 3.0280749797821045 | CLS Loss: 0.023424724116921425\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 3.029681921005249 | KNN Loss: 3.010601282119751 | CLS Loss: 0.019080666825175285\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 3.0537543296813965 | KNN Loss: 3.034749984741211 | CLS Loss: 0.019004423171281815\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 3.036506414413452 | KNN Loss: 3.024712085723877 | CLS Loss: 0.011794348247349262\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 3.012889862060547 | KNN Loss: 2.9922444820404053 | CLS Loss: 0.020645448938012123\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 3.069568634033203 | KNN Loss: 3.054685592651367 | CLS Loss: 0.014882939867675304\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 3.035381555557251 | KNN Loss: 3.0251948833465576 | CLS Loss: 0.010186583735048771\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 3.0675199031829834 | KNN Loss: 3.0507397651672363 | CLS Loss: 0.01678013801574707\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 3.037400007247925 | KNN Loss: 3.026442527770996 | CLS Loss: 0.010957542806863785\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 3.0770504474639893 | KNN Loss: 3.0609424114227295 | CLS Loss: 0.016108142212033272\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 3.0300872325897217 | KNN Loss: 3.0126938819885254 | CLS Loss: 0.017393378540873528\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 3.0536558628082275 | KNN Loss: 3.0471222400665283 | CLS Loss: 0.006533718667924404\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 3.0184085369110107 | KNN Loss: 3.012833833694458 | CLS Loss: 0.005574696697294712\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 3.059330701828003 | KNN Loss: 3.030463218688965 | CLS Loss: 0.028867442160844803\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 3.021737813949585 | KNN Loss: 3.016629219055176 | CLS Loss: 0.005108678713440895\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 3.0574469566345215 | KNN Loss: 3.0395939350128174 | CLS Loss: 0.017852935940027237\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 3.0334815979003906 | KNN Loss: 3.0180678367614746 | CLS Loss: 0.015413796529173851\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 3.054979085922241 | KNN Loss: 3.0385875701904297 | CLS Loss: 0.016391485929489136\n",
      "Epoch: 053, Loss: 3.0509, Train: 0.9950, Valid: 0.9856, Best: 0.9868\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 3.034944534301758 | KNN Loss: 3.03328013420105 | CLS Loss: 0.0016644123243167996\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 3.045245885848999 | KNN Loss: 3.0283703804016113 | CLS Loss: 0.016875600442290306\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 3.0617263317108154 | KNN Loss: 3.041185140609741 | CLS Loss: 0.02054128237068653\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 3.042778968811035 | KNN Loss: 3.0319201946258545 | CLS Loss: 0.010858851484954357\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 3.1216397285461426 | KNN Loss: 3.086711883544922 | CLS Loss: 0.03492778167128563\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 3.023271322250366 | KNN Loss: 3.0156607627868652 | CLS Loss: 0.007610618602484465\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 3.058785915374756 | KNN Loss: 3.0461995601654053 | CLS Loss: 0.0125863216817379\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 3.081285238265991 | KNN Loss: 3.046782970428467 | CLS Loss: 0.034502170979976654\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 3.045133352279663 | KNN Loss: 3.027141571044922 | CLS Loss: 0.017991794273257256\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 3.0450801849365234 | KNN Loss: 3.0362610816955566 | CLS Loss: 0.00881919451057911\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 3.0561885833740234 | KNN Loss: 3.037277936935425 | CLS Loss: 0.018910730257630348\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 3.061122417449951 | KNN Loss: 3.0434534549713135 | CLS Loss: 0.017668956890702248\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 3.0408365726470947 | KNN Loss: 3.026552677154541 | CLS Loss: 0.014283894561231136\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 3.0508012771606445 | KNN Loss: 3.022803544998169 | CLS Loss: 0.027997644618153572\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 3.0368587970733643 | KNN Loss: 3.024258852005005 | CLS Loss: 0.01259996835142374\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 3.026700019836426 | KNN Loss: 3.0024502277374268 | CLS Loss: 0.02424990013241768\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 3.0263116359710693 | KNN Loss: 3.0183324813842773 | CLS Loss: 0.00797908753156662\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 3.0355474948883057 | KNN Loss: 3.0012784004211426 | CLS Loss: 0.03426919877529144\n",
      "Epoch: 054, Loss: 3.0544, Train: 0.9945, Valid: 0.9865, Best: 0.9868\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 3.031557083129883 | KNN Loss: 3.0024170875549316 | CLS Loss: 0.029139984399080276\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 3.049891948699951 | KNN Loss: 3.028289556503296 | CLS Loss: 0.02160233072936535\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 3.047013521194458 | KNN Loss: 3.019442081451416 | CLS Loss: 0.027571527287364006\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 3.016932249069214 | KNN Loss: 3.007251739501953 | CLS Loss: 0.009680571034550667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 3.0876059532165527 | KNN Loss: 3.0606045722961426 | CLS Loss: 0.027001449838280678\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 3.046112060546875 | KNN Loss: 3.0245144367218018 | CLS Loss: 0.021597709506750107\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 3.0568127632141113 | KNN Loss: 3.0344200134277344 | CLS Loss: 0.022392842918634415\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 3.018359899520874 | KNN Loss: 3.0099265575408936 | CLS Loss: 0.008433266542851925\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 3.064112901687622 | KNN Loss: 3.0317254066467285 | CLS Loss: 0.032387517392635345\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 3.0333433151245117 | KNN Loss: 3.0269806385040283 | CLS Loss: 0.006362715270370245\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 3.0289909839630127 | KNN Loss: 3.0198559761047363 | CLS Loss: 0.009134982712566853\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 3.068129777908325 | KNN Loss: 3.054579257965088 | CLS Loss: 0.013550424948334694\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 3.075377941131592 | KNN Loss: 3.065782308578491 | CLS Loss: 0.009595637209713459\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 3.0711724758148193 | KNN Loss: 3.046116590499878 | CLS Loss: 0.025055959820747375\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 3.05765700340271 | KNN Loss: 3.0374159812927246 | CLS Loss: 0.020241113379597664\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 3.0436458587646484 | KNN Loss: 3.032740831375122 | CLS Loss: 0.01090509444475174\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 3.086216688156128 | KNN Loss: 3.052861213684082 | CLS Loss: 0.033355459570884705\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 3.0255753993988037 | KNN Loss: 3.0031614303588867 | CLS Loss: 0.02241399511694908\n",
      "Epoch: 055, Loss: 3.0534, Train: 0.9950, Valid: 0.9863, Best: 0.9868\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 3.0525805950164795 | KNN Loss: 3.0318691730499268 | CLS Loss: 0.02071140892803669\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 3.0086445808410645 | KNN Loss: 3.005927085876465 | CLS Loss: 0.002717563882470131\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 3.0005111694335938 | KNN Loss: 2.9839441776275635 | CLS Loss: 0.016566943377256393\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 3.0261237621307373 | KNN Loss: 3.0136611461639404 | CLS Loss: 0.012462686747312546\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 3.00561261177063 | KNN Loss: 2.9869823455810547 | CLS Loss: 0.01863030530512333\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 3.073110818862915 | KNN Loss: 3.06514835357666 | CLS Loss: 0.00796253327280283\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 3.030913829803467 | KNN Loss: 3.0189168453216553 | CLS Loss: 0.011996949091553688\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 3.044534921646118 | KNN Loss: 3.033418655395508 | CLS Loss: 0.011116291396319866\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 3.0574140548706055 | KNN Loss: 3.041503429412842 | CLS Loss: 0.01591065526008606\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 3.069228410720825 | KNN Loss: 3.0576705932617188 | CLS Loss: 0.01155785471200943\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 3.114824056625366 | KNN Loss: 3.1077566146850586 | CLS Loss: 0.007067530415952206\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 3.038745403289795 | KNN Loss: 3.0246493816375732 | CLS Loss: 0.014096018858253956\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 3.0718159675598145 | KNN Loss: 3.0478055477142334 | CLS Loss: 0.024010322988033295\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 3.026207447052002 | KNN Loss: 3.0093932151794434 | CLS Loss: 0.016814250499010086\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 3.0665805339813232 | KNN Loss: 3.046455144882202 | CLS Loss: 0.020125458016991615\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 3.0413031578063965 | KNN Loss: 3.033785820007324 | CLS Loss: 0.007517325691878796\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 3.024533271789551 | KNN Loss: 3.0214879512786865 | CLS Loss: 0.0030454080551862717\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 3.032151460647583 | KNN Loss: 3.023453712463379 | CLS Loss: 0.008697707206010818\n",
      "Epoch: 056, Loss: 3.0500, Train: 0.9947, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 3.052563428878784 | KNN Loss: 3.0116159915924072 | CLS Loss: 0.040947508066892624\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 3.0608718395233154 | KNN Loss: 3.049814462661743 | CLS Loss: 0.011057434603571892\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 3.046022415161133 | KNN Loss: 3.0347537994384766 | CLS Loss: 0.011268651112914085\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 3.029522180557251 | KNN Loss: 3.0138044357299805 | CLS Loss: 0.015717757865786552\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 3.0558767318725586 | KNN Loss: 3.048574209213257 | CLS Loss: 0.007302621379494667\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 3.0503177642822266 | KNN Loss: 3.0388662815093994 | CLS Loss: 0.01145157776772976\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 3.030601978302002 | KNN Loss: 3.023742198944092 | CLS Loss: 0.00685966806486249\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 3.0452637672424316 | KNN Loss: 3.0274691581726074 | CLS Loss: 0.017794661223888397\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 3.036816358566284 | KNN Loss: 3.022658586502075 | CLS Loss: 0.014157673344016075\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 3.028212070465088 | KNN Loss: 3.009768009185791 | CLS Loss: 0.01844414882361889\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 3.042637348175049 | KNN Loss: 3.031888008117676 | CLS Loss: 0.010749307461082935\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 3.0517473220825195 | KNN Loss: 3.043938398361206 | CLS Loss: 0.007808889728039503\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 3.032578468322754 | KNN Loss: 3.0189368724823 | CLS Loss: 0.01364171039313078\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 3.065870761871338 | KNN Loss: 3.0543246269226074 | CLS Loss: 0.011546225287020206\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 3.0109243392944336 | KNN Loss: 3.0040700435638428 | CLS Loss: 0.006854405626654625\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 3.0459978580474854 | KNN Loss: 3.0049057006835938 | CLS Loss: 0.041092194616794586\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 3.033917188644409 | KNN Loss: 3.0229499340057373 | CLS Loss: 0.010967345908284187\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 3.0733349323272705 | KNN Loss: 3.063079357147217 | CLS Loss: 0.010255658067762852\n",
      "Epoch: 057, Loss: 3.0487, Train: 0.9953, Valid: 0.9866, Best: 0.9871\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 3.019531488418579 | KNN Loss: 3.0102994441986084 | CLS Loss: 0.009232121519744396\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 3.035830020904541 | KNN Loss: 3.0310773849487305 | CLS Loss: 0.004752551671117544\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 3.0120019912719727 | KNN Loss: 3.0053813457489014 | CLS Loss: 0.006620628759264946\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 3.03031063079834 | KNN Loss: 3.0194168090820312 | CLS Loss: 0.010893711820244789\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 3.0397439002990723 | KNN Loss: 3.017963171005249 | CLS Loss: 0.02178063988685608\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}