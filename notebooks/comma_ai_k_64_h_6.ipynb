{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from queue import LifoQueue\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import network.cpc\n",
    "from network.cpc import CDCK2\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from utils.ClassificationUtiols import onehot_coding\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn import tree as tt\n",
    "\n",
    "# IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: /home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_64/models/epoch_25.pt\n",
      "sensor names: (18 total)\n",
      "- speed\n",
      "- steering_angle\n",
      "- wheel_speed_0\n",
      "- wheel_speed_1\n",
      "- wheel_speed_2\n",
      "- wheel_speed_3\n",
      "- accelerometer_0\n",
      "- accelerometer_1\n",
      "- accelerometer_2\n",
      "- gyro_0\n",
      "- gyro_1\n",
      "- gyro_2\n",
      "- gyro_bias_0\n",
      "- gyro_bias_1\n",
      "- gyro_bias_2\n",
      "- gyro_uncalibrated_0\n",
      "- gyro_uncalibrated_1\n",
      "- gyro_uncalibrated_2\n",
      "Multihorizon size of the model: 30\n",
      "Test split ratio: 0.2\n",
      "Total number of windows in the dataset (without splitting): 101465\n"
     ]
    }
   ],
   "source": [
    "model_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_64/models/epoch_25.pt'\n",
    "dataset_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_64/data/test_data.file'\n",
    "\n",
    "print(f\"Load the model from: {model_path}\")\n",
    "model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "with open(dataset_path, 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "all_sensors = dataset.dataset.all_signals    \n",
    "print(f\"sensor names: ({len(all_sensors)} total)\")\n",
    "\n",
    "for s in all_sensors:\n",
    "    print(f\"- {s}\")\n",
    "    \n",
    "print(f\"Multihorizon size of the model: {model.timestep}\")\n",
    "print(f\"Test split ratio: {len(dataset) / len(dataset.dataset)}\")\n",
    "print(f\"Total number of windows in the dataset (without splitting): {len(dataset.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5fafc118d24934b6a3c7470c7d4dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projections = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "device = 'cuda'\n",
    "model = model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(total=len(loader.dataset))\n",
    "    for batch in loader:\n",
    "        hidden = CDCK2.init_hidden(len(batch))\n",
    "        batch = batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        y = model.predict(batch, hidden).detach().cpu()\n",
    "        projections = torch.cat([projections, y.detach().cpu()])\n",
    "        samples = torch.cat([samples, batch.detach().cpu()])\n",
    "        bar.update(y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM and calculate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4081aa4baa904f7baf20c0b1eabe0c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "best_score = float('inf')\n",
    "clusters = None\n",
    "range_ = list(range(5, 20))\n",
    "for k in tqdm(range_):\n",
    "    y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "    cur_score = davies_bouldin_score(projections, y)\n",
    "    scores.append(cur_score)\n",
    "    \n",
    "    if cur_score < best_score:\n",
    "        best_score = cur_score\n",
    "        clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('DB Score')\n",
    "plt.plot(range_, scores)\n",
    "best_k = range_[np.argmin(scores)]\n",
    "plt.axvline(best_k, color='r')\n",
    "plt.show()\n",
    "\n",
    "labels = set(clusters)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 200\n",
    "\n",
    "p = reduce_dims_and_plot(projections,\n",
    "                         y=clusters,\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnormalized_samples = samples.clone()\n",
    "\n",
    "# for col, sensor in enumerate(tqdm(dataset.dataset.all_signals)):\n",
    "#     denormalizer = dataset.dataset.get_denormalization_for_sensor(sensor)\n",
    "#     unnormalized_samples[:, col, :] = denormalizer(unnormalized_samples[:, col, :])\n",
    "\n",
    "sampled = samples[..., range(0, samples.shape[-1], 200)]\n",
    "\n",
    "samples_f = sampled.flatten(1)\n",
    "tree_dataset = list(zip(samples_f, clusters))\n",
    "batch_size = 2000\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 500\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "tree_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT accuracy: 0.955551175282117\n"
     ]
    }
   ],
   "source": [
    "tree = SDT(input_dim=samples_f.shape[1], output_dim=len(labels), depth=tree_depth, lamda=1e-3, use_cuda=True)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)\n",
    "clf = DecisionTreeClassifier(max_depth=tree_depth).fit(samples_f, clusters)\n",
    "print(f\"DT accuracy: {clf.score(samples_f, clusters)}\")\n",
    "tree.initialize_from_decision_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.518021573270192\n",
      "layer 0: 0.988950276243094\n",
      "layer 1: 0.988950276243094\n",
      "layer 2: 0.7417127071823204\n",
      "layer 3: 0.494475138121547\n",
      "layer 4: 0.494475138121547\n",
      "Epoch: 00 | Batch: 000 / 011 | Total loss: 1.758 | Reg loss: 0.011 | Tree loss: 1.758 | Accuracy: 0.374500 | 0.683 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 011 | Total loss: 1.747 | Reg loss: 0.011 | Tree loss: 1.747 | Accuracy: 0.359500 | 0.398 sec/iter\n",
      "Epoch: 00 | Batch: 002 / 011 | Total loss: 1.739 | Reg loss: 0.011 | Tree loss: 1.739 | Accuracy: 0.340500 | 0.301 sec/iter\n",
      "Epoch: 00 | Batch: 003 / 011 | Total loss: 1.716 | Reg loss: 0.011 | Tree loss: 1.716 | Accuracy: 0.372500 | 0.254 sec/iter\n",
      "Epoch: 00 | Batch: 004 / 011 | Total loss: 1.719 | Reg loss: 0.011 | Tree loss: 1.719 | Accuracy: 0.337000 | 0.225 sec/iter\n",
      "Epoch: 00 | Batch: 005 / 011 | Total loss: 1.695 | Reg loss: 0.011 | Tree loss: 1.695 | Accuracy: 0.363500 | 0.207 sec/iter\n",
      "Epoch: 00 | Batch: 006 / 011 | Total loss: 1.683 | Reg loss: 0.011 | Tree loss: 1.683 | Accuracy: 0.367500 | 0.193 sec/iter\n",
      "Epoch: 00 | Batch: 007 / 011 | Total loss: 1.683 | Reg loss: 0.011 | Tree loss: 1.683 | Accuracy: 0.340000 | 0.183 sec/iter\n",
      "Epoch: 00 | Batch: 008 / 011 | Total loss: 1.663 | Reg loss: 0.011 | Tree loss: 1.663 | Accuracy: 0.371000 | 0.174 sec/iter\n",
      "Epoch: 00 | Batch: 009 / 011 | Total loss: 1.655 | Reg loss: 0.012 | Tree loss: 1.655 | Accuracy: 0.406500 | 0.168 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 011 | Total loss: 1.650 | Reg loss: 0.012 | Tree loss: 1.650 | Accuracy: 0.406143 | 0.163 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 01 | Batch: 000 / 011 | Total loss: 1.743 | Reg loss: 0.010 | Tree loss: 1.743 | Accuracy: 0.359500 | 0.212 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 011 | Total loss: 1.727 | Reg loss: 0.010 | Tree loss: 1.727 | Accuracy: 0.361000 | 0.214 sec/iter\n",
      "Epoch: 01 | Batch: 002 / 011 | Total loss: 1.714 | Reg loss: 0.010 | Tree loss: 1.714 | Accuracy: 0.361000 | 0.204 sec/iter\n",
      "Epoch: 01 | Batch: 003 / 011 | Total loss: 1.702 | Reg loss: 0.010 | Tree loss: 1.702 | Accuracy: 0.360500 | 0.196 sec/iter\n",
      "Epoch: 01 | Batch: 004 / 011 | Total loss: 1.695 | Reg loss: 0.010 | Tree loss: 1.695 | Accuracy: 0.342500 | 0.188 sec/iter\n",
      "Epoch: 01 | Batch: 005 / 011 | Total loss: 1.674 | Reg loss: 0.010 | Tree loss: 1.674 | Accuracy: 0.375000 | 0.181 sec/iter\n",
      "Epoch: 01 | Batch: 006 / 011 | Total loss: 1.662 | Reg loss: 0.011 | Tree loss: 1.662 | Accuracy: 0.408000 | 0.176 sec/iter\n",
      "Epoch: 01 | Batch: 007 / 011 | Total loss: 1.635 | Reg loss: 0.011 | Tree loss: 1.635 | Accuracy: 0.428500 | 0.172 sec/iter\n",
      "Epoch: 01 | Batch: 008 / 011 | Total loss: 1.637 | Reg loss: 0.011 | Tree loss: 1.637 | Accuracy: 0.409500 | 0.167 sec/iter\n",
      "Epoch: 01 | Batch: 009 / 011 | Total loss: 1.614 | Reg loss: 0.011 | Tree loss: 1.614 | Accuracy: 0.437500 | 0.164 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 011 | Total loss: 1.624 | Reg loss: 0.012 | Tree loss: 1.624 | Accuracy: 0.392491 | 0.161 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 02 | Batch: 000 / 011 | Total loss: 1.725 | Reg loss: 0.010 | Tree loss: 1.725 | Accuracy: 0.359000 | 0.195 sec/iter\n",
      "Epoch: 02 | Batch: 001 / 011 | Total loss: 1.712 | Reg loss: 0.010 | Tree loss: 1.712 | Accuracy: 0.342000 | 0.192 sec/iter\n",
      "Epoch: 02 | Batch: 002 / 011 | Total loss: 1.694 | Reg loss: 0.010 | Tree loss: 1.694 | Accuracy: 0.349000 | 0.189 sec/iter\n",
      "Epoch: 02 | Batch: 003 / 011 | Total loss: 1.669 | Reg loss: 0.010 | Tree loss: 1.669 | Accuracy: 0.406000 | 0.186 sec/iter\n",
      "Epoch: 02 | Batch: 004 / 011 | Total loss: 1.659 | Reg loss: 0.010 | Tree loss: 1.659 | Accuracy: 0.407000 | 0.183 sec/iter\n",
      "Epoch: 02 | Batch: 005 / 011 | Total loss: 1.641 | Reg loss: 0.011 | Tree loss: 1.641 | Accuracy: 0.423500 | 0.181 sec/iter\n",
      "Epoch: 02 | Batch: 006 / 011 | Total loss: 1.625 | Reg loss: 0.011 | Tree loss: 1.625 | Accuracy: 0.429500 | 0.178 sec/iter\n",
      "Epoch: 02 | Batch: 007 / 011 | Total loss: 1.605 | Reg loss: 0.011 | Tree loss: 1.605 | Accuracy: 0.442500 | 0.176 sec/iter\n",
      "Epoch: 02 | Batch: 008 / 011 | Total loss: 1.609 | Reg loss: 0.011 | Tree loss: 1.609 | Accuracy: 0.410500 | 0.174 sec/iter\n",
      "Epoch: 02 | Batch: 009 / 011 | Total loss: 1.582 | Reg loss: 0.012 | Tree loss: 1.582 | Accuracy: 0.438000 | 0.172 sec/iter\n",
      "Epoch: 02 | Batch: 010 / 011 | Total loss: 1.588 | Reg loss: 0.012 | Tree loss: 1.588 | Accuracy: 0.409556 | 0.17 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 03 | Batch: 000 / 011 | Total loss: 1.713 | Reg loss: 0.010 | Tree loss: 1.713 | Accuracy: 0.339500 | 0.202 sec/iter\n",
      "Epoch: 03 | Batch: 001 / 011 | Total loss: 1.685 | Reg loss: 0.010 | Tree loss: 1.685 | Accuracy: 0.362000 | 0.199 sec/iter\n",
      "Epoch: 03 | Batch: 002 / 011 | Total loss: 1.668 | Reg loss: 0.011 | Tree loss: 1.668 | Accuracy: 0.402500 | 0.196 sec/iter\n",
      "Epoch: 03 | Batch: 003 / 011 | Total loss: 1.646 | Reg loss: 0.011 | Tree loss: 1.646 | Accuracy: 0.422500 | 0.194 sec/iter\n",
      "Epoch: 03 | Batch: 004 / 011 | Total loss: 1.631 | Reg loss: 0.011 | Tree loss: 1.631 | Accuracy: 0.417000 | 0.191 sec/iter\n",
      "Epoch: 03 | Batch: 005 / 011 | Total loss: 1.614 | Reg loss: 0.011 | Tree loss: 1.614 | Accuracy: 0.421500 | 0.189 sec/iter\n",
      "Epoch: 03 | Batch: 006 / 011 | Total loss: 1.594 | Reg loss: 0.011 | Tree loss: 1.594 | Accuracy: 0.427500 | 0.187 sec/iter\n",
      "Epoch: 03 | Batch: 007 / 011 | Total loss: 1.578 | Reg loss: 0.012 | Tree loss: 1.578 | Accuracy: 0.439000 | 0.185 sec/iter\n",
      "Epoch: 03 | Batch: 008 / 011 | Total loss: 1.551 | Reg loss: 0.012 | Tree loss: 1.551 | Accuracy: 0.465000 | 0.183 sec/iter\n",
      "Epoch: 03 | Batch: 009 / 011 | Total loss: 1.541 | Reg loss: 0.012 | Tree loss: 1.541 | Accuracy: 0.492500 | 0.181 sec/iter\n",
      "Epoch: 03 | Batch: 010 / 011 | Total loss: 1.554 | Reg loss: 0.013 | Tree loss: 1.554 | Accuracy: 0.474403 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 04 | Batch: 000 / 011 | Total loss: 1.683 | Reg loss: 0.011 | Tree loss: 1.683 | Accuracy: 0.380500 | 0.203 sec/iter\n",
      "Epoch: 04 | Batch: 001 / 011 | Total loss: 1.668 | Reg loss: 0.011 | Tree loss: 1.668 | Accuracy: 0.394000 | 0.201 sec/iter\n",
      "Epoch: 04 | Batch: 002 / 011 | Total loss: 1.638 | Reg loss: 0.011 | Tree loss: 1.638 | Accuracy: 0.434500 | 0.199 sec/iter\n",
      "Epoch: 04 | Batch: 003 / 011 | Total loss: 1.629 | Reg loss: 0.011 | Tree loss: 1.629 | Accuracy: 0.407500 | 0.196 sec/iter\n",
      "Epoch: 04 | Batch: 004 / 011 | Total loss: 1.600 | Reg loss: 0.011 | Tree loss: 1.600 | Accuracy: 0.430500 | 0.195 sec/iter\n",
      "Epoch: 04 | Batch: 005 / 011 | Total loss: 1.574 | Reg loss: 0.012 | Tree loss: 1.574 | Accuracy: 0.460000 | 0.193 sec/iter\n",
      "Epoch: 04 | Batch: 006 / 011 | Total loss: 1.565 | Reg loss: 0.012 | Tree loss: 1.565 | Accuracy: 0.467500 | 0.191 sec/iter\n",
      "Epoch: 04 | Batch: 007 / 011 | Total loss: 1.530 | Reg loss: 0.012 | Tree loss: 1.530 | Accuracy: 0.527500 | 0.189 sec/iter\n",
      "Epoch: 04 | Batch: 008 / 011 | Total loss: 1.509 | Reg loss: 0.012 | Tree loss: 1.509 | Accuracy: 0.571000 | 0.187 sec/iter\n",
      "Epoch: 04 | Batch: 009 / 011 | Total loss: 1.499 | Reg loss: 0.013 | Tree loss: 1.499 | Accuracy: 0.580500 | 0.186 sec/iter\n",
      "Epoch: 04 | Batch: 010 / 011 | Total loss: 1.486 | Reg loss: 0.013 | Tree loss: 1.486 | Accuracy: 0.552901 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 05 | Batch: 000 / 011 | Total loss: 1.655 | Reg loss: 0.011 | Tree loss: 1.655 | Accuracy: 0.433500 | 0.203 sec/iter\n",
      "Epoch: 05 | Batch: 001 / 011 | Total loss: 1.633 | Reg loss: 0.012 | Tree loss: 1.633 | Accuracy: 0.439000 | 0.201 sec/iter\n",
      "Epoch: 05 | Batch: 002 / 011 | Total loss: 1.612 | Reg loss: 0.012 | Tree loss: 1.612 | Accuracy: 0.437000 | 0.2 sec/iter\n",
      "Epoch: 05 | Batch: 003 / 011 | Total loss: 1.586 | Reg loss: 0.012 | Tree loss: 1.586 | Accuracy: 0.456500 | 0.198 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Batch: 004 / 011 | Total loss: 1.560 | Reg loss: 0.012 | Tree loss: 1.560 | Accuracy: 0.450500 | 0.197 sec/iter\n",
      "Epoch: 05 | Batch: 005 / 011 | Total loss: 1.548 | Reg loss: 0.012 | Tree loss: 1.548 | Accuracy: 0.442500 | 0.195 sec/iter\n",
      "Epoch: 05 | Batch: 006 / 011 | Total loss: 1.509 | Reg loss: 0.013 | Tree loss: 1.509 | Accuracy: 0.482500 | 0.194 sec/iter\n",
      "Epoch: 05 | Batch: 007 / 011 | Total loss: 1.499 | Reg loss: 0.013 | Tree loss: 1.499 | Accuracy: 0.497500 | 0.193 sec/iter\n",
      "Epoch: 05 | Batch: 008 / 011 | Total loss: 1.475 | Reg loss: 0.013 | Tree loss: 1.475 | Accuracy: 0.533500 | 0.191 sec/iter\n",
      "Epoch: 05 | Batch: 009 / 011 | Total loss: 1.461 | Reg loss: 0.014 | Tree loss: 1.461 | Accuracy: 0.566500 | 0.19 sec/iter\n",
      "Epoch: 05 | Batch: 010 / 011 | Total loss: 1.462 | Reg loss: 0.014 | Tree loss: 1.462 | Accuracy: 0.587031 | 0.189 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 06 | Batch: 000 / 011 | Total loss: 1.626 | Reg loss: 0.012 | Tree loss: 1.626 | Accuracy: 0.480500 | 0.205 sec/iter\n",
      "Epoch: 06 | Batch: 001 / 011 | Total loss: 1.604 | Reg loss: 0.012 | Tree loss: 1.604 | Accuracy: 0.469000 | 0.203 sec/iter\n",
      "Epoch: 06 | Batch: 002 / 011 | Total loss: 1.577 | Reg loss: 0.012 | Tree loss: 1.577 | Accuracy: 0.461500 | 0.202 sec/iter\n",
      "Epoch: 06 | Batch: 003 / 011 | Total loss: 1.550 | Reg loss: 0.013 | Tree loss: 1.550 | Accuracy: 0.469000 | 0.201 sec/iter\n",
      "Epoch: 06 | Batch: 004 / 011 | Total loss: 1.519 | Reg loss: 0.013 | Tree loss: 1.519 | Accuracy: 0.501000 | 0.199 sec/iter\n",
      "Epoch: 06 | Batch: 005 / 011 | Total loss: 1.501 | Reg loss: 0.013 | Tree loss: 1.501 | Accuracy: 0.503000 | 0.198 sec/iter\n",
      "Epoch: 06 | Batch: 006 / 011 | Total loss: 1.473 | Reg loss: 0.013 | Tree loss: 1.473 | Accuracy: 0.532500 | 0.197 sec/iter\n",
      "Epoch: 06 | Batch: 007 / 011 | Total loss: 1.459 | Reg loss: 0.014 | Tree loss: 1.459 | Accuracy: 0.555500 | 0.196 sec/iter\n",
      "Epoch: 06 | Batch: 008 / 011 | Total loss: 1.434 | Reg loss: 0.014 | Tree loss: 1.434 | Accuracy: 0.607500 | 0.195 sec/iter\n",
      "Epoch: 06 | Batch: 009 / 011 | Total loss: 1.417 | Reg loss: 0.014 | Tree loss: 1.417 | Accuracy: 0.632500 | 0.194 sec/iter\n",
      "Epoch: 06 | Batch: 010 / 011 | Total loss: 1.409 | Reg loss: 0.015 | Tree loss: 1.409 | Accuracy: 0.617747 | 0.192 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 07 | Batch: 000 / 011 | Total loss: 1.602 | Reg loss: 0.013 | Tree loss: 1.602 | Accuracy: 0.493000 | 0.206 sec/iter\n",
      "Epoch: 07 | Batch: 001 / 011 | Total loss: 1.564 | Reg loss: 0.013 | Tree loss: 1.564 | Accuracy: 0.497000 | 0.205 sec/iter\n",
      "Epoch: 07 | Batch: 002 / 011 | Total loss: 1.531 | Reg loss: 0.013 | Tree loss: 1.531 | Accuracy: 0.499500 | 0.204 sec/iter\n",
      "Epoch: 07 | Batch: 003 / 011 | Total loss: 1.522 | Reg loss: 0.013 | Tree loss: 1.522 | Accuracy: 0.501000 | 0.202 sec/iter\n",
      "Epoch: 07 | Batch: 004 / 011 | Total loss: 1.469 | Reg loss: 0.014 | Tree loss: 1.469 | Accuracy: 0.542500 | 0.201 sec/iter\n",
      "Epoch: 07 | Batch: 005 / 011 | Total loss: 1.454 | Reg loss: 0.014 | Tree loss: 1.454 | Accuracy: 0.536500 | 0.2 sec/iter\n",
      "Epoch: 07 | Batch: 006 / 011 | Total loss: 1.435 | Reg loss: 0.014 | Tree loss: 1.435 | Accuracy: 0.574500 | 0.199 sec/iter\n",
      "Epoch: 07 | Batch: 007 / 011 | Total loss: 1.415 | Reg loss: 0.014 | Tree loss: 1.415 | Accuracy: 0.617000 | 0.198 sec/iter\n",
      "Epoch: 07 | Batch: 008 / 011 | Total loss: 1.385 | Reg loss: 0.015 | Tree loss: 1.385 | Accuracy: 0.660500 | 0.197 sec/iter\n",
      "Epoch: 07 | Batch: 009 / 011 | Total loss: 1.363 | Reg loss: 0.015 | Tree loss: 1.363 | Accuracy: 0.665000 | 0.196 sec/iter\n",
      "Epoch: 07 | Batch: 010 / 011 | Total loss: 1.354 | Reg loss: 0.015 | Tree loss: 1.354 | Accuracy: 0.682594 | 0.195 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 08 | Batch: 000 / 011 | Total loss: 1.561 | Reg loss: 0.014 | Tree loss: 1.561 | Accuracy: 0.511500 | 0.205 sec/iter\n",
      "Epoch: 08 | Batch: 001 / 011 | Total loss: 1.530 | Reg loss: 0.014 | Tree loss: 1.530 | Accuracy: 0.519500 | 0.204 sec/iter\n",
      "Epoch: 08 | Batch: 002 / 011 | Total loss: 1.502 | Reg loss: 0.014 | Tree loss: 1.502 | Accuracy: 0.526500 | 0.203 sec/iter\n",
      "Epoch: 08 | Batch: 003 / 011 | Total loss: 1.473 | Reg loss: 0.014 | Tree loss: 1.473 | Accuracy: 0.524000 | 0.202 sec/iter\n",
      "Epoch: 08 | Batch: 004 / 011 | Total loss: 1.433 | Reg loss: 0.014 | Tree loss: 1.433 | Accuracy: 0.562500 | 0.2 sec/iter\n",
      "Epoch: 08 | Batch: 005 / 011 | Total loss: 1.419 | Reg loss: 0.015 | Tree loss: 1.419 | Accuracy: 0.581500 | 0.199 sec/iter\n",
      "Epoch: 08 | Batch: 006 / 011 | Total loss: 1.386 | Reg loss: 0.015 | Tree loss: 1.386 | Accuracy: 0.634500 | 0.198 sec/iter\n",
      "Epoch: 08 | Batch: 007 / 011 | Total loss: 1.360 | Reg loss: 0.015 | Tree loss: 1.360 | Accuracy: 0.651000 | 0.197 sec/iter\n",
      "Epoch: 08 | Batch: 008 / 011 | Total loss: 1.343 | Reg loss: 0.015 | Tree loss: 1.343 | Accuracy: 0.663500 | 0.195 sec/iter\n",
      "Epoch: 08 | Batch: 009 / 011 | Total loss: 1.322 | Reg loss: 0.016 | Tree loss: 1.322 | Accuracy: 0.667000 | 0.194 sec/iter\n",
      "Epoch: 08 | Batch: 010 / 011 | Total loss: 1.260 | Reg loss: 0.016 | Tree loss: 1.260 | Accuracy: 0.699659 | 0.193 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 09 | Batch: 000 / 011 | Total loss: 1.523 | Reg loss: 0.015 | Tree loss: 1.523 | Accuracy: 0.538000 | 0.192 sec/iter\n",
      "Epoch: 09 | Batch: 001 / 011 | Total loss: 1.484 | Reg loss: 0.015 | Tree loss: 1.484 | Accuracy: 0.550000 | 0.191 sec/iter\n",
      "Epoch: 09 | Batch: 002 / 011 | Total loss: 1.459 | Reg loss: 0.015 | Tree loss: 1.459 | Accuracy: 0.559500 | 0.19 sec/iter\n",
      "Epoch: 09 | Batch: 003 / 011 | Total loss: 1.423 | Reg loss: 0.015 | Tree loss: 1.423 | Accuracy: 0.568000 | 0.189 sec/iter\n",
      "Epoch: 09 | Batch: 004 / 011 | Total loss: 1.398 | Reg loss: 0.015 | Tree loss: 1.398 | Accuracy: 0.553000 | 0.188 sec/iter\n",
      "Epoch: 09 | Batch: 005 / 011 | Total loss: 1.373 | Reg loss: 0.015 | Tree loss: 1.373 | Accuracy: 0.551500 | 0.187 sec/iter\n",
      "Epoch: 09 | Batch: 006 / 011 | Total loss: 1.349 | Reg loss: 0.016 | Tree loss: 1.349 | Accuracy: 0.574500 | 0.186 sec/iter\n",
      "Epoch: 09 | Batch: 007 / 011 | Total loss: 1.305 | Reg loss: 0.016 | Tree loss: 1.305 | Accuracy: 0.637500 | 0.185 sec/iter\n",
      "Epoch: 09 | Batch: 008 / 011 | Total loss: 1.292 | Reg loss: 0.016 | Tree loss: 1.292 | Accuracy: 0.673500 | 0.185 sec/iter\n",
      "Epoch: 09 | Batch: 009 / 011 | Total loss: 1.282 | Reg loss: 0.016 | Tree loss: 1.282 | Accuracy: 0.664000 | 0.184 sec/iter\n",
      "Epoch: 09 | Batch: 010 / 011 | Total loss: 1.277 | Reg loss: 0.017 | Tree loss: 1.277 | Accuracy: 0.689420 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 10 | Batch: 000 / 011 | Total loss: 1.478 | Reg loss: 0.015 | Tree loss: 1.478 | Accuracy: 0.574500 | 0.193 sec/iter\n",
      "Epoch: 10 | Batch: 001 / 011 | Total loss: 1.456 | Reg loss: 0.015 | Tree loss: 1.456 | Accuracy: 0.573500 | 0.192 sec/iter\n",
      "Epoch: 10 | Batch: 002 / 011 | Total loss: 1.420 | Reg loss: 0.016 | Tree loss: 1.420 | Accuracy: 0.597000 | 0.191 sec/iter\n",
      "Epoch: 10 | Batch: 003 / 011 | Total loss: 1.373 | Reg loss: 0.016 | Tree loss: 1.373 | Accuracy: 0.618500 | 0.19 sec/iter\n",
      "Epoch: 10 | Batch: 004 / 011 | Total loss: 1.365 | Reg loss: 0.016 | Tree loss: 1.365 | Accuracy: 0.614000 | 0.189 sec/iter\n",
      "Epoch: 10 | Batch: 005 / 011 | Total loss: 1.319 | Reg loss: 0.016 | Tree loss: 1.319 | Accuracy: 0.669500 | 0.189 sec/iter\n",
      "Epoch: 10 | Batch: 006 / 011 | Total loss: 1.298 | Reg loss: 0.016 | Tree loss: 1.298 | Accuracy: 0.682500 | 0.188 sec/iter\n",
      "Epoch: 10 | Batch: 007 / 011 | Total loss: 1.269 | Reg loss: 0.017 | Tree loss: 1.269 | Accuracy: 0.691000 | 0.187 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Batch: 008 / 011 | Total loss: 1.249 | Reg loss: 0.017 | Tree loss: 1.249 | Accuracy: 0.718000 | 0.186 sec/iter\n",
      "Epoch: 10 | Batch: 009 / 011 | Total loss: 1.227 | Reg loss: 0.017 | Tree loss: 1.227 | Accuracy: 0.728500 | 0.186 sec/iter\n",
      "Epoch: 10 | Batch: 010 / 011 | Total loss: 1.211 | Reg loss: 0.017 | Tree loss: 1.211 | Accuracy: 0.754266 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 11 | Batch: 000 / 011 | Total loss: 1.448 | Reg loss: 0.016 | Tree loss: 1.448 | Accuracy: 0.598000 | 0.194 sec/iter\n",
      "Epoch: 11 | Batch: 001 / 011 | Total loss: 1.400 | Reg loss: 0.016 | Tree loss: 1.400 | Accuracy: 0.622000 | 0.193 sec/iter\n",
      "Epoch: 11 | Batch: 002 / 011 | Total loss: 1.384 | Reg loss: 0.016 | Tree loss: 1.384 | Accuracy: 0.587500 | 0.192 sec/iter\n",
      "Epoch: 11 | Batch: 003 / 011 | Total loss: 1.346 | Reg loss: 0.016 | Tree loss: 1.346 | Accuracy: 0.580000 | 0.191 sec/iter\n",
      "Epoch: 11 | Batch: 004 / 011 | Total loss: 1.307 | Reg loss: 0.017 | Tree loss: 1.307 | Accuracy: 0.599000 | 0.191 sec/iter\n",
      "Epoch: 11 | Batch: 005 / 011 | Total loss: 1.277 | Reg loss: 0.017 | Tree loss: 1.277 | Accuracy: 0.621000 | 0.19 sec/iter\n",
      "Epoch: 11 | Batch: 006 / 011 | Total loss: 1.247 | Reg loss: 0.017 | Tree loss: 1.247 | Accuracy: 0.653000 | 0.189 sec/iter\n",
      "Epoch: 11 | Batch: 007 / 011 | Total loss: 1.225 | Reg loss: 0.017 | Tree loss: 1.225 | Accuracy: 0.672000 | 0.189 sec/iter\n",
      "Epoch: 11 | Batch: 008 / 011 | Total loss: 1.217 | Reg loss: 0.017 | Tree loss: 1.217 | Accuracy: 0.660500 | 0.188 sec/iter\n",
      "Epoch: 11 | Batch: 009 / 011 | Total loss: 1.193 | Reg loss: 0.018 | Tree loss: 1.193 | Accuracy: 0.703000 | 0.187 sec/iter\n",
      "Epoch: 11 | Batch: 010 / 011 | Total loss: 1.201 | Reg loss: 0.018 | Tree loss: 1.201 | Accuracy: 0.665529 | 0.187 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 12 | Batch: 000 / 011 | Total loss: 1.410 | Reg loss: 0.017 | Tree loss: 1.410 | Accuracy: 0.610500 | 0.195 sec/iter\n",
      "Epoch: 12 | Batch: 001 / 011 | Total loss: 1.374 | Reg loss: 0.017 | Tree loss: 1.374 | Accuracy: 0.617500 | 0.194 sec/iter\n",
      "Epoch: 12 | Batch: 002 / 011 | Total loss: 1.335 | Reg loss: 0.017 | Tree loss: 1.335 | Accuracy: 0.626000 | 0.193 sec/iter\n",
      "Epoch: 12 | Batch: 003 / 011 | Total loss: 1.309 | Reg loss: 0.017 | Tree loss: 1.309 | Accuracy: 0.665000 | 0.193 sec/iter\n",
      "Epoch: 12 | Batch: 004 / 011 | Total loss: 1.264 | Reg loss: 0.017 | Tree loss: 1.264 | Accuracy: 0.699000 | 0.192 sec/iter\n",
      "Epoch: 12 | Batch: 005 / 011 | Total loss: 1.219 | Reg loss: 0.017 | Tree loss: 1.219 | Accuracy: 0.714500 | 0.192 sec/iter\n",
      "Epoch: 12 | Batch: 006 / 011 | Total loss: 1.217 | Reg loss: 0.018 | Tree loss: 1.217 | Accuracy: 0.728000 | 0.191 sec/iter\n",
      "Epoch: 12 | Batch: 007 / 011 | Total loss: 1.182 | Reg loss: 0.018 | Tree loss: 1.182 | Accuracy: 0.748000 | 0.19 sec/iter\n",
      "Epoch: 12 | Batch: 008 / 011 | Total loss: 1.170 | Reg loss: 0.018 | Tree loss: 1.170 | Accuracy: 0.756000 | 0.19 sec/iter\n",
      "Epoch: 12 | Batch: 009 / 011 | Total loss: 1.148 | Reg loss: 0.018 | Tree loss: 1.148 | Accuracy: 0.748000 | 0.189 sec/iter\n",
      "Epoch: 12 | Batch: 010 / 011 | Total loss: 1.117 | Reg loss: 0.019 | Tree loss: 1.117 | Accuracy: 0.774744 | 0.189 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 13 | Batch: 000 / 011 | Total loss: 1.382 | Reg loss: 0.017 | Tree loss: 1.382 | Accuracy: 0.616500 | 0.196 sec/iter\n",
      "Epoch: 13 | Batch: 001 / 011 | Total loss: 1.335 | Reg loss: 0.018 | Tree loss: 1.335 | Accuracy: 0.641000 | 0.195 sec/iter\n",
      "Epoch: 13 | Batch: 002 / 011 | Total loss: 1.305 | Reg loss: 0.018 | Tree loss: 1.305 | Accuracy: 0.648000 | 0.195 sec/iter\n",
      "Epoch: 13 | Batch: 003 / 011 | Total loss: 1.264 | Reg loss: 0.018 | Tree loss: 1.264 | Accuracy: 0.662500 | 0.194 sec/iter\n",
      "Epoch: 13 | Batch: 004 / 011 | Total loss: 1.224 | Reg loss: 0.018 | Tree loss: 1.224 | Accuracy: 0.672000 | 0.193 sec/iter\n",
      "Epoch: 13 | Batch: 005 / 011 | Total loss: 1.205 | Reg loss: 0.018 | Tree loss: 1.205 | Accuracy: 0.706500 | 0.193 sec/iter\n",
      "Epoch: 13 | Batch: 006 / 011 | Total loss: 1.163 | Reg loss: 0.018 | Tree loss: 1.163 | Accuracy: 0.704000 | 0.192 sec/iter\n",
      "Epoch: 13 | Batch: 007 / 011 | Total loss: 1.136 | Reg loss: 0.018 | Tree loss: 1.136 | Accuracy: 0.716000 | 0.191 sec/iter\n",
      "Epoch: 13 | Batch: 008 / 011 | Total loss: 1.126 | Reg loss: 0.019 | Tree loss: 1.126 | Accuracy: 0.734500 | 0.191 sec/iter\n",
      "Epoch: 13 | Batch: 009 / 011 | Total loss: 1.094 | Reg loss: 0.019 | Tree loss: 1.094 | Accuracy: 0.734500 | 0.19 sec/iter\n",
      "Epoch: 13 | Batch: 010 / 011 | Total loss: 1.134 | Reg loss: 0.019 | Tree loss: 1.134 | Accuracy: 0.672355 | 0.19 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 14 | Batch: 000 / 011 | Total loss: 1.325 | Reg loss: 0.018 | Tree loss: 1.325 | Accuracy: 0.659000 | 0.196 sec/iter\n",
      "Epoch: 14 | Batch: 001 / 011 | Total loss: 1.291 | Reg loss: 0.018 | Tree loss: 1.291 | Accuracy: 0.653500 | 0.196 sec/iter\n",
      "Epoch: 14 | Batch: 002 / 011 | Total loss: 1.252 | Reg loss: 0.018 | Tree loss: 1.252 | Accuracy: 0.676500 | 0.195 sec/iter\n",
      "Epoch: 14 | Batch: 003 / 011 | Total loss: 1.223 | Reg loss: 0.018 | Tree loss: 1.223 | Accuracy: 0.690000 | 0.195 sec/iter\n",
      "Epoch: 14 | Batch: 004 / 011 | Total loss: 1.196 | Reg loss: 0.019 | Tree loss: 1.196 | Accuracy: 0.688500 | 0.194 sec/iter\n",
      "Epoch: 14 | Batch: 005 / 011 | Total loss: 1.147 | Reg loss: 0.019 | Tree loss: 1.147 | Accuracy: 0.718000 | 0.193 sec/iter\n",
      "Epoch: 14 | Batch: 006 / 011 | Total loss: 1.143 | Reg loss: 0.019 | Tree loss: 1.143 | Accuracy: 0.715500 | 0.193 sec/iter\n",
      "Epoch: 14 | Batch: 007 / 011 | Total loss: 1.095 | Reg loss: 0.019 | Tree loss: 1.095 | Accuracy: 0.751000 | 0.192 sec/iter\n",
      "Epoch: 14 | Batch: 008 / 011 | Total loss: 1.083 | Reg loss: 0.019 | Tree loss: 1.083 | Accuracy: 0.764500 | 0.192 sec/iter\n",
      "Epoch: 14 | Batch: 009 / 011 | Total loss: 1.086 | Reg loss: 0.020 | Tree loss: 1.086 | Accuracy: 0.749500 | 0.191 sec/iter\n",
      "Epoch: 14 | Batch: 010 / 011 | Total loss: 1.067 | Reg loss: 0.020 | Tree loss: 1.067 | Accuracy: 0.757679 | 0.191 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 15 | Batch: 000 / 011 | Total loss: 1.283 | Reg loss: 0.019 | Tree loss: 1.283 | Accuracy: 0.682000 | 0.197 sec/iter\n",
      "Epoch: 15 | Batch: 001 / 011 | Total loss: 1.271 | Reg loss: 0.019 | Tree loss: 1.271 | Accuracy: 0.664500 | 0.196 sec/iter\n",
      "Epoch: 15 | Batch: 002 / 011 | Total loss: 1.216 | Reg loss: 0.019 | Tree loss: 1.216 | Accuracy: 0.685500 | 0.196 sec/iter\n",
      "Epoch: 15 | Batch: 003 / 011 | Total loss: 1.186 | Reg loss: 0.019 | Tree loss: 1.186 | Accuracy: 0.686500 | 0.195 sec/iter\n",
      "Epoch: 15 | Batch: 004 / 011 | Total loss: 1.159 | Reg loss: 0.019 | Tree loss: 1.159 | Accuracy: 0.683000 | 0.195 sec/iter\n",
      "Epoch: 15 | Batch: 005 / 011 | Total loss: 1.117 | Reg loss: 0.019 | Tree loss: 1.117 | Accuracy: 0.705500 | 0.194 sec/iter\n",
      "Epoch: 15 | Batch: 006 / 011 | Total loss: 1.085 | Reg loss: 0.019 | Tree loss: 1.085 | Accuracy: 0.730500 | 0.194 sec/iter\n",
      "Epoch: 15 | Batch: 007 / 011 | Total loss: 1.075 | Reg loss: 0.020 | Tree loss: 1.075 | Accuracy: 0.737500 | 0.193 sec/iter\n",
      "Epoch: 15 | Batch: 008 / 011 | Total loss: 1.046 | Reg loss: 0.020 | Tree loss: 1.046 | Accuracy: 0.767500 | 0.193 sec/iter\n",
      "Epoch: 15 | Batch: 009 / 011 | Total loss: 1.035 | Reg loss: 0.020 | Tree loss: 1.035 | Accuracy: 0.758500 | 0.192 sec/iter\n",
      "Epoch: 15 | Batch: 010 / 011 | Total loss: 1.039 | Reg loss: 0.020 | Tree loss: 1.039 | Accuracy: 0.761092 | 0.191 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Batch: 000 / 011 | Total loss: 1.266 | Reg loss: 0.019 | Tree loss: 1.266 | Accuracy: 0.668500 | 0.196 sec/iter\n",
      "Epoch: 16 | Batch: 001 / 011 | Total loss: 1.219 | Reg loss: 0.019 | Tree loss: 1.219 | Accuracy: 0.676500 | 0.195 sec/iter\n",
      "Epoch: 16 | Batch: 002 / 011 | Total loss: 1.189 | Reg loss: 0.019 | Tree loss: 1.189 | Accuracy: 0.674500 | 0.195 sec/iter\n",
      "Epoch: 16 | Batch: 003 / 011 | Total loss: 1.147 | Reg loss: 0.020 | Tree loss: 1.147 | Accuracy: 0.715000 | 0.194 sec/iter\n",
      "Epoch: 16 | Batch: 004 / 011 | Total loss: 1.107 | Reg loss: 0.020 | Tree loss: 1.107 | Accuracy: 0.717000 | 0.193 sec/iter\n",
      "Epoch: 16 | Batch: 005 / 011 | Total loss: 1.091 | Reg loss: 0.020 | Tree loss: 1.091 | Accuracy: 0.728000 | 0.193 sec/iter\n",
      "Epoch: 16 | Batch: 006 / 011 | Total loss: 1.047 | Reg loss: 0.020 | Tree loss: 1.047 | Accuracy: 0.742000 | 0.192 sec/iter\n",
      "Epoch: 16 | Batch: 007 / 011 | Total loss: 1.040 | Reg loss: 0.020 | Tree loss: 1.040 | Accuracy: 0.762000 | 0.191 sec/iter\n",
      "Epoch: 16 | Batch: 008 / 011 | Total loss: 1.023 | Reg loss: 0.020 | Tree loss: 1.023 | Accuracy: 0.748000 | 0.19 sec/iter\n",
      "Epoch: 16 | Batch: 009 / 011 | Total loss: 0.998 | Reg loss: 0.021 | Tree loss: 0.998 | Accuracy: 0.769000 | 0.19 sec/iter\n",
      "Epoch: 16 | Batch: 010 / 011 | Total loss: 0.970 | Reg loss: 0.021 | Tree loss: 0.970 | Accuracy: 0.778157 | 0.189 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 17 | Batch: 000 / 011 | Total loss: 1.218 | Reg loss: 0.020 | Tree loss: 1.218 | Accuracy: 0.693500 | 0.189 sec/iter\n",
      "Epoch: 17 | Batch: 001 / 011 | Total loss: 1.189 | Reg loss: 0.020 | Tree loss: 1.189 | Accuracy: 0.696000 | 0.188 sec/iter\n",
      "Epoch: 17 | Batch: 002 / 011 | Total loss: 1.140 | Reg loss: 0.020 | Tree loss: 1.140 | Accuracy: 0.716500 | 0.187 sec/iter\n",
      "Epoch: 17 | Batch: 003 / 011 | Total loss: 1.106 | Reg loss: 0.020 | Tree loss: 1.106 | Accuracy: 0.724000 | 0.187 sec/iter\n",
      "Epoch: 17 | Batch: 004 / 011 | Total loss: 1.088 | Reg loss: 0.020 | Tree loss: 1.088 | Accuracy: 0.704000 | 0.186 sec/iter\n",
      "Epoch: 17 | Batch: 005 / 011 | Total loss: 1.052 | Reg loss: 0.020 | Tree loss: 1.052 | Accuracy: 0.728500 | 0.186 sec/iter\n",
      "Epoch: 17 | Batch: 006 / 011 | Total loss: 1.021 | Reg loss: 0.020 | Tree loss: 1.021 | Accuracy: 0.737500 | 0.185 sec/iter\n",
      "Epoch: 17 | Batch: 007 / 011 | Total loss: 0.994 | Reg loss: 0.021 | Tree loss: 0.994 | Accuracy: 0.757500 | 0.185 sec/iter\n",
      "Epoch: 17 | Batch: 008 / 011 | Total loss: 0.994 | Reg loss: 0.021 | Tree loss: 0.994 | Accuracy: 0.768000 | 0.184 sec/iter\n",
      "Epoch: 17 | Batch: 009 / 011 | Total loss: 0.973 | Reg loss: 0.021 | Tree loss: 0.973 | Accuracy: 0.766500 | 0.184 sec/iter\n",
      "Epoch: 17 | Batch: 010 / 011 | Total loss: 1.009 | Reg loss: 0.021 | Tree loss: 1.009 | Accuracy: 0.726962 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 18 | Batch: 000 / 011 | Total loss: 1.189 | Reg loss: 0.020 | Tree loss: 1.189 | Accuracy: 0.698000 | 0.189 sec/iter\n",
      "Epoch: 18 | Batch: 001 / 011 | Total loss: 1.149 | Reg loss: 0.020 | Tree loss: 1.149 | Accuracy: 0.712500 | 0.188 sec/iter\n",
      "Epoch: 18 | Batch: 002 / 011 | Total loss: 1.104 | Reg loss: 0.020 | Tree loss: 1.104 | Accuracy: 0.723000 | 0.188 sec/iter\n",
      "Epoch: 18 | Batch: 003 / 011 | Total loss: 1.083 | Reg loss: 0.021 | Tree loss: 1.083 | Accuracy: 0.696000 | 0.187 sec/iter\n",
      "Epoch: 18 | Batch: 004 / 011 | Total loss: 1.057 | Reg loss: 0.021 | Tree loss: 1.057 | Accuracy: 0.719000 | 0.187 sec/iter\n",
      "Epoch: 18 | Batch: 005 / 011 | Total loss: 1.005 | Reg loss: 0.021 | Tree loss: 1.005 | Accuracy: 0.752500 | 0.186 sec/iter\n",
      "Epoch: 18 | Batch: 006 / 011 | Total loss: 0.993 | Reg loss: 0.021 | Tree loss: 0.993 | Accuracy: 0.752500 | 0.186 sec/iter\n",
      "Epoch: 18 | Batch: 007 / 011 | Total loss: 0.975 | Reg loss: 0.021 | Tree loss: 0.975 | Accuracy: 0.747000 | 0.186 sec/iter\n",
      "Epoch: 18 | Batch: 008 / 011 | Total loss: 0.960 | Reg loss: 0.021 | Tree loss: 0.960 | Accuracy: 0.759500 | 0.185 sec/iter\n",
      "Epoch: 18 | Batch: 009 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.770000 | 0.185 sec/iter\n",
      "Epoch: 18 | Batch: 010 / 011 | Total loss: 0.915 | Reg loss: 0.022 | Tree loss: 0.915 | Accuracy: 0.805461 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 19 | Batch: 000 / 011 | Total loss: 1.158 | Reg loss: 0.021 | Tree loss: 1.158 | Accuracy: 0.712500 | 0.189 sec/iter\n",
      "Epoch: 19 | Batch: 001 / 011 | Total loss: 1.136 | Reg loss: 0.021 | Tree loss: 1.136 | Accuracy: 0.696000 | 0.189 sec/iter\n",
      "Epoch: 19 | Batch: 002 / 011 | Total loss: 1.085 | Reg loss: 0.021 | Tree loss: 1.085 | Accuracy: 0.704500 | 0.189 sec/iter\n",
      "Epoch: 19 | Batch: 003 / 011 | Total loss: 1.049 | Reg loss: 0.021 | Tree loss: 1.049 | Accuracy: 0.712500 | 0.188 sec/iter\n",
      "Epoch: 19 | Batch: 004 / 011 | Total loss: 1.017 | Reg loss: 0.021 | Tree loss: 1.017 | Accuracy: 0.724000 | 0.188 sec/iter\n",
      "Epoch: 19 | Batch: 005 / 011 | Total loss: 0.981 | Reg loss: 0.021 | Tree loss: 0.981 | Accuracy: 0.739000 | 0.187 sec/iter\n",
      "Epoch: 19 | Batch: 006 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.760500 | 0.187 sec/iter\n",
      "Epoch: 19 | Batch: 007 / 011 | Total loss: 0.957 | Reg loss: 0.022 | Tree loss: 0.957 | Accuracy: 0.760000 | 0.186 sec/iter\n",
      "Epoch: 19 | Batch: 008 / 011 | Total loss: 0.928 | Reg loss: 0.022 | Tree loss: 0.928 | Accuracy: 0.774000 | 0.186 sec/iter\n",
      "Epoch: 19 | Batch: 009 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.780000 | 0.186 sec/iter\n",
      "Epoch: 19 | Batch: 010 / 011 | Total loss: 0.897 | Reg loss: 0.022 | Tree loss: 0.897 | Accuracy: 0.784983 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 20 | Batch: 000 / 011 | Total loss: 1.121 | Reg loss: 0.021 | Tree loss: 1.121 | Accuracy: 0.727500 | 0.19 sec/iter\n",
      "Epoch: 20 | Batch: 001 / 011 | Total loss: 1.088 | Reg loss: 0.021 | Tree loss: 1.088 | Accuracy: 0.721000 | 0.19 sec/iter\n",
      "Epoch: 20 | Batch: 002 / 011 | Total loss: 1.040 | Reg loss: 0.021 | Tree loss: 1.040 | Accuracy: 0.727000 | 0.189 sec/iter\n",
      "Epoch: 20 | Batch: 003 / 011 | Total loss: 1.021 | Reg loss: 0.022 | Tree loss: 1.021 | Accuracy: 0.715500 | 0.189 sec/iter\n",
      "Epoch: 20 | Batch: 004 / 011 | Total loss: 0.981 | Reg loss: 0.022 | Tree loss: 0.981 | Accuracy: 0.742000 | 0.188 sec/iter\n",
      "Epoch: 20 | Batch: 005 / 011 | Total loss: 0.949 | Reg loss: 0.022 | Tree loss: 0.949 | Accuracy: 0.755000 | 0.188 sec/iter\n",
      "Epoch: 20 | Batch: 006 / 011 | Total loss: 0.940 | Reg loss: 0.022 | Tree loss: 0.940 | Accuracy: 0.751000 | 0.188 sec/iter\n",
      "Epoch: 20 | Batch: 007 / 011 | Total loss: 0.935 | Reg loss: 0.022 | Tree loss: 0.935 | Accuracy: 0.757000 | 0.187 sec/iter\n",
      "Epoch: 20 | Batch: 008 / 011 | Total loss: 0.890 | Reg loss: 0.022 | Tree loss: 0.890 | Accuracy: 0.781500 | 0.187 sec/iter\n",
      "Epoch: 20 | Batch: 009 / 011 | Total loss: 0.902 | Reg loss: 0.022 | Tree loss: 0.902 | Accuracy: 0.770000 | 0.187 sec/iter\n",
      "Epoch: 20 | Batch: 010 / 011 | Total loss: 0.904 | Reg loss: 0.022 | Tree loss: 0.904 | Accuracy: 0.805461 | 0.186 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 21 | Batch: 000 / 011 | Total loss: 1.089 | Reg loss: 0.022 | Tree loss: 1.089 | Accuracy: 0.718500 | 0.191 sec/iter\n",
      "Epoch: 21 | Batch: 001 / 011 | Total loss: 1.069 | Reg loss: 0.022 | Tree loss: 1.069 | Accuracy: 0.712000 | 0.191 sec/iter\n",
      "Epoch: 21 | Batch: 002 / 011 | Total loss: 1.008 | Reg loss: 0.022 | Tree loss: 1.008 | Accuracy: 0.724500 | 0.19 sec/iter\n",
      "Epoch: 21 | Batch: 003 / 011 | Total loss: 0.983 | Reg loss: 0.022 | Tree loss: 0.983 | Accuracy: 0.715000 | 0.19 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Batch: 004 / 011 | Total loss: 0.970 | Reg loss: 0.022 | Tree loss: 0.970 | Accuracy: 0.731000 | 0.19 sec/iter\n",
      "Epoch: 21 | Batch: 005 / 011 | Total loss: 0.932 | Reg loss: 0.022 | Tree loss: 0.932 | Accuracy: 0.756000 | 0.189 sec/iter\n",
      "Epoch: 21 | Batch: 006 / 011 | Total loss: 0.917 | Reg loss: 0.022 | Tree loss: 0.917 | Accuracy: 0.761000 | 0.189 sec/iter\n",
      "Epoch: 21 | Batch: 007 / 011 | Total loss: 0.899 | Reg loss: 0.022 | Tree loss: 0.899 | Accuracy: 0.767500 | 0.189 sec/iter\n",
      "Epoch: 21 | Batch: 008 / 011 | Total loss: 0.882 | Reg loss: 0.023 | Tree loss: 0.882 | Accuracy: 0.785500 | 0.188 sec/iter\n",
      "Epoch: 21 | Batch: 009 / 011 | Total loss: 0.856 | Reg loss: 0.023 | Tree loss: 0.856 | Accuracy: 0.796000 | 0.188 sec/iter\n",
      "Epoch: 21 | Batch: 010 / 011 | Total loss: 0.893 | Reg loss: 0.023 | Tree loss: 0.893 | Accuracy: 0.764505 | 0.188 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 22 | Batch: 000 / 011 | Total loss: 1.056 | Reg loss: 0.022 | Tree loss: 1.056 | Accuracy: 0.734500 | 0.192 sec/iter\n",
      "Epoch: 22 | Batch: 001 / 011 | Total loss: 1.013 | Reg loss: 0.022 | Tree loss: 1.013 | Accuracy: 0.732000 | 0.192 sec/iter\n",
      "Epoch: 22 | Batch: 002 / 011 | Total loss: 0.985 | Reg loss: 0.022 | Tree loss: 0.985 | Accuracy: 0.734000 | 0.191 sec/iter\n",
      "Epoch: 22 | Batch: 003 / 011 | Total loss: 0.958 | Reg loss: 0.022 | Tree loss: 0.958 | Accuracy: 0.735500 | 0.191 sec/iter\n",
      "Epoch: 22 | Batch: 004 / 011 | Total loss: 0.923 | Reg loss: 0.022 | Tree loss: 0.923 | Accuracy: 0.739000 | 0.191 sec/iter\n",
      "Epoch: 22 | Batch: 005 / 011 | Total loss: 0.910 | Reg loss: 0.023 | Tree loss: 0.910 | Accuracy: 0.744000 | 0.19 sec/iter\n",
      "Epoch: 22 | Batch: 006 / 011 | Total loss: 0.889 | Reg loss: 0.023 | Tree loss: 0.889 | Accuracy: 0.756500 | 0.19 sec/iter\n",
      "Epoch: 22 | Batch: 007 / 011 | Total loss: 0.888 | Reg loss: 0.023 | Tree loss: 0.888 | Accuracy: 0.774000 | 0.19 sec/iter\n",
      "Epoch: 22 | Batch: 008 / 011 | Total loss: 0.877 | Reg loss: 0.023 | Tree loss: 0.877 | Accuracy: 0.772000 | 0.19 sec/iter\n",
      "Epoch: 22 | Batch: 009 / 011 | Total loss: 0.852 | Reg loss: 0.023 | Tree loss: 0.852 | Accuracy: 0.792000 | 0.189 sec/iter\n",
      "Epoch: 22 | Batch: 010 / 011 | Total loss: 0.844 | Reg loss: 0.023 | Tree loss: 0.844 | Accuracy: 0.757679 | 0.189 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 23 | Batch: 000 / 011 | Total loss: 1.056 | Reg loss: 0.023 | Tree loss: 1.056 | Accuracy: 0.705000 | 0.193 sec/iter\n",
      "Epoch: 23 | Batch: 001 / 011 | Total loss: 0.996 | Reg loss: 0.023 | Tree loss: 0.996 | Accuracy: 0.729500 | 0.193 sec/iter\n",
      "Epoch: 23 | Batch: 002 / 011 | Total loss: 0.959 | Reg loss: 0.023 | Tree loss: 0.959 | Accuracy: 0.737500 | 0.192 sec/iter\n",
      "Epoch: 23 | Batch: 003 / 011 | Total loss: 0.931 | Reg loss: 0.023 | Tree loss: 0.931 | Accuracy: 0.735500 | 0.192 sec/iter\n",
      "Epoch: 23 | Batch: 004 / 011 | Total loss: 0.893 | Reg loss: 0.023 | Tree loss: 0.893 | Accuracy: 0.759500 | 0.192 sec/iter\n",
      "Epoch: 23 | Batch: 005 / 011 | Total loss: 0.887 | Reg loss: 0.023 | Tree loss: 0.887 | Accuracy: 0.767000 | 0.191 sec/iter\n",
      "Epoch: 23 | Batch: 006 / 011 | Total loss: 0.869 | Reg loss: 0.023 | Tree loss: 0.869 | Accuracy: 0.766000 | 0.191 sec/iter\n",
      "Epoch: 23 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.023 | Tree loss: 0.849 | Accuracy: 0.789500 | 0.191 sec/iter\n",
      "Epoch: 23 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.023 | Tree loss: 0.838 | Accuracy: 0.790500 | 0.191 sec/iter\n",
      "Epoch: 23 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.023 | Tree loss: 0.821 | Accuracy: 0.792000 | 0.19 sec/iter\n",
      "Epoch: 23 | Batch: 010 / 011 | Total loss: 0.837 | Reg loss: 0.023 | Tree loss: 0.837 | Accuracy: 0.829352 | 0.19 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 24 | Batch: 000 / 011 | Total loss: 1.014 | Reg loss: 0.023 | Tree loss: 1.014 | Accuracy: 0.708000 | 0.192 sec/iter\n",
      "Epoch: 24 | Batch: 001 / 011 | Total loss: 0.969 | Reg loss: 0.023 | Tree loss: 0.969 | Accuracy: 0.726000 | 0.192 sec/iter\n",
      "Epoch: 24 | Batch: 002 / 011 | Total loss: 0.928 | Reg loss: 0.023 | Tree loss: 0.928 | Accuracy: 0.731000 | 0.191 sec/iter\n",
      "Epoch: 24 | Batch: 003 / 011 | Total loss: 0.915 | Reg loss: 0.023 | Tree loss: 0.915 | Accuracy: 0.749500 | 0.191 sec/iter\n",
      "Epoch: 24 | Batch: 004 / 011 | Total loss: 0.882 | Reg loss: 0.023 | Tree loss: 0.882 | Accuracy: 0.756000 | 0.19 sec/iter\n",
      "Epoch: 24 | Batch: 005 / 011 | Total loss: 0.879 | Reg loss: 0.023 | Tree loss: 0.879 | Accuracy: 0.747500 | 0.19 sec/iter\n",
      "Epoch: 24 | Batch: 006 / 011 | Total loss: 0.842 | Reg loss: 0.023 | Tree loss: 0.842 | Accuracy: 0.776500 | 0.19 sec/iter\n",
      "Epoch: 24 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.023 | Tree loss: 0.826 | Accuracy: 0.769000 | 0.189 sec/iter\n",
      "Epoch: 24 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.024 | Tree loss: 0.825 | Accuracy: 0.788500 | 0.189 sec/iter\n",
      "Epoch: 24 | Batch: 009 / 011 | Total loss: 0.799 | Reg loss: 0.024 | Tree loss: 0.799 | Accuracy: 0.808500 | 0.188 sec/iter\n",
      "Epoch: 24 | Batch: 010 / 011 | Total loss: 0.771 | Reg loss: 0.024 | Tree loss: 0.771 | Accuracy: 0.819113 | 0.188 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 25 | Batch: 000 / 011 | Total loss: 0.994 | Reg loss: 0.023 | Tree loss: 0.994 | Accuracy: 0.717500 | 0.188 sec/iter\n",
      "Epoch: 25 | Batch: 001 / 011 | Total loss: 0.954 | Reg loss: 0.023 | Tree loss: 0.954 | Accuracy: 0.719500 | 0.187 sec/iter\n",
      "Epoch: 25 | Batch: 002 / 011 | Total loss: 0.930 | Reg loss: 0.023 | Tree loss: 0.930 | Accuracy: 0.721500 | 0.187 sec/iter\n",
      "Epoch: 25 | Batch: 003 / 011 | Total loss: 0.886 | Reg loss: 0.023 | Tree loss: 0.886 | Accuracy: 0.761500 | 0.187 sec/iter\n",
      "Epoch: 25 | Batch: 004 / 011 | Total loss: 0.864 | Reg loss: 0.023 | Tree loss: 0.864 | Accuracy: 0.762500 | 0.186 sec/iter\n",
      "Epoch: 25 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.024 | Tree loss: 0.843 | Accuracy: 0.771000 | 0.186 sec/iter\n",
      "Epoch: 25 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.024 | Tree loss: 0.813 | Accuracy: 0.790000 | 0.186 sec/iter\n",
      "Epoch: 25 | Batch: 007 / 011 | Total loss: 0.805 | Reg loss: 0.024 | Tree loss: 0.805 | Accuracy: 0.792000 | 0.185 sec/iter\n",
      "Epoch: 25 | Batch: 008 / 011 | Total loss: 0.792 | Reg loss: 0.024 | Tree loss: 0.792 | Accuracy: 0.809000 | 0.185 sec/iter\n",
      "Epoch: 25 | Batch: 009 / 011 | Total loss: 0.783 | Reg loss: 0.024 | Tree loss: 0.783 | Accuracy: 0.808500 | 0.185 sec/iter\n",
      "Epoch: 25 | Batch: 010 / 011 | Total loss: 0.739 | Reg loss: 0.024 | Tree loss: 0.739 | Accuracy: 0.846416 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 26 | Batch: 000 / 011 | Total loss: 0.966 | Reg loss: 0.024 | Tree loss: 0.966 | Accuracy: 0.715500 | 0.188 sec/iter\n",
      "Epoch: 26 | Batch: 001 / 011 | Total loss: 0.935 | Reg loss: 0.024 | Tree loss: 0.935 | Accuracy: 0.719500 | 0.188 sec/iter\n",
      "Epoch: 26 | Batch: 002 / 011 | Total loss: 0.906 | Reg loss: 0.024 | Tree loss: 0.906 | Accuracy: 0.720500 | 0.188 sec/iter\n",
      "Epoch: 26 | Batch: 003 / 011 | Total loss: 0.862 | Reg loss: 0.024 | Tree loss: 0.862 | Accuracy: 0.753500 | 0.187 sec/iter\n",
      "Epoch: 26 | Batch: 004 / 011 | Total loss: 0.848 | Reg loss: 0.024 | Tree loss: 0.848 | Accuracy: 0.765500 | 0.187 sec/iter\n",
      "Epoch: 26 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.024 | Tree loss: 0.818 | Accuracy: 0.784000 | 0.187 sec/iter\n",
      "Epoch: 26 | Batch: 006 / 011 | Total loss: 0.801 | Reg loss: 0.024 | Tree loss: 0.801 | Accuracy: 0.787000 | 0.186 sec/iter\n",
      "Epoch: 26 | Batch: 007 / 011 | Total loss: 0.787 | Reg loss: 0.024 | Tree loss: 0.787 | Accuracy: 0.798500 | 0.186 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Batch: 008 / 011 | Total loss: 0.782 | Reg loss: 0.024 | Tree loss: 0.782 | Accuracy: 0.792500 | 0.186 sec/iter\n",
      "Epoch: 26 | Batch: 009 / 011 | Total loss: 0.771 | Reg loss: 0.024 | Tree loss: 0.771 | Accuracy: 0.815000 | 0.186 sec/iter\n",
      "Epoch: 26 | Batch: 010 / 011 | Total loss: 0.751 | Reg loss: 0.024 | Tree loss: 0.751 | Accuracy: 0.825939 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 27 | Batch: 000 / 011 | Total loss: 0.940 | Reg loss: 0.024 | Tree loss: 0.940 | Accuracy: 0.722500 | 0.187 sec/iter\n",
      "Epoch: 27 | Batch: 001 / 011 | Total loss: 0.916 | Reg loss: 0.024 | Tree loss: 0.916 | Accuracy: 0.718500 | 0.187 sec/iter\n",
      "Epoch: 27 | Batch: 002 / 011 | Total loss: 0.881 | Reg loss: 0.024 | Tree loss: 0.881 | Accuracy: 0.736000 | 0.186 sec/iter\n",
      "Epoch: 27 | Batch: 003 / 011 | Total loss: 0.858 | Reg loss: 0.024 | Tree loss: 0.858 | Accuracy: 0.747000 | 0.186 sec/iter\n",
      "Epoch: 27 | Batch: 004 / 011 | Total loss: 0.809 | Reg loss: 0.024 | Tree loss: 0.809 | Accuracy: 0.782500 | 0.186 sec/iter\n",
      "Epoch: 27 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.024 | Tree loss: 0.812 | Accuracy: 0.782500 | 0.185 sec/iter\n",
      "Epoch: 27 | Batch: 006 / 011 | Total loss: 0.798 | Reg loss: 0.024 | Tree loss: 0.798 | Accuracy: 0.770000 | 0.185 sec/iter\n",
      "Epoch: 27 | Batch: 007 / 011 | Total loss: 0.776 | Reg loss: 0.024 | Tree loss: 0.776 | Accuracy: 0.805500 | 0.185 sec/iter\n",
      "Epoch: 27 | Batch: 008 / 011 | Total loss: 0.757 | Reg loss: 0.024 | Tree loss: 0.757 | Accuracy: 0.812500 | 0.184 sec/iter\n",
      "Epoch: 27 | Batch: 009 / 011 | Total loss: 0.744 | Reg loss: 0.024 | Tree loss: 0.744 | Accuracy: 0.818500 | 0.184 sec/iter\n",
      "Epoch: 27 | Batch: 010 / 011 | Total loss: 0.765 | Reg loss: 0.025 | Tree loss: 0.765 | Accuracy: 0.832765 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 28 | Batch: 000 / 011 | Total loss: 0.927 | Reg loss: 0.024 | Tree loss: 0.927 | Accuracy: 0.723000 | 0.185 sec/iter\n",
      "Epoch: 28 | Batch: 001 / 011 | Total loss: 0.892 | Reg loss: 0.024 | Tree loss: 0.892 | Accuracy: 0.741000 | 0.185 sec/iter\n",
      "Epoch: 28 | Batch: 002 / 011 | Total loss: 0.863 | Reg loss: 0.024 | Tree loss: 0.863 | Accuracy: 0.740500 | 0.185 sec/iter\n",
      "Epoch: 28 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.024 | Tree loss: 0.841 | Accuracy: 0.748500 | 0.184 sec/iter\n",
      "Epoch: 28 | Batch: 004 / 011 | Total loss: 0.790 | Reg loss: 0.024 | Tree loss: 0.790 | Accuracy: 0.782000 | 0.184 sec/iter\n",
      "Epoch: 28 | Batch: 005 / 011 | Total loss: 0.784 | Reg loss: 0.024 | Tree loss: 0.784 | Accuracy: 0.793000 | 0.184 sec/iter\n",
      "Epoch: 28 | Batch: 006 / 011 | Total loss: 0.776 | Reg loss: 0.024 | Tree loss: 0.776 | Accuracy: 0.794000 | 0.184 sec/iter\n",
      "Epoch: 28 | Batch: 007 / 011 | Total loss: 0.765 | Reg loss: 0.024 | Tree loss: 0.765 | Accuracy: 0.793000 | 0.183 sec/iter\n",
      "Epoch: 28 | Batch: 008 / 011 | Total loss: 0.763 | Reg loss: 0.025 | Tree loss: 0.763 | Accuracy: 0.808000 | 0.183 sec/iter\n",
      "Epoch: 28 | Batch: 009 / 011 | Total loss: 0.721 | Reg loss: 0.025 | Tree loss: 0.721 | Accuracy: 0.832500 | 0.183 sec/iter\n",
      "Epoch: 28 | Batch: 010 / 011 | Total loss: 0.753 | Reg loss: 0.025 | Tree loss: 0.753 | Accuracy: 0.832765 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 29 | Batch: 000 / 011 | Total loss: 0.912 | Reg loss: 0.024 | Tree loss: 0.912 | Accuracy: 0.713500 | 0.184 sec/iter\n",
      "Epoch: 29 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.024 | Tree loss: 0.883 | Accuracy: 0.720000 | 0.184 sec/iter\n",
      "Epoch: 29 | Batch: 002 / 011 | Total loss: 0.846 | Reg loss: 0.024 | Tree loss: 0.846 | Accuracy: 0.743500 | 0.183 sec/iter\n",
      "Epoch: 29 | Batch: 003 / 011 | Total loss: 0.803 | Reg loss: 0.024 | Tree loss: 0.803 | Accuracy: 0.782500 | 0.183 sec/iter\n",
      "Epoch: 29 | Batch: 004 / 011 | Total loss: 0.797 | Reg loss: 0.024 | Tree loss: 0.797 | Accuracy: 0.781000 | 0.183 sec/iter\n",
      "Epoch: 29 | Batch: 005 / 011 | Total loss: 0.761 | Reg loss: 0.025 | Tree loss: 0.761 | Accuracy: 0.799000 | 0.182 sec/iter\n",
      "Epoch: 29 | Batch: 006 / 011 | Total loss: 0.744 | Reg loss: 0.025 | Tree loss: 0.744 | Accuracy: 0.817000 | 0.182 sec/iter\n",
      "Epoch: 29 | Batch: 007 / 011 | Total loss: 0.736 | Reg loss: 0.025 | Tree loss: 0.736 | Accuracy: 0.820000 | 0.182 sec/iter\n",
      "Epoch: 29 | Batch: 008 / 011 | Total loss: 0.738 | Reg loss: 0.025 | Tree loss: 0.738 | Accuracy: 0.814500 | 0.182 sec/iter\n",
      "Epoch: 29 | Batch: 009 / 011 | Total loss: 0.732 | Reg loss: 0.025 | Tree loss: 0.732 | Accuracy: 0.813500 | 0.181 sec/iter\n",
      "Epoch: 29 | Batch: 010 / 011 | Total loss: 0.692 | Reg loss: 0.025 | Tree loss: 0.692 | Accuracy: 0.860068 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 30 | Batch: 000 / 011 | Total loss: 0.886 | Reg loss: 0.025 | Tree loss: 0.886 | Accuracy: 0.727000 | 0.183 sec/iter\n",
      "Epoch: 30 | Batch: 001 / 011 | Total loss: 0.831 | Reg loss: 0.025 | Tree loss: 0.831 | Accuracy: 0.750000 | 0.182 sec/iter\n",
      "Epoch: 30 | Batch: 002 / 011 | Total loss: 0.828 | Reg loss: 0.025 | Tree loss: 0.828 | Accuracy: 0.743000 | 0.182 sec/iter\n",
      "Epoch: 30 | Batch: 003 / 011 | Total loss: 0.815 | Reg loss: 0.025 | Tree loss: 0.815 | Accuracy: 0.750500 | 0.182 sec/iter\n",
      "Epoch: 30 | Batch: 004 / 011 | Total loss: 0.769 | Reg loss: 0.025 | Tree loss: 0.769 | Accuracy: 0.785500 | 0.182 sec/iter\n",
      "Epoch: 30 | Batch: 005 / 011 | Total loss: 0.758 | Reg loss: 0.025 | Tree loss: 0.758 | Accuracy: 0.793000 | 0.181 sec/iter\n",
      "Epoch: 30 | Batch: 006 / 011 | Total loss: 0.734 | Reg loss: 0.025 | Tree loss: 0.734 | Accuracy: 0.809000 | 0.181 sec/iter\n",
      "Epoch: 30 | Batch: 007 / 011 | Total loss: 0.735 | Reg loss: 0.025 | Tree loss: 0.735 | Accuracy: 0.818500 | 0.181 sec/iter\n",
      "Epoch: 30 | Batch: 008 / 011 | Total loss: 0.713 | Reg loss: 0.025 | Tree loss: 0.713 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 30 | Batch: 009 / 011 | Total loss: 0.711 | Reg loss: 0.025 | Tree loss: 0.711 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 30 | Batch: 010 / 011 | Total loss: 0.704 | Reg loss: 0.025 | Tree loss: 0.704 | Accuracy: 0.832765 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 31 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.025 | Tree loss: 0.848 | Accuracy: 0.752000 | 0.18 sec/iter\n",
      "Epoch: 31 | Batch: 001 / 011 | Total loss: 0.828 | Reg loss: 0.025 | Tree loss: 0.828 | Accuracy: 0.760500 | 0.179 sec/iter\n",
      "Epoch: 31 | Batch: 002 / 011 | Total loss: 0.821 | Reg loss: 0.025 | Tree loss: 0.821 | Accuracy: 0.746500 | 0.179 sec/iter\n",
      "Epoch: 31 | Batch: 003 / 011 | Total loss: 0.779 | Reg loss: 0.025 | Tree loss: 0.779 | Accuracy: 0.779000 | 0.179 sec/iter\n",
      "Epoch: 31 | Batch: 004 / 011 | Total loss: 0.740 | Reg loss: 0.025 | Tree loss: 0.740 | Accuracy: 0.803500 | 0.178 sec/iter\n",
      "Epoch: 31 | Batch: 005 / 011 | Total loss: 0.749 | Reg loss: 0.025 | Tree loss: 0.749 | Accuracy: 0.790500 | 0.178 sec/iter\n",
      "Epoch: 31 | Batch: 006 / 011 | Total loss: 0.749 | Reg loss: 0.025 | Tree loss: 0.749 | Accuracy: 0.792000 | 0.178 sec/iter\n",
      "Epoch: 31 | Batch: 007 / 011 | Total loss: 0.715 | Reg loss: 0.025 | Tree loss: 0.715 | Accuracy: 0.832000 | 0.178 sec/iter\n",
      "Epoch: 31 | Batch: 008 / 011 | Total loss: 0.697 | Reg loss: 0.025 | Tree loss: 0.697 | Accuracy: 0.831500 | 0.177 sec/iter\n",
      "Epoch: 31 | Batch: 009 / 011 | Total loss: 0.711 | Reg loss: 0.025 | Tree loss: 0.711 | Accuracy: 0.830000 | 0.177 sec/iter\n",
      "Epoch: 31 | Batch: 010 / 011 | Total loss: 0.676 | Reg loss: 0.025 | Tree loss: 0.676 | Accuracy: 0.839590 | 0.177 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 32 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.025 | Tree loss: 0.853 | Accuracy: 0.743500 | 0.176 sec/iter\n",
      "Epoch: 32 | Batch: 001 / 011 | Total loss: 0.808 | Reg loss: 0.025 | Tree loss: 0.808 | Accuracy: 0.749000 | 0.176 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Batch: 002 / 011 | Total loss: 0.812 | Reg loss: 0.025 | Tree loss: 0.812 | Accuracy: 0.750500 | 0.176 sec/iter\n",
      "Epoch: 32 | Batch: 003 / 011 | Total loss: 0.765 | Reg loss: 0.025 | Tree loss: 0.765 | Accuracy: 0.778000 | 0.176 sec/iter\n",
      "Epoch: 32 | Batch: 004 / 011 | Total loss: 0.745 | Reg loss: 0.025 | Tree loss: 0.745 | Accuracy: 0.797500 | 0.175 sec/iter\n",
      "Epoch: 32 | Batch: 005 / 011 | Total loss: 0.719 | Reg loss: 0.025 | Tree loss: 0.719 | Accuracy: 0.798000 | 0.175 sec/iter\n",
      "Epoch: 32 | Batch: 006 / 011 | Total loss: 0.719 | Reg loss: 0.025 | Tree loss: 0.719 | Accuracy: 0.817500 | 0.175 sec/iter\n",
      "Epoch: 32 | Batch: 007 / 011 | Total loss: 0.716 | Reg loss: 0.025 | Tree loss: 0.716 | Accuracy: 0.821500 | 0.175 sec/iter\n",
      "Epoch: 32 | Batch: 008 / 011 | Total loss: 0.673 | Reg loss: 0.025 | Tree loss: 0.673 | Accuracy: 0.853500 | 0.174 sec/iter\n",
      "Epoch: 32 | Batch: 009 / 011 | Total loss: 0.705 | Reg loss: 0.025 | Tree loss: 0.705 | Accuracy: 0.813500 | 0.174 sec/iter\n",
      "Epoch: 32 | Batch: 010 / 011 | Total loss: 0.709 | Reg loss: 0.025 | Tree loss: 0.709 | Accuracy: 0.836177 | 0.174 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 33 | Batch: 000 / 011 | Total loss: 0.824 | Reg loss: 0.025 | Tree loss: 0.824 | Accuracy: 0.747500 | 0.175 sec/iter\n",
      "Epoch: 33 | Batch: 001 / 011 | Total loss: 0.833 | Reg loss: 0.025 | Tree loss: 0.833 | Accuracy: 0.726500 | 0.175 sec/iter\n",
      "Epoch: 33 | Batch: 002 / 011 | Total loss: 0.789 | Reg loss: 0.025 | Tree loss: 0.789 | Accuracy: 0.755500 | 0.175 sec/iter\n",
      "Epoch: 33 | Batch: 003 / 011 | Total loss: 0.744 | Reg loss: 0.025 | Tree loss: 0.744 | Accuracy: 0.785500 | 0.175 sec/iter\n",
      "Epoch: 33 | Batch: 004 / 011 | Total loss: 0.738 | Reg loss: 0.025 | Tree loss: 0.738 | Accuracy: 0.793000 | 0.174 sec/iter\n",
      "Epoch: 33 | Batch: 005 / 011 | Total loss: 0.702 | Reg loss: 0.025 | Tree loss: 0.702 | Accuracy: 0.819000 | 0.174 sec/iter\n",
      "Epoch: 33 | Batch: 006 / 011 | Total loss: 0.731 | Reg loss: 0.025 | Tree loss: 0.731 | Accuracy: 0.807500 | 0.174 sec/iter\n",
      "Epoch: 33 | Batch: 007 / 011 | Total loss: 0.686 | Reg loss: 0.025 | Tree loss: 0.686 | Accuracy: 0.832500 | 0.174 sec/iter\n",
      "Epoch: 33 | Batch: 008 / 011 | Total loss: 0.675 | Reg loss: 0.025 | Tree loss: 0.675 | Accuracy: 0.836000 | 0.174 sec/iter\n",
      "Epoch: 33 | Batch: 009 / 011 | Total loss: 0.683 | Reg loss: 0.026 | Tree loss: 0.683 | Accuracy: 0.830000 | 0.174 sec/iter\n",
      "Epoch: 33 | Batch: 010 / 011 | Total loss: 0.649 | Reg loss: 0.026 | Tree loss: 0.649 | Accuracy: 0.836177 | 0.173 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 34 | Batch: 000 / 011 | Total loss: 0.826 | Reg loss: 0.025 | Tree loss: 0.826 | Accuracy: 0.756000 | 0.175 sec/iter\n",
      "Epoch: 34 | Batch: 001 / 011 | Total loss: 0.792 | Reg loss: 0.025 | Tree loss: 0.792 | Accuracy: 0.748000 | 0.174 sec/iter\n",
      "Epoch: 34 | Batch: 002 / 011 | Total loss: 0.757 | Reg loss: 0.025 | Tree loss: 0.757 | Accuracy: 0.766000 | 0.174 sec/iter\n",
      "Epoch: 34 | Batch: 003 / 011 | Total loss: 0.743 | Reg loss: 0.025 | Tree loss: 0.743 | Accuracy: 0.785500 | 0.174 sec/iter\n",
      "Epoch: 34 | Batch: 004 / 011 | Total loss: 0.734 | Reg loss: 0.025 | Tree loss: 0.734 | Accuracy: 0.784000 | 0.174 sec/iter\n",
      "Epoch: 34 | Batch: 005 / 011 | Total loss: 0.706 | Reg loss: 0.025 | Tree loss: 0.706 | Accuracy: 0.804000 | 0.173 sec/iter\n",
      "Epoch: 34 | Batch: 006 / 011 | Total loss: 0.682 | Reg loss: 0.025 | Tree loss: 0.682 | Accuracy: 0.826000 | 0.173 sec/iter\n",
      "Epoch: 34 | Batch: 007 / 011 | Total loss: 0.667 | Reg loss: 0.026 | Tree loss: 0.667 | Accuracy: 0.849000 | 0.173 sec/iter\n",
      "Epoch: 34 | Batch: 008 / 011 | Total loss: 0.692 | Reg loss: 0.026 | Tree loss: 0.692 | Accuracy: 0.817500 | 0.173 sec/iter\n",
      "Epoch: 34 | Batch: 009 / 011 | Total loss: 0.662 | Reg loss: 0.026 | Tree loss: 0.662 | Accuracy: 0.843000 | 0.173 sec/iter\n",
      "Epoch: 34 | Batch: 010 / 011 | Total loss: 0.631 | Reg loss: 0.026 | Tree loss: 0.631 | Accuracy: 0.860068 | 0.172 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 35 | Batch: 000 / 011 | Total loss: 0.817 | Reg loss: 0.025 | Tree loss: 0.817 | Accuracy: 0.740000 | 0.174 sec/iter\n",
      "Epoch: 35 | Batch: 001 / 011 | Total loss: 0.797 | Reg loss: 0.025 | Tree loss: 0.797 | Accuracy: 0.737000 | 0.174 sec/iter\n",
      "Epoch: 35 | Batch: 002 / 011 | Total loss: 0.759 | Reg loss: 0.025 | Tree loss: 0.759 | Accuracy: 0.766500 | 0.174 sec/iter\n",
      "Epoch: 35 | Batch: 003 / 011 | Total loss: 0.739 | Reg loss: 0.025 | Tree loss: 0.739 | Accuracy: 0.781500 | 0.174 sec/iter\n",
      "Epoch: 35 | Batch: 004 / 011 | Total loss: 0.704 | Reg loss: 0.025 | Tree loss: 0.704 | Accuracy: 0.795000 | 0.173 sec/iter\n",
      "Epoch: 35 | Batch: 005 / 011 | Total loss: 0.705 | Reg loss: 0.026 | Tree loss: 0.705 | Accuracy: 0.791500 | 0.173 sec/iter\n",
      "Epoch: 35 | Batch: 006 / 011 | Total loss: 0.684 | Reg loss: 0.026 | Tree loss: 0.684 | Accuracy: 0.817000 | 0.173 sec/iter\n",
      "Epoch: 35 | Batch: 007 / 011 | Total loss: 0.661 | Reg loss: 0.026 | Tree loss: 0.661 | Accuracy: 0.833500 | 0.173 sec/iter\n",
      "Epoch: 35 | Batch: 008 / 011 | Total loss: 0.652 | Reg loss: 0.026 | Tree loss: 0.652 | Accuracy: 0.845000 | 0.173 sec/iter\n",
      "Epoch: 35 | Batch: 009 / 011 | Total loss: 0.646 | Reg loss: 0.026 | Tree loss: 0.646 | Accuracy: 0.850500 | 0.173 sec/iter\n",
      "Epoch: 35 | Batch: 010 / 011 | Total loss: 0.657 | Reg loss: 0.026 | Tree loss: 0.657 | Accuracy: 0.836177 | 0.172 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 36 | Batch: 000 / 011 | Total loss: 0.776 | Reg loss: 0.026 | Tree loss: 0.776 | Accuracy: 0.767500 | 0.175 sec/iter\n",
      "Epoch: 36 | Batch: 001 / 011 | Total loss: 0.797 | Reg loss: 0.026 | Tree loss: 0.797 | Accuracy: 0.734500 | 0.175 sec/iter\n",
      "Epoch: 36 | Batch: 002 / 011 | Total loss: 0.770 | Reg loss: 0.026 | Tree loss: 0.770 | Accuracy: 0.753000 | 0.175 sec/iter\n",
      "Epoch: 36 | Batch: 003 / 011 | Total loss: 0.727 | Reg loss: 0.026 | Tree loss: 0.727 | Accuracy: 0.779500 | 0.175 sec/iter\n",
      "Epoch: 36 | Batch: 004 / 011 | Total loss: 0.684 | Reg loss: 0.026 | Tree loss: 0.684 | Accuracy: 0.800500 | 0.175 sec/iter\n",
      "Epoch: 36 | Batch: 005 / 011 | Total loss: 0.668 | Reg loss: 0.026 | Tree loss: 0.668 | Accuracy: 0.816000 | 0.174 sec/iter\n",
      "Epoch: 36 | Batch: 006 / 011 | Total loss: 0.666 | Reg loss: 0.026 | Tree loss: 0.666 | Accuracy: 0.834500 | 0.174 sec/iter\n",
      "Epoch: 36 | Batch: 007 / 011 | Total loss: 0.664 | Reg loss: 0.026 | Tree loss: 0.664 | Accuracy: 0.817500 | 0.174 sec/iter\n",
      "Epoch: 36 | Batch: 008 / 011 | Total loss: 0.639 | Reg loss: 0.026 | Tree loss: 0.639 | Accuracy: 0.842500 | 0.174 sec/iter\n",
      "Epoch: 36 | Batch: 009 / 011 | Total loss: 0.645 | Reg loss: 0.026 | Tree loss: 0.645 | Accuracy: 0.854500 | 0.174 sec/iter\n",
      "Epoch: 36 | Batch: 010 / 011 | Total loss: 0.665 | Reg loss: 0.026 | Tree loss: 0.665 | Accuracy: 0.812287 | 0.174 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 37 | Batch: 000 / 011 | Total loss: 0.788 | Reg loss: 0.026 | Tree loss: 0.788 | Accuracy: 0.757000 | 0.176 sec/iter\n",
      "Epoch: 37 | Batch: 001 / 011 | Total loss: 0.755 | Reg loss: 0.026 | Tree loss: 0.755 | Accuracy: 0.755500 | 0.176 sec/iter\n",
      "Epoch: 37 | Batch: 002 / 011 | Total loss: 0.731 | Reg loss: 0.026 | Tree loss: 0.731 | Accuracy: 0.778500 | 0.176 sec/iter\n",
      "Epoch: 37 | Batch: 003 / 011 | Total loss: 0.713 | Reg loss: 0.026 | Tree loss: 0.713 | Accuracy: 0.789000 | 0.176 sec/iter\n",
      "Epoch: 37 | Batch: 004 / 011 | Total loss: 0.690 | Reg loss: 0.026 | Tree loss: 0.690 | Accuracy: 0.799500 | 0.176 sec/iter\n",
      "Epoch: 37 | Batch: 005 / 011 | Total loss: 0.670 | Reg loss: 0.026 | Tree loss: 0.670 | Accuracy: 0.813500 | 0.175 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Batch: 006 / 011 | Total loss: 0.653 | Reg loss: 0.026 | Tree loss: 0.653 | Accuracy: 0.823500 | 0.175 sec/iter\n",
      "Epoch: 37 | Batch: 007 / 011 | Total loss: 0.652 | Reg loss: 0.026 | Tree loss: 0.652 | Accuracy: 0.830000 | 0.175 sec/iter\n",
      "Epoch: 37 | Batch: 008 / 011 | Total loss: 0.676 | Reg loss: 0.026 | Tree loss: 0.676 | Accuracy: 0.820500 | 0.175 sec/iter\n",
      "Epoch: 37 | Batch: 009 / 011 | Total loss: 0.615 | Reg loss: 0.026 | Tree loss: 0.615 | Accuracy: 0.861000 | 0.175 sec/iter\n",
      "Epoch: 37 | Batch: 010 / 011 | Total loss: 0.647 | Reg loss: 0.026 | Tree loss: 0.647 | Accuracy: 0.825939 | 0.175 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 38 | Batch: 000 / 011 | Total loss: 0.766 | Reg loss: 0.026 | Tree loss: 0.766 | Accuracy: 0.757500 | 0.177 sec/iter\n",
      "Epoch: 38 | Batch: 001 / 011 | Total loss: 0.760 | Reg loss: 0.026 | Tree loss: 0.760 | Accuracy: 0.739000 | 0.177 sec/iter\n",
      "Epoch: 38 | Batch: 002 / 011 | Total loss: 0.730 | Reg loss: 0.026 | Tree loss: 0.730 | Accuracy: 0.776500 | 0.177 sec/iter\n",
      "Epoch: 38 | Batch: 003 / 011 | Total loss: 0.703 | Reg loss: 0.026 | Tree loss: 0.703 | Accuracy: 0.787500 | 0.176 sec/iter\n",
      "Epoch: 38 | Batch: 004 / 011 | Total loss: 0.670 | Reg loss: 0.026 | Tree loss: 0.670 | Accuracy: 0.790000 | 0.176 sec/iter\n",
      "Epoch: 38 | Batch: 005 / 011 | Total loss: 0.642 | Reg loss: 0.026 | Tree loss: 0.642 | Accuracy: 0.826500 | 0.176 sec/iter\n",
      "Epoch: 38 | Batch: 006 / 011 | Total loss: 0.648 | Reg loss: 0.026 | Tree loss: 0.648 | Accuracy: 0.816000 | 0.176 sec/iter\n",
      "Epoch: 38 | Batch: 007 / 011 | Total loss: 0.641 | Reg loss: 0.026 | Tree loss: 0.641 | Accuracy: 0.846000 | 0.176 sec/iter\n",
      "Epoch: 38 | Batch: 008 / 011 | Total loss: 0.652 | Reg loss: 0.026 | Tree loss: 0.652 | Accuracy: 0.827500 | 0.175 sec/iter\n",
      "Epoch: 38 | Batch: 009 / 011 | Total loss: 0.622 | Reg loss: 0.026 | Tree loss: 0.622 | Accuracy: 0.851500 | 0.175 sec/iter\n",
      "Epoch: 38 | Batch: 010 / 011 | Total loss: 0.636 | Reg loss: 0.026 | Tree loss: 0.636 | Accuracy: 0.856655 | 0.175 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 39 | Batch: 000 / 011 | Total loss: 0.759 | Reg loss: 0.026 | Tree loss: 0.759 | Accuracy: 0.764000 | 0.177 sec/iter\n",
      "Epoch: 39 | Batch: 001 / 011 | Total loss: 0.733 | Reg loss: 0.026 | Tree loss: 0.733 | Accuracy: 0.771500 | 0.177 sec/iter\n",
      "Epoch: 39 | Batch: 002 / 011 | Total loss: 0.719 | Reg loss: 0.026 | Tree loss: 0.719 | Accuracy: 0.774500 | 0.177 sec/iter\n",
      "Epoch: 39 | Batch: 003 / 011 | Total loss: 0.697 | Reg loss: 0.026 | Tree loss: 0.697 | Accuracy: 0.785500 | 0.176 sec/iter\n",
      "Epoch: 39 | Batch: 004 / 011 | Total loss: 0.660 | Reg loss: 0.026 | Tree loss: 0.660 | Accuracy: 0.810000 | 0.176 sec/iter\n",
      "Epoch: 39 | Batch: 005 / 011 | Total loss: 0.643 | Reg loss: 0.026 | Tree loss: 0.643 | Accuracy: 0.820000 | 0.176 sec/iter\n",
      "Epoch: 39 | Batch: 006 / 011 | Total loss: 0.653 | Reg loss: 0.026 | Tree loss: 0.653 | Accuracy: 0.819000 | 0.176 sec/iter\n",
      "Epoch: 39 | Batch: 007 / 011 | Total loss: 0.646 | Reg loss: 0.026 | Tree loss: 0.646 | Accuracy: 0.835500 | 0.176 sec/iter\n",
      "Epoch: 39 | Batch: 008 / 011 | Total loss: 0.623 | Reg loss: 0.026 | Tree loss: 0.623 | Accuracy: 0.842500 | 0.176 sec/iter\n",
      "Epoch: 39 | Batch: 009 / 011 | Total loss: 0.622 | Reg loss: 0.026 | Tree loss: 0.622 | Accuracy: 0.854500 | 0.175 sec/iter\n",
      "Epoch: 39 | Batch: 010 / 011 | Total loss: 0.597 | Reg loss: 0.026 | Tree loss: 0.597 | Accuracy: 0.866894 | 0.175 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 40 | Batch: 000 / 011 | Total loss: 0.752 | Reg loss: 0.026 | Tree loss: 0.752 | Accuracy: 0.761000 | 0.178 sec/iter\n",
      "Epoch: 40 | Batch: 001 / 011 | Total loss: 0.737 | Reg loss: 0.026 | Tree loss: 0.737 | Accuracy: 0.769500 | 0.178 sec/iter\n",
      "Epoch: 40 | Batch: 002 / 011 | Total loss: 0.700 | Reg loss: 0.026 | Tree loss: 0.700 | Accuracy: 0.776500 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 003 / 011 | Total loss: 0.664 | Reg loss: 0.026 | Tree loss: 0.664 | Accuracy: 0.803000 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 004 / 011 | Total loss: 0.661 | Reg loss: 0.026 | Tree loss: 0.661 | Accuracy: 0.793000 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 005 / 011 | Total loss: 0.634 | Reg loss: 0.026 | Tree loss: 0.634 | Accuracy: 0.818000 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 006 / 011 | Total loss: 0.649 | Reg loss: 0.026 | Tree loss: 0.649 | Accuracy: 0.817000 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 007 / 011 | Total loss: 0.623 | Reg loss: 0.026 | Tree loss: 0.623 | Accuracy: 0.828500 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 008 / 011 | Total loss: 0.608 | Reg loss: 0.026 | Tree loss: 0.608 | Accuracy: 0.854000 | 0.177 sec/iter\n",
      "Epoch: 40 | Batch: 009 / 011 | Total loss: 0.624 | Reg loss: 0.026 | Tree loss: 0.624 | Accuracy: 0.838000 | 0.176 sec/iter\n",
      "Epoch: 40 | Batch: 010 / 011 | Total loss: 0.618 | Reg loss: 0.026 | Tree loss: 0.618 | Accuracy: 0.849829 | 0.176 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 41 | Batch: 000 / 011 | Total loss: 0.720 | Reg loss: 0.026 | Tree loss: 0.720 | Accuracy: 0.766000 | 0.179 sec/iter\n",
      "Epoch: 41 | Batch: 001 / 011 | Total loss: 0.715 | Reg loss: 0.026 | Tree loss: 0.715 | Accuracy: 0.775000 | 0.179 sec/iter\n",
      "Epoch: 41 | Batch: 002 / 011 | Total loss: 0.685 | Reg loss: 0.026 | Tree loss: 0.685 | Accuracy: 0.787500 | 0.178 sec/iter\n",
      "Epoch: 41 | Batch: 003 / 011 | Total loss: 0.691 | Reg loss: 0.026 | Tree loss: 0.691 | Accuracy: 0.786500 | 0.178 sec/iter\n",
      "Epoch: 41 | Batch: 004 / 011 | Total loss: 0.642 | Reg loss: 0.026 | Tree loss: 0.642 | Accuracy: 0.825500 | 0.178 sec/iter\n",
      "Epoch: 41 | Batch: 005 / 011 | Total loss: 0.627 | Reg loss: 0.026 | Tree loss: 0.627 | Accuracy: 0.829500 | 0.178 sec/iter\n",
      "Epoch: 41 | Batch: 006 / 011 | Total loss: 0.642 | Reg loss: 0.026 | Tree loss: 0.642 | Accuracy: 0.830500 | 0.178 sec/iter\n",
      "Epoch: 41 | Batch: 007 / 011 | Total loss: 0.617 | Reg loss: 0.026 | Tree loss: 0.617 | Accuracy: 0.842000 | 0.178 sec/iter\n",
      "Epoch: 41 | Batch: 008 / 011 | Total loss: 0.615 | Reg loss: 0.026 | Tree loss: 0.615 | Accuracy: 0.846000 | 0.177 sec/iter\n",
      "Epoch: 41 | Batch: 009 / 011 | Total loss: 0.606 | Reg loss: 0.026 | Tree loss: 0.606 | Accuracy: 0.853000 | 0.177 sec/iter\n",
      "Epoch: 41 | Batch: 010 / 011 | Total loss: 0.633 | Reg loss: 0.026 | Tree loss: 0.633 | Accuracy: 0.812287 | 0.177 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 42 | Batch: 000 / 011 | Total loss: 0.737 | Reg loss: 0.026 | Tree loss: 0.737 | Accuracy: 0.770500 | 0.178 sec/iter\n",
      "Epoch: 42 | Batch: 001 / 011 | Total loss: 0.700 | Reg loss: 0.026 | Tree loss: 0.700 | Accuracy: 0.771000 | 0.178 sec/iter\n",
      "Epoch: 42 | Batch: 002 / 011 | Total loss: 0.694 | Reg loss: 0.026 | Tree loss: 0.694 | Accuracy: 0.777500 | 0.178 sec/iter\n",
      "Epoch: 42 | Batch: 003 / 011 | Total loss: 0.665 | Reg loss: 0.026 | Tree loss: 0.665 | Accuracy: 0.791000 | 0.178 sec/iter\n",
      "Epoch: 42 | Batch: 004 / 011 | Total loss: 0.640 | Reg loss: 0.026 | Tree loss: 0.640 | Accuracy: 0.822000 | 0.178 sec/iter\n",
      "Epoch: 42 | Batch: 005 / 011 | Total loss: 0.630 | Reg loss: 0.026 | Tree loss: 0.630 | Accuracy: 0.824000 | 0.178 sec/iter\n",
      "Epoch: 42 | Batch: 006 / 011 | Total loss: 0.627 | Reg loss: 0.026 | Tree loss: 0.627 | Accuracy: 0.827000 | 0.177 sec/iter\n",
      "Epoch: 42 | Batch: 007 / 011 | Total loss: 0.599 | Reg loss: 0.026 | Tree loss: 0.599 | Accuracy: 0.853000 | 0.177 sec/iter\n",
      "Epoch: 42 | Batch: 008 / 011 | Total loss: 0.600 | Reg loss: 0.026 | Tree loss: 0.600 | Accuracy: 0.847500 | 0.177 sec/iter\n",
      "Epoch: 42 | Batch: 009 / 011 | Total loss: 0.600 | Reg loss: 0.026 | Tree loss: 0.600 | Accuracy: 0.844000 | 0.177 sec/iter\n",
      "Epoch: 42 | Batch: 010 / 011 | Total loss: 0.617 | Reg loss: 0.026 | Tree loss: 0.617 | Accuracy: 0.825939 | 0.177 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 43 | Batch: 000 / 011 | Total loss: 0.715 | Reg loss: 0.026 | Tree loss: 0.715 | Accuracy: 0.772000 | 0.179 sec/iter\n",
      "Epoch: 43 | Batch: 001 / 011 | Total loss: 0.686 | Reg loss: 0.026 | Tree loss: 0.686 | Accuracy: 0.773500 | 0.179 sec/iter\n",
      "Epoch: 43 | Batch: 002 / 011 | Total loss: 0.668 | Reg loss: 0.026 | Tree loss: 0.668 | Accuracy: 0.794000 | 0.179 sec/iter\n",
      "Epoch: 43 | Batch: 003 / 011 | Total loss: 0.654 | Reg loss: 0.026 | Tree loss: 0.654 | Accuracy: 0.801000 | 0.179 sec/iter\n",
      "Epoch: 43 | Batch: 004 / 011 | Total loss: 0.624 | Reg loss: 0.026 | Tree loss: 0.624 | Accuracy: 0.826500 | 0.179 sec/iter\n",
      "Epoch: 43 | Batch: 005 / 011 | Total loss: 0.630 | Reg loss: 0.026 | Tree loss: 0.630 | Accuracy: 0.818500 | 0.178 sec/iter\n",
      "Epoch: 43 | Batch: 006 / 011 | Total loss: 0.618 | Reg loss: 0.026 | Tree loss: 0.618 | Accuracy: 0.833500 | 0.178 sec/iter\n",
      "Epoch: 43 | Batch: 007 / 011 | Total loss: 0.615 | Reg loss: 0.026 | Tree loss: 0.615 | Accuracy: 0.838000 | 0.178 sec/iter\n",
      "Epoch: 43 | Batch: 008 / 011 | Total loss: 0.599 | Reg loss: 0.026 | Tree loss: 0.599 | Accuracy: 0.852500 | 0.178 sec/iter\n",
      "Epoch: 43 | Batch: 009 / 011 | Total loss: 0.592 | Reg loss: 0.027 | Tree loss: 0.592 | Accuracy: 0.849500 | 0.178 sec/iter\n",
      "Epoch: 43 | Batch: 010 / 011 | Total loss: 0.583 | Reg loss: 0.027 | Tree loss: 0.583 | Accuracy: 0.849829 | 0.178 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 44 | Batch: 000 / 011 | Total loss: 0.690 | Reg loss: 0.026 | Tree loss: 0.690 | Accuracy: 0.781500 | 0.18 sec/iter\n",
      "Epoch: 44 | Batch: 001 / 011 | Total loss: 0.714 | Reg loss: 0.026 | Tree loss: 0.714 | Accuracy: 0.765500 | 0.18 sec/iter\n",
      "Epoch: 44 | Batch: 002 / 011 | Total loss: 0.675 | Reg loss: 0.026 | Tree loss: 0.675 | Accuracy: 0.774000 | 0.18 sec/iter\n",
      "Epoch: 44 | Batch: 003 / 011 | Total loss: 0.662 | Reg loss: 0.026 | Tree loss: 0.662 | Accuracy: 0.797500 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 004 / 011 | Total loss: 0.627 | Reg loss: 0.026 | Tree loss: 0.627 | Accuracy: 0.803500 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 005 / 011 | Total loss: 0.616 | Reg loss: 0.026 | Tree loss: 0.616 | Accuracy: 0.815000 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 006 / 011 | Total loss: 0.608 | Reg loss: 0.026 | Tree loss: 0.608 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 007 / 011 | Total loss: 0.597 | Reg loss: 0.026 | Tree loss: 0.597 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 008 / 011 | Total loss: 0.579 | Reg loss: 0.027 | Tree loss: 0.579 | Accuracy: 0.845500 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 009 / 011 | Total loss: 0.571 | Reg loss: 0.027 | Tree loss: 0.571 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 44 | Batch: 010 / 011 | Total loss: 0.617 | Reg loss: 0.027 | Tree loss: 0.617 | Accuracy: 0.839590 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 45 | Batch: 000 / 011 | Total loss: 0.696 | Reg loss: 0.026 | Tree loss: 0.696 | Accuracy: 0.783500 | 0.181 sec/iter\n",
      "Epoch: 45 | Batch: 001 / 011 | Total loss: 0.690 | Reg loss: 0.026 | Tree loss: 0.690 | Accuracy: 0.776500 | 0.18 sec/iter\n",
      "Epoch: 45 | Batch: 002 / 011 | Total loss: 0.664 | Reg loss: 0.026 | Tree loss: 0.664 | Accuracy: 0.788000 | 0.18 sec/iter\n",
      "Epoch: 45 | Batch: 003 / 011 | Total loss: 0.644 | Reg loss: 0.026 | Tree loss: 0.644 | Accuracy: 0.811000 | 0.18 sec/iter\n",
      "Epoch: 45 | Batch: 004 / 011 | Total loss: 0.614 | Reg loss: 0.026 | Tree loss: 0.614 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 45 | Batch: 005 / 011 | Total loss: 0.620 | Reg loss: 0.026 | Tree loss: 0.620 | Accuracy: 0.812000 | 0.18 sec/iter\n",
      "Epoch: 45 | Batch: 006 / 011 | Total loss: 0.604 | Reg loss: 0.027 | Tree loss: 0.604 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 45 | Batch: 007 / 011 | Total loss: 0.568 | Reg loss: 0.027 | Tree loss: 0.568 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 45 | Batch: 008 / 011 | Total loss: 0.573 | Reg loss: 0.027 | Tree loss: 0.573 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 45 | Batch: 009 / 011 | Total loss: 0.594 | Reg loss: 0.027 | Tree loss: 0.594 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 45 | Batch: 010 / 011 | Total loss: 0.563 | Reg loss: 0.027 | Tree loss: 0.563 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 46 | Batch: 000 / 011 | Total loss: 0.717 | Reg loss: 0.026 | Tree loss: 0.717 | Accuracy: 0.751000 | 0.18 sec/iter\n",
      "Epoch: 46 | Batch: 001 / 011 | Total loss: 0.686 | Reg loss: 0.026 | Tree loss: 0.686 | Accuracy: 0.775000 | 0.18 sec/iter\n",
      "Epoch: 46 | Batch: 002 / 011 | Total loss: 0.646 | Reg loss: 0.026 | Tree loss: 0.646 | Accuracy: 0.796500 | 0.18 sec/iter\n",
      "Epoch: 46 | Batch: 003 / 011 | Total loss: 0.633 | Reg loss: 0.026 | Tree loss: 0.633 | Accuracy: 0.801000 | 0.18 sec/iter\n",
      "Epoch: 46 | Batch: 004 / 011 | Total loss: 0.622 | Reg loss: 0.027 | Tree loss: 0.622 | Accuracy: 0.809500 | 0.18 sec/iter\n",
      "Epoch: 46 | Batch: 005 / 011 | Total loss: 0.589 | Reg loss: 0.027 | Tree loss: 0.589 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 46 | Batch: 006 / 011 | Total loss: 0.589 | Reg loss: 0.027 | Tree loss: 0.589 | Accuracy: 0.841500 | 0.179 sec/iter\n",
      "Epoch: 46 | Batch: 007 / 011 | Total loss: 0.588 | Reg loss: 0.027 | Tree loss: 0.588 | Accuracy: 0.844500 | 0.179 sec/iter\n",
      "Epoch: 46 | Batch: 008 / 011 | Total loss: 0.588 | Reg loss: 0.027 | Tree loss: 0.588 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 46 | Batch: 009 / 011 | Total loss: 0.559 | Reg loss: 0.027 | Tree loss: 0.559 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 46 | Batch: 010 / 011 | Total loss: 0.553 | Reg loss: 0.027 | Tree loss: 0.553 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 47 | Batch: 000 / 011 | Total loss: 0.699 | Reg loss: 0.027 | Tree loss: 0.699 | Accuracy: 0.771000 | 0.181 sec/iter\n",
      "Epoch: 47 | Batch: 001 / 011 | Total loss: 0.661 | Reg loss: 0.027 | Tree loss: 0.661 | Accuracy: 0.780500 | 0.181 sec/iter\n",
      "Epoch: 47 | Batch: 002 / 011 | Total loss: 0.640 | Reg loss: 0.027 | Tree loss: 0.640 | Accuracy: 0.795000 | 0.181 sec/iter\n",
      "Epoch: 47 | Batch: 003 / 011 | Total loss: 0.631 | Reg loss: 0.027 | Tree loss: 0.631 | Accuracy: 0.808500 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 004 / 011 | Total loss: 0.615 | Reg loss: 0.027 | Tree loss: 0.615 | Accuracy: 0.808500 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 005 / 011 | Total loss: 0.593 | Reg loss: 0.027 | Tree loss: 0.593 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 006 / 011 | Total loss: 0.583 | Reg loss: 0.027 | Tree loss: 0.583 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 007 / 011 | Total loss: 0.573 | Reg loss: 0.027 | Tree loss: 0.573 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 008 / 011 | Total loss: 0.580 | Reg loss: 0.027 | Tree loss: 0.580 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 009 / 011 | Total loss: 0.581 | Reg loss: 0.027 | Tree loss: 0.581 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 47 | Batch: 010 / 011 | Total loss: 0.544 | Reg loss: 0.027 | Tree loss: 0.544 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 48 | Batch: 000 / 011 | Total loss: 0.678 | Reg loss: 0.027 | Tree loss: 0.678 | Accuracy: 0.782500 | 0.182 sec/iter\n",
      "Epoch: 48 | Batch: 001 / 011 | Total loss: 0.654 | Reg loss: 0.027 | Tree loss: 0.654 | Accuracy: 0.793000 | 0.181 sec/iter\n",
      "Epoch: 48 | Batch: 002 / 011 | Total loss: 0.653 | Reg loss: 0.027 | Tree loss: 0.653 | Accuracy: 0.790500 | 0.181 sec/iter\n",
      "Epoch: 48 | Batch: 003 / 011 | Total loss: 0.612 | Reg loss: 0.027 | Tree loss: 0.612 | Accuracy: 0.813000 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Batch: 004 / 011 | Total loss: 0.607 | Reg loss: 0.027 | Tree loss: 0.607 | Accuracy: 0.813000 | 0.181 sec/iter\n",
      "Epoch: 48 | Batch: 005 / 011 | Total loss: 0.582 | Reg loss: 0.027 | Tree loss: 0.582 | Accuracy: 0.839500 | 0.181 sec/iter\n",
      "Epoch: 48 | Batch: 006 / 011 | Total loss: 0.594 | Reg loss: 0.027 | Tree loss: 0.594 | Accuracy: 0.832000 | 0.181 sec/iter\n",
      "Epoch: 48 | Batch: 007 / 011 | Total loss: 0.567 | Reg loss: 0.027 | Tree loss: 0.567 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 48 | Batch: 008 / 011 | Total loss: 0.571 | Reg loss: 0.027 | Tree loss: 0.571 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 48 | Batch: 009 / 011 | Total loss: 0.572 | Reg loss: 0.027 | Tree loss: 0.572 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 48 | Batch: 010 / 011 | Total loss: 0.594 | Reg loss: 0.027 | Tree loss: 0.594 | Accuracy: 0.832765 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 49 | Batch: 000 / 011 | Total loss: 0.674 | Reg loss: 0.027 | Tree loss: 0.674 | Accuracy: 0.771000 | 0.181 sec/iter\n",
      "Epoch: 49 | Batch: 001 / 011 | Total loss: 0.659 | Reg loss: 0.027 | Tree loss: 0.659 | Accuracy: 0.789500 | 0.181 sec/iter\n",
      "Epoch: 49 | Batch: 002 / 011 | Total loss: 0.647 | Reg loss: 0.027 | Tree loss: 0.647 | Accuracy: 0.782500 | 0.181 sec/iter\n",
      "Epoch: 49 | Batch: 003 / 011 | Total loss: 0.614 | Reg loss: 0.027 | Tree loss: 0.614 | Accuracy: 0.817000 | 0.181 sec/iter\n",
      "Epoch: 49 | Batch: 004 / 011 | Total loss: 0.599 | Reg loss: 0.027 | Tree loss: 0.599 | Accuracy: 0.817500 | 0.181 sec/iter\n",
      "Epoch: 49 | Batch: 005 / 011 | Total loss: 0.584 | Reg loss: 0.027 | Tree loss: 0.584 | Accuracy: 0.818000 | 0.181 sec/iter\n",
      "Epoch: 49 | Batch: 006 / 011 | Total loss: 0.590 | Reg loss: 0.027 | Tree loss: 0.590 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 49 | Batch: 007 / 011 | Total loss: 0.568 | Reg loss: 0.027 | Tree loss: 0.568 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 49 | Batch: 008 / 011 | Total loss: 0.557 | Reg loss: 0.027 | Tree loss: 0.557 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 49 | Batch: 009 / 011 | Total loss: 0.562 | Reg loss: 0.027 | Tree loss: 0.562 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 49 | Batch: 010 / 011 | Total loss: 0.604 | Reg loss: 0.027 | Tree loss: 0.604 | Accuracy: 0.839590 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 50 | Batch: 000 / 011 | Total loss: 0.673 | Reg loss: 0.027 | Tree loss: 0.673 | Accuracy: 0.775500 | 0.182 sec/iter\n",
      "Epoch: 50 | Batch: 001 / 011 | Total loss: 0.653 | Reg loss: 0.027 | Tree loss: 0.653 | Accuracy: 0.776500 | 0.182 sec/iter\n",
      "Epoch: 50 | Batch: 002 / 011 | Total loss: 0.636 | Reg loss: 0.027 | Tree loss: 0.636 | Accuracy: 0.794000 | 0.182 sec/iter\n",
      "Epoch: 50 | Batch: 003 / 011 | Total loss: 0.599 | Reg loss: 0.027 | Tree loss: 0.599 | Accuracy: 0.813500 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 004 / 011 | Total loss: 0.572 | Reg loss: 0.027 | Tree loss: 0.572 | Accuracy: 0.829500 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 005 / 011 | Total loss: 0.577 | Reg loss: 0.027 | Tree loss: 0.577 | Accuracy: 0.833000 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 006 / 011 | Total loss: 0.585 | Reg loss: 0.027 | Tree loss: 0.585 | Accuracy: 0.847500 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 007 / 011 | Total loss: 0.570 | Reg loss: 0.027 | Tree loss: 0.570 | Accuracy: 0.838500 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 008 / 011 | Total loss: 0.565 | Reg loss: 0.027 | Tree loss: 0.565 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 009 / 011 | Total loss: 0.561 | Reg loss: 0.027 | Tree loss: 0.561 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 50 | Batch: 010 / 011 | Total loss: 0.541 | Reg loss: 0.027 | Tree loss: 0.541 | Accuracy: 0.873720 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 51 | Batch: 000 / 011 | Total loss: 0.650 | Reg loss: 0.027 | Tree loss: 0.650 | Accuracy: 0.785500 | 0.183 sec/iter\n",
      "Epoch: 51 | Batch: 001 / 011 | Total loss: 0.660 | Reg loss: 0.027 | Tree loss: 0.660 | Accuracy: 0.775500 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 002 / 011 | Total loss: 0.652 | Reg loss: 0.027 | Tree loss: 0.652 | Accuracy: 0.781000 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 003 / 011 | Total loss: 0.612 | Reg loss: 0.027 | Tree loss: 0.612 | Accuracy: 0.815500 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 004 / 011 | Total loss: 0.595 | Reg loss: 0.027 | Tree loss: 0.595 | Accuracy: 0.804500 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 005 / 011 | Total loss: 0.567 | Reg loss: 0.027 | Tree loss: 0.567 | Accuracy: 0.834000 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 006 / 011 | Total loss: 0.561 | Reg loss: 0.027 | Tree loss: 0.561 | Accuracy: 0.848500 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 007 / 011 | Total loss: 0.539 | Reg loss: 0.027 | Tree loss: 0.539 | Accuracy: 0.861500 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 008 / 011 | Total loss: 0.546 | Reg loss: 0.027 | Tree loss: 0.546 | Accuracy: 0.873500 | 0.182 sec/iter\n",
      "Epoch: 51 | Batch: 009 / 011 | Total loss: 0.569 | Reg loss: 0.027 | Tree loss: 0.569 | Accuracy: 0.858500 | 0.181 sec/iter\n",
      "Epoch: 51 | Batch: 010 / 011 | Total loss: 0.595 | Reg loss: 0.027 | Tree loss: 0.595 | Accuracy: 0.853242 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 52 | Batch: 000 / 011 | Total loss: 0.669 | Reg loss: 0.027 | Tree loss: 0.669 | Accuracy: 0.783000 | 0.183 sec/iter\n",
      "Epoch: 52 | Batch: 001 / 011 | Total loss: 0.667 | Reg loss: 0.027 | Tree loss: 0.667 | Accuracy: 0.773000 | 0.183 sec/iter\n",
      "Epoch: 52 | Batch: 002 / 011 | Total loss: 0.633 | Reg loss: 0.027 | Tree loss: 0.633 | Accuracy: 0.791000 | 0.183 sec/iter\n",
      "Epoch: 52 | Batch: 003 / 011 | Total loss: 0.611 | Reg loss: 0.027 | Tree loss: 0.611 | Accuracy: 0.803500 | 0.183 sec/iter\n",
      "Epoch: 52 | Batch: 004 / 011 | Total loss: 0.580 | Reg loss: 0.027 | Tree loss: 0.580 | Accuracy: 0.822000 | 0.183 sec/iter\n",
      "Epoch: 52 | Batch: 005 / 011 | Total loss: 0.564 | Reg loss: 0.027 | Tree loss: 0.564 | Accuracy: 0.846500 | 0.182 sec/iter\n",
      "Epoch: 52 | Batch: 006 / 011 | Total loss: 0.566 | Reg loss: 0.027 | Tree loss: 0.566 | Accuracy: 0.843000 | 0.182 sec/iter\n",
      "Epoch: 52 | Batch: 007 / 011 | Total loss: 0.543 | Reg loss: 0.027 | Tree loss: 0.543 | Accuracy: 0.867000 | 0.182 sec/iter\n",
      "Epoch: 52 | Batch: 008 / 011 | Total loss: 0.535 | Reg loss: 0.027 | Tree loss: 0.535 | Accuracy: 0.866500 | 0.182 sec/iter\n",
      "Epoch: 52 | Batch: 009 / 011 | Total loss: 0.549 | Reg loss: 0.027 | Tree loss: 0.549 | Accuracy: 0.864500 | 0.182 sec/iter\n",
      "Epoch: 52 | Batch: 010 / 011 | Total loss: 0.540 | Reg loss: 0.027 | Tree loss: 0.540 | Accuracy: 0.873720 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 53 | Batch: 000 / 011 | Total loss: 0.651 | Reg loss: 0.027 | Tree loss: 0.651 | Accuracy: 0.781000 | 0.183 sec/iter\n",
      "Epoch: 53 | Batch: 001 / 011 | Total loss: 0.642 | Reg loss: 0.027 | Tree loss: 0.642 | Accuracy: 0.784500 | 0.183 sec/iter\n",
      "Epoch: 53 | Batch: 002 / 011 | Total loss: 0.606 | Reg loss: 0.027 | Tree loss: 0.606 | Accuracy: 0.796000 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 003 / 011 | Total loss: 0.622 | Reg loss: 0.027 | Tree loss: 0.622 | Accuracy: 0.798500 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 004 / 011 | Total loss: 0.586 | Reg loss: 0.027 | Tree loss: 0.586 | Accuracy: 0.816500 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 005 / 011 | Total loss: 0.577 | Reg loss: 0.027 | Tree loss: 0.577 | Accuracy: 0.819000 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 006 / 011 | Total loss: 0.559 | Reg loss: 0.027 | Tree loss: 0.559 | Accuracy: 0.832500 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 007 / 011 | Total loss: 0.547 | Reg loss: 0.027 | Tree loss: 0.547 | Accuracy: 0.855500 | 0.182 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 | Batch: 008 / 011 | Total loss: 0.529 | Reg loss: 0.027 | Tree loss: 0.529 | Accuracy: 0.874500 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 009 / 011 | Total loss: 0.556 | Reg loss: 0.027 | Tree loss: 0.556 | Accuracy: 0.850000 | 0.182 sec/iter\n",
      "Epoch: 53 | Batch: 010 / 011 | Total loss: 0.551 | Reg loss: 0.027 | Tree loss: 0.551 | Accuracy: 0.866894 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 54 | Batch: 000 / 011 | Total loss: 0.658 | Reg loss: 0.027 | Tree loss: 0.658 | Accuracy: 0.778000 | 0.183 sec/iter\n",
      "Epoch: 54 | Batch: 001 / 011 | Total loss: 0.614 | Reg loss: 0.027 | Tree loss: 0.614 | Accuracy: 0.803500 | 0.183 sec/iter\n",
      "Epoch: 54 | Batch: 002 / 011 | Total loss: 0.641 | Reg loss: 0.027 | Tree loss: 0.641 | Accuracy: 0.780000 | 0.183 sec/iter\n",
      "Epoch: 54 | Batch: 003 / 011 | Total loss: 0.591 | Reg loss: 0.027 | Tree loss: 0.591 | Accuracy: 0.803500 | 0.183 sec/iter\n",
      "Epoch: 54 | Batch: 004 / 011 | Total loss: 0.567 | Reg loss: 0.027 | Tree loss: 0.567 | Accuracy: 0.827000 | 0.183 sec/iter\n",
      "Epoch: 54 | Batch: 005 / 011 | Total loss: 0.581 | Reg loss: 0.027 | Tree loss: 0.581 | Accuracy: 0.821500 | 0.183 sec/iter\n",
      "Epoch: 54 | Batch: 006 / 011 | Total loss: 0.563 | Reg loss: 0.027 | Tree loss: 0.563 | Accuracy: 0.833500 | 0.182 sec/iter\n",
      "Epoch: 54 | Batch: 007 / 011 | Total loss: 0.554 | Reg loss: 0.027 | Tree loss: 0.554 | Accuracy: 0.841500 | 0.182 sec/iter\n",
      "Epoch: 54 | Batch: 008 / 011 | Total loss: 0.528 | Reg loss: 0.027 | Tree loss: 0.528 | Accuracy: 0.866000 | 0.182 sec/iter\n",
      "Epoch: 54 | Batch: 009 / 011 | Total loss: 0.537 | Reg loss: 0.027 | Tree loss: 0.537 | Accuracy: 0.875500 | 0.182 sec/iter\n",
      "Epoch: 54 | Batch: 010 / 011 | Total loss: 0.506 | Reg loss: 0.027 | Tree loss: 0.506 | Accuracy: 0.880546 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 55 | Batch: 000 / 011 | Total loss: 0.614 | Reg loss: 0.027 | Tree loss: 0.614 | Accuracy: 0.800000 | 0.184 sec/iter\n",
      "Epoch: 55 | Batch: 001 / 011 | Total loss: 0.652 | Reg loss: 0.027 | Tree loss: 0.652 | Accuracy: 0.785500 | 0.184 sec/iter\n",
      "Epoch: 55 | Batch: 002 / 011 | Total loss: 0.607 | Reg loss: 0.027 | Tree loss: 0.607 | Accuracy: 0.803000 | 0.184 sec/iter\n",
      "Epoch: 55 | Batch: 003 / 011 | Total loss: 0.592 | Reg loss: 0.027 | Tree loss: 0.592 | Accuracy: 0.813000 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 004 / 011 | Total loss: 0.579 | Reg loss: 0.027 | Tree loss: 0.579 | Accuracy: 0.818000 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 005 / 011 | Total loss: 0.560 | Reg loss: 0.027 | Tree loss: 0.560 | Accuracy: 0.831000 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 006 / 011 | Total loss: 0.559 | Reg loss: 0.027 | Tree loss: 0.559 | Accuracy: 0.839000 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 007 / 011 | Total loss: 0.545 | Reg loss: 0.027 | Tree loss: 0.545 | Accuracy: 0.844000 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 008 / 011 | Total loss: 0.563 | Reg loss: 0.027 | Tree loss: 0.563 | Accuracy: 0.845000 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 009 / 011 | Total loss: 0.541 | Reg loss: 0.027 | Tree loss: 0.541 | Accuracy: 0.864500 | 0.183 sec/iter\n",
      "Epoch: 55 | Batch: 010 / 011 | Total loss: 0.534 | Reg loss: 0.027 | Tree loss: 0.534 | Accuracy: 0.863481 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 56 | Batch: 000 / 011 | Total loss: 0.653 | Reg loss: 0.027 | Tree loss: 0.653 | Accuracy: 0.779000 | 0.184 sec/iter\n",
      "Epoch: 56 | Batch: 001 / 011 | Total loss: 0.627 | Reg loss: 0.027 | Tree loss: 0.627 | Accuracy: 0.793500 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 002 / 011 | Total loss: 0.605 | Reg loss: 0.027 | Tree loss: 0.605 | Accuracy: 0.807500 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 003 / 011 | Total loss: 0.598 | Reg loss: 0.027 | Tree loss: 0.598 | Accuracy: 0.796000 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 004 / 011 | Total loss: 0.557 | Reg loss: 0.027 | Tree loss: 0.557 | Accuracy: 0.817000 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 005 / 011 | Total loss: 0.553 | Reg loss: 0.027 | Tree loss: 0.553 | Accuracy: 0.834500 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 006 / 011 | Total loss: 0.546 | Reg loss: 0.027 | Tree loss: 0.546 | Accuracy: 0.845500 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 007 / 011 | Total loss: 0.532 | Reg loss: 0.027 | Tree loss: 0.532 | Accuracy: 0.869000 | 0.183 sec/iter\n",
      "Epoch: 56 | Batch: 008 / 011 | Total loss: 0.545 | Reg loss: 0.027 | Tree loss: 0.545 | Accuracy: 0.853500 | 0.182 sec/iter\n",
      "Epoch: 56 | Batch: 009 / 011 | Total loss: 0.538 | Reg loss: 0.027 | Tree loss: 0.538 | Accuracy: 0.851000 | 0.182 sec/iter\n",
      "Epoch: 56 | Batch: 010 / 011 | Total loss: 0.583 | Reg loss: 0.027 | Tree loss: 0.583 | Accuracy: 0.819113 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 57 | Batch: 000 / 011 | Total loss: 0.635 | Reg loss: 0.027 | Tree loss: 0.635 | Accuracy: 0.782500 | 0.184 sec/iter\n",
      "Epoch: 57 | Batch: 001 / 011 | Total loss: 0.631 | Reg loss: 0.027 | Tree loss: 0.631 | Accuracy: 0.791500 | 0.184 sec/iter\n",
      "Epoch: 57 | Batch: 002 / 011 | Total loss: 0.595 | Reg loss: 0.027 | Tree loss: 0.595 | Accuracy: 0.807000 | 0.184 sec/iter\n",
      "Epoch: 57 | Batch: 003 / 011 | Total loss: 0.581 | Reg loss: 0.027 | Tree loss: 0.581 | Accuracy: 0.820000 | 0.184 sec/iter\n",
      "Epoch: 57 | Batch: 004 / 011 | Total loss: 0.558 | Reg loss: 0.027 | Tree loss: 0.558 | Accuracy: 0.822500 | 0.183 sec/iter\n",
      "Epoch: 57 | Batch: 005 / 011 | Total loss: 0.553 | Reg loss: 0.027 | Tree loss: 0.553 | Accuracy: 0.836000 | 0.183 sec/iter\n",
      "Epoch: 57 | Batch: 006 / 011 | Total loss: 0.549 | Reg loss: 0.027 | Tree loss: 0.549 | Accuracy: 0.844000 | 0.183 sec/iter\n",
      "Epoch: 57 | Batch: 007 / 011 | Total loss: 0.532 | Reg loss: 0.027 | Tree loss: 0.532 | Accuracy: 0.866500 | 0.183 sec/iter\n",
      "Epoch: 57 | Batch: 008 / 011 | Total loss: 0.562 | Reg loss: 0.027 | Tree loss: 0.562 | Accuracy: 0.840500 | 0.183 sec/iter\n",
      "Epoch: 57 | Batch: 009 / 011 | Total loss: 0.521 | Reg loss: 0.027 | Tree loss: 0.521 | Accuracy: 0.869500 | 0.183 sec/iter\n",
      "Epoch: 57 | Batch: 010 / 011 | Total loss: 0.516 | Reg loss: 0.027 | Tree loss: 0.516 | Accuracy: 0.883959 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 58 | Batch: 000 / 011 | Total loss: 0.638 | Reg loss: 0.027 | Tree loss: 0.638 | Accuracy: 0.776500 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 001 / 011 | Total loss: 0.623 | Reg loss: 0.027 | Tree loss: 0.623 | Accuracy: 0.786500 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 002 / 011 | Total loss: 0.597 | Reg loss: 0.027 | Tree loss: 0.597 | Accuracy: 0.808000 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 003 / 011 | Total loss: 0.565 | Reg loss: 0.027 | Tree loss: 0.565 | Accuracy: 0.826000 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 004 / 011 | Total loss: 0.559 | Reg loss: 0.027 | Tree loss: 0.559 | Accuracy: 0.831000 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 005 / 011 | Total loss: 0.555 | Reg loss: 0.027 | Tree loss: 0.555 | Accuracy: 0.824000 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 006 / 011 | Total loss: 0.543 | Reg loss: 0.027 | Tree loss: 0.543 | Accuracy: 0.841000 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 007 / 011 | Total loss: 0.521 | Reg loss: 0.027 | Tree loss: 0.521 | Accuracy: 0.875000 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 008 / 011 | Total loss: 0.545 | Reg loss: 0.027 | Tree loss: 0.545 | Accuracy: 0.845500 | 0.184 sec/iter\n",
      "Epoch: 58 | Batch: 009 / 011 | Total loss: 0.534 | Reg loss: 0.027 | Tree loss: 0.534 | Accuracy: 0.861000 | 0.183 sec/iter\n",
      "Epoch: 58 | Batch: 010 / 011 | Total loss: 0.542 | Reg loss: 0.027 | Tree loss: 0.542 | Accuracy: 0.853242 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 | Batch: 000 / 011 | Total loss: 0.643 | Reg loss: 0.027 | Tree loss: 0.643 | Accuracy: 0.778000 | 0.185 sec/iter\n",
      "Epoch: 59 | Batch: 001 / 011 | Total loss: 0.601 | Reg loss: 0.027 | Tree loss: 0.601 | Accuracy: 0.803500 | 0.185 sec/iter\n",
      "Epoch: 59 | Batch: 002 / 011 | Total loss: 0.595 | Reg loss: 0.027 | Tree loss: 0.595 | Accuracy: 0.810000 | 0.185 sec/iter\n",
      "Epoch: 59 | Batch: 003 / 011 | Total loss: 0.565 | Reg loss: 0.027 | Tree loss: 0.565 | Accuracy: 0.831000 | 0.185 sec/iter\n",
      "Epoch: 59 | Batch: 004 / 011 | Total loss: 0.545 | Reg loss: 0.027 | Tree loss: 0.545 | Accuracy: 0.844000 | 0.185 sec/iter\n",
      "Epoch: 59 | Batch: 005 / 011 | Total loss: 0.538 | Reg loss: 0.027 | Tree loss: 0.538 | Accuracy: 0.847000 | 0.184 sec/iter\n",
      "Epoch: 59 | Batch: 006 / 011 | Total loss: 0.545 | Reg loss: 0.027 | Tree loss: 0.545 | Accuracy: 0.838500 | 0.184 sec/iter\n",
      "Epoch: 59 | Batch: 007 / 011 | Total loss: 0.534 | Reg loss: 0.027 | Tree loss: 0.534 | Accuracy: 0.854500 | 0.184 sec/iter\n",
      "Epoch: 59 | Batch: 008 / 011 | Total loss: 0.546 | Reg loss: 0.027 | Tree loss: 0.546 | Accuracy: 0.848500 | 0.184 sec/iter\n",
      "Epoch: 59 | Batch: 009 / 011 | Total loss: 0.547 | Reg loss: 0.027 | Tree loss: 0.547 | Accuracy: 0.853500 | 0.184 sec/iter\n",
      "Epoch: 59 | Batch: 010 / 011 | Total loss: 0.501 | Reg loss: 0.027 | Tree loss: 0.501 | Accuracy: 0.873720 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 60 | Batch: 000 / 011 | Total loss: 0.630 | Reg loss: 0.027 | Tree loss: 0.630 | Accuracy: 0.793500 | 0.185 sec/iter\n",
      "Epoch: 60 | Batch: 001 / 011 | Total loss: 0.598 | Reg loss: 0.027 | Tree loss: 0.598 | Accuracy: 0.802000 | 0.185 sec/iter\n",
      "Epoch: 60 | Batch: 002 / 011 | Total loss: 0.597 | Reg loss: 0.027 | Tree loss: 0.597 | Accuracy: 0.804500 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 003 / 011 | Total loss: 0.573 | Reg loss: 0.027 | Tree loss: 0.573 | Accuracy: 0.813500 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 004 / 011 | Total loss: 0.578 | Reg loss: 0.027 | Tree loss: 0.578 | Accuracy: 0.806500 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 005 / 011 | Total loss: 0.557 | Reg loss: 0.027 | Tree loss: 0.557 | Accuracy: 0.832000 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 006 / 011 | Total loss: 0.535 | Reg loss: 0.027 | Tree loss: 0.535 | Accuracy: 0.842500 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 007 / 011 | Total loss: 0.508 | Reg loss: 0.027 | Tree loss: 0.508 | Accuracy: 0.865500 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 008 / 011 | Total loss: 0.538 | Reg loss: 0.027 | Tree loss: 0.538 | Accuracy: 0.854000 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 009 / 011 | Total loss: 0.510 | Reg loss: 0.027 | Tree loss: 0.510 | Accuracy: 0.875500 | 0.184 sec/iter\n",
      "Epoch: 60 | Batch: 010 / 011 | Total loss: 0.526 | Reg loss: 0.027 | Tree loss: 0.526 | Accuracy: 0.843003 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 61 | Batch: 000 / 011 | Total loss: 0.617 | Reg loss: 0.027 | Tree loss: 0.617 | Accuracy: 0.787000 | 0.185 sec/iter\n",
      "Epoch: 61 | Batch: 001 / 011 | Total loss: 0.602 | Reg loss: 0.027 | Tree loss: 0.602 | Accuracy: 0.806500 | 0.185 sec/iter\n",
      "Epoch: 61 | Batch: 002 / 011 | Total loss: 0.587 | Reg loss: 0.027 | Tree loss: 0.587 | Accuracy: 0.813500 | 0.185 sec/iter\n",
      "Epoch: 61 | Batch: 003 / 011 | Total loss: 0.565 | Reg loss: 0.027 | Tree loss: 0.565 | Accuracy: 0.812500 | 0.185 sec/iter\n",
      "Epoch: 61 | Batch: 004 / 011 | Total loss: 0.548 | Reg loss: 0.027 | Tree loss: 0.548 | Accuracy: 0.825500 | 0.185 sec/iter\n",
      "Epoch: 61 | Batch: 005 / 011 | Total loss: 0.562 | Reg loss: 0.027 | Tree loss: 0.562 | Accuracy: 0.824500 | 0.185 sec/iter\n",
      "Epoch: 61 | Batch: 006 / 011 | Total loss: 0.532 | Reg loss: 0.027 | Tree loss: 0.532 | Accuracy: 0.850500 | 0.184 sec/iter\n",
      "Epoch: 61 | Batch: 007 / 011 | Total loss: 0.530 | Reg loss: 0.027 | Tree loss: 0.530 | Accuracy: 0.859000 | 0.184 sec/iter\n",
      "Epoch: 61 | Batch: 008 / 011 | Total loss: 0.526 | Reg loss: 0.027 | Tree loss: 0.526 | Accuracy: 0.864500 | 0.184 sec/iter\n",
      "Epoch: 61 | Batch: 009 / 011 | Total loss: 0.519 | Reg loss: 0.027 | Tree loss: 0.519 | Accuracy: 0.864000 | 0.184 sec/iter\n",
      "Epoch: 61 | Batch: 010 / 011 | Total loss: 0.544 | Reg loss: 0.027 | Tree loss: 0.544 | Accuracy: 0.846416 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 62 | Batch: 000 / 011 | Total loss: 0.614 | Reg loss: 0.027 | Tree loss: 0.614 | Accuracy: 0.793500 | 0.186 sec/iter\n",
      "Epoch: 62 | Batch: 001 / 011 | Total loss: 0.627 | Reg loss: 0.027 | Tree loss: 0.627 | Accuracy: 0.780000 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 002 / 011 | Total loss: 0.578 | Reg loss: 0.027 | Tree loss: 0.578 | Accuracy: 0.805500 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 003 / 011 | Total loss: 0.560 | Reg loss: 0.027 | Tree loss: 0.560 | Accuracy: 0.827500 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 004 / 011 | Total loss: 0.550 | Reg loss: 0.027 | Tree loss: 0.550 | Accuracy: 0.825500 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 005 / 011 | Total loss: 0.548 | Reg loss: 0.027 | Tree loss: 0.548 | Accuracy: 0.837500 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 006 / 011 | Total loss: 0.510 | Reg loss: 0.027 | Tree loss: 0.510 | Accuracy: 0.870000 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 007 / 011 | Total loss: 0.536 | Reg loss: 0.027 | Tree loss: 0.536 | Accuracy: 0.850500 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 008 / 011 | Total loss: 0.518 | Reg loss: 0.027 | Tree loss: 0.518 | Accuracy: 0.869000 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 009 / 011 | Total loss: 0.530 | Reg loss: 0.027 | Tree loss: 0.530 | Accuracy: 0.872000 | 0.185 sec/iter\n",
      "Epoch: 62 | Batch: 010 / 011 | Total loss: 0.505 | Reg loss: 0.027 | Tree loss: 0.505 | Accuracy: 0.883959 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 63 | Batch: 000 / 011 | Total loss: 0.614 | Reg loss: 0.027 | Tree loss: 0.614 | Accuracy: 0.792000 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 001 / 011 | Total loss: 0.597 | Reg loss: 0.027 | Tree loss: 0.597 | Accuracy: 0.803000 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 002 / 011 | Total loss: 0.586 | Reg loss: 0.027 | Tree loss: 0.586 | Accuracy: 0.793500 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 003 / 011 | Total loss: 0.561 | Reg loss: 0.027 | Tree loss: 0.561 | Accuracy: 0.814500 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 004 / 011 | Total loss: 0.542 | Reg loss: 0.027 | Tree loss: 0.542 | Accuracy: 0.835000 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 005 / 011 | Total loss: 0.547 | Reg loss: 0.027 | Tree loss: 0.547 | Accuracy: 0.841000 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 006 / 011 | Total loss: 0.519 | Reg loss: 0.027 | Tree loss: 0.519 | Accuracy: 0.857500 | 0.185 sec/iter\n",
      "Epoch: 63 | Batch: 007 / 011 | Total loss: 0.504 | Reg loss: 0.027 | Tree loss: 0.504 | Accuracy: 0.875500 | 0.184 sec/iter\n",
      "Epoch: 63 | Batch: 008 / 011 | Total loss: 0.525 | Reg loss: 0.027 | Tree loss: 0.525 | Accuracy: 0.848000 | 0.184 sec/iter\n",
      "Epoch: 63 | Batch: 009 / 011 | Total loss: 0.533 | Reg loss: 0.027 | Tree loss: 0.533 | Accuracy: 0.856500 | 0.184 sec/iter\n",
      "Epoch: 63 | Batch: 010 / 011 | Total loss: 0.524 | Reg loss: 0.027 | Tree loss: 0.524 | Accuracy: 0.866894 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 64 | Batch: 000 / 011 | Total loss: 0.611 | Reg loss: 0.027 | Tree loss: 0.611 | Accuracy: 0.797500 | 0.186 sec/iter\n",
      "Epoch: 64 | Batch: 001 / 011 | Total loss: 0.581 | Reg loss: 0.027 | Tree loss: 0.581 | Accuracy: 0.806000 | 0.186 sec/iter\n",
      "Epoch: 64 | Batch: 002 / 011 | Total loss: 0.570 | Reg loss: 0.027 | Tree loss: 0.570 | Accuracy: 0.812000 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 003 / 011 | Total loss: 0.561 | Reg loss: 0.027 | Tree loss: 0.561 | Accuracy: 0.809500 | 0.185 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 | Batch: 004 / 011 | Total loss: 0.542 | Reg loss: 0.027 | Tree loss: 0.542 | Accuracy: 0.823500 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 005 / 011 | Total loss: 0.534 | Reg loss: 0.027 | Tree loss: 0.534 | Accuracy: 0.846000 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 006 / 011 | Total loss: 0.531 | Reg loss: 0.027 | Tree loss: 0.531 | Accuracy: 0.853500 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 007 / 011 | Total loss: 0.519 | Reg loss: 0.027 | Tree loss: 0.519 | Accuracy: 0.854500 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 008 / 011 | Total loss: 0.524 | Reg loss: 0.027 | Tree loss: 0.524 | Accuracy: 0.864000 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 009 / 011 | Total loss: 0.523 | Reg loss: 0.027 | Tree loss: 0.523 | Accuracy: 0.865000 | 0.185 sec/iter\n",
      "Epoch: 64 | Batch: 010 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.890785 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 65 | Batch: 000 / 011 | Total loss: 0.601 | Reg loss: 0.027 | Tree loss: 0.601 | Accuracy: 0.790500 | 0.186 sec/iter\n",
      "Epoch: 65 | Batch: 001 / 011 | Total loss: 0.586 | Reg loss: 0.027 | Tree loss: 0.586 | Accuracy: 0.807500 | 0.186 sec/iter\n",
      "Epoch: 65 | Batch: 002 / 011 | Total loss: 0.576 | Reg loss: 0.027 | Tree loss: 0.576 | Accuracy: 0.804000 | 0.186 sec/iter\n",
      "Epoch: 65 | Batch: 003 / 011 | Total loss: 0.578 | Reg loss: 0.027 | Tree loss: 0.578 | Accuracy: 0.793000 | 0.186 sec/iter\n",
      "Epoch: 65 | Batch: 004 / 011 | Total loss: 0.538 | Reg loss: 0.027 | Tree loss: 0.538 | Accuracy: 0.828500 | 0.186 sec/iter\n",
      "Epoch: 65 | Batch: 005 / 011 | Total loss: 0.526 | Reg loss: 0.027 | Tree loss: 0.526 | Accuracy: 0.848000 | 0.186 sec/iter\n",
      "Epoch: 65 | Batch: 006 / 011 | Total loss: 0.517 | Reg loss: 0.027 | Tree loss: 0.517 | Accuracy: 0.850500 | 0.185 sec/iter\n",
      "Epoch: 65 | Batch: 007 / 011 | Total loss: 0.507 | Reg loss: 0.027 | Tree loss: 0.507 | Accuracy: 0.868000 | 0.185 sec/iter\n",
      "Epoch: 65 | Batch: 008 / 011 | Total loss: 0.508 | Reg loss: 0.028 | Tree loss: 0.508 | Accuracy: 0.874500 | 0.185 sec/iter\n",
      "Epoch: 65 | Batch: 009 / 011 | Total loss: 0.529 | Reg loss: 0.028 | Tree loss: 0.529 | Accuracy: 0.858500 | 0.185 sec/iter\n",
      "Epoch: 65 | Batch: 010 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.860068 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 66 | Batch: 000 / 011 | Total loss: 0.622 | Reg loss: 0.027 | Tree loss: 0.622 | Accuracy: 0.781500 | 0.187 sec/iter\n",
      "Epoch: 66 | Batch: 001 / 011 | Total loss: 0.582 | Reg loss: 0.027 | Tree loss: 0.582 | Accuracy: 0.802500 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 002 / 011 | Total loss: 0.577 | Reg loss: 0.027 | Tree loss: 0.577 | Accuracy: 0.804500 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 003 / 011 | Total loss: 0.548 | Reg loss: 0.027 | Tree loss: 0.548 | Accuracy: 0.819000 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 004 / 011 | Total loss: 0.522 | Reg loss: 0.027 | Tree loss: 0.522 | Accuracy: 0.834000 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 005 / 011 | Total loss: 0.530 | Reg loss: 0.027 | Tree loss: 0.530 | Accuracy: 0.840000 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 006 / 011 | Total loss: 0.538 | Reg loss: 0.027 | Tree loss: 0.538 | Accuracy: 0.855500 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 007 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.875000 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 008 / 011 | Total loss: 0.518 | Reg loss: 0.028 | Tree loss: 0.518 | Accuracy: 0.864000 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 009 / 011 | Total loss: 0.507 | Reg loss: 0.028 | Tree loss: 0.507 | Accuracy: 0.858000 | 0.186 sec/iter\n",
      "Epoch: 66 | Batch: 010 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.839590 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 67 | Batch: 000 / 011 | Total loss: 0.590 | Reg loss: 0.027 | Tree loss: 0.590 | Accuracy: 0.795500 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 001 / 011 | Total loss: 0.596 | Reg loss: 0.027 | Tree loss: 0.596 | Accuracy: 0.796500 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 002 / 011 | Total loss: 0.536 | Reg loss: 0.027 | Tree loss: 0.536 | Accuracy: 0.832500 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 003 / 011 | Total loss: 0.567 | Reg loss: 0.027 | Tree loss: 0.567 | Accuracy: 0.792500 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 004 / 011 | Total loss: 0.545 | Reg loss: 0.027 | Tree loss: 0.545 | Accuracy: 0.817000 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 005 / 011 | Total loss: 0.524 | Reg loss: 0.027 | Tree loss: 0.524 | Accuracy: 0.839000 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 006 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.855500 | 0.186 sec/iter\n",
      "Epoch: 67 | Batch: 007 / 011 | Total loss: 0.524 | Reg loss: 0.028 | Tree loss: 0.524 | Accuracy: 0.853500 | 0.185 sec/iter\n",
      "Epoch: 67 | Batch: 008 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.873000 | 0.185 sec/iter\n",
      "Epoch: 67 | Batch: 009 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.855000 | 0.185 sec/iter\n",
      "Epoch: 67 | Batch: 010 / 011 | Total loss: 0.514 | Reg loss: 0.028 | Tree loss: 0.514 | Accuracy: 0.860068 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 68 | Batch: 000 / 011 | Total loss: 0.592 | Reg loss: 0.027 | Tree loss: 0.592 | Accuracy: 0.806000 | 0.187 sec/iter\n",
      "Epoch: 68 | Batch: 001 / 011 | Total loss: 0.577 | Reg loss: 0.027 | Tree loss: 0.577 | Accuracy: 0.804000 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 002 / 011 | Total loss: 0.568 | Reg loss: 0.027 | Tree loss: 0.568 | Accuracy: 0.818500 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 003 / 011 | Total loss: 0.547 | Reg loss: 0.027 | Tree loss: 0.547 | Accuracy: 0.819500 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 004 / 011 | Total loss: 0.538 | Reg loss: 0.027 | Tree loss: 0.538 | Accuracy: 0.837500 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 005 / 011 | Total loss: 0.507 | Reg loss: 0.028 | Tree loss: 0.507 | Accuracy: 0.863000 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 006 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.860000 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 007 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.850000 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 008 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.866000 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 009 / 011 | Total loss: 0.507 | Reg loss: 0.028 | Tree loss: 0.507 | Accuracy: 0.866500 | 0.186 sec/iter\n",
      "Epoch: 68 | Batch: 010 / 011 | Total loss: 0.550 | Reg loss: 0.028 | Tree loss: 0.550 | Accuracy: 0.825939 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 69 | Batch: 000 / 011 | Total loss: 0.616 | Reg loss: 0.027 | Tree loss: 0.616 | Accuracy: 0.788000 | 0.186 sec/iter\n",
      "Epoch: 69 | Batch: 001 / 011 | Total loss: 0.564 | Reg loss: 0.027 | Tree loss: 0.564 | Accuracy: 0.804000 | 0.186 sec/iter\n",
      "Epoch: 69 | Batch: 002 / 011 | Total loss: 0.562 | Reg loss: 0.027 | Tree loss: 0.562 | Accuracy: 0.805500 | 0.186 sec/iter\n",
      "Epoch: 69 | Batch: 003 / 011 | Total loss: 0.552 | Reg loss: 0.027 | Tree loss: 0.552 | Accuracy: 0.826000 | 0.186 sec/iter\n",
      "Epoch: 69 | Batch: 004 / 011 | Total loss: 0.534 | Reg loss: 0.028 | Tree loss: 0.534 | Accuracy: 0.829000 | 0.186 sec/iter\n",
      "Epoch: 69 | Batch: 005 / 011 | Total loss: 0.508 | Reg loss: 0.028 | Tree loss: 0.508 | Accuracy: 0.848500 | 0.186 sec/iter\n",
      "Epoch: 69 | Batch: 006 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.852500 | 0.185 sec/iter\n",
      "Epoch: 69 | Batch: 007 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.852000 | 0.185 sec/iter\n",
      "Epoch: 69 | Batch: 008 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.876500 | 0.185 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 | Batch: 009 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.862000 | 0.185 sec/iter\n",
      "Epoch: 69 | Batch: 010 / 011 | Total loss: 0.479 | Reg loss: 0.028 | Tree loss: 0.479 | Accuracy: 0.873720 | 0.185 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 70 | Batch: 000 / 011 | Total loss: 0.580 | Reg loss: 0.028 | Tree loss: 0.580 | Accuracy: 0.804000 | 0.185 sec/iter\n",
      "Epoch: 70 | Batch: 001 / 011 | Total loss: 0.574 | Reg loss: 0.028 | Tree loss: 0.574 | Accuracy: 0.807500 | 0.185 sec/iter\n",
      "Epoch: 70 | Batch: 002 / 011 | Total loss: 0.562 | Reg loss: 0.028 | Tree loss: 0.562 | Accuracy: 0.810000 | 0.185 sec/iter\n",
      "Epoch: 70 | Batch: 003 / 011 | Total loss: 0.561 | Reg loss: 0.028 | Tree loss: 0.561 | Accuracy: 0.807000 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 004 / 011 | Total loss: 0.531 | Reg loss: 0.028 | Tree loss: 0.531 | Accuracy: 0.845000 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 005 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.853500 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 006 / 011 | Total loss: 0.518 | Reg loss: 0.028 | Tree loss: 0.518 | Accuracy: 0.857000 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 007 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.867000 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 008 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.875000 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 009 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.872500 | 0.184 sec/iter\n",
      "Epoch: 70 | Batch: 010 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.853242 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 71 | Batch: 000 / 011 | Total loss: 0.603 | Reg loss: 0.028 | Tree loss: 0.603 | Accuracy: 0.793500 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 001 / 011 | Total loss: 0.580 | Reg loss: 0.028 | Tree loss: 0.580 | Accuracy: 0.794000 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 002 / 011 | Total loss: 0.559 | Reg loss: 0.028 | Tree loss: 0.559 | Accuracy: 0.819500 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 003 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.834000 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 004 / 011 | Total loss: 0.543 | Reg loss: 0.028 | Tree loss: 0.543 | Accuracy: 0.822500 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 005 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.844000 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 006 / 011 | Total loss: 0.519 | Reg loss: 0.028 | Tree loss: 0.519 | Accuracy: 0.856000 | 0.183 sec/iter\n",
      "Epoch: 71 | Batch: 007 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.854000 | 0.182 sec/iter\n",
      "Epoch: 71 | Batch: 008 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.875500 | 0.182 sec/iter\n",
      "Epoch: 71 | Batch: 009 / 011 | Total loss: 0.486 | Reg loss: 0.028 | Tree loss: 0.486 | Accuracy: 0.882000 | 0.182 sec/iter\n",
      "Epoch: 71 | Batch: 010 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.849829 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 72 | Batch: 000 / 011 | Total loss: 0.585 | Reg loss: 0.028 | Tree loss: 0.585 | Accuracy: 0.799000 | 0.183 sec/iter\n",
      "Epoch: 72 | Batch: 001 / 011 | Total loss: 0.584 | Reg loss: 0.028 | Tree loss: 0.584 | Accuracy: 0.798500 | 0.183 sec/iter\n",
      "Epoch: 72 | Batch: 002 / 011 | Total loss: 0.551 | Reg loss: 0.028 | Tree loss: 0.551 | Accuracy: 0.822500 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 003 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.826000 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 004 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.819500 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 005 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.824500 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 006 / 011 | Total loss: 0.513 | Reg loss: 0.028 | Tree loss: 0.513 | Accuracy: 0.842000 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 007 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.856500 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 008 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.880000 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 009 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.872000 | 0.182 sec/iter\n",
      "Epoch: 72 | Batch: 010 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.873720 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 73 | Batch: 000 / 011 | Total loss: 0.583 | Reg loss: 0.028 | Tree loss: 0.583 | Accuracy: 0.798000 | 0.182 sec/iter\n",
      "Epoch: 73 | Batch: 001 / 011 | Total loss: 0.586 | Reg loss: 0.028 | Tree loss: 0.586 | Accuracy: 0.799000 | 0.182 sec/iter\n",
      "Epoch: 73 | Batch: 002 / 011 | Total loss: 0.554 | Reg loss: 0.028 | Tree loss: 0.554 | Accuracy: 0.808500 | 0.182 sec/iter\n",
      "Epoch: 73 | Batch: 003 / 011 | Total loss: 0.536 | Reg loss: 0.028 | Tree loss: 0.536 | Accuracy: 0.817000 | 0.182 sec/iter\n",
      "Epoch: 73 | Batch: 004 / 011 | Total loss: 0.529 | Reg loss: 0.028 | Tree loss: 0.529 | Accuracy: 0.826000 | 0.182 sec/iter\n",
      "Epoch: 73 | Batch: 005 / 011 | Total loss: 0.520 | Reg loss: 0.028 | Tree loss: 0.520 | Accuracy: 0.842000 | 0.182 sec/iter\n",
      "Epoch: 73 | Batch: 006 / 011 | Total loss: 0.496 | Reg loss: 0.028 | Tree loss: 0.496 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 73 | Batch: 007 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 73 | Batch: 008 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.856000 | 0.181 sec/iter\n",
      "Epoch: 73 | Batch: 009 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.877000 | 0.181 sec/iter\n",
      "Epoch: 73 | Batch: 010 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.883959 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 74 | Batch: 000 / 011 | Total loss: 0.596 | Reg loss: 0.028 | Tree loss: 0.596 | Accuracy: 0.788500 | 0.182 sec/iter\n",
      "Epoch: 74 | Batch: 001 / 011 | Total loss: 0.570 | Reg loss: 0.028 | Tree loss: 0.570 | Accuracy: 0.799500 | 0.182 sec/iter\n",
      "Epoch: 74 | Batch: 002 / 011 | Total loss: 0.551 | Reg loss: 0.028 | Tree loss: 0.551 | Accuracy: 0.814500 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 003 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.842000 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 004 / 011 | Total loss: 0.534 | Reg loss: 0.028 | Tree loss: 0.534 | Accuracy: 0.838500 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 005 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.860500 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 006 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 007 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 008 / 011 | Total loss: 0.507 | Reg loss: 0.028 | Tree loss: 0.507 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 009 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 74 | Batch: 010 / 011 | Total loss: 0.481 | Reg loss: 0.028 | Tree loss: 0.481 | Accuracy: 0.894198 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 75 | Batch: 000 / 011 | Total loss: 0.595 | Reg loss: 0.028 | Tree loss: 0.595 | Accuracy: 0.787000 | 0.181 sec/iter\n",
      "Epoch: 75 | Batch: 001 / 011 | Total loss: 0.572 | Reg loss: 0.028 | Tree loss: 0.572 | Accuracy: 0.802000 | 0.181 sec/iter\n",
      "Epoch: 75 | Batch: 002 / 011 | Total loss: 0.548 | Reg loss: 0.028 | Tree loss: 0.548 | Accuracy: 0.810500 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 | Batch: 003 / 011 | Total loss: 0.541 | Reg loss: 0.028 | Tree loss: 0.541 | Accuracy: 0.820000 | 0.181 sec/iter\n",
      "Epoch: 75 | Batch: 004 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.820000 | 0.181 sec/iter\n",
      "Epoch: 75 | Batch: 005 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.839500 | 0.181 sec/iter\n",
      "Epoch: 75 | Batch: 006 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 75 | Batch: 007 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 75 | Batch: 008 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 75 | Batch: 009 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 75 | Batch: 010 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 76 | Batch: 000 / 011 | Total loss: 0.576 | Reg loss: 0.028 | Tree loss: 0.576 | Accuracy: 0.806000 | 0.181 sec/iter\n",
      "Epoch: 76 | Batch: 001 / 011 | Total loss: 0.575 | Reg loss: 0.028 | Tree loss: 0.575 | Accuracy: 0.798500 | 0.181 sec/iter\n",
      "Epoch: 76 | Batch: 002 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 003 / 011 | Total loss: 0.524 | Reg loss: 0.028 | Tree loss: 0.524 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 004 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 005 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 006 / 011 | Total loss: 0.518 | Reg loss: 0.028 | Tree loss: 0.518 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 007 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 008 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 009 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 76 | Batch: 010 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 77 | Batch: 000 / 011 | Total loss: 0.583 | Reg loss: 0.028 | Tree loss: 0.583 | Accuracy: 0.798000 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 001 / 011 | Total loss: 0.555 | Reg loss: 0.028 | Tree loss: 0.555 | Accuracy: 0.809500 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 002 / 011 | Total loss: 0.553 | Reg loss: 0.028 | Tree loss: 0.553 | Accuracy: 0.807000 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 003 / 011 | Total loss: 0.520 | Reg loss: 0.028 | Tree loss: 0.520 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 004 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.826000 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 005 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 006 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 007 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 77 | Batch: 008 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.861000 | 0.178 sec/iter\n",
      "Epoch: 77 | Batch: 009 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.862500 | 0.178 sec/iter\n",
      "Epoch: 77 | Batch: 010 / 011 | Total loss: 0.513 | Reg loss: 0.028 | Tree loss: 0.513 | Accuracy: 0.856655 | 0.178 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 78 | Batch: 000 / 011 | Total loss: 0.590 | Reg loss: 0.028 | Tree loss: 0.590 | Accuracy: 0.794500 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 001 / 011 | Total loss: 0.572 | Reg loss: 0.028 | Tree loss: 0.572 | Accuracy: 0.809000 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 002 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.829500 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 003 / 011 | Total loss: 0.529 | Reg loss: 0.028 | Tree loss: 0.529 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 004 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 005 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 006 / 011 | Total loss: 0.496 | Reg loss: 0.028 | Tree loss: 0.496 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 007 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 008 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 009 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 78 | Batch: 010 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 79 | Batch: 000 / 011 | Total loss: 0.583 | Reg loss: 0.028 | Tree loss: 0.583 | Accuracy: 0.801500 | 0.18 sec/iter\n",
      "Epoch: 79 | Batch: 001 / 011 | Total loss: 0.569 | Reg loss: 0.028 | Tree loss: 0.569 | Accuracy: 0.804000 | 0.18 sec/iter\n",
      "Epoch: 79 | Batch: 002 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.813500 | 0.18 sec/iter\n",
      "Epoch: 79 | Batch: 003 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 79 | Batch: 004 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 79 | Batch: 005 / 011 | Total loss: 0.510 | Reg loss: 0.028 | Tree loss: 0.510 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 79 | Batch: 006 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 79 | Batch: 007 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 79 | Batch: 008 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 79 | Batch: 009 / 011 | Total loss: 0.473 | Reg loss: 0.028 | Tree loss: 0.473 | Accuracy: 0.883500 | 0.179 sec/iter\n",
      "Epoch: 79 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.028 | Tree loss: 0.427 | Accuracy: 0.904437 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 80 | Batch: 000 / 011 | Total loss: 0.588 | Reg loss: 0.028 | Tree loss: 0.588 | Accuracy: 0.794000 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 001 / 011 | Total loss: 0.552 | Reg loss: 0.028 | Tree loss: 0.552 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 002 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 003 / 011 | Total loss: 0.523 | Reg loss: 0.028 | Tree loss: 0.523 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 004 / 011 | Total loss: 0.528 | Reg loss: 0.028 | Tree loss: 0.528 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 005 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 006 / 011 | Total loss: 0.496 | Reg loss: 0.028 | Tree loss: 0.496 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 007 / 011 | Total loss: 0.502 | Reg loss: 0.028 | Tree loss: 0.502 | Accuracy: 0.873000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Batch: 008 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 009 / 011 | Total loss: 0.479 | Reg loss: 0.028 | Tree loss: 0.479 | Accuracy: 0.882000 | 0.18 sec/iter\n",
      "Epoch: 80 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.028 | Tree loss: 0.440 | Accuracy: 0.894198 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 81 | Batch: 000 / 011 | Total loss: 0.560 | Reg loss: 0.028 | Tree loss: 0.560 | Accuracy: 0.811000 | 0.181 sec/iter\n",
      "Epoch: 81 | Batch: 001 / 011 | Total loss: 0.542 | Reg loss: 0.028 | Tree loss: 0.542 | Accuracy: 0.812500 | 0.181 sec/iter\n",
      "Epoch: 81 | Batch: 002 / 011 | Total loss: 0.540 | Reg loss: 0.028 | Tree loss: 0.540 | Accuracy: 0.823000 | 0.181 sec/iter\n",
      "Epoch: 81 | Batch: 003 / 011 | Total loss: 0.534 | Reg loss: 0.028 | Tree loss: 0.534 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 004 / 011 | Total loss: 0.507 | Reg loss: 0.028 | Tree loss: 0.507 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 005 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 006 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 007 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 008 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 009 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.884000 | 0.18 sec/iter\n",
      "Epoch: 81 | Batch: 010 / 011 | Total loss: 0.524 | Reg loss: 0.028 | Tree loss: 0.524 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 82 | Batch: 000 / 011 | Total loss: 0.565 | Reg loss: 0.028 | Tree loss: 0.565 | Accuracy: 0.807500 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 001 / 011 | Total loss: 0.560 | Reg loss: 0.028 | Tree loss: 0.560 | Accuracy: 0.815500 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 002 / 011 | Total loss: 0.538 | Reg loss: 0.028 | Tree loss: 0.538 | Accuracy: 0.825500 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 003 / 011 | Total loss: 0.517 | Reg loss: 0.028 | Tree loss: 0.517 | Accuracy: 0.830000 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 004 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.842500 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 005 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.851000 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 006 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 007 / 011 | Total loss: 0.496 | Reg loss: 0.028 | Tree loss: 0.496 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 008 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.857500 | 0.181 sec/iter\n",
      "Epoch: 82 | Batch: 009 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 82 | Batch: 010 / 011 | Total loss: 0.488 | Reg loss: 0.028 | Tree loss: 0.488 | Accuracy: 0.901024 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 83 | Batch: 000 / 011 | Total loss: 0.567 | Reg loss: 0.028 | Tree loss: 0.567 | Accuracy: 0.798500 | 0.182 sec/iter\n",
      "Epoch: 83 | Batch: 001 / 011 | Total loss: 0.545 | Reg loss: 0.028 | Tree loss: 0.545 | Accuracy: 0.817500 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 002 / 011 | Total loss: 0.525 | Reg loss: 0.028 | Tree loss: 0.525 | Accuracy: 0.827500 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 003 / 011 | Total loss: 0.527 | Reg loss: 0.028 | Tree loss: 0.527 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 004 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.854500 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 005 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 006 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 007 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 008 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 009 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 83 | Batch: 010 / 011 | Total loss: 0.496 | Reg loss: 0.028 | Tree loss: 0.496 | Accuracy: 0.866894 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 84 | Batch: 000 / 011 | Total loss: 0.546 | Reg loss: 0.028 | Tree loss: 0.546 | Accuracy: 0.824500 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 001 / 011 | Total loss: 0.541 | Reg loss: 0.028 | Tree loss: 0.541 | Accuracy: 0.823500 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 002 / 011 | Total loss: 0.549 | Reg loss: 0.028 | Tree loss: 0.549 | Accuracy: 0.811000 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 003 / 011 | Total loss: 0.545 | Reg loss: 0.028 | Tree loss: 0.545 | Accuracy: 0.821500 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 004 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 005 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 006 / 011 | Total loss: 0.486 | Reg loss: 0.028 | Tree loss: 0.486 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 007 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 84 | Batch: 008 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 84 | Batch: 009 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 84 | Batch: 010 / 011 | Total loss: 0.519 | Reg loss: 0.028 | Tree loss: 0.519 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 85 | Batch: 000 / 011 | Total loss: 0.564 | Reg loss: 0.028 | Tree loss: 0.564 | Accuracy: 0.806500 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 001 / 011 | Total loss: 0.567 | Reg loss: 0.028 | Tree loss: 0.567 | Accuracy: 0.795500 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 002 / 011 | Total loss: 0.519 | Reg loss: 0.028 | Tree loss: 0.519 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 003 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 004 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 005 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 006 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 007 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.884000 | 0.18 sec/iter\n",
      "Epoch: 85 | Batch: 008 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 85 | Batch: 009 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.878000 | 0.179 sec/iter\n",
      "Epoch: 85 | Batch: 010 / 011 | Total loss: 0.515 | Reg loss: 0.028 | Tree loss: 0.515 | Accuracy: 0.843003 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 | Batch: 000 / 011 | Total loss: 0.564 | Reg loss: 0.028 | Tree loss: 0.564 | Accuracy: 0.814000 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 001 / 011 | Total loss: 0.549 | Reg loss: 0.028 | Tree loss: 0.549 | Accuracy: 0.817000 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 002 / 011 | Total loss: 0.533 | Reg loss: 0.028 | Tree loss: 0.533 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 003 / 011 | Total loss: 0.519 | Reg loss: 0.028 | Tree loss: 0.519 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 004 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 005 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 006 / 011 | Total loss: 0.502 | Reg loss: 0.028 | Tree loss: 0.502 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 007 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 008 / 011 | Total loss: 0.473 | Reg loss: 0.028 | Tree loss: 0.473 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 009 / 011 | Total loss: 0.482 | Reg loss: 0.028 | Tree loss: 0.482 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 86 | Batch: 010 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 87 | Batch: 000 / 011 | Total loss: 0.544 | Reg loss: 0.028 | Tree loss: 0.544 | Accuracy: 0.824000 | 0.181 sec/iter\n",
      "Epoch: 87 | Batch: 001 / 011 | Total loss: 0.545 | Reg loss: 0.028 | Tree loss: 0.545 | Accuracy: 0.820000 | 0.181 sec/iter\n",
      "Epoch: 87 | Batch: 002 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.821500 | 0.181 sec/iter\n",
      "Epoch: 87 | Batch: 003 / 011 | Total loss: 0.514 | Reg loss: 0.028 | Tree loss: 0.514 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 87 | Batch: 004 / 011 | Total loss: 0.523 | Reg loss: 0.028 | Tree loss: 0.523 | Accuracy: 0.831000 | 0.181 sec/iter\n",
      "Epoch: 87 | Batch: 005 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 87 | Batch: 006 / 011 | Total loss: 0.479 | Reg loss: 0.028 | Tree loss: 0.479 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 87 | Batch: 007 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 87 | Batch: 008 / 011 | Total loss: 0.491 | Reg loss: 0.028 | Tree loss: 0.491 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 87 | Batch: 009 / 011 | Total loss: 0.481 | Reg loss: 0.028 | Tree loss: 0.481 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 87 | Batch: 010 / 011 | Total loss: 0.481 | Reg loss: 0.028 | Tree loss: 0.481 | Accuracy: 0.887372 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 88 | Batch: 000 / 011 | Total loss: 0.565 | Reg loss: 0.028 | Tree loss: 0.565 | Accuracy: 0.809000 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 001 / 011 | Total loss: 0.540 | Reg loss: 0.028 | Tree loss: 0.540 | Accuracy: 0.815500 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 002 / 011 | Total loss: 0.543 | Reg loss: 0.028 | Tree loss: 0.543 | Accuracy: 0.818000 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 003 / 011 | Total loss: 0.523 | Reg loss: 0.028 | Tree loss: 0.523 | Accuracy: 0.821000 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 004 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 005 / 011 | Total loss: 0.479 | Reg loss: 0.028 | Tree loss: 0.479 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 006 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 007 / 011 | Total loss: 0.481 | Reg loss: 0.028 | Tree loss: 0.481 | Accuracy: 0.875500 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 008 / 011 | Total loss: 0.482 | Reg loss: 0.028 | Tree loss: 0.482 | Accuracy: 0.875000 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 009 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.876000 | 0.181 sec/iter\n",
      "Epoch: 88 | Batch: 010 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 89 | Batch: 000 / 011 | Total loss: 0.565 | Reg loss: 0.028 | Tree loss: 0.565 | Accuracy: 0.799500 | 0.182 sec/iter\n",
      "Epoch: 89 | Batch: 001 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.827500 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 002 / 011 | Total loss: 0.515 | Reg loss: 0.028 | Tree loss: 0.515 | Accuracy: 0.843000 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 003 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.837500 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.858500 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 005 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.855500 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 006 / 011 | Total loss: 0.508 | Reg loss: 0.028 | Tree loss: 0.508 | Accuracy: 0.854500 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 007 / 011 | Total loss: 0.474 | Reg loss: 0.028 | Tree loss: 0.474 | Accuracy: 0.879500 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 008 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.880000 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 009 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.873000 | 0.181 sec/iter\n",
      "Epoch: 89 | Batch: 010 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.870307 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 90 | Batch: 000 / 011 | Total loss: 0.572 | Reg loss: 0.028 | Tree loss: 0.572 | Accuracy: 0.801500 | 0.182 sec/iter\n",
      "Epoch: 90 | Batch: 001 / 011 | Total loss: 0.555 | Reg loss: 0.028 | Tree loss: 0.555 | Accuracy: 0.809500 | 0.182 sec/iter\n",
      "Epoch: 90 | Batch: 002 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.834000 | 0.182 sec/iter\n",
      "Epoch: 90 | Batch: 003 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.819500 | 0.182 sec/iter\n",
      "Epoch: 90 | Batch: 004 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.850000 | 0.182 sec/iter\n",
      "Epoch: 90 | Batch: 005 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.851000 | 0.182 sec/iter\n",
      "Epoch: 90 | Batch: 006 / 011 | Total loss: 0.467 | Reg loss: 0.028 | Tree loss: 0.467 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 90 | Batch: 007 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 90 | Batch: 008 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 90 | Batch: 009 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.872000 | 0.181 sec/iter\n",
      "Epoch: 90 | Batch: 010 / 011 | Total loss: 0.466 | Reg loss: 0.028 | Tree loss: 0.466 | Accuracy: 0.866894 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 91 | Batch: 000 / 011 | Total loss: 0.551 | Reg loss: 0.028 | Tree loss: 0.551 | Accuracy: 0.809000 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 001 / 011 | Total loss: 0.544 | Reg loss: 0.028 | Tree loss: 0.544 | Accuracy: 0.821500 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 002 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.827500 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 003 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.831000 | 0.182 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91 | Batch: 004 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.860000 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 005 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.858000 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 006 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.876000 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 007 / 011 | Total loss: 0.485 | Reg loss: 0.028 | Tree loss: 0.485 | Accuracy: 0.875000 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 008 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.878000 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 009 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.872500 | 0.182 sec/iter\n",
      "Epoch: 91 | Batch: 010 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.863481 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 92 | Batch: 000 / 011 | Total loss: 0.547 | Reg loss: 0.028 | Tree loss: 0.547 | Accuracy: 0.817000 | 0.182 sec/iter\n",
      "Epoch: 92 | Batch: 001 / 011 | Total loss: 0.525 | Reg loss: 0.028 | Tree loss: 0.525 | Accuracy: 0.826000 | 0.182 sec/iter\n",
      "Epoch: 92 | Batch: 002 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.824500 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 003 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 004 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.840000 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 005 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.851000 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 006 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.842500 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 007 / 011 | Total loss: 0.470 | Reg loss: 0.028 | Tree loss: 0.470 | Accuracy: 0.871000 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 008 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 009 / 011 | Total loss: 0.485 | Reg loss: 0.028 | Tree loss: 0.485 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 92 | Batch: 010 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.860068 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 93 | Batch: 000 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.828500 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 001 / 011 | Total loss: 0.539 | Reg loss: 0.028 | Tree loss: 0.539 | Accuracy: 0.816000 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 002 / 011 | Total loss: 0.540 | Reg loss: 0.028 | Tree loss: 0.540 | Accuracy: 0.818000 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 003 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 004 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 005 / 011 | Total loss: 0.486 | Reg loss: 0.028 | Tree loss: 0.486 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 006 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.877000 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 007 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 008 / 011 | Total loss: 0.471 | Reg loss: 0.028 | Tree loss: 0.471 | Accuracy: 0.872500 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 009 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 93 | Batch: 010 / 011 | Total loss: 0.455 | Reg loss: 0.028 | Tree loss: 0.455 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 94 | Batch: 000 / 011 | Total loss: 0.549 | Reg loss: 0.028 | Tree loss: 0.549 | Accuracy: 0.803000 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 001 / 011 | Total loss: 0.531 | Reg loss: 0.028 | Tree loss: 0.531 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 002 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.839000 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 003 / 011 | Total loss: 0.508 | Reg loss: 0.028 | Tree loss: 0.508 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 004 / 011 | Total loss: 0.512 | Reg loss: 0.028 | Tree loss: 0.512 | Accuracy: 0.832000 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 005 / 011 | Total loss: 0.473 | Reg loss: 0.028 | Tree loss: 0.473 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 006 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 007 / 011 | Total loss: 0.468 | Reg loss: 0.028 | Tree loss: 0.468 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 008 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.877000 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 009 / 011 | Total loss: 0.463 | Reg loss: 0.028 | Tree loss: 0.463 | Accuracy: 0.877500 | 0.181 sec/iter\n",
      "Epoch: 94 | Batch: 010 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.887372 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 95 | Batch: 000 / 011 | Total loss: 0.567 | Reg loss: 0.028 | Tree loss: 0.567 | Accuracy: 0.800500 | 0.182 sec/iter\n",
      "Epoch: 95 | Batch: 001 / 011 | Total loss: 0.520 | Reg loss: 0.028 | Tree loss: 0.520 | Accuracy: 0.828000 | 0.182 sec/iter\n",
      "Epoch: 95 | Batch: 002 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.825000 | 0.182 sec/iter\n",
      "Epoch: 95 | Batch: 003 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.835000 | 0.182 sec/iter\n",
      "Epoch: 95 | Batch: 004 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.838000 | 0.182 sec/iter\n",
      "Epoch: 95 | Batch: 005 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 95 | Batch: 006 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 95 | Batch: 007 / 011 | Total loss: 0.467 | Reg loss: 0.028 | Tree loss: 0.467 | Accuracy: 0.888000 | 0.181 sec/iter\n",
      "Epoch: 95 | Batch: 008 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.873000 | 0.181 sec/iter\n",
      "Epoch: 95 | Batch: 009 / 011 | Total loss: 0.472 | Reg loss: 0.028 | Tree loss: 0.472 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 95 | Batch: 010 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.877133 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 96 | Batch: 000 / 011 | Total loss: 0.538 | Reg loss: 0.028 | Tree loss: 0.538 | Accuracy: 0.822500 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 001 / 011 | Total loss: 0.524 | Reg loss: 0.028 | Tree loss: 0.524 | Accuracy: 0.823000 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 002 / 011 | Total loss: 0.525 | Reg loss: 0.028 | Tree loss: 0.525 | Accuracy: 0.831000 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 003 / 011 | Total loss: 0.514 | Reg loss: 0.028 | Tree loss: 0.514 | Accuracy: 0.831500 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 004 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.839500 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 005 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.866000 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 006 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.872500 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 007 / 011 | Total loss: 0.470 | Reg loss: 0.028 | Tree loss: 0.470 | Accuracy: 0.878000 | 0.182 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 | Batch: 008 / 011 | Total loss: 0.468 | Reg loss: 0.028 | Tree loss: 0.468 | Accuracy: 0.877000 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 009 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.873000 | 0.182 sec/iter\n",
      "Epoch: 96 | Batch: 010 / 011 | Total loss: 0.464 | Reg loss: 0.028 | Tree loss: 0.464 | Accuracy: 0.870307 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 97 | Batch: 000 / 011 | Total loss: 0.546 | Reg loss: 0.028 | Tree loss: 0.546 | Accuracy: 0.808000 | 0.183 sec/iter\n",
      "Epoch: 97 | Batch: 001 / 011 | Total loss: 0.536 | Reg loss: 0.028 | Tree loss: 0.536 | Accuracy: 0.814000 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 002 / 011 | Total loss: 0.513 | Reg loss: 0.028 | Tree loss: 0.513 | Accuracy: 0.833000 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 003 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.841000 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 004 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.855500 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 005 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.872500 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 006 / 011 | Total loss: 0.485 | Reg loss: 0.028 | Tree loss: 0.485 | Accuracy: 0.867000 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 007 / 011 | Total loss: 0.470 | Reg loss: 0.028 | Tree loss: 0.470 | Accuracy: 0.877500 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 008 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.861500 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 009 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.879000 | 0.182 sec/iter\n",
      "Epoch: 97 | Batch: 010 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.846416 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 98 | Batch: 000 / 011 | Total loss: 0.558 | Reg loss: 0.028 | Tree loss: 0.558 | Accuracy: 0.808500 | 0.183 sec/iter\n",
      "Epoch: 98 | Batch: 001 / 011 | Total loss: 0.534 | Reg loss: 0.028 | Tree loss: 0.534 | Accuracy: 0.818000 | 0.183 sec/iter\n",
      "Epoch: 98 | Batch: 002 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.837500 | 0.183 sec/iter\n",
      "Epoch: 98 | Batch: 003 / 011 | Total loss: 0.513 | Reg loss: 0.028 | Tree loss: 0.513 | Accuracy: 0.838000 | 0.183 sec/iter\n",
      "Epoch: 98 | Batch: 004 / 011 | Total loss: 0.498 | Reg loss: 0.028 | Tree loss: 0.498 | Accuracy: 0.845500 | 0.183 sec/iter\n",
      "Epoch: 98 | Batch: 005 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.859500 | 0.183 sec/iter\n",
      "Epoch: 98 | Batch: 006 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.852500 | 0.182 sec/iter\n",
      "Epoch: 98 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.880000 | 0.182 sec/iter\n",
      "Epoch: 98 | Batch: 008 / 011 | Total loss: 0.464 | Reg loss: 0.028 | Tree loss: 0.464 | Accuracy: 0.874000 | 0.182 sec/iter\n",
      "Epoch: 98 | Batch: 009 / 011 | Total loss: 0.472 | Reg loss: 0.028 | Tree loss: 0.472 | Accuracy: 0.872500 | 0.182 sec/iter\n",
      "Epoch: 98 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.028 | Tree loss: 0.418 | Accuracy: 0.894198 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 99 | Batch: 000 / 011 | Total loss: 0.567 | Reg loss: 0.028 | Tree loss: 0.567 | Accuracy: 0.804000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 001 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.828000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 002 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.822000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 003 / 011 | Total loss: 0.510 | Reg loss: 0.028 | Tree loss: 0.510 | Accuracy: 0.834000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 004 / 011 | Total loss: 0.476 | Reg loss: 0.028 | Tree loss: 0.476 | Accuracy: 0.856000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 005 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.861000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.028 | Tree loss: 0.453 | Accuracy: 0.885000 | 0.183 sec/iter\n",
      "Epoch: 99 | Batch: 007 / 011 | Total loss: 0.472 | Reg loss: 0.028 | Tree loss: 0.472 | Accuracy: 0.864000 | 0.182 sec/iter\n",
      "Epoch: 99 | Batch: 008 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.866000 | 0.182 sec/iter\n",
      "Epoch: 99 | Batch: 009 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.867500 | 0.182 sec/iter\n",
      "Epoch: 99 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.028 | Tree loss: 0.397 | Accuracy: 0.918089 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 100 | Batch: 000 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.831000 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 001 / 011 | Total loss: 0.544 | Reg loss: 0.028 | Tree loss: 0.544 | Accuracy: 0.812500 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 002 / 011 | Total loss: 0.512 | Reg loss: 0.028 | Tree loss: 0.512 | Accuracy: 0.837500 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 003 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.835500 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 004 / 011 | Total loss: 0.510 | Reg loss: 0.028 | Tree loss: 0.510 | Accuracy: 0.838000 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.028 | Tree loss: 0.456 | Accuracy: 0.871500 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 006 / 011 | Total loss: 0.476 | Reg loss: 0.028 | Tree loss: 0.476 | Accuracy: 0.869500 | 0.182 sec/iter\n",
      "Epoch: 100 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.028 | Tree loss: 0.456 | Accuracy: 0.882500 | 0.181 sec/iter\n",
      "Epoch: 100 | Batch: 008 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 100 | Batch: 009 / 011 | Total loss: 0.466 | Reg loss: 0.028 | Tree loss: 0.466 | Accuracy: 0.875000 | 0.181 sec/iter\n",
      "Epoch: 100 | Batch: 010 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.873720 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 101 | Batch: 000 / 011 | Total loss: 0.540 | Reg loss: 0.028 | Tree loss: 0.540 | Accuracy: 0.816500 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 001 / 011 | Total loss: 0.534 | Reg loss: 0.028 | Tree loss: 0.534 | Accuracy: 0.817000 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 002 / 011 | Total loss: 0.520 | Reg loss: 0.028 | Tree loss: 0.520 | Accuracy: 0.832500 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.851500 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 004 / 011 | Total loss: 0.491 | Reg loss: 0.028 | Tree loss: 0.491 | Accuracy: 0.854000 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 005 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.855000 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.028 | Tree loss: 0.455 | Accuracy: 0.885000 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 007 / 011 | Total loss: 0.466 | Reg loss: 0.028 | Tree loss: 0.466 | Accuracy: 0.888000 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 008 / 011 | Total loss: 0.474 | Reg loss: 0.028 | Tree loss: 0.474 | Accuracy: 0.875500 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 009 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.855500 | 0.182 sec/iter\n",
      "Epoch: 101 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.028 | Tree loss: 0.414 | Accuracy: 0.897611 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102 | Batch: 000 / 011 | Total loss: 0.547 | Reg loss: 0.028 | Tree loss: 0.547 | Accuracy: 0.810500 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 001 / 011 | Total loss: 0.552 | Reg loss: 0.028 | Tree loss: 0.552 | Accuracy: 0.805000 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 002 / 011 | Total loss: 0.530 | Reg loss: 0.028 | Tree loss: 0.530 | Accuracy: 0.827500 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 003 / 011 | Total loss: 0.502 | Reg loss: 0.028 | Tree loss: 0.502 | Accuracy: 0.834500 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.858500 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 005 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.846000 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 006 / 011 | Total loss: 0.464 | Reg loss: 0.028 | Tree loss: 0.464 | Accuracy: 0.871500 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.028 | Tree loss: 0.455 | Accuracy: 0.884000 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.028 | Tree loss: 0.450 | Accuracy: 0.888000 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 009 / 011 | Total loss: 0.457 | Reg loss: 0.028 | Tree loss: 0.457 | Accuracy: 0.881000 | 0.182 sec/iter\n",
      "Epoch: 102 | Batch: 010 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.853242 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 103 | Batch: 000 / 011 | Total loss: 0.537 | Reg loss: 0.028 | Tree loss: 0.537 | Accuracy: 0.830500 | 0.183 sec/iter\n",
      "Epoch: 103 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.835000 | 0.183 sec/iter\n",
      "Epoch: 103 | Batch: 002 / 011 | Total loss: 0.523 | Reg loss: 0.028 | Tree loss: 0.523 | Accuracy: 0.823500 | 0.183 sec/iter\n",
      "Epoch: 103 | Batch: 003 / 011 | Total loss: 0.513 | Reg loss: 0.028 | Tree loss: 0.513 | Accuracy: 0.833500 | 0.183 sec/iter\n",
      "Epoch: 103 | Batch: 004 / 011 | Total loss: 0.485 | Reg loss: 0.028 | Tree loss: 0.485 | Accuracy: 0.850500 | 0.182 sec/iter\n",
      "Epoch: 103 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.865500 | 0.182 sec/iter\n",
      "Epoch: 103 | Batch: 006 / 011 | Total loss: 0.464 | Reg loss: 0.028 | Tree loss: 0.464 | Accuracy: 0.875000 | 0.182 sec/iter\n",
      "Epoch: 103 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.877000 | 0.182 sec/iter\n",
      "Epoch: 103 | Batch: 008 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.864500 | 0.182 sec/iter\n",
      "Epoch: 103 | Batch: 009 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.867000 | 0.182 sec/iter\n",
      "Epoch: 103 | Batch: 010 / 011 | Total loss: 0.490 | Reg loss: 0.028 | Tree loss: 0.490 | Accuracy: 0.870307 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 104 | Batch: 000 / 011 | Total loss: 0.557 | Reg loss: 0.028 | Tree loss: 0.557 | Accuracy: 0.805500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 001 / 011 | Total loss: 0.536 | Reg loss: 0.028 | Tree loss: 0.536 | Accuracy: 0.822500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 002 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.835500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.853500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 004 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.843000 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 005 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.848500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 006 / 011 | Total loss: 0.463 | Reg loss: 0.028 | Tree loss: 0.463 | Accuracy: 0.864500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.868500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.028 | Tree loss: 0.458 | Accuracy: 0.875500 | 0.183 sec/iter\n",
      "Epoch: 104 | Batch: 009 / 011 | Total loss: 0.461 | Reg loss: 0.028 | Tree loss: 0.461 | Accuracy: 0.881000 | 0.182 sec/iter\n",
      "Epoch: 104 | Batch: 010 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.880546 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 105 | Batch: 000 / 011 | Total loss: 0.535 | Reg loss: 0.028 | Tree loss: 0.535 | Accuracy: 0.826500 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.028 | Tree loss: 0.510 | Accuracy: 0.835500 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.839500 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 003 / 011 | Total loss: 0.510 | Reg loss: 0.028 | Tree loss: 0.510 | Accuracy: 0.839000 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.855000 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 005 / 011 | Total loss: 0.472 | Reg loss: 0.028 | Tree loss: 0.472 | Accuracy: 0.871000 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 006 / 011 | Total loss: 0.471 | Reg loss: 0.028 | Tree loss: 0.471 | Accuracy: 0.875000 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 007 / 011 | Total loss: 0.467 | Reg loss: 0.028 | Tree loss: 0.467 | Accuracy: 0.872000 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 008 / 011 | Total loss: 0.468 | Reg loss: 0.028 | Tree loss: 0.468 | Accuracy: 0.868500 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 009 / 011 | Total loss: 0.473 | Reg loss: 0.028 | Tree loss: 0.473 | Accuracy: 0.873000 | 0.183 sec/iter\n",
      "Epoch: 105 | Batch: 010 / 011 | Total loss: 0.450 | Reg loss: 0.028 | Tree loss: 0.450 | Accuracy: 0.873720 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 106 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.028 | Tree loss: 0.512 | Accuracy: 0.829500 | 0.184 sec/iter\n",
      "Epoch: 106 | Batch: 001 / 011 | Total loss: 0.524 | Reg loss: 0.028 | Tree loss: 0.524 | Accuracy: 0.827500 | 0.184 sec/iter\n",
      "Epoch: 106 | Batch: 002 / 011 | Total loss: 0.514 | Reg loss: 0.028 | Tree loss: 0.514 | Accuracy: 0.824500 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 003 / 011 | Total loss: 0.479 | Reg loss: 0.028 | Tree loss: 0.479 | Accuracy: 0.853000 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.852000 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 005 / 011 | Total loss: 0.471 | Reg loss: 0.028 | Tree loss: 0.471 | Accuracy: 0.860500 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 006 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.858500 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 007 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.860000 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 008 / 011 | Total loss: 0.471 | Reg loss: 0.028 | Tree loss: 0.471 | Accuracy: 0.867000 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 009 / 011 | Total loss: 0.457 | Reg loss: 0.028 | Tree loss: 0.457 | Accuracy: 0.877500 | 0.183 sec/iter\n",
      "Epoch: 106 | Batch: 010 / 011 | Total loss: 0.470 | Reg loss: 0.028 | Tree loss: 0.470 | Accuracy: 0.883959 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 107 | Batch: 000 / 011 | Total loss: 0.519 | Reg loss: 0.028 | Tree loss: 0.519 | Accuracy: 0.825500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 001 / 011 | Total loss: 0.536 | Reg loss: 0.028 | Tree loss: 0.536 | Accuracy: 0.821500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 002 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.837500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 003 / 011 | Total loss: 0.502 | Reg loss: 0.028 | Tree loss: 0.502 | Accuracy: 0.841500 | 0.183 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107 | Batch: 004 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.855000 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 005 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.854500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.869500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.028 | Tree loss: 0.459 | Accuracy: 0.882000 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.028 | Tree loss: 0.458 | Accuracy: 0.877500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 009 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.863500 | 0.183 sec/iter\n",
      "Epoch: 107 | Batch: 010 / 011 | Total loss: 0.461 | Reg loss: 0.028 | Tree loss: 0.461 | Accuracy: 0.870307 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 108 | Batch: 000 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.839500 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 001 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.827500 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 002 / 011 | Total loss: 0.548 | Reg loss: 0.028 | Tree loss: 0.548 | Accuracy: 0.804500 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 003 / 011 | Total loss: 0.486 | Reg loss: 0.028 | Tree loss: 0.486 | Accuracy: 0.844500 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 004 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.848000 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.869000 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.028 | Tree loss: 0.458 | Accuracy: 0.883000 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 007 / 011 | Total loss: 0.464 | Reg loss: 0.028 | Tree loss: 0.464 | Accuracy: 0.881000 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 008 / 011 | Total loss: 0.461 | Reg loss: 0.028 | Tree loss: 0.461 | Accuracy: 0.878000 | 0.183 sec/iter\n",
      "Epoch: 108 | Batch: 009 / 011 | Total loss: 0.459 | Reg loss: 0.028 | Tree loss: 0.459 | Accuracy: 0.874500 | 0.182 sec/iter\n",
      "Epoch: 108 | Batch: 010 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.880546 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 109 | Batch: 000 / 011 | Total loss: 0.531 | Reg loss: 0.028 | Tree loss: 0.531 | Accuracy: 0.818500 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 001 / 011 | Total loss: 0.527 | Reg loss: 0.028 | Tree loss: 0.527 | Accuracy: 0.823000 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 002 / 011 | Total loss: 0.513 | Reg loss: 0.028 | Tree loss: 0.513 | Accuracy: 0.826500 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.859000 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 004 / 011 | Total loss: 0.482 | Reg loss: 0.028 | Tree loss: 0.482 | Accuracy: 0.855500 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 005 / 011 | Total loss: 0.482 | Reg loss: 0.028 | Tree loss: 0.482 | Accuracy: 0.865500 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 006 / 011 | Total loss: 0.463 | Reg loss: 0.028 | Tree loss: 0.463 | Accuracy: 0.876500 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 007 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.873000 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 008 / 011 | Total loss: 0.473 | Reg loss: 0.028 | Tree loss: 0.473 | Accuracy: 0.871000 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 009 / 011 | Total loss: 0.460 | Reg loss: 0.028 | Tree loss: 0.460 | Accuracy: 0.874000 | 0.183 sec/iter\n",
      "Epoch: 109 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.028 | Tree loss: 0.414 | Accuracy: 0.883959 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 110 | Batch: 000 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.825000 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 001 / 011 | Total loss: 0.535 | Reg loss: 0.028 | Tree loss: 0.535 | Accuracy: 0.817500 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 002 / 011 | Total loss: 0.512 | Reg loss: 0.028 | Tree loss: 0.512 | Accuracy: 0.837500 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 003 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.838000 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.028 | Tree loss: 0.466 | Accuracy: 0.864000 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.028 | Tree loss: 0.466 | Accuracy: 0.862000 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.865000 | 0.183 sec/iter\n",
      "Epoch: 110 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.865500 | 0.182 sec/iter\n",
      "Epoch: 110 | Batch: 008 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.864000 | 0.182 sec/iter\n",
      "Epoch: 110 | Batch: 009 / 011 | Total loss: 0.456 | Reg loss: 0.028 | Tree loss: 0.456 | Accuracy: 0.880500 | 0.182 sec/iter\n",
      "Epoch: 110 | Batch: 010 / 011 | Total loss: 0.489 | Reg loss: 0.028 | Tree loss: 0.489 | Accuracy: 0.863481 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 111 | Batch: 000 / 011 | Total loss: 0.535 | Reg loss: 0.028 | Tree loss: 0.535 | Accuracy: 0.813000 | 0.183 sec/iter\n",
      "Epoch: 111 | Batch: 001 / 011 | Total loss: 0.512 | Reg loss: 0.028 | Tree loss: 0.512 | Accuracy: 0.840000 | 0.183 sec/iter\n",
      "Epoch: 111 | Batch: 002 / 011 | Total loss: 0.515 | Reg loss: 0.028 | Tree loss: 0.515 | Accuracy: 0.833000 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 003 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.846000 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 004 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.850500 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.028 | Tree loss: 0.453 | Accuracy: 0.877000 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 006 / 011 | Total loss: 0.464 | Reg loss: 0.028 | Tree loss: 0.464 | Accuracy: 0.873000 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 007 / 011 | Total loss: 0.461 | Reg loss: 0.028 | Tree loss: 0.461 | Accuracy: 0.871500 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.028 | Tree loss: 0.458 | Accuracy: 0.869000 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 009 / 011 | Total loss: 0.461 | Reg loss: 0.028 | Tree loss: 0.461 | Accuracy: 0.860000 | 0.182 sec/iter\n",
      "Epoch: 111 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.028 | Tree loss: 0.440 | Accuracy: 0.863481 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 112 | Batch: 000 / 011 | Total loss: 0.539 | Reg loss: 0.028 | Tree loss: 0.539 | Accuracy: 0.821000 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 001 / 011 | Total loss: 0.525 | Reg loss: 0.028 | Tree loss: 0.525 | Accuracy: 0.817500 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 002 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.828500 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 003 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.845000 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 004 / 011 | Total loss: 0.477 | Reg loss: 0.028 | Tree loss: 0.477 | Accuracy: 0.862500 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 005 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.865500 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.028 | Tree loss: 0.455 | Accuracy: 0.881500 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 007 / 011 | Total loss: 0.467 | Reg loss: 0.028 | Tree loss: 0.467 | Accuracy: 0.871000 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.028 | Tree loss: 0.450 | Accuracy: 0.885500 | 0.182 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.028 | Tree loss: 0.451 | Accuracy: 0.873500 | 0.182 sec/iter\n",
      "Epoch: 112 | Batch: 010 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.853242 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 113 | Batch: 000 / 011 | Total loss: 0.526 | Reg loss: 0.028 | Tree loss: 0.526 | Accuracy: 0.835000 | 0.182 sec/iter\n",
      "Epoch: 113 | Batch: 001 / 011 | Total loss: 0.528 | Reg loss: 0.028 | Tree loss: 0.528 | Accuracy: 0.820000 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 002 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.846500 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 005 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.842500 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 006 / 011 | Total loss: 0.463 | Reg loss: 0.028 | Tree loss: 0.463 | Accuracy: 0.873500 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.028 | Tree loss: 0.448 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.028 | Tree loss: 0.457 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 009 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 113 | Batch: 010 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.877133 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 114 | Batch: 000 / 011 | Total loss: 0.527 | Reg loss: 0.028 | Tree loss: 0.527 | Accuracy: 0.813000 | 0.181 sec/iter\n",
      "Epoch: 114 | Batch: 001 / 011 | Total loss: 0.533 | Reg loss: 0.028 | Tree loss: 0.533 | Accuracy: 0.823000 | 0.181 sec/iter\n",
      "Epoch: 114 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 114 | Batch: 003 / 011 | Total loss: 0.497 | Reg loss: 0.028 | Tree loss: 0.497 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 004 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.028 | Tree loss: 0.452 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 007 / 011 | Total loss: 0.476 | Reg loss: 0.028 | Tree loss: 0.476 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 009 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.878500 | 0.18 sec/iter\n",
      "Epoch: 114 | Batch: 010 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 115 | Batch: 000 / 011 | Total loss: 0.531 | Reg loss: 0.028 | Tree loss: 0.531 | Accuracy: 0.809500 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 001 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 002 / 011 | Total loss: 0.508 | Reg loss: 0.028 | Tree loss: 0.508 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 003 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 004 / 011 | Total loss: 0.484 | Reg loss: 0.028 | Tree loss: 0.484 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 005 / 011 | Total loss: 0.476 | Reg loss: 0.028 | Tree loss: 0.476 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 006 / 011 | Total loss: 0.467 | Reg loss: 0.028 | Tree loss: 0.467 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.028 | Tree loss: 0.440 | Accuracy: 0.879000 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 115 | Batch: 010 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 116 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.028 | Tree loss: 0.508 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 001 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 002 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 003 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 004 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 005 / 011 | Total loss: 0.480 | Reg loss: 0.028 | Tree loss: 0.480 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 006 / 011 | Total loss: 0.470 | Reg loss: 0.028 | Tree loss: 0.470 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 116 | Batch: 007 / 011 | Total loss: 0.470 | Reg loss: 0.028 | Tree loss: 0.470 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 116 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.875500 | 0.179 sec/iter\n",
      "Epoch: 116 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.888000 | 0.179 sec/iter\n",
      "Epoch: 116 | Batch: 010 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.890785 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 117 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 117 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 117 | Batch: 002 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 003 / 011 | Total loss: 0.493 | Reg loss: 0.028 | Tree loss: 0.493 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 004 / 011 | Total loss: 0.476 | Reg loss: 0.028 | Tree loss: 0.476 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 005 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 006 / 011 | Total loss: 0.476 | Reg loss: 0.028 | Tree loss: 0.476 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.028 | Tree loss: 0.451 | Accuracy: 0.883000 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 009 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.874000 | 0.179 sec/iter\n",
      "Epoch: 117 | Batch: 010 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 118 | Batch: 000 / 011 | Total loss: 0.532 | Reg loss: 0.028 | Tree loss: 0.532 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 118 | Batch: 001 / 011 | Total loss: 0.511 | Reg loss: 0.028 | Tree loss: 0.511 | Accuracy: 0.834000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.028 | Tree loss: 0.472 | Accuracy: 0.855500 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 004 / 011 | Total loss: 0.482 | Reg loss: 0.028 | Tree loss: 0.482 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 005 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 006 / 011 | Total loss: 0.463 | Reg loss: 0.028 | Tree loss: 0.463 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 007 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.883000 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 118 | Batch: 010 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 119 | Batch: 000 / 011 | Total loss: 0.521 | Reg loss: 0.028 | Tree loss: 0.521 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 001 / 011 | Total loss: 0.533 | Reg loss: 0.028 | Tree loss: 0.533 | Accuracy: 0.819000 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 003 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.028 | Tree loss: 0.455 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.028 | Tree loss: 0.453 | Accuracy: 0.879000 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.028 | Tree loss: 0.462 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 007 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 119 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.877000 | 0.179 sec/iter\n",
      "Epoch: 119 | Batch: 009 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 119 | Batch: 010 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.856655 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 120 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.028 | Tree loss: 0.509 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 001 / 011 | Total loss: 0.516 | Reg loss: 0.028 | Tree loss: 0.516 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 002 / 011 | Total loss: 0.500 | Reg loss: 0.028 | Tree loss: 0.500 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.028 | Tree loss: 0.468 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.028 | Tree loss: 0.475 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 005 / 011 | Total loss: 0.471 | Reg loss: 0.028 | Tree loss: 0.471 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 006 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 007 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 009 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 120 | Batch: 010 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 121 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.028 | Tree loss: 0.499 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 001 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 002 / 011 | Total loss: 0.504 | Reg loss: 0.028 | Tree loss: 0.504 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.028 | Tree loss: 0.469 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 005 / 011 | Total loss: 0.481 | Reg loss: 0.028 | Tree loss: 0.481 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 006 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 007 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 008 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 009 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 121 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 122 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.028 | Tree loss: 0.518 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 001 / 011 | Total loss: 0.522 | Reg loss: 0.028 | Tree loss: 0.522 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.028 | Tree loss: 0.495 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 003 / 011 | Total loss: 0.492 | Reg loss: 0.028 | Tree loss: 0.492 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 004 / 011 | Total loss: 0.481 | Reg loss: 0.028 | Tree loss: 0.481 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.028 | Tree loss: 0.465 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 007 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 008 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.886000 | 0.18 sec/iter\n",
      "Epoch: 122 | Batch: 010 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 123 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.028 | Tree loss: 0.503 | Accuracy: 0.838500 | 0.181 sec/iter\n",
      "Epoch: 123 | Batch: 001 / 011 | Total loss: 0.506 | Reg loss: 0.028 | Tree loss: 0.506 | Accuracy: 0.827000 | 0.181 sec/iter\n",
      "Epoch: 123 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.028 | Tree loss: 0.505 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 003 / 011 | Total loss: 0.487 | Reg loss: 0.028 | Tree loss: 0.487 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 004 / 011 | Total loss: 0.478 | Reg loss: 0.028 | Tree loss: 0.478 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 005 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.861500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123 | Batch: 006 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 007 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 009 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 123 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 124 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.028 | Tree loss: 0.515 | Accuracy: 0.830500 | 0.181 sec/iter\n",
      "Epoch: 124 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.028 | Tree loss: 0.501 | Accuracy: 0.832000 | 0.181 sec/iter\n",
      "Epoch: 124 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.028 | Tree loss: 0.483 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 124 | Batch: 003 / 011 | Total loss: 0.496 | Reg loss: 0.028 | Tree loss: 0.496 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 124 | Batch: 004 / 011 | Total loss: 0.486 | Reg loss: 0.028 | Tree loss: 0.486 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 124 | Batch: 005 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 124 | Batch: 006 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 124 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 124 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.881000 | 0.18 sec/iter\n",
      "Epoch: 124 | Batch: 009 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 124 | Batch: 010 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 125 | Batch: 000 / 011 | Total loss: 0.519 | Reg loss: 0.028 | Tree loss: 0.519 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 001 / 011 | Total loss: 0.527 | Reg loss: 0.028 | Tree loss: 0.527 | Accuracy: 0.824500 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 002 / 011 | Total loss: 0.502 | Reg loss: 0.028 | Tree loss: 0.502 | Accuracy: 0.837500 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 003 / 011 | Total loss: 0.494 | Reg loss: 0.028 | Tree loss: 0.494 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 006 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 125 | Batch: 007 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 125 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 125 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 125 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.901024 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 126 | Batch: 000 / 011 | Total loss: 0.535 | Reg loss: 0.028 | Tree loss: 0.535 | Accuracy: 0.808500 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 001 / 011 | Total loss: 0.518 | Reg loss: 0.028 | Tree loss: 0.518 | Accuracy: 0.828000 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.853500 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.857500 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.849500 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 007 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 009 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.877000 | 0.181 sec/iter\n",
      "Epoch: 126 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.907850 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 127 | Batch: 000 / 011 | Total loss: 0.523 | Reg loss: 0.029 | Tree loss: 0.523 | Accuracy: 0.826500 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 001 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 002 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 006 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.883000 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.879000 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 009 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.874000 | 0.181 sec/iter\n",
      "Epoch: 127 | Batch: 010 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.890785 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 128 | Batch: 000 / 011 | Total loss: 0.532 | Reg loss: 0.029 | Tree loss: 0.532 | Accuracy: 0.826000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 001 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.833000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 002 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.882000 | 0.181 sec/iter\n",
      "Epoch: 128 | Batch: 009 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.869500 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128 | Batch: 010 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.877133 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 129 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.836000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 001 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.835000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 003 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.846500 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 007 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.879000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 009 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.878000 | 0.181 sec/iter\n",
      "Epoch: 129 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.029 | Tree loss: 0.403 | Accuracy: 0.904437 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 130 | Batch: 000 / 011 | Total loss: 0.522 | Reg loss: 0.029 | Tree loss: 0.522 | Accuracy: 0.820500 | 0.182 sec/iter\n",
      "Epoch: 130 | Batch: 001 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.828500 | 0.182 sec/iter\n",
      "Epoch: 130 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.831500 | 0.182 sec/iter\n",
      "Epoch: 130 | Batch: 003 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.844000 | 0.182 sec/iter\n",
      "Epoch: 130 | Batch: 004 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.848000 | 0.182 sec/iter\n",
      "Epoch: 130 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.868000 | 0.182 sec/iter\n",
      "Epoch: 130 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.865500 | 0.181 sec/iter\n",
      "Epoch: 130 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.869000 | 0.181 sec/iter\n",
      "Epoch: 130 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.884500 | 0.181 sec/iter\n",
      "Epoch: 130 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 130 | Batch: 010 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.880546 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 131 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.828000 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.843000 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 002 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.844000 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.864000 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 004 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.842000 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.857500 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 006 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.859000 | 0.182 sec/iter\n",
      "Epoch: 131 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.884500 | 0.181 sec/iter\n",
      "Epoch: 131 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 131 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.880500 | 0.181 sec/iter\n",
      "Epoch: 131 | Batch: 010 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.856655 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 132 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.029 | Tree loss: 0.515 | Accuracy: 0.832500 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 001 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.840000 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.855000 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 003 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.844000 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 004 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.857500 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 005 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.863500 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.860500 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.870500 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 008 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.870500 | 0.182 sec/iter\n",
      "Epoch: 132 | Batch: 009 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 132 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.029 | Tree loss: 0.377 | Accuracy: 0.921502 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 133 | Batch: 000 / 011 | Total loss: 0.529 | Reg loss: 0.029 | Tree loss: 0.529 | Accuracy: 0.820000 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.833500 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.850000 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.857500 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.861500 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 005 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.849000 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.879500 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.862000 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.869500 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 009 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.864500 | 0.182 sec/iter\n",
      "Epoch: 133 | Batch: 010 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.863481 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 134 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.835000 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.845000 | 0.182 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134 | Batch: 002 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.838000 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.856500 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 004 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.844000 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.867000 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.869500 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 007 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.857500 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.886000 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 009 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.878500 | 0.182 sec/iter\n",
      "Epoch: 134 | Batch: 010 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.887372 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 135 | Batch: 000 / 011 | Total loss: 0.530 | Reg loss: 0.029 | Tree loss: 0.530 | Accuracy: 0.812500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.838000 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.849000 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 003 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.847500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.850500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.867500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.879500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.853500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.868000 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 009 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.871500 | 0.182 sec/iter\n",
      "Epoch: 135 | Batch: 010 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.866894 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 136 | Batch: 000 / 011 | Total loss: 0.521 | Reg loss: 0.029 | Tree loss: 0.521 | Accuracy: 0.830000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.837000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.836500 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 003 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.838000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.866000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.865500 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 006 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.864500 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.884000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.870000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 009 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.871000 | 0.182 sec/iter\n",
      "Epoch: 136 | Batch: 010 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.887372 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 137 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.832000 | 0.183 sec/iter\n",
      "Epoch: 137 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.838500 | 0.183 sec/iter\n",
      "Epoch: 137 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.839500 | 0.183 sec/iter\n",
      "Epoch: 137 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.854500 | 0.183 sec/iter\n",
      "Epoch: 137 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.849500 | 0.182 sec/iter\n",
      "Epoch: 137 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.858500 | 0.182 sec/iter\n",
      "Epoch: 137 | Batch: 006 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.860000 | 0.182 sec/iter\n",
      "Epoch: 137 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.882000 | 0.182 sec/iter\n",
      "Epoch: 137 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.871000 | 0.182 sec/iter\n",
      "Epoch: 137 | Batch: 009 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.859000 | 0.182 sec/iter\n",
      "Epoch: 137 | Batch: 010 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.870307 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 138 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.832500 | 0.183 sec/iter\n",
      "Epoch: 138 | Batch: 001 / 011 | Total loss: 0.516 | Reg loss: 0.029 | Tree loss: 0.516 | Accuracy: 0.828000 | 0.183 sec/iter\n",
      "Epoch: 138 | Batch: 002 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.830000 | 0.183 sec/iter\n",
      "Epoch: 138 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.852000 | 0.183 sec/iter\n",
      "Epoch: 138 | Batch: 004 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.857500 | 0.183 sec/iter\n",
      "Epoch: 138 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.875000 | 0.183 sec/iter\n",
      "Epoch: 138 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.871000 | 0.182 sec/iter\n",
      "Epoch: 138 | Batch: 007 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.867000 | 0.182 sec/iter\n",
      "Epoch: 138 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.870000 | 0.182 sec/iter\n",
      "Epoch: 138 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.880500 | 0.182 sec/iter\n",
      "Epoch: 138 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.853242 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 139 | Batch: 000 / 011 | Total loss: 0.519 | Reg loss: 0.029 | Tree loss: 0.519 | Accuracy: 0.834500 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.852000 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 002 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.844000 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 003 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.849000 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.861500 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.862500 | 0.183 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.867500 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.866500 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 008 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.876500 | 0.183 sec/iter\n",
      "Epoch: 139 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.868500 | 0.182 sec/iter\n",
      "Epoch: 139 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.866894 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 140 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.832500 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 001 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.830000 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 002 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.858500 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.848500 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 004 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.843000 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.863000 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.864000 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868000 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 008 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.865500 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 009 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.866500 | 0.183 sec/iter\n",
      "Epoch: 140 | Batch: 010 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.843003 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 141 | Batch: 000 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.839000 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.834500 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.856000 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.852500 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.859500 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 005 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.849500 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.866000 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.869000 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.875500 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.877000 | 0.183 sec/iter\n",
      "Epoch: 141 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.873720 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 142 | Batch: 000 / 011 | Total loss: 0.520 | Reg loss: 0.029 | Tree loss: 0.520 | Accuracy: 0.831500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 001 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.827500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.833500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.844500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.849000 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.864500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.875500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 007 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.870500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.873000 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.880500 | 0.183 sec/iter\n",
      "Epoch: 142 | Batch: 010 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.863481 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 143 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.829500 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 001 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.836000 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.851500 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.853500 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 004 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.850500 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.861000 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.870000 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.878500 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.885500 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 009 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.867000 | 0.183 sec/iter\n",
      "Epoch: 143 | Batch: 010 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.860068 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 144 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.029 | Tree loss: 0.515 | Accuracy: 0.833500 | 0.184 sec/iter\n",
      "Epoch: 144 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.838000 | 0.184 sec/iter\n",
      "Epoch: 144 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.843000 | 0.184 sec/iter\n",
      "Epoch: 144 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.841000 | 0.183 sec/iter\n",
      "Epoch: 144 | Batch: 004 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.845000 | 0.183 sec/iter\n",
      "Epoch: 144 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.861500 | 0.183 sec/iter\n",
      "Epoch: 144 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.877500 | 0.183 sec/iter\n",
      "Epoch: 144 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.884500 | 0.183 sec/iter\n",
      "Epoch: 144 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.873500 | 0.183 sec/iter\n",
      "Epoch: 144 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.876000 | 0.183 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.883959 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 145 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.851500 | 0.184 sec/iter\n",
      "Epoch: 145 | Batch: 001 / 011 | Total loss: 0.521 | Reg loss: 0.029 | Tree loss: 0.521 | Accuracy: 0.835000 | 0.184 sec/iter\n",
      "Epoch: 145 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.846000 | 0.184 sec/iter\n",
      "Epoch: 145 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.858500 | 0.184 sec/iter\n",
      "Epoch: 145 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.861500 | 0.183 sec/iter\n",
      "Epoch: 145 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.861000 | 0.183 sec/iter\n",
      "Epoch: 145 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.860000 | 0.183 sec/iter\n",
      "Epoch: 145 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.869500 | 0.183 sec/iter\n",
      "Epoch: 145 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.865000 | 0.183 sec/iter\n",
      "Epoch: 145 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.872500 | 0.183 sec/iter\n",
      "Epoch: 145 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.029 | Tree loss: 0.390 | Accuracy: 0.904437 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 146 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.830000 | 0.184 sec/iter\n",
      "Epoch: 146 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.840500 | 0.184 sec/iter\n",
      "Epoch: 146 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.847500 | 0.184 sec/iter\n",
      "Epoch: 146 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857500 | 0.184 sec/iter\n",
      "Epoch: 146 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.855000 | 0.184 sec/iter\n",
      "Epoch: 146 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.857000 | 0.183 sec/iter\n",
      "Epoch: 146 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.867000 | 0.183 sec/iter\n",
      "Epoch: 146 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.874500 | 0.183 sec/iter\n",
      "Epoch: 146 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.871500 | 0.183 sec/iter\n",
      "Epoch: 146 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.866500 | 0.183 sec/iter\n",
      "Epoch: 146 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.887372 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 147 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.837500 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 001 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.830000 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.855500 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 003 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.846500 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.852500 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.874500 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.879000 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.875500 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 008 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.862000 | 0.184 sec/iter\n",
      "Epoch: 147 | Batch: 009 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.855000 | 0.183 sec/iter\n",
      "Epoch: 147 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.894198 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 148 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.838000 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.830500 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.856000 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.849500 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 004 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.838000 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.858000 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.878500 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.858500 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.876500 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.875500 | 0.184 sec/iter\n",
      "Epoch: 148 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.901024 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 149 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.845500 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.847500 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.842000 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 003 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.832500 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.857500 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854500 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.861000 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.867000 | 0.184 sec/iter\n",
      "Epoch: 149 | Batch: 008 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.861500 | 0.183 sec/iter\n",
      "Epoch: 149 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.887000 | 0.183 sec/iter\n",
      "Epoch: 149 | Batch: 010 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.866894 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 150 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.840500 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.844000 | 0.184 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150 | Batch: 002 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.829500 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 003 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.853000 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.859000 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860500 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 006 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.857000 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.871000 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.870000 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.869500 | 0.184 sec/iter\n",
      "Epoch: 150 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.877133 | 0.184 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 151 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.833000 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 001 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.826000 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.850000 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.872000 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 004 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.862500 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.864000 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.869500 | 0.184 sec/iter\n",
      "Epoch: 151 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.866000 | 0.183 sec/iter\n",
      "Epoch: 151 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.878500 | 0.183 sec/iter\n",
      "Epoch: 151 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.883000 | 0.183 sec/iter\n",
      "Epoch: 151 | Batch: 010 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.832765 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 152 | Batch: 000 / 011 | Total loss: 0.524 | Reg loss: 0.029 | Tree loss: 0.524 | Accuracy: 0.828500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.839500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.846500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.849500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.849000 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.864500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.873500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.872500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.879000 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.886500 | 0.183 sec/iter\n",
      "Epoch: 152 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.860068 | 0.183 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 153 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.846500 | 0.183 sec/iter\n",
      "Epoch: 153 | Batch: 001 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.860000 | 0.183 sec/iter\n",
      "Epoch: 153 | Batch: 002 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.824000 | 0.183 sec/iter\n",
      "Epoch: 153 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.847500 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.858000 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 005 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.858000 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.869000 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863500 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.881000 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.874000 | 0.182 sec/iter\n",
      "Epoch: 153 | Batch: 010 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.863481 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 154 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.839500 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.848000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.852000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 003 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.845000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.856000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.873500 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.867500 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 007 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.866000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.873000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.853000 | 0.182 sec/iter\n",
      "Epoch: 154 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.846416 | 0.182 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 155 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.836500 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.846000 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.853500 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.867500 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.860000 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.864000 | 0.182 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.878000 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 007 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.859000 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869500 | 0.182 sec/iter\n",
      "Epoch: 155 | Batch: 009 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 155 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.873720 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 156 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.845500 | 0.182 sec/iter\n",
      "Epoch: 156 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.833500 | 0.182 sec/iter\n",
      "Epoch: 156 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.846500 | 0.182 sec/iter\n",
      "Epoch: 156 | Batch: 003 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.851500 | 0.182 sec/iter\n",
      "Epoch: 156 | Batch: 004 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.839500 | 0.181 sec/iter\n",
      "Epoch: 156 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.871000 | 0.181 sec/iter\n",
      "Epoch: 156 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 156 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 156 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.872000 | 0.181 sec/iter\n",
      "Epoch: 156 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.875000 | 0.181 sec/iter\n",
      "Epoch: 156 | Batch: 010 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.880546 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 157 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.837000 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 001 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.844500 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 003 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.833500 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 004 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.869000 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 008 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.869500 | 0.181 sec/iter\n",
      "Epoch: 157 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.866894 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 158 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.835000 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.849500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 004 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.878500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 009 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 158 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.877133 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 159 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.839500 | 0.181 sec/iter\n",
      "Epoch: 159 | Batch: 001 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.852000 | 0.181 sec/iter\n",
      "Epoch: 159 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 159 | Batch: 003 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.879000 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 008 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 159 | Batch: 010 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.822526 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 160 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 160 | Batch: 009 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.853000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 | Batch: 010 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 161 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 004 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 161 | Batch: 010 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 162 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 003 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 009 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 162 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 163 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 001 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 005 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 007 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 008 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 163 | Batch: 010 / 011 | Total loss: 0.362 | Reg loss: 0.029 | Tree loss: 0.362 | Accuracy: 0.914676 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 164 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 164 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.847500 | 0.181 sec/iter\n",
      "Epoch: 164 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 164 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 007 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 164 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.029 | Tree loss: 0.397 | Accuracy: 0.897611 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 165 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.850000 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.843000 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.831500 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 004 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 165 | Batch: 007 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 165 | Batch: 008 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 165 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 165 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.029 | Tree loss: 0.400 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 166 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.851000 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 001 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.843000 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 166 | Batch: 002 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.841500 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.856000 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 004 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 006 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.869500 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 166 | Batch: 010 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.822526 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 167 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.841000 | 0.181 sec/iter\n",
      "Epoch: 167 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 167 | Batch: 002 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 167 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 167 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.855500 | 0.181 sec/iter\n",
      "Epoch: 167 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 167 | Batch: 006 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 167 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 167 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 167 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 167 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.029 | Tree loss: 0.392 | Accuracy: 0.901024 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 168 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 001 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 003 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 168 | Batch: 010 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.846416 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 169 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.879500 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 169 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 170 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 009 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 170 | Batch: 010 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 171 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 171 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 171 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 007 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.844000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 171 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 171 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 172 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.841000 | 0.181 sec/iter\n",
      "Epoch: 172 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.842500 | 0.181 sec/iter\n",
      "Epoch: 172 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 172 | Batch: 003 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 172 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 172 | Batch: 005 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 172 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 172 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 172 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 172 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 172 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 173 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.852000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 002 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 003 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.844000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 004 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.837000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 006 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.871000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 008 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 173 | Batch: 010 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 174 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.854500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 003 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.860500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 005 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.848000 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 006 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.880000 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 009 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.858500 | 0.181 sec/iter\n",
      "Epoch: 174 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.849829 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 175 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.834500 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 002 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.841000 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.860500 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 175 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 175 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 176 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 001 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 002 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 005 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 006 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 007 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 008 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 176 | Batch: 010 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 177 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 001 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 008 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 177 | Batch: 010 / 011 | Total loss: 0.519 | Reg loss: 0.029 | Tree loss: 0.519 | Accuracy: 0.805461 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 178 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.846500 | 0.181 sec/iter\n",
      "Epoch: 178 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.854500 | 0.181 sec/iter\n",
      "Epoch: 178 | Batch: 002 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.836000 | 0.181 sec/iter\n",
      "Epoch: 178 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 178 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 179 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.836000 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 002 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.841500 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.873500 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.875000 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 179 | Batch: 008 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 179 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 179 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.839590 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 180 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.848000 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 001 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 180 | Batch: 010 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.836177 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 181 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.837500 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.853500 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.839500 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.850000 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.868000 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 181 | Batch: 010 / 011 | Total loss: 0.341 | Reg loss: 0.029 | Tree loss: 0.341 | Accuracy: 0.931741 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 182 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.830500 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 001 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.843500 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 182 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.871000 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.873000 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.869500 | 0.181 sec/iter\n",
      "Epoch: 182 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.890785 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 183 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 001 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 002 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.849500 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.851000 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 007 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.848000 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 183 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.883959 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 184 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.858500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.852000 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.874000 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 184 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 185 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.837000 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 002 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.837000 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.853500 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.849500 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.857500 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 007 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.875000 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.874500 | 0.181 sec/iter\n",
      "Epoch: 185 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.849829 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 186 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.842000 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.876000 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.860500 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.880500 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 186 | Batch: 010 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.860068 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 187 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.847500 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.839000 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.869000 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 187 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 187 | Batch: 010 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.856655 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 188 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.843000 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 002 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.842000 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.877000 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.873500 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 188 | Batch: 010 / 011 | Total loss: 0.406 | Reg loss: 0.029 | Tree loss: 0.406 | Accuracy: 0.873720 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 189 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.827500 | 0.182 sec/iter\n",
      "Epoch: 189 | Batch: 001 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.846500 | 0.182 sec/iter\n",
      "Epoch: 189 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.849000 | 0.182 sec/iter\n",
      "Epoch: 189 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 004 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.868000 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.855500 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 189 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.839590 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 190 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.831500 | 0.182 sec/iter\n",
      "Epoch: 190 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.855000 | 0.182 sec/iter\n",
      "Epoch: 190 | Batch: 002 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.863000 | 0.182 sec/iter\n",
      "Epoch: 190 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.847000 | 0.182 sec/iter\n",
      "Epoch: 190 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.852500 | 0.182 sec/iter\n",
      "Epoch: 190 | Batch: 005 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 190 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 190 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 190 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 190 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 190 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.029 | Tree loss: 0.403 | Accuracy: 0.904437 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 191 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.842000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.832000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.841000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 003 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 004 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.856000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.860500 | 0.181 sec/iter\n",
      "Epoch: 191 | Batch: 010 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.866894 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 192 | Batch: 000 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.839500 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.844500 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.831500 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.869500 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 192 | Batch: 010 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.883959 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 193 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 001 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.829000 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.857500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.866500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 193 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.870307 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 194 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.826500 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.865500 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.872500 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.869500 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 008 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 194 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.029 | Tree loss: 0.397 | Accuracy: 0.880546 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 195 | Batch: 000 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.852000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.856000 | 0.181 sec/iter\n",
      "Epoch: 195 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.029 | Tree loss: 0.376 | Accuracy: 0.904437 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 196 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.829000 | 0.181 sec/iter\n",
      "Epoch: 196 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 196 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.852000 | 0.181 sec/iter\n",
      "Epoch: 196 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.838500 | 0.181 sec/iter\n",
      "Epoch: 196 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 196 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 196 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 196 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 196 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 196 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 196 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 197 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 003 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 004 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 006 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 007 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.885000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 008 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 197 | Batch: 010 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 198 | Batch: 000 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 198 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 198 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 198 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 198 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.863000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 198 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 198 | Batch: 007 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 198 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 198 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 198 | Batch: 010 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 199 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 199 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.845000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 004 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 009 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 199 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 200 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.839000 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.833500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.853500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 200 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.897611 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 201 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.841000 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 002 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.879000 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.875000 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 201 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.029 | Tree loss: 0.388 | Accuracy: 0.897611 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 202 | Batch: 000 / 011 | Total loss: 0.521 | Reg loss: 0.029 | Tree loss: 0.521 | Accuracy: 0.829500 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.853500 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 003 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 009 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 202 | Batch: 010 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 203 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 001 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.849500 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 004 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.876500 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.855000 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 007 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 203 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.887372 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 204 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 204 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.845500 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.853000 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 005 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.877000 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 204 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.849829 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 205 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.839000 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 002 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 005 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 205 | Batch: 010 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.836177 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 206 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 206 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 206 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 206 | Batch: 003 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 206 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 206 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 206 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 206 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 206 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 206 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 206 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 207 | Batch: 000 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 001 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 005 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 008 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 207 | Batch: 010 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 208 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 007 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 008 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.885000 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 208 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 209 | Batch: 000 / 011 | Total loss: 0.516 | Reg loss: 0.029 | Tree loss: 0.516 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.853500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 209 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 007 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 209 | Batch: 010 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 210 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 210 | Batch: 010 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 211 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 003 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 211 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.029 | Tree loss: 0.399 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 212 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 009 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 212 | Batch: 010 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 213 | Batch: 000 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 001 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 003 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 005 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 213 | Batch: 010 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 214 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.814500 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 001 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 002 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 005 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.864500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 009 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 214 | Batch: 010 / 011 | Total loss: 0.357 | Reg loss: 0.029 | Tree loss: 0.357 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 215 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 215 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.029 | Tree loss: 0.401 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 216 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 005 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 006 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.880500 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 007 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.884000 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.886000 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 216 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 217 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.832500 | 0.181 sec/iter\n",
      "Epoch: 217 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 009 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 217 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 218 | Batch: 000 / 011 | Total loss: 0.524 | Reg loss: 0.029 | Tree loss: 0.524 | Accuracy: 0.822000 | 0.181 sec/iter\n",
      "Epoch: 218 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 218 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.860500 | 0.181 sec/iter\n",
      "Epoch: 218 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 218 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 218 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 218 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 218 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 218 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 218 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 218 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.846416 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 219 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.832000 | 0.181 sec/iter\n",
      "Epoch: 219 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.841000 | 0.181 sec/iter\n",
      "Epoch: 219 | Batch: 002 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 219 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.857500 | 0.181 sec/iter\n",
      "Epoch: 219 | Batch: 004 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 219 | Batch: 005 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 219 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 219 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 219 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 219 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 219 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 | Batch: 000 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.837000 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.858500 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.878500 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 220 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 220 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.846416 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 221 | Batch: 000 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.847500 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.820000 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.844000 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 221 | Batch: 010 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.829352 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 222 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.827000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.841500 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.842500 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 004 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 007 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.876000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.868000 | 0.181 sec/iter\n",
      "Epoch: 222 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.880546 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 223 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.839000 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.832500 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.846000 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 004 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.874000 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 223 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.029 | Tree loss: 0.369 | Accuracy: 0.907850 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 224 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.827500 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.828000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 006 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 224 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.856655 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 225 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.831000 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 002 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.856000 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 003 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.846500 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.862500 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 225 | Batch: 006 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.873500 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868000 | 0.181 sec/iter\n",
      "Epoch: 225 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.880546 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 226 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.821500 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 001 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.842000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 003 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.845000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 007 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.849500 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 226 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.883959 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 227 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.831000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 001 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.849000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 004 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.850000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.865500 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.869000 | 0.181 sec/iter\n",
      "Epoch: 227 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.873720 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 228 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.830500 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.831500 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 002 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.851500 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 005 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.847500 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.868000 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.873000 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 228 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.866894 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 229 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.823500 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.829500 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.858000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 004 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.829000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.867000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 006 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.889500 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 229 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.860068 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 230 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.830500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 001 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.848500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.843000 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.855500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.861500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.872500 | 0.181 sec/iter\n",
      "Epoch: 230 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.859000 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.870307 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 231 | Batch: 000 / 011 | Total loss: 0.525 | Reg loss: 0.029 | Tree loss: 0.525 | Accuracy: 0.810000 | 0.182 sec/iter\n",
      "Epoch: 231 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.828500 | 0.182 sec/iter\n",
      "Epoch: 231 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.850500 | 0.182 sec/iter\n",
      "Epoch: 231 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.849000 | 0.182 sec/iter\n",
      "Epoch: 231 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857500 | 0.181 sec/iter\n",
      "Epoch: 231 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.860000 | 0.181 sec/iter\n",
      "Epoch: 231 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 231 | Batch: 007 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.875500 | 0.181 sec/iter\n",
      "Epoch: 231 | Batch: 008 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 231 | Batch: 009 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.865000 | 0.181 sec/iter\n",
      "Epoch: 231 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.849829 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 232 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.842000 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.841000 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.862500 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 003 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851000 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.860500 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.850500 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.864000 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.864000 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.865500 | 0.182 sec/iter\n",
      "Epoch: 232 | Batch: 009 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 232 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.860068 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 233 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.832500 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.820500 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.854000 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.859000 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.863500 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.863500 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.869500 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.864000 | 0.182 sec/iter\n",
      "Epoch: 233 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 233 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.856500 | 0.181 sec/iter\n",
      "Epoch: 233 | Batch: 010 / 011 | Total loss: 0.394 | Reg loss: 0.029 | Tree loss: 0.394 | Accuracy: 0.863481 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 234 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.838000 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.839000 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.829000 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.851500 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.857000 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.857500 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.861000 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.871000 | 0.182 sec/iter\n",
      "Epoch: 234 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867500 | 0.181 sec/iter\n",
      "Epoch: 234 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.872000 | 0.181 sec/iter\n",
      "Epoch: 234 | Batch: 010 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.860068 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 235 | Batch: 000 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.838500 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.836000 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.844500 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.835500 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.861500 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 005 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.851500 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 006 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.852000 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 007 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.870500 | 0.182 sec/iter\n",
      "Epoch: 235 | Batch: 008 / 011 | Total loss: 0.409 | Reg loss: 0.029 | Tree loss: 0.409 | Accuracy: 0.881500 | 0.181 sec/iter\n",
      "Epoch: 235 | Batch: 009 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.874000 | 0.181 sec/iter\n",
      "Epoch: 235 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.843003 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 236 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.823500 | 0.182 sec/iter\n",
      "Epoch: 236 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.832500 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 236 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.847500 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.844000 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.872000 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.858500 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.872500 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.862500 | 0.181 sec/iter\n",
      "Epoch: 236 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.029 | Tree loss: 0.399 | Accuracy: 0.863481 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 237 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.825500 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.835000 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.840500 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.848000 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.859500 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.837500 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.875000 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.876500 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.877000 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.861000 | 0.181 sec/iter\n",
      "Epoch: 237 | Batch: 010 / 011 | Total loss: 0.398 | Reg loss: 0.029 | Tree loss: 0.398 | Accuracy: 0.924915 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 238 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.837000 | 0.181 sec/iter\n",
      "Epoch: 238 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.822000 | 0.181 sec/iter\n",
      "Epoch: 238 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 238 | Batch: 003 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 006 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 008 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.882500 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 238 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 239 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 239 | Batch: 010 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 240 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 001 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.812500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 240 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.029 | Tree loss: 0.383 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 241 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 003 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 005 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.852000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 241 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 241 | Batch: 010 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 242 | Batch: 000 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.813000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.880000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 242 | Batch: 010 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.832765 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 243 | Batch: 000 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 243 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 243 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 243 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 243 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 243 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 243 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 243 | Batch: 007 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 243 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 243 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 243 | Batch: 010 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.846416 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 244 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.824000 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.847000 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 244 | Batch: 010 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 245 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.812500 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 002 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 245 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 246 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.833500 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.840000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 246 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.871000 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 246 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 247 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 001 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 002 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.853000 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.853000 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 007 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 247 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.029 | Tree loss: 0.382 | Accuracy: 0.887372 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 248 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 248 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.808000 | 0.18 sec/iter\n",
      "Epoch: 248 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 248 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 248 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 248 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 248 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 248 | Batch: 007 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 248 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 248 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 248 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 249 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 249 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 250 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 006 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 250 | Batch: 010 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 251 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 004 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 005 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 007 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 009 / 011 | Total loss: 0.407 | Reg loss: 0.029 | Tree loss: 0.407 | Accuracy: 0.882500 | 0.18 sec/iter\n",
      "Epoch: 251 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 252 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 252 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 252 | Batch: 002 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 252 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.847000 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 252 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 252 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 252 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 252 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 252 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 252 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 252 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 253 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 253 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 253 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 253 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 253 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 253 | Batch: 005 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 253 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 253 | Batch: 007 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 253 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 253 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 253 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.894198 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 254 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.810500 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 007 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 254 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 254 | Batch: 010 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 255 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.817000 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 002 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.878500 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 255 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.029 | Tree loss: 0.393 | Accuracy: 0.887372 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 256 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 256 | Batch: 010 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 257 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.874000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 257 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 257 | Batch: 010 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 258 | Batch: 000 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 009 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 258 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 259 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 001 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 002 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 007 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 259 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 260 | Batch: 000 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.832500 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 002 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 006 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 008 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 260 | Batch: 010 / 011 | Total loss: 0.398 | Reg loss: 0.029 | Tree loss: 0.398 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 261 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 001 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 009 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.881000 | 0.18 sec/iter\n",
      "Epoch: 261 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 262 | Batch: 000 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 262 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.821000 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 001 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 007 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 263 | Batch: 010 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 264 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 008 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 264 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.839590 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 265 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.822000 | 0.181 sec/iter\n",
      "Epoch: 265 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.826500 | 0.181 sec/iter\n",
      "Epoch: 265 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 265 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.848000 | 0.181 sec/iter\n",
      "Epoch: 265 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 265 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 265 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 265 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 265 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 265 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 265 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.887372 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 266 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.817500 | 0.181 sec/iter\n",
      "Epoch: 266 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.817000 | 0.181 sec/iter\n",
      "Epoch: 266 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 266 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.846500 | 0.181 sec/iter\n",
      "Epoch: 266 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.854000 | 0.181 sec/iter\n",
      "Epoch: 266 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.873000 | 0.181 sec/iter\n",
      "Epoch: 266 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 266 | Batch: 007 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 266 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 266 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 266 | Batch: 010 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 267 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.029 | Tree loss: 0.515 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 267 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 268 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.815500 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.814500 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.842500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 006 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.879500 | 0.18 sec/iter\n",
      "Epoch: 268 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.029 | Tree loss: 0.382 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 269 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.818000 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 269 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 270 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 270 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 270 | Batch: 010 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 271 | Batch: 000 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 271 | Batch: 001 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 271 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 271 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.840000 | 0.181 sec/iter\n",
      "Epoch: 271 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 271 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 271 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 271 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 271 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 271 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 271 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 272 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.814500 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 001 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.830000 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.823000 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 003 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.826500 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.852500 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 006 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.876000 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 272 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 272 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 272 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 273 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.817500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.814500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.836500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.843000 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.871500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 008 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.859500 | 0.181 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 273 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 273 | Batch: 010 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.890785 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 274 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.811000 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.825500 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.833000 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 003 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.856000 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864500 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.875500 | 0.181 sec/iter\n",
      "Epoch: 274 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 274 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 274 | Batch: 010 / 011 | Total loss: 0.384 | Reg loss: 0.029 | Tree loss: 0.384 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 275 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.813500 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 005 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 275 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.029 | Tree loss: 0.395 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 276 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.821000 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 004 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 276 | Batch: 010 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 277 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.812000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 001 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 005 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.884000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 277 | Batch: 010 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 278 | Batch: 000 / 011 | Total loss: 0.523 | Reg loss: 0.029 | Tree loss: 0.523 | Accuracy: 0.808500 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 007 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 278 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 279 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 001 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.837000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 279 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.883000 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 279 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 280 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 006 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 280 | Batch: 010 / 011 | Total loss: 0.379 | Reg loss: 0.029 | Tree loss: 0.379 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 281 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 005 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 006 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 281 | Batch: 008 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 281 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 281 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 282 | Batch: 000 / 011 | Total loss: 0.525 | Reg loss: 0.029 | Tree loss: 0.525 | Accuracy: 0.810500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.824000 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.855000 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.855500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.881500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 282 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.029 | Tree loss: 0.401 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 283 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.829000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.825000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 002 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.810500 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.874000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 283 | Batch: 010 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.846416 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 284 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.826500 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.829500 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.832500 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.870500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 284 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 284 | Batch: 010 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.805461 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 285 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.828000 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 001 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.818500 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.841500 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 285 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.029 | Tree loss: 0.400 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 286 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.801000 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.823000 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.841500 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 003 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 006 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 286 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 287 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 001 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.813000 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 005 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 287 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.029 | Tree loss: 0.381 | Accuracy: 0.897611 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 288 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.832000 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.827500 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 002 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.820500 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.875000 | 0.179 sec/iter\n",
      "Epoch: 288 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 289 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.819500 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.840000 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 289 | Batch: 010 / 011 | Total loss: 0.391 | Reg loss: 0.029 | Tree loss: 0.391 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.819000 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.816000 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.840000 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.840000 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.878500 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 290 | Batch: 010 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.856655 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 291 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 291 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 291 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.853500 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 006 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 008 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.879000 | 0.179 sec/iter\n",
      "Epoch: 291 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 292 | Batch: 000 / 011 | Total loss: 0.516 | Reg loss: 0.029 | Tree loss: 0.516 | Accuracy: 0.814500 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.829000 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 002 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.817000 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 292 | Batch: 010 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 293 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 293 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 293 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 293 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 293 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 293 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 293 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 293 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 293 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 293 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 293 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.029 | Tree loss: 0.399 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 294 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 004 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 294 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 294 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 294 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.029 | Tree loss: 0.380 | Accuracy: 0.897611 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 295 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 001 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 003 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.862500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 295 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 295 | Batch: 009 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 295 | Batch: 010 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.894198 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 296 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 003 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 004 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 005 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 296 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 296 | Batch: 008 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 296 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 296 | Batch: 010 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 297 | Batch: 000 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.812000 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 009 / 011 | Total loss: 0.402 | Reg loss: 0.029 | Tree loss: 0.402 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 297 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.029 | Tree loss: 0.399 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 298 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.814500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 298 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 299 | Batch: 000 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.816500 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 006 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 009 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 299 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.029 | Tree loss: 0.383 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 300 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 002 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 005 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 008 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.885500 | 0.18 sec/iter\n",
      "Epoch: 300 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.865000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 301 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.810000 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 001 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 006 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.880000 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 301 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 302 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 002 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 302 | Batch: 010 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 303 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.811000 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 002 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 303 | Batch: 010 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 304 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.808500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 001 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.822000 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 004 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 304 | Batch: 010 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 305 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.812500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 006 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 305 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.029 | Tree loss: 0.403 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 306 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 002 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.844000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 306 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 306 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.029 | Tree loss: 0.402 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 307 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.822000 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 001 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 005 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 307 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 308 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 001 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 009 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 308 | Batch: 010 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 309 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 007 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 309 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 310 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 006 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 310 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.029 | Tree loss: 0.383 | Accuracy: 0.887372 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 311 | Batch: 000 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.872000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 311 | Batch: 008 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 311 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 312 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.818500 | 0.181 sec/iter\n",
      "Epoch: 312 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.821500 | 0.181 sec/iter\n",
      "Epoch: 312 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 312 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 313 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.829500 | 0.181 sec/iter\n",
      "Epoch: 313 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.817500 | 0.181 sec/iter\n",
      "Epoch: 313 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.839000 | 0.181 sec/iter\n",
      "Epoch: 313 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.824500 | 0.181 sec/iter\n",
      "Epoch: 313 | Batch: 004 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.831000 | 0.181 sec/iter\n",
      "Epoch: 313 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 313 | Batch: 006 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 313 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 313 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 313 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 313 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.029 | Tree loss: 0.377 | Accuracy: 0.904437 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 314 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.828000 | 0.181 sec/iter\n",
      "Epoch: 314 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 314 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 003 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.880000 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 314 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 315 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.813000 | 0.181 sec/iter\n",
      "Epoch: 315 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.825000 | 0.181 sec/iter\n",
      "Epoch: 315 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.828500 | 0.181 sec/iter\n",
      "Epoch: 315 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.845500 | 0.181 sec/iter\n",
      "Epoch: 315 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.855000 | 0.181 sec/iter\n",
      "Epoch: 315 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 315 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 315 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 315 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 315 | Batch: 009 / 011 | Total loss: 0.401 | Reg loss: 0.029 | Tree loss: 0.401 | Accuracy: 0.888500 | 0.18 sec/iter\n",
      "Epoch: 315 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 316 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.811500 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 001 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.815500 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.831000 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 004 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.843500 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 005 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.839000 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.865500 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.879000 | 0.181 sec/iter\n",
      "Epoch: 316 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.904437 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 317 | Batch: 000 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.829000 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.816000 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.827500 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.834500 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.850500 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.868500 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.873000 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.870500 | 0.181 sec/iter\n",
      "Epoch: 317 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 318 | Batch: 000 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 001 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.838000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 002 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.830500 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 003 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.819000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.840000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.857000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.870000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 008 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865500 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866000 | 0.181 sec/iter\n",
      "Epoch: 318 | Batch: 010 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.853242 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 319 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.823000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.811500 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 002 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.844500 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.847000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 004 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.880000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.863000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.859000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.862000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 009 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.853000 | 0.181 sec/iter\n",
      "Epoch: 319 | Batch: 010 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.843003 | 0.181 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 320 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.821500 | 0.181 sec/iter\n",
      "Epoch: 320 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.816000 | 0.181 sec/iter\n",
      "Epoch: 320 | Batch: 002 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.834500 | 0.181 sec/iter\n",
      "Epoch: 320 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.836000 | 0.181 sec/iter\n",
      "Epoch: 320 | Batch: 004 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864000 | 0.181 sec/iter\n",
      "Epoch: 320 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.851000 | 0.181 sec/iter\n",
      "Epoch: 320 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 320 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 320 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 320 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 320 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 321 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.821000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.822000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 004 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 009 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 321 | Batch: 010 / 011 | Total loss: 0.384 | Reg loss: 0.029 | Tree loss: 0.384 | Accuracy: 0.887372 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 322 | Batch: 000 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 001 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.849000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 322 | Batch: 006 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 007 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 008 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 322 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 323 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.813000 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 001 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.808500 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 002 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 009 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 323 | Batch: 010 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 324 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 005 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 324 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.846416 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 325 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.818000 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 004 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 006 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 325 | Batch: 010 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 326 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 003 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 326 | Batch: 007 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 326 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 326 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.873000 | 0.179 sec/iter\n",
      "Epoch: 326 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 327 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.836500 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 002 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.842000 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.841500 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 006 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 327 | Batch: 010 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.843003 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 328 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.824000 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.826000 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.835500 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 328 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.029 | Tree loss: 0.402 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 329 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.821000 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.841000 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 002 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.837500 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.841500 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.845500 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.876500 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 329 | Batch: 010 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.843003 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 330 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.825500 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 001 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.817500 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.827500 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.837000 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 006 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 330 | Batch: 010 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 331 | Batch: 000 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.820000 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.817000 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 003 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 005 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 331 | Batch: 010 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 332 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.819500 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.837500 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.822000 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.827500 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.841000 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 005 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.875000 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 008 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 332 | Batch: 010 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 333 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.813500 | 0.18 sec/iter\n",
      "Epoch: 333 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.851500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 333 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 333 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 334 | Batch: 000 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 334 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.818000 | 0.18 sec/iter\n",
      "Epoch: 334 | Batch: 002 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.820500 | 0.18 sec/iter\n",
      "Epoch: 334 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 334 | Batch: 004 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 334 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 334 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 334 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 334 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 334 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 334 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 335 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 335 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 335 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 335 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 004 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.853000 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 335 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 336 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.825500 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 001 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.838000 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.844500 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 009 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 336 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 337 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.828000 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.829000 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.822500 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.842000 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 007 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.878000 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 337 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 338 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.819500 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 003 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 004 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.855500 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.870500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 338 | Batch: 008 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 338 | Batch: 010 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.832765 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 339 | Batch: 000 / 011 | Total loss: 0.523 | Reg loss: 0.029 | Tree loss: 0.523 | Accuracy: 0.813500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.875000 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 339 | Batch: 010 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.832765 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 340 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.810000 | 0.18 sec/iter\n",
      "Epoch: 340 | Batch: 001 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 340 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 340 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 340 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 340 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 340 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 340 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 340 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 340 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 340 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.029 | Tree loss: 0.403 | Accuracy: 0.887372 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 341 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.816000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 001 / 011 | Total loss: 0.515 | Reg loss: 0.029 | Tree loss: 0.515 | Accuracy: 0.814000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 002 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 005 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 006 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 341 | Batch: 010 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 342 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.878500 | 0.18 sec/iter\n",
      "Epoch: 342 | Batch: 010 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 343 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.815500 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 002 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 343 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 343 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 343 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.873000 | 0.179 sec/iter\n",
      "Epoch: 343 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 344 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 344 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 344 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 344 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 344 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 344 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 344 | Batch: 006 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.853500 | 0.179 sec/iter\n",
      "Epoch: 344 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.873000 | 0.179 sec/iter\n",
      "Epoch: 344 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 344 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 344 | Batch: 010 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.856655 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 345 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 345 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.029 | Tree loss: 0.400 | Accuracy: 0.904437 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 346 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.814500 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 006 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 346 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 347 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.816000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 002 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 347 | Batch: 010 / 011 | Total loss: 0.344 | Reg loss: 0.029 | Tree loss: 0.344 | Accuracy: 0.897611 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 348 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.807000 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 008 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.884500 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 348 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 349 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.847000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 349 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 349 | Batch: 010 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 350 | Batch: 000 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 003 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 008 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 350 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 351 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 351 | Batch: 010 / 011 | Total loss: 0.407 | Reg loss: 0.029 | Tree loss: 0.407 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 352 | Batch: 000 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 352 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 353 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 005 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 009 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.879500 | 0.18 sec/iter\n",
      "Epoch: 353 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 354 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 004 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.858000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 354 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 009 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 354 | Batch: 010 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.839590 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 355 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 001 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 003 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 004 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 005 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 007 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 355 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.029 | Tree loss: 0.401 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 356 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 001 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 004 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 005 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 356 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.029 | Tree loss: 0.380 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 357 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 001 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.879000 | 0.18 sec/iter\n",
      "Epoch: 357 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.029 | Tree loss: 0.397 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 358 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.815500 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 002 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 007 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 358 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 359 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 001 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 004 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.879000 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 359 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.832765 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 001 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 006 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 008 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 360 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 361 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 001 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 003 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 005 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 006 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 008 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 361 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 362 | Batch: 000 / 011 | Total loss: 0.516 | Reg loss: 0.029 | Tree loss: 0.516 | Accuracy: 0.810000 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 006 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 362 | Batch: 010 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 363 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 003 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 007 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 008 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.879000 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 009 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.880000 | 0.18 sec/iter\n",
      "Epoch: 363 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.029 | Tree loss: 0.390 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 364 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 001 / 011 | Total loss: 0.523 | Reg loss: 0.029 | Tree loss: 0.523 | Accuracy: 0.802000 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 364 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 365 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.818000 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.826000 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 003 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.859500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 365 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 365 | Batch: 010 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 366 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.821500 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.822500 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 004 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 006 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 007 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 366 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 367 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.815500 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.819500 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 002 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 004 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 005 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.855500 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 009 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.853000 | 0.179 sec/iter\n",
      "Epoch: 367 | Batch: 010 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 368 | Batch: 000 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 001 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.812500 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 004 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 006 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 008 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 009 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 368 | Batch: 010 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 369 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.834500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 001 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.819000 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.844500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 004 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 006 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.886500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 369 | Batch: 010 / 011 | Total loss: 0.334 | Reg loss: 0.029 | Tree loss: 0.334 | Accuracy: 0.907850 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 370 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.822500 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.827000 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.840000 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 370 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.874000 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370 | Batch: 010 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 371 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.826500 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 002 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.853000 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 371 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 372 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 001 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 002 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.842000 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.847000 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 007 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 372 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.029 | Tree loss: 0.401 | Accuracy: 0.894198 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 373 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.831000 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 003 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.827500 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 005 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 006 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.855000 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.855000 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 373 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.029 | Tree loss: 0.383 | Accuracy: 0.890785 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 374 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.842000 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.847000 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 004 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.842000 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 005 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.880000 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.855500 | 0.179 sec/iter\n",
      "Epoch: 374 | Batch: 010 / 011 | Total loss: 0.398 | Reg loss: 0.029 | Tree loss: 0.398 | Accuracy: 0.897611 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 375 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.029 | Tree loss: 0.515 | Accuracy: 0.819000 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.822000 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 002 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.843500 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 375 | Batch: 010 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 376 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.818500 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 001 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.826500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 376 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 006 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.881500 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 376 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.029 | Tree loss: 0.393 | Accuracy: 0.887372 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 377 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.832500 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.817500 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 002 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.837500 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.844500 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.849500 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 009 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 377 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 378 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 378 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 378 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.836000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.836000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 006 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 378 | Batch: 010 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 379 | Batch: 000 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.811000 | 0.18 sec/iter\n",
      "Epoch: 379 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 002 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 007 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 379 | Batch: 010 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 380 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 380 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 380 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 380 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 009 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 380 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.846416 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 381 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.812000 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 003 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 004 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.862000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 381 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 381 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.878000 | 0.179 sec/iter\n",
      "Epoch: 381 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 382 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.815500 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 006 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 382 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 383 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 383 | Batch: 010 / 011 | Total loss: 0.407 | Reg loss: 0.029 | Tree loss: 0.407 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 384 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 001 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 004 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 384 | Batch: 010 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 385 | Batch: 000 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 002 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 008 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 385 | Batch: 010 / 011 | Total loss: 0.537 | Reg loss: 0.029 | Tree loss: 0.537 | Accuracy: 0.815700 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 386 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 006 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 009 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 386 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.883959 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 387 | Batch: 000 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 006 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 387 | Batch: 010 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 388 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.815000 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 003 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 004 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.882500 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 388 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 389 | Batch: 000 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 389 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.029 | Tree loss: 0.395 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 390 | Batch: 000 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.832500 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 004 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 008 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 009 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 390 | Batch: 010 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 391 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.817000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 001 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.817000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 007 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.880000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 009 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 391 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 392 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 001 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.834500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 392 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 009 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 392 | Batch: 010 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.839590 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 393 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.816000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 003 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 009 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.880500 | 0.18 sec/iter\n",
      "Epoch: 393 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 394 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 003 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 394 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 395 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 395 | Batch: 010 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.832765 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 396 | Batch: 000 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.817000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 396 | Batch: 010 / 011 | Total loss: 0.406 | Reg loss: 0.029 | Tree loss: 0.406 | Accuracy: 0.894198 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 397 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.818000 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 002 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 006 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 008 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.871500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 397 | Batch: 009 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.884000 | 0.18 sec/iter\n",
      "Epoch: 397 | Batch: 010 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 398 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.878500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 398 | Batch: 010 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.839590 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 399 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 003 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 399 | Batch: 010 / 011 | Total loss: 0.384 | Reg loss: 0.029 | Tree loss: 0.384 | Accuracy: 0.894198 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 400 | Batch: 000 / 011 | Total loss: 0.519 | Reg loss: 0.029 | Tree loss: 0.519 | Accuracy: 0.820500 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 400 | Batch: 010 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 401 | Batch: 000 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 001 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.853000 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 401 | Batch: 010 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 402 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 402 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.029 | Tree loss: 0.392 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 403 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 002 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.840500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 403 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 403 | Batch: 010 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 404 | Batch: 000 / 011 | Total loss: 0.516 | Reg loss: 0.029 | Tree loss: 0.516 | Accuracy: 0.815000 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 001 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 009 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 404 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.853242 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 405 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 008 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 405 | Batch: 010 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 406 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.816000 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 002 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.880500 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 406 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.846416 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 407 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.821000 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.829500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 008 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 407 | Batch: 010 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 408 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.822000 | 0.18 sec/iter\n",
      "Epoch: 408 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.819000 | 0.18 sec/iter\n",
      "Epoch: 408 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 408 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 408 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 408 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 408 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 408 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 408 | Batch: 008 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.877500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 408 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 408 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 409 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 409 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 409 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.822500 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.831000 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 005 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 409 | Batch: 010 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.894198 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 410 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.826000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.836000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.821000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 003 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 007 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 410 | Batch: 010 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.819113 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 411 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.820500 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.839000 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 007 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.879000 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 411 | Batch: 010 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 412 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.826000 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.834500 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 005 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.845000 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 006 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 009 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.880500 | 0.179 sec/iter\n",
      "Epoch: 412 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 413 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.835500 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.823000 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 007 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 413 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.856655 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 414 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.837500 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 004 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 005 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 414 | Batch: 010 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.897611 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 415 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.815500 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.843500 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 004 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 415 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.029 | Tree loss: 0.400 | Accuracy: 0.887372 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 416 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.812000 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.831000 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.842000 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 005 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 006 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 007 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.878500 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 416 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 417 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.834500 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.835500 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.845000 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 004 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 009 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 417 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 418 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 001 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.819500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 008 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 418 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 419 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.832500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 001 / 011 | Total loss: 0.520 | Reg loss: 0.029 | Tree loss: 0.520 | Accuracy: 0.807500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 002 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.844500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.849500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.845500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 419 | Batch: 005 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 419 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 420 | Batch: 000 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.837000 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.829500 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 002 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.808000 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.837500 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 007 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 420 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 421 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.829000 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 004 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.880500 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 421 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 422 | Batch: 000 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.831500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 002 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.820500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 005 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.877000 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 422 | Batch: 010 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.812287 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 423 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.821000 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.882000 | 0.179 sec/iter\n",
      "Epoch: 423 | Batch: 010 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 424 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.827500 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.834500 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 004 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 007 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.855500 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 424 | Batch: 010 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.860068 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 425 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.832000 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 005 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 007 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 009 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 425 | Batch: 010 / 011 | Total loss: 0.396 | Reg loss: 0.029 | Tree loss: 0.396 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 426 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 001 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.815500 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.820000 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 005 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.877500 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 426 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 427 | Batch: 000 / 011 | Total loss: 0.522 | Reg loss: 0.029 | Tree loss: 0.522 | Accuracy: 0.820500 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.828000 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.828000 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 003 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.847000 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 005 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.879000 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.878500 | 0.179 sec/iter\n",
      "Epoch: 427 | Batch: 010 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.856655 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 428 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.836500 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.817000 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 005 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 009 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 428 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 429 | Batch: 000 / 011 | Total loss: 0.528 | Reg loss: 0.029 | Tree loss: 0.528 | Accuracy: 0.808500 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 001 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.815500 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 002 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.873000 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 008 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.875000 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 009 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.880500 | 0.179 sec/iter\n",
      "Epoch: 429 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 430 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.813500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 430 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.823000 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.828500 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 007 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 009 / 011 | Total loss: 0.400 | Reg loss: 0.029 | Tree loss: 0.400 | Accuracy: 0.884000 | 0.179 sec/iter\n",
      "Epoch: 430 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 431 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.821000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.832000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.835000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 003 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 004 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 006 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.877500 | 0.179 sec/iter\n",
      "Epoch: 431 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 432 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 432 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.820500 | 0.18 sec/iter\n",
      "Epoch: 432 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 432 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.832500 | 0.18 sec/iter\n",
      "Epoch: 432 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 432 | Batch: 005 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.871500 | 0.179 sec/iter\n",
      "Epoch: 432 | Batch: 006 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.874000 | 0.179 sec/iter\n",
      "Epoch: 432 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 432 | Batch: 008 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 432 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.871000 | 0.179 sec/iter\n",
      "Epoch: 432 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 433 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.813000 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 007 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 008 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 433 | Batch: 009 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.874000 | 0.179 sec/iter\n",
      "Epoch: 433 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 434 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.813500 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 002 / 011 | Total loss: 0.502 | Reg loss: 0.029 | Tree loss: 0.502 | Accuracy: 0.808500 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 003 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 004 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 007 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 434 | Batch: 010 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 435 | Batch: 000 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.814000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 001 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 002 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.818000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.845000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.868500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 435 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 009 / 011 | Total loss: 0.410 | Reg loss: 0.029 | Tree loss: 0.410 | Accuracy: 0.881500 | 0.179 sec/iter\n",
      "Epoch: 435 | Batch: 010 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.819113 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 436 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.824500 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.827000 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.833500 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 005 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.873000 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 436 | Batch: 010 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 437 | Batch: 000 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 437 | Batch: 001 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 437 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.849000 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 007 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 009 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 437 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 438 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 001 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.822000 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 438 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.876500 | 0.179 sec/iter\n",
      "Epoch: 438 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 438 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.029 | Tree loss: 0.389 | Accuracy: 0.887372 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 439 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.823000 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 002 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.812500 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 004 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 005 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.883000 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 439 | Batch: 010 / 011 | Total loss: 0.350 | Reg loss: 0.029 | Tree loss: 0.350 | Accuracy: 0.918089 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 440 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.821000 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.814500 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 004 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 005 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 440 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.853242 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 441 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.824500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 002 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 007 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.880500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 008 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 441 | Batch: 010 / 011 | Total loss: 0.394 | Reg loss: 0.029 | Tree loss: 0.394 | Accuracy: 0.894198 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 442 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 004 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 442 | Batch: 010 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 443 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 006 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 009 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 443 | Batch: 010 / 011 | Total loss: 0.352 | Reg loss: 0.029 | Tree loss: 0.352 | Accuracy: 0.918089 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 444 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 002 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 004 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 005 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 007 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 008 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 444 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.029 | Tree loss: 0.381 | Accuracy: 0.897611 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 445 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 001 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 445 | Batch: 010 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.832765 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 446 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.832500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 446 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 004 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 005 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 008 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 009 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 446 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 447 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 002 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 003 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 004 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 447 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 447 | Batch: 010 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.822526 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 448 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.834000 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.834500 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.826000 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 003 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 006 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.847000 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.850000 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.874000 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 009 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.884500 | 0.179 sec/iter\n",
      "Epoch: 448 | Batch: 010 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.870307 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 449 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.826500 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.840500 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.840000 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.841000 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 005 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.858000 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 008 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 449 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.819113 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 450 | Batch: 000 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.821500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 001 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.844500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.835500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 004 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 009 / 011 | Total loss: 0.415 | Reg loss: 0.029 | Tree loss: 0.415 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 450 | Batch: 010 / 011 | Total loss: 0.391 | Reg loss: 0.029 | Tree loss: 0.391 | Accuracy: 0.860068 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 451 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.827500 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.841500 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 003 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 004 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.873000 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 005 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 008 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.859000 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 451 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 451 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.029 | Tree loss: 0.377 | Accuracy: 0.907850 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 452 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 003 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851000 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 006 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.851500 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 452 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.894198 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 453 | Batch: 000 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 001 / 011 | Total loss: 0.513 | Reg loss: 0.029 | Tree loss: 0.513 | Accuracy: 0.822000 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.849500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 004 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 005 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.869000 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 009 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 453 | Batch: 010 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.832765 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 454 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.839000 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.822000 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.829000 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 004 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 005 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 006 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.856500 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.879500 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 454 | Batch: 010 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 455 | Batch: 000 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 001 / 011 | Total loss: 0.496 | Reg loss: 0.029 | Tree loss: 0.496 | Accuracy: 0.829500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.835500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 004 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 006 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.837000 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.857000 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 008 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.875500 | 0.179 sec/iter\n",
      "Epoch: 455 | Batch: 010 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.873720 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 456 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 001 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.812500 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.838500 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 004 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.882500 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 005 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863000 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865500 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.857500 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.861000 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.870000 | 0.179 sec/iter\n",
      "Epoch: 456 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.029 | Tree loss: 0.395 | Accuracy: 0.890785 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 457 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.823500 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 001 / 011 | Total loss: 0.506 | Reg loss: 0.029 | Tree loss: 0.506 | Accuracy: 0.821000 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.833500 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.836500 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.852500 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.859500 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 457 | Batch: 010 / 011 | Total loss: 0.350 | Reg loss: 0.029 | Tree loss: 0.350 | Accuracy: 0.911263 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 458 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.029 | Tree loss: 0.510 | Accuracy: 0.813500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.820500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 002 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.830500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.842500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 005 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.868000 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 006 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.868500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 458 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.029 | Tree loss: 0.390 | Accuracy: 0.880546 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 459 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.820000 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.833000 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.848000 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 006 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.874500 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 007 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 459 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.883959 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 460 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 460 | Batch: 001 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.843000 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.834500 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.832000 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 004 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.850500 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.839500 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.847500 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 009 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 460 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 461 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.029 | Tree loss: 0.509 | Accuracy: 0.817500 | 0.18 sec/iter\n",
      "Epoch: 461 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 461 | Batch: 002 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 461 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 461 | Batch: 004 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 461 | Batch: 005 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 461 | Batch: 006 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 461 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.872000 | 0.179 sec/iter\n",
      "Epoch: 461 | Batch: 008 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.876000 | 0.179 sec/iter\n",
      "Epoch: 461 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.861500 | 0.179 sec/iter\n",
      "Epoch: 461 | Batch: 010 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.853242 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 462 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.822500 | 0.18 sec/iter\n",
      "Epoch: 462 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 462 | Batch: 002 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 462 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.832000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 462 | Batch: 005 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 462 | Batch: 006 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 462 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.867000 | 0.179 sec/iter\n",
      "Epoch: 462 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.872500 | 0.179 sec/iter\n",
      "Epoch: 462 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 462 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 463 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.816000 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.819000 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 004 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 463 | Batch: 010 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.832765 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 464 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.837500 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 004 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 005 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 009 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 464 | Batch: 010 / 011 | Total loss: 0.355 | Reg loss: 0.029 | Tree loss: 0.355 | Accuracy: 0.901024 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 465 | Batch: 000 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 001 / 011 | Total loss: 0.477 | Reg loss: 0.029 | Tree loss: 0.477 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 003 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 006 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 009 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 465 | Batch: 010 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 466 | Batch: 000 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 001 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.835500 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 002 / 011 | Total loss: 0.500 | Reg loss: 0.029 | Tree loss: 0.500 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 004 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.843000 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 005 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 008 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 466 | Batch: 010 / 011 | Total loss: 0.412 | Reg loss: 0.029 | Tree loss: 0.412 | Accuracy: 0.887372 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 467 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 003 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.029 | Tree loss: 0.450 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 007 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.870000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 467 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 467 | Batch: 010 / 011 | Total loss: 0.357 | Reg loss: 0.029 | Tree loss: 0.357 | Accuracy: 0.907850 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 468 | Batch: 000 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 002 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.825000 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 468 | Batch: 010 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 469 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.029 | Tree loss: 0.518 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.828000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 004 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 469 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.029 | Tree loss: 0.382 | Accuracy: 0.890785 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 470 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.821500 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 001 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 002 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 003 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 005 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 006 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 470 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.029 | Tree loss: 0.460 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 471 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.833500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 001 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 008 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 471 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 472 | Batch: 000 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.029 | Tree loss: 0.497 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 003 / 011 | Total loss: 0.465 | Reg loss: 0.029 | Tree loss: 0.465 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 008 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 472 | Batch: 010 / 011 | Total loss: 0.515 | Reg loss: 0.029 | Tree loss: 0.515 | Accuracy: 0.829352 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 473 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.833000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 473 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 006 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 473 | Batch: 010 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.843003 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 474 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.816000 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 001 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.836000 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 003 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 004 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 007 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.869000 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 474 | Batch: 010 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 475 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.832500 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.819500 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 002 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 003 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 004 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 005 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 475 | Batch: 010 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.866894 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 476 | Batch: 000 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 001 / 011 | Total loss: 0.468 | Reg loss: 0.029 | Tree loss: 0.468 | Accuracy: 0.848500 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.842500 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 003 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.862000 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 004 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 005 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.845500 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 476 | Batch: 010 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 477 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.831500 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.029 | Tree loss: 0.480 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 005 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 006 / 011 | Total loss: 0.417 | Reg loss: 0.029 | Tree loss: 0.417 | Accuracy: 0.876500 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 007 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.877000 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 008 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 009 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 477 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.029 | Tree loss: 0.408 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 478 | Batch: 000 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.816500 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 003 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.848000 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 007 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.876000 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 478 | Batch: 008 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 478 | Batch: 010 / 011 | Total loss: 0.379 | Reg loss: 0.029 | Tree loss: 0.379 | Accuracy: 0.880546 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 479 | Batch: 000 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.827500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 001 / 011 | Total loss: 0.478 | Reg loss: 0.029 | Tree loss: 0.478 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 002 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.857500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 007 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.866500 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 009 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.876000 | 0.18 sec/iter\n",
      "Epoch: 479 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 480 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.824000 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.830500 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.855000 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.857000 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 005 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 006 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 480 | Batch: 010 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 481 | Batch: 000 / 011 | Total loss: 0.514 | Reg loss: 0.029 | Tree loss: 0.514 | Accuracy: 0.818500 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.851000 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 006 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.880000 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.029 | Tree loss: 0.428 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 009 / 011 | Total loss: 0.420 | Reg loss: 0.029 | Tree loss: 0.420 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 481 | Batch: 010 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 482 | Batch: 000 / 011 | Total loss: 0.511 | Reg loss: 0.029 | Tree loss: 0.511 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 001 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.849500 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.849000 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 004 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.874000 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 006 / 011 | Total loss: 0.445 | Reg loss: 0.029 | Tree loss: 0.445 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 007 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.853500 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 482 | Batch: 010 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.849829 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 483 | Batch: 000 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 001 / 011 | Total loss: 0.512 | Reg loss: 0.029 | Tree loss: 0.512 | Accuracy: 0.813500 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 002 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 003 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.869500 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 007 / 011 | Total loss: 0.416 | Reg loss: 0.029 | Tree loss: 0.416 | Accuracy: 0.875000 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.867000 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 483 | Batch: 010 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.860068 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 484 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.029 | Tree loss: 0.482 | Accuracy: 0.832500 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.840000 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 004 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 005 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 006 / 011 | Total loss: 0.446 | Reg loss: 0.029 | Tree loss: 0.446 | Accuracy: 0.852000 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.029 | Tree loss: 0.411 | Accuracy: 0.875500 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 009 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 484 | Batch: 010 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.846416 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 485 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.827000 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 002 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.842000 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 003 / 011 | Total loss: 0.476 | Reg loss: 0.029 | Tree loss: 0.476 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 004 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.865500 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 005 / 011 | Total loss: 0.444 | Reg loss: 0.029 | Tree loss: 0.444 | Accuracy: 0.852500 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.863500 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 007 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.854000 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 008 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.878000 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.872500 | 0.18 sec/iter\n",
      "Epoch: 485 | Batch: 010 / 011 | Total loss: 0.452 | Reg loss: 0.029 | Tree loss: 0.452 | Accuracy: 0.836177 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 486 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 002 / 011 | Total loss: 0.498 | Reg loss: 0.029 | Tree loss: 0.498 | Accuracy: 0.826000 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 004 / 011 | Total loss: 0.470 | Reg loss: 0.029 | Tree loss: 0.470 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.885000 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.029 | Tree loss: 0.405 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 486 | Batch: 010 / 011 | Total loss: 0.384 | Reg loss: 0.029 | Tree loss: 0.384 | Accuracy: 0.870307 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 487 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.835000 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.847000 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.845000 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 004 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.868500 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 005 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.856500 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.864500 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 487 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.029 | Tree loss: 0.451 | Accuracy: 0.856655 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 488 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.823500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.029 | Tree loss: 0.488 | Accuracy: 0.833000 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 002 / 011 | Total loss: 0.462 | Reg loss: 0.029 | Tree loss: 0.462 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 003 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.846500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.865000 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.854500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.870500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 009 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.881500 | 0.18 sec/iter\n",
      "Epoch: 488 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.029 | Tree loss: 0.395 | Accuracy: 0.873720 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 489 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 001 / 011 | Total loss: 0.479 | Reg loss: 0.029 | Tree loss: 0.479 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.843500 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.844000 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 004 / 011 | Total loss: 0.467 | Reg loss: 0.029 | Tree loss: 0.467 | Accuracy: 0.838000 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.857500 | 0.18 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 489 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 007 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.863000 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 008 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 009 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.870000 | 0.18 sec/iter\n",
      "Epoch: 489 | Batch: 010 / 011 | Total loss: 0.407 | Reg loss: 0.029 | Tree loss: 0.407 | Accuracy: 0.877133 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 490 | Batch: 000 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.838500 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.029 | Tree loss: 0.501 | Accuracy: 0.820500 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.029 | Tree loss: 0.481 | Accuracy: 0.837000 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.029 | Tree loss: 0.459 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.029 | Tree loss: 0.454 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.860500 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.872000 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861000 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 008 / 011 | Total loss: 0.418 | Reg loss: 0.029 | Tree loss: 0.418 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.873000 | 0.18 sec/iter\n",
      "Epoch: 490 | Batch: 010 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.829352 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 491 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.029 | Tree loss: 0.494 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 001 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.831000 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 002 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.851500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 003 / 011 | Total loss: 0.466 | Reg loss: 0.029 | Tree loss: 0.466 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 004 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 005 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.862500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 008 / 011 | Total loss: 0.424 | Reg loss: 0.029 | Tree loss: 0.424 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 009 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.871500 | 0.18 sec/iter\n",
      "Epoch: 491 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.883959 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 492 | Batch: 000 / 011 | Total loss: 0.505 | Reg loss: 0.029 | Tree loss: 0.505 | Accuracy: 0.834000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.029 | Tree loss: 0.485 | Accuracy: 0.830000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.029 | Tree loss: 0.484 | Accuracy: 0.841000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 004 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.859500 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.868000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.873500 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 009 / 011 | Total loss: 0.449 | Reg loss: 0.029 | Tree loss: 0.449 | Accuracy: 0.860000 | 0.18 sec/iter\n",
      "Epoch: 492 | Batch: 010 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.863481 | 0.18 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 493 | Batch: 000 / 011 | Total loss: 0.493 | Reg loss: 0.029 | Tree loss: 0.493 | Accuracy: 0.834500 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 001 / 011 | Total loss: 0.487 | Reg loss: 0.029 | Tree loss: 0.487 | Accuracy: 0.832500 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 002 / 011 | Total loss: 0.463 | Reg loss: 0.029 | Tree loss: 0.463 | Accuracy: 0.850500 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.029 | Tree loss: 0.471 | Accuracy: 0.850000 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 004 / 011 | Total loss: 0.430 | Reg loss: 0.029 | Tree loss: 0.430 | Accuracy: 0.871000 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.847500 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.855500 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 007 / 011 | Total loss: 0.432 | Reg loss: 0.029 | Tree loss: 0.432 | Accuracy: 0.858500 | 0.18 sec/iter\n",
      "Epoch: 493 | Batch: 008 / 011 | Total loss: 0.429 | Reg loss: 0.029 | Tree loss: 0.429 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 493 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.863500 | 0.179 sec/iter\n",
      "Epoch: 493 | Batch: 010 / 011 | Total loss: 0.431 | Reg loss: 0.029 | Tree loss: 0.431 | Accuracy: 0.856655 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 494 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.029 | Tree loss: 0.517 | Accuracy: 0.817500 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.835500 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 002 / 011 | Total loss: 0.457 | Reg loss: 0.029 | Tree loss: 0.457 | Accuracy: 0.852000 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 003 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.844000 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.864000 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 005 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.029 | Tree loss: 0.458 | Accuracy: 0.854500 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 007 / 011 | Total loss: 0.434 | Reg loss: 0.029 | Tree loss: 0.434 | Accuracy: 0.873500 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 008 / 011 | Total loss: 0.422 | Reg loss: 0.029 | Tree loss: 0.422 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 494 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.029 | Tree loss: 0.423 | Accuracy: 0.867500 | 0.179 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 494 | Batch: 010 / 011 | Total loss: 0.486 | Reg loss: 0.029 | Tree loss: 0.486 | Accuracy: 0.825939 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 495 | Batch: 000 / 011 | Total loss: 0.495 | Reg loss: 0.029 | Tree loss: 0.495 | Accuracy: 0.848500 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 001 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.822000 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.029 | Tree loss: 0.490 | Accuracy: 0.830000 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.846000 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.029 | Tree loss: 0.461 | Accuracy: 0.846500 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 005 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.869500 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 007 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.866000 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 008 / 011 | Total loss: 0.436 | Reg loss: 0.029 | Tree loss: 0.436 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 009 / 011 | Total loss: 0.433 | Reg loss: 0.029 | Tree loss: 0.433 | Accuracy: 0.860500 | 0.179 sec/iter\n",
      "Epoch: 495 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.866894 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 496 | Batch: 000 / 011 | Total loss: 0.508 | Reg loss: 0.029 | Tree loss: 0.508 | Accuracy: 0.829000 | 0.18 sec/iter\n",
      "Epoch: 496 | Batch: 001 / 011 | Total loss: 0.489 | Reg loss: 0.029 | Tree loss: 0.489 | Accuracy: 0.839500 | 0.18 sec/iter\n",
      "Epoch: 496 | Batch: 002 / 011 | Total loss: 0.474 | Reg loss: 0.029 | Tree loss: 0.474 | Accuracy: 0.836000 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 003 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.854000 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.029 | Tree loss: 0.440 | Accuracy: 0.866500 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 005 / 011 | Total loss: 0.453 | Reg loss: 0.029 | Tree loss: 0.453 | Accuracy: 0.856000 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 006 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.877500 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.029 | Tree loss: 0.448 | Accuracy: 0.858500 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 008 / 011 | Total loss: 0.414 | Reg loss: 0.029 | Tree loss: 0.414 | Accuracy: 0.878500 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 009 / 011 | Total loss: 0.437 | Reg loss: 0.029 | Tree loss: 0.437 | Accuracy: 0.862000 | 0.179 sec/iter\n",
      "Epoch: 496 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.863481 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 497 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.029 | Tree loss: 0.503 | Accuracy: 0.825500 | 0.18 sec/iter\n",
      "Epoch: 497 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.029 | Tree loss: 0.491 | Accuracy: 0.836500 | 0.18 sec/iter\n",
      "Epoch: 497 | Batch: 002 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.840500 | 0.18 sec/iter\n",
      "Epoch: 497 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.029 | Tree loss: 0.456 | Accuracy: 0.856000 | 0.18 sec/iter\n",
      "Epoch: 497 | Batch: 004 / 011 | Total loss: 0.472 | Reg loss: 0.029 | Tree loss: 0.472 | Accuracy: 0.841500 | 0.18 sec/iter\n",
      "Epoch: 497 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.029 | Tree loss: 0.438 | Accuracy: 0.859000 | 0.179 sec/iter\n",
      "Epoch: 497 | Batch: 006 / 011 | Total loss: 0.419 | Reg loss: 0.029 | Tree loss: 0.419 | Accuracy: 0.877500 | 0.179 sec/iter\n",
      "Epoch: 497 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.029 | Tree loss: 0.442 | Accuracy: 0.860000 | 0.179 sec/iter\n",
      "Epoch: 497 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.029 | Tree loss: 0.421 | Accuracy: 0.862500 | 0.179 sec/iter\n",
      "Epoch: 497 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.029 | Tree loss: 0.439 | Accuracy: 0.865000 | 0.179 sec/iter\n",
      "Epoch: 497 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.877133 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 498 | Batch: 000 / 011 | Total loss: 0.507 | Reg loss: 0.029 | Tree loss: 0.507 | Accuracy: 0.826500 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.029 | Tree loss: 0.504 | Accuracy: 0.818000 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 002 / 011 | Total loss: 0.473 | Reg loss: 0.029 | Tree loss: 0.473 | Accuracy: 0.839000 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 003 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 004 / 011 | Total loss: 0.483 | Reg loss: 0.029 | Tree loss: 0.483 | Accuracy: 0.828500 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 005 / 011 | Total loss: 0.443 | Reg loss: 0.029 | Tree loss: 0.443 | Accuracy: 0.861500 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.864000 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 007 / 011 | Total loss: 0.425 | Reg loss: 0.029 | Tree loss: 0.425 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 498 | Batch: 008 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.870500 | 0.179 sec/iter\n",
      "Epoch: 498 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.029 | Tree loss: 0.427 | Accuracy: 0.864500 | 0.179 sec/iter\n",
      "Epoch: 498 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.029 | Tree loss: 0.369 | Accuracy: 0.904437 | 0.179 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "Epoch: 499 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.029 | Tree loss: 0.499 | Accuracy: 0.832000 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 001 / 011 | Total loss: 0.492 | Reg loss: 0.029 | Tree loss: 0.492 | Accuracy: 0.820000 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 002 / 011 | Total loss: 0.469 | Reg loss: 0.029 | Tree loss: 0.469 | Accuracy: 0.846000 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.029 | Tree loss: 0.475 | Accuracy: 0.844500 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 004 / 011 | Total loss: 0.435 | Reg loss: 0.029 | Tree loss: 0.435 | Accuracy: 0.858000 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 005 / 011 | Total loss: 0.426 | Reg loss: 0.029 | Tree loss: 0.426 | Accuracy: 0.874500 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 006 / 011 | Total loss: 0.441 | Reg loss: 0.029 | Tree loss: 0.441 | Accuracy: 0.867500 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.029 | Tree loss: 0.447 | Accuracy: 0.866000 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 008 / 011 | Total loss: 0.455 | Reg loss: 0.029 | Tree loss: 0.455 | Accuracy: 0.859000 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 009 / 011 | Total loss: 0.413 | Reg loss: 0.029 | Tree loss: 0.413 | Accuracy: 0.877500 | 0.18 sec/iter\n",
      "Epoch: 499 | Batch: 010 / 011 | Total loss: 0.464 | Reg loss: 0.029 | Tree loss: 0.464 | Accuracy: 0.846416 | 0.18 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 4.666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAJ8CAYAAADDFZ2EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAxOAAAMTgF/d4wjAAC2h0lEQVR4nOzdd1QUd98F8LuFKs1CxILdRFm6osSGBXsv2BtgT0yMxhJj1BhL7LEXrFFULFFjixUVBRUFBBZLIlERu1JU+u68fzzRN0ZRyi6zy97POTnngR1mL8/Xgb38ZmckgiAIICIiIiIiItITUrEDEBEREREREeUHiywRERERERHpFRZZIiIiIiIi0issskRERERERKRXWGSJiIiIiIhIr7DIEhERERERkV5hkSUiIiIiIiK9wiJLREQat2nTJlSsWLFQ+xgxYgSGDBlSpM9JRERE+oFFloioiG3cuBESiQSTJk0SO4pOW716NdatW6fRfVapUqXQ++zatSskEglOnDjxwe0EQcCCBQvw6aefokSJEihfvjzmzp371jbXrl1Dp06dYG1tDWtra7i7u+Phw4fchw7vIyQkBBYWFm/9Z2RkBGtraxARURESiIioSNWtW1coXbq0YGtrK2RkZGjteXJycgSVSqW1/X/Ixo0bhQoVKujcc1auXFkICAgo8HNs3rxZaNWqlQBAOH78+Ae3/fLLLwU3NzchMjJSUKlUQlJSkhAdHf3m8b/++ksoWbKksGDBAiElJUVQqVTC1atXhRcvXnAfOr6P/3J3dxe++OKLXB8nIiLNY5ElIipCly5dEgAIR44cEYyNjYUtW7YIgiAIycnJgpmZmXD27Nm3th89erTQsWPHNx9v3rxZcHZ2FqysrAQHBwdh+/btbx4LDg4WAAjbt28XatasKRgbGwsPHjwQdu7cKbi7uws2NjZC6dKlhY4dOwrx8fFvvk6tVgtz5swR7O3tBWtra8Hf31/w8fERBg0a9GabpKQkYcSIEUKlSpWEUqVKCW3bthVu3bqV6/f5ulSuXr1aqFy5smBlZSX06NFDSElJyfM+Bw0aJPTr1+/Nxzdv3hSaNm0qWFpaCrVq1RLWrl0rABD+/vvvPD1nmzZtBIlEIpiYmAglSpQQHBwc8jKyNxISEgR7e3vhzp07Hy2yN2/eFCQSyVsF6b/69+8vdOvWjfvQs338V1hYmABAUCqVef4aIiIqPJ5aTERUhFauXAlXV1e0adMGXbt2xcqVKwEA1tbW6NGjB9avX/9m24yMDGzduvXN+0Q3bdqEKVOmYP369UhKSsKaNWswbNgwnDt37q3nCAoKQlhYGFJTU2FrawtLS0ts2LABT58+xfXr1yEIAvr27ftm+y1btmD+/PnYtWsXnj59is8//xx79+5987ggCOjatStSU1MRGRmJ+/fvw8nJCR06dEB2dnau3+vDhw9x/fp1XLt2DdevX0dUVBQWLlxYoH3m5OSgQ4cOqFmzJh4+fIgTJ05gw4YN+XrOI0eOoFKlSli+fDlevnwJpVIJALh79y5sbGze+f/x3wRBgJ+fH6ZMmYJKlSrlut1rJ0+ehIWFBQ4dOoRKlSqhXLly6N69O27fvv1mm+PHj8PW1hYtWrRAqVKl4OjoiFWrVnEfOr6P/1q5ciWaNm0KBweHXLchIiItELdHExEZjufPnwtmZmbCypUrBUEQhJMnTwoAhKioKEEQBOHMmTOCubn5mxXErVu3CuXKlRNycnIEQRAEJycnYfXq1W/tc8iQIYK/v78gCP+/Inv9+vUP5oiIiBAACKmpqYIgCEKLFi2E8ePHv7VNnTp13qzIXrlyRTAyMnrr1MqcnBzB1NRUCAkJee9zbNy4UTAxMRGysrLefO7bb78V2rRpk+d9/ntFNiQkRJBKpW8yC4IgHDhw4J0V2Q89pyAU/NTiFStWCN7e3m8+xkdWZH/66ScBgNCtWzfh2bNnQnJystCvXz/B0dHxzTxlMplgZmYmHDt2TMjOzhbOnDkjWFhYCDt27OA+dHgf//b06VPB1NRU2LlzZ/7+QRERUaFxRZaIqIi8vshTv379AADNmjVDjRo13qzKNmnSBBUrVsT27dsBAOvWrcPgwYMhk8kAAH/++SfGjRsHGxubN/9t374d9+/ff+t5qlat+tbHZ86cQYsWLVCuXDlYWVnBy8sLAPD48WMAQGJiIipXrvzW11SpUuXN//7zzz+Rk5ODihUrvnne0qVLAwASEhJy/X7LlCkDIyOjNx+XKFECL168KNA+ExMTUapUKVhaWr43Y16es6Bu3bqFn376KV8XibKysgIAzJw5E6VKlYK1tTXmz5+P2NhY3Lx58802HTt2RMuWLSGXy9GkSRP07dsXv/32G/ehw/v4t/Xr16NkyZLo2rVrnv9tEBGRZrDIEhEVAUEQsHr1amRlZeHTTz+FnZ0dypUrh3v37iEwMBCpqakAAH9/f6xbtw5//fUXzp49C39//zf7sLOzw8qVK5GcnPzmv5cvX+Lw4cNvPZdU+v8/2rOystChQwe0adMGN2/eRGpqKs6cOfMmEwBUqFABd+7ceWsf//7Yzs4OxsbGePLkyVvPnZ6ejj59+hTo/4/87rNChQp4/vz5W6X0v5nz4t//3+RVSEgInj17hjp16qBMmTIoU6YMAKB79+4YNmzYe7/G3d0dACCRSHLdr7u7+0cf5z50bx+vqdVqrFmzBkOHDoVcLv/o9kREpGFiLwkTERmCo0ePCgCEU6dOCQ8ePHjz382bN4USJUoIS5cuFQRBEB4+fCgYGRkJHTp0EJo1a/bWPn755RehRo0awqVLlwSVSiVkZGQIly5dEi5fviwIwv+fWpydnf3ma168eCHIZLI3p9MmJiYK7dq1EwAIf/75pyAIgrBp0yahdOnSwqVLl4Ts7Gxhw4YNglwuf3NqcU5OjlCnTh3B399fePTokSAI/ztNevfu3cKrV6/e+/2+7wrC06ZNExo2bJjnff771OLs7GyhZs2awogRI4RXr14JiYmJQoMGDd57safcnlMQBOHzzz8Xvv322w/O6r9evXolJCQkvPUf/rmo1rNnz977NWq1WnB3dxd8fHyE5ORk4cWLF8LAgQMFFxeXN6ew7tu3TzAzMxNOnTolqFQq4fz584KVlZWwe/du7kOH9/HaoUOHBLlcLty7dy9f/56IiEgzWGSJiIpAly5d3nqP5b99/fXXQu3atd983LVrVwGAEBgY+M62W7duFdzd3QVra2uhdOnSgpeXl3DmzBlBEN5fZAXhfwWvcuXKQokSJQRnZ2dh48aNbxVZtVotzJw5U6hYsaJgbW0t+Pn5CV26dBGGDx/+Zh/Pnz8XRo8eLVSpUkWwsLAQ7O3thX79+glpaWnv/Z7yUio/ts//XrX4+vXrgpeXl2BhYSHUqlVLWL58uQBAePDgQZ6f88iRI0LNmjUFa2trwcnJSRAEQbhz545QokSJd64Y/SH4z3tkz549K5QoUUK4c+fOm88lJiYK3bp1EywtLQVbW1uhR48ebz0uCIKwfv16oXr16oK5ublQu3btd96/y33o5j4EQRA6dOiQr6sbExGRZkkE4Z9zy4iIiP7h6uqKXr164bvvvhM7Sq727duH3r17Iz09PU+nghIREVHxwffIEhERgoKCkJ6ejoyMDCxevBhxcXHw8fERO9ZbwsLCcPPmTQiCgBs3bmDq1Kno27cvSywREZEBYpElIiIEBATAzs4Otra22Lp1K/bv348aNWqIHestDx48QKtWrVCiRAm0aNECnp6eWLx4sdixiIiISAQ8tZiIiIiIiIj0CldkiYiIiIiISK+wyBIREREREZFeYZElIiIiIiIivcIiS0RERERERHqFRZaIiIiIiIj0CossERERERER6RUWWSIiIiIiItIrLLJERERERESkV1hkiYiIiIiISK+wyBIREREREZFeYZElIiIiIiIivcIiS0RERERERHqFRZaIiIiIiIj0CossERERERER6RUWWSIiIiIiItIrLLJERERERESkV1hkiYiIiIiISK+wyBIREREREZFeYZElIiIiIiIivcIiS0RERERERHqFRZaIiIiIiIj0CossERERERER6RUWWSIiIiIiItIrLLJERERERESkV1hkiYiIiIiISK+wyBIREREREZFeYZElIiIiIiIivcIiS0RERERERHqFRZaIiIiIiIj0CossERERERER6RUWWSIiIiIiItIrLLJERERERESkV1hkiYiIiIiISK+wyBIREREREZFeYZElIiIiIiIivcIiS0RERERERHqFRZaIiIiIiIj0CossERERERER6RUWWSIiIiIiItIrLLJERERERESkV1hkiYiIiIiISK+wyBIREREREZFeYZElIiIiIiIivcIiS0RERERERHpFLnYAIqLcxD95ib2RiUhISsOLjBxYmsphX9IcXd0qoJqthdjxiIiIiEgkEkEQBLFDEBG9plILOHHtEQJC4hF5NxlSKZCt+v8fU0YyCdRqwK2SDYY2rgbv2mUhk0pETExERERERY1Floh0RmpGNvw3hSM6MQWZOeqPbm8il8K5ojU2DPKApalRESQkIiIiIl3AIktEOiE1IxtdV55HwvM0ZKny/mPJWCaBfSlz7B3VEFYss0REREQGgRd7IiLRqdQC/DeF57vEAkCWSkDC8zT4bw6HSs2/yxEREREZAhZZIhLdiWuPEJ2Yku8S+1qWSkD0vRScvP5Iw8mIiIiISBfxqsVEJLqAkPj3vic2OSQQKaFBkMiN33zOrEY92Hae8M62WTlqBITEo5WDnVazEhEREZH4WGSJSFTxT14i8m5yro+bVKgFu/7zProfAUDEnWT8/fQVqpYpobmARERERKRzeGoxEYlqb2QipBr6SSSVAnsj72lmZ0RERESks7giS0SiSkhKe+s+sf+V9egWEpb0hcTIBCYVHWDTZACMbN5/+nC2SkBCUrq2ohIRERGRjmCRJSJRvcjIyfUx81oNYeHcEjIrW6hePkNS8EY83jEF5fyWQWps9t6vSU3P1lZUIiIiItIRPLWYiERlaZr739OMbatAbv0JJBIJ5JZlUKbdGOS8eIbMxGu5fo2VGe8lS0RERFTcscgSkajsS5rDSCbJ28YSQCKRAML7T0U2kklgX/L9K7VEREREVHywyBKRqLq6VYD63TvvAABeXQuBKi0FAKB6lYRnh5dCam4Dkwq137u9Si2gq1tFbUUlIiIiIh3B98gSkaiq2VrArZINLt9JeuexV8pgPD+2CkJ2JqSmJWBi74iyfWZCamL+zrYSAHUql+Std4iIiIgMAIssEYluaONqiEmMRGbO20uzn/SYmud9GMulGNq4mqajEREREZEO4qnFRCQ679pl4VzBGsZ5fa/sfxjLpHCpaI0WtcpqOBkRERER6SIWWSISnUwqwfrBHrA1l8Eonz+VjGUS2Jcyw/pBHpBJC1aEiYiIiEi/sMgSkU5IefIQN5YNgX0JNUzkUnyskkoASNQ5MEt/jH2jGsLSlLfdISIiIjIULLJEJLrs7Gz06tULXdq3xvFJHbCsjxvqVC4JmUTyzq15jGQSyCQS1K1SEnM61MT9LROwe/tWkZITERERkRgkgpDLDRmJiIrIt99+i+PHj+PChQswM/v/+8DGP3mJfVGJSEhKR2p6NqzMjGBf0gxd3Sq+uTrxsWPH0K1bN4SGhsLZ2Vmsb4GIiIiIihCLLBGJav/+/RgwYAAuX76MTz/9tED7mDZtGnbs2IHLly/D0tJSwwmJiIiISNewyBKRaP7++2+4u7tj9erV6NWrV4H3o1Kp0KpVK3zyySfYtm0bJBJe9ImIiIioOON7ZIlIFJmZmejZsyf69etXqBILADKZDNu2bcPp06exZs0aDSUkIiIiIl3FFVkiEsXo0aMRFhaG8+fPw8TERCP7PHPmDNq1a4eQkBC4u7trZJ9EREREpHu4IktERW7nzp3YunUrdu3apbESCwBeXl6YMmUKfHx8kJycrLH9EhEREZFu4YosERWpmzdvom7dutiyZQs6d+6s8f2r1Wp06NABpqam2LNnD98vS0RERFQMcUWWiIpMeno6fHx8MGzYMK2UWACQSqXYsmULLl++jCVLlmjlOYiIiIhIXFyRJaIiM3ToUCiVSpw5cwZGRkZafa6wsDB4e3vj5MmT8PT01OpzEREREVHR4oosERWJX3/9FXv37kVQUJDWSywAfP7555g5cyZ69uyJZ8+eaf35iIiIiKjocEWWiLROqVSifv362LVrF9q2bVtkzysIArp164asrCwcOHAAUin/dkdERERUHPBVHRFp1cuXL+Hj44Ovv/66SEssAEgkEmzYsAHXrl3DvHnzivS5iYiIiEh7uCJLRFojCAIGDBiAe/fu4cSJE5DL5aLkuHz5Mry8vHD48GF4eXmJkoGIiIiINIcrskSkNevWrcPx48exfft20UosANStWxfz589Hnz598OjRI9FyEBEREZFmcEWWiLQiKioKDRs2xIEDB9C8eXOx40AQBPTp0wfPnj3DH3/8AZlMJnYkIiIiIiogrsgSkcalpqbCx8cHkyZN0okSC/zv/bIBAQG4e/cuZs6cKXYcIiIiIioErsgSkUYJgoBevXohJSUFR44c0bkrBUdHR6NBgwbYt28fvL29xY5DRERERAWgW68wiUjvrVixAqGhodi6davOlVgAcHZ2xtKlS9G3b1/cv39f7DhEREREVABckSUijQkPD0fTpk1x9OhRNGrUSOw4uRIEAb6+voiPj8epU6dEvRAVEREREeWf7i2XEJFeSkpKgo+PD6ZPn67TJRb43/tlV6xYgefPn+OHH34QOw4RERER5RNXZImo0ARBQOfOnQEA+/bt08lTit/n2rVrqFevHnbs2IH27duLHYeIiIiI8kg/Xm0SkU5buHAhoqOjsWnTJr0psQBQu3ZtrFmzBgMHDsSdO3fEjkNEREREecQVWSIqlPPnz6NVq1YIDg5GvXr1xI5TICNGjEBUVBTOnj0LY2NjseMQERER0Ufoz9IJEemcJ0+eoFevXpgzZ47ellgA+OWXX5CZmYmJEyeKHYWIiIiI8oArskRUIGq1Gm3btoWlpSV27doFiUQidqRC+euvv1CnTh1s3LgR3bp1EzsOEREREX0A7zlBRAUye/Zs3Lp1C1euXNH7EgsANWrUwPr16+Hn5wcXFxdUr15d7EhERERElAuuyBJRvgUHB6NDhw44d+4c3NzcxI6jUV9//TVCQkIQGhoKU1NTseMQERER0XvwPbJElC8PHz5Enz59sHjx4mJXYgFg/vz5MDIywtixY8WOQkRERES54IosEeWZSqWCt7c3KlSogC1bthSLU4rf5/bt23B3d8eKFSvQp08fseMQERER0X9wRZaI8mz69Ol4+PAhVq9eXWxLLABUqVIFv/76K4YPH47r16+LHYeIiIiI/oMrskSUJ3/88Qd69OiBixcvQqFQiB2nSEycOBGHDx/GxYsXYW5uLnYcIiIiIvoHiywRfdS9e/fg6uqKhQsXYtCgQWLHKTLZ2dlo3rw5atSogY0bN4odh4iIiIj+wSJLRB+UnZ2Npk2bolatWli/fr3YcYpcYmIiXF1dMW/ePPj6+oodh4iIiIjAIktEHzF+/HgcO3YMFy5cgJmZmdhxRHHs2DF069YNYWFhcHJyEjsOERERkcFjkSWiXO3fvx8DBgzA5cuX8emnn4odR1TTpk1DUFAQwsPDYWlpKXYcIiIiIoPGIktE7/X333/D3d0dq1evRq9evcSOIzqVSoVWrVrhk08+wbZt24r1VZuJiIiIdB1vv0NE78jMzETPnj3Rr18/lth/yGQybNu2DadPn8aaNWvEjkNERERk0LgiS0TvGD16NMLCwnD+/HmYmJiIHUennDlzBu3atUNISAjc3d3FjkNERERkkLgiS0Rv2blzJ7Zu3Ypdu3axxL6Hl5cXpkyZAh8fHyQnJ4sdh4iIiMggcUWWiN64efMm6tatiy1btqBz585ix9FZarUaHTp0gKmpKfbs2cP3yxIREREVMa7IEhEAID09HT4+Phg2bBhL7EdIpVJs2bIFly9fxpIlS8SOQ0RERGRwuCJLRACAoUOHQqlU4syZMzAyMhI7jl4ICwuDt7c3Tp48CU9PT7HjEBERERkMrsgSEX799Vfs3bsXQUFBLLH58Pnnn2PmzJno2bMnnj17JnYcIiIiIoPBFVkiA6dUKuHp6Yldu3ahTZs2YsfRO4IgoFu3bsjKysKBAwcglfLvg0RERETaxldcRAbs5cuX8PHxwddff80SW0ASiQQbN27EtWvXMG/ePLHjEBERERkErsgSGShBEDBo0CAkJCTg+PHjkMvlYkfSa1euXEGTJk1w5MgRNGnSROw4RERERMUaV2SJDNT69etx7NgxbNu2jSVWA+rUqYMFCxagd+/eePz4sdhxiIiIiIo1rsgSGaCoqCg0atQIBw4cQLNmzcSOU2wIgoC+ffvi6dOn+OOPPyCTycSORERERFQscUWWyMCkpqbCx8cHEydOZInVMIlEgrVr1+Lu3buYOXOm2HGIiIiIii2uyBIZEEEQ0KtXL6SkpODIkSO8wq6WREdHo0GDBti3bx+8vb3FjkNERERU7PBVLJEBWbFiBUJDQ7F161aWWC1ydnbG0qVL0bdvX9y/f1/sOERERETFDldkiQxEeHg4mjZtiqNHj6JRo0Zixyn2BEGAr68v4uPjcerUKV5Qi4iIiEiDuCRDZACSkpLg4+OD6dOns8QWEYlEghUrVuD58+f44YcfxI5DREREVKxwRZaomBMEAZ07dwYA7Nu3j6cUF7Fr166hXr162LFjB9q3by92HCIiIqJiga9oiYq5hQsXIjo6Gps2bWKJFUHt2rWxZs0aDBw4EHfu3BE7DhEREVGxwBVZomLs/PnzaNWqFYKDg1GvXj2x4xi0ESNGICoqCmfPnoWxsbHYcYiIiIj0GpdniIqpJ0+eoFevXvj5559ZYnXAL7/8gszMTEycOFHsKERERER6jyuyRMWQWq1G27ZtYWVlhZ07d0IikYgdiQD89ddfqFOnDjZu3Ihu3bqJHYeIiIhIb/F+EETF0OzZsxEfH4/Lly+zxOqQGjVqYMOGDfDz84OLiwuqV68udiQiIiIivcRTi4mKgefPn2PXrl0QBAGnTp3CnDlzsGvXLlhbW4sdjf6je/fuGDx4MHx8fJCRkYFHjx5h7969YsciIiIi0is8tZioGFi9ejVGjhyJFi1aIDo6GrNmzcLQoUPFjkW5yMrKQuPGjWFnZ4eQkBCkpqYiLS2NF4EiIiIiyiOuyBIVA+Hh4QCAU6dO4eXLl6hTp47IiehD5HI5GjdujN9//x1JSUmQSqW4du2a2LGIiIiI9AaLLFExcPHiRQCAIAhIT0+Hp6cnYmNjRU5FuRk3bhwWLlz45mO5XI6oqCjxAhERERHpGRZZIj2nUqlw48YNAICJiQnMzMwwYcIE1KhRQ+RklBtfX180bdoUcrkcEokE6enpb/4YQUREREQfx/fIEum4+CcvsTcyEQlJaXiRkQNLUznsS5qjq1sFVLO1wOXLl+Hh4QFjY2NMmjQJ33zzDWxsbMSOTXkQHh6OSZMm4dSpUyhbtiwePnz45rGPzZ2IiIjIkLHIEukglVrAiWuPEBASj8i7yZBKgWzV/x+qRjIJ1GrArZINeruUwbFNCzF/3jxepVhPHT9+HKGhoZjyw9Q8z31o42rwrl0WMilvr0RERESGh0WWSMekZmTDf1M4ohNTkJmj/uj2JnIpnCtaY8MgD1iaGhVBQtIGzp2IiIgo71hkiXRIakY2uq48j4TnachS5f3QNJZJYF/KHHtHNYQVS43e4dyJiIiI8ocXeyLSESq1AP9N4fkuMwCQpRKQ8DwN/pvDoVLzb1P6hHMnIiIiyj+52AGI6H9OXHuE6MSUd8pMckggUkKDIJEbv/mcWY16sO084a3tslQCou+l4OT1R2jlYFckmanwOHciIiKi/GORJdIRASHxub430qRCLdj1n/fRfWTlqBEQEs9Co0c4dyIiIqL846nFRDog/slLRN5NLvR+BAARd5Lx99NXhd4XaR/nTkRERFQwLLJEOmBvZCKkHzgasx7dQsKSvri30hdPfp+P7OSHuW4rlQJ7I+9pISVpGudOREREVDA8tZhIByQkpb11v9B/M6/VEBbOLSGzsoXq5TMkBW/E4x1TUM5vGaTGZu9sn60SkJCUru3IpAGcOxEREVHBcEWWSAe8yMjJ9TFj2yqQW38CiUQCuWUZlGk3BjkvniEz8VquX5Oanq2NmKRhnDsRERFRwbDIEukAS9N8nBwhASQSCfCBW0BbmfGeovqAcyciIiIqGBZZIh1gX9IcRjLJex97dS0EqrQUAIDqVRKeHV4KqbkNTCrUfu/2RjIJ7Eu+e+op6R7OnYiIiKhg+B5ZIh3Q1a0CVp6+9d7HXimD8fzYKgjZmZCaloCJvSPK9pkJqYn5e7dXqQV0dauozbikIZw7ERERUcGwyBLpgNLGKpRGKh7D8p3HPukxNc/7kQCoU7kkqpYpocF0pC3VbC3gVskGl+8kvfNYfuYOCKhTuRTnTkRERAaDpxYTiezIkSNwdHSE7M/TMJG//zTTvDKWSzG0cTUNJaOiMLRxNZjIC/ejWMjJxvPQ3Xj06JGGUhERERHpNhZZIpEkJSVh8ODB6N27N6ZNm4aQHSvhXMEGxrm8Z/JjjGVSuFS0RotaZTWclLTJu3ZZOFewLtTc3SqXQqn0RDg4OGDbtm0QPnBBKCIiIqLigEWWSAQHDhyAQqHA48ePERsbiyFDhkAuk2L9YA/YlzLPd6kxlklhX8oM6wd5QCYt3KouFS2ZVFLouW8Z0gC7dgZh7dq1+Oabb9ClSxc8ePBAS4mJiIiIxMciS1SEnj17hn79+mHgwIGYM2cODh06BHt7+zePW5kaYe+ohnCxt4GJXIqP1RoJABO5FK721tg3qiEsTXn7FX2kqbl3794dcXFxsLS0hIODAzZv3szVWSIiIiqWJAJf5RAViT179mDUqFHw9PTEqlWrUL58+Vy3VakFnLz+CGvPxiPybjKkUiBb9f+HqpFMArUacK9sg6GNq6FFrbJciS0GNDn333//HSNGjICrqyvWrl2LihV5RWMiIiIqPlhkibTs8ePH+PLLL3Hy5EksW7YMffr0gUSS99IZ/+Ql9kUlYm3gHlSr5YjPqlWCfUkzdHWryKvUFmOv575x5+8oV7k6FJ9Wy/fck5KSMHbsWPz2229YsGABhgwZkq9/e0RERES6ikWWSEsEQUBQUBBGjx4NLy8vrFixAmXLFvxCTPXr18eECRPQvXt3DaYkXdeyZUv07dsXvr6+Bd7HkSNHMGzYMNSqVQsBAQGoUqWK5gISERERiYDvkSXSgocPH6Jbt2746quvsGrVKuzevbtQJZaoMNq2bYvY2FhUrVoVTk5OWLlyJdRqtdixiIiIiAqMRZZIgwRBwJYtW+Dg4AAzMzPExcWhR48eYscigrW1NdauXYu9e/di3rx5aNGiBW7duiV2LCIiIqICYZEl0pDExER07NgR48ePx4YNG7Bt2zaUKVNG7FhEb/H29kZMTAwcHBzg4uKCJUuWcHWWiIiI9A6LLFEhCYKA9evXQ6FQoFSpUoiLi0OXLl3EjkWUK0tLS6xYsQIHDx7E0qVL0aRJE9y8eVPsWERERER5xiJLVAh3795FmzZtMHXqVAQGBuLXX39FqVKlxI5FlCdNmzZFdHQ06tatCzc3NyxYsAAqlUrsWEREREQfxSJLVACCIGDNmjVwdHSEvb09lEol2rdvL3YsonwrUaIEfvnlFxw7dgwBAQFo2LAh4uLixI5FRERE9EEsskT59Pfff8Pb2xuzZ8/G7t27sW7dOtjY2Igdi6hQGjZsiKioKDRu3Bh169bFnDlzkJOTI3YsIiIiovdikSXKI7VajeXLl8PZ2RmffvopYmJi0KpVK7FjEWmMmZkZ5s+fj+DgYGzduhWenp6IiYkROxYRERHRO1hkifLgzz//RNOmTbFo0SLs378fq1atgpWVldixiLSifv36iIiIQOvWrVG/fn3MmDED2dnZYsciIiIieoNFlugDVCoVFi1aBDc3N7i6uiI6OhrNmzcXOxaR1pmYmGDWrFkICQnB7t274eHhgcjISLFjEREREQFgkSXK1fXr19G4cWOsWrUKR44cwdKlS2FhYSF2LKIiVadOHVy+fBldunRBw4YNMWXKFGRmZoodi4iIiAwciyzRf+Tk5GDu3LmoU6cOPv/8c1y9ehWNGzcWOxaRaIyNjTF9+nSEhYXh8OHDqFOnDsLDw8WORURERAaMRZboX2JjY9GgQQNs2rQJJ06cwMKFC2Fubi52LCKd4OLigosXL6JPnz7w8vLCxIkTkZGRIXYsIiIiMkAsskQAsrOzMXPmTNSrVw/NmzdHZGQkPv/8c7FjEekcIyMjfP/99wgPD0dwcDBcXV0RGhoqdiwiIiIyMCyyZPCioqJQr1497NixA2fOnMHPP/8MU1NTsWMR6TSFQoHQ0FD4+fmhZcuWGDt2LNLS0sSORURERAaCRZYMVlZWFqZNm4YGDRqgQ4cOuHLlCjw8PMSORaQ35HI5JkyYgCtXruDChQtwcXHB2bNnxY5FREREBkAudgAiMVy5cgW+vr6QSqU4f/483NzcxI5EpLdq1aqFkJAQLF26FO3atYOvry/mzJnDq3wTERGR1nBFlgxKRkYGJk+ejMaNG8PHxwfh4eEssUQaIJPJ8M033yAqKgrR0dFwdnbGqVOnxI5FRERExRRXZMlgXLx4Eb6+vjA3N8fFixfh5OQkdiSiYqdGjRoIDg7GypUr0blzZ/Tr1w/z5s2DlZWV2NGIiIioGOGKLBV76enp+Pbbb9G8eXMMHDgQFy5cYIkl0iKpVIovv/wS0dHR+PPPP+Ho6IijR4+KHYuIiIiKERZZKtbOnTsHFxcXnDt3DpcvX8akSZMgl/NEBKKiULVqVZw4cQJTpkyBj48P/P39kZycLHYsIiIiKgZYZKlYevXqFb7++mu0bt0aw4cPx/nz51G7dm2xYxEZHIlEgmHDhiE2Nhb37t2DQqHAwYMHxY5FREREeo5Floqd06dPw9nZGREREYiMjMS4ceMgk8nEjkVk0CpVqoQ//vgDP/30E/r3748BAwbg+fPnYsciIiIiPcUiS8XGixcvMGrUKHTo0AFff/01zpw5g08//VTsWET0D4lEAj8/PyiVSiQlJcHBwQF79+4VOxYRERHpIRZZKhaOHz8OJycnXLt2DVevXsVXX30FqZT/vIl0UYUKFXDgwAEsWLAA/v7+6N27N548eSJ2LCIiItIjfKVPei0lJQVDhw5F9+7dMXHiRJw8eRLVq1cXOxYRfYREIkH//v0RFxeHrKwsKBQK7Nq1S+xYREREpCdYZElvHTlyBI6Ojrhz5w5iYmIwcuRIrsIS6Rk7Ozvs2bMHy5Ytw6hRo9CjRw88evRI7FhERESk4/iqn/ROUlISBg8ejN69e2PatGk4evQoKleuLHYsIiogiUSCXr16IS4uDjKZDA4ODggMDIQgCGJHIyIiIh3FIkt65ffff4dCocCTJ0+gVCoxZMgQSCQSsWMRkQbY2toiKCgIAQEBGDt2LDp37oz79++LHYuIiIh0EIss6YVnz56hX79+GDRoEObMmYODBw+iYsWKYsciIi3o1q0b4uLiYGVlBYVCgU2bNnF1loiIiN7CIks6b8+ePXBwcMDLly+hVCoxaNAgrsISFXOlS5fG1q1bsXnzZkyePBnt27dHQkKC2LGIiIhIR7DIks56/PgxfHx8MGzYMCxevBj79u1D+fLlxY5FREWoU6dOUCqVKFu2LBwdHREQEMDVWSIiImKRJd0jCAK2b98OBwcHCIKAuLg49O3bl6uwRAaqZMmS2LhxI3bs2IEZM2agVatWuH37ttixiIiISEQssqRTHj58iG7duuHrr7/G6tWrsXv3bpQtW1bsWESkA9q2bYvY2FhUrVoVTk5OWLlyJdRqtdixiIiISAQssqQTBEHAli1b4ODgADMzM8TFxaFHjx5ixyIiHWNtbY21a9di7969mDdvHlq0aIFbt26JHYuIiIiKGIssiS4xMREdO3bEhAkTsHHjRmzbtg1lypQROxYR6TBvb2/ExMRAoVDAxcUFS5Ys4eosERGRAWGRJdEIgoD169dDoVCgdOnSUCqV6Ny5s9ixiEhPWFpaYvny5Th06BCWLVuGJk2a4ObNm2LHIiIioiLAIkuiuHv3Ltq0aYNp06YhMDAQmzdvRqlSpcSORUR6yMvLC1evXoWHhwfc3NywYMECqFQqsWMRERGRFrHIUpFSq9VYvXo1HB0dYW9vD6VSifbt24sdi4j0XIkSJbB48WIcO3YMAQEBaNCgAeLi4sSORURERFrCIktFJj4+Ht7e3pgzZw52796NdevWwdraWuxYRFSMNGzYEFFRUfDy8kLdunUxe/Zs5OTkiB2LiIiINIxFlrROrVZj2bJlcHFxwWeffYaYmBi0atVK7FhEVEyZmZlh3rx5CA4ORmBgIOrXr4/o6GixYxEREZEGsciSVv35559o2rQpFi9ejP3792PVqlWwsrISOxYRGYD69esjIiICbdq0gaenJ2bMmIHs7GyxYxEREZEGsMiSVqhUKixatAhubm5wdXVFdHQ0mjdvLnYsIjIwJiYmmDVrFkJCQrB79254eHggMjJS7FhERERUSCyypHHXr19H48aNsWrVKhw5cgRLly6FhYWF2LGIyIDVqVMHly9fRpcuXdCwYUNMmTIFmZmZYsciIiKiAmKRJY3JycnB3LlzUadOHTRo0ABXr15F48aNxY5FRAQAMDY2xvTp0xEWFobDhw+jTp06CA8PFzsWERERFQCLLGlEbGwsGjRogE2bNuHkyZNYsGABzM3NxY5FRPQOFxcXXLx4EX369IGXlxcmTpyIjIwMsWMRERFRPrDIUqFkZ2dj5syZqFevHlq0aIHIyEh4enqKHYuI6IOMjIzw/fffIzw8HMHBwXB1dUVoaKjYsYiIiCiPWGSpwK5evYr69esjKCgIZ8+exZw5c2Bqaip2LCKiPFMoFAgNDYW/vz9atmyJsWPHIi0tTexYRERE9BEsspRvWVlZmDZtGj7//HN06NABly9fRt26dcWORURUIHK5HOPHj0dERAQuXrwIFxcXnD17VuxYRERE9AFysQOQfrly5Qp8fX0hlUoRGhoKV1dXsSMREWnEZ599hrNnz2LZsmVo164dfH19MWfOHF51nYiISAdxRZbyJCMjA5MnT0bjxo3h4+OD8PBwllgiKnZkMhnGjBmDqKgoREdHw9nZGadOnRI7FhEREf0HV2Tpoy5evAhfX1+Ym5vj4sWLcHJyEjsSEZFW1ahRA8HBwVi5ciU6d+6Mfv36Yd68ebCyshI7GhEREYErsvQB6enp+Pbbb9G8eXMMHDgQFy5cYIklIoMhlUrx5ZdfIjo6Gn/++SccHR1x9OhRsWMRERERWGQpF+fOnYOLiwvOnz+Py5cvY9KkSZDLuYBPRIanatWqOHHiBKZMmYKePXvC398fycnJYsciIiIyaCyy9JZXr15hzJgxaN26NYYPH45z586hdu3aYscyaOnp6UhOTkZOTg5evXqF5ORkCIIgdizSsoyMDCQnJyM7OxtpaWlITk6GWq0WO5bBkkgkGDZsGGJiYpCYmAiFQoFDhw6JHYuIiMhgSQS+IqZ/nD59Gv7+/ihfvjzWr1+PTz/9VOxIBMDOzg6PHj1663NLly7F6NGjRUpERaFmzZr466+/3vrcTz/9hClTpoiUiF4TBAGbNm3CN998g06dOuGXX35BqVKlxI5FRERkULgiS3jx4gW++OILdOzYEWPGjMGZM2dYYnVI165dYWxs/OZjmUyG9u3bi5iIikKPHj1gYmLy5mOZTIYuXbqIF4jekEgk8PX1hVKpRFJSEhQKBfbt2yd2LCIiIoPCFVkDd+LECQwZMgTVqlXDunXrUK1aNbEj0X8kJiaiSpUqyMnJgVwuR58+ffDrr7+KHYu07NmzZ6hYsSIyMjIglUrRoUMH7N+/X+xY9B+CICAwMBBfffUVWrdujWXLlqFMmTJixyIiIir2uCJroFJSUjB06FB069YNkyZNwokTJ1hidVSFChUwZMgQAIBarcb06dPFDURFonTp0hgzZgwkEgkAYNasWSInoveRSCTo378/4uLikJmZCQcHB+zatUvsWERERMUeV2QNgCAIb14MA8CRI0cwbNgw1K5dGwEBAahcubKI6SgvEhMTYW9vj8aNG+PMmTNix6Ei8uzZM3zyySdwdnZGZGSk2HHoIwRBwM6dO/Hll1/Cy8sLK1asQNmyZd96/N8/i4mIiKjguCJbzG3btg2ffvopXr58iaSkJAwePBi9e/fGtGnTcPToUZZYPVGhQgXMmjULAQEBYkehIlS6dGksXLgQGzduFDsK5YFEIkGvXr0QFxcHmUwGBwcHBAYGQhAE7N27F1WqVEFqaqrYMYmIiIoFrsjqkfgnL7E3MhEJSWl4kZEDS1M57Euao6tbBVSztXhn+xcvXqBy5cpITU1FixYtEBMTAzc3N6xZswYVK1YU4Tuggsjv3Kl44Nz132+//YaRI0fCzc0NoaGhSEtLw1dffYVFixbl+jWcOxERUd6wyOo4lVrAiWuPEBASj8i7yZBKgWzV/4/MSCaBWg24VbLB0MbV4F27LGTS/526NmHCBCxduhSZmZkAgO+++w6zZs3iqW16oDBzJ/3FuRc/z549g5ubGxISEgAARkZGUCqVqFmz5pttOHciIqL8Y5HVYakZ2fDfFI7oxBRk5qg/ur2JXArnitbYMMgDT+4n4NNPP4VKpXrzeIUKFXDz5k2Ym5trMzYVUmHmbmlqVAQJSRs49+Lp999/R5cuXfD6V61EInnrve6cOxERUcHwPbI6KjUjG11XnsfVe8l5enEDAJk5alxNSEaXlefRsVtPqFQqyGQyAIC5uTmsrKzw/PlzbcamQirs3FMzsrWckLSBcy++EhISULZs2Tc/iwHg7Nmz2LZtG+dORERUCFyR1UEqtYDea8Nw9V4yslT5H4+xTILypjnwr/ICbq4uqFSpEqysrLSQlDRJE3N3sbfBjqGf87RDPcK5Gwa1Wo2HDx/izp07OHPmDPr07YdvDydw7kRERAUkFzsAvevEtUeITkx568VN8rlteBV7Cqr0VEikchjbVUfJpr4wLvvuvV+zVAIeZBqhrHsLODrYFWV0KoT3zR0AkkMCkRIaBInc+M3nzGrUg23nCW9tl6USEH0vBSevP0Irzl1v5Dr3PB7znLt+kEqlKF++PMqXL4/PP/8cR5UPebwTEREVAousDgoIiX/nNLMStZvAsm4nyEwtIKiy8eLyATwKmoqKX26GRCp7Zx9ZOWoEhMTzBY4eed/cXzOpUAt2/ed9dB+cu/7Jbe75OeY5d/3D452IiKhw+B5ZHRP/5CUi7ya/83mj0hUhM/3n1gsCAKkM6rRkqDNevnc/AoCIO8n4++krrWUlzclt7vnFueuXD809P8c8565feLwTEREVHldkdczeyERIpcC/Ljb8Rtpf4Xh6YAGEzFcAJLD06AyZuXWu+5JKgb2R9zC25WfaC0wa8aG5A0DWo1tIWNIXEiMTmFR0gE2TATCyef8qDOeuPz429/wc85y7/uDxTkREVHgssjomISntrfsH/pt5DQ9U+iYIqvQXeBVzEjKrMh/cV7ZKQEJSujZikoZ9cO61GsLCuSVkVrZQvXyGpOCNeLxjCsr5LYPU2Oyd7Tl3/fGhuQP5O+Y5d/3B452IiKjweGqxjnmRkfPRbWRmlrD06IRnR5Yi61H8B7dNTeftGfTBh+ZubFsFcutPIJFIILcsgzLtxiDnxTNkJl7L9Ws4d/2Ql+MdyPsxz7nrBx7vREREhcciq2MsTfO4SC4IgEqF7KT7H9zMysxIA6lI2/I8dwCQABKJ5H//BnLBueuHfM09D8c8564feLwTEREVHousjrEvaQ4j2bv3BEwN3w/VqyQAgCotBc+PrgRkcphUdMh1X0YyCexLvnsqGume3OYOAK+uhUCVlgIAUL1KwrPDSyE1t4FJhdrv3Z5z1x8fmnt+j3nOXX/weCciIio8vkdWx3R1q4CVp2+98/mM21FICdsFITsdUmNzGJeribK9Z0JuUSrXfanUArq6VdRmXNKQ3OYOAK+UwXh+bBWE7ExITUvAxN4RZfvMhNTE/L3bc+7640Nzz+8xz7nrDx7vREREhcciq2Oq2VrArZINLt9Jeuvzn/hMy9d+JADqVC6JqmVKaDAdaUuV0uaobKFC/It3T5L4pMfUPO+Hc9cvuR3vQP6Oec5dv3xw7jzeiYiI8oSnFuugoY2rwUReuNEYy6UY2riahhKRNsXHx8Pb2xu3DgXAOJfTDfOKc9c/PN4Nkybmrs7JgvndMGRmZmooFRERkf5gkdVB3rXLwrmCdYFLjbFMCpeK1mhRq6yGk5EmqdVqLF26FM7OzqhVqxauHt4Kl4o2nLuB4fFumDQxd8dyFoj5Yzvq1KmD8PBwDSckIiLSbSyyOkgmlWD9YA/YlzLP94scY5kU9qXMsH6QB2TSwq3ukfb8+eef8PLywi+//IIDBw5g5cqVsLG24twNEI93w6SJue8Y1RQXL4Shb9++8PLywsSJE5GRkaGlxERERLqFRVZHWZkaYe+ohnCxt4GJXIqPvcyRADCRS+Fqb419oxrC0pS3Y9BFKpUKCxcuhKurK9zd3RETE4NmzZq9eZxzN0ycu2HSxNyNjIwwefJkhIeHIzg4GK6urggNDS2K+ERERKKSCMIHbk5HolOpBZy8/ghrz8Yj8m4ypFIgW/X/IzOSSaBWA+6VbTC0cTW0qFWWKzM66tq1a/Dz88OzZ8+wYcMGNGrUKNdtOXfDxLkbJk3NPScnB4sXL8b06dMxfPhwzJw5E+bm77/aMRERkb5jkdUj8U9eYl9UIhKS0pGang0rMyPYlzRDV7eKvGqlDsvJycGCBQvw008/YeTIkZgxY0a+Xly+nvvawD2oVssRn1WrxLkbAB7vhun13LfuPQJr23JwVXyW77nfuHEDfn5+ePz4MdavX48mTZpoOTUREVHRY5El0qLY2Fj4+vri5cuX2LhxIzw9PQu8r/r162PChAno3r27BhMSkS7q3r07GjdujDFjxhTo61UqFZYtW4YpU6bA19cXc+bMgYWFhWZDEhERiYjvkSXSguzsbPz000+oV68evL29ERkZWagSS0SUHzKZDGPGjEFUVBSio6Ph7OyMU6dOiR2LiIhIY+RiByAqbqKiouDr64ucnBycPXsWdevWFTsSERmoGjVqIDg4GKtWrULnzp3Rr18/zJs3D1ZWVmJHIyIiKhSuyBJpSFZWFqZOnYoGDRqgU6dOuHLlCkssEYlOKpXiiy++QHR0NP788084Ojri6NGjYsciIiIqFK7IEmnA5cuX4evrC7lcjtDQULi6uoodiYjoLVWrVsWJEycQEBCAnj17okePHli4cCFsbGzEjkZERJRvXJElKoSMjAxMmjQJTZo0Qa9evXDp0iWWWCLSWRKJBMOGDUNMTAwSExOhUChw8OBBsWMRERHlG1dkiQooLCwMfn5+sLCwwMWLF+Hk5CR2JCKiPKlUqRKOHDmCTZs2oX///ujYsSOWLFmCUqVKiR2NiIgoT7giS5RPaWlpGDduHLy9vTF48GCEhYWxxBKR3pFIJPD19YVSqURycjIcHBywd+9esWMRERHlCYssUT6EhITAxcUFoaGhuHz5MiZOnAi5nCc2EJH+qlChAn7//XcsWLAA/v7+6N27N548eSJ2LCIiog9ikSXKg1evXuHrr79G27ZtMXLkSJw7dw61a9cWOxYRkUZIJBL0798fcXFxyMrKgkKhwM6dOyEIgtjRiIiI3otFlugjgoOD4eTkhMjISERGRmLs2LGQyWRixyIi0jg7Ozvs2bMHy5cvxxdffIEePXrg0aNHYsciIiJ6B4ssUS5evHiBkSNHolOnTvjmm29w+vRp1KxZU+xYRERaJZFI0LNnT8TFxUEul8PBwQGBgYFcnSUiIp3CIkv0HseOHYOjoyNu3LiBq1evYvTo0ZBKebgQkeGwtbVFUFAQAgICMHbsWHTu3Bn3798XOxYREREAFlmit6SkpGDIkCHo0aMHvvvuO5w4cQLVqlUTOxYRkWi6deuGuLg4WFlZQaFQYOPGjVydJSIi0bHIEv3j8OHDUCgUuHv3LmJiYjBixAiuwhIRAShdujS2bt2KX3/9FVOmTEG7du2QkJAgdiwiIjJgfJVOBu/58+cYNGgQ+vbtix9//BFHjx5F5cqVxY5FRKRzOnbsCKVSiXLlysHR0REBAQFcnSUiIlGwyJJB279/PxQKBZ4+fYrY2Fj4+/tDIpGIHYuISGfZ2Nhgw4YNCAoKwowZM9CqVSvcvn1b7FhERGRgWGTJID19+hR9+vSBr68v5s6di4MHD6JixYpixyIi0htt2rSBUqlEtWrV4OTkhBUrVkCtVosdi4iIDASLLBmc3bt3w8HBAenp6VAqlRg4cCBXYYmICsDKygpr1qzB3r17MX/+fDRv3hy3bt0SOxYRERkAFlkyGI8fP4aPjw9GjBiBpUuXYu/evShXrpzYsYiI9J63tzdiYmLg6OgIFxcX/PLLL1CpVGLHIiKiYoxFloo9QRCwfft2ODg4QCKRIC4uDr179+YqLBGRBllaWmL58uU4dOgQli9fjiZNmuDGjRtixyIiomKKRZaKtQcPHqBr164YM2YM1qxZg507d+KTTz4ROxYRUbHl5eWFq1evol69enB3d8f8+fO5OktERBrHIkvFkiAI2Lx5MxwcHFCiRAkolUp0795d7FhERAahRIkSWLx4MY4dO4Z169ahQYMGiIuLEzsWEREVIyyyVOzcu3cPHTp0wKRJk7B582YEBgaiTJkyYsciIjI4DRs2RFRUFLy8vFC3bl3Mnj0b2dnZYsciIqJigEWWig1BELBu3TooFArY2toiLi4OnTp1EjsWEZFBMzMzw7x58xAcHIzAwEB4enoiOjpa7FhERKTnWGSpWLhz5w5at26N6dOnY/v27di0aRNKliwpdiwiIvpH/fr1ERERgTZt2sDT0xPTp09HVlaW2LGIiEhPsciSXlOr1Vi1ahWcnJxQuXJlKJVKtGvXTuxYRET0HiYmJpg1axZCQkLw22+/wcPDAxEREWLHIiIiPcQiS3orPj4eLVq0wM8//4w9e/YgICAA1tbWYsciIqKPqFOnDi5fvoyuXbuiUaNG+P7775GZmSl2LCIi0iMssqR31Go1li5dCmdnZ9SuXRuxsbFo2bKl2LGIiCgfjI2NMX36dISFheHIkSNwd3fHpUuXxI5FRER6gkWW9Mqff/4JLy8vLFmyBAcOHMDKlSthaWkpdiwiIiogFxcXXLx4EX379kXTpk0xYcIEpKenix2LiIh0HIss6QWVSoWFCxfC1dUV7u7uiI6ORrNmzcSORUREGmBkZITvv/8e4eHhOH36NNzc3BAaGip2LCIi0mEssqTzrl27hkaNGmHNmjU4evQolixZghIlSogdi4iINEyhUCA0NBT+/v5o2bIlvvnmG6SlpYkdi4iIdBCLLOmsnJwc/Pzzz6hbty4aNWqEq1evolGjRmLHIiIiLZLL5Rg/fjyuXLmCixcvwtnZGWfOnBE7FhER6Ri52AGI3icmJga+vr549eoVTp48CU9PT7EjERFREapVqxZCQkKwdOlStGvXDr6+vvj5559hYWEhdjQiItIBXJElnZKdnY0ZM2agfv36aNmyJSIjI1liiYgMlEwmwzfffIOrV68iJiYGTk5OOHnypNixiIhIB3BFlnRGZGQkfH19oVKpcPbsWdStW1fsSEREpANq1KiB4OBgrFy5El26dEHfvn0xf/58WFlZiR2NiIhEwhVZEl1WVhamTp2Khg0bonPnzrhy5QpLLBERvUUqleLLL79EdHQ0/vrrLzg6OuLo0aNixyIiIpFwRZZEdfnyZfj6+kIulyM0NBSurq5iRyIiIh1WtWpVnDhxAgEBAfDx8UGPHj2waNEi2NjYiB2NiIiKEFdkSRQZGRmYNGkSmjRpgl69euHSpUsssURElCcSiQTDhg1DbGws7t+/D4VCgYMHD4odi4iIihBXZKnIhYWFwc/PDxYWFrh06RIcHR3FjkRERHqoUqVKOHLkCDZt2oT+/fujY8eOWLJkCUqVKiV2NCIi0jKuyFKRSUtLw7hx4+Dt7Y3BgwcjLCyMJZaIiApFIpHA19cXSqUSycnJcHBwwN69e8WORUREWsYiS0UiJCQELi4uCA0NxZUrVzBx4kTI5TwhgIiINKNChQr4/fffsWDBAvj7+6NXr1548uSJ2LGIiEhLWGRJq169eoWvvvoKbdq0wciRI3Hu3DnUqlVL7FhERFQMSSQS9O/fH3FxccjOzoaDgwOCgoIgCILY0YiISMNYZElrgoOD4eTkhKioKERFRWHs2LGQyWRixyIiomLOzs4Oe/bswfLly/Hll1+iR48eePTokdixiIhIg1hkSeNevHiBkSNHolOnTvjmm29w+vRp1KxZU+xYRERkQCQSCXr16oW4uDjI5XI4ODggMDCQq7NERMUEiyxp1LFjx+Do6IgbN27g6tWrGD16NKRS/jMjIiJx2NraIigoCAEBARg7diw6d+6M+/fvix2LiIgKiQ2DNCIlJQVDhgxBjx498N133+HEiROoVq2a2LGIiIgAAN26dUNcXBysrKygUCiwceNGrs4SEekxFlkqtMOHD0OhUCAhIQGxsbEYMWIEV2GJiEjnlC5dGlu3bsWvv/6KKVOmoF27dkhISBA7FhERFQDbBhXY8+fPMWjQIPTt2xczZszAH3/8gUqVKokdi4iI6IM6duwIpVKJcuXKwdHREWvXruXqLBGRnmGRpQLZv38/FAoFnj17BqVSCT8/P0gkErFjERER5YmNjQ02bNiAoKAg/PTTT2jZsiVu374tdiwiIsojFlnKl6dPn6Jv377w9fXFvHnzcODAAVSoUEHsWERERAXSpk0bKJVKVK9eHU5OTlixYgXUarXYsYiI6CNYZCnPdu/eDYVCgfT0dCiVSgwYMICrsEREpPesrKywZs0a7Nu3DwsWLEDz5s1x69YtsWMREdEHsMjSRz1+/Bg+Pj4YMWIElixZgt9++w3lypUTOxYREZFGtWjRAjExMXB0dISLiwt++eUXqFQqsWMREdF7sMhSrgRBwPbt2+Hg4ACJRIK4uDj07t2bq7BERFRsWVhYYPny5Th06BCWL1+OJk2a4MaNG2LHIiKi/2CRpfd68OABunbtijFjxmDNmjXYuXMnPvnkE7FjERERFQkvLy9cvXoV9erVg7u7O+bPn8/VWSIiHcIiS28RBAGbN2+Gg4MDSpQoAaVSie7du4sdi4iIqMiVKFECixcvxrFjx7Bu3To0aNAAcXFxYsciIiKwyNK/3Lt3Dx06dMB3332HzZs3IzAwEGXKlBE7lsH7/PPPYWdnh4iICPj7+6NcuXLYvn272LGISAu6desGOzs7HDp0CD/88APs7Owwf/58sWMZvIYNGyIqKgpeXl6oW7cuZs+ejezsbLFjEREZNBZZgiAIWL9+PRQKBWxtbaFUKtGpUyexY9E/ypQpgydPniAnJwcpKSl4+PAhqlevLnYsItKCihUr4tmzZ8jMzMTLly/x5MkTHu86wszMDPPmzUNwcDACAwPh6emJ6OhosWMRERksiSAIgtghSDx37tzBsGHDEBcXh7Vr16Jt27ZiR6L/iImJgZubG1QqFSQSCZo1a4aTJ0+KHYuItODhw4eoVKnSm9W+mjVr4vr165BK+XdnXZKZmYkZM2Zg8eLFmDhxIr777jsYGxuLHYuIyKDwN6OBUqvVWLVqFZycnFC5cmXExsayxOooJyenN7ORSqWYM2eOyImISFvs7OwwYsQISKVSyOVy/PzzzyyxOsjExASzZs3CuXPn8Ntvv8HDwwMRERFixyIiMihckTVA8fHxGDJkCOLj47Fu3Tp4e3uLHYk+IiYmBs7OznB0dERMTIzYcYhIix4+fIjy5cujdOnSePToEYusjsvKysKcOXMwd+5cjB07Fj/88ANMTEzEjkVEVOzxt2Mxd/78efTq1QsqlQpqtRpLly6Fi4sLateujZiYGJZYPeHk5IQuXbpgwYIFYkchIi2zs7ODv78/V2P1hLGxMaZNm4YLFy7gyJEjqFOnDi5dugQAUCqV6NixI9LT00VOSURU/HBFVo/EP3mJvZGJSEhKw4uMHFiaymFf0hxd3Sqgmq3FO9vn5OSgVq1aiI+Px/jx4xEaGor79+9j/fr1aNq0adF/A1Qg+Z07EekvHu/6LTs7G/Pnz8fMmTMxatQoHDlyBNeuXcOPP/6IH374Idev49yJiPKPRVbHqdQCTlx7hICQeETeTYZUCmSr/n9kRjIJ1GrArZINhjauBu/aZSGTSgAAK1aswLfffouMjAwAwMCBA7Fy5UqUKFFClO+F8q4wcyci/cLjvfhRKpVo3bo17t+/D0EQYGxsjPj4eFSoUOHNNpw7EVHhsMjqsNSMbPhvCkd0Ygoyc9Qf3d5ELoVzRWtsGOSB7LQXsLe3R1paGgBAJpPBzc0NFy9e5KlqOq4wc7c0NSqChESkKTzei6fr16/D2dn5zdWnpVIpunTpgj179gDg3ImINIFFVkelZmSj68rzSHiehixV3kdkLJPAvpQ5hGPzEXz0MIyMjCCXy5GZmQmpVIpr166hRo0aWkxOhVHYue8d1RBWfJFDpBd4vBdfP//8M7777rs3v4MzMjIgCAJ+++03tGjbgXMnItIAFlkdpFIL6L02DFfvJefrl9xrxjIJLLOfwz3pLBo1bIjKlSujcuXKqFixIoyM+MtPV2li7i72Ntgx9HOefkak43i8F3+pqam4e/cu7ty5g7///htHjhzB12PGIOBWCc6diEgDWGR10FHlQ3y1I/Kt042Sz23Dq9hTUKWnQiKVw9iuOko29YVx2Wrv3YeJXIplfdzQysGuqGJTIb1v7gCQHBKIlNAgSOTGbz5nVqMebDtPeGcfnDuRfuDxbpg4dyIizZGLHYDeFRAS/84vuRK1m8CybifITC0gqLLx4vIBPAqaiopfboZEKntnH1k5agSExPMXnR5539xfM6lQC3b95310H5w7kX7g8W6YOHciIs3hVX90TPyTl4i8m/zO541KV4TM9J9L8AsApDKo05Khznj53v0IACLuJOPvp6+0lpU0J7e55xfnTqT7eLwbJs6diEizuCKrY/ZGJkIqBVSqdx9L+yscTw8sgJD5CoAElh6dITO3znVfUimwN/Iexrb8THuBSSM+NHcAyHp0CwlL+kJiZAKTig6waTIARjbv/2s8506k23i8GybOnYhIs1hkdUxCUtpb95H7N/MaHqj0TRBU6S/wKuYkZFZlPrivbJWAhKR0bcQkDfvg3Gs1hIVzS8isbKF6+QxJwRvxeMcUlPNbBqmx2Tvbc+5Euo3Hu2Hi3ImINIunFuuYFxk5H91GZmYJS49OeHZkKbIexX9w29T0bE1FIy360NyNbatAbv0JJBIJ5JZlUKbdGOS8eIbMxGu5fg3nTqS7eLwbJs6diEizWGR1jKVpHhfJBQFQqZCddP+Dm1mZ8XY7+iDPcwcACSCRSP73byAXnDuR7uLxbpg4dyIizWKR1TH2Jc1hJHv33nCp4fuhepUEAFClpeD50ZWATA6Tig657stIJoF9yXdPSSLdk9vcAeDVtRCo0lIAAKpXSXh2eCmk5jYwqVD7vdtz7kS6jce7YeLciYg0i++R1TFd3Spg5elb73w+43YUUsJ2QchOh9TYHMblaqJs75mQW5TKdV8qtYCubhW1GZc0JLe5A8ArZTCeH1sFITsTUtMSMLF3RNk+MyE1MX/v9pw7kW7j8W6YOHciIs1ikdUx1Wwt4FbJBpfvJL31+U98puVrPxIAdSqXRNUyJTSYjrSlmq0FHMqaIeZh2juPfdJjap73w7kT6b5qthZQ2Jkj+sG7t0/h8V585fb7HeDciYgKgqcW66ChjavBRF640RjLpRjauJqGEpE2paWlYdy4cTi37kcY53LaWV5x7kS6LTs7G7Nnz8bZtdNgVMjfwDze9Y8mfr+rc7LwqToBwgfeP0tEZAhYZHWQd+2ycK5gXeBSYyyTwqWiNVrUKqvhZKRpZ8+ehYuLC8LCwnAuaBVcKtpw7kTFVHR0NDw9PREYGIg/1s+Dq31JHu8GRhO/36uXlGP9jDHo3Lkz7t//8AUfiYiKMxZZHSSTSrB+sAfsS5nn+5edsUwK+1JmWD/IAzJp4Vb3SHtevnyJ0aNHo127dhg1ahRCQkKgcKjNuRMVQ1lZWZg+fTo8PT3Rtm1bREREwLN+fR7vBkgTv9/3j20DZWwsrK2toVAosHHjRq7OEpFBkgj86aezUjOy4b85HNH3UpCVo8aHBiXB/04zc6lojfWDPGBpysvy66pTp05hyJAhsLe3x/r161GjRo23HufciYqPiIgI+Pr6AgA2btwId3f3tx7n8W6YNDX3gwcPYvjw4XB2dsbatWthb2+v9exERLqCRVbHqdQCTl5/hLVn4xF5NxlSKZCt+v+RGckkUKsB98o2GNq4GlrUKsu/0Ouo1NRUTJgwAYGBgZgzZw5GjRoFqfT9J0Vw7kT6LTMzEzNmzMDixYsxceJEfPfddzA2Nn7vtjzeDZOm5p6cnIyxY8diz549WLBgAYYMGfK/e9ASERVzLLJ6JP7JS+yLSkRCUjpS07NhZWYE+5Jm6OpWkVcv1HHHjh3D0KFDUaNGDaxbtw5Vq1bN89e+nvvawD2oVssRn1WrxLkT6bBLly7B19cXpqam2LhxI5ydnfP8ta+P9617j8DathxcFZ/xeDcAr+cedOgkjEtYo66LIt9z/+OPPzB06FDUqlULAQEBqFKlinZDExGJjEWWSIuSk5Mxbtw47Nq1C/Pnz8ewYcMK/Jfy+vXrY8KECejevbuGUxKRJqSnp2PatGlYvnw5pkyZgvHjx8PIqGCn/3bv3h2NGzfGmDFjNBuSdJqfnx+qVKmCqVPzfjuef0tNTcX48eOxbds2/Pzzzxg5cmSuZ/4QEek7/nQj0pJDhw7B0dER9+7dQ2xsLIYPH87TvYiKqdDQULi5ueHMmTMIDw/H5MmTC1xiiQrKysoKa9aswb59+7BgwQI0b94ct27dEjsWEZFWsMgSadjz588xcOBA9OvXDzNmzMAff/yBSpUqiR2LiLQgLS0N33zzDVq2bAl/f3+cP38eCoVC7Fhk4Fq0aIGYmBg4OjrCxcUFv/zyC1QqldixiIg0ikWWSIP27dsHhUKB58+fQ6lUws/Pj6uwRMXUmTNn4OzsjEuXLiEiIgLjx4+HXC4XOxYRAMDCwgLLly/HoUOHsHz5cjRp0gQ3btwQOxYRkcawyBJpwNOnT9GnTx/4+flh/vz5OHDgACpUqCB2LCLSgpcvX+LLL79E+/btMXr0aJw9exafffaZ2LGI3svLywvR0dGoX78+3N3dMX/+fK7OElGxwCJLVEi7du2Cg4MDMjMzERcXh/79+3MVlqiYOnnyJJycnBAbG4urV6/i66+/hkwmEzsW0QeZm5tj0aJFOH78ONavX48GDRogLi5O7FhERIXCIktUQI8ePUKPHj0watQoLFu2DHv27IGdnZ3YsYhIC1JTUzF8+HB06dIF48ePx6lTp1C9enWxYxHlS4MGDRAZGYmmTZvCw8MDs2fPRk5OjtixiIgKhEWWKJ8EQcC2bdugUCggk8kQFxeHXr16cRWWqJj6448/oFAocOvWLcTExGDUqFG8pQnpLTMzM8ydOxfBwcEIDAxE/fr1ER0dLXYsIqJ8429ionx48OABunTpgm+++QZr1qxBUFAQbG1txY5FRFqQnJwMPz8/9OrVCz/88AOOHz+OKlWqiB2LSCPq1auHiIgItGnTBp6envjxxx+RlZUldiwiojxjkSXKA0EQsHnzZjg4OMDS0hJxcXHo3r272LGISEsOHjwIhUKBBw8eIDY2FsOGDeNZF1TsmJiYYNasWTh37hx+++03eHh4ICIiQuxYRER5wiJL9BH37t1D+/bt8d1332Hz5s3YunUrSpcuLXYsItKC58+fY8CAARgwYABmzZqFw4cPw97eXuxYRFrl7u6O8PBwdOvWDY0aNcKUKVOQmZkpdiwiog9ikSXKhSAICAgIgEKhQNmyZaFUKtGpUyexYxGRluzduxcODg5ISUmBUqnE4MGDuQpLBsPY2BjTpk3DhQsXcOTIEdSpUweXLl0SOxYRUa5YZIne486dO2jdujVmzJiBHTt2YOPGjShZsqTYsYhIC548eYJevXphyJAhWLhwIfbv34/y5cuLHYtIFM7Ozrhw4QL69u2Lpk2bYuLEicjIyBA7FhHRO1hkif5FrVZj1apVcHJyQpUqVRAbG4u2bduKHYuItEAQBAQFBcHBwQE5OTlQKpXo168fV2HJ4BkZGWHy5MkIDw/H6dOn4erqitDQULFjERG9RS52ACJdER8fD39/f/z999/47bff4O3tLXYkItKShw8fYtSoUQgJCcGKFSvg4+PDAkv0HwqFAufPn8fixYvRsmVLDB8+HDNnzoS5ubnY0YiIuCJLpFarsXTpUri4uEChUCAmJoYllqiYEgQBW7duhUKhgLGxMeLi4tCzZ0+WWKJcyOVyjB8/HhEREbh48SJcXFxw9uxZsWMREXFFlgzbzZs34efnhwcPHuDAgQNo2rSp2JGISEsSExMxYsQIhIeHY926dejatavYkYj0xmeffYazZ89i2bJlaNeuHXx9fTFnzhxYWFiIHY2IDBRXZMkgqVQqLFiwAG5ubqhbty6io6NZYomKKUEQsHHjRigUCtjY2ECpVLLEEhWATCbDmDFjEBUVhejoaDg5OeHkyZNixyIiA8UVWTI4cXFx8PPzQ1JSEo4dO4aGDRuKHYmItCQhIQHDhg1DdHQ0tm7dig4dOogdiUjv1ahRA8HBwVi1ahW6dOmCvn37Yv78+bCyshI7GhEZEK7IksHIycnBnDlzULduXTRu3BhRUVEssUTFlCAIWLt2LRwdHVGuXDkolUqWWCINkkql+OKLLxAdHY1bt27B0dERR48eFTsWERkQrsiSQYiJiYGvry/S09MRHByM+vXrix2JiLTk9u3bGDJkCG7evImgoCC0adNG7EhExVbVqlVx/PhxBAQEoGfPnujevTsWLVoEGxsbsaMRUTHHFVkq1rKzszFjxgzUr18frVu3RkREBEssUTGlVquxYsUKODk5oUaNGoiNjWWJJSoCEokEw4YNQ2xsLB48eACFQoGDBw+KHYuIijmuyFKxFRkZCV9fX6jVaoSEhKBOnTpiRyIiLfnrr78wZMgQ3LlzB/v27UOLFi3EjkRkcOzt7XH48GFs3rwZAwYMQIcOHbBkyRKUKlVK7GhEVAxxRZaKnczMTPzwww9o2LAhunTpgsuXL7PEEhVTKpUKv/zyC1xdXeHk5ISYmBiWWCIRSSQSDB48GEqlEikpKXBwcMDevXvFjkVExRBXZKlYCQ8Ph6+vL4yNjREWFgYXFxexIxGRlty4cQN+fn549OgRDh8+jCZNmogdiYj+Ub58eezfvx/btm3DkCFDEBQUhGXLlsHW1lbsaERUTHBFloqFjIwMTJo0CV5eXujTpw8uXrzIEktUTOXk5GDevHlwd3dH/fr1ER0dzRJLpIMkEgn69esHpVKJ7OxsKBQK7Ny5E4IgiB2NiIoBrsiS3gsLC4Ofnx8sLS0RHh4OhUIhdiQi0hKlUglfX1+kpqbi+PHjaNCggdiRiOgj7OzssHv3buzatQtffPEFgoKCsHLlSpQtW1bsaESkx7giS3orLS0N48aNg7e3N3x9fREaGsoSS1RMZWdnY/bs2fDw8ECzZs0QGRnJEkukRyQSCXr27Im4uDgYGRnBwcEBgYGBXJ0logLjiizppZCQEPj5+cHW1hZXrlxBrVq1xI5ERFoSHR0NX19fZGRk4PTp06hXr57YkYiogGxtbbFjxw7s3bsXI0eORFBQEFavXo3y5cuLHY2I9AxXZEmvvHr1Cl999RXatm2LUaNGISQkhCWWqJjKysrC9OnT4enpibZt2yIiIoIllqiY6Nq1K5RKJaytraFQKLBp0yauzhJRvnBFlvRGcHAw/P39UbFiRURFRaFGjRpiRyIiLYmIiICvry8A4Ny5c3B3dxc5ERFpWunSpbFlyxYcPHgQw4cPx86dO7FmzRrY29uLHY2I9ABXZEnnvXjxAiNHjkSnTp0wduxYnD59miWWqJjKzMzE999/j0aNGqFbt24IDw9niSUq5jp06AClUgk7Ozs4OjoiICCAq7NE9FFckSWdduzYMQwdOhQ1atRAdHQ0qlatKnYkItKSS5cuwdfXF6amprhw4QKcnZ3FjkRERcTGxgYbNmxAz549MWzYMOzcuRMBAQGoUqWK2NGISEdxRZZ0UnJyMvz9/eHj44Pvv/8eJ06cYIklKqbS09MxYcIENGvWDP3798fFixdZYokMVJs2bRAbG4vq1avDyckJK1asgFqtFjsWEekgFlnSOYcOHYKjoyMSExMRExODYcOGQSKRiB2LiLQgNDQUrq6uOHv2LMLDw/Hdd99BLufJQkSGzMrKCqtXr8a+ffuwYMECNG/eHLdu3RI7FhHpGBZZ0hnPnz/HwIED0a9fP/z00084cuQIKlWqJHYsItKCtLQ0fPPNN2jZsiWGDh2K8+fPw8HBQexYRKRDWrRogZiYGDg5OcHFxQW//PILVCqV2LGISEewyJJO2LdvHxQKBZ4/fw6lUglfX1+uwhIVU2fOnIGzszMuXbqEiIgIfPvtt5DJZGLHIiIdZGFhgWXLluHQoUNYvnw5mjRpghs3bogdi4h0AIssierp06fo06cP/Pz8MH/+fBw4cAAVKlQQOxYRacHLly/x5Zdfon379hg9ejTOnj2Lzz77TOxYRKQHvLy8EB0djfr168Pd3R0LFizg6iyRgWORJdHs2rULDg4OyMzMRFxcHPr3789VWKJi6uTJk3ByckJsbCyuXr2Kr7/+mquwRJQv5ubmWLRoEY4fP45169ahQYMGiIuLEzsWEYmERZaK3KNHj9CjRw+MGjUKy5Ytw549e2BnZyd2LCLSgtTUVAwfPhxdunTB+PHjcerUKVSvXl3sWESkxxo0aIDIyEg0bdoUHh4emD17NnJycsSORURFjEWWiowgCNi2bRsUCgVkMhni4uLQq1cvrsISFVN//PEHFAoF4uPjERMTg1GjRkEq5a8dIio8MzMzzJ07F8HBwQgMDET9+vURHR0tdiwiKkJ8RUFF4sGDB+jSpQu++eYbrF27FkFBQbC1tRU7FhFpQVJSEnx9fdGrVy9MnToVx44dQ5UqVcSORUTFUL169RAREYG2bdvC09MTP/74I7KyssSORURFgEWWtEoQBGzevBkODg6wtLREXFwcunXrJnYsItKSAwcOQKFQ4OHDh4iNjcXQoUN51gURaZWJiQlmzpyJc+fO4bfffoOHhwciIiLEjkVEWsYiS1pz7949tG/fHpMnT8avv/6KrVu3onTp0mLHIiIteP78OQYMGICBAwdi9uzZOHz4MOzt7cWORUQGxN3dHeHh4ejWrRsaNWqEKVOmIDMzU+xYRKQlLLKkcYIgICAgAAqFAnZ2dlAqlejYsaPYsYhIS/bu3QsHBwekpKRAqVRi8ODBXIUlIlEYGxtj2rRpuHDhAo4cOYI6derg0qVLYsciIi1gkSWNun37Nlq1aoUZM2YgKCgIGzZsgI2NjdixiEgLnjx5gl69emHIkCFYtGgR9u/fj/Lly4sdi4gIzs7OuHDhAvr27YumTZtiwoQJSE9PFzsWEWkQiyxphFqtxqpVq+Dk5ISqVasiNjYWbdq0ETsWEWmBIAgICgqCg4MDcnJyoFQq0bdvX67CEpFOMTIywuTJkxEeHo4zZ87Azc0NoaGhYsciIg2Rix2A9F98fDz8/f3x999/Y+/evfD29hY7EhFpycOHDzFq1CiEhIRgxYoV8PHxYYElIp2mUChw/vx5LF68GC1btsTw4cMxc+ZMmJubix2NiAqBK7JUYGq1GkuXLoWLiwsUCgViYmJYYomKKUEQsHXrVigUChgbGyMuLg49e/ZkiSUivSCXyzF+/HhERETg4sWLcHFxwdmzZ8WORUSFwBVZKpCbN2/Cz88PDx8+xMGDB+Hl5SV2JCLSksTERIwYMQLh4eFYt24dunbtKnYkIqIC+eyzz3D27FksX74c7dq1g6+vL+bMmQMLCwuxoxFRPnFFlvJFpVJhwYIFcHNzg4eHB65evcoSS1RMCYKAjRs3QqFQoGTJkoiLi2OJJSK9J5PJ8PXXX+Pq1auIiYmBk5MTTp48KXYsIsonrshSnsXFxcHPzw9JSUk4duwYGjZsKHYkItKShIQEDBs2DNHR0di6dSs6dOggdiQiIo2qXr06Tp06hdWrV6NLly7o27cv5s+fDysrK7GjEVEecEWWPionJwdz5syBh4cHmjRpgqioKJZYomJKEASsXbsWjo6OKF++PJRKJUssERVbUqkUo0aNQkxMDOLj4+Ho6IijR4+KHYuI8oArsvRBMTEx8PX1RXp6Ok6dOoX69euLHYmItOT27dsYMmQIbt68iZ07d6J169ZiRyIiKhJVqlTBsWPHsG7dOvTs2RPdu3fHokWLYGNjI3Y0IsoFV2TpvbKzszFjxgzUr18frVu3RkREBEssUTGlVquxYsUKODk5oUaNGoiNjWWJJSKDI5FIMHToUMTGxuLBgwdQKBQ4ePCg2LGIKBdckaV3REZGwtfXF2q1GiEhIahTp47YkYhIS/766y8MGTIEd+7cwb59+9CiRQuxIxERicre3h6HDx/G5s2bMWDAAHTo0AFLlixBqVKlxI5GRP/CFVl6IzMzEz/88AMaNmyILl264PLlyyyxOmDkyJFo164dbty4gVmzZqF9+/YIDg4WOxbpOZVKhV9++QWurq5wcnJCTEwMS6wOmDp1Ktq1a4fz589j7dq1aNeuHYKCgsSORVo2Z84ctGvXDseOHcPWrVvRrl07bNy4UexYBk0ikWDw4MFQKpVISUmBg4MD9u7dK3YsIvoXrsgSACA8PBy+vr4wNjZGWFgYXFxcxI5E/7h06RIiIiIA/G+1PDIyEiNGjBA5FemzGzduwM/PD48ePcLhw4fRpEkTsSPRP5RKJf744w8IgoBHjx7h+vXraN++vdixSMv+/PNPHD16FGq1GgBw69YtNGrUSORUBADly5fH/v37sW3bNgwZMgRBQUFYtmwZbG1txY5GZPC4ImvgMjIyMGnSJHh5eaFPnz64ePEiS6yOmTt3LoyNjd98XKtWLV5FlgpEpVJh/vz5cHd3R/369REdHc0Sq2N++uknyGSyNx+XKlUK/v7+IiaiojBt2jRIpf//kszc3ByjR48WMRH9m0QiQb9+/aBUKpGdnQ2FQoGdO3dCEASxoxEZNBZZAxYWFgY3NzecOnUK4eHh+P7772FkZCR2LPqPFi1awNHREQBgZGSEuXPnQiKRiJyK9E1cXBwaNGiA9evX4/jx41i0aBHMzc3FjkX/4eDggI4dO0IikUAul2P69OkwNTUVOxZpWeXKldG/f39IpVLI5XJMmjQJlpaWYsei/7Czs8Pu3buxfPlyfPHFF+jRowcePXokdiwig8Uia4DS0tIwbtw4eHt7w8/PD6GhoVAoFGLHolxIJBLMnTsXAGBra4uOHTuKnIj0SXZ2NmbPng0PDw80bdoUkZGRaNCggdix6ANmzpwJQRBgbGyMIUOGiB2Hisj06dMhCAKkUim++uorseNQLiQSCXr27Im4uDgYGRnBwcEBgYGBXJ0lEgGLbDF369YtLFq06M3HZ8+ehYuLCy5cuICIiAiMHz8ecjnfKq3rWrRogRo1amDKlClcjaVcPXnyBDNmzHjzPrvo6Gh4enpi27ZtOH36NObOnQszMzORU9LHODg4oH79+vjiiy+4GmtAKleujObNm2PgwIFcjdUDtra22LFjB9atW4dx48ahc+fOuH//PgAgOTkZ06ZNQ3Z2tsgpiYo3icA/IemN+CcvsTcyEQlJaXiRkQNLUznsS5qjq1sFVLO1eGd7QRDg5eWFkJAQBAYGIiwsDBs3bsTMmTMxevTot96HRborv3On4qEgcx84cCC2bNmCBQsW4MWLF5g3bx7GjRuHKVOmwMTEpIi/AyoIHu+GiXPXb8+fP8eYMWNw4MABLFq0CKdOncLWrVuxZMmSD66uc+5EhcMiq+NUagEnrj1CQEg8Iu8mQyoFslX/PzIjmQRqNeBWyQZDG1eDd+2ykEn/t2J34MAB+Pj4IDMzE1KpFPXr18evv/6KGjVqiPXtUB4VZu6kvwoz9ytXrsDT0xM5OTmQSCT47LPPsG3bNri5uYn17VAeFXTur3998ywN/cSf88XPwYMHMWjQICQlJUEQBJibm+POnTsoU6bMm204dyLNYZHVYakZ2fDfFI7oxBRk5qg/ur2JXArnitbYMMgDxhI1qlWr9uY0F5lMhq5du2LXrl3ajk2FVJi5W5ryYl36qjBztzCRo06dOoiMjAQASKVS1KlTBxcuXHjrSqikewo7d5ZY/cSf88VTamoqqlWrhmfPngEA5HI5Bg8ejICAgP89zrkTaRSLrI5KzchG15XnkfA8DVmqvI/IWCaBfSlzVLm5GxvWrAAAmJqaQiKRID09HTdu3MCnn36qrdhUSIWd+95RDWHFX3Z6p7Bzb5p9GVMnjQcAmJiYQCaTIS0tDSdOnECLFi20FZsKice7YeLci69FixZh3LhxKFGiBLKyst68R/bUqVOo83kjzp1Iw1hkdZBKLaD32jBcvZecrx92rxnLJJAl3wNOLUGL5s1QrVo1VK5cGdWqVYOrqyv/gq+jNDF3F3sb7Bj6OU9D0iOamLtZ+mO83D8L3i2ao3r16qhcuTKqVKkCDw8PrsjqKB7vholzL97S09Nx+fJl3LlzB3fu3MG1a9dw+vRpfDN2HC6Y1+fciTSMl6vVQSeuPUJ0Yso7P+xexZ3Bi4hDyHr8N4SsdFSasB8S6bsXbMpSCTApaY9lu0+ilYNdUcWmQspt7skhgUgJDYJEbvzmc2Y16sG284S3tstSCYi+l4KT1x9x7nok17mf24ZXsaegSk+FRCqHsV11lGzqC+Oy1d7aLkslQGJeFqt+D+Hc9QiPd8OkieOdc9ddZmZmaNy4MRo3bvzW548qH2Ltjkge70QaxiKrgwJC4t/73gmpqQUs3dtDyM7EsyNLP7iPrBw1AkLi+QNPj+Q2dwAwqVALdv3nfXQfnLv+yW3uJWo3gWXdTpCZWkBQZePF5QN4FDQVFb/c/M4fsDh3/cPj3TDxeDdMPN6JtIPnnOmY+CcvEXk3+b2PmVWrgxIOXpDbfPyHmAAg4k4y/n76SrMBSSs+NPf84Nz1y4fmblS6ImSm/9x+QQAglUGdlgx1xst3tuXc9QuPd8PE490w8Xgn0h6uyOqYvZGJkEoBlarw+5JKgb2R9zC25WeF3xlp1cfmnvXoFhKW9IXEyAQmFR1g02QAjHL5gwbnrj8+Nve0v8Lx9MACCJmvAEhg6dEZMnPr927LuesPHu+Gice7YeLxTqQ9LLI6JiEp7a37iRVGtkpAQlK6RvZF2vWhuZvXaggL55aQWdlC9fIZkoI34vGOKSjntwxSY7N3tufc9cfHjnfzGh6o9E0QVOkv8CrmJGRWZXLdlnPXHzzeDROPd8PE451Ie3hqsY55kZGj0f2lpmdrdH+kHR+au7FtFcitP4FEIoHcsgzKtBuDnBfPkJl4Ldev4dz1Q16Pd5mZJSw9OuHZkaXIehSf63acu37g8W6YeLwbJh7vRNrDIqtjLE01u0huZcZ7jumDfM1dgv/dQukDd87i3PVDvuYuCIBKheyk+7luwrnrBx7vhonHu2Hi8U6kPSyyOsa+pDmMZO+/R5igVkHIyYKg/t9f94Sc7P99LLz/SnhGMgnsS757agrpng/N/dW1EKjSUgAAqldJeHZ4KaTmNjCpUPu923Pu+uNDc08N3w/VqyQAgCotBc+PrgRkcphUdHjv9py7/uDxbph4vBsmHu9E2sP3yOqYrm4VsPL0rfc+9io2GM8O//Lm44RFPQAAZfvMhmll53e2V6kFdHWrqJWcpFkfnLsyGM+PrYKQnQmpaQmY2DuibJ+ZkJqYv3d7zl1/fGjuGbejkBK2C0J2OqTG5jAuVxNle8+E3KLUe7fn3PUHj3fDxOPdMPF4J9IeFlkdU83WAm6VbHD5TtI7j1k4e8PC2TtP+5EAqFO5JKqWKaHhhKQNH5r7Jz2m5nk/nLt++eDcfableT+cu37h8W6YeLwbJh7vRNrDU4t10NDG1WAiL9xojOVSDG1cTUOJqCg4SB/AqJBHJOeuf3i8GybO3TBx7oZJE3OXQo0hDatqKBFR8cAiq4O8a5eFcwVrGOfynoqPMZZJ4VLRGi1qldVwMtKGV69ewdfXFyu/H4FqNnLO3cDweDdM3rXLonpJI8gLNnbOXU/xeDdMhZ27kRRQPYnH3K8H4N69expOR6S/WGR1kEwqwfrBHrAvZZ7vH3rGMinsS5lh/SAPyKQFfIVERSYmJgYeHh64desWoiIjsWt0c87dwPB4N0xXoyIRNncgbIxyOHcDwuPdMBV27pVKl0DYzwNRpXIlODs7Y9euXVpKSqRfWGR1lJWpEfaOaggXexuYyKX42I89CQATuRSu9tbYN6ohLE15eXZdJggCAgIC4Onpie7du+PUqVOoWLEi526gOHfDEhkZCW9vb0yZMA6nvmuX57lDUHPuxQCPd8NU2LmXK1MSGzZswNq1azF8+HD4+vrixYsXRRGdSGdJBOEDN6si0anUAk5ef4S1Z+MReTcZUimQrfr/kRnJJFCrAffKNhjauBpa1CrLv9TquNTUVAwfPhzBwcHYunUrvL3fvYAX526YOPfi7+rVq2jevDkmTpyICRMmAMjr3AWon8Sja21LzB8ziHMvBni8G6b/zh1QQyX8/1zzMvd79+5h0KBBuH37NgIDA+Hp6Vm03wSRjmCR1SPxT15iX1QiEpLSkZqeDSszI9iXNENXt4q8ip2eiIiIQK9evVC5cmVs3boVdnZ2H/2af8/9aWoajuzfg2+GDkTfBjU492KMx3vxExMTg+bNm2Ps2LH47rvv3rvNh+Z+5fQRfPXVV7h16xbMzHgvyeKEx7thin/yEgOmLoO5rT0qVf8sX3NXq9VYtGgRpk6dikmTJmHy5MmQy3kzEjIsLLJERUAQBKxYsQITJ07E5MmTMWnSJMhksgLtq3z58ti5cycaNWqk4ZREpC2xsbFo1qwZxowZg++//75A+xAEAR4eHujVqxfGjx+v4YREJIYmTZpg6NChGDBgQIG+PjIyEn379kWpUqWwZcsWVKvGK1qT4eB7ZIm0LCkpCd27d8fPP/+MP/74A99//32BSywAKBQKKJVKDSYkIm2Ki4tD8+bNMXr06AKXWACQSCSYNWsWfv75Z6SkpGgwIRGJJTExERUqVCjw17u5ueHKlStwdXWFm5sbfv31V3CNigwFiyyRFl28eBFubm7IzMxEVFQUGjduXOh9Ojo6IjY2VgPpiEjbrl+/jubNm2PkyJGYOnVqoffXqlUrODk5YeHChRpIR0RiEgSh0EUWAMzNzbFixQoEBgbi22+/RZ8+fZCUlKShlES6i0WWSAvUajUWLFjwZhXmwIEDKFOmjEb2zRVZIv1w48YNNGvWDEOGDMH06dM1sk+JRILZs2dj8eLFePz4sUb2SUTieP78OTIzMwtdZF/r0KEDYmJikJqaChcXF5w5c0Yj+yXSVSyyRBr29OlTdOzYEcuXL8epU6cwbtw4SKWaO9RYZIl0382bN9GsWTMMHjwYP/30EyQSzV1ttkGDBmjatClmz56tsX0SUdFLTEyElZUVLCwsNLbPsmXL4tChQ5gwYQLatWuH7777DllZWRrbP5EuYZEl0qCzZ8/C1dUVpqamiIyMRP369TX+HA4ODnj8+DGePn2q8X0TUeH99ddfaNasGQYMGIDZs2drtMS+NmvWLKxZswZ3797V+L6JqGho4rTi95FIJPjyyy9x6dIlHD58GA0aNMCNGzc0/jxEYmORJdIAlUqFmTNnom3btpg0aRJ2796NkiVLauW5rK2tUbFiRa7KEumgW7duoVmzZujTpw9+/vlnrZRYAHB2dka3bt3w448/amX/RKR92iqyrykUCly6dAlNmzZFnTp1sHbtWl4IiooVFlmiQnr48CFat26NzZs3IyQkBF9++aXWXry+xtOLiXTP33//jWbNmqFHjx6YP3++1n8O/PjjjwgMDMT169e1+jxEpB3aLrIAYGJiggULFmDfvn348ccf0bVrVzx58kSrz0lUVFhkiQrhxIkTcHV1ha2tLa5cuQJ3d/cieV4WWSLdcvv2bTRr1gxdu3bFokWLtF5iAaBGjRoYPHiwRq6GTERFryiK7Gve3t6Ijo6GTCaDs7Mzjh49WiTPS6RNLLJEBZCTk4MffvgBXbp0wcyZM7Ft2zZYWVkV2fOzyBLpjrt376JZs2bo0KEDfvnllyIpsa/98MMPOHjwICIiIorsOYlIMxITE1G+fPkie77SpUtj9+7dmDVrFnr06IExY8YgIyOjyJ6fSNNYZIny6d69e2jevDn27NmDCxcuYMiQIUX6whVgkSXSFQkJCWjatCnatm2LZcuWFfnPggoVKuCLL77A5MmTi/R5iajw7t+/X2Qrsq9JJBL4+fkhIiICYWFh8PDwQExMTJFmINIUFlmifDh8+DBcXV1Ro0YNhIeHw9HRUZQcDg4OePr0Ke8jSSSie/fuoVmzZmjZsiWWL19e5CX2tUmTJiEsLIz3jCTSM0V5avF/1axZE+fOnUOXLl3g6emJJUuWQK1Wi5KFqKBYZInyIDs7G+PHj0evXr2wePFibNiwASVKlBAtj6WlJSpXrozY2FjRMhAZsvv376N58+Zo1qwZVq1apdF7RedX6dKl8e2332Ly5Mm8IimRnsjMzMSTJ09EK7IAYGRkhJ9++glHjx7F4sWL0bZtWzx48EC0PET5xSJL9BG3b99G48aNcezYMVy+fBkDBgwQOxIAnl5MJJYHDx6gWbNmaNSoEdasWSNqiX1tzJgx+PPPP3Ho0CGxoxBRHjx48AAymQxly5YVOwoaNWqEq1evwtbWFk5OTti/f7/YkYjyRPzfvkQ67LfffoObmxvc3d1x4cIFfPbZZ2JHeoNFlqjoPXz4EM2bN4enpycCAgJ0osQC/ztLY/Lkyfj+++95eiCRHkhMTISdnR1kMpnYUQD87x71W7duxdKlSzFo0CAMHz4cr169EjsW0Qfpxm9gIh2TmZmJ0aNHw8/PD2vXrsXKlSthZmYmdqy3sMgSFa1Hjx6hefPmqFu3LjZs2KAzL0BfGzFiBJKSkhAUFCR2FCL6CDHfH/shffv2RVRUFOLi4uDu7o7Lly+LHYkoVyyyRP/x119/oUGDBrhw4QIiIiLg4+MjdqT3el1k+Z44Iu17/PgxWrRoATc3N2zatEnnSiwAmJqaYtq0afjhhx+QnZ0tdhwi+gBdLbIAUKVKFZw+fRqDBg1CkyZNMGfOHKhUKrFjEb2DRZboX3bs2AF3d3c0adIE586dQ7Vq1cSOlKvatWsjKSkJDx8+FDsKUbH29OlTeHt7w8nJCZs3b9bJEvvaoEGDIJfLsXHjRrGjENEH6HKRBQCZTIbJkyfjzJkz2LhxI5o3b467d++KHYvoLSyyRADS0tIwbNgwjBo1Clu3bsXixYthYmIidqwPKlGiBKpWrcrTi4m06NmzZ2jRogVq1aqFLVu2QC6Xix3pg+RyOX766Sf8+OOPSE9PFzsOEeVC14vsax4eHoiIiMCnn34KFxcXvnWBdAqLLBm8uLg41K9fH0qlElFRUejUqZPYkfKM75Ml0p7nz5/D29sbNWvWRGBgoM6X2Ne6d++OsmXLYsWKFWJHIaJc6EuRBQALCwsEBARgw4YNGDVqFAYOHIjU1FSxYxGxyJJh27RpE+rVq4cOHTrg9OnTqFSpktiR8sXR0ZFFlkgLkpKS4O3tjapVq2L79u0wMjISO1KeSaVSzJ49G3PmzOGLTSIdpU9F9rWuXbsiJiYGDx48gKurK0JDQ8WORAaORZYM0suXLzFw4EBMmDABe/bswZw5c/TqheprCoUCsbGxYscgKlaSk5PRsmVLVKpUCTt27NDLnw2tW7eGo6MjFi5cKHYUIvoPQRD0ssgCQPny5XH06FGMHj0aLVu2xLRp05CTkyN2LDJQEoGXPCUDc/XqVfTq1QvlypVDYGAgypcvL3akAouMjETTpk2RnJwMiUQidhwivZeSkoKWLVuibNmy2LNnD4yNjcWOVGDnz59HmzZtEB8fD1tbW7HjENE/nj17hjJlyiA1NRWWlpZixymwq1evol+/frCwsEBgYCCqV68udiQyMFyRJYMhCAJWr16NBg0aoE+fPjhx4oRel1gAqFWrFl6+fInExESxoxDpvdTUVLRu3Rq2trbYvXu3XpdYAGjYsCG8vLwwZ84csaMQ0b/cv38flpaWel1iAcDFxQXh4eGoV6/em1uTcX2MihKLLBmElJQU9O7dGzNmzMDBgwcxbdo0nb6FRl6ZmZmhWrVqfJ8sUSG9ePECbdq0QcmSJbFnzx6dv2p5Xs2aNQurV69GQkKC2FGI6B/6elrx+5iZmWHp0qUICgrCpEmT0LNnTzx//lzsWGQgWGSp2Lt8+TLc3d2RkpKCqKgoNGvWTOxIGsUrFxMVzosXL9C2bVtYWlpi7969MDU1FTuSxri4uKBz58748ccfxY5CRP8oTkX2tbZt2yI6OhqZmZlwdnbGqVOnxI5EBoBFlootQRCwZMkSeHl5YejQoTh8+DA++eQTsWNpHIssUcG9fPkS7du3h5mZGfbt21esSuxrM2bMwNatW3Hjxg2xoxARimeRBYBPPvkE+/fvx5QpU9CpUydMmDABmZmZYseiYoxFloql58+fo0uXLli4cCGOHTuGSZMmQSotnv/cWWSJCubVq1fo0KEDjIyMsH//fpiZmYkdSStq1qyJQYMGYerUqWJHISIU3yILABKJBCNGjEB4eDhOnDgBT09PXLt2TexYVEwVz1f2ZNBCQ0Ph6uoKQRAQGRmJhg0bih1JqxQKBeLi4niBBaJ8SEtLQ8eOHSGRSPD777/D3Nxc7Eha9cMPP+DAgQOIiIgQOwqRwSvORfa12rVr48KFC2jVqhU8PDywcuVKvk4hjWORpWJDrVZj7ty58Pb2xtixY7F//36ULl1a7Fha99lnnyEtLY0XcyHKo/T0dHTq1Ak5OTk4ePAgSpQoIXYkratYsSJGjRqFKVOmiB2FyOAZQpEFAGNjY8ydOxcHDhzA7Nmz0bFjRzx+/FjsWFSMsMhSsfDkyRO0b98ea9euxdmzZzFmzBiDua+qqakpatSogdjYWLGjEOm89PR0dO7cGZmZmTh8+LBBlNjXJk2ahHPnzuHs2bNiRyEyaIZSZF9r1qwZoqOjYW5uDicnJxw+fFjsSFRMsMiS3jt9+jRcXFxgYWGBiIgI1K1bV+xIRY7vkyX6uIyMDHTt2hWvXr3C4cOHYWFhIXakIlWmTBmMGzcOkydP5il+RCLJzMzEkydPDKrIAkCpUqUQFBSEuXPnonfv3vjyyy+Rnp4udizScyyypLdUKhV+/PFHtG/fHlOnTsXOnTthbW0tdixRsMgSfVhmZia6deuGlJQUHDlyBJaWlmJHEsXYsWNx48YNHDlyROwoRAbpwYMHkMlkKFu2rNhRipxEIsHgwYMRGRmJK1euoG7durh69arYsUiPsciSXnrw4AFatmyJbdu2ITQ0FCNGjDCYU4nfh0WWKHeZmZno3r07nj17hj/++ANWVlZiRxKNpaUlJk+ejMmTJ0OtVosdh8jgJCYmws7ODjKZTOwooqlevTpCQkLg4+ODBg0aYNGiRfx5RAXCIkt659ixY3BxcUGFChVw5coVuLi4iB1JdK+vXMxfBERvy8rKgo+PDx49eoSjR48a7Fkb/zZy5Eg8e/YMO3fuFDsKkcExtPfH5kYul2P69Ok4fvw4li9fjtatWyMxMVHsWKRnWGRJb+Tk5GDy5Mno1q0b5s2bh19//dXg3uOWm08//RRZWVm4c+eO2FGIdEZ2djZ69eqFxMREHDt2DDY2NmJH0gmmpqaYNm0afvjhB2RnZ4sdh8igsMi+rUGDBoiKikL58uXh7OyM3377TexIpEdYZEkvJCQkoGnTpvj9999x6dIlDB482KBPJf4vY2Nj1KxZk6cXE/0jOzsbvXv3xu3bt3H8+HGULFlS7Eg6ZfDgwZBKpdi0aZPYUYgMCovsu6ysrLB582asXLkS/v7+GDJkCF6+fCl2LNIDLLKk8w4cOABXV1fUrl0bly5dgoODg9iRdBLfJ0v0Pzk5OejXrx9u3bqFEydOoFSpUmJH0jlyuRw//fQTfvzxR145lKgIJSYmonz58mLH0Em9evVCdHQ0/vrrL7i5ueHSpUtiRyIdxyJLOisrKwtjx45Fv379sGzZMgQEBMDc3FzsWDqLRZbofyW2f//+uH79Ok6cOIHSpUuLHUln9ejRA7a2tli5cqXYUYgMxv3797ki+wH29vY4efIkhgwZgqZNm2LWrFlQqVRixyIdxSJLOik+Ph6NGjXC6dOnceXKFfTt21fsSDqPRZYMXU5ODgYOHAilUomTJ0+iTJkyYkfSaVKpFLNnz8acOXOQmpoqdhwig8BTiz9OJpNh4sSJCAkJwZYtW9C0aVPcvn1b7Fikg1hkSefs3r0b7u7u8PT0RFhYGGrWrCl2JL3g6OiIa9eu8crFZJBUKhUGDx6Mq1ev4uTJk7C1tRU7kl5o06YNHBwcsGjRIrGjEBV7giCwyOZDnTp1cOXKFTg6OsLV1RWBgYFiRyIdIxEEQRA7BBEAZGRkYOzYsdi+fTvWr1+Pbt26iR1Jr2RnZ6NEiRK4du0aqlevLnYcoiKjUqng5+eHS5cu4fTp0yhbtqzYkfTKuXPn0LZtW8THx/MPAERa9Pz5c5QuXRqpqamwtLQUO45e+f333+Hv749WrVphxYoVvAo9AeCKLOmImzdvwtPTE1euXEFERARLbAEYGRnhs88+Q2xsrNhRiIqMWq3GkCFDcOHCBZw6dYoltgAaNWqEJk2aYM6cOWJHISrWEhMTYWlpyRJbAJ06dUJMTAyePXsGFxcXhISEiB2JdACLLIkuMDAQdevWRcuWLRESEoKqVauKHUlv8X2yZEjUajWGDRuG8+fPIzg4GOXKlRM7kt6aNWsWVq1ahYSEBLGjEBVbPK24cOzs7HD48GGMGzcObdq0wZQpU3gvbAPHIkuiefXqFfz9/fH1119j+/btmD9/PoyNjcWOpddYZMlQqNVqjBgxAmfOnEFwcDBvZ1FIrq6u6NKlC2bMmCF2FKJii0W28KTS/2vv3gNqvv8/gD/POd2TinItbWFSKSG3aDPXL5t7ExqhzKWNjS9bc51t9jU/donJNSy3WG5zTy7llikkM2RDNjW66F7nnN8fxtpUSqfe53PO8/GfnD49eb3O53NevT8XOd577z2cPXsWu3fvhpeXF65fvy46FgnCQZaEuHLlCtq3b4/r168jISEB/fr1Ex1JJ3CQJX2gVqsxefJkREVFITo6mh8MNeSTTz7Bxo0b8csvv4iOQqSTOMhqjqurK86dOwcvLy+0adMGa9asAW/7o384yFKNUqvVWLt2LTp06IDBgwfj6NGjsLOzEx1LZ7i4uODnn3/mM9dIZ6nVagQFBeHgwYOIjo7m/kODmjdvjlGjRmHOnDmioxDpJA6ymmViYoKlS5dix44dmDVrFoYMGYIHDx6IjkU1iIMs1ZhHjx7Bz88PH330ESIjI7FgwQIYGBiIjqVTmjZtCrVajZs3b4qOQqRxarUaU6ZMwY8//ojo6Gg0adJEdCSdM2fOHOzevRvx8fGioxDpHA6y1aNXr164fPkyVCoV3NzccOTIEdGRqIZwkKUaER8fj7Zt2+L+/fu4ePEievbsKTqSTjIwMICTkxNPLyado1ar8f7772PXrl2Ijo6Gg4OD6Eg6yc7ODhMnTsTHH38sOgqRzuEgW31sbGwQGRmJefPmYeDAgZg2bRoKCgpEx6JqxkGWqpVarcby5cvRpUsXjB49GgcPHkSDBg1Ex9JpvE6WdI1arcb06dOxY8cOREdH887m1eyjjz5CTEwMH29BpGEcZKuXTCZDYGAgLly4gOPHj6N9+/b8PKTjOMhStcnIyICPjw8+//xz7N+/Hx9//DEUCoXoWDqPgyzpErVajZkzZ2Lr1q04duwYHB0dRUfSeTY2Npg2bRqCg4N58xQiDSkoKEBaWhoH2Rrwyiuv4NSpU+jXrx/at2+Pb7/9lvsyHcVBlqrFuXPn4OHhgdzcXCQkJMDb21t0JL3h6urKQZZ0glqtRnBwMMLDwxEdHY2mTZuKjqQ33n//fVy9ehX79+8XHYVIJ/z+++9QKBSoX7++6Ch6wcjICJ9//jn27duHL7/8Ev369cMff/whOhZpGAdZ0ii1Wo0lS5agW7dumDx5Mvbu3QsbGxvRsfSKi4sLrl27xoeEk6Sp1WrMnj0bYWFhOHr0KJo3by46kl6pXbs2goODERwcDJVKJToOkeSlpKSgQYMGPDOthr366qu4dOkSLC0t4ebmhr1794qORBrEQZY05sGDB+jfvz+++eYbREVFYfr06ZDL2WI17eWXX4ZcLseNGzdERyF6YfPmzcPq1asRHR2NFi1aiI6jlyZNmoQHDx4gIiJCdBQiyeP1seJYWVlh06ZNWLJkCUaOHIlJkyYhNzdXdCzSAE4ZpBExMTFo3bo1DA0NER8fj44dO4qOpLcUCgVatmzJ04tJsubPn48VK1bg6NGjcHJyEh1Hb5mYmGDu3LmYPXs2z/AgqqKUlBQ0atRIdAy9JZPJ4Ofnh4SEBFy6dAlt27bFhQsXRMeiKuIgS1WiUqmwcOFC9O7dGzNnzsSOHTtgbW0tOpbe4w2fSKo+/fRTLFu2DEePHoWzs7PoOHrP398fABAWFiY0B5HU3bt3jyuyWuDll1/GsWPHMGLECHTp0gVffvklL5+QMJmat/GiF3T//n28/fbbSE5OxrZt29CmTRvRkQiAUqnEjBkzcObMGfTp0wfFxcWYP3++6FhEz7Vw4UIsWbIER48eRatWrUTHob9s3boV06ZNw40bN2BiYiI6DpGk/O9//8ODBw8QFRUFJycnvPvuu3B3d4epqanoaHrv7NmzGDlyJBwcHLB+/XrY2dmJjkSVxEGWXkhUVBT8/Pzw2muvITQ0FLVr1xYdiQBERERg5MiRUCqVUKvVkMvlsLOzw6+//io6GlG5Fi1ahEWLFiEqKgru7u6i41AJKpUKbdu2hZ+fH1555RVs27YN69atg4GBgehoRFqvQ4cOiIuLg0wmg6GhIQoKCjB//nzMmTNHdDQC8OjRI0ydOhWRkZEIDQ2Fj4+P6EhUCTy1mCpFqVRi7ty5GDBgABYsWIBNmzZxiNUiHTt2hJGREVQqFdRqNRQKBXx9fUXHIirX//3f/+F///sfjhw5wiFWC8nlcgwbNgwzZ87EkCFD8P333yM7O1t0LCJJmDhxIkxNTaFSqVBQUIBatWphwoQJomPRXywsLLBmzRqsWrUK77zzDsaMGYNHjx6JjkUVxEGWKiwlJQXdu3dHREQETp8+jYCAAMhkMtGxqAR7e3uEh4fD0NAQwONHmAwcOFBsKKJ/Wb9+PRISEgAAS5cuxWeffYbDhw+jdevWQnNR6d544w3MmTMHSqXy6U2fePMnoooZOnQolEolgMfPNv32229Rr149wano34YMGYJLly7h9u3baN26Nc6cOSM6ElUAB1kq1ZOd7hP79+9H69at4ejoiLi4OF6/psUGDBiAMWPGAAAMDQ3Rvn17wYmI/paXl4d33nkHXl5emDZtGj755BMcPnyY19hrsTZt2uDfVyFxkCWqmFq1aqFfv34AHr+XRo8eLTgRlcXOzg6HDx/GpEmT0L17d3zyyScoLi4WHYvKwUGWnpGTk4MmTZpg9erVKCoqwsyZM/HWW29hyZIlWLt2LczNzUVHpOf4+uuvUbt2bbRs2ZLP8iWtcvDgQcjlcuTm5mLJkiVYsmQJ2rZtKzoWlePJLxtsbGyenoXDQZao4kaMGAEACA8P55lsWk4ul2PatGmIjY3Fli1b8OqrryI5ORkAsG7dOgQHBwtOSCXxZk96IDktG5HxKbiTnotH+cWwMDGAvbUZBnk0hqNtrWde/+WXX+Ljjz8GALRs2RLA47tW8nmO0nIq8SaOXM/Ew0JZhepOVBUV3c/4+Phg+/btT/9samqKM2fOwM3NTURsqoSHDx9iwIABiImJQWJiIlxcXCp9fCHSF/9+bxjJlGjWwJrvDQnJzc3FjBkzsHHjRsycORPz5s2DSqXC5cuXn34+/jfuE2sWB1kdpVSpceTqfaw6mYz42xmQy4Ei5d+lNlTIoFIBHk2sENjVET1a1odCLkN2djYaNWr09EJ3CwsLJCcnw8bGRtQ/hSrhRetO9CIq229dHa1gZVkbRUVFMDIyglKpRLNmzbB+/Xp06NBB4L+EKkqtVmPzlq2wdvXGmthfuZ8hKoHHYN0UGRkJHx8fKJVKGBgYoHfv3ti7d+/Tv2fdxeEgq4Oy8oswLiwOl1IyUVD8/Ic8GxvI4WZnibWjPbF00UJ88sknT6+RlcvlePvttxEWFlbNqamqqlJ3CxPDGkhIuuRF+q2BUQFOfjoCDW2sMWHCBPj6+qJ58+Y1kJY0hfsZotLxvaG73n33XaxatQoFBQUAAIVCgdjYWHTo0IF1F4yDrI7Jyi/CoOWxuPMwF4XKipfWSCFDYytTnJzdH8r8bMhkMpiYmMDJyenpYxdIe1Wl7vZ1zBA5yQu1uUOlCqpKv9maKbD/g9fZbxLE/QxR6fje0G1OTk64du0ajI2NoVarUVhYCDs7O1y5nsy6C8ZBVocoVWr4rjyNi3czKvWGesJIIYNZfhrmdrFCu7ZtYGdnx5sSSIAm6u5ub4UtgZ14qgs9F/tNP7HuRKXje0M/ZGRk4Nq1a/j5558RExODK0lX0fjtRay7YLydqQ45cvU+LqVkvtAbCgAKlWrkmdaD+SsdYG9vzyFWIjRR90t3MxH1830NJyNdxH7TT6w7Uen43tAPVlZW6NChA0aPHo1Vq1Zh7srtrLsWMBAdgDRn1cnkUs/PzzgZjsxTWyEzMHr6NdNm7WE7YMYzry0sVmHVyWT0cm5QrVlJc0qre/qxMOTdjENxZirkhiYwbtIK1t3GwKC2banbYN2pokrrt4yYTchJPAplXhZkcgMYNWgK69fGwKi+Y6nbYL9JT6l1r8SxBWDdSTfxs5d+KrPulTgesu5Vx0FWRySnZSP+dkaZf2/c2AkN/BY9dztqABd+y8CtP3Pwsg2fF6vtyqt73X7vw8jWAeqiAjw49B1St3+CRmO/LfW1rDtVRFn9Zt7SGxbt+kNhUgtqZREend+D+1vnwC5oPWRyxTOvZ79JS3n7mYoeWwDWnXQPP3vpp/LqXpnjIetedTy1WEdExqdArqFqyuVAZPxdzWyMqlVZdbd+zR/GDZpBpjCE3KQWLDsMQVHqLSjzs8vcFutOz1NWvxnWtYPC5K/n46kByBVQ5WZAxX7TCTy+EJWO7w39VF7dK3s8ZN2rhiuyOuJOeu4/nln1b4X3b+LO1yMgMzSGsZ0zrLzfhqFV6acyFCnVuJOeV11RSYOeV/cn8m5dgKJ2vb93rqVg3el5yuu33Btx+HPPYqgLcgDIYOE5AAozyzK3xX6TjvLqXpljC8C6k27hZy/99Ly6V+Z4yLpXDQdZHfEov7jMvzNz8kItt55Q1LaFMvsB0qPXIXXLLDQc+y3kRqalfk9WXlF1RSUNKq/uT+T9moDM2M2wHRT83Ney7lSecvczzTzR5P2tUOY9Qs7lKChq2zx3e+w3aSir7i9ybAFYd9Id/Oyln5732auyx0PW/cXx1GIdYWFS9u8kjGxfgoFlPchkMhhY2MCm71QUP3qAgpSrZX5PbVM+10oKyqs7AOTeOIe0yIWweWMaTB3bPnd7rDuV53n9BgAKUwtYePbHg/3foPB+crmvZb9JQ1l1f5FjC8C6k+7gZy/9VJFjIVDx4yHr/uI4yOoIe2szGCoq+LgcGR4/WqeMRwgbKmSwty77t+mkPcqre/aVaPy5ZzFsB8yAWYvOz90W607PU+H9jFoNKJUoSr9X5kvYb9JR4bo/59gCsO6kW/jZSz9Vqu7POR6y7lXDQVZHDPJoDNWzdwEHAORcPQllbiYAQJmTjgf7voHczArGjVuW+nqlSo1BHnbVFZU0qKy6Z/20B+mHVqDe0DkVWokFWHd6vjL7LW4XlDnpAABlbiYeHlwOKAxgbOdc5rbYb9JRVt0re2wBWHfSLfzspZ/Kq3tlj4ese9XwGlkd4WhbCx5NrHD+t/Rn/i7nSjQeHvoO6qICyE3MYWzvivrDP4Xc2OyZ18oAtHWw5m3AJaKsuqcfDgXkCqRum/ePr9d7ax5M7F2f2Q7rThVRVr/l/5qAzNMRUBflQW5kBqOGzVHf91MY1KpT6nbYb9JSVt0rc2wBWHfSPfzspZ/Kq3tljoese9VxkNUhgV0dcTkl/pkHNNcbOqfC2zAykCOw67MPbSbtVVrdHT7cW6ltsO5UUaX1Wz2fuZXaBvtNWn744Qf8sjsSxm1H/LPulTi2AKw76SZNfPaCqhj9Xyn7qQKkfcqseyWOh9wnVh1PLdYhPVrWh1tjSxhV9Lz9fzGQAe52lujuVF/Dyag6VbXuRgo5604Vxn7TH3/88QeGDh2KwMBA/HdEH9adqBRV3yfKYKXKxKQBXfDdd99BVdY5q6RVeCzUDhxkdYhCLsMaf0/Y1zGr9BvLQKZG/oMU9K11Gwr5i70pSYyq1N1IIYd9HVOsGe3JulOFsN90n1qtxoYNG+Ds7AyFQoGrV6/ibb+RrDtRKaq+TzTDiQXDsTMyEl988QV69uyJX3/9tXrCksbwWKgdOMjqmNomhoic5AV3eysYKWR43ttDBsDYQI42DnUQ0r8J3ps4HiEhITURlTSoZN2NDeQVrntre0vsnOQFCxPe+p0qjv2mu27fvo2+ffviww8/xNq1a7F161bUq1cPAOtOVBZNvDe6d++OxMRENG/eHG5ubggNDYW6nDuAk3jcJ4onU/NdopOUKjW6+k4CnLrjfrEZ5HKgSPl3qQ0VMqhUQBsHKwR2dUR3p/pQyGU4e/Ys+vbti8mTJ2P+/PmPbxVPkqFUqRH1832sPJGM+NsZFa470Ytgv+kOlUqFFStW4MMPP4SPjw8WL14Ma2vrUl/LuhOVTlPvjcOHD2PcuHFo0aIFVq9eDQcHh5r8Z1AlcZ8oDgdZHfXLL7/Azc0Nv/32G3Lk5tiZkII76XnIyitCbVND2FubYpCHXal3Srt69Sp69eqFfv36YdmyZVAoFAL+BVRVyWnZlao7UVWw36Trl19+QUBAAO7cuYOVK1eiZ8+eFf7eJ3Xfd/wsHmbn49XO7Vl3Ijx+b6w8lICw7XvQb+DQSu8Ts7KyMH36dGzZsgX/93//h4CAAC4uSACPhTWLg6yOmjp1KtLS0hAeHv5C33/nzh306tULLi4uCA8Ph7GxsYYTEhGRSMXFxViyZAnmz5+PgIAAfPbZZ6hV68XunLp06VLExsZi+/btGk5JJF3R0dEICAjAzZs3X3gbBw8eREBAAJydnbFq1So0adJEgwmJpI3XyOqg7OxsrFu3DkFBQS+8DXt7e8TExODu3bvo27cvsrKyNJiQiIhEunjxIjp27Ih169bh8OHD+Prrr194iAUAc3Nz5OTkaDAhkfSlpqY+vcb8RfXu3RuJiYmwt7dHq1atsGbNGl47S/QXDrI66Pvvv0ezZs3QsWPHKm2nbt26OHLkCAwNDdGtWzekpqZqKCEREYlQUFCA2bNno1OnTujduzfi4+PRuXPnKm+XgyzRs1JTU2Fra1vl7VhaWmL16tXYsmUL5s6di759++Lu3bsaSEgkbRxkdYxarcayZcsQFBSkkWspatWqhd27d6NFixbw8vLCrVu3NJCSiIhq2pkzZ9CmTRvs3bsXsbGx+Oyzz2BiYqKRbZuZmXGQJfqXtLS0Kq/IlvSf//wHiYmJaNiwIVxdXbFu3TquzpJe4yCrY06cOIF79+7B19dXY9s0MjLC999/j759+8LLywuXL1/W2LaJiKh65eTk4P3338frr78OPz8/nDt3Dh4eHhr9Gebm5sjNzdXoNomkTlMrsiVZWVlh7dq12LRpE2bNmoU33ngDKSkpGv0ZRFLBQVbHhISEYNy4cTA1NdXoduVyOb766isEBQXB29sbMTExGt0+ERFp3tGjR+Hm5oa4uDhcuHABH330EQwNNf/sQp5aTPQsTa/IltS3b18kJibC1tYWLi4uWL9+PVdnSe9wkNUhd+/exe7duzFx4sRq2b5MJkNwcDAWLVqEPn36YM+ePdXyc4iIqGoyMzMRGBiIAQMGYOrUqThx4gScnJyq7edxkCV6VnWsyJZkbW2NsLAwfP/99/joo4/w5ptv4t69e9X284i0DQdZHbJy5Ur06tULL7/8crX+nMDAQGzYsAHDhw9HWFhYtf4sIiKqnD179sDZ2Rm//fYbLl++jHfffRdyefUe7jnIEj2rOldkS3rjjTeQmJiIOnXqwMXFBRs3buTqLOkFA9EBSDMKCgoQGhqKDRs21MjPGzx4MKytrTFw4ECkpaXhv//9b438XCIiKl1aWhree+89HDhwAEuXLsXo0aM1ctO/ijAzM0NBQQGUSiUUCkWN/EwibVfdK7Il1alTBxs2bMDu3bvxzjvvICIiAqGhoWjYsGGN/HwiEbgiqyN27NgBS0tL9OzZs8Z+Zrdu3XDs2DEsXrwY//3vf/nbPyIiAdRqNTZv3gxnZ2cUFBQgKSkJ/v7+NTbEAo9XZAHwhk9EfykqKkJ6enqNrMiW1L9/f1y5cgW1a9eGi4sLwsPD+fmMdJZMze7WCZ07d8awYcMwZcqUGv/ZN27cQK9eveDt7Y3Vq1fDwIAL/URENSElJQUTJkzAuXPnEBISgqFDh9boAPtEUVERjIyM8Pvvv6NBgwY1/vOJtM3vv/+ORo0aIT8/H8bGxkIy7Ny5E++88w46deqEFStW8L1JOocrsjrgwoULuHjxIkaPHi3k5zdr1gyxsbGIj4/HoEGD+Bt5IqJqplarsWrVKjg7O8Pa2hpJSUnw8fERMsQCgKGhIQwNDXmdLNFf0tLSYGlpKWyIBYCBAwciKSkJZmZmcHFxwebNm7k6SzqFg6wOWLZsGd5++21YWVkJy9CwYUMcP34cmZmZ6N27N9LT04VlISLSZTdv3kT37t2xYMECbNmyBRs2bEDdunVFx+INn4hKSE1NrfHTiktTt25dbNq0CatWrcKUKVMwZMgQ3L9/X3QsIo3gICtxDx48wKZNmzB58mTRUWBlZYWDBw+iTp068Pb25i3giYg0SKlUYsmSJXB3d4eTkxMSExPxn//8R3Ssp8zMzDjIEv2lJm/0VBGDBw9GUlISjIyM4OLigq1bt3J1liSPg6zErVu3Dh06dECrVq1ERwEAmJqaYseOHfD09ETnzp3xyy+/iI5ERCR5V65cgZeXF7777jvs27cPy5cvR+3atUXH+gdzc3NeWkL0l5p69E5l2NjYYMuWLVixYgWCgoLg4+OD1NRU0bGIXhgHWQlTKpVYvny5VqzGlmRgYIA1a9bA19cXXbp0wU8//SQ6EhGRJBUWFmLBggXw9PSEt7c3Ll26BG9vb9GxSsVTi4n+pm0rsiUNHToUSUlJkMvlcHFxQUREhOhIRC+Et5eVsP3796OgoAADBw4UHeUZMpkMX3zxBWxtbfH6668jMjISr7/+uuhYRESScf78eYwdOxYAcOLECbRr105wovJxkCX6mzauyJZka2uLbdu2Ydu2bZg4cSIiIiKwbNkyrR2+iUrDFVkJCwkJwYQJE2BoaCg6SpmmTZuGb7/9Fm+++Sa2b98uOg4RkdbLy8vDjBkz4O3tjaFDh+L8+fNaP8QCHGSJStLmFdmS3nrrLSQlJUGlUsHFxQU7duwQHYmowrgiK1HXr1/HsWPHEBYWJjrKc40aNQp169bFsGHD8Oeff2LChAmiIxERaaUTJ04gICAA1tbWiIuLg4uLi+hIFcabPRH9TdtXZEuqV68eIiIisHXrVowfPx4REREICQmBjY2N6GhE5eKKrEQtX74cgwcPlszDrfv164eDBw8iODgYCxYs4J3yiIhKyMrKwuTJk9G3b19MnDgRp06dktQQC/BmT0QlSWVF9gmZTAZfX18kJSWhsLAQLi4u+OGHH0THIioXB1kJysnJwbp16xAUFCQ6SqV4eXnhxIkTWLFiBd577z2oVCrRkYiIhNu/fz9cXV1x9epVXLx4Ee+//z4UCoXoWJXGU4uJ/ialFdmS6tevjx07dmDp0qUIDAzEiBEj8ODBA9GxiErFQVaCwsPD4ejoiE6dOomOUmmurq44deoUDh06hJEjR6KwsFB0JCIiIR48eIBRo0bB19cXs2fPRlRUFJo2bSo61gvjIEv0WEFBATIzMyW1IluSTCbDiBEjcOXKFeTm5sLFxQU7d+4UHYvoGRxkJUatViMkJASTJ0+GTCYTHeeFODg4ICYmBjdu3MAbb7yB7Oxs0ZGIiGrU9u3b4ezsjPT0dFy5cgWBgYGS3ac/wUGW6LE///wTACR/jWmDBg0QGRmJxYsXY+zYsfDz88PDhw9FxyJ6ioOsxJw8eRJ3797F8OHDRUepEltbWxw9ehQqlQqvv/76050+EZEu+/333zFkyBBMnDgRX331FXbv3g07OzvRsTSCN3sieiw1NRV16tTR6qdKVJRMJoOfnx+uXLmCrKwsuLi4YPfu3aJjEQHgICs5ISEhGDduHMzMzERHqTILCwv8+OOPeOmll9ClSxfcvn1bdCQiomqhVquxbt06ODs7w8jICElJSRg+fLjkV2FL4s2eiB6T2o2eKqJhw4bYtWsX/ve//2H06NEYNWoU0tPTRcciPcdBVkJSUlKwa9cuTJw4UXQUjTE2NsbmzZvx+uuvo3PnzkhKShIdiYhIo3799Vf06dMHs2bNwvr167F582ad+5AL8NRioiekeqOn55HJZBg1ahQSExPx8OFDuLi4YO/evaJjkR7jICshK1euRM+ePeHo6Cg6ikYpFAosW7YMAQEB6Nq1K06fPi06EhFRlalUKoSEhKBVq1Zo0qQJrly5gv79+4uOVW04yBI9posrsiU1btwYe/bsweeffw4/Pz/4+/sjIyNDdCzSQxxkJaKwsBChoaGSe+RORclkMsybNw8LFixAr169sH//ftGRiIhe2LVr1+Dt7Y0lS5Zg586dWLVqFaysrETHqlYcZIke09UV2ZJkMhn8/f2RmJiI1NRUuLi4YN++faJjkZ7hICsRP/zwAywsLNCrVy/RUarVpEmTsGbNGvj4+CA8PFx0HCKiSikqKsLChQvh4eEBT09PXL58Gd27dxcdq0bwZk9Ej+n6imxJdnZ2+PHHH7FgwQIMHz4cY8eO5eos1RgOshLx5JE7crnul+ytt97Czp07n97Vk4hIChISEtChQwds3LgRR48exdKlS2Fubi46Vo3hzZ6IHtOHFdmSZDIZxo4di8TERNy7dw+urq44cOCA6FikB3R/KtIBCQkJiI+Ph7+/v+goNaZHjx6IiorCZ599huDgYKjVatGRiIhKlZ+fj1mzZqFz587o168f4uPj0bFjR9GxahxPLSZ6TJ9WZEuyt7fH/v37MW/ePAwbNgwBAQHIzMwUHYt0GAdZCQgJCYGfn5/OX1/1b56enoiJiUF4eDgCAwNRXFwsOhIR0T+cOnUKHh4eOHDgAE6fPo0FCxbA2NhYdCwhOMgSPaZvK7IlyWQyBAQE4PLly7h9+zZcXV1x6NAh0bFIR3GQ1XIPHz7Epk2bMHnyZNFRhGjRogVOnTqFM2fOwMfHB/n5+aIjEREhOzsbU6ZMQc+ePTFmzBicOXMG7u7uomMJZWZmhuLiYhQWFoqOQiRUamqq3g6yTzRp0gQHDx7E7NmzMXToUIwfPx5ZWVmiY5GO4SCr5datWwdPT0+4ubmJjiJM48aNceLECdy/fx99+vThaSpEJNSRI0fQqlUrXLhwAfHx8ZgxYwYMDAxExxLuyfXAvE6W9FleXh6ys7P18tTif5PJZBg/fjwuX76M5ORktGrVCocPHxYdi3QIB1ktplQqsXz5cr1djS2pTp06OHLkCMzNzfHqq6/ijz/+EB2JiPRMRkYGxo0bh0GDBmH69Ok4fvw4XnnlFdGxtIaZmRkA8PRi0mtpaWmQyWSoW7eu6Chaw8HBAYcPH8ZHH32EwYMHY8KECXj06JHoWKQDOMhqsQMHDiAvLw+DBg0SHUUrmJmZYefOnXBzc4OXlxdu3rwpOhIR6Yldu3bB2dkZKSkpSExM1Ju7yFeGQqGAiYkJB1nSa6mpqahbty4UCoXoKFpFJpNhwoQJuHz5Mq5fv45WrVohKipKdCySOB6FtdiyZcswYcIEGBoaio6iNQwNDREWFoaBAwfCy8sLCQkJoiMRkQ5LTU3FsGHDMGbMGHzxxRfYv38/HBwcRMfSWnyWLOk7fb7RU0W89NJLOHz4MGbMmIGBAwdi0qRJyM7OFh2LJIqDrJa6ceMGoqKiMH78eNFRtI5cLsfixYvxwQcf4LXXXsPx48dFRyIiHaNWqxEeHg5nZ2colUokJSVh1KhRkMlkoqNpNT5LlvSdvj56pzLkcjkmTZqEixcv4urVq2jVqhWio6NFxyIJ4iCrpZYvX47BgwejQYMGoqNoJZlMhhkzZmDJkiXo168fdu7cKToSEemIO3fu4M0338S0adMQGhqK7du3c19cQXwED+k7rshWnKOjI6KiojBt2jS8+eabCAoK4uosVQoHWS2Uk5ODtWvXIigoSHQUrTd27FiEh4fDz88Pa9asER2HiCRMpVIhNDQUrq6usLW1RVJSEoYMGSI6lqRwkCV9xxXZypHL5QgKCsLFixdx+fJluLm58Uw7qjA+L0ALbdq0CS+//DI6d+4sOookDBgwAPv27UP//v2RlpaGmTNn8vQ/IqqUGzduICAgALdu3cK2bdvQu3dv0ZEkiYMs6bu0tDS89NJLomNITtOmTREdHY2QkBD069cPY8eOxcKFC58+1ouoNFyR1TJqtRohISEICgriMFYJ3t7eOH78OL766itMmzYNKpVKdCQikgClUonFixfD3d0drq6uSExM5BBbBbzZE+m71NRUnlr8guRyOd577z0kJCQgPj4e7u7uOHHihOhYpMU4yGqZmJgY3LlzB8OHDxcdRXLc3d1x6tQp7N69G6NHj0ZRUZHoSESkxRITE9GpUyesWrUKBw4cQEhICCwsLETHkjTe7In0XVpaGk8trqJmzZrh+PHjCAoKQt++fTF16lTuV6hUHGS1TEhICMaOHfv0wfJUOY6OjoiNjUViYiIGDBjAlQEiekZhYSHmz5+P9u3bo3v37khISEDXrl1Fx9IJPLWY9B1XZDVDLpdj6tSpiI+Px/nz5+Hu7o6YmBjRsUjLcJDVIvfu3cPOnTsxceJE0VEkrX79+jh27Bjy8vLQo0cPPHz4UHQkItIScXFxaNu2LSIjI3Hy5EksXLgQpqamomPpDA6ypO+4IqtZzZs3x/HjxzFx4kT07t0bH3zwAVdn6SkOslpk5cqV6NmzJ5o2bSo6iuRZWlpi//79aNiwIbp27Yq7d++KjkREAuXm5mL69Ol49dVX4evr+3SgJc3iNbKkz3JycpCbm8sVWQ1TKBT44IMPcOHCBZw5cwatW7fGqVOnRMciLcBBVksUFhYiNDQUkydPFh1FZ5iYmCAiIgJeXl7o3Lkzfv75Z9GRiEiA48ePw93dHbGxsTh//jw+/vhjGBoaio6lk3iNLOmztLQ0KBQKWFtbi46ik1q0aIGTJ09i/Pjx6NmzJ6ZPn468vDzRsUggDrJa4ocffoC5uTnvlqlhCoUCoaGhGDVqFLp06YJz586JjkRENSQrKwsTJ05Ev379EBQUhJiYGDg7O4uOpdN4ajHps9TUVNjY2EAu58fr6qJQKDB9+nT89NNPiImJgYeHB06fPi06FgnCd5qWCAkJweTJk7nzqwYymQyffvopZs+ejR49euDQoUOiIxFRNdu3bx9cXFxw/fp1XLp0CVOmTIFCoRAdS+dxkCV9xutja46TkxNiY2MxduxY9OjRAzNmzEB+fr7oWFTDODVpgSfPy/L39xcdRadNmTIF3333HQYNGoQtW7aIjkNE1eDPP/+En58fRowYgXnz5uHw4cNwdHQUHUtv8BpZ0me8Y3HNUigUmDFjBuLi4nD8+HF4eHjg7NmzomNRDeIgqwWWLVuGkSNH8pqKGjBy5Ejs2LEDgYGBCAkJER2HiDRErVZj27ZtcHZ2xqNHj5CUlIRx48ZBJpOJjqZXeI0s6bO0tDQOsgI4OzsjNjYWo0ePRrdu3fDhhx9ydVZPcJAV7OHDhwgPD+dNnmpQnz59cOTIEcydOxdz586FWq0WHYmIquDevXsYPHgwgoKC8O2332Lnzp1o1KiR6Fh6iacWkz5LTU3lqcWCGBgY4MMPP0RcXByioqLQtm1bxMXFiY5F1YyDrGDr1q1Du3bt4O7uLjqKXunQoQNiYmKwdu1aTJo0CUqlUnQkIqoktVqNtWvXwsXFBWZmZkhKSsKwYcO4CisQB1nSZ1yRFc/FxQWnT5/GyJEj8eqrryI4OBgFBQWiY1E14SArkEqlwvLlyxEUFCQ6il5q2bIlYmNjcezYMfj6+nJHRyQht27dQq9evTBnzhxs3LgR4eHhsLGxER1L7/EaWdJnXJHVDgYGBggODsa5c+dw6NAhtG3bFufPnxcdi6oBB1mBDhw4gLy8PAwaNEh0FL3VpEkTnDx5Erdv30bfvn2RlZUlOhIRlUOpVOKbb76Bm5sbmjZtiitXruCNN94QHYv+wmtkSZ/xZk/axdXVFadPn4avry+8vb0xa9YsLlroGA6yAoWEhOCdd96BoaGh6Ch6zcbGBlFRUTAwMEC3bt2QmpoqOhIRleLq1avw9vbGN998g927d2PFihWwtLQUHYtKeHJqMe89QPqIj9/RPoaGhpg1axbOnDmDffv2oV27drhw4YLoWKQhHGQFuXHjBqKiojB+/HjRUQhArVq1sGfPHrzyyivw8vLCrVu3REcior8UFRXh888/R7t27dCpUydcunQJ3bp1Ex2LSlCr1UhKSsKVK1egUqkQERGBiIgI5OXliY5GVK3y8vKwYcMG/PDDD/jjjz+Qk5ODzMxM0bHoX9zc3HD27Fn4+PigS5cumDNnDgoLC0XHoiqSqflr0xrVrl07ODs7Q61Wo6ioiM8z1TIqlQpTpkzBjh07cPDgQbRq1Up0JCK9Fh8fj7Fjx6KoqAhr165F+/btRUeiUly7dg1OTk4wMjJCYWEhTExMkJ+fj59//hktWrQQHY+o2vz222946aWXnva8QqGASqXC5cuX4eLiIjoeleLixYvw9/eHSqVCWFgYPDw8REeiF8QV2Rp2/fp1bNq0Cd9//z0uXLiArVu38hQsLSKXy/HNN99g0qRJ8Pb2RkxMjOhIRHopPz8fwcHB8PLywoABA3DhwgUOsVrsydksxcXFAB7Xz9PTk0Ms6TwHBwd4eno+fW6pSqVCq1at0LJlS8HJqCzu7u44e/YsBg0aBC8vL8ydO5ersxLFFdkaZm9vj7t37z79s0KhwK1bt2Bvby8wFZVm5cqV+OCDD7B582a8+eabouMQ6Y3Y2FiMGzcOFhYWWLt2Lc+MkIiEhAR4enqiuLgYRkZGiIiIQP/+/UXHIqp2mzZtwtixY1FQUAADAwOcO3eOq3wSER8fD39/f8hkMqxfv56Pw5QYrsjWsCc3JpHJZDAzM8OhQ4c4xGqp8ePHY/369Rg+fDjCwsKgVCoxbNgwLFmyRHQ0Ip2UnZ2N9957D7169UJAQABOnz7NIVZCWrduDR8fHwCAtbU17yZNemPw4MFPn18dGBjIIVZCPDw8EBcXh/79+6NTp06YP38+ioqKRMeiCuKKbA1r3bo1Ll68iAYNGiA6OhpOTk6iI9FzREdHY8CAAXjllVeQkJCAOnXq4Pfff4dCoRAdjUiyMjIyYGVl9fTPhw4dwvjx4+Hg4IDVq1ejefPm4sLRC7t79y6aNGmC6dOnY9GiRaLjENWYXr164dixY0hLS+Pd1CXqp59+gr+/PwwNDREWFgY3NzcAj+9GnZeXhyZNmghOSP/GFdkaplQqUa9ePVy6dIlDrER069YNgwYNwk8//QSlUomsrCxERUWJjkUkWVFRUahbty5Onz6N9PR0jBkzBkOHDsWHH36I6OhoDrESZmdnh6NHj+Kzzz4THYWoRm3cuBFHjx7lECthbdu2xfnz59G3b1907NgRCxYsQF5eHrp37w5vb2+u1GohrshWk+S0bETGp+BOei4e5RfDwsQA9tZm6N3CGi0aWfPZsRKyceNGjBo16h9f69+/P3bt2vXMa8uq+yCPxnC0rVVTkYlqTGV7vqioCE5OTkhOTka9evUgk8nQpk0bhIaG8jILieP+j/QNe153nT9/Hv7+/nj48CEePnwImUyGRYsW4d133y3ze9gPNY+DrAYpVWocuXofq04mI/52BuRyoEj593+voUIGlQrwaGKFwK6O6NGyPhRymcDEVBEXL17EwoULceDAAeTm5qKoqAgymQx3795Fo0aNWHfSO1Xp+a+//hozZ85EQUEBgMe/FNq5c+fT68tIWrj/I33Dntcf8fHxaNeuHVQqFQDA3Nwct2/fRp06dZ6+hv0gFgdZDcnKL8K4sDhcSslEQbHqua83NpDDzc4Sa0d7wsKEq7NSoFKpEB8fjx07dmDNmjXYunUr2nT0Yt1Jr1RlX5eXlQ57e/t/POZALpfj4sWLcHV1rc7YVA143CN9w57XL56envjpp5/+8ZhMX19fbN68GQD7QRtwkNWArPwiDFoeizsPc1GorPh/p5FCBvs6Zoic5IXabGjJYd1J31S15w2jv8bBvTsBPP7NdoMGDeDg4IClS5c+vakGSQP3f6Rv2PP6JywsDDExMbh27RqSk5Pxxx9/QKVSobi4GDlFKvaDFuAgW0VKlRq+K0/j4t2MSjXyE0YKGdztrbAlsBNPNZAQ1p30jSZ6vmV9M3zcqRZcWraEubl5NaSkmsD9H+kb9jwBj8/My87OhnktC/aDljAQHUDqjly9j0spmf9o5IyYTchJPAplXhZkcgMYNWgK69fGwKi+4zPfX6hU49LdTET9fB+9nBvUZHSqgtLqnn4sDHk341CcmQq5oQmMm7SCdbcxMKht+8z3s+4kNaX1PABknAxH5qmtkBkYPf2aabP2sB0w4x+vK1Sq8XNqHjLMnDjESlyZvVDBYx/3fyQ1ZfV8TtJxPLrwIwpTb0FdmIcmM3ZBJn/20Xzsed0gl8tRu3ZtHLzyR6n9UFLqjk+Rd/0M6vl+CtOXWv/j79gPmsNBtopWnUx+5rx485besGjXHwqTWlAri/Do/B7c3zoHdkHrS9/BFauw6mQym1lCSqs7ANTt9z6MbB2gLirAg0PfIXX7J2g09ttSt8G6k5SU1fMAYNzYCQ38nv/MUPa8biirFypz7GMvkJSU1fNyk1qwaNPv8TF//zflboM9rzvKOx4CQPblKKiLC8rdBvtBM/gc2SpITstG/O2MZ75uWNcOCpO/brOtBiBXQJWbAVV+dqnbUQO48FsGbv2ZU21ZSXPKqrv1a/4wbtAMMoUh5Ca1YNlhCIpSb0HJupPEldXzlcWel77yeqEyxz72AklFeT1v6tgW5s6vwsDq+cMIe143PO94WJz1JzJOfo+6fcp+TA/AftAUDrJVEBmfAnkZ/4O5N+Jwe+kw3F48COlRq2HhOQAKs7Ifki2XA5Hxd6spKWlSeXUvKe/WBShq1/v7g10pWHeSguf1fOH9m7jz9QjcXT4Gabu/RFHGH2W+lj0vbc/rhcoc+9gLJAUVPeZXBHte+srrB7VajQf7voZl52EwsKz33G2xH6qOpxZXwZ303H88K6oks2aeaPL+VijzHiHnchQUtW3K3VaRUo076XnVEZM0rLy6P5H3awIyYzfDdlBwua9j3UkKyt3XOXmhlltPKGrbQpn9AOnR65C6ZRYajv0WciPTZ17Pnpe25+3/KnPsYy+QFFTkmF9R7HnpK68fsuP3AVDDonWfCm2L/VB1XJGtgkf5xc99jcLUAhae/fFg/zcovJ9c7muz8oo0FY2q0fPqnnvjHNIiF8LmjWkwdWz73O2x7qTtyut5I9uXYGBZDzKZDAYWNrDpOxXFjx6gIOVqmd/Dnpeuihz3gIof+9gLpO0q2vMVxZ6XtrL6oSj9d2TGbkHd/7xXqe2xH6qGK7JVYGFSwf8+tRpQKlGUfq/UOxc/UduUz5OSgvLqnn0lGg8PfQfbATMrNMQCrDtpvwrv6wBABshkssf7vTKw56WrUr1QgWMfe4G0XaV6vgLY89JWVj8U3LkCZd4j/B429R9fT4v8HOZOXVH3P6VfM8t+qBoOslVgb20GQ4XsmVMMsuJ2wdzZGwpzayhzM5FxfAOgMICxnXOZ2zJUyGBv/expeKR9yqz7T3uQeeJ71Bs6Byb2rhXaFutOUlBWzwNAztWTMHFwg8LMEsqcdKQfXQu5mRWMG7csdVvseWkrrxcqe+xjL5AUlNfzapUSUCmhVj1epVMXFwFyJaAwgEz27EmP7HnpK6sfzFp2gcm/HrOTstwfdXtPhsnLbUrdFvuh6jjIVsEgj8ZYfuzmM1/P/zUBmacjoC7Kg9zIDEYNm6O+76cwqFWnzG0pVWoM8rCrzrikIWXVPf1wKCBXIHXbvH98vd5b88ocbFl3koKyeh4Acv46C0FdVAC5iTmM7V1Rf/inkBublfp69ry0ldcLlT32sRdICsrd/yVG48G+r57++c6SoQCA+sM/h4mD2zOvZ89LX1n9IDc0gdzQ5Nmvm1lCYWpR6rbYD1XHQbYKHG1rwaOJFc7/lv6Pr9fzmVup7cgAtHWwxss25hpMR9WlrLo7fLi3Utth3Ukqyup5AKg3dE6Ft8Oel75ye6ESxz72AklFeT1fy60Harn1qNB22PO6obx++LfyPheyHzSDN3uqosCujjA2qNp/o5GBHIFdy752lrQP6076hj1PT7AXSN+w56kk9oP24CBbRT1a1odbY0sYKWQv9P1GCjnc7SzR3am+hpNRdWLdSd+w5+kJ9gLpG/Y8lcR+0B4cZKtIIZdhjb8n7OuYVbqhjRRy2NcxxZrRnlDIX+zNQGKw7qRv2PP0BHuB9A17nkpiP2gPmVpdzjMSqMKy8oswbn0cLt3NRGGxCuX9p8rw+JQCdztLrBntCQsT3npbqlh30jfseXqCvUD6hj1PJbEfxOMgq0FKlRpRP9/HyhPJiL+dAbkc/7g9t6FCBpUKaONghcCujujuVJ+/jdEBrDvpG/Y8PcFeIH3DnqeS2A9icZCtJslp2diZkII76XnIyitCbVND2FubYpCHHe9QpsNYd9I37Hl6gr1A+oY9TyWxH2oeB1kiIiIiIiKSFN7siYiIiIiIiCSFgywRERERERFJCgdZIiIiIiIikhQOskRERERERCQpHGSJiIiIiIhIUjjIEhERERERkaRwkCUiIiIiIiJJ4SBLREREREREksJBloiIiIiIiCSFgywRERERERFJCgdZIiIiIiIikhQOskRERERERCQpHGSJiIiIiIhIUjjIEhERERERkaRwkCUiIiIiIiJJ4SBLREREREREksJBloiIiIiIiCSFgywRERERERFJCgdZIiIiIiIikhQOskRERERERCQpHGSJiIiIiIhIUjjIEhERERERkaRwkCUiIiIiIiJJ4SBLREREREREksJBloiIiIiIiCSFgywRERERERFJCgdZIiIiIiIikhQOskRERERERCQpHGSJiIiIiIhIUjjIEhERERERkaRwkCUiIiIiIiJJ4SBLREREREREksJBloiIiIiIiCSFgywRERERERFJCgdZIiIiIiIikhQOskRERERERCQpHGSJiIiIiIhIUjjIEhERERERkaRwkCUiIiIiIiJJ4SBLREREREREksJBloiIiIiIiCSFgywRERERERFJCgdZIiIiIiIikhQOskRERERERCQpHGSJiIiIiIhIUjjIEhERERERkaRwkCUiIiIiIiJJ4SBLREREREREkvL/2EmyupvZZgMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'MLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "7535\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "5296\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "3288\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "4174\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "Average comprehensibility: 44.666666666666664\n",
      "std comprehensibility: 13.984117975602022\n",
      "var comprehensibility: 195.55555555555557\n",
      "minimum comprehensibility: 18\n",
      "maximum comprehensibility: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    }
   ],
   "source": [
    "signal_names = dataset.dataset.all_signals\n",
    "normalizers = torch.tensor([])\n",
    "attr_names = []\n",
    "for signal_name in signal_names:\n",
    "    attr_names += [f\"T{i}.{signal_name}\" for i in range(sampled.shape[-1])]\n",
    "    sensor_norm = torch.tensor([torch.tensor(dataset.dataset.sensor_maxs[signal_name]) for _ in range(sampled.shape[-1])])\n",
    "    normalizers = torch.cat([normalizers, sensor_norm])\n",
    "    \n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    for cond in conds:\n",
    "        cond.weights = cond.weights / normalizers\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
