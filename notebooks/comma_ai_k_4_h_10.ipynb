{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from queue import LifoQueue\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import network.cpc\n",
    "from network.cpc import CDCK2\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from utils.ClassificationUtiols import onehot_coding\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn import tree as tt\n",
    "\n",
    "# IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: /home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_4/models/epoch_28.pt\n",
      "sensor names: (18 total)\n",
      "- speed\n",
      "- steering_angle\n",
      "- wheel_speed_0\n",
      "- wheel_speed_1\n",
      "- wheel_speed_2\n",
      "- wheel_speed_3\n",
      "- accelerometer_0\n",
      "- accelerometer_1\n",
      "- accelerometer_2\n",
      "- gyro_0\n",
      "- gyro_1\n",
      "- gyro_2\n",
      "- gyro_bias_0\n",
      "- gyro_bias_1\n",
      "- gyro_bias_2\n",
      "- gyro_uncalibrated_0\n",
      "- gyro_uncalibrated_1\n",
      "- gyro_uncalibrated_2\n",
      "Multihorizon size of the model: 30\n",
      "Test split ratio: 0.2\n",
      "Total number of windows in the dataset (without splitting): 101465\n"
     ]
    }
   ],
   "source": [
    "model_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_4/models/epoch_28.pt'\n",
    "dataset_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_4/data/test_data.file'\n",
    "\n",
    "print(f\"Load the model from: {model_path}\")\n",
    "model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "with open(dataset_path, 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "all_sensors = dataset.dataset.all_signals    \n",
    "print(f\"sensor names: ({len(all_sensors)} total)\")\n",
    "\n",
    "for s in all_sensors:\n",
    "    print(f\"- {s}\")\n",
    "    \n",
    "print(f\"Multihorizon size of the model: {model.timestep}\")\n",
    "print(f\"Test split ratio: {len(dataset) / len(dataset.dataset)}\")\n",
    "print(f\"Total number of windows in the dataset (without splitting): {len(dataset.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e448d2f56694c12b1d1deed7aa8e04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projections = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "device = 'cuda'\n",
    "model = model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(total=len(loader.dataset))\n",
    "    for batch in loader:\n",
    "        hidden = CDCK2.init_hidden(len(batch))\n",
    "        batch = batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        y = model.predict(batch, hidden).detach().cpu()\n",
    "        projections = torch.cat([projections, y.detach().cpu()])\n",
    "        samples = torch.cat([samples, batch.detach().cpu()])\n",
    "        bar.update(y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM and calculate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0980549fd6754ae09bbd4acfca7fa9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "best_score = float('inf')\n",
    "clusters = None\n",
    "range_ = list(range(5, 60))\n",
    "for k in tqdm(range_):\n",
    "    y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "    cur_score = davies_bouldin_score(projections, y)\n",
    "    scores.append(cur_score)\n",
    "    \n",
    "    if cur_score < best_score:\n",
    "        best_score = cur_score\n",
    "        clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57}\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('DB Score')\n",
    "plt.plot(range_, scores)\n",
    "best_k = range_[np.argmin(scores)]\n",
    "plt.axvline(best_k, color='r')\n",
    "plt.show()\n",
    "\n",
    "labels = set(clusters)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAOMCAYAAAA2VQZbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAADCxElEQVR4nOydd3xUVfqHnzOTBiGUhBJ6R6RIFRhAiARBVlAQ68Ji3YBtLeuCZf3p2pBYsAOxrCKoq6KI2JBIqEMvIi10CBBKCCQkIZPMnN8f904yk0ySqZkknIfP/czcdu6ZYXK/933Pe95XSClRKBQKhaKmYwh2BxQKhUKhqAyU4CkUCoXikkAJnkKhUCguCZTgKRQKheKSQAmeQqFQKC4JlOApFAqF4pJACZ5CUQ5CiDghRJof2pkthHjGH31SKBTeoQRPoagEpJRTpJQvgP9EVG/rOiHEKiHEOSFEuhDiQyFElMP+cCHEx0KILH3/YyXOjxdC7BZC5AohlgkhWvujXwpFVUQJnuKSRQgREuw++IF6wItAM+ByoDnwqsP+54COQGvgamCqEOJaACFEQ+Bb4BkgGtgI/K+yOq5QVDZK8BTVDiHEISHEk0KInUKITCHEf4UQEQ77RwshtupWzxohxBUlzp0mhPgDyBFChFTUXolrNxNCLBBCnBZCHBRC/EPfHi2ESBNCjNHX6wgh9gkhJunrnwghXhRCRAI/A82EEBf0pZluYcU4XKe3fo3Q8r4LKeXnUspfpJS5UspM4ANgkMMhdwAvSCkzpZS79P136vtuBHZIKb+WUl5EE8ceQojObvw3KBTVDiV4iurKBGAk0B7oBPwbQAjRC/gYmAzEAHOARUKIcIdzbweuA+pLKQvLa88RIYQB+AHYhmZJxQOPCCFGSinPAncDHwghGgMzga1SyrmObUgpc4BRwHEpZR19OQ6kALc4HPo34EspZYEu3IPd/F6GADv0/jYAmur9tbMN6Kq/7+q4T+/bfof9CkWNQgmeorryrpTyqC40L6GJGEACMEdKuU5KaZVSfgrkAwMczn1bPzfPjfYcuRJoJKV8XkppkVIeQLOYbgOQUi4BvgaSgb+gia67fApMBBBCGPXrf6a3W19KuaqiBoQQ16BZdP+nb6qjv553OOw8EOWw33Ffyf0KRY1CCZ6iunLU4f1htDEs0Maq/qlbReeEEOeAlg77S55bUXuOtEZzRTq2/RTQxOGYJKAb8ImUMsODz/M90EUI0Ra4BjgvpVzv7slCiAHA58BNUspUffMF/bWuw6F1gWyH/Y77Su5XKGoUSvAU1ZWWDu9bAcf190eBl3SryL7UllJ+4XC8qxIhZbXnyFHgYIm2o6SUf4EiyywJmAvcL4ToUEbfS11fH0P7Cs3K+xu6decOuht3EXC3lDLZoc1M4ATQw+HwHuguT/21h0M7kWgu3R0oFDUQJXiK6soDQogWQoho4GmKows/AKYIIfoLjUg9dL8iN11Z7TmyHsjWg15qCSGMQohuQogr9f1PoYnZ3WiRknN1ESzJSSBGCFGvxPa5aAEl1+Om4AkhugG/AA9JKX9wcchc4N9CiAZ6MMrfgU/0fd8B3YQQ4/Ugnf8D/pBS7nbn2gpFdUMJnqK68jmwBDiAFmjxIoCUciPaTf1dIBPYR3FUosftOSKltAKjgZ7AQeAM8CFQTwjRB3gMmKQfNwNN/J5w0c5u4AvggO4abaZvXw3YgM1SysP24/VIzqvK6Pc/gUbARw5Rn44W2rP65zkMLAdelVL+ol/vNDAebcwyE+iPPh6pUNREhCoAq6huCCEOAfdKKZdWxfZ87MvvwOdSyg+D3ReFoqZREybeKhQ1At012hu4Idh9UShqIsqlqVBUAYQQnwJLgUeklCpKUqEIAMqlqVAoFIpLAmXhKRQKheKSQAmeQqFQKC4JakTQSsOGDWWbNm2C3Q2FQqGoVmzatOmMlLJRsPtRWdQIwWvTpg0bN24MdjcUCoWiWiGEOFzxUTUH5dJUKBQKxSWBEjyFQqFQXBIowVMoFArFJUGNGMNTKBQKhX/YtGlT45CQkA/RylxVN6PIBvxZWFh4b58+fU6V3KkET6FQKBRFhISEfBgbG3t5o0aNMg0GQ7XKTGKz2cTp06e7pKenf4hWdcSJoKu3XmJlixBisb7eVgixTgixTwjxPyFEWLD7qFAoFJcQ3Ro1apRV3cQOwGAwyEaNGp1Hs05LURUsvIeBXRRXXp4BzJRSfimEmA3cA8wKVucUinLpK0pvMxghqj5EN4arxmjv+8TBFaZK7pxC4RWG6ih2dvS+uzTmgmrhCSFaANeh1RRDCCGAYcA3+iGfAmOD0jmFoiJciR2AzQrnM+DgLpibCO8/DffFw7dJ8PehcHUDGNNGW1coFC755ptv6rZp06Zbq1atuj311FOx/mgz2C7NN4GpaAONADHAOSllob6eBjQPQr8UivLxRKykhIJ8mD4FtqyA7HPk/7aI/PH3kC9s5I/UDstvA/kGyG8KhdPBZg5IzxWKKk9hYSGPPvpoq59++ik1NTV1x4IFC6I3bdoU4Wu7QRM8IcRo4JSUcpOX5ycIITYKITaePn3az71TKCrg9wXuHysM2qJXJsn/cxvkd0f78xOwBPIFWk1yCaSD9SkoiFeip6gmLDVH8uQbsSw1R/qjuZSUlMjWrVvnd+nSxRIRESFvvPHGs9988019X9sNpoU3CLherzb9JZor8y2gvhDCPrbYAjjm6mQpZZKUsq+Usm+jRpdMKjhFVaGBG785IWDACOjSF64YqIkeQH4X+wH6UgYXoWCQJob5AvJbQsF9SgQVVYyl5khG39eJxI+bM/q+Tv4QvaNHj4Y1b97cYl9v0aKF5dixYz4HMAZN8KSUT0opW0gp2wC3Ab9LKScAy4Cb9MPuAL4PUhcVirJZ+k3Fx0gJ65fCjvWaK1OALWcgxSIn9aWs80vsTgPbbCi4GgqTlNtTUUVINkdRUGjAZoPCQgPJ5qhgd6ksgj2G54ppwGNCiH1oY3ofBbk/CkVpCvLdO85mK36b1Y+C3Ssp/rMrx7orj3ywTtHdnlcr0VMEmXhTNqEhNowGCAmxEW/K9rXJli1bOll0aWlpThaft1SFaQlIKVOAFP39AaBfMPujUFSI0QhWq9uHF6S9jO3MvVToxnQXu+WXD4WJEPad700qFF4x3JTD4lmpJJujiDdlM9yU42uTQ4cOzTl06FDE7t27w9q0aVPw7bffRs+fP/+Ar+1WCcFTKKodE/6pTTlwg4K0l7GdfMJhi6Of0nfxkws1K8+gpvkpgsVwU44/hM5OaGgor7/++pFrr722k9Vq5a9//euZvn37XvS1XSV4CoU3/GOG9jrvNSe3pStsGRP0d4Jyx+x8wJaiBE9Rs7j11lvP33rrref92WZVHMNTKKoH/5gB662wURYvH6+BXkMgNLzoMBHh6IkRJRY/IMAQ55+mFIqajBI8hcKfXGGCD5aD+aImgANGENLyabTcChVEZXpDfQhdraw7hcIdlEtToQgk7/6KAQg1Q+ETIFf4oc1oCM/wQzsKxSWGsvAUikrAYIKw5RAuwTAVMHpw7hQIXaOdGy6V2CkU3qIET6GoZEJnQHihJl6ha4AeaAJoH9ITQBgwRNsfOku5LBUKf6BcmgpFEDGYIHxrsHuhUFwaKAtP4TNrMVOX2oQhipaOtAl2txRBYiVJvM1IvmUaUxBFy8dMDHbXFNWEm2++uU10dHSPjh07dvVnu0rwFB5zHSOdxG0IA7lIntMxhzlMLDFB6qEiWKwkiflMZidLWILzxPz1zOc5upRxpkJRzN13331m0aJFe/3drhI8hUdcx0h+Y4lbx57lrLL0LjHmM7nc/ens4lumVVJvFJXG0uWRPPlCLEuX+6U80KhRoy40atSosOIjPUMJnsIjVrHSo+MPc5hB9A9QbxRViSluTqRfxtsB7omiUlm6PJLRf+1E4jvNGf3XTv4SvUCgglYUFbIWM8tJIYYYoonhGGlunZdedzX1s+vqaztBKneWAgq4yMdM5G7mBbsrCn+QvCKKggK9PFCBgeQVUQwf6re8mv5ECZ7CJWsx8zqJ/MAibJSfK9IV6XVX0yC7XtG6RCKEEj2Fxnrmc5K9PMm6YHdF4SvxQ7KZOdtGYYGBkFAb8UN8Lg8UKJRLU1GKtZgZwkC+Z6FbYvdXJnANI5y22S07of8rYuJRv/ZVUXWY7WHatMOs5y1GBqg3ikpj+NAcFn+eyr8eOsbiz1OrqnUHSvAULridWzw6/nPmM47xDGYIAHcn3eQsclC8Pj8bks76pZ+KqsdsJFNZQxjuDePsYgkHUBVsqz3Dh+Yw/Zl0f4ndmDFj2g4ePLjzwYMHw5s0aXLFzJkzG/qjXeXSVJTC3TE6Rx7kPt5lFutZy40LrgE0kZPIUuLHm2chIdofXVVUQdph4m0u8DETWc/8Co9PJYV2qFQyimJ++OGHg4FoV1l4ilIYPUn0CHw/chbnwzZxp3EAWcZNDNjYC6BI7GRJV9dui7LyqjHmgzD9N0hao72ay7g13c08ZiNpTT/KutWEUotOxAWsrwqFI8rCU5TiVm7jczeezEETu2uXXFW0LhDUPRvpZNmVsvAk8GA6dI8AU21/dTsozCeJL/iIWJpxH1PpU0MtlYmfwQ9/Qo4FrCWeXwSw+mEwtXV9rj0wZSVJbGEBvRhPc7qTSgqdiFPWnaLSEFIGpgJzZdK3b1+5cePGYHejRlGfSHLJrfC4zNobqZ0XUVrU3KUOsKRNtRS+ztTlAq4D0v7GFG5iUo0QwDb/gcOZ5R9jFPB3E0y6smzhU1Q9hBCbpJR9Hbdt27btUI8ePc4Eq0/+YNu2bQ179OjRpuR25dJUuOQcObSmtdO2etRnBWt4nzn0pR/Nac6KqzYAlHZbussFYOAhMFcsrlWJXjQtU+wAPmM2NzCQLjRgPEPZVE0DMyZ+VrHYgWb1zV4DQ98t28WpUAQbJXiKMtnLISzIouU0mQzAxL0ksIZ1HCSNBr/2ILP1Bd8vdtWhaiV6p0l367gszrGOFdzAQCZUwxD8Bds8O77ACkPf0YRSoahqKMFT+MQATEQf6o+YGgO1vGtDIpFWiW3gQe4xL2U62zFz2r8drQIsZwn/qGYVA0K8uEMU2GD+Jugy3YOTssyQNl17dbWuUPgBJXgK/zAjFnK7wIQo1/tba5GfrhyfwmF6euMUG0+xhXiWVGnRa0sHr877ji/83JPAcv9g78/ddRJGznLjwCwzbL8KDj8F2wfB2hjYPlBfHwjrmnrfCUW1ZN++faH9+/fv1L59+64dOnTo+sILLzT2R7tK8BT+ZV5LGOEiACVb6jlbnCXPPvZnf02J08bFLNhIcdNtGAzeZK5X50lsvMw07mUco+nPfJL83DP/MuN6mDoM6oR5d/6SPSAe0ZZeiWWM7x16ArDqKxKsJaasFKbDagHmuiXPVNRQQkNDef3119P279+/Y8OGDbs++uijxps2bYrwtV0leAr/82sb6BfuvG1UJOejiqt9SP2f/T3AzyPOs9aUU7QtjthK6a439MFEJHW8Ovd9EvmFhWxlPdOYTBeiebkKl8yZcT1kJ8KcW3y5YUi2HpcMfMuGedFQWB2uidhqI2Svcq8JW7YSvapK8tJInnoyluSlfqmU0Lp164LBgwfnAjRo0MDWvn37vCNHjnj52FWMEjxFYFjXXnNvRhu013ktmfqalsHFLnBbeuby84jznIku5LMJGVz3676i023APawORs/dYhNmzv7Zjex5T5D/5wCf2soik/dJZEAVrx2YMBBWPQxTBkJ9j8drRdFyw6ovAYu+3aYvbmKrsnmJL12Sl0YyZnQnXk1szpjRnfwlenb27NkTtnPnztpDhw71OTpOTTxXBI55LZ1WP0nIAGD8ggYsGJ/JhwnlT/XZRRYt+YavGIqJRgHrpjd8/udeMh5LRhaEIUItxLwRT3i3tT61edzclLZzZ9GWjrw+aTi9quAUPlNbbZl1i+aevOEjOK3fhowC2sXA3lL/rXY3tjZX84ylav1fKnwkOdmhPFChgeTkKOKH+yWn5vnz5w033nhj+1deeeVodHS052VbSqAET1FpdCSKDxPOVCh0jqSRy2B+ZhWjqpTo5W8diiwIA1sIskBi2Rrnk+AZk+4ldPIswMgR4JbZNi7vaaDnABg3iSorfqdedL2v7jTIzrevSTSx04Svc9TOSuidotKIj8/mzZk2CgsNhITYiI/3ixmen58vrrvuuvY333zz2TvuuOOcP9pUgqeoNB6hC5PxXBRswH2sZStj/N8pL5nQszUfhBZiKShAhBYQ1jPF67YM5gGETtHEzjFjza6t2vLFbIhtAS3bwfEjEFEL7noEbk3w8UMEkKwZjmsGujx3hD3nmnFZ1E52XtsPCENza9o/b/XP+HTJEj88hx8Wp2qWXXy2P6w7m83Gbbfd1rpTp04Xn3vuuZP+6CYowaveTI4Aaz4Yw2HOxeLtH0yEdWXkwuw/Af4e4ErTSWfJmH4MW46NJXflkjMjhi1okXeXU5ddZHnc5IFyspoEA1M3SHkjhPlbD3O45yz+6LahKM7QEwzmAYQ8MhOksUR6NudUbelp2mLn35O116oseo7sfK6V/u4K4KLzziwzZKWAMQZOz4fsFZXcO4XPxA/P8ZcbE+C3336rs3DhwpiOHTvmde7cuQvAf/7zn2O33nrreV/aVbk0qysJYWArcN7WfwLsXQVnD5d/biBFL+kscvIJp02vTE3nqRnHfGp2Am2Zx1UVHxgkNmHmZZ5gHc4360bEcjOTyCaLxXxNJhlF+wzmAYRdvQzyiyNaPc1Jurf6//mW5uA0OJ7oep+oAwOr1sNPdUbl0lRUffabS4sdaFZdRWIHsGWh37tUxALtZuRY6Xz8tw18anIETStX7GZHsukbwZM7QniS+9zKg9kHEwtYzv1MJYbGtKA1M5jDFk7wFDOYziw+4QfCKBY3Q0ocWEIdJt4Xj3O5S0cBs6fDlpqUkKTtDGg3h5JWLgAxN8CmjpooKhQeolya1ZE13k16LiIkvOJjvGV8FCy54JRMesGNbmQfdiAMQQrXkkI6ccRWbrDK+2FsalzAzWPBYrSCnM3/xH/5mmVuVT54ihk8xQyX+/pg4muW8Q1zSWUnO3b0xirtIme/uXtedeL1p7RxvbnJVTO4xSuaJkBkd9h/H1zcCxGdoHZXOKO76o8nQnoSdP0J6taUD60INMrCq27sN8ORzb61kXsWZgzV2vI3CdEcmBPFgTb5nGxU4JY7M5pQwjAggDAMpHAtJhrxJN0DK3bpZtg0XXsF2JEEsgBzcygwUDR1rEDmYyal6LRNmHmX6V5VQOiDiZsO1GXb1FEUzr8J6W1ZpRIUWGBdSoWHVS/qmqDXVjDlQK8tcOZr5/22c1rqMZVvU+EmysKrTuw3w2vxUHCx4mMrYu8KmD4QGnWEez+F9v55SrZiZnDCLtIT3PtpzWEACXTCzOnKtejSzbDwarBawBACl98Dp7UHCdMxCLWBRUD+jgGcf/09/pXWhY9awj8e285L3eIpwEIoYfyPZM9q3u1IwpyViPxuj66n/hG80DDoH+eXpqowFsxRDZnbqC3poRH8VL8ZFoMBbG8B72mHrH8cznYmOvoYGf3aV9jiRGbxM9sYRQ/mcV9gu68IOkETPCFES2Au0ATNp5MkpXxLCBEN/A9oAxwCbpFSeuYTq6nsSYFCC34N4T69F14ZDE+s8ln0rJgZybek0w1nN10xtTAggfG0dhqXM9GocoRuRxLsXwC5p7QIV9DGQ3fMLjqkz0n4eiG8FTqAz95YCRgpALbul9z9QDcgi4bvXUXtbhswk+KZ4K1/FlMUvDl2Abz2hFNleF+4mFeD3JmuyDJjjmrI0G7DKRAlHFNGLTE56x+HMz0AOHumHRHrd2Lp93LRX8sEBjmJmoGJRfvm61l9lOjVbILp0iwE/iml7AIMAB4QQnQBngCSpZQdgWR9XQFwWRyEhEHJP3gHsk8O4Ni2J8g+6UG6K2nTxNSR/Wb47D54rhe5u8K5UBhKbgX13KyksJpO+lrpm/gE2pLLRPKYWPkRl+lm+GkcpEyGo0sgY2u5h/c5Cdlf/gsw4pgWS8PImQdWYv1zMCbiPOtHfhZ9TsL/+j9F5xGf+cm+0+gotKXGccYM+57jiVY9NLETwnmxc7az/kbbln+2ndOj4XxWI5jIfXxMCJNKPTZ+zmqm8WUgP4kiyARN8KSUJ6SUm/X32cAuoDlwA/CpftinwNigdLAq0t4EjyfDuBfhb3PgxpchqjjBcvbJAez6OZmjm15g18/JpUWvcQfoOATCS5TwEQZNTO3sN8OrV8Py2eTeuBVbZwsYC7HJJVxAuFhiADASxyD26I04306m0jU40wrSzfBJC1gwEA4u9OBEwfG8Zi63a4uBsVs/9cy6A2g/DtAEdfH1d/DVm/8htoVmpNgNFV+pUaK3diL8PogksZ8V9ZqUcZD+gaN36+uyxLozs/kdq4v8nRJIZDGCiQgmksTvPnVd4T25ubmie/ful1922WVdOnTo0PXRRx919cfoMVUiaEUI0QboBawDmkgp7RO50tFcngo77U3wlydhaIL2OvNEkehlpcdhs4WBDMFmCyUrPc753JyzMG05vJelzcWLqAstepZ2Zxa5TsHm/NBcBme5QAxWtrOQ14nnDwxYCcHGBNoimcQM+vjn83tCulkTuhxv5gBK7mn3UdH70hiY0LO1581eMw86TYDwaOg0gV4PP8fKo7C7UFt69PO8n6VffU45GHy2TYNvIuHIfECyIFafuO5o0dnnENs39XsNGm4DQ7722u81n7owmY+V6AWJiIgIuWrVqj179uzZuWPHjp3Jycl1k5OTfU5KHfSgFSFEHWAB8IiUMks4/KCllFII4XLASgiRACQAtGrVytUhlw4zT8CjTakbm4LBYMFmkxgMBdSNTXE+rtuo4vflTDy3XhGDNd+AcZcVMqCoSk8FoleIJhALeQMAIyOoxa+efhr/8f0In05PaP8h+wv6kPhHAiU/fHSUlm3FK65x/d1vMcO29eWd6JyTstjaLD1e+qb5ah4xLfOyg0Fm7URd6IppdDFPeyNlsejprwYENvt34qPIleRZviWBYX5ts0ayamkkq5KjGByfzWDfM64YDAbq1atnA7BYLKKwsFA4aoO3BFXwhBChaGI3X0r5rb75pBCiqZTyhBCiKXDK1blSyiTQqmf27du3Juab8IyZJ4hansTl7Z4i66iJui3NRMlUyAUQ0P+vbmVXsWImr8Uj0FzCGCNhPzXFMlrPaVXB782G893ayHivPorfKPS5mggzphgYKw0kfgE/rAGrDWKj4cR3fuifA+Y/4a9DrBgxIBBlhPy4M1dPADb2pwzAU29rUDhjhnV3QM7ecg87HaHXI7Lf9HThMyCYxV1M5uOAdC9L+wNSlMeqpZHcOboThQUGPpxp45PFqf4QvcLCQrp169blyJEj4XfcccepYcOG+dxmMKM0BfARsEtK+YbDrkXAHcAr+uv3Qehe9WRoAlFDQRuhuxV40+MmrKQAFhA2CDHC9fcTRgwWHgW3//hbE8ZThFFNEj2WpKVuGbYfD10TMAHfvRS4y5n/hIEPSNoVFo8wVPws62jtOWdoMYYV0C6uGuSj3J8Emya7dej4tCMsiW1a7MbUWcX/YaJjwARvHFcGpN0axarkKAodygOtSo7yh+CFhISwe/funWfOnDFed9117Tds2BBx5ZVX+jQnK5gW3iDgb8B2IcRWfdtTaEL3lRDiHuAwcEtwuhdYsvV8uXXjIKoKPYkbiaM4k30YEIOFR/T1ELTg2vIRhFYNsYvpWWE0Zil6TYWBrjOlBIon5mivBbUEYXnFBXIFAoMRbFZwPY7oPH5Xu2E63W9aSJ9Jc7nBdFegu+0eZ8xwOgV+3gwbmkPX1dDJ87y3CQf3AzC5V18wGAi1GbCEFHssJPMQTPRLl6OIIJQQNTfPXQbHZ/OhQ3mgwf4pD2SnYcOG1quuuir7hx9+qFdtBU9KuYqyH2TjK7Mvlc3haXDiNUCCIQIuT64aomfFjJUUwngTbfAuRh+Xy/OoHQP9A9A7L4h7HxYMwu15i1GtK13sAPYf116PXgktN0BoHoCkRWtByiFtbO+7uYJj6WfI4yj1Y7Po0gsyMyTyXAcObm3BtePhyoQfOM5CmnEX7YL9wGEugBfSIKUx5N0F3KNtFzZ4fozXopdwcD80GQFDS48NS+aRxO98RAo7OcYF8l20UjHZqS2otXgcezN7MDEWkv+EU1lgk2AQcEUreP8uMHWquK1LgsHDc/hkcao/x/COHz8eEhYWJhs2bGi9cOGCWLZsWd3HH3883dd2VbWESmZLF8jf5byt3gho8VxwRc+KmTzisVt2YbyJhX+AFzcNI2OphZ8Hubwl3Qy750L62vKtPREK91sqrVuOTJsNiV+Ao8W25j2D90ExwWDaBXj/IjgNm5a8t+iu19Z/QOJw99oNqQvhTSD3EBjCocP90MO9h5KJzGIhG8jBg//Xz2+BxaPxJLfphEEw7wH3L1GVqKrVEtatW1frzjvvbGu1WpFSihtuuOHsa6+9dqLiMzXKqpYQ9CjNmsgf/SG33Gg7Z84vgfPJ0PSfEFI/OG7OorE7rEA+BbyKN2KntVWFxo9iTdqSbtZuZPlnXR8nC+Dr/nDzusrtHzBjivb6+VJBu6bwymRRvcSu6RltAlEpyhCLYx3db7v9FLcFriTzuI/pNOdpvnLPxv/8FlhsLzLsfkTg/NWwcCM8cA3M+Ks3PVWUpH///nm7du3a6e92leD5gWwz7IgDTx4kS2GFE4mACI6bs3jsLh+wIdnnQ2tliEqwSDfDd0Ndl1Ry5PSmyumPC2ZMKRa+akX/zDLErhzquFnDs8kIr8XOThyX61GvZUteJGGI1E5c+HG0vsWxCrt7wpeTD4mLtSUqArICE0Oj8JEqMfG8OpNthh0D8U3sHJFgy4PTPlYA8hQjJmqRjJHh1LifxbGUisUOoFbTgHfFCbMZXpmuvVZXNrlT5106LMCFBvDOuxWf1jjO+37pmOjI41xX9gHJceRMf4Teix8A6Zg+Djyx8hzJvgh17/bqVEWAURaej2SlBKbdUx9Ao0mVbeWZCOM58liJq0CVHcAS/f0IoGuZLVUxwWweR8nQfZeM+sq/1003a2LbPA4OAq8lwtq1cPKkc3i90QjvvQ9/rwKRrZ4w7YLmAa8QAaIQpJ47rTAcVt0CWTHw9O2uTzGEQaM4v3RzBrfRnsa8yS/s4njxjuQ4+EgLpil2wrtv1ZVHth8Kmij8TxW7M1U/6sYFqGFr4MS0POyW3m768TmayKG//hNYrC//dNhXkhAeD3xHPSHWBL3+Vf4xjftpx/mLdDN8Hw/rnoEvB8HEgbBwIaSnl5pLhtUK999XbOlVB8tv2gVI9OCuLkMolYT7j3hYWsZUgrgUaOi//48EhrGTRMY6priba7+2Y4BKTUpEqiiJsvB8JMoEbefAQcf5s7XQ5k/ZY0DcegouQWgAxbQCdgK3Y+QEDxHOeWawHBuHnWbgFQLbgK4ItIoC2l4jE4goo+J3ULFPN9iS6Hp/l3v8e71jKVqtPWnVHis7ohW7KgubDV5NhE0bIS3NeZ+1CkZSv+etCeOYFk3CB69Bq90lpikY/Cp2jkxlNL+ynTwsUBDmsEcJ3aWAsvD8QJME6LoGWr6svQ7IhX7ZMCAfuq4EEVZxG3ZCm0KDsdB1efCmKbzOCvZxIzm04izdmcx9GGjt9HQUAvQAarGaWqwgjJepxRpqUXH6sqAxcAaMXwNNh+B0g2s5Arr62Z3YPA6MYcUPPOVnztL4fmFpsQMwVsGbsTcPcYCzFaVVneD7EjH9rcpwc/oBEx1J5kle5haMDe3BVYF5oIiYFJBmFT6gLDw/EWVyLVBRJuiSUhyEEtkLCjMgJEZ7rRsHudvh7AKIHq+JZ7BJJQY4h/3GZMPA67Tn7xzGPqN0JG3ow+cY9YSNxmqRuBHNbXnjclgzDbYkYm7Sh8Sut7IlayORdVvzMLXpTigpWIgjDBMePK048sN2eNsGLdHE7pBv3c7YnsSZ7hk0JI6YqvBdjw+D+X6K1MosLnFFg34wILAPTSY6YqIjT76tBZcEarwtv1ATvYuVHIBWUygsLKR79+5dYmNjLcuWLfMlbLwIJXiVQFli6Li/KgidndYcxUwUxU++NgT7+R9ahs4EjNRyELtqyZmtmJv0YeD4H4q3yUImC+esSBMIZx4NPGt70kSYr2f7d12SzSMyBsCqzg9ixYaRMAaTHHzRm1cXNp+FXd6WInKwqobNh/Cm0O05aF+5fwhZH0Onx2Cvzzk8XJNfcSY+RRm8+OKLTTp06JB34cIFP1WKVC7NMkniD+ryNkbeoD/zKz6hBmHhc1rzDZEcoT7buZxZRHEYgK+AVP5ZvcUOoP14Bo7T85K7qp6tM598BOkI0gkhnbacYhxnMWPBjIX70lMZt2ct96WnYv7+a2jetFjs/MSZoWA1FgBWrORxhhQyMLOF+9jCfWQQpOCWndEwNQKaC2iENpTrDpFACwG9L8JzK+Hl++GG45UudnY+DeD8x/BLxaRYvzSSd5+MZf1Sn2vWAezfvz/0119/rff3v//drxlfLpX/Do/oz3zWO8ymXU86/ZnPOiYEsVeVRzf6k8Z8mlA664gE/qA+vSu/W/6lawLYjjtvc6y15gIrcAgbh7CwkLMYbRJrkyhootWn+GhUf+759yNMmvc1prX+mcSeMQB2P4ZTYYTdTMfKv7EXej3IbAzUpj0P0r2yA4Zm1NEWR6ZdgG8t0D8E1hfCPpvW9xbAV/XAFOpwcMtK7KxrTJ1g6mht0rg/CQ+5RNyZ65dG8oheHujzmTbeXJxKP9/yaT7wwAMtExMT086fP+836w6UhVeKLvzXSezsbORkEHpTuWzHzFTGsa5otl1pjITQh7jK61QgMZT4+XtYYNIqcLIOC0JDmT35b1ydvADzAN8rvB+4B5YvB2uMvX/6dcmmZFVzG7nsJZHtTPP5uj4zow7sjdbcnqnRYGsIsiEcbVhC7KoOM/6qpez0lQmDQH6uLZeE2AGsL1EeaH1ylC/NffHFF/UaNmxYeNVVV/m9GKESPMDMcaazjpF8w64y0mJF1NCvauk0eCGygGeNBcztFM02czqZnC7zeBs27mUQ/RH0RzDAbT9WYJlGFtGkU1t3OyZR/gPmRDK1N75WUZayeAEwGMgPD+PepNe5791XvBa+jAGw7V00N6EH08P2Usa0C0WFjHoGvI1RAphzT/VNIu0T/eKzCQm1YTBCSIiNfr6VB1q1alWd3377rX7z5s2733nnne3Wrl0bdcMNN7T1R1cv+WoJSfzBZH6r8LixtOc7xnp1jarK0mmwJtE5y6AUVsyrr+Kcaa3b7QgMrPU+Tt0nJpLJV+TjKnHYBMLZi5VmGJhKHaeIyzqkVyCJbuLKDerwNxWWbyElfrzHLs4902DH82iDDo7/QW4K340BCrWvyZgtcNUmsL7j+blTR1fPxNF+q5awfmkk65Oj6Bef7as705HFixdHvf766008jdIsq1pCzTRb3MRdsQOYSr8A96by2fWtfVjI4Z80EJMS51E7Em8j9bzHjIWOnGJ+GWIHWsDJegpZiIWBnGUkGdzHee7jPJ5GoocAoWgGVy1gCCHMIYpwR7FztPSK3JwhpAwd6OnHo+FyMFrQ5vPb9MUDYzRogSzVGFMYrOwDY/8FNHN9zNTRzoEoBqqv2PmVfsNzeHB6uj/FLhCUGbQihOgOfAA0B34GpkkpM/V966WU1VoBzBznPpa6ffxzrAFgPJ1I4IpAdavSOGqGqGaQuQ+nTPJS2MiIS/G4ve2Y6V4JkZtmLMwlj4/IK1PoymIJBVDOWdFoEzDaYOA0Nk4gCQceojYzqOvynO6EMpc81mLhuLDR7PRZdtSvQ0GI9qcVWlBI3PI1HvYUYtbC4GvgzDAjDW95n/PdYSuTKz5R5wwpwZ+6UA0xhcF3vWBaO0hMBr4p3hc7TBO2S17cKpHRo0dnjx492m8V1MuL0pwFPAesBe4FVgkhrpdS7kd72K3WpHAUmwdunyV6WL79tTqL3lEzzI0Dq0UisWEzWkEKctsf4I9P7/TInWlnMkOYw4qAip4ZC1dxNiDO0wmE8y35WJDswUoy0W5NOjeVnJzeqEmRKLN4MZPeeB+TzQhDhsCuXdD5cpgwAR7+B+SXUW/QYIB27YnpEU/MXyZBdxP2uJXDfIQVC0bCaM09tCOBbwmnZLmOhjUlsChIzKgH7UfC4ybIAfoaYV3jYPdK4SvlCV6UlPIX/f1rQohNwC9CiL8RqFw8lUgcLQlBUOjFR3keM91piKksv0cV54+5WppHe2ong9XA9jkJHE340Os2rRSyiZSACZ4ZC1cHSOzAPt9O+2FbgBQsXmdZKRLB0RO0xRXdusNncyE5GU6dhDFjYG75GUbakUA7nOeqaVGZmtg9bN3GMbrQnJ0sMCYqC89HEiK1RVFzKHcMTwhRz/5eSrkMGA98BrQOcL8CjolmrOA26ntxUzvGBeL5GjPHKz64iiP0gaHYBeN9bus75vjchismkslAznpZf9197Gmww4A4X8L13MFkgvdnwZ5UyDxfodiVxXG+BTSxS6M7EiNpdGe8dSrrKaMSgUJxiVKe4M0ALnfcIKX8A4gH/a+smmOiGZk8RJQXHloLVlI4GoBeBZ4rJoEhxIY2eqdZuOnjF/jc7skAfB/9SWe+xyEm3vE4tXmBOm67M6sCzbgRgGN00beIovWT/BykXikUVZMyXZpSys/L2H4E+HvAehQEsvgHTZlFOu7NczQAYRiJqwJZIryhZU8zfb6ZxfcfP0BYejjH73nPJ3emndZc5ofeFTON06wPqPdcazsWA/+hDgn4z3818UX4biXUqw1/Gwn168C5C7B1H4wfAgnX++c69swqzdlDGl2wfyaBlSaM8s9FFIoagkotpnOC+6jL22SXEcU3h2vIII8YapFBHnG0rLZjeOaC9YwfM568689goIDLxCp8So2g8z92+qGVYr4ln+KZ14FAG7WrRRYJ+CHNhs7EF2G+Ptsl9yIkfuG8f8kG7dWfonfUCCHWQqx6IgAbYfS3zqMDMNcApipYYUihqGwu6Xl4JXmtjMi2NdxOAlfwJP2LXgMhdkfNsGq69hpIUmpdQb4IAWHERjipPANAqHkA9cctoHHMSWLrZFFv4qdut9mfEX7v542E6+/8beVJp9c4Uvza+jfLKz5mwQq/XhIAG6Wriu8DBtvAXO3DzBSXGs2bN+/eqVOnLp07d+7SrVu3yys+o2IqtPCEEIOklKsr2lYTsE81eJClFCCpQwhLuDkg4vZhfzi+EUJrQZ1mkHsa8s8V7w+NhKZ9oMUASN8Kl4+HPn5KJh8T2h6b3FE0SdpKAw6bFzBg8BiwFf8kas//GwDn591RtK3OtJep8+bDUBBGwZXryVg3CIBh+B70UpIZNCKRdFwJnkALLrmLWkyiFu+Rw9fkY6E4z3L5aEe0Zhcv+VFQp82GfDfKxPXs4LdLFtEK9EkzztiAFKmsPEX1Y/ny5alNmzb1W5Eld1ya70Cp5PiuttUIErgi4HPsPuwPx9dr7wtyINNFNeyCHDiyQlsADuj5nP0hehkU6AaA/Q4oaZVoAltIUdSmtlUS8fMozuvrdaa9TFTiE0X7w9abiOm/moR1fzIWP6lxCSSxiBLJvEOAe3WhsweXmAhzWWs9iRye5QJndFGrAzTFSDp5DGQDH3CWpn7qe9Ki0u7LssgKQD6KQ0YQZczbiHG9WaHwD9uWRrItOYoe8dn0qLrZVsrLtGICBgKNhBCPOeyqi/uVrxQuOOFl5ZhdC/wjeHFE6++KLZvax4XTSJk9evPiqJ9pbr6Z0Lm3Ykm6Qd8rio6ptWkgY/E8dZYnSGJJIoePyHOZF7M8EogsJxjFv7NrHp/l/rGzF2kL2IitfYETM3dAZ8/nzZmlZr3FCdhejqF6v4QtNpgkKsfSM7OXFHYRx+XcvrkjR85Cq2g4VCMfk8smKQcWXITxETV4Tt+2pZG8oJcHWjTTxjOLU/0levHx8R2FENx1112nH3/8cZ9r45Vn4YWhPRCHgFNMQxZwk68XvpSp0xSy0zw/L7anf65vogFrGMBwlpFLOLVJo2dcOIfXxxYdo90TrUR+MRE5fxKuvHQCQYQ/ol3coHzhqhrkeDx7Qstkmp4bRdPJLTkxx+yR6JklxNu0aedhEvLKOdYKzJbwgYSVAQ5iMbOXuMyvsGy7C3JjsX/Ow+nQZvOlI3pJOTA5S3u/xALPZsGJpsX7zRZIsUBcmJbSrNqyTS8PJPXyQNuSo/wheKtWrdrdtm3bgmPHjoUMGzasU9euXS+OGjXqgi9tljctYTmwXAjxiZTS1dCAwktu+gr+64VRFFHff30w0YAcfQ4XwIL6Jcd/BBBSsuxaKZp38l+fqjPmP6FZNKR59Axa7FJOpxn8+ZlHgpciNbGzUjKxWNlYgSE2KAigj2ZuZjoW8zRcOYIO1/yykkUsKPEAlA4YT0BDAdeEwdf5xf9vE8JhXnTJFqoJPeKzWTTTRmGhgZAQGz18Kw9kp23btgUAzZs3L7zuuuvOmc3myIAJngPhQogkoI3j8VLKYb5c+FLkqBnWJEKa56kqEQZoHef3LhWx+G3vzou/x7/9qI4kLYIH3oRCj/OeFfsgYzkO3eI8OjtOaJadXfTcpRBoaoUTfhK9iVthwQmtQMSV9WBXbn/KnE4iYagZXumsrf5lA5wrhPpG+KkfmBr4p09VgfERmmXniA04JWF+ibRB8/Oh+Xkth2e1o8fwHJ5ZnOrPMbysrCyD1WqlQYMGtqysLMOyZcvqPv300z6ntnJH8L4GZgMf4tnflcKBo2b4dCjYPE3xr2N6HFoGKDXip9PgXOki7xUydiqMDEysSrXB/Cc8+CYUWjW3nd19V/wKQ66AAV21Sec9O8CS9bB1P/p++xjeUY/H8EwCkg2apfeUh4GmXvx3u2TiVphvvw1JWJEJ2mhI2R1akQlXmZ1vJuesMNAMa0w1R/QSIjU3prvf9bf56GkEqiE9huf4M1glLS0tZNy4cR0ArFarGD9+fMZNN92U5Wu77gheoZTSg+F4hSsOp3gvdu1GwPAA/iWs8zBRXEg4vLDMqxiLGkfKVrDaSouc43rLJjBjSvE5ju+1qbB1wctEzyY9COWpID2KLizzbl7+IGFZ3U3JqDmCB9qYXdMT7onecWVOFNGlSxfLnj17/JvJAvcmnv8ghLhfCNFUCBFtX/zdkZpO6zgweJCy01gLolrAwKkw8deAdQuA/jdWfIwjSuyKiesJYWEFuB7s1ETv53WV2yd38DU+1ZwJ0/dBrp9r/8Z5OX9i2kbo+K32CmA+BdO3a6/BxGyBWDddx+4lNlT4gjsWnn3W8b8ctkmgnf+7U3NpaYI7lmtjeOlb4fyh8o+/9k3/TTSviDt06/G3JMg557jH0WLRmL5GiR1AFmZOMZdG3WDOG4IPvxjOylXjcOXKG9U/8P1pjetJ547Y/ydboc3Z8xZzJsSvg4s273PguEoOMKebd9Zd/8WwPkN7n7hDWxzt7Wuaam/Gt4IE/6Z7LROzBRIvwEIPSnzEVnyIwkeElNU/51Dfvn3lxo0bg90Nr9iUBD/dB9L+pCygQXvN/VmYD7WiodNo+KP+Ob6MO8AhUyZ30ZwZdA5If35NgtmTobTYaevfVfLP5ZNIsOZqXRk0GzoHYczw7VnLWbAhkt5tjTRu24tuPRfSoNtNlHTMLVp0L6++Potix4mN665JZvG/R1ZKP9tYNdEzluqZPlropyCV6fvgmVTfB/R7RsEZC7SrrQWxFIldoRkKUyAkDkLKf7qatlETOHeJDoPpvf0vfNPOw/u54EsIoWxa8TH+RgixSUrZ13Hbtm3bDvXo0cPnOW/BZNu2bQ179OjRpuR2d1KL1QYeA1pJKROEEB2By6SUi/3fzUsPuxW35SPIy9SyrmTu07ZJJBfS4fROsIm6jIzowSfJG0g0HQIIiOiNTID0/bAwsXjyOWg3zEaVXAWxSOwAJKyerL0tS/ROmiE9BWLjoImfrNC3Zy3n4S+HALBiv1aFICx8BG++cSXdujmH215//Ydcf71z1YkrWOOfjriBo9U2zQqJDvtm+3HeXVwMhBl8s/AABjSAWd2ctyUd3M/L+2PJuphA99DtvNLlPUwtH3B5vvkUfOgiS1F5nLXA5LUSCn8m4bIGFQqqS+yCLGLAuoVpOVeSWHiXvtO7L3qNSoVTKbjj0vwvsAmK0mkcQ4vcDKjgCSGuBd5Ce2D9UEr5SiCvFyyOmuHXR6DwIvrdo9iysuc+kUiM0gAWG21TokkzneNbTgXMyrtjBuS2P85XH2VRZ3trDHkR1G1dQNKh8IpP9iNWF4MahxY4C97PI+H4ktLHhUXD3zJ878PXW+yfWXOSSYwUFISyZWtcKcFzRd0gVR2fYYT2NlggYbyABD+miTc1gOT+kLgfFvowRjb7iLY4uzfbQQFwDlYwlIHpQwAbdUMMDGsKU7uBqbEmdkN/gQIvFfehTVez5cw8JnWqg6lpd8ibBpaZaBePBmqBoSHYMtBueYBoD8b+UPgFjmO231of1d95/1QxN6+aTz6vJrjzZ9BeSpmI9ktASqk7mAKHEMIIvAeMAroAtwshupR/VvXk8G+HKczTHpWlg9jJEs/ONmzYwiQH484CcCONi/YlcYT+rGEcmzCT6Zd+3ZfQnJfX2RiYu5An5C7mVrLYARhrl97WRs9RvX4afCRcix2A5Sz8N0Kz+rZN11694dohm/V3+v+HkBhDrfTqmVLhuaG08O6ifiLBAL8a/St2dkwN/BewUkqzLjpWfNCWrEJYeFQTOfMpSPzTe7EDsMgIZh+6l6G/Xc59K5diTl8BRaXBzgLHwLYNSNN7KEHug8L5lAxQutFgL54sS7wqqhru/ClYhBC10P8XhRDtAQ+GYr2iH7BPSnlASmkBvgRuqOCc6keemdObVwHCSeDs76X+z2qQbJqSxifJG0gznQOK3ZlJHGEyO1lPFgs5zUDWMY3dfumeia48yV8x0dUv7XnKnTkOoidg0BzNuls/DbYnlnsqALZ8WDwQNj4FP8d7J3oPTezFVf/8Eq7Mh9tzEPee5y9vvO+WdddKL7tUU2nktUVSjiAUCLQC97rIOJQ6Ak3kHtkAKT5NJCwW0gJpZPaBq4lflYz57ACvWpsR/hQTDJ859LlsSt5w7VU/JtXy6tI1mjNnzhivvfbadm3btu3arl27rkuXLvU5t6A7Ls1ngV+AlkKI+cAg4E5fL1wBzYGjDutpQCXEugWOo2ZtLl7ruOIJ5EdX7GXX8jH6n7WzZZfROpeDozKQwLZJx4uEDqC2ww3gI0on5UzkEO2pTQKtAvNhKpE7XUxl3ZPkeTvWPG18z9OxvbqY+Nf1aay//gQFhBBKIdfyuVvn7mcykXQPmlszkCQdcZhw7jHlOIg0PxLFjs7SkcLrfQ6nKClKRvJtYaScicMU7UUaJGBexB1E5ecw2zoZV3bE1Nqls6jUmFyaASIhIaHliBEjsn755ZcDFy9eFBcuXPDZV1Gh4EkpfxNCbAYGoP3yHpZSBj2CRwiRAFpdl1atqvaN/agZPosHqwWMYfC3n7bzfeEWTo37K4Y8Y9HoEPrrycsvMHtn2cEOI2iEmUzuZwdby4gLe5hdPEkqRgS1MXDclk9Ubj7Tl+wkoXUc9Kl+N+GPDPjkLYqN8+68MdzMfN5kCQfoxRq64X65iz8YyBWsqXGit8AjC6vkf1o5FQuL5qqWFjp/IIAGYYK6oXCo6GFKYhA24hqm+NT2pJC5/Nd6F/kUu/8Fgtl1XVdKMNUkodu5NJJdyVFcHp9NF98zrmRkZBjXrVsX9c033xwCiIiIkBERET5PzXdXMSOATLRKCV2EEEN8vXAFHANaOqy3oGjkWENKmSSl7Cul7NuoUaMAd8c3DqdoYietYLXY+Pq3jXy1vj/CYsCAQArIr1vIoSFn+WjN+lJiF+7wh28AOlGbwawrU+wALiI5SyGnKeCwzKdASM5GhjF5XE+Svn0JNgW4rLofOGmGpePgv7W08TpfxC6qg2+Rm+N5hOfoRje2e3zuHwwmi6r/fXvC+BKTxuZ00xZtfMvxP6qkW9JRxKz6YtNeDRch6hgY/J9yRABzBoDtDsi4HT4fArWM2t9TqJC81+Nxr607OybjWpaFX80U42zGGhYyJeIkq2NqcFkgOzuXRvL26E78ktict0d3Yqfvrsc9e/aERUdHF958881tLr/88i633npr66ysrMBbeEKIGcCtwA6KR2slsMLXi5fDBqCjEKItmtDdBvw1gNfzL3lmOH4L2DR3Y+v2AzCGJmMlFGNoAb9eU4uDYWcZGibBogWjfPbLpiK3ZTQhDKEBU2mHCW1yUhJHeJBdWJG8zqGKihiUQGqZfQGkZMEIEwnmlCpt5Z00w0967lHn6RGln/oN4WB6G1bfT5mTw674l+vtntCUBCLpzh8MpsIyEk7YOE9KjbLyEnSnyoJ0TfwSWsFE5kPUGTA/pB9VXA2iGHvwjxUGvAcNSkyX3x4PR5tR2gos29qb0Ba6NoC4Jtr6/Wtha4nYLYOADIdEzqbGkDwCUk5CXBMDpsZvQ9ZSkLsq/OxlE4YpNA9TxB8Q1hNCLpGp5LuSo7Dq5YGshQZ2JUf5auUVFhaKXbt21X7rrbeODBs2LOeuu+5q+cwzz8S+9dZbPiWQdmcMbyzavLtAB6oUIaUsFEI8CPyKNi3hYymlB9NLK5k8M+SlQK04bT3NufZPy15r+dun8RxeF0fr/ils6DOctDr1+CR5A21Tojk4NIM00/mi428hllk4T1DKoAAb0kOhsyPAIcHA+CVmuPFpr1qqLNJTinOPOo5vSmRp0ZNaMEuD7sXz8H79CxSc0/cbIN8PUxRAG9O7glUc5AmyPXjmO8rLFHKOtj6kBzZvgZQNEHclmHo5b5+7HrgSJvWqnAKvoIlcgsNowiL+hAb50O1r+PMWigSryXYIy4Z6aXC+BQio33wH50qKHUB+OM5i5/rDdIyC+KYwqb0mXo5suV6L5Jy7H/67DwqlNm/QLoh2TI1LnFtXT914vg0V560pQcQcCL9EM6lfHp/NbzNtWAsNGENsXO57eaA2bdpYmjRpYhk2bFgOwK233pr5yiuv+PwE4Y7gHUDzrFea4AFIKX8CfqrMa3rM/qZgKzGYEep69kTLXmtp2UtzmUw9d46FdQaQNiCTtAGZxdZXOcQRTRgGLNgwIpBAQbk+Pod9ArAJou1jeDc+XanW3RHMHCSFtsTRysHKeYWm5JBOJLHUpxUn2ExTejOFddp4W2ghUi/cJhysBYmzpVdf/8qbmIrdliN/0iIzbRYwhHk/fueKupjowXI204tctrp1jo0LHNOngnsqeuYtcP/zsFUPvq0VAckfa6Jn3gJX3w35eu21OYNg9QeVJ3qOtCOGbRyHVusgKh0yOkDMvhJWnJZY9FxZjWTap3KUzPJTvG3OgIozpdjFbFJ7uxVXWhjLpN4hbXK5ZS4UfAZUYKyI2EtX7AC6DM/hH4tT/TmG16pVq8LY2FjLtm3bwnv06JG/ZMmSupdddpnHJZZLUmFqMSHEAqAHkIyD6Ekp/+Hrxf1FUFKLuRI7DzBHdOb62Gc4E9LASfDCEKTQr8iV6XQOmaRwlji03N0pnCWGUOZznC1kU4ikMaEcJo/icRMt0m0ONhIY7XV/veUZpxuX4Hpm8xOPUFhOfe4worCQTbh5ANH3v0fY1mJzpjD2GCHpzZ0Eb/Qa1+Nzgci84kgWZv5gYMUHAgm3rGb3n/0whlh4bFJtZjzu3jXMW2DwBLCV+DN9+VHN0ntkOqwvMazYczRsedW99v2JmUNcxTtYkRjwzOlbxJ7+sPaWUpuFkPSob+D9AR4Il784Xw8tfKEMqrF1V5VTi61Zs6ZWQkJCG4vFIlq1apX/xRdfHGrUqJFbA7xlpRZzR/DucLVdSvmpOxeuDIIieHu9fYQOA0MdMMZC/YdJqn8tCzhJT6KoTyhxRLsUO08QLMa52rSVfvzEOt73qV1PeaaccRdPqJN0L5ELxpMzfgHRD72NwRKBowXQbASMCnBFibLYRFfyKL+KScItq9m13Vlxh/QVvPKYC9fk99r7XpfDPxPhQhkp9MfGw4/LoaCw9L669eC8b/EXXmPmECns4wiZfMBarN5EGu3pD5vGQEEYhBYwoc9x5l3W3v+ddZcLI8FaMsNBazBeBqHjq63YQdUWPF/wOpemlPJTIUQY0EnftEdK6WVlt+rLpvf2s+vrLC6/9mf6TGkIbj3DGqDFKsiaq63WnQS1TE5z8hJM+H2+3BxgMlaHPr5BMwb59RoVccSPUYkXEj7kQoKWo7Luq48Tuq+Tk5SeXOm3S3lMMx5mP5PLPSZ1Vx/9XbFbdsVGiL+7hGvyTsi3lNFICRYml71vzFXutREITLTBRBvMHOJj1mP1JsX0ZeuofdlmZjKWBEyAJnZJmSd4dGM0uQWhNAo18H1f96orTFwBPx+DUc1hnqfx5TkTXYgdEPmFd3k4FUGlwjBPIUQcsBct1df7QGolTEuoUmx6bz8/PtiOA8t78uOTT7Lp3Q2457CJhFomaDJLW3Sx+ywelj2jvR4NQLR6AqOZynEErwFvEIKRqdzm/wuVwxbmBqTdjLl3Yg9fsY/tNAniDb4pCdRjRLnHdLrcPm/POROHpUALQgHt1V2xK49+3WFeENyZJTHRhrvp57WNn0sB9/EN0/SUvUmZJ5hsbkJuQRggOG2RDFxjY9oH/4N3wmBtOGyeWKoO3sQVMP+gljR6/kEYuQRtfO7idO3VFYVmLbjmvNBTibk6JsXLT6YIJu7Ma3gdGCGlHCqlHAKMBGYGtltVi10LnOcQ7fp1vJtnZsM557QgznPytPVAMIMEVvMOL3MvK3iz0tOD5bhV49lz8k1rSV8ziIKOqdjC8t1zZ5q3wvQk7TUAdOdXmjMVA3XQXMkh+qv2e0n6ahCXdzcjhBWjsQCjUWA0QlioNg4Hxa++MPUeWPeV7+34i0lcSQShGL2UPRuSRH6nJ6/xr4ydWtqx8wIyRVG+zcRmt5B0zR3Q2YK5/n7if8nnmc0QvwTMG7bzw8GirOwgJUuO2Zi2JgUuPg058XrlA10AcybC+dpwYSDIY+VnCguJ8+ozKYKLO4IXKqXcY1+RUqbikA/hUuDy8c5JYS8fuaDsg0tyegqcnla02jpOy7YijNpr6zj/9DGJI4xkA0kcKdoWzFyYkT6UsxzM1LJ3Sk30ju/pTO0vGjGqUTnHgiZycXfC029prwESvbbMYCDZDKaQwRTorzbaM4f6jCD5qz+x7Qyh8M8wVn4GL/yj2J0J2muED1k3RgzC7UCYysJEG5K5jxcY5VM72zhOljijhXZaJBSiFZ7LESBgQcZ4EJByJg6LNGIFLFZJyoKvaZe5yyHIU4AQJB58gqTD92j55lZdBecHwsWnoGA+SD2YyjF3dUlCJlSuO7Mii1ThNu4I3kYhxIdCiDh9+QContVWvaTPA+257qVnaTf4V657IYE+t35Y8UlFSDiXqAW57K1Nyw7T+FsyXP0C/C25OK+mLyRxhG+aNiJC9OGbpo1owyuEcg39ud/3xr2kF5MAA8mE8xZRzCWSNKdAGteEU4+RzKDMicYSsIHBAle9GgOf/1i+iCV+CBaLNg/RYoGBf4WRf/fiE3lHUxLoxq80pTiwwdQLnkxwDlgBeOsp769zoHRK1SqBiTY8yXDvG7CLVW4d/Y3DZPY8CRYYH7MAJMQ1TCGMAoxIwigk7tTvvL9N/xuwB+fpEdELjo3XkhRcYXU0xssWOUci53n/eTwkq3AaBw0DGXKhB7VOd2fomSVkMK3iExUucWce3n3AA4B9GsJKqORwvypAnym16HOzb0+qkAfnEmnZ5hgtn/TfH823TWOonR4BQO30CDo1fYDDJ5awnt005SbG6gErkxhRadZeK0wsIxKz/kyVjYFPqcMdXKCFHsiQljaAw4fjaN06hRYttLBCI5qZM5h/scqphKnG4MVXEmE+RNuU2rRaWxuQkLIeTD1Ld8K8FRallN6+ZDXU7w9GA5w9D3Vqw5IPXbdRiSTcqr0+/ipkeziTqX93//cnqBTVhgQQ0GQf2ri5AccpN2NTvyPh4IfQF0wb15L8xzBSGg8jbvCVmLI3gyWPKEsm2WENnJMvnFig3cniippyPfXPjn1fvcor/ZNFEhnGRO7I+JGVBdq9Z0XBNcSfqsNPjUfSjCCFJldjKrTw9Awr7wL/Qauc8F5lZl2pMtSKA+GnmnAXPteys/iJ8HSttoh9blqt9OJUdumcZTY/MJsfGMhDJAW2bq8T64osOu0GJYEdRAGa2H02bxnLUl7ks3nLSEvTSrM04nIARjKjhGvTwPXMYeSOexn6SkNd7IDQEIjrV3yY43jd3IVgKyO46Hy2Jnagxf4P/GvA3J2ekHArZG3UMlzJXVoQijt8vUSL9KyqrMHDabuCIhckAI0OwYBvAJsmXFISbs1n6q5XYbmA14AUMJ1dy5O7X8b0y9Nw75sAZP0YQ/TF0yAlRquFOVsSSFj0IaxGc4/aA0klzuN2VkAKEC0gck2lih1ADtrQyYYCe4yg9l1ssw7AbMniJBMrtT+VybZt28I7d+7cxb7UqVOn1/PPP+/zDEx3cmleB8wG9qN9422FEJOllD/7evFqRS0TNF+mTTHITYbCo2i1TLxMdJuXorXpB/JjM4hIb1iUczIvtuw8WpN5g+60rRRLz5XU1KYLL7CaoX8sxGrV0khZrQY++eNeIlv8yX8dcoaPZIbu3nQgbquWaiTfAgYDvPvvYsvMvFWL9c+3aNabpxZbWZZiEFn3VfH8vPQz8MMysLr4Yi0WLdKzpJu0qmCiDf1oxXqHMWZnykglZrfKJIw9O49RB+axRVwHUjLpyFxMmeshJAwKSjyDp+2E94uni2T8XCKvGMA+YAbQGW1M0ISWsr4gDMQj0Nr7NHD+IJLxXBRLuDJ0hW7h2c1QK2stcfQOe4VDJNOGE0HtZyDo0aNH/u7du3cCFBYWEhsb2+O2224752u77rg0XweullLug6ICsD8Cl5bggSZQJUUqbSTklVF2u0xCivNu+oEeJ75jS9Nx1EqPIS82g99O3Fru8QN5iDW8w3YO8hE/0YwYpnKb30WwLlGcIwtHf5HgNAAtRYlimwJyMHIPP3JzeY2aemrRHinriyw786yFpPTtR9zWQ5jyLZpVZ7PBSvfL+ADOlmIVwtSrWMjE5eDa/yb8EukZSNbxCG14gcNkuthbnBVI+zjF6yEFWQzcs5mp36Vi2muBKWMgOwMG3gXZ10O3OFi3EL51oypwSfYBB4xQpwFE3w0DgityjtTVx30frvsCe892JV22BKxEYGFAWArh5r5EpAwiPe5mYk1fB7ez+5ZGsj85ivbx2XTwPbWYI4sWLarbqlWr/E6dOvk8cccdwcu2i53OAcDn5KA1hha/FmVd2b1lADvWxdG1fwqde5WV6sIAjd71m3UH2hSEFidu4RjuJ0cYyENO6wtZzRwe82v6sXNFP5PiZMATdTl7oHssX2+zYbHawFgA3f8HuPnDMvXUlqSvMM9aRPysD7hoCEX0H8PjD55mxtv6rJkKsgg5Mee5Kmfducamu9kcNunjXdvnrcDUa2iQ+uUeXzCGq3gBKw0xcobb+Aufs8MhLboEDA7/dwcpDN3Him4w9KU2LH/6EKYDW+C+Wc4NdzZBbHv47SM4uEV/6HHT+zJ9pXZ+FSKLJHJYwDbL9UzMSMZCGGFYuKn2f7mx1lxMmwqJjV+AyA9DGmzwXh4kBKls+r6lkcwd3QlrgYHVM21MWpzqT9H74osvom+66Sa/pH93R/A2CiF+Ar5C+zXeDGwQQtwIIKX81h8dqe7s3jKAZ+9IptASRkiYhf98Gu8gegYwNIZaA6DBVL+KHcBEXvZI7Mpiih/dnWbWu9gq+IpdLGMyp1uc5pGJ95B4eBO0XgUtNuB0FzdvLbbiHF2W9m33/Bt2HSDl7r9zMTQUGRKClJLEu+4FoP6FC8RtXI/pj22ae9OVH9DOnOcgoXT+xqqIERvWktGuQquGsWBRHgkx06BufUjdAVvXwbU3wlPBtVqSjhSXEcpotQEtj8UewEhXbKzmH8xlJXCWSQxloUjl87wULhSmcq7OiaJxvAIjpHSLxFTWrXRkgrbsNsOfKRAV4+TWdEloRJUUuww9e0+ypTcWwrARghVJM+MReoetJSLlYUR+GMIWAjaJfDAL0T0ETEGYMba/RHmg/clR/hK8ixcviqVLl9Z74403/BKH7I7gRQAnAfuj42mgFjAGTQCV4GFgx7o4Ci1h2GwhFBZIdqz/C50HxUK0/wXOkWkkMZ+lfmlLAnNZ4hfBS2GV/s550v4SlhUds6TFMq20bwmmpd3HjPh12sBUWJjmwgRtfM5icRKvuI3ri2749tfEO+8pej9izSp+ffRBeP//4Mk34ew554tVI7EDuK3NVuYf7OPSeh1vXQBzPnLeNzsRkn+A5J1a0V9zCpjiiqplrDPD/Lnw+w7YexGsd4P8O1grnkHiFklHYPKf2vslZ2AqIwlrNQcLBYQRShxXFqUjs2OiJzNq3UISXzNZPlf0eUKtkrg/c+DuSeVftLOpWMR2rIDlZWRLARjobhKJysMerAIwICyFMCwUIAmlgAFhKQBcjFutWXY2rVyWtAIpBcERvPbx2ax2KA/U3vfyQHa++eabel26dMlt2bKli6yxnuNOLs27/HGhGk1HK137DyIkzEJhgSQkTNB1/DPQPPCX/hb/JpKczQ9eT18wp8Hcw0eh9Sp6tYj2ug+Jzb5k7c+hdNkZSq+tYfwc/QB7ok+TtSuD7HqSAUtNnCp4lZ3t24OUCJsNaXAIOHaI7lsy6ComvvYG8xKGa8I27XX4fDG0awGv/LOauDF1NpmZt3MQhH7CfONfsQdZ15YXmFn4TxIKy5gfuncXTBwJa5eDJR+E4N9yDkmn7uBCvjYNRHckYtgAhQfAON0/oregRMKdremtSG71ISls0MWuZ5nnJnAzCPgo7WWapWUydXk4pruTPbPIHpsHMc1dj++F1tL2VzHC6MlFtLiA3mFrmRcTz1pLHAPCUugdpnmN8k0byXhvGg0fTERaBYRLiAtSPpAOw3OYtDg1EGN4X375ZfQtt9xy1l/tuVMtoS3wENAGB4GUUl7vr074SlCqJbhgtxl2pEDXuMrzkoxkKkv8lQdg4ROwcxhIQb+mRtbd7d5p5jR44ndYcdQGSDAWEDbxZt5pMZ5/8xKnPXW3lveTzLkS9v8E0sXd2KGqu+P7EGmjoJefTJZgcu84WLLQu3ONRrBqY1p3Z3zKl7l/c9hZ7Eq2f/WWlWAd7N2lHHG08ADmdHMuGlupPNAF0hwqms9YU+XcmQDnmE4m7mUhCDf3pVbKcBrEPe+VdVeVqyVkZWUZWrVqdcX+/fu3x8TEeBQO73W1BGAh8BHwA16WuLpUcPSkVDs+nw4Hi6MU158A8ZL21P/4AJgRr203p0GiGVLPQoEV0rIgr+inKAADWA1Y/hhHRouznGIv45jIQn50vy+lAxCLybwNMJZdNNdR7HQKDUamHYMZlWBxB5T1blRYt7t3S6KL3b/PvewgdqW/Q3t4UchVsG4N9Pfx92wXN/sYXlDEzj6m99BH2vqfKVpkZxX9Y40gDi39S8X3+HzTRoymFtTEbI9169a1nTt3bqs/23RH8C5KKd/250UV/mM8Q3y38NK6wEF7TLvzTdAGJK6Fb/fAvwbAA79CYZmPPcLpbRKf8gvJrGCN930reU/O6eO8XiJlVOnzte2J+vNqtRa9nAsVHyOlkzXnyMcX7uWN7Cf0teLIWfuX7PhsYQSuHgjL/CR6QbPqdpvh6aFQWAAhofDScrjpySB1xj0iMBHF38lmtlvH1ysv96zCCXdyab4lhHhWCGESQvS2LwHvmcItEhjNHB4jlgZEEsEEhiP5vVQ5oB60pyeui2h2OHwdFSUR3JcJU34uT+zs6DfRzJYc4ohPYjeW6xjBsOINZyZB/hUOl3IhdmUJH5romf06Q6iSqR/j3nHhES43P5L5rv7OdeJIUeIVYEWK+92rknz6hCZ2oL3+3zXwadXPRVmHSbhnjxiIoGpaqlURd77R7sDfgGHgNFlmWJlnKCqVBEaXmj83Q5+0+i0ruZGritbN7OA+3mQPR6lPHSalPUJW1mAOCrBWMG3NvVltuuVwwrdnojX8ignNxTqN53idd7GeetThGpQrbmUxcB/IHj51LXg89hw8WUGYPUBuaVXvfXwbhZQsx1DSX1yaXTvc7VwVZLcZdq1y3pafUxzAckfVmWReEs3Ku9fByhM04CWy+Awr9nFII23xS/DiJYM7gncz0E5K6YfylIrKZAYJRUJnx0RXtvIBoI3Hxc8HixUMAhrXhhNuW0CO8ueYfVff3v43n/o+kJFIPSPHDJ6DnCtJLGjmU5vVngkJMOdVOLSv4mNLkGrtor9zFLiKHxi+nA/NmsOLVVcbyubPlLKTD3z7apUWPG3i+UKHLZJMniKcEbRiZ7C6Ve1xx6X5J1A/wP1QBIGUw5rYWSUU2CA9B2qFwJo74PJyvWeyxGJDu3lqUZrGtsvpOfZ9unBZabekB0zUJ9+ac+DNfddREwfmPWbmXK8s205G+02yZIbkivney5m20zhBR/YwzSHXo5kcpnMKM5XgW+4Wpz3JuaRyE0F7wkkmksFkbC6KKOezhIMIDuKme1vhhDsWXn1gtxBiA1CUobUqTUtQeEdcawgzwsXC4lugxaoJ4c4p0GQmnMot62yDdkbv/zJl1J9MSnuDlMMG4lqDqUUc4BxROJHJLGQxOZTZYCl+RrMSUy5oabrdsUgqotpPTuhjgm9Xw9P3we4/y06f1aUH7NxWtLq5WQ8ij1qQhODp93jDjZ53sz97WZ9pgGMNSZSQ2GI/okGuk8y0JoRDenWMgNDZBM0uK5qKcPTHDLDWB/JoPHg4fqp94leySCKXcibKF3GWg8TQFr9k3LpkcMfCexYYB7yMlkjaviiqOaYWkDwBJveCcCMYhSaAca21/WU+HDveMGVxW08O0l5dMY85XOAYkkzmMJPLuYy6RBFSjgSN4hoA4uqUtu28kT4jUFhdx+8c6WOCX7bCoUL4rkRQkNEIRyS8NAsiamkVJUJCYfocbp0QiiffXHQ0PDbVc3fmRI5oYreuLRyJhqPRsLYtMrO203GHKaQLezxr3FOufwSwi10DtM9fm1OrVpJfBQuIZ5nXIaY/AeYBFR+M3+ZjV0n+85//NO7QoUPXjh07dh0zZkzb3Nxcn5943amHtxzYDUTpyy59m6IGYGoBs/4CyybCC0M1AbSL1oAyQ/h1e9BgIfSKBUwqERFaEQncyU7Wcp4jFHAGSSZr+JWXeYYRDCOaBkzgFuYxR+tjJKR0gCnR2rKmA9h6wMux7l9T9qghYleSPiZN9Ka+rL0eLCze/kUyPP4ifL0cJiTwcRlJRbr3hHfnQLiDyRMWBgsWey52ZnL4nPOQEQk2exSo0BJeZ0SWOn4XFieXp98ZmQA9R+iWHcX9wUB+SuAu6w35ZpDx72N45gWM8cluiJ732YyqOgcPHgxNSkpqsnXr1p179+7dYbVaxYcffujzB3anHt4twKtACtov5R0hxL+klN/4enFF1cHUorR1NtUEC1NLH9uzsaBNi5PEdv+dSS2eLYqm9On69MNEP57kMdf7I7XFkbg6rqfnOs4wg2oclekufUxFuTEr2p4rISpEm6ZnNEK2Q5Bf1+5aXk2ACZO8m383l0ztu4/JAYMsjusWUtvmgkTOsJFUrJzmRkL4B2M9v3B5/OdXeN5KsXWrBVgZqtgwWH4KYAlDWAXSIhEpcUhTWVVXoqqWO/Po0kjSkqNoEZ9NS/+kFrNarSInJ8cQHh5uzcvLM7Ro0aLA1zbdGcN7GrhSSnkKQAjRCFgKKMGr4ZhaQM/GsPVU8bYhLWH5JIAmwO1B6pmGKRJWdoAnjsOGPC0gb3w9mNcmqN2q8mSXEcne3+TbJHMzOcy217prkAv9D8Kx+pq+tDinbXOJ5HcaAA3QXEcL/S56of2MFKy3j1RrwmepYhXiw+NAhOliF2ZFxpmBCMIZQm3iMBCDjQwiiKtac++OLo3kR7080LaZNq5bnOqr6LVt27bggQceSG/btu0V4eHhtquuuirrxhtvzPK1q27NbLSLnU4G7o39KWoA74+Cq+ZqkZxGAa9UsdmXpkhY3jHYvVAApJSMvGyQW47IuUKzzT81dyU35QyPxjUk3A/39XwzFGyyt19MzmwtUXbjX32/hj8IN0GjZMhPEYTHRRBuSgl2l9wjTS8PhA1shQbSkqN8FbzTp08bf/zxx/r79u3bHhMTY73uuuvavf/++9H333+/TwOX7gjXL0KIX4UQdwoh7uRSrXZ+iWJqASsnwctx2mtZQSkKRRylx+jcwz6uJultrs0X8e259d8xHL/Kxulx+BxccvZ+ykxLmb8ETo30rX1/Em6Cuk/iF6GvNFrEZ2MMtSGMYAix0cL38kA//PBD3VatWuU3a9asMDw8XI4dO/bcmjVr6vjarjvlgf6lF3u1505PklJ+5+uFFdUHV+N7CjhrhowUiImD6Op0gwoQJiIJxT6FxFO0UVdTSh1C8wUhNoEE8hZKLv4kaJziuQicmwbZLqoClSR/iSaq1UpkqhIth+dw3eJUf47htWnTxrJ58+Y62dnZhsjISNvvv/8e1adPH0/cBS4pU/CEEB2AJlLK1XpV82/17YOFEO2llPt9vbhCUV05a4Y18WC7CAiIugKsOZC7H5BQ70oYui7Yvax8rqYOS3AjyXUpNHejOS4HhNRH2vSk1gVSc/N5IEjuip2dM7dA86MedFfhTMvhOf4KVgEYNmxYzpgxYzKvuOKKy0NCQujatWvuY489dtrXdstzab4JuBokPK/vUyguOQ4lwW9tYdUQsOVRlGgmeyvk7sWebIbz62GRKF6Su8De6ZpQ1mTGU9en8zebcvhtTLFHTCKxGrSADnfJN0P2uxUf54gtzb+uzXwzZE333R17KTNz5szjBw8e3LF3794dCxcuPFirVi2f0+OUJ3hNpJTbS27Ut7Xx9cIKRXXjUBL8MRnyDoGnOXtzdsGup2DN1ZUvev+jP+9g5D3CWU1gKwUkEMMcmhHlcWqA4lJFc6aexhImsQqJ1Sj5+v2tbDZtdauVfDOcGgoeJPQpPncJXEjy/DxXfTgdD+efglMD4aiAo6FwtBZkTPS9fYX3lDeGV7+cfbX83A+FIqAcSoId/wJrFmCE5rdBnzImYrvirBm2P+h7P2z5sOEWqNUMIppBB72UWSDGAk9g5mduIYc07dpY2Ewim9F8fb2ZyiD8n0A5gRi6E8FADpTYUzLhuCskm0253JqyB1OKFXPcEjabPsaAgQZEYcDAXYxjhov5mtN4g5i5Lbmt4KYid6in5C6AOgkVH+dIxkTI/Rzt49WHyNtA5pU4qFBbcvWsYTEe/PYU/qM8wdsohPi7lPIDx41CiHuBTYHtlkLhI0fMcCAF2sVx6PVj/PH2+OJ9Vjg2H0C4JXpnzbAmzoYscFUxznPy07QFIH0hiFCQNjCEwcBk/4jeaqaxmVcpL0myJn6v8ZAblbU9xUQka2jnIHq6rxeBFtZiRGBElipvD3CEzaYn2OzwPdiwkcF5ABL5mF9Zg4kr6MXl/MxKfmQFBRQyJ/1Nn/pde3zFx9jJN0PmfVCwzWHjOW26Q3nkLlCCFyzKE7xHgO+EEBMoFri+QBhabk2FomryyzRYURyxsCvJPo3U+eZ6atEFoOJI54yFh7FZWuKr0JWF1MMabXmwZhhEdoboAdBykvvit5pp7Odb2nMj9WhfZMVVjI33iOABLnrV9/IwEYmkOwDT+YBneAdrUeqVThjpzmOMI5UMFrIb6AisB76ssO1t7GYbu0ttPxPrRfaR2oANDA3hwkfapoqsPLvbspQlVyESLIH5HSkqpkzBk1KeBAYKIa4Guumbf5RS/u7rRYUQrwJjAAuwH7hLSnlO3/ckcA/azJl/SCmryLRQRZXmiFkTuX3JYHGeBlRoiSpxsGZJNO7wG+48u2WtPQG0oqKCqaIWdH8TzusZPI59BYUeTpO1XZRkb9WCYI7+VzBwGeSbzKRwH+c5QFuuZyTzOIGZ3czlLDs5yXqsumC5L3QO1ywughIw4riSMMK4SD5aDGYqkv1kYWQR31Ccg8w3FkxaxK0fjiO0UEs3Xq5rMwTN1aiP99nStCVzPZx/GbBq/6eGBlDnHk0E882QMxcsm70RO/0XJKzUgLod1RJ35uEtA5b5+bq/AU9KKQuFEDOAJ4FpQoguwG1AV6AZsFQI0UlK6X+fi6L68tVE2KoPhggj1GoAuWfKPDym1e+cOTQKR/dewzY/0+fltVQkeGe/286xlVfqa45ZOrUbaUh9GPCTa0sspC7s91h/im/QtnzJ6pR5HDLdiV0QUpnPPr7GhpUyZ1N7iKESCuWY6EkyHzKXRfyXhRRiJYxQFvAbNj+JHcBm0zZuWXEX98ydwG38BUNdyH4D7asyQtRjYMuCnI/RHrfLwHa4+L0VTQQzJ6OF+XnZXan/dgzxB4EO3jWi8ImgpAiTUi6RUtrj3NYC9mnNNwBfSinzpZQHgX3gh8zEipqDo9gBSGu5Ygcw8PbraNjmZwzGi9Sun8rgvw1k4IzP4dpyAjaOmOGzcWS8/aVeNbtY7KIuv8DgNXC9hL9klu12DKvv0SdzQuq3x4KZwwkzO/8J2LDgL7EDY0Dcma4w0ZNZ/B/L+JgXeJA2NOO0PfemnxDAZNNY7p/1F6JnQf0Z0HgF1HtJe60/A0Ja4f3X55XYFT9oyVo5xPzq83SyS4IXXnihcceOHbt26NCh6/PPP9/YH226k0sz0NwN/E9/3xxNAO2k6dsUNY0jZvjlCTh7AHr+tXzxcWSPd1ntBt5+nfOG/HJqCx0xw+zBgI2YlukYQp7GVggIQfvJJ+g6y720MzFxXnUV0FxxEonxdCxNhqRwckUcljIz57tPGPVpw3Vc5DTtGU83PAxJ9AMmemKiJ/+Hh5PlKiCWhpwgpdT2cJNzFhUtSTPIfPzlSa0A7WFJCEmD5INVK/FzFWXDhg0Rc+fObbR58+ZdERERtqFDh3a68cYbz3fr1s0n/3vABE8IsRRwdVd5Wkr5vX7M02hedHdK/JZsPwG0v9ZWrVr50FNFpXPEDLMHFq+vSITVbwM2qB0N8f+BfmXciC8b5WzhecuZcgqPfnUH9jthdIu1DLw9noyjw4j5x21Ej+vu9iWiTdB8gj0i1HOKxp8KQ4lI8V3wjIRxPT/RtIrccHvThfWUmurrMY1owPe8g4mebh1fnKQZbOfgYgpIiy6ABdrYnLE5FKaCFlngDwQRNwiiTO7/fqoVJ5dGcjI5iibx2TTxPePK9u3ba/Xq1etCVFSUDWDQoEHZX375Zf0XX3zxpC/tBkzwpJTDy9uvJ6IeDcRLKe02/zGgpcNhLfRtrtpPApIA+vbt6/MMfEWAOGKGzXqRNUs27P0Nck6VPs6qu9Wy02HhZFj3PtwwC1qVuDnfosdz+yp6kY1cb1+fBGf3Om2KbrGW6Afvgn6e3azOmqFuV2CCNs8uPwNkCe9hSDTU7QYX9oLlRHFKLenoBgsp4GJcikfXLomRWowjucqIHcA6vqA/t3steh1ozVxeclvoHClp9ZXF0RD85j02elCwuFpxcmkkK0d3wlZgIHWmjasWp/oqej179sx7/vnnm6enpxsjIyPlb7/9Vq9Hjx4+C2lQxvCEENcCU4HrpZSOOREWAbcJIcKFEG0pjlNWVEeOmHk07hzDbn6VRx8do4mUK7FzxYltkDRUE8yS3DIPXpbaMnYOtPBimLdxF9fb/1zgentZFmcZ2HNt7noGTnyrWXrGsNLHDVgMg5fDtcchdOqvYLAhsYGQWGOPkTv2O5/dmUZqcz+5VUrs7KzjC6Zyt1fntqOFV2LnCaJkgK+3hEDkJD+1VdU4mRyFzaE80Mlkn7+13r17X3z44YfT4+PjO1199dUdu3btmms0+h7ZGqy6du8CUcBvQoitQojZAFLKHcBXwE7gF+ABFaFZfXn0hijWH7yW/MJI1h8axaNf/OhZA7YCbfJ4efRLgPvXweVj3W/XEArNesHC+7TFUVS7eTDzuBwyUsCmx5bY8rRozcISmWmb65afPdXYiRl/J33VYM69/DTpqwdx7ERLznw33iuxq0dHmtCPq5nD/SXr1FUxZvCYV6K3ko0B6I0znmZdcSSkC4QNgcgpWsBMja3G0CQ+G0OoDfTyQE18Lw8E8Oijj57ZsWPHro0bN+5p0KCBtVOnTj5HVwUlaEVKWWZMrpTyJeClSuyOIkBs22mvzKoN2m9LG+JZA4ZQaBfn3rFDp0LqT2DVY83rxIIhBLLSHA6yh/xL+P5+LcITYOOH0HIgnD9S4niH846YS7tXy+CsWQtjF4B0nMmgY4yENg/AwXfg2JcgwqxkJt9IjikNTGkOAmcghHCu4k32MJ8sDtCJv1KP9qzjWXJJd3n9xvTjVqpXqYYZPMaHLOCsnk3FHa6ibwB7pFFfj6XypPICQIM5volltaLJ8ByuWpzqzzE8gGPHjoU0b968cO/evWE//vhj/Q0bNpTONOAhVSFKU1FD6TEgh/UrwrDf8Xu0WOHeibVioO1VMGSq2yJDKxP8PaUonRitTJAyHZb8G+dQPAk2K04qZCuEw8V9290Sfu+lvR+2BToflfDtvXDjhxX256xZSxBtKyeWzJoDR9dC4UUwSCjMM/DzwO/4HqgVfYbnMpogCGEAz9OcOJpicoqmPIGZdowlHTNn2Faq/VOs5x0EkbRgFF9VSVemKzJYTQyDOMt5jBi5jVFsZid5XKQVTYmmHhvYyWkyiKMfvzKnUvpVfwaEtNfn4ZUkSquYnjMXrOnaOF3kpBpszZVFk+E5/hI6O9dff337c+fOhYSEhMg333zzSMOGDX329inBUwSMmcujebTLGrbtvYIeLVYws+TUgJIMmer+9ARXtDI5C1K7OAgNh0ILGIyA0MQNiq07nU9GQEoPzSo7U48iY3BJXxi7Cg4028nAzVdxLSv5pdV2zrQZTp3DrSmsf4FhP9UrmotX5Mp0wHEWn/11xwotd0sIkkJgp37BvLONeC7mJB9l/I2+POnUzgm0jCuOIicwEkZ98imdUiuHNL5hMDexqlqJXlXEbq3lLtDybZa03i45gasENm3aVE4otXcowVMElJk7B8JzdUul+yrGAAYDXP+ex4EhFdLKBPckF1t9AAdS2G1NYUGTJZytC9dshPRoWDC0xLm64FmNxfu2dLTy34Krua7Nn9Q73BaA0HN1WTnIxlWrDUSbtLl3hrBiC89uRzpPXYcdwFygC4KdQHFcqCTvbEPG4pxR7wRmFjBEl0ccjra6FLtibBwjpUoKnmOEZighWNga3A5VQJ2ES8hNWUNRgqcIPJbyKmDbtIGuXC+S/rpDCatv94WFPNFpCVY94Cu1JdS1a3F5OX11tcoNzafukbb6Jr0it9Qsu2iTtgxcBkfnwvnNkLleFh+nN2MDnNMwOg/y1Yo+w0L+5iR6x0gpJXbuYuapUtZisCk5HaGAQsLoWeVFT1G9CVaUpuJSQpRWkj/TBjB3zRP8mTZACy5xNzjFR7bnfovVgKY8erci7Doiy3i1o5+T1eqgvltPACakU1aVaBP0mAUn79mvF8WRRfPqrGjFcToD/wFuBf6NNv8GICwqk+cympCGc4725sQhXD6fuvcn/E6AKj14y2Z2ltpW4KWgKxTuogRPEXg6OOcg+DNtAA9+vow5y1/kvnkr+P5MxcEg/qJ77Rsx2kuz6YJ28/ERrsvGCZyE0c7XhzpyvvV+JDYK6p8rcmc6ss4Mdz/UiueA40ABglTgKyRrkfTUK8EZgFAEXfSLDHvyVQDCqOvUXlNMjGcFzRhCGPWJog1XM4ebWEU3phDiRpmjqkRvSs+DDFUOJ0WAUb8wReC561f+fPwefkruS2ZOEw6f7USBNRwQ2KSB15Im0H4SdKsEzevcZQav7IQFIe9zNqqQay6O59pu8/icpmTaw/zdMIa+PqTZZOOZSjQz2I2Z7aTQnTg6Y+LDlPVYC/qwF8E/AUdFnalfwHFMb6f+rp2eUWUg00tdUxO95S63X82sovWqZs25omSWleowhqeo/ijBUwSc75Pg1ZkfIW2uzSibDeYnwvTvKqc/nbvM4Gmco0H/yn94D1dx5+XzCx8wgLE8TTyFWACJgRAy4nojQpchLSWdKIJ1aGVB7InEVgJ7EcS2PsdVprq0Z45PSZ0fQvIOzjmxHiqn8nmwWMcXwe6C4hJDCZ4ioPxphsQp6KaMc8VxR1Yu0oTxfAb0jqsca8+Ra0kgnf0s8LCAag6ZLCARi0MYSqa5N5kpcVz2zkMc/+gesjb0A2nA7ke11/PuD6xDq+/d+XLYvLM+lIjO9JaH1HiYohpz8803t0lOTq4XExNTuHfv3h0AJ0+eNI4bN67dsWPHwps3b57//fffH2jUqJFHc/PUGJ4ioMxLxPX4WAm3m7TBa/fDnKdg8kAYJIqXR0cGvp+7MRNJfR5gDm3pQSgR1CaKxrTBUEF16rUsLHp/3jyAzfHJ7H/mBVIfeYtm93yEIeIiGAsQ4fnU7rgfY0Q+v8VaCJ0j+FhCroTNpWM4FIpLlrvvvvvMokWLnLK4P/vss03j4uKyDx8+/GdcXFz2//3f/3mcjltZeIqAsnermwcKPQGKC9Yv0YQPIKI2/GMm3ODH+VC7MfM08RRgT4+iRVUWcJFcPEsLmJkSh80SBtYQbBZJg4wr+Sh5Pz+mZHBdXAy31tTyMIpLm3NLIzmXHEX9+Gzq+55xZdSoURf27NnjlG79l19+qb98+fI9AJMnT84YOnToZZRRTacslOApAkp4LfeOC4sAS17Fx13MhcTJ2qJhI3TEEjr9+hCPMZfO+gTrkkEkjpTct50UCsjXqhT4SIO4FAxhFmwWiSGsgIQ4E7eaunNr1Zv3rVD4h3NLI9k5uhOywMDxmTa6LE71h+iVJCMjI6R169YFAC1btizIyMjwWL+U4CkCyq2POIpT2bgjdqXRgj4KloxkR9QGHlkyilhTGrWpy3FSkUhCCGMMD7GdFLLJJJfzZOuZSUII4++8yWmO6DXovOMHJDcRST651DOtpXdyPJkpcYyLa8Gtpge8bFWhqCacS45C6uWBZKFBs/T8L3iOGAwGhIv5vRWhBE8RUG5IgGP7tSjMigivDZ37wp9rwOpWzIVD9YML9cgevAJWDSHUoZyOhYtlBqIUkM9sHkAiMWDA5kWlzx90mfxGL8HzC0msMS1goKkt1/oQaalQVBvqx2dzfKYNWWhAhNio75/yQCWJiYkpPHz4cGjr1q0LDh8+HBodHe1xZJYKWlEEnPtnwJw1MHYKhLoogmonPxdGToAVBbBawoSpYCz3kcxuk+mzw20h5D7hPH9NlDMnzYARGzZsWCmkAFcT8BrT2uW5AkOR2DlyLQk8z69K7BSXDvWH59BlcSrN/3UsUO5MgJEjR56bM2dODMCcOXNirr322nOetiGkrHrzczylb9++cuPGwBeDVPjOn2b4aS58P7v848JrQ/8R0LITfPF62QEtrkJAjSN+JixuJSFxKUSYNmGloNQxEdQhkvpk4Kr+ncZ4pvIzs0oFrrzKmlLjggpFdUQIsUlK6VRYcNu2bYd69OhxJlh9AhgzZkzbtWvXRmVmZobExMQUPvHEE8dvv/32zHHjxrU/fvx4WPPmzS3ffffd/iZNmri8M2zbtq1hjx492pTcrgRPUen8adamHniL0P0S0mWMif33bIOwAqJSrnZycXpCJ/qRyvpS2yOow9ceRm8qFFWRqip4vlKW4CmXpqLS+Wmub+dLW3liZ3dLGsESTvar/2Lf60+QuW6Ay7bWjv2Rnxpns3bsj6X2uRI7gItc4GumsxuzV/1XKBTBQQWtKCqdwGZ6dBQ9uLDoenYvux5DmAXTonga9C+29lZevZrzmzTX5JnfR7Hsym1cvaFHmS1nrhtAxqo4YganMK//M4QQxkskK/emQlFNUBaeotIZNSlQLZfI3gKE2Az6JPBQMlbFFe3LXDegSOzs5+Xs6c7h/97rsuXMdQMwX5/M7hdfwHx9MhnrrqQQC9tJ8f/HUCgUAUEJnqLS6WbSIjA9RRigUeN8SgeqSJzq/ejvBXCmViEYCzCEFRAzOKXoDE38HOuQa6KX/v14l9fOWOWYQSWUjFVXE0IY3Ynz/IMoFIqgoFyaikrnTzPMf7XkVkfxccSGUU/1FWor4K5TT/Mar2JzyG9pwMpgfqEBp8gjEjMjsIRJ+MccWt60iNor44i5KsXJnRkzOAVDrYvY8iKcrht7wwKXfY4ZXJxBxRhWwHWD63OvcmcqFNUKJXiKSufnubiYTeBsaRVjQGLleuYxiv/RjY20Zxfv8wyH6UgbUrmPF+nGRq2yusEAg/rB8ZPs3niYBddaOfDAYfJqWcglFImN5nSiU38bXRc9z95VnUg/n0X+H4PpfsN62t/1B9cwhzZ0d05N1h++WLSdH1ZlMGZwDLf398JEVSgUQUUJnqLSKXsiTEmxKxbAJqRpogZ0YyPvc4PzoQYDJEyCSbeC6UoAOgNPl9eR/vpSRF/g/qK1ktbb7f27c7vT8QqFIhC4Kg/08ccfN3j55ZebHThwICIlJWXXkCFDcj1tV43hKSqdvzgFrTiPu5Uej7MRioXerC7dUKOGULs29OgGq36EWa8ViZ1Coai+uCoP1LNnz7wFCxbs69u37wVv21UWnqLS6WbSUo09fQucSQNH0RNYMWLFSgitSOVaFtC71ma65W+mqJhBm5bw5KOaRadQKIJP7tJIcpOjqB2fTe3AlAfq3bv3RV/bVYKnCArdTPD9Ufiz/7/ZvD6C3qwuclk6YTRC8mJluSkUVZXcpZEc18sDnZtpo9niVH+IXiBQLk1FUOm27iUmjdhON+MWCA+DkBBtPM5ohLF/gZVK7BSKKk1uifJAuclRwe5SWSgLTxF8fv2q+L15A6SshrhBSugUiupA7fhszjmUB6odmPJA/kAJnqJqYbqyxgudeR2krIK4wWBSUZ+K6k7t4Tk0W5zqzzG8QKEET6GoRMzrIP56sFi0aYMNG0J6uvMxUx+BGc8HpXsKhXfUHp7jT6FzLA/UpEmTK5544onjMTExhf/6179aZWZmhowbN67j5Zdfnrtq1aq9FbdWjBI8hSKAmNfBE8/C+s1aTb9CK9gcKj2UFDuAxDe1VyV6ikuVH3744aCr7ZMmTTrnS7sqaEWhCADmvyTSq852Bl5jY8UaycWLYClwFrvysIueQqHwH8rCUyj8EShj3gBz/wc795C07QqmWP+DFEY9WYx3BZFEXZBZ3nVHoVCURgme4tLGvAGuGg1Wq7Y+9i8w9SHPhM+8AeJuAIsFs6EvD9R+FonRa6FzRNSFOW9Bwl0+N6VQXPIol6bi0uaJ54vFDmDhTzBwFIQ3g/se18SsIlJWQ0GB9jZkEFa72EmpLT4y+WGY9n8+N6NQXPIEVfCEEP8UQkghREN9XQgh3hZC7BNC/CGE6B3M/ikuAXaVEeRlscDsT2DQKBg6RhM+8waY/mZpEUxZUyRsMbazSAzFQucHKw/g1be0ABiFQuE9QXNpCiFaAiOAIw6bRwEd9aU/MIsS+ewVCr8x8T44fab8YySwwqxZfQb9+TA8DJK/09yeE++DJb8XHZ5hiNZOEv59lpRSm7un5u0pFN4TTAtvJjAV52oxNwBzpcZaoL4QomlQeqeo2Uy8D+Z/7dk5Npu25Fs0NybAdz86HRJXuBoD/nFlOhISok1UVyguBW6++eY20dHRPTp27NjVvm3y5Mkt2rZt27VTp05drrnmmvZnzpwxlteGK4IieEKIG4BjUsptJXY1B446rKfp2xQK/2He4LnYOSIEHEmDpLmQl+e0y2TbyOOWd7QV6VjmyD16docRw7RAlTlvQb8+MHY0rPhZWXeKSwdX5YFGjhyZlZqauiM1NXVnhw4dLj7zzDOxnrYbMJemEGIp4KpDTwNPobkzfWk/AUgAaNWqlS9NKS41UlzU1vMEgwE++AwMLsbnjEZm9PyZ9q278dHBATTrWIdOHWDmu2C1gdEAVw9x8oIWERIC77/hLGwqOlNRLShcGklhchQh8dmEBKY80I033lg0ScdkMuV88803DTxtN2CCJ6Uc7mq7EKI70BbYJrQB/RbAZiFEP+AY0NLh8Bb6NlftJwFJAH379vWv/0hRs4kbpKlLYWGpXQfoy14G0ZHVtGMjn/Aef3AdgkIacIK4nmYGb39Si+yUelUHm65k7yYW1egrehrTGXudc/7MpP/CR3OhWVMYdQ1knFW5NRXVlMKlkeSM7gQFBvJn2ohcnOoP0SuPTz75pOFNN9101tPzKj1oRUq5HWhsXxdCHAL6SinPCCEWAQ8KIb5EC1Y5L6U8Udl9VNRwTFfCih8g8R1IXgHZWgHlhfybpTysH2SjM8vYTXzRaenU48utnSFkF4ONcyEsFN58WVer8ietm/qXttyU9aaoERQmR4FeHohCg2bpBU7wpk2bFms0GuWUKVOqvuBVwE/AX4B9QC6gbgmKwGC6Er6bq821m/0Jn/AeG7lF3ykAA7sZ5rBejLnjswz+W3NVwkihAAiJzyZ/pg0KDRBiIyRw5YHefvvtmF9//bX+ypUrUw0Gz0NQgi54Uso2Du8l8EDweqO45Jh0K6s+EGy0OoodLt4XU++yOvDkI4HumUJRPQgZnkPk4lR/juG54ptvvqn71ltvxa5cuXJPVFSUm1lpnQm64CkUQcV0JVv7dIL1UFrsJK5Eb/hU7fWTibDrZ2jYAWrVh57jYXBCqcMVippPyPAcfwqdq/JAM2fOjLVYLIZhw4Z1Aujdu/eFzz///EhFbTl1018dVCiqKz3vqcfu9a72uLbw/lgIK96DjfO19Rz93N1LtFclegqFb7gqD/Too49WkCWiYlQuTcUlj6cCtfZj2Pw/1/u2LvC9PwqFIjAowVMogHc9mNiSlw220jMaAM2tqVAoqiZK8BQKnc5upkKw5rve3rqfcmcqFFUZJXgKhU6qi+wn7hLdGv6lqhkoFFUaJXgKhU5ZbsqKCKsDzx/ya1cUCkUAUIKnUPjIg0uC3QOFQuEOSvAUCp36LTw/p1lPaGfye1cUiksaV+WBHn744WadOnXq0rlz5y6DBg3qeOjQoVBP21WCp1Do3P2V5+fc9r7/+6FQXOq4Kg/07LPPpqempu7cvXv3zlGjRp1/6qmnPK6VqgRPodBpZ4LQ2u4fHxWrrDuFAqCQpZH5PBlbyNJIf7Q3atSoC40aNXIaVY+Oji5KJ5aTk2PQq+14hMq0olA4MDMHHo4oe+qBHUMoTFd1PBQKClkaeRGtPFABM20RLE4NITD5NB966KHmX3/9dUxUVJR1+fLlezw9X1l4CkUJ3roIt82BkAjX+6Nbw9uWyu2TQlFVseJcHkhbDwzvvPPOsfT09D9uuummjFdffbVxxWc4owRPoXDB4AR4M08Tvs4joO8E7fW2OWoKgkLhiJH4bAi1gREIsWnrgeXuu+8+u3jx4qpT8VyhqAkMTlDZUxSK8ghheE4Ei1OtJEcZic8OlDtz+/bt4d27d88H+Oqrr+q3b98+z9M2lOApFAqFwidCGJ7jT6FzVR7ol19+qXfgwIEIIYRs0aKF5aOPPjrseT8VCoVCoahCqPJACoVCoVD4gBI8hUKhUFwSKMFTKBQKxSWBEjyFQqFQXBLUiKCVTZs2nRFCeByx4yYNAZ8HS2s46jtyD/U9VYz6jtzDX99Taz+0UW2oEYInpWwUqLaFEBullH0D1X5NQH1H7qG+p4pR35F7qO/JO5RLU6FQKBRVClflgew8++yzTYQQfU6cOOGxwaYET6FQKBRVClflgQD27dsXmpycXLdp06ZeZbNVglcxScHuQDVAfUfuob6nilHfkXtUqe8pj6WRZ3kyNi+A5YEAHnzwwZavvvpqmjelgaCGjOEFEilllfphVUXUd+Qe6nuqGPUduUdV+p7yWBqZrpcHOs9MWyyLU2sFIJ/mvHnz6jdt2rTAZDJ5nEPTjhI8hUKhUHhNXonyQHkkR/lb8LKzsw2JiYmxy5YtK+Xm9ATl0lQoFAqF19QqUR6oVgDKA+3atSs8LS0t/IorrujSvHnz7idPngzr3bv35UeOHPHIaFOCVwFCiH8KIaQQoqG+LoQQbwsh9gkh/hBC9A52H4OFEOJVIcRu/Xv4TghR32Hfk/p3tEcIMTKI3Qw6Qohr9e9hnxDiiWD3p6oghGgphFgmhNgphNghhHhY3x4thPhNCLFXf/W47llNQwhhFEJsEUIs1tfbCiHW6b+p/wkhwoLVt1oMz4llcWo9/nUsUO7Mfv365Z09e3bbsWPHth87dmx7kyZNLJs3b97VqlWrUuN85aEErxyEEC2BEcARh82jgI76kgDMCkLXqgq/Ad2klFcAqcCTAEKILsBtQFfgWuB9IYQxaL0MIvrnfg/td9MFuF3/fhRQCPxTStkFGAA8oH83TwDJUsqOQLK+fqnzMLDLYX0GMFNK2QHIBO4JSq90ajE8J5rp6f4SuzFjxrQdPHhw54MHD4Y3adLkipkzZzb0R7tqDK98ZgJTge8dtt0AzJVSSmCtEKK+EKKplPJEUHoYRKSUSxxW1wI36e9vAL6UUuYDB4UQ+4B+gLmSu1gV6Afsk1IeABBCfIn2/ewMaq+qAPrfzAn9fbYQYhfQHO37idMP+xRIAaYFoYtVAiFEC+A64CXgMaGFKA4D/qof8inwHDXo4dtVeSBHjh07tt2bdpWFVwZCiBuAY1LKbSV2NQeOOqyn6dsude4Gftbfq++oGPVduIEQog3QC1gHNHF4gEwHmgSrX1WEN9EevG36egxwTkppd+ep35SbXNIWnhBiKRDrYtfTwFNo7sxLmvK+Iynl9/oxT6O5p+ZXZt8UNQMhRB1gAfCIlDLLcY6VlFIKIWTQOhdkhBCjgVNSyk1CiLggd6fac0kLnpRyuKvtQojuQFtgm/7H1wLYLIToBxwDWjoc3kLfViMp6zuyI4S4ExgNxOtuXrjEvqMKUN9FOQghQtHEbr6U8lt980n7MIEQoilwKng9DDqDgOuFEH8BIoC6wFtAfSFEiG7lqd+UmyiXpguklNullI2llG2klG3QXAa9pZTpwCJgkh6tOQA4fymO34EWfYjmarleSpnrsGsRcJsQIlwI0RYtwGd9MPpYBdgAdNSj6sLQgnkWBblPVQJ9LOojYJeU8g2HXYuAO/T3d+A8hn5JIaV8UkrZQr8P3Qb8LqWcACyjeMz8kv6OPOGStvC85CfgL8A+IBe4K7jdCSrvAuHAb7olvFZKOUVKuUMI8RVaYEYh8ICU0hrEfgYNKWWhEOJB4Fe0iUofSyl3BLlbVYVBwN+A7UKIrfq2p4BXgK+EEPcAh4FbgtO9Ks004EshxIvAFrQHB0UFiGIvlEKhUCgudbZt23aoR48e1bom4bZt2xr26NGjTcntyqWpUCgUiiqFq/JAjz32WLPGjRtf0blz5y6dO3fu8r///a+ep+0qwVMoFApFlaKs8kBTpkw5uXv37p27d+/eeeutt573tF0leAqFQqHwiXMsjTzEk7HnAlweyFeU4CkUCoXCa86xNHIHozulkdh8B6M7+Uv0XPHRRx817tSpU5ebb765zenTpz1OV6gET6FQKBRec47kKKmXB5IUGs6RHBWI6zz66KOnDh8+vH3Xrl07Y2NjC+6///6WFZ/ljBI8RY1GCBErhPhSCLFfCLFJCPGTEKJTsPvlC0KIOCHEwDL2dRZCmIUQ+UKIxyu7b4pLj/rEZwu9PJAgxFY/AOWBAFq2bFkYEhKC0WjkwQcfPL1161aPLUk1D09RY9EnNn8HfCqlvE3f1gMtN2NqMPvmI3HABWCNi31ngX8AYyuxP4pLmPoMz+nK4tRzJEfVJz67fgDKAwEcPnw4tHXr1gUAX375Zf3LLrvM48rnSvAUNZmrgQIp5Wz7BnsycF0ME9HK9kjgRSnl//R8hf8BzgHdga+A7WjlWWoBY6WU+4UQnwAXgb5o6Z4ek1IuFkJEoGWt74s26f4xKeUyPQXb9UBtoD3wnZRyqt6XEfo1w4H9wF1SygtCiENomfDHAKHAzfo1pwBWIcRE4CEp5UqHz3cKOCWEuM4/X6FCUTH1GZ7jT6EbM2ZM27Vr10ZlZmaGNGnS5Ionnnji+PLly6N27txZC6BFixaW//73v4c9bVcJnqIm0w3YVMa+G4GeQA+gIbBBCLFC39cDuBzNWjoAfCil7KcXKH0IeEQ/rg1a+Z/2wDIhRAfgAbScx92FEJ2BJQ4u1J5oFQHygT1CiHeAPODfwHApZY4QYhrwGPC8fs4ZKWVvIcT9wONSynuFELOBC1LK17z/ahSKqour8kCPPvqoz5PhleApLlUGA1/oKc9OCiGWA1cCWcAGe35UIcR+wF73bzua1WjnKymlDdgrhDgAdNbbfQdASrlbCHEYsAtespTyvN7uTqA1UB+tMOxqPT1bGM51A+0JlTehibRCofASJXiKmswOihPsekK+w3ubw7oN57+Zknn5KsrT59iuVW9LAL9JKW+v4Bz78QqFwktUlKaiJvM7EC6ESLBvEEJcIYS4ClgJ3CqEMAohGgFD8Lyiw81CCIMQoj3QDtijtztBv1YnoJW+vSzWAoN0dyhCiEg3okizgYCEfisUNRkleIoai16fbxwwXJ+WsAOYjlZF+zvgD2AbmjBO1cs/ecIRNJH8GZgipbwIvA8YhBDbgf8Bd0op88tqQEp5GrgT+EII8QeaO7NzBdf9ARgnhNiqi3cR+jSMNLRxwH8LIdKEEHU9/FwKRY1EVUtQKLxAj9JcLKX8Jth9USj8iaqWoFAoFApFNUcJnkLhBVLKO5V1p1AEBlflgQBeeumlxm3btu3aoUOHrlOmTGnhabsq6kuhUCgUVYq77777zMMPP3zqrrvuamvf9sMPP0T9+OOP9Xfu3LmzVq1a8tixYx7rl7LwFAqFQuETp1ga+SdPxp4KYHmgWbNmNZo6deqJWrVqSYDmzZt7XD5ICZ5CoVAovOYUSyP/v717D2+qzvc9/k3aUCDEQim0NUBb2obeqwIDOjpAkzmABNncRPEMIG5GZ8bLg+6qOA/DxvGyp14YdJzBQZCjjIgjChIVJJGpwwhnEI+UUtoIhQIRKtALbaBt0vT8YetheoibtZLMjnu9X39pQj9P/vs8v7WS9flU7Ba3lJo/FbslXKXXU01NTe+ysjJTYWFh9ujRo0eUlZX1VZpB4QEAVPtaXKZA1zxQQPz6ryM0D9TR0aGrr6+P+eKLL6pKS0tPzJ07NyMQCCjKoPAAAKoNFmuzvmseSC+xgcERmgdKTk5unzVrVqNer5cJEyZc0Ov1nadPn1Z0H4/CAwCoNlhs3hvE4bZIiecGcbgHR2geaOrUqY0u1zenx/Ly8jifz6dPTk5WdB+Pb2kCAEIyWGzecBbd5eaB7r///rNz5sxJy8rKyjMYDIE//vGPR/V6ZWc2Cg8AEFUuNw8kIrJly5bLvn6luKQJANAECg8AoAkUHgBAEyg8AIAmUHgAAE2g8AAAmsDPEgAAUWX27NlpLpcrfuDAgf4vv/zyoIjIlClThh85cqS3iEhzc3OMyWTqqKqqqlSSS+EBAKLK5eaB3n///Zru/160aNGQ+Pj4DqW5XNIEAITkhDiNn8qS5BMRnAfqFggEZOvWrQnz58+vV5rLCQ8AoNoJcRq3it3SIT79F7IiMFUc7qERep6miMj27dv7JSYm+goKCtqU/i0nPACAaifEZeq4ZB7oRITmgbqtX78+YebMmYpPdyIUHgAgBEPF2hwjhoCuax5oaITmgUREfD6fbNu2bcC8efNUFR6XNAEAqg0Vm3eqONwnxGUaKtbmSF7O3LJly1XDhw9vzcjI8Kn5e054AICQDBWb9wZ5+nS4ym7q1KnpN954Y/bRo0fjkpKSClesWJEoIrJhw4aE2bNnqzrdiXDCAwBEmWDzQJs2bToWSi4nPACAJlB4AABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AEFVmz56dlpCQUJSVlZXX/dqnn37ap6ioKDs7Ozs3Pz8/Z+fOnX2V5lJ4AICosnDhwrPvvffel5e+VlJSMuSXv/zlV1VVVZVLly796pFHHhmqNJfCAwCE5Ig4jR/JkuQjEZwH0ul00tTUFCMi0tjYGJOUlNSuNJcnrQAAVDsiTuP6rnmg3bIi8D/F4c6IwPM0X3jhhRNTpkzJWrp06dBAICC7du2qUprBCQ8AoNqRrnmgTglIh/j1RyI0D/TCCy8Mevrpp0+cPn26/KmnnjqxYMGCNKUZFB4AQLWMS+aBYiQ2kBGheaBNmzYNnDdvXqOIyMKFCxvKy8sVXz6l8AAAqmWIzfs/xeG+UUo8kbqcKSIyaNAg3wcffGASEdm6daspNTW1VWkG9/AAACHJEJs3nEU3derU9D179pgaGhpik5KSCh999NGv/vCHP9Q++OCDQx966CFdXFxcYNWqVbVKcyk8AEBUCTYPdPDgwUOh5HJJEwCgCRQeAEATKDwAgCZQeAAATaDwAACaQOEBADSBwgMARJXLzQPt3r27zzXXXJNtsVhyi4uLM+vr6xX3F4UHAIgql5sHWrRoUdqTTz550u12V95yyy0Ny5cvT1aaS+EBAEJySJzGd2VJ8qEIzgPV1tbGTZ48uUVExG63n3c4HAOU5lJ4AADVDonT+JLYLR9JqfklsVvCVXo9ZWZmtv7pT3/qLyKyfv36hNOnT/dSmkHhAQBUq+oxD1QVoXmgtWvXHlu1atWgvLy8nObmZr3BYOhUmsGzNAEAqmWLtdklKwId4tfHSGwgO0LzQNdee23r3/72ty9FRMrLy+M++uij/kozKDwAgGo5YvP+QhzuKnGZssXanBOheSCPxxNrNpv9HR0dsmzZspS77rrra6UZFB4AICQ5YvOGs+guNw/U0tKiX7NmzWARkZtvvrnh/vvvP6c0l8IDAESVYPNAS5cuVXyquxRfWgEAaAKFBwDQBAoPAKAJFB4AQBMoPACAJlB4AABNoPAAAFHl8OHDhjFjxlgyMjLyMjMz8379618PFhGpq6uLueGGG7JSU1Pzb7jhhqwzZ87EKMml8AAAUcVgMMhzzz138siRIwf37t17aM2aNYP37dvXe9myZSnjx49vrq2trRg/fnzzr371K0UTQfzwHAAQki/EadwvLlORWJuvCcMTV1JTU32pqak+EZEBAwYEMjIyLh4/frzXtm3b+peVlVWLiNx9993nxo0bN0JEPFeaS+EBAFT7QpzGx8Vu8YtPv0VWBH4lDnc4Sq9bdXV1r8rKyr7jxo1rOXfuXGx3EQ4dOtR37tw5RR3GJU0AgGr7xWXyXzIPtD+M80BNTU36GTNmZPzHf/zHiYSEhMCl7+n1etHpdIryKDwAgGpFYm2OFUNALzESI7GBojDNA7W1temmTJmSMXv27Pr58+c3iogMHDjQX1tbaxARqa2tNSQkJPi/M6QHCg8AoNo1YvP+ShzuGVLiCdflzEAgILfddluqxWJp/fd///e67tcnTpzY+PLLLw8UEXn55ZcHTpo0qVFJLvfwAAAhuUZs3nDet9uxY0e/zZs3D8zKyrqYnZ2dKyKyfPlyz/Lly09Nnz49IzU1NdFsNre/++67R5TkUngAgKgyceLEls7Ozn2Xe2/37t1utblc0gQAaAKFBwDQBAoPAKAJFB4AQBMoPACAJlB4AABNoPAAAFEl2DzQ2rVrB2RmZubp9fqRn3zySV+luRQeACCqBJsHuuaaay5u2rTp8KhRo1rU5PLDcwBASP4uTuNecZlGi7X5BxGcB5o+ffr5UHIpPACAan8Xp/GhrnmgN2VF4DlxuMNRet0unQcKNYtLmgAA1fZ2zQMFJCB+8ev3/pPmgdSg8AAAqo2+ZB4oVmIDoyM4DxQqLmkCAFT7gdi8z4nDHc57eMHmgUJF4QEAQvIDsXnDed8u2DxQW1ubrqSkZFhDQ0Ps9OnTs3Jyci7s2rXryyvNpfAAAFHlu+aB5s2b16g2l3t4AABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AoAkUHgAgqgSbB7r77ruHpKen51ksltwf//jHGWfPno1RkkvhAQCiSrB5oIkTJ553u90H3W53ZWZmZuvSpUuTleRSeACAkPxVnManZUnyX8VpDEdeamqq78Ybb7wg8o/zQDNmzDhvMBhEROT666/3ejyeXkpyKTwAgGp/Fadxvtgtf5BS83yxW8JVet2CzQOtW7cucdKkSU1Ksig8AIBqu3rMA+36J8wDPfLII8kxMTGd99xzT72SPAoPAKDajT3mgW6M8DzQCy+8MHD79u3933nnnaN6vbIK4+HRAADVbhKb93+Jw71LXKYbxdp8UwTngd5+++2rVq5cmfzXv/612mQyKR6EpfAAACG5SWzecBRdt2DzQCUlJUPb29v1xcXFFhGR6667ruWNN944fqW5FB4AIKoEmweaM2eOoi+p9MQ9PACAJlB4AABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AEFWCzQM98MADV1ssltzs7OzcH/7wh1nHjh0zKMml8AAAUSXYPNCyZctOu93uyqqqqsrJkyc3PfbYYylKcik8AEBIXOI0/lKWJLsiPA906QOkvV6vXqfTKcrlSSsAANVc4jT+i9gtPvHpX5AVgc3icFvD+JixnvNA9913n/nPf/7zQJPJ1FFWVlatJIsTHgBAtY/FZfJdMg/0cYTngV588UXP6dOny2fNmnXumWeeGawkj8IDAKhWLNZmgxgCMV3zQMURngfqtnDhwnqHwzFASSaXNAEAqlnF5t0sDvfH4jIVi7U5HJczg80DHThwIK6goKBNROStt97qn5GRcVFJLoUHAAiJVWzecN63CzYPtHbt2sSampreOp2uc8iQIe1r1qypVZJL4QEAogrzQAAAhIDCAwBoAoUHANAECg8AoAkUHgBAEyg8AIAmUHgAgKgSbB6o27Jly5J0Ot3IU6dOKfppHYUHAIgqweaBRL4pQ5fLdVVKSkq70lwKDwAQEqf8xbhElic75S8RnQcSEbn33nuHPvPMMyeVTgOJ8KQVAEAInPIXo11us/jEp18hfwg45E23TcZHZB5o/fr1/VNSUnzXX3+9omdoduOEBwBQzSVll8wD+fQuKYvIPJDBYJDS0tLkZ5999iu1eRQeAEA1q4zrmgfSS6wYAlYZF5F5oEOHDsWdPHkyrrCwMNdsNhfU1dX1uu6663KOHz9+xVcquaQJAFDNJuO9DnnT7ZIyk1XGNYfjcubl5oF+8IMfXKyvr9/f/W/MZnPBZ599diglJcV/pbkUHgAgJDYZ7w3nfbtg80ChriVQeACAqBJsHuhSHo/ngNJc7uEBADSBwgMAaAKFBwDQBAoPAKAJFB4AQBMoPACAJlB4AICoEmwe6MEHH7x68ODBhdnZ2bnZ2dm5GzdujFeSy+/wAABRpXse6MYbb7zQ0NCgv/baa3Nvvvnm8yIi99xzT93jjz9epyaXwgMAhMQpu40u2WOyythmm1wf8hNXUlNTfampqT6R/38eKBRc0gQAqOaU3Ua7/MJSKq+a7fILi1N2h2UTr9ul80AiImvWrBlssVhyZ8+enXbmzJkYJVkUHgBANZfsMfnE3zUP5Ne7ZE9E5oESEhICixcv/rq2tvbAoUOHKpOTk30///nPhyrJo/AAAKpZZWyzQWK75oFiA1YZG5F5IBGRoUOH+mNjYyUmJkbuvffeM1988YWi0yT38AAAqtnkeq9DXnKH8x7e5eaBRERqa2sN3ff23nzzzf4jRoxQtHxO4QEAQmKT673hKLpuweaBNmzYkFBZWdlHRGTIkCHtr776aq2SXAoPABBVgs0DhbqHxz08AIAmUHgAAE2g8AAAmkDhAQA0gcIDAGgChQcA0AQKDwAQVYLNA4mIPPnkk4PT09PzMjMz8+65554hSnL5HR4AIKoEmwf66quvDO+//37/ysrKyj59+nR6PB5FHUbhAQBC4pR9Rpd8brLKdc02GRmxeaDVq1cnPvzww6f69OnTKSJiNpv9SnK5pAkAUM0p+4x2ecxSKm+a7fKYxSn7IjYPVFNT07usrMxUWFiYPXr06BFlZWV9lWRReAAA1Vzyedc8UKf4pUPvks8jNg/U0dGhq6+vj/niiy+qSktLT8ydOzcjEAhccR6FBwBQzSrXXTIPFBOwynURmwdKTk5unzVrVqNer5cJEyZc0Ov1nadPn77iW3MUHgBANZuM9DrkKXeJzPE45Cl3OO7hBZsHmjp1aqPL5TKJiJSXl8f5fD59cnLyFd/H40srAICQ2GSkNxxF1y3YPND9999/ds6cOWlZWVl5BoMh8Mc//vGoXn/l5zYKDwAQVYLNA4mIbNmy5ajaXC5pAgA0gcIDAGgChQcA0AQKDwCgCRQeAEATKDwAgCbwswQAQFQ5fPiw4Y477kg/e/asQafTyfz5888sXbr06ylTpgw/cuRIbxGR5ubmGJPJ1FFVVVV5pbkUHgAgqgSbB3r//fdruv/NokWLhsTHx3coyeWSJgAgJE6pMC6RjclOqQjLUkJqaqrvxhtvvCDyj/NA3e8HAgHZunVrwvz58+uV5HLCAwCo5pQKo12es/jEr18h2wIOechtk/ywPWbs0nmg7te2b9/eLzEx0VdQUNCmJIsTHgBANZccvGQeyK93ycGIzQN1v75+/fqEmTNnKjrdiVB4AIAQWCWvax5IJ7ESG7BKXsTmgUREfD6fbNu2bcC8efMUFx6XNAEAqtkk3+uQh9wuOWiySl5zOC5nBpsHEhHZsmXLVcOHD2/NyMjwKc2l8AAAIbFJvjec9+2CzQPNmTOnacOGDQmzZ89WfLoTofAAAFHmu+aBNm3adExtLvfwAACaQOEBADSBwgMAaAKFBwDQBAoPAKAJFB4AQBMoPABAVDl8+LBhzJgxloyMjLzMzMy8X//614NFRD799NM+RUVF2dnZ2bn5+fk5O3fu7Kskl8IDAESV7nmgI0eOHNy7d++hNWvWDN63b1/vkpKSIb/85S+/qqqqqly6dOlXjzzyyFAlufzwHAAQEqe4jS5xm6xiabaJJeQnrqSmpvpSU1N9Iv84D6TT6aSpqSlGRKSxsTEmKSmpXUkuhQcAUM0pbqNdXrH4pEO/Qj4JOORf3eEovW6XzgOlpqa2T5kyJWvp0qVDA4GA7Nq1q0pJFpc0AQCqucRt8klH1zxQh94l7ojNA73wwguDnn766ROnT58uf+qpp04sWLAgTUkehQcAUM0qlmaDxHTNA8UErGKJ2DzQpk2bBs6bN69RRGThwoUN5eXlihbWKTwAgGo2sXgd8q/uEpngCdflzGDzQIMGDfJ98MEHJhGRrVu3mlJTU1uV5Oo6OztD/WwAgP8m9u/ff6yoqOjsf+Vn2L59e79JkyaNyMrKuqjXf3MuW758uad///4dDz744FC/36+Li4sLvPTSS8dvuummCz3/fv/+/YlFRUVpPV/nSysAgKjyXfNABw8ePKQ2l0uaAABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AoAkUHgAgqgSbB9q9e3efa665JttiseQWFxdn1tfXK+owCg8AEFWCzQMtWrQo7cknnzzpdrsrb7nllobly5cnK8ml8AAAIXFKrXGJ/DXZKbWKnm0ZTGpqqu/GG2+8IPKP80C1tbVxkydPbhERsdvt5x0OxwAluRQeAEA1p9Qa7fKupVT+brbLu5ZwlV63S+eBMjMzW//0pz/1FxFZv359wunTp3spyaLwAACqueR41zyQiF8Cepccj9g80Nq1a4+tWrVqUF5eXk5zc7PeYDAoehg0z9IEAKhmlWHNK2RfwC8BfazoA1YZFrF5oGuvvbb1b3/725ciIuXl5XEfffRRfyWZFB4AQDWbpHodMt3tkuMmqwxrtklqxOaBPB5PrNls9nd0dMiyZctS7rrrrq+V5FJ4AICQ2CTVG46i67Zjx45+mzdvHpiVlXUxOzs7V+SbeSC32x23Zs2awSIiN998c8P9999/Tkkue3gAgG9Fwx5eqILt4fGlFQCAJlB4AABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AEFUuXLigKygoyBkxYkRuZmZm3uLFi68WEamqqupVWFiYPWzYsPwpU6YMb21t1SnJpfAAAFGld+/enbt27aqurq6uPHjwYKXL5brK5XIZH3zwwSH33ntv3fHjxyvi4+P9K1euTFSSS+EBAELilFPGJfJ5slNOhWUpQa/XS3x8fEBEpL29Xef3+3U6nU52795tuvPOOxtERBYuXHhu69at/RXlhuPDAQC0ySmnjHZxWUqlwmwXlyVcpef3+yU7Ozs3KSmpaNy4cedzcnLaTCZTh8FgEBGRtLS09rq6OuaBAAD/HC45ZfJJ4JJ5oFNhmQeKjY2VqqqqyuPHj5d//vnnxvLy8t6hZlJ4AADVrJLSbBB9IEZEvpkHSgnLPFC3xMTEjptuuql5165dxubm5hifzyciIseOHeuVlJTUriSLwgMAqGaTFK9DrO4Syfc4xOq2SUrIqwlfffVV7NmzZ2NERFpaWnQ7d+68Kjc3t3Xs2LHNr7766gARkbVr1w602+2NSnKZBwIAhMQmKd5wFF23EydOGBYsWJDe0dEhnZ2dumnTptXffvvtTUVFRRfnzJmT8cQTT5jz8vIuPPDAA4pWHSg8AEBUGTNmzMVDhw5V9nw9Nze3/cCBA4fU5nJJEwCgCRQeAEATKDwAgCZQeAAATaDwAACaQOEBADSBwgMARJVg80BPPfXUoGHDhuXrdLqRp06dUvyzOn6HBwCIKt3zQPHx8YG2tjbd6NGjR7hcrqZx48a1zJw5s6m4uHiEmlwKDwAQEqecNbrknMkqA5ttkhjyE1eCzQP98Ic/vBhSbqgfDACgXU45a7TL55ZSOWq2y+cWp5yNyDxQcXFx6EUajg8GANAml5zrMQ90LiLzQHv37mUeCADwX8cqA3vMAw2MyDzQ1q1b40PNovAAAKrZJNHrkOvcJZLucch17nDcw7vcPFBOTk5rqLkUHgAgJDZJ9D4tI06Ho+xEvpkHuummm0ZYLJbca6+9NnfChAnnb7/99qYnnnhicFJSUmFdXV2voqKi3Dlz5qQqydV1dnaG4/MBAP4b2L9//7GioiJFO3PRZv/+/YlFRUVpPV/nhAcA0AQKDwCgCRQeAEATKDwAgCZQeAAATaDwAACaQOEBAKJKsHmgW265JT0tLS0/Kysrb/bs2WltbW06JbkUHgAgqnTPA1VXV1cePHiw0uVyXeVyuYx33HFHfU1NTUV1dfXB1tZW3W9/+9tEJbkUHgAgJE5pMS6R08lOaQnLUkKweaA5c+Y06fV60ev1MmrUKO/Jkyd7KcoNx4cDAGiTU1qMdjlmKZUzZrscs4Sr9L5rHqitrU23cePGgVOmTGlSkknhAQBUc0mLySedXfNAnXqXtER8Hmj+/PnDxo4d2zJp0qQWJZkUHgBANav0azaIrmseSBewSr+IzgM99NBDKWfPno1dvXr1CaVZFB4AQDWb9PM6JM1dIoM8Dklz26RfxOaBnn/++cSPP/44fvPmzTUxMTGKc2ND/WAAAG2zST9vOIqu24kTJwwLFixI7+jokM7OTt20adPqb7/99qbY2NiRKSkpbaNGjcoREbHb7Q3PPvvsqSvNpfAAAFFlzJgxFw8dOlTZ83W/378vlFwuaQIANIHCAwBoAoUHANAECg8AoAkUHgBAEyg8AIAm8LMEAEBUuXDhgm7MmDHZ7e3tuo6ODt3UqVMbVqxY8dWtt96aun//fmNnZ6cMHz68dePGjce6HzJ9JTjhAQCiSrB5oFWrVp2orq6udLvdlUOGDGn/zW9+M1hJLoUHAAiJU9qMS6Q52SltEZ0HSkhICIiIBAIBuXjxol6nU7T/SuEBANRzSpvRLg2WUvGa7dJgCVfpBZsHmjVrVtqgQYOKDh8+3PvRRx/9WkkmhQcAUM0l7SafSNc8kOhd0h7ReaC33377WF1d3f6srKzWtWvXDlCSSeEBAFSzSq9mg0jXPJAErNIrovNAIt+U4R133FG/efNmCg8A8M9hkzivQwa4S8ToccgAt03iIjIPlJ2d3VpRUREn8s09vHfffbd/VlZWq5JcfpYAAAiJTeK84Si6bpebB5ozZ07T6NGjs1taWvSdnZ26nJycC+vWratVkkvhAQCiSrB5oM8//7wqlFwuaQIANIHCAwBoAoUHANAECg8AoAkUHgBAEyg8AIAmUHgAgKhy4cIFXUFBQc6IESNyMzMz8xYvXnz1pe8vWLBgaN++fa9Vmsvv8AAAUaV7Hig+Pj7Q1tamGz169AiXy9VktVq9n3zySd/GxkZV3cUJDwAQEmenGJcEJNnZKRGdB/L7/VJSUjJk5cqVJ1XlhuPDAQC0ydkpRntALKWdYrYHxBKu0rvcPNDTTz89+Oabb25MTU31qcnkkiYAQDVXp/zjPFCnmGw6Cfm5mt3zQGfPno2ZMmVKxocffthv8+bNA/bs2VOtNpMTHgBANatO/nEeSCcRmQdyOp2m2tra3mlpaQVms7mgtbVVP2zYsHwlWRQeAEA1m068Dr24S3TicejFHY7T3eXmgUaNGnXh7Nmz+z0ezwGPx3Ogd+/egePHj1coyeWSJgAgJDadeMNRdN0uNw90++23N4WaS+EBAKJKsHmgS124cOH/KM3lkiYAQBMoPACAJlB4AABNoPAAAJpA4QEANIHCAwBoAoUHAIgqweaBZs6cmWY2mwuys7Nzs7Ozcz/99NM+SnL5HR4AIKoEmwcSEXniiSdO3nnnnQ1qcjnhAQBC4mwT45Lzkuxsi+w8UMi5IScAADTL2SZGe71YSr1itteLJVyld7l5IBGR5cuXmy0WS+5dd9019OLFi4pakMIDAKjmausxD9QmpnDkds8DHT9+vPzzzz837t27t/fzzz/vqampqdi/f/+hhoaGmKVLlyYryaTwAACqWeN6zAPFRWYeaOvWrfGpqak+vV4vffr06Vy4cOG5ffv2KTpNUngAANVsceJ1JIi7xCgeR4K4bXGRmQfKyclpra2tNYiIBAIBeeedd/rn5ORcVJLLtzQBACGxxYk3HEXXLdg80NixYy319fWxnZ2dutzc3AuvvfZarZJcCg8AEFWCzQPt2bPHHUoulzQBAJpA4QEANIHCAwBoAoUHANAECg8AoAkUHgBAEyg8AEBUCTYPFAgE5L777jOnpaXlDx8+PO+JJ54YrCSX3+EBAKJKsHmgioqK3idPnjQcOXKkIiYmRjwej6IOo/AAACFxNovR1SImaz9ptplCf+JKsHmgV155ZfCGDRtqYmJiRETEbDb7FeWG+sEAANrlbBaj/ahYSr8Ws/2oWJzNkZsHOnHiRNzrr78+ID8/P+dHP/pR1oEDB+KUZFJ4AADVXC1i8nV2zQN1it7VErl5oPb2dl3v3r07KyoqDt11111nFixYkKYkk8IDAKhm7SfNBl3XPJBOAtZ+kZsHSkpKar/99tsbRER+8pOfNLrd7j5Ksig8AIBqNpN4HeniLhksHke6uMNxDy/YPNDkyZMbt23bZhIR+eCDD0ypqaltSnL50goAICQ2k3jDUXTdgs0D/fjHP26ZNWtW+u9///ukvn37BlavXn1MSS6FBwCIKsHmgRITEzv+8pe/HFabyyVNAIAmUHgAAE2g8AAAmkDhAQA0gcIDAGgChQcA0AR+lgAAiCoXLlzQjRkzJru9vV3X0dGhmzp1asOKFSu+Gjly5Aiv1xsjIlJfXx9bWFjodTqdR640l8IDAESVYPNA+/btq+7+NxMnTsyYOnVqo5JcLmkCAELiPCvGJVWS7DwbnqWEYPNA3err6/W7d+82zZ07t0FRbjg+HABAm5xnxWj/TCylNWK2fyaWcJXe5eaBut974403Btxwww3nExISAkoyKTwAgGqus2LyBbrmgQKid52N3DxQ93tvvfVWwm233VavNJPCAwCoZk2UZoO+ax5ILwFrYuTmgURETp06FVteXm689dZbm5RmUXgAANVsieJ1jBJ3yXDxOEaJ25YYuXkgEZHXX399QHFxcWPfvn07lebyLU0AQEhsieINR9F1CzYPJCLy9ttvJzz88MOn1ORSeACAqBJsHkhE5O9//3v15V6/ElzSBABoAoUHANAECg8AoAkUHgBAEyg8AIAmUHgAAE2g8AAAUeXChQu6goKCnBEjRuRmZmbmLV68+GoRkS1btphyc3NzsrOzc0eOHDmioqIiTkkuhQcAiCrd80DV1dWVBw8erHS5XFe5XC7jAw88kLp+/fqjVVVVlbNnz65ftmxZipJcCg8AEBLnV2Jcsk+SnV9Ffh6osbExRkSkqakpJiUlxacklyetAABUc34lRrtLLL6A6FdUSsBhFbft6tAfM+b3+yU/Pz/3+PHjcfPnz/+6uLjYu2rVqmMzZszIiouLC/Tr169j7969h5RkcsIDAKjmOtVjHuhU5OaBnn/++aR33nnny7q6uvK5c+ee/dnPfjZUSSaFBwBQzZrSYx4oJTLzQO+99178oUOH+nQPwc6bN6/hs88+66cki8IDAKhmu1q8Dqu4S/LFE67LmZebB8rNzW1taWmJKS8vjxMRcTgcV2VmZrYqyeUeHgAgJLarxRuOousWbB7I5/PVzpo1K0On00l8fHzHunXrjirJ1XV2Kt7QAwD8N7V///5jRUVFZ/+rP0co9u/fn1hUVJTW83UuaQIANIHCAwBoAoUHANAECg8AoAkUHgBAEyg8AIAmUHgAgKgSbB7ovffeM+Xm5uZkZWXlzZgxI83nU/TsaAoPABBdLjcPtGPHDuNPf/rT9DfffLPmyy+/PDhs2LD23/3ud4lKcik8AEBInEfFuORjSXYejdw8UExMjBgMhkBhYWGbiMikSZPOb968ub+i3HB8OACANjmPitG+USyle8Rs3yiWcJWe3++X7Ozs3KSkpKJx48adHz9+vLejo0P3ySef9BUR2bhx44BTp071UpJJ4QEAVHMd7ZoH6uyaBzoamXmgffv29X7ttddqFi9ePLSgoCDHZDJ16PXKKozCAwCoZk3vmgfSdc0DpUdmHmjr1q3xNpvNu2/fvuoDBw4cGj9+fMvw4cMVrSVQeAAA1Wzp4nXMEXfJWPE45ojblh6ZeaCcnJxWj8cTKyJy8eJF3TPPPJN8zz33nFGSyzwQACAktnTxhqPougWbB7r77ruH7NixIz4QCOgWLlz49S233KLoNMk8EADgW8wDAQDwPUfhAQA0gcIDAGgChQcA0AQKDwCgCRQeAEATKDwAQNTx+/2Sk5OTO2HChEwRkaqqql6FhYXZw4YNy58yZcrw1tZWndJMCg8AEHWeeOKJpMzMzIvd///ggw8Ouffee+uOHz9eER8f71+5cqWiaSARCg8AECJntRiXbJVkZ3V4lhKOHDli2L59e/yiRYvOiogEAgHZvXu36c4772wQEVm4cOG5rVu39leaS+EBAFRzVovRvlospR+L2b5aLOEovV/84hdDS0tLT3avIdTV1cWaTKYOg8EgIiJpaWntdXV1iqaBRCg8AEAIXG4x+Tq65oE6RO9yhzYPtGHDhvjExET/TTfddCFcn7EbD48GAKhmtUjzijIJ+DtEHxsjAasltHmgXbt29duxY0d/s9kc39bWpvd6vfq77757aHNzc4zP5xODwSDHjh3rlZSU1K40mxMeAEA12wjxOhaJu6RYPI5F4raNCG014aWXXvLU1dWVezyeA+vWrasZO3Zs83vvvXd07Nixza+++uoAEZG1a9cOtNvtjUqzKTwAQEhsI8T79FQ5HWrZfZfnnnvu5Isvvpg8bNiw/IaGhtgHHnhA8aID80AAgG8xDwQAwPcchQcA0AQKDwCgCRQeAEATKDwAgCZQeAAATaDwAABRp+c80FNPPTVo2LBh+TqdbuSpU6dUPSWMwgMARJ2e80Djxo1r2bFjh/vqq69W/EixbhQeACAkzgoxLnlTkp0VkZkHEhH54Q9/eHHEiBGqy06EwgMAhMBZIUb7M2Ip3Spm+zNiCUfp9ZwHChcKDwCgmqtCTD5/1zyQX/SuCuaBAAD/DVnzpXnFhxLw+0UfGysBa37454GmTZuWvmXLlqOhflZOeAAA1Wz54nWUiLtkqngcJeK25Yd/HigcZSdC4QEAQmTLF+/Tt8npUMvuuzzxxBODk5KSCuvq6noVFRXlzpkzJ1VpBvNAAIBvMQ8EAMD3HIUHANAECg8AoAkUHgBAEyg8AIAmUHgAAE2g8AAAUafnPNAtt9ySnpaWlp+VlZU3e/bstLa2Np3STAoPABB1es4D3XHHHfU1NTUV1dXVB1tbW3W//e1vE5VmUngAgJA4PxPjkpcl2flZ5OaB5syZ06TX60Wv18uoUaO8J0+e7KU0l8IDAKjm/EyM9kfFUrpBzPZHxRKO0vuueaC2tjbdxo0bB06ZMqVJaS6FBwBQzbXvknmgDtG79kV2Hmj+/PnDxo4d2zJp0qQWpdnMAwEAVLOOlOYVf5aAv0P0sTESsI6M3DzQQw89lHL27NnY7du3H1GTzcOjAQDfUvPwaOdnYnTtE5N1pDTbRoVvMcHhcJiee+65pJ07dx5+/vnnE19//fXEv/71r9X9+vX7zuIK9vBoTngAgJDYRok3nEV3OQ8//HBqSkpK26hRo3JEROx2e8Ozzz57SkkGhQcAiEp2u73Zbrc3i4j4/f59oebxpRUAgCZQeAAATaDwAACaQOEBADSBwgMAaAKFBwDQBAoPABB1es4D3XrrrakjRozItVgsuZMmTRre1NSkuL8oPABA1Ok5D7Rq1aoT1dXVlW63u3LIkCHtv/nNbwYrzaTwAAAhce4W45LnJdm5O3LzQAkJCQERkUAgIBcvXtTrdIr3Xyk8AIB6zt1itN8jltI1YrbfI5ZwlF6weaBZs2alDRo0qOjw4cO9H3300a+V5lJ4AADVXLu75oECIn6/6F27IzcP9Pbbbx+rq6vbn5WV1bp27doBSrMpPACAatbrpdkQK4EYvUhsrASs14dtHqhgwYIFw/fs2WOaNm1aevf7sbGxcscdd9Rv3ryZwgMA/PPYrhevY5W4S+4Sj2OVuG3Xh7aa8NJLL3nq6urKPR7PgXXr1tWMHTu2+d133z1aUVERJ/LNPbx33323f1ZWVqvSbNYSAAAhsV0v3lCL7rt0dnbKvHnz0ltaWvSdnZ26nJycC+vWratVmsMALADgW2oGYKNNsAFYLmkCADSBwgMAaAKFBwDQBAoPAKAJFB4AQBMoPACAJlB4AICo03MeqNuCBQuG9u3b91o1mRQeACDq9JwHEhH55JNP+jY2Nqp+YAqFBwAIifMvYlyyTJKdf4ncPJDf75eSkpIhK1euPKk2l8IDAKjm/IsY7bPFUrpSzPbZYglH6V1uHujpp58efPPNNzempqb61OZSeAAA1Vw7xeTzdc0D+UTv2hn+eaBjx44ZNm/ePOCxxx5TvIF3KR4eDQBQzTpBmlf8XgJ+n+hjDRKwTgjbPFB8W1ub3uv16gsLC/N69erVmZaWViAi0traqh82bFj+8ePHK5Rk8/BoAMC31Dw82vkXMbp2isk6QZpt48O3muBwOEzPPfdc0s6dOw9f+nrfvn2vvXDhwv8J9nfBHh7NCQ8AEBLbePGGs+gihXt4AICoZLfbm3ue7kREvut0910oPACAJlB4AABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AEHV6zgPNnDkzzWw2F2RnZ+dmZ2fnfvrpp32UZvLDcwBA1OmeB2ppaYm55LWTd955Z4PaTE54AICQfOwU49IlkvyxM3LzQOFA4QEAVPvYKcaZdrGsKBXzTLtYwlF6l5sHEhFZvny52WKx5N51111DL168qFOaS+EBAFTb6fp/80A+v+h3usI/DyQi8vzzz3tqamoq9u/ff6ihoSFm6dKlyUqzKTwAgGoTrNJsMEhAHyNiiJXABGvY5oEKFixYMHzPnj2madOmpaempvr0er306dOnc+HChef27dun+CRJ4QEAVCu2iXeTQ9yLS8SzySHuYltoqwkvvfSSp66urtzj8RxYt25dzdixY5u3bNlytLa21iAiEggE5J133umfk5NzUWk239IEAISk2CbeUIvuPzNnzpz0+vr62M7OTl1ubu6F1157rVZpBgOwAIBvqRmAjTbBBmC5pAkA0AQKDwCgCRQeAEATKDwAgCZQeAAATaDwAACaQOEBAKJOz3mgQCAg9913nzktLS1/+PDheU888cRgpZn88BwAEHV6zgO9+OKLA0+ePGk4cuRIRUxMjHg8HsX9xQkPABCST51ifHaJJH8awXmgV155ZfCvf/3rUzEx38zjmc1mv9JcCg8AoNqnTjEusotldamYF9nFEo7Su9w80IkTJ+Jef/31Afn5+Tk/+tGPsg4cOBCnNJfCAwCo9qlLTP6ueSC/X/SfRmgeqL29Xde7d+/OioqKQ3fdddeZBQsWpCnN5h4eAEC1G6zS/OoKCfj9oo+NlcAN4ZsHim9ra9N7vV79tGnT0pOSktpvv/32BhGRn/zkJ4333ntvmtJsTngAANVusIl3tUPci0rEs9oh7hsiNA80efLkxm3btplERD744ANTampqm9JsTngAgJDcYBNvqEX3n3n88cdPz5o1K/33v/99Ut++fQOrV68+pjSDeSAAwLeYBwIA4HuOwgMAaAKFBwDQBAoPAKAJFB4AQBMoPACAJvA7PABA1PH7/VJQUJCbnJzcvnPnzsMjR44c4fV6Y0RE6uvrYwsLC71Op/OIkkwKDwAQdXrOA+3bt6+6+72JEydmTJ06tVFpJpc0AQAh2esU4x+WSPLeCM4Ddauvr9fv3r3bNHfu3AaluRQeAEC1vU4xPmwXy59KxfywXSzhKL3LzQN1e+ONNwbccMMN5xMSEgJKcyk8AIBqn7nE5POJvrNrHuizCM0DdXvrrbcSbrvttno12RQeAEC1UVZpNhgkoI8RiY2VwKjwzQMVLFiwYPiePXtM06ZNSxcROXXqVGx5ebnx1ltvbVKTTeEBAFQbbRNvqUPcc0vEU+oQ9+gIzQOJiLz++usDiouLG/v27atq9YBvaQIAQjLaJt5Qi+5KvP322wkPP/zwKbV/zzwQAOBbzAMBAPA9R+EBADSBwgMAaAKFBwDQBAoPAKAJFB4AQBMoPABA1PH7/ZKTk5M7YcKETBGRLVu2mHJzc3Oys7NzR44cOaKioiJOaSaFBwCIOt3zQN3//8ADD6SuX7/+aFVVVeXs2bPrly1blqI0k8IDAIRkv1OMry+R5P0RngdqbGyMERFpamqKSUlJ8SnN5dFiAADV9jvF+KRdLH6f6LeukMAvHeIuCvExY93zQE1NTTHdr61aterYjBkzsuLi4gL9+vXr2Lt37yGluZzwAACqlbvE5L9kHqg8QvNAzz//fNI777zzZV1dXfncuXPP/uxnPxuqNJsTHgBAtUKrNG9dIQG/X/SxsRIoDN88UHxbW5ve6/Xqx48fn3nkyJHexcXFXhGRefPmNUyaNClLaTYnPACAakU28f7SIe7pJeIJx+XMy80D7dix43BLS0tMeXl5nIiIw+G4KjMzs1VpNic8AEBIimziDbXovovBYJCVK1fWzpo1K0On00l8fHzHunXrjirNYR4IAPAt5oEAAPieo/AAAJpA4QEANIHCAwBoAoUHANAECg8AoAkUHgAg6vScB3rvvfdMubm5OVlZWXkzZsxI8/kUPzuawgMARJ9L54E6Ojrkpz/9afqbb75Z8+WXXx4cNmxY++9+97tEpZkUHgAgJFVOMW5ZIslVEZoHqqurizUYDIHCwsI2EZFJkyad37x5c3+luRQeAEC1KqcYV9nF4iwV8yq7WMJRet3zQHr9NxWVnJzs7+jo0H3yySd9RUQ2btw44NSpU72U5lJ4AADVql1i6uiaB+rwi746AvNAer1eXnvttZrFixcPLSgoyDGZTB3dZagED48GAKg2wirNO1dIoMMv+phYCYyIwDzQtGnT0rds2XJ037591SIi77zzzlWHDx/urTSbh0cDAL6l5uHRVU4xVrvENMIqzdlhXE1wOBym5557Lmnnzp2HPR5PrNls9l+8eFFXXFyctWTJklO33HLLZcs12MOjOeEBAEKSbRNvOIvuch5//PHkHTt2xAcCAd3ChQu/DlZ234UTHgDgW8wDAQDwPUfhAQA0gcIDAGgChQcA0AQKDwCgCRQeAEAT+B0eACDqmM3mAqPR2KHX6yU2NrazoqLiUF1dXcz06dOHezyeOLPZ3LZly5aaQYMGdVxpJic8AEBUKisrc1dVVVVWVFQcEhFZtmxZyvjx45tra2srxo8f3/yrX/0qWUkeJzwAQEhqnGI86hJTulWah0fwiSvbtm3rX1ZWVi0icvfdd58bN27cCBHxXOnfc8IDAKhW4xTjBrtYPi0V8wa7WGrCtIknImK1WrPy8vJynn322UQRkXPnzsWmpqb6RESGDh3qO3funKJDGyc8AIBqR11iCnTNAwX8oj/qElM4Tnm7du2qSk9P93k8ntji4mJLXl5e66Xv6/V60el0ijI54QEAVEu3SrPeIAFdjIg+VgLpIc4DfZubnu4TETGbzf4pU6Y07t692zhw4EB/bW2tQUSktrbWkJCQ4FeSSeEBAFQbbhPv7Q5x31Aintsd4g7H6e78+fP6hoYGffd/79y586rCwsKLEydObHz55ZcHioi8/PLLAydNmtSoJJdLmgCAkAy3iTecX1Y5efJk7PTp0zNFRDo6OnQzZ848N2vWrPM33nijd/r06RmpqamJZrO5/d133z2iJJfCAwBEldzc3Pbq6urKnq8nJyd37N692602l0uaAABNoPAAAJpA4QEANIHCAwBoAoUHANAECg8AoAkUHgAg6pjN5gKLxZKbnZ2dm5+fnyMisnbt2gGZmZl5er1+5CeffNJXaSa/wwMARKWysjJ3SkrKt48Pu+aaay5u2rTp8KJFi9LU5FF4AICQeJxi/Molpqut0myO4DzQdddd1/qf/6vguKQJAFDN4xTjR3axlJeK+SO7WDwRnAcKFSc8AIBqX3XNA0nXPNBXLjGF45R3uXmgyZMnt4SSyQkPAKDa1V3zQNI1D3R1BOeBQs2k8AAAqplt4v0fDnEXlojnfzjEHY7TXbB5oFBzuaQJAAiJ2SbecH5ZJdg80Guvvda/pKRkWENDQ+z06dOzcnJyLuzatevLK83VdXZ2huszAgC+5/bv33+sqKjo7H/15wjF/v37E4uKitJ6vs4lTQCAJlB4AABNoPAAAJpA4QEANIHCAwBoAoUHANAEfocHAIg6ZrO5wGg0duj1eomNje2sqKg4dPfddw/56KOP4g0GQ2dqamrbhg0bjiUmJnZcaSYnPABAVCorK3NXVVVVVlRUHBIRmThx4nm3233Q7XZXZmZmti5dujRZSR6FBwAIyRmnGCuXSPKZMC4lXM6MGTPOGwwGERG5/vrrvR6Pp5eSv6fwAACqnXGK8X/bxXK4VMz/2y6WcJbed80DrVu3LnHSpElNSvK4hwcAUO1Mj3mgMy4xDYrwPNAjjzySHBMT03nPPffUK8nkhAcAUG1Qj3mgQRGeB3rhhRcGbt++vf8777xzVK9XVmEUHgBAtUE28Y5xiDuzRDxjHOIOx+ku2DzQ22+/fdXKlSuTP/jgg8MmkymgNJdLmgCAkAyyiTccRdct2DzQsGHD8tvb2/XFxcUWEZHrrruu5Y033jh+pbkUHgAgquTm5rZXV1dX9nz9+PHjFaHkckkTAKAJFB4AQBMoPACAJlB4AABNoPAAAJpA4QEANIGfJQAAos7l5oEeeOCBqz/88MP+er1eBg4c6PvTn/50LC0tzXelmZzwAABRqec80LJly0673e7KqqqqysmTJzc99thjKUryKDwAQEianGI8vkSSmyI8D5SQkPDt48S8Xq9ep9Mp+nsuaQIAVGtyirHKLpZOn+hPrZBAtkPc8WF6zJjVas3S6XRy5513nvm3f/u3syIi9913n/nPf/7zQJPJ1FFWVlatJI8THgBAtSaXmDq75oE6/aJvcokpHLm7du2qqqysPPTRRx99uXr16sEffvhhPxGRF1980XP69OnyWbNmnXvmmWcGK8mk8AAAqsVbpVnXNQ+ki5VAfITngbotXLiw3uFwDFCSSeEBAFSLt4k32yHuq0vEE67LmcHmgQ4cOBDX/W/eeuut/hkZGReV5HIPDwAQknibeMN1304k+DzQxIkTM2pqanrrdLrOIUOGtK9Zs6ZWSS6FBwCIKsHmgbZv334klFwuaQIANIHCAwBoAoUHANAECg8AoAkUHgBAEyg8AIAmUHgAgKhjNpsLLBZLbnZ2dm5+fn7Ope8tW7YsSafTjTx16pSin9bxOzwAQFQqKytzp6Sk+C997fDhwwaXy3VVSkpKu9I8TngAgJC0OsXYuESSWyM8DyQicu+99w595plnTiqdBhKh8AAAIWh1ivGMXSzNpWI+YxdLOEvParVm5eXl5Tz77LOJIiLr16/vn5KS4rv++usVPUOzG5c0AQCqtbrEJF3zQOIXfatLTL3D8FzNXbt2VaWnp/s8Hk9scXGxJS8vr7W0tDR5586dX6rN5IQHAFCtt1WapWseSGIl0DtC80Aff/yx6eTJk3GFhYW5ZrO5oK6urtd1112Xc/z48Ss+uFF4AADVetvEO8ghblOJeAY5xB2O093l5oHGjBnjra+v3+/xeA54PJ4DSUlJ7Z9//vmhYcOG+f+zvG5c0gQAhKS3TbzhKLpuweaBQs2l8AAAUSXYPNClPB7PAaW5XNIEAGgChQcA0AQKDwCgCRQeAEATKDwAgCZQeAAATaDwAABR53LzQA8++ODVgwcPLszOzs7Nzs7O3bhxY7ySTH6HBwCISpebB7rnnnvqHn/88To1eZzwAAAhCTjF6F8iyYF/wjxQKCg8AIBqAacYfXaxdJSK2WcXSzhLr+c8kIjImjVrBlssltzZs2ennTlzJkZJHoUHAFAt0GMeKOASUzhyd+3aVVVZWXnoo48++nL16tWDP/zww36LFy/+ura29sChQ4cqk5OTfT//+c+HKsmk8AAAqul7zAPpIzQPtHv3buPQoUP9sbGxEhMTI/fee++ZL774QtFpksIDAKimt4nX4BB3TIl4DA5x6yM0D1RYWHixtrbW0P1v3nzzzf4jRoxQtHzOtzQBACHR28QbjqLrFmwe6F/+5V/SKysr+4iIDBkypP3VV1+tVZJL4QEAokqweaDNmzcfDSWXS5oAAE2g8AAAmkDhAQA0gcIDAGgChQcA0AQKDwCgCfwsAQAQdcxmc4HRaOzQ6/USGxvbWVFRcUhE5Mknnxz8yiuvDIqJiRGbzda0atWqk1eaSeEBAKJSz3mgrVu3mt5///3+lZWVlX369On0eDyKOoxLmgCA0DjbjbLEmyzO9ojOA/3hD38Y9PDDD5/q06dPp8g3z9lU8vcUHgBAPWe7UeznLVJ60Sz285Zwll7PeaCampreZWVlpsLCwuzRo0ePKCsr66skj0uaAAD1XL5/mAcSl88ktl4hP1dz165dVenp6T6PxxNbXFxsycvLa+3o6NDV19fHfPHFF1VlZWV9586dm3HixIkDev2Vnd044QEA1LMa/mEeSKyGiM0DJScnt8+aNatRr9fLhAkTLuj1+s7Tp09f8cGNwgMAqGfr5RXHVW4p6eMRx1XucJzugs0DTZ06tdHlcplERMrLy+N8Pp8+OTn5iu/jcUkTABAaWy9vOIquW7B5oNbWVt2cOXPSsrKy8gwGQ+CPf/zj0Su9nClC4QEAokyweaDevXt3btmyRfVEEJc0AQCaQOEBADSBwgMAaAKFBwDQBAoPAKAJFB4AQBP4WQIAIOpcbh5oypQpw48cOdJbRKS5uTnGZDJ1VFVV/X8/XwiGwgMARKWe80Dvv/9+Tfd/L1q0aEh8fHyHkjwKDwAQGmeLUVxek1iNzWLrF7YnrgQTCARk69atCTt27KhW8nfcwwMAqOdsMYr9hEVKz5nFfsIizpaIzQN12759e7/ExERfQUFBm5I8TngAAPVcXpP4OrvmgTr14vKawnHKu9w80OTJk1tERNavX58wc+bMeqWZnPAAAOpZjc1i0HXNA+kCYjVGbB5IRMTn88m2bdsGzJs3j8IDAPwT2fp5xTHULSUDPeIY6g7H6S7YPJCIyJYtW64aPnx4a0ZGhk9pLpc0AQChsfXzhvPLKsHmgURENmzYkDB79mzFpzsRCg8AEGWCzQOJiGzatOmY2lwuaQIANIHCAwBoAoUHANAECg8AcKlAIBDQ/Vd/CLW6Pnvgcu9ReACAS1WcOXMm/vtYeoFAQHfmzJl4Eam43Pt8SxMA8C2/3/+vp0+ffuX06dP58v07FAVEpMLv9//r5d7UdXZ2/pM/DwAA/3zft/YGAEAVCg8AoAkUHgBAEyg8AIAmUHgAAE34v0GN5N2e8PO0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 200\n",
    "\n",
    "p = reduce_dims_and_plot(projections,\n",
    "                         y=clusters,\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnormalized_samples = samples.clone()\n",
    "\n",
    "# for col, sensor in enumerate(tqdm(dataset.dataset.all_signals)):\n",
    "#     denormalizer = dataset.dataset.get_denormalization_for_sensor(sensor)\n",
    "#     unnormalized_samples[:, col, :] = denormalizer(unnormalized_samples[:, col, :])\n",
    "\n",
    "sampled = samples[..., range(0, samples.shape[-1], 200)]\n",
    "\n",
    "samples_f = sampled.flatten(1)\n",
    "tree_dataset = list(zip(samples_f, clusters))\n",
    "batch_size = 2000\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 500\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "tree_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT accuracy: 0.9603804267481397\n"
     ]
    }
   ],
   "source": [
    "tree = SDT(input_dim=samples_f.shape[1], output_dim=len(labels), depth=tree_depth, lamda=1e-3, use_cuda=True)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)\n",
    "clf = DecisionTreeClassifier(max_depth=tree_depth).fit(samples_f, clusters)\n",
    "print(f\"DT accuracy: {clf.score(samples_f, clusters)}\")\n",
    "tree.initialize_from_decision_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.30161533351695535\n",
      "layer 0: 0.988950276243094\n",
      "layer 1: 0.988950276243094\n",
      "layer 2: 0.988950276243094\n",
      "layer 3: 0.988950276243094\n",
      "layer 4: 0.988950276243094\n",
      "layer 5: 0.8344267955801106\n",
      "layer 6: 0.6799033149171272\n",
      "layer 7: 0.47902279005524867\n",
      "layer 8: 0.26268991712707185\n",
      "Epoch: 00 | Batch: 000 / 011 | Total loss: 4.069 | Reg loss: 0.019 | Tree loss: 4.069 | Accuracy: 0.048500 | 1.057 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 011 | Total loss: 4.066 | Reg loss: 0.019 | Tree loss: 4.066 | Accuracy: 0.029000 | 0.994 sec/iter\n",
      "Epoch: 00 | Batch: 002 / 011 | Total loss: 4.061 | Reg loss: 0.018 | Tree loss: 4.061 | Accuracy: 0.048500 | 0.975 sec/iter\n",
      "Epoch: 00 | Batch: 003 / 011 | Total loss: 4.057 | Reg loss: 0.018 | Tree loss: 4.057 | Accuracy: 0.054500 | 0.967 sec/iter\n",
      "Epoch: 00 | Batch: 004 / 011 | Total loss: 4.055 | Reg loss: 0.018 | Tree loss: 4.055 | Accuracy: 0.048000 | 0.963 sec/iter\n",
      "Epoch: 00 | Batch: 005 / 011 | Total loss: 4.051 | Reg loss: 0.018 | Tree loss: 4.051 | Accuracy: 0.042500 | 0.961 sec/iter\n",
      "Epoch: 00 | Batch: 006 / 011 | Total loss: 4.047 | Reg loss: 0.017 | Tree loss: 4.047 | Accuracy: 0.057000 | 0.961 sec/iter\n",
      "Epoch: 00 | Batch: 007 / 011 | Total loss: 4.043 | Reg loss: 0.017 | Tree loss: 4.043 | Accuracy: 0.088500 | 0.96 sec/iter\n",
      "Epoch: 00 | Batch: 008 / 011 | Total loss: 4.039 | Reg loss: 0.017 | Tree loss: 4.039 | Accuracy: 0.094500 | 0.959 sec/iter\n",
      "Epoch: 00 | Batch: 009 / 011 | Total loss: 4.032 | Reg loss: 0.017 | Tree loss: 4.032 | Accuracy: 0.125000 | 0.959 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 011 | Total loss: 4.031 | Reg loss: 0.017 | Tree loss: 4.031 | Accuracy: 0.109215 | 0.94 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 01 | Batch: 000 / 011 | Total loss: 4.060 | Reg loss: 0.016 | Tree loss: 4.060 | Accuracy: 0.050000 | 0.961 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 011 | Total loss: 4.056 | Reg loss: 0.016 | Tree loss: 4.056 | Accuracy: 0.052500 | 0.959 sec/iter\n",
      "Epoch: 01 | Batch: 002 / 011 | Total loss: 4.052 | Reg loss: 0.016 | Tree loss: 4.052 | Accuracy: 0.114000 | 0.957 sec/iter\n",
      "Epoch: 01 | Batch: 003 / 011 | Total loss: 4.050 | Reg loss: 0.016 | Tree loss: 4.050 | Accuracy: 0.109000 | 0.956 sec/iter\n",
      "Epoch: 01 | Batch: 004 / 011 | Total loss: 4.045 | Reg loss: 0.016 | Tree loss: 4.045 | Accuracy: 0.099500 | 0.956 sec/iter\n",
      "Epoch: 01 | Batch: 005 / 011 | Total loss: 4.039 | Reg loss: 0.016 | Tree loss: 4.039 | Accuracy: 0.097000 | 0.955 sec/iter\n",
      "Epoch: 01 | Batch: 006 / 011 | Total loss: 4.036 | Reg loss: 0.016 | Tree loss: 4.036 | Accuracy: 0.094500 | 0.955 sec/iter\n",
      "Epoch: 01 | Batch: 007 / 011 | Total loss: 4.033 | Reg loss: 0.016 | Tree loss: 4.033 | Accuracy: 0.097000 | 0.955 sec/iter\n",
      "Epoch: 01 | Batch: 008 / 011 | Total loss: 4.027 | Reg loss: 0.017 | Tree loss: 4.027 | Accuracy: 0.107500 | 0.955 sec/iter\n",
      "Epoch: 01 | Batch: 009 / 011 | Total loss: 4.022 | Reg loss: 0.017 | Tree loss: 4.022 | Accuracy: 0.105500 | 0.955 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 011 | Total loss: 4.021 | Reg loss: 0.017 | Tree loss: 4.021 | Accuracy: 0.068259 | 0.946 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 02 | Batch: 000 / 011 | Total loss: 4.057 | Reg loss: 0.015 | Tree loss: 4.057 | Accuracy: 0.047000 | 0.958 sec/iter\n",
      "Epoch: 02 | Batch: 001 / 011 | Total loss: 4.052 | Reg loss: 0.015 | Tree loss: 4.052 | Accuracy: 0.111000 | 0.957 sec/iter\n",
      "Epoch: 02 | Batch: 002 / 011 | Total loss: 4.047 | Reg loss: 0.015 | Tree loss: 4.047 | Accuracy: 0.126000 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 003 / 011 | Total loss: 4.042 | Reg loss: 0.015 | Tree loss: 4.042 | Accuracy: 0.121500 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 004 / 011 | Total loss: 4.037 | Reg loss: 0.016 | Tree loss: 4.037 | Accuracy: 0.095000 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 005 / 011 | Total loss: 4.030 | Reg loss: 0.016 | Tree loss: 4.030 | Accuracy: 0.104000 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 006 / 011 | Total loss: 4.025 | Reg loss: 0.016 | Tree loss: 4.025 | Accuracy: 0.095500 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 007 / 011 | Total loss: 4.015 | Reg loss: 0.016 | Tree loss: 4.015 | Accuracy: 0.113000 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 008 / 011 | Total loss: 4.014 | Reg loss: 0.016 | Tree loss: 4.014 | Accuracy: 0.089500 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 009 / 011 | Total loss: 4.005 | Reg loss: 0.016 | Tree loss: 4.005 | Accuracy: 0.116000 | 0.956 sec/iter\n",
      "Epoch: 02 | Batch: 010 / 011 | Total loss: 3.998 | Reg loss: 0.017 | Tree loss: 3.998 | Accuracy: 0.126280 | 0.95 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 03 | Batch: 000 / 011 | Total loss: 4.054 | Reg loss: 0.015 | Tree loss: 4.054 | Accuracy: 0.042500 | 0.958 sec/iter\n",
      "Epoch: 03 | Batch: 001 / 011 | Total loss: 4.047 | Reg loss: 0.015 | Tree loss: 4.047 | Accuracy: 0.117500 | 0.957 sec/iter\n",
      "Epoch: 03 | Batch: 002 / 011 | Total loss: 4.041 | Reg loss: 0.015 | Tree loss: 4.041 | Accuracy: 0.126000 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 003 / 011 | Total loss: 4.035 | Reg loss: 0.015 | Tree loss: 4.035 | Accuracy: 0.116500 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 004 / 011 | Total loss: 4.024 | Reg loss: 0.015 | Tree loss: 4.024 | Accuracy: 0.114500 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 005 / 011 | Total loss: 4.014 | Reg loss: 0.016 | Tree loss: 4.014 | Accuracy: 0.106000 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 006 / 011 | Total loss: 4.010 | Reg loss: 0.016 | Tree loss: 4.010 | Accuracy: 0.098500 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 007 / 011 | Total loss: 3.997 | Reg loss: 0.016 | Tree loss: 3.997 | Accuracy: 0.091500 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 008 / 011 | Total loss: 3.988 | Reg loss: 0.016 | Tree loss: 3.988 | Accuracy: 0.094000 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 009 / 011 | Total loss: 3.983 | Reg loss: 0.016 | Tree loss: 3.983 | Accuracy: 0.083000 | 0.956 sec/iter\n",
      "Epoch: 03 | Batch: 010 / 011 | Total loss: 3.971 | Reg loss: 0.017 | Tree loss: 3.971 | Accuracy: 0.081911 | 0.951 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 04 | Batch: 000 / 011 | Total loss: 4.049 | Reg loss: 0.015 | Tree loss: 4.049 | Accuracy: 0.082000 | 0.957 sec/iter\n",
      "Epoch: 04 | Batch: 001 / 011 | Total loss: 4.043 | Reg loss: 0.015 | Tree loss: 4.043 | Accuracy: 0.083000 | 0.956 sec/iter\n",
      "Epoch: 04 | Batch: 002 / 011 | Total loss: 4.033 | Reg loss: 0.015 | Tree loss: 4.033 | Accuracy: 0.096500 | 0.956 sec/iter\n",
      "Epoch: 04 | Batch: 003 / 011 | Total loss: 4.023 | Reg loss: 0.015 | Tree loss: 4.023 | Accuracy: 0.103500 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 004 / 011 | Total loss: 4.007 | Reg loss: 0.015 | Tree loss: 4.007 | Accuracy: 0.103500 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 005 / 011 | Total loss: 3.995 | Reg loss: 0.016 | Tree loss: 3.995 | Accuracy: 0.099500 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 006 / 011 | Total loss: 3.984 | Reg loss: 0.016 | Tree loss: 3.984 | Accuracy: 0.091000 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 007 / 011 | Total loss: 3.970 | Reg loss: 0.016 | Tree loss: 3.970 | Accuracy: 0.101500 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 008 / 011 | Total loss: 3.961 | Reg loss: 0.016 | Tree loss: 3.961 | Accuracy: 0.077500 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 009 / 011 | Total loss: 3.953 | Reg loss: 0.017 | Tree loss: 3.953 | Accuracy: 0.086000 | 0.955 sec/iter\n",
      "Epoch: 04 | Batch: 010 / 011 | Total loss: 3.940 | Reg loss: 0.017 | Tree loss: 3.940 | Accuracy: 0.109215 | 0.952 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 05 | Batch: 000 / 011 | Total loss: 4.043 | Reg loss: 0.015 | Tree loss: 4.043 | Accuracy: 0.097500 | 0.956 sec/iter\n",
      "Epoch: 05 | Batch: 001 / 011 | Total loss: 4.035 | Reg loss: 0.015 | Tree loss: 4.035 | Accuracy: 0.087000 | 0.955 sec/iter\n",
      "Epoch: 05 | Batch: 002 / 011 | Total loss: 4.020 | Reg loss: 0.015 | Tree loss: 4.020 | Accuracy: 0.117000 | 0.955 sec/iter\n",
      "Epoch: 05 | Batch: 003 / 011 | Total loss: 4.005 | Reg loss: 0.016 | Tree loss: 4.005 | Accuracy: 0.105000 | 0.955 sec/iter\n",
      "Epoch: 05 | Batch: 004 / 011 | Total loss: 3.985 | Reg loss: 0.016 | Tree loss: 3.985 | Accuracy: 0.102500 | 0.955 sec/iter\n",
      "Epoch: 05 | Batch: 005 / 011 | Total loss: 3.968 | Reg loss: 0.016 | Tree loss: 3.968 | Accuracy: 0.085500 | 0.956 sec/iter\n",
      "Epoch: 05 | Batch: 006 / 011 | Total loss: 3.956 | Reg loss: 0.016 | Tree loss: 3.956 | Accuracy: 0.074500 | 0.956 sec/iter\n",
      "Epoch: 05 | Batch: 007 / 011 | Total loss: 3.939 | Reg loss: 0.016 | Tree loss: 3.939 | Accuracy: 0.068500 | 0.956 sec/iter\n",
      "Epoch: 05 | Batch: 008 / 011 | Total loss: 3.928 | Reg loss: 0.017 | Tree loss: 3.928 | Accuracy: 0.072500 | 0.956 sec/iter\n",
      "Epoch: 05 | Batch: 009 / 011 | Total loss: 3.916 | Reg loss: 0.017 | Tree loss: 3.916 | Accuracy: 0.065500 | 0.956 sec/iter\n",
      "Epoch: 05 | Batch: 010 / 011 | Total loss: 3.882 | Reg loss: 0.017 | Tree loss: 3.882 | Accuracy: 0.085324 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 06 | Batch: 000 / 011 | Total loss: 4.036 | Reg loss: 0.016 | Tree loss: 4.036 | Accuracy: 0.091000 | 0.957 sec/iter\n",
      "Epoch: 06 | Batch: 001 / 011 | Total loss: 4.022 | Reg loss: 0.016 | Tree loss: 4.022 | Accuracy: 0.116500 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 002 / 011 | Total loss: 4.002 | Reg loss: 0.016 | Tree loss: 4.002 | Accuracy: 0.121000 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 003 / 011 | Total loss: 3.982 | Reg loss: 0.016 | Tree loss: 3.982 | Accuracy: 0.109000 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 004 / 011 | Total loss: 3.960 | Reg loss: 0.016 | Tree loss: 3.960 | Accuracy: 0.096000 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 005 / 011 | Total loss: 3.936 | Reg loss: 0.016 | Tree loss: 3.936 | Accuracy: 0.086500 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 006 / 011 | Total loss: 3.914 | Reg loss: 0.017 | Tree loss: 3.914 | Accuracy: 0.085500 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 007 / 011 | Total loss: 3.899 | Reg loss: 0.017 | Tree loss: 3.899 | Accuracy: 0.076000 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 008 / 011 | Total loss: 3.883 | Reg loss: 0.017 | Tree loss: 3.883 | Accuracy: 0.060000 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 009 / 011 | Total loss: 3.878 | Reg loss: 0.017 | Tree loss: 3.878 | Accuracy: 0.061500 | 0.956 sec/iter\n",
      "Epoch: 06 | Batch: 010 / 011 | Total loss: 3.831 | Reg loss: 0.018 | Tree loss: 3.831 | Accuracy: 0.092150 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 07 | Batch: 000 / 011 | Total loss: 4.023 | Reg loss: 0.016 | Tree loss: 4.023 | Accuracy: 0.113000 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 001 / 011 | Total loss: 4.001 | Reg loss: 0.016 | Tree loss: 4.001 | Accuracy: 0.123500 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 002 / 011 | Total loss: 3.977 | Reg loss: 0.016 | Tree loss: 3.977 | Accuracy: 0.116500 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 003 / 011 | Total loss: 3.952 | Reg loss: 0.016 | Tree loss: 3.952 | Accuracy: 0.092500 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 004 / 011 | Total loss: 3.921 | Reg loss: 0.017 | Tree loss: 3.921 | Accuracy: 0.092000 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 005 / 011 | Total loss: 3.896 | Reg loss: 0.017 | Tree loss: 3.896 | Accuracy: 0.089000 | 0.955 sec/iter\n",
      "Epoch: 07 | Batch: 006 / 011 | Total loss: 3.875 | Reg loss: 0.017 | Tree loss: 3.875 | Accuracy: 0.062500 | 0.955 sec/iter\n",
      "Epoch: 07 | Batch: 007 / 011 | Total loss: 3.860 | Reg loss: 0.017 | Tree loss: 3.860 | Accuracy: 0.058000 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 008 / 011 | Total loss: 3.844 | Reg loss: 0.018 | Tree loss: 3.844 | Accuracy: 0.070000 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 009 / 011 | Total loss: 3.840 | Reg loss: 0.018 | Tree loss: 3.840 | Accuracy: 0.055500 | 0.956 sec/iter\n",
      "Epoch: 07 | Batch: 010 / 011 | Total loss: 3.804 | Reg loss: 0.018 | Tree loss: 3.804 | Accuracy: 0.078498 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 08 | Batch: 000 / 011 | Total loss: 4.003 | Reg loss: 0.017 | Tree loss: 4.003 | Accuracy: 0.119000 | 0.956 sec/iter\n",
      "Epoch: 08 | Batch: 001 / 011 | Total loss: 3.981 | Reg loss: 0.017 | Tree loss: 3.981 | Accuracy: 0.119500 | 0.956 sec/iter\n",
      "Epoch: 08 | Batch: 002 / 011 | Total loss: 3.947 | Reg loss: 0.017 | Tree loss: 3.947 | Accuracy: 0.134000 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 003 / 011 | Total loss: 3.922 | Reg loss: 0.017 | Tree loss: 3.922 | Accuracy: 0.119500 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 004 / 011 | Total loss: 3.882 | Reg loss: 0.017 | Tree loss: 3.882 | Accuracy: 0.104000 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 005 / 011 | Total loss: 3.863 | Reg loss: 0.017 | Tree loss: 3.863 | Accuracy: 0.093500 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 006 / 011 | Total loss: 3.824 | Reg loss: 0.018 | Tree loss: 3.824 | Accuracy: 0.089000 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 007 / 011 | Total loss: 3.821 | Reg loss: 0.018 | Tree loss: 3.821 | Accuracy: 0.074000 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 008 / 011 | Total loss: 3.797 | Reg loss: 0.018 | Tree loss: 3.797 | Accuracy: 0.067500 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 009 / 011 | Total loss: 3.792 | Reg loss: 0.018 | Tree loss: 3.792 | Accuracy: 0.059000 | 0.955 sec/iter\n",
      "Epoch: 08 | Batch: 010 / 011 | Total loss: 3.771 | Reg loss: 0.019 | Tree loss: 3.771 | Accuracy: 0.054608 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 09 | Batch: 000 / 011 | Total loss: 3.980 | Reg loss: 0.017 | Tree loss: 3.980 | Accuracy: 0.117500 | 0.956 sec/iter\n",
      "Epoch: 09 | Batch: 001 / 011 | Total loss: 3.949 | Reg loss: 0.017 | Tree loss: 3.949 | Accuracy: 0.140000 | 0.956 sec/iter\n",
      "Epoch: 09 | Batch: 002 / 011 | Total loss: 3.914 | Reg loss: 0.018 | Tree loss: 3.914 | Accuracy: 0.144000 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 003 / 011 | Total loss: 3.877 | Reg loss: 0.018 | Tree loss: 3.877 | Accuracy: 0.134000 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 004 / 011 | Total loss: 3.847 | Reg loss: 0.018 | Tree loss: 3.847 | Accuracy: 0.111500 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 005 / 011 | Total loss: 3.824 | Reg loss: 0.018 | Tree loss: 3.824 | Accuracy: 0.106000 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 006 / 011 | Total loss: 3.781 | Reg loss: 0.018 | Tree loss: 3.781 | Accuracy: 0.089000 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 007 / 011 | Total loss: 3.767 | Reg loss: 0.018 | Tree loss: 3.767 | Accuracy: 0.089000 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 008 / 011 | Total loss: 3.755 | Reg loss: 0.019 | Tree loss: 3.755 | Accuracy: 0.077500 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 009 / 011 | Total loss: 3.745 | Reg loss: 0.019 | Tree loss: 3.745 | Accuracy: 0.072000 | 0.955 sec/iter\n",
      "Epoch: 09 | Batch: 010 / 011 | Total loss: 3.732 | Reg loss: 0.019 | Tree loss: 3.732 | Accuracy: 0.081911 | 0.953 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 10 | Batch: 000 / 011 | Total loss: 3.950 | Reg loss: 0.018 | Tree loss: 3.950 | Accuracy: 0.160500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 001 / 011 | Total loss: 3.921 | Reg loss: 0.018 | Tree loss: 3.921 | Accuracy: 0.153500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 002 / 011 | Total loss: 3.879 | Reg loss: 0.018 | Tree loss: 3.879 | Accuracy: 0.158500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 003 / 011 | Total loss: 3.842 | Reg loss: 0.018 | Tree loss: 3.842 | Accuracy: 0.144500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 004 / 011 | Total loss: 3.793 | Reg loss: 0.018 | Tree loss: 3.793 | Accuracy: 0.135500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 005 / 011 | Total loss: 3.763 | Reg loss: 0.019 | Tree loss: 3.763 | Accuracy: 0.099500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 006 / 011 | Total loss: 3.741 | Reg loss: 0.019 | Tree loss: 3.741 | Accuracy: 0.091000 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 007 / 011 | Total loss: 3.719 | Reg loss: 0.019 | Tree loss: 3.719 | Accuracy: 0.096000 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 008 / 011 | Total loss: 3.700 | Reg loss: 0.019 | Tree loss: 3.700 | Accuracy: 0.088000 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 009 / 011 | Total loss: 3.691 | Reg loss: 0.020 | Tree loss: 3.691 | Accuracy: 0.097500 | 0.955 sec/iter\n",
      "Epoch: 10 | Batch: 010 / 011 | Total loss: 3.685 | Reg loss: 0.020 | Tree loss: 3.685 | Accuracy: 0.092150 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 11 | Batch: 000 / 011 | Total loss: 3.919 | Reg loss: 0.019 | Tree loss: 3.919 | Accuracy: 0.177500 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 001 / 011 | Total loss: 3.877 | Reg loss: 0.019 | Tree loss: 3.877 | Accuracy: 0.163000 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 002 / 011 | Total loss: 3.832 | Reg loss: 0.019 | Tree loss: 3.832 | Accuracy: 0.152500 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 003 / 011 | Total loss: 3.787 | Reg loss: 0.019 | Tree loss: 3.787 | Accuracy: 0.139000 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 004 / 011 | Total loss: 3.753 | Reg loss: 0.019 | Tree loss: 3.753 | Accuracy: 0.121500 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 005 / 011 | Total loss: 3.717 | Reg loss: 0.019 | Tree loss: 3.717 | Accuracy: 0.113500 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 006 / 011 | Total loss: 3.699 | Reg loss: 0.019 | Tree loss: 3.699 | Accuracy: 0.085000 | 0.954 sec/iter\n",
      "Epoch: 11 | Batch: 007 / 011 | Total loss: 3.669 | Reg loss: 0.020 | Tree loss: 3.669 | Accuracy: 0.081000 | 0.954 sec/iter\n",
      "Epoch: 11 | Batch: 008 / 011 | Total loss: 3.646 | Reg loss: 0.020 | Tree loss: 3.646 | Accuracy: 0.083000 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 009 / 011 | Total loss: 3.634 | Reg loss: 0.020 | Tree loss: 3.634 | Accuracy: 0.087000 | 0.955 sec/iter\n",
      "Epoch: 11 | Batch: 010 / 011 | Total loss: 3.636 | Reg loss: 0.020 | Tree loss: 3.636 | Accuracy: 0.085324 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 12 | Batch: 000 / 011 | Total loss: 3.879 | Reg loss: 0.019 | Tree loss: 3.879 | Accuracy: 0.179500 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 001 / 011 | Total loss: 3.834 | Reg loss: 0.019 | Tree loss: 3.834 | Accuracy: 0.162000 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 002 / 011 | Total loss: 3.788 | Reg loss: 0.019 | Tree loss: 3.788 | Accuracy: 0.145000 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 003 / 011 | Total loss: 3.741 | Reg loss: 0.019 | Tree loss: 3.741 | Accuracy: 0.148500 | 0.954 sec/iter\n",
      "Epoch: 12 | Batch: 004 / 011 | Total loss: 3.702 | Reg loss: 0.020 | Tree loss: 3.702 | Accuracy: 0.134500 | 0.954 sec/iter\n",
      "Epoch: 12 | Batch: 005 / 011 | Total loss: 3.664 | Reg loss: 0.020 | Tree loss: 3.664 | Accuracy: 0.122500 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 006 / 011 | Total loss: 3.641 | Reg loss: 0.020 | Tree loss: 3.641 | Accuracy: 0.095500 | 0.954 sec/iter\n",
      "Epoch: 12 | Batch: 007 / 011 | Total loss: 3.606 | Reg loss: 0.020 | Tree loss: 3.606 | Accuracy: 0.100000 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 008 / 011 | Total loss: 3.598 | Reg loss: 0.020 | Tree loss: 3.598 | Accuracy: 0.093500 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 009 / 011 | Total loss: 3.567 | Reg loss: 0.021 | Tree loss: 3.567 | Accuracy: 0.097000 | 0.955 sec/iter\n",
      "Epoch: 12 | Batch: 010 / 011 | Total loss: 3.572 | Reg loss: 0.021 | Tree loss: 3.572 | Accuracy: 0.095563 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 13 | Batch: 000 / 011 | Total loss: 3.839 | Reg loss: 0.020 | Tree loss: 3.839 | Accuracy: 0.151000 | 0.955 sec/iter\n",
      "Epoch: 13 | Batch: 001 / 011 | Total loss: 3.791 | Reg loss: 0.020 | Tree loss: 3.791 | Accuracy: 0.159000 | 0.955 sec/iter\n",
      "Epoch: 13 | Batch: 002 / 011 | Total loss: 3.733 | Reg loss: 0.020 | Tree loss: 3.733 | Accuracy: 0.162000 | 0.955 sec/iter\n",
      "Epoch: 13 | Batch: 003 / 011 | Total loss: 3.683 | Reg loss: 0.020 | Tree loss: 3.683 | Accuracy: 0.150500 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 004 / 011 | Total loss: 3.639 | Reg loss: 0.020 | Tree loss: 3.639 | Accuracy: 0.165000 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 005 / 011 | Total loss: 3.610 | Reg loss: 0.020 | Tree loss: 3.610 | Accuracy: 0.120500 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 006 / 011 | Total loss: 3.574 | Reg loss: 0.021 | Tree loss: 3.574 | Accuracy: 0.124000 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 007 / 011 | Total loss: 3.554 | Reg loss: 0.021 | Tree loss: 3.554 | Accuracy: 0.098000 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 008 / 011 | Total loss: 3.532 | Reg loss: 0.021 | Tree loss: 3.532 | Accuracy: 0.103000 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 009 / 011 | Total loss: 3.527 | Reg loss: 0.021 | Tree loss: 3.527 | Accuracy: 0.092500 | 0.954 sec/iter\n",
      "Epoch: 13 | Batch: 010 / 011 | Total loss: 3.519 | Reg loss: 0.021 | Tree loss: 3.519 | Accuracy: 0.102389 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 14 | Batch: 000 / 011 | Total loss: 3.786 | Reg loss: 0.020 | Tree loss: 3.786 | Accuracy: 0.174000 | 0.955 sec/iter\n",
      "Epoch: 14 | Batch: 001 / 011 | Total loss: 3.739 | Reg loss: 0.020 | Tree loss: 3.739 | Accuracy: 0.163000 | 0.955 sec/iter\n",
      "Epoch: 14 | Batch: 002 / 011 | Total loss: 3.679 | Reg loss: 0.021 | Tree loss: 3.679 | Accuracy: 0.165000 | 0.955 sec/iter\n",
      "Epoch: 14 | Batch: 003 / 011 | Total loss: 3.638 | Reg loss: 0.021 | Tree loss: 3.638 | Accuracy: 0.166500 | 0.954 sec/iter\n",
      "Epoch: 14 | Batch: 004 / 011 | Total loss: 3.580 | Reg loss: 0.021 | Tree loss: 3.580 | Accuracy: 0.155500 | 0.954 sec/iter\n",
      "Epoch: 14 | Batch: 005 / 011 | Total loss: 3.551 | Reg loss: 0.021 | Tree loss: 3.551 | Accuracy: 0.135500 | 0.954 sec/iter\n",
      "Epoch: 14 | Batch: 006 / 011 | Total loss: 3.532 | Reg loss: 0.021 | Tree loss: 3.532 | Accuracy: 0.126000 | 0.954 sec/iter\n",
      "Epoch: 14 | Batch: 007 / 011 | Total loss: 3.504 | Reg loss: 0.021 | Tree loss: 3.504 | Accuracy: 0.115500 | 0.955 sec/iter\n",
      "Epoch: 14 | Batch: 008 / 011 | Total loss: 3.481 | Reg loss: 0.022 | Tree loss: 3.481 | Accuracy: 0.105500 | 0.955 sec/iter\n",
      "Epoch: 14 | Batch: 009 / 011 | Total loss: 3.474 | Reg loss: 0.022 | Tree loss: 3.474 | Accuracy: 0.103000 | 0.955 sec/iter\n",
      "Epoch: 14 | Batch: 010 / 011 | Total loss: 3.468 | Reg loss: 0.022 | Tree loss: 3.468 | Accuracy: 0.078498 | 0.953 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 15 | Batch: 000 / 011 | Total loss: 3.735 | Reg loss: 0.021 | Tree loss: 3.735 | Accuracy: 0.179500 | 0.955 sec/iter\n",
      "Epoch: 15 | Batch: 001 / 011 | Total loss: 3.676 | Reg loss: 0.021 | Tree loss: 3.676 | Accuracy: 0.169000 | 0.955 sec/iter\n",
      "Epoch: 15 | Batch: 002 / 011 | Total loss: 3.632 | Reg loss: 0.021 | Tree loss: 3.632 | Accuracy: 0.162000 | 0.955 sec/iter\n",
      "Epoch: 15 | Batch: 003 / 011 | Total loss: 3.585 | Reg loss: 0.021 | Tree loss: 3.585 | Accuracy: 0.159000 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 004 / 011 | Total loss: 3.539 | Reg loss: 0.021 | Tree loss: 3.539 | Accuracy: 0.164500 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 005 / 011 | Total loss: 3.495 | Reg loss: 0.022 | Tree loss: 3.495 | Accuracy: 0.148000 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 006 / 011 | Total loss: 3.463 | Reg loss: 0.022 | Tree loss: 3.463 | Accuracy: 0.136000 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 007 / 011 | Total loss: 3.445 | Reg loss: 0.022 | Tree loss: 3.445 | Accuracy: 0.126500 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 008 / 011 | Total loss: 3.434 | Reg loss: 0.022 | Tree loss: 3.434 | Accuracy: 0.125000 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 009 / 011 | Total loss: 3.419 | Reg loss: 0.022 | Tree loss: 3.419 | Accuracy: 0.103000 | 0.954 sec/iter\n",
      "Epoch: 15 | Batch: 010 / 011 | Total loss: 3.388 | Reg loss: 0.023 | Tree loss: 3.388 | Accuracy: 0.116041 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 16 | Batch: 000 / 011 | Total loss: 3.685 | Reg loss: 0.022 | Tree loss: 3.685 | Accuracy: 0.200500 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 001 / 011 | Total loss: 3.637 | Reg loss: 0.022 | Tree loss: 3.637 | Accuracy: 0.181500 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 002 / 011 | Total loss: 3.573 | Reg loss: 0.022 | Tree loss: 3.573 | Accuracy: 0.174000 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 003 / 011 | Total loss: 3.521 | Reg loss: 0.022 | Tree loss: 3.521 | Accuracy: 0.169500 | 0.954 sec/iter\n",
      "Epoch: 16 | Batch: 004 / 011 | Total loss: 3.478 | Reg loss: 0.022 | Tree loss: 3.478 | Accuracy: 0.168500 | 0.954 sec/iter\n",
      "Epoch: 16 | Batch: 005 / 011 | Total loss: 3.452 | Reg loss: 0.022 | Tree loss: 3.452 | Accuracy: 0.153000 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 006 / 011 | Total loss: 3.417 | Reg loss: 0.022 | Tree loss: 3.417 | Accuracy: 0.138500 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 007 / 011 | Total loss: 3.391 | Reg loss: 0.023 | Tree loss: 3.391 | Accuracy: 0.137500 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 008 / 011 | Total loss: 3.378 | Reg loss: 0.023 | Tree loss: 3.378 | Accuracy: 0.132000 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 009 / 011 | Total loss: 3.363 | Reg loss: 0.023 | Tree loss: 3.363 | Accuracy: 0.121000 | 0.955 sec/iter\n",
      "Epoch: 16 | Batch: 010 / 011 | Total loss: 3.294 | Reg loss: 0.023 | Tree loss: 3.294 | Accuracy: 0.136519 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 17 | Batch: 000 / 011 | Total loss: 3.642 | Reg loss: 0.022 | Tree loss: 3.642 | Accuracy: 0.197000 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 001 / 011 | Total loss: 3.578 | Reg loss: 0.022 | Tree loss: 3.578 | Accuracy: 0.201500 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 002 / 011 | Total loss: 3.526 | Reg loss: 0.022 | Tree loss: 3.526 | Accuracy: 0.200000 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 003 / 011 | Total loss: 3.473 | Reg loss: 0.023 | Tree loss: 3.473 | Accuracy: 0.187000 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 004 / 011 | Total loss: 3.422 | Reg loss: 0.023 | Tree loss: 3.422 | Accuracy: 0.173000 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 005 / 011 | Total loss: 3.394 | Reg loss: 0.023 | Tree loss: 3.394 | Accuracy: 0.146500 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 006 / 011 | Total loss: 3.366 | Reg loss: 0.023 | Tree loss: 3.366 | Accuracy: 0.149500 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 007 / 011 | Total loss: 3.336 | Reg loss: 0.023 | Tree loss: 3.336 | Accuracy: 0.150500 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 008 / 011 | Total loss: 3.316 | Reg loss: 0.023 | Tree loss: 3.316 | Accuracy: 0.138000 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 009 / 011 | Total loss: 3.306 | Reg loss: 0.024 | Tree loss: 3.306 | Accuracy: 0.135500 | 0.955 sec/iter\n",
      "Epoch: 17 | Batch: 010 / 011 | Total loss: 3.269 | Reg loss: 0.024 | Tree loss: 3.269 | Accuracy: 0.139932 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 18 | Batch: 000 / 011 | Total loss: 3.580 | Reg loss: 0.023 | Tree loss: 3.580 | Accuracy: 0.196500 | 0.955 sec/iter\n",
      "Epoch: 18 | Batch: 001 / 011 | Total loss: 3.527 | Reg loss: 0.023 | Tree loss: 3.527 | Accuracy: 0.195500 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 002 / 011 | Total loss: 3.461 | Reg loss: 0.023 | Tree loss: 3.461 | Accuracy: 0.193000 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 003 / 011 | Total loss: 3.431 | Reg loss: 0.023 | Tree loss: 3.431 | Accuracy: 0.183000 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 004 / 011 | Total loss: 3.371 | Reg loss: 0.023 | Tree loss: 3.371 | Accuracy: 0.171000 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 005 / 011 | Total loss: 3.339 | Reg loss: 0.023 | Tree loss: 3.339 | Accuracy: 0.151000 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 006 / 011 | Total loss: 3.318 | Reg loss: 0.024 | Tree loss: 3.318 | Accuracy: 0.157500 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 007 / 011 | Total loss: 3.292 | Reg loss: 0.024 | Tree loss: 3.292 | Accuracy: 0.133500 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 008 / 011 | Total loss: 3.281 | Reg loss: 0.024 | Tree loss: 3.281 | Accuracy: 0.138000 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 009 / 011 | Total loss: 3.256 | Reg loss: 0.024 | Tree loss: 3.256 | Accuracy: 0.153000 | 0.954 sec/iter\n",
      "Epoch: 18 | Batch: 010 / 011 | Total loss: 3.241 | Reg loss: 0.024 | Tree loss: 3.241 | Accuracy: 0.139932 | 0.953 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 19 | Batch: 000 / 011 | Total loss: 3.532 | Reg loss: 0.024 | Tree loss: 3.532 | Accuracy: 0.196000 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 001 / 011 | Total loss: 3.487 | Reg loss: 0.024 | Tree loss: 3.487 | Accuracy: 0.193500 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 002 / 011 | Total loss: 3.430 | Reg loss: 0.024 | Tree loss: 3.430 | Accuracy: 0.203000 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 003 / 011 | Total loss: 3.372 | Reg loss: 0.024 | Tree loss: 3.372 | Accuracy: 0.198500 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 004 / 011 | Total loss: 3.330 | Reg loss: 0.024 | Tree loss: 3.330 | Accuracy: 0.175000 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 005 / 011 | Total loss: 3.292 | Reg loss: 0.024 | Tree loss: 3.292 | Accuracy: 0.171000 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 006 / 011 | Total loss: 3.265 | Reg loss: 0.024 | Tree loss: 3.265 | Accuracy: 0.154000 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 007 / 011 | Total loss: 3.244 | Reg loss: 0.024 | Tree loss: 3.244 | Accuracy: 0.144500 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 008 / 011 | Total loss: 3.215 | Reg loss: 0.024 | Tree loss: 3.215 | Accuracy: 0.140500 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 009 / 011 | Total loss: 3.220 | Reg loss: 0.025 | Tree loss: 3.220 | Accuracy: 0.134500 | 0.954 sec/iter\n",
      "Epoch: 19 | Batch: 010 / 011 | Total loss: 3.200 | Reg loss: 0.025 | Tree loss: 3.200 | Accuracy: 0.133106 | 0.953 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 20 | Batch: 000 / 011 | Total loss: 3.481 | Reg loss: 0.024 | Tree loss: 3.481 | Accuracy: 0.213000 | 0.955 sec/iter\n",
      "Epoch: 20 | Batch: 001 / 011 | Total loss: 3.433 | Reg loss: 0.024 | Tree loss: 3.433 | Accuracy: 0.203000 | 0.955 sec/iter\n",
      "Epoch: 20 | Batch: 002 / 011 | Total loss: 3.387 | Reg loss: 0.024 | Tree loss: 3.387 | Accuracy: 0.198500 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 003 / 011 | Total loss: 3.329 | Reg loss: 0.024 | Tree loss: 3.329 | Accuracy: 0.202000 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 004 / 011 | Total loss: 3.287 | Reg loss: 0.024 | Tree loss: 3.287 | Accuracy: 0.192500 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 005 / 011 | Total loss: 3.241 | Reg loss: 0.024 | Tree loss: 3.241 | Accuracy: 0.166000 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 006 / 011 | Total loss: 3.235 | Reg loss: 0.025 | Tree loss: 3.235 | Accuracy: 0.140000 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 007 / 011 | Total loss: 3.201 | Reg loss: 0.025 | Tree loss: 3.201 | Accuracy: 0.152500 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 008 / 011 | Total loss: 3.194 | Reg loss: 0.025 | Tree loss: 3.194 | Accuracy: 0.136500 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 009 / 011 | Total loss: 3.170 | Reg loss: 0.025 | Tree loss: 3.170 | Accuracy: 0.143500 | 0.954 sec/iter\n",
      "Epoch: 20 | Batch: 010 / 011 | Total loss: 3.124 | Reg loss: 0.025 | Tree loss: 3.124 | Accuracy: 0.122867 | 0.954 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 21 | Batch: 000 / 011 | Total loss: 3.441 | Reg loss: 0.025 | Tree loss: 3.441 | Accuracy: 0.215500 | 0.955 sec/iter\n",
      "Epoch: 21 | Batch: 001 / 011 | Total loss: 3.389 | Reg loss: 0.025 | Tree loss: 3.389 | Accuracy: 0.207000 | 0.955 sec/iter\n",
      "Epoch: 21 | Batch: 002 / 011 | Total loss: 3.341 | Reg loss: 0.025 | Tree loss: 3.341 | Accuracy: 0.211000 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 003 / 011 | Total loss: 3.295 | Reg loss: 0.025 | Tree loss: 3.295 | Accuracy: 0.172500 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 004 / 011 | Total loss: 3.250 | Reg loss: 0.025 | Tree loss: 3.250 | Accuracy: 0.198000 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 005 / 011 | Total loss: 3.222 | Reg loss: 0.025 | Tree loss: 3.222 | Accuracy: 0.164500 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 006 / 011 | Total loss: 3.190 | Reg loss: 0.025 | Tree loss: 3.190 | Accuracy: 0.158500 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 007 / 011 | Total loss: 3.162 | Reg loss: 0.025 | Tree loss: 3.162 | Accuracy: 0.145000 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 008 / 011 | Total loss: 3.147 | Reg loss: 0.025 | Tree loss: 3.147 | Accuracy: 0.144500 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 009 / 011 | Total loss: 3.127 | Reg loss: 0.026 | Tree loss: 3.127 | Accuracy: 0.136500 | 0.954 sec/iter\n",
      "Epoch: 21 | Batch: 010 / 011 | Total loss: 3.131 | Reg loss: 0.026 | Tree loss: 3.131 | Accuracy: 0.126280 | 0.954 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 22 | Batch: 000 / 011 | Total loss: 3.402 | Reg loss: 0.025 | Tree loss: 3.402 | Accuracy: 0.209000 | 0.955 sec/iter\n",
      "Epoch: 22 | Batch: 001 / 011 | Total loss: 3.359 | Reg loss: 0.025 | Tree loss: 3.359 | Accuracy: 0.195500 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 002 / 011 | Total loss: 3.300 | Reg loss: 0.025 | Tree loss: 3.300 | Accuracy: 0.196000 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 003 / 011 | Total loss: 3.266 | Reg loss: 0.025 | Tree loss: 3.266 | Accuracy: 0.211000 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 004 / 011 | Total loss: 3.207 | Reg loss: 0.025 | Tree loss: 3.207 | Accuracy: 0.185000 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 005 / 011 | Total loss: 3.192 | Reg loss: 0.025 | Tree loss: 3.192 | Accuracy: 0.159500 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 006 / 011 | Total loss: 3.144 | Reg loss: 0.026 | Tree loss: 3.144 | Accuracy: 0.157500 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 007 / 011 | Total loss: 3.144 | Reg loss: 0.026 | Tree loss: 3.144 | Accuracy: 0.144500 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 008 / 011 | Total loss: 3.113 | Reg loss: 0.026 | Tree loss: 3.113 | Accuracy: 0.159000 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 009 / 011 | Total loss: 3.091 | Reg loss: 0.026 | Tree loss: 3.091 | Accuracy: 0.143000 | 0.954 sec/iter\n",
      "Epoch: 22 | Batch: 010 / 011 | Total loss: 3.068 | Reg loss: 0.026 | Tree loss: 3.068 | Accuracy: 0.160410 | 0.954 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 23 | Batch: 000 / 011 | Total loss: 3.366 | Reg loss: 0.025 | Tree loss: 3.366 | Accuracy: 0.202500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 001 / 011 | Total loss: 3.315 | Reg loss: 0.025 | Tree loss: 3.315 | Accuracy: 0.209500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 002 / 011 | Total loss: 3.277 | Reg loss: 0.026 | Tree loss: 3.277 | Accuracy: 0.216500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 003 / 011 | Total loss: 3.228 | Reg loss: 0.026 | Tree loss: 3.228 | Accuracy: 0.204000 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 004 / 011 | Total loss: 3.193 | Reg loss: 0.026 | Tree loss: 3.193 | Accuracy: 0.191000 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 005 / 011 | Total loss: 3.152 | Reg loss: 0.026 | Tree loss: 3.152 | Accuracy: 0.173500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 006 / 011 | Total loss: 3.135 | Reg loss: 0.026 | Tree loss: 3.135 | Accuracy: 0.168500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 007 / 011 | Total loss: 3.109 | Reg loss: 0.026 | Tree loss: 3.109 | Accuracy: 0.152500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 008 / 011 | Total loss: 3.068 | Reg loss: 0.026 | Tree loss: 3.068 | Accuracy: 0.150000 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 009 / 011 | Total loss: 3.060 | Reg loss: 0.026 | Tree loss: 3.060 | Accuracy: 0.145500 | 0.954 sec/iter\n",
      "Epoch: 23 | Batch: 010 / 011 | Total loss: 3.016 | Reg loss: 0.026 | Tree loss: 3.016 | Accuracy: 0.136519 | 0.954 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 24 | Batch: 000 / 011 | Total loss: 3.337 | Reg loss: 0.026 | Tree loss: 3.337 | Accuracy: 0.190500 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 001 / 011 | Total loss: 3.298 | Reg loss: 0.026 | Tree loss: 3.298 | Accuracy: 0.210500 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 002 / 011 | Total loss: 3.242 | Reg loss: 0.026 | Tree loss: 3.242 | Accuracy: 0.218000 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 003 / 011 | Total loss: 3.203 | Reg loss: 0.026 | Tree loss: 3.203 | Accuracy: 0.214000 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 004 / 011 | Total loss: 3.156 | Reg loss: 0.026 | Tree loss: 3.156 | Accuracy: 0.195500 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 005 / 011 | Total loss: 3.112 | Reg loss: 0.026 | Tree loss: 3.112 | Accuracy: 0.191000 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 006 / 011 | Total loss: 3.076 | Reg loss: 0.026 | Tree loss: 3.076 | Accuracy: 0.187000 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 007 / 011 | Total loss: 3.068 | Reg loss: 0.026 | Tree loss: 3.068 | Accuracy: 0.162000 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 008 / 011 | Total loss: 3.047 | Reg loss: 0.026 | Tree loss: 3.047 | Accuracy: 0.161500 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 009 / 011 | Total loss: 3.051 | Reg loss: 0.027 | Tree loss: 3.051 | Accuracy: 0.142000 | 0.954 sec/iter\n",
      "Epoch: 24 | Batch: 010 / 011 | Total loss: 3.048 | Reg loss: 0.027 | Tree loss: 3.048 | Accuracy: 0.126280 | 0.954 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 25 | Batch: 000 / 011 | Total loss: 3.295 | Reg loss: 0.026 | Tree loss: 3.295 | Accuracy: 0.204500 | 0.955 sec/iter\n",
      "Epoch: 25 | Batch: 001 / 011 | Total loss: 3.254 | Reg loss: 0.026 | Tree loss: 3.254 | Accuracy: 0.194000 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 002 / 011 | Total loss: 3.228 | Reg loss: 0.026 | Tree loss: 3.228 | Accuracy: 0.215000 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 003 / 011 | Total loss: 3.180 | Reg loss: 0.026 | Tree loss: 3.180 | Accuracy: 0.204500 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 004 / 011 | Total loss: 3.117 | Reg loss: 0.026 | Tree loss: 3.117 | Accuracy: 0.232500 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 005 / 011 | Total loss: 3.094 | Reg loss: 0.026 | Tree loss: 3.094 | Accuracy: 0.214000 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 006 / 011 | Total loss: 3.072 | Reg loss: 0.027 | Tree loss: 3.072 | Accuracy: 0.177000 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 007 / 011 | Total loss: 3.035 | Reg loss: 0.027 | Tree loss: 3.035 | Accuracy: 0.175000 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 008 / 011 | Total loss: 3.028 | Reg loss: 0.027 | Tree loss: 3.028 | Accuracy: 0.165000 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 009 / 011 | Total loss: 3.033 | Reg loss: 0.027 | Tree loss: 3.033 | Accuracy: 0.166500 | 0.954 sec/iter\n",
      "Epoch: 25 | Batch: 010 / 011 | Total loss: 3.037 | Reg loss: 0.027 | Tree loss: 3.037 | Accuracy: 0.167235 | 0.954 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 26 | Batch: 000 / 011 | Total loss: 3.260 | Reg loss: 0.027 | Tree loss: 3.260 | Accuracy: 0.197500 | 0.955 sec/iter\n",
      "Epoch: 26 | Batch: 001 / 011 | Total loss: 3.227 | Reg loss: 0.027 | Tree loss: 3.227 | Accuracy: 0.214000 | 0.955 sec/iter\n",
      "Epoch: 26 | Batch: 002 / 011 | Total loss: 3.175 | Reg loss: 0.027 | Tree loss: 3.175 | Accuracy: 0.220000 | 0.954 sec/iter\n",
      "Epoch: 26 | Batch: 003 / 011 | Total loss: 3.145 | Reg loss: 0.027 | Tree loss: 3.145 | Accuracy: 0.204500 | 0.954 sec/iter\n",
      "Epoch: 26 | Batch: 004 / 011 | Total loss: 3.115 | Reg loss: 0.027 | Tree loss: 3.115 | Accuracy: 0.225500 | 0.954 sec/iter\n",
      "Epoch: 26 | Batch: 005 / 011 | Total loss: 3.087 | Reg loss: 0.027 | Tree loss: 3.087 | Accuracy: 0.184000 | 0.954 sec/iter\n",
      "Epoch: 26 | Batch: 006 / 011 | Total loss: 3.039 | Reg loss: 0.027 | Tree loss: 3.039 | Accuracy: 0.177000 | 0.953 sec/iter\n",
      "Epoch: 26 | Batch: 007 / 011 | Total loss: 3.029 | Reg loss: 0.027 | Tree loss: 3.029 | Accuracy: 0.164000 | 0.953 sec/iter\n",
      "Epoch: 26 | Batch: 008 / 011 | Total loss: 3.021 | Reg loss: 0.027 | Tree loss: 3.021 | Accuracy: 0.150000 | 0.953 sec/iter\n",
      "Epoch: 26 | Batch: 009 / 011 | Total loss: 2.998 | Reg loss: 0.027 | Tree loss: 2.998 | Accuracy: 0.169000 | 0.953 sec/iter\n",
      "Epoch: 26 | Batch: 010 / 011 | Total loss: 2.935 | Reg loss: 0.027 | Tree loss: 2.935 | Accuracy: 0.180887 | 0.952 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 27 | Batch: 000 / 011 | Total loss: 3.250 | Reg loss: 0.027 | Tree loss: 3.250 | Accuracy: 0.208500 | 0.952 sec/iter\n",
      "Epoch: 27 | Batch: 001 / 011 | Total loss: 3.201 | Reg loss: 0.027 | Tree loss: 3.201 | Accuracy: 0.203000 | 0.952 sec/iter\n",
      "Epoch: 27 | Batch: 002 / 011 | Total loss: 3.159 | Reg loss: 0.027 | Tree loss: 3.159 | Accuracy: 0.215000 | 0.951 sec/iter\n",
      "Epoch: 27 | Batch: 003 / 011 | Total loss: 3.123 | Reg loss: 0.027 | Tree loss: 3.123 | Accuracy: 0.220000 | 0.951 sec/iter\n",
      "Epoch: 27 | Batch: 004 / 011 | Total loss: 3.079 | Reg loss: 0.027 | Tree loss: 3.079 | Accuracy: 0.227500 | 0.951 sec/iter\n",
      "Epoch: 27 | Batch: 005 / 011 | Total loss: 3.048 | Reg loss: 0.027 | Tree loss: 3.048 | Accuracy: 0.222000 | 0.95 sec/iter\n",
      "Epoch: 27 | Batch: 006 / 011 | Total loss: 3.025 | Reg loss: 0.027 | Tree loss: 3.025 | Accuracy: 0.188000 | 0.95 sec/iter\n",
      "Epoch: 27 | Batch: 007 / 011 | Total loss: 3.019 | Reg loss: 0.027 | Tree loss: 3.019 | Accuracy: 0.176000 | 0.95 sec/iter\n",
      "Epoch: 27 | Batch: 008 / 011 | Total loss: 3.003 | Reg loss: 0.027 | Tree loss: 3.003 | Accuracy: 0.168500 | 0.95 sec/iter\n",
      "Epoch: 27 | Batch: 009 / 011 | Total loss: 2.976 | Reg loss: 0.027 | Tree loss: 2.976 | Accuracy: 0.171000 | 0.949 sec/iter\n",
      "Epoch: 27 | Batch: 010 / 011 | Total loss: 2.961 | Reg loss: 0.028 | Tree loss: 2.961 | Accuracy: 0.180887 | 0.949 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 28 | Batch: 000 / 011 | Total loss: 3.232 | Reg loss: 0.027 | Tree loss: 3.232 | Accuracy: 0.205000 | 0.949 sec/iter\n",
      "Epoch: 28 | Batch: 001 / 011 | Total loss: 3.189 | Reg loss: 0.027 | Tree loss: 3.189 | Accuracy: 0.206000 | 0.949 sec/iter\n",
      "Epoch: 28 | Batch: 002 / 011 | Total loss: 3.120 | Reg loss: 0.027 | Tree loss: 3.120 | Accuracy: 0.236500 | 0.948 sec/iter\n",
      "Epoch: 28 | Batch: 003 / 011 | Total loss: 3.083 | Reg loss: 0.027 | Tree loss: 3.083 | Accuracy: 0.208000 | 0.948 sec/iter\n",
      "Epoch: 28 | Batch: 004 / 011 | Total loss: 3.057 | Reg loss: 0.027 | Tree loss: 3.057 | Accuracy: 0.226500 | 0.948 sec/iter\n",
      "Epoch: 28 | Batch: 005 / 011 | Total loss: 3.026 | Reg loss: 0.027 | Tree loss: 3.026 | Accuracy: 0.220500 | 0.948 sec/iter\n",
      "Epoch: 28 | Batch: 006 / 011 | Total loss: 2.998 | Reg loss: 0.027 | Tree loss: 2.998 | Accuracy: 0.212500 | 0.947 sec/iter\n",
      "Epoch: 28 | Batch: 007 / 011 | Total loss: 3.013 | Reg loss: 0.028 | Tree loss: 3.013 | Accuracy: 0.169500 | 0.947 sec/iter\n",
      "Epoch: 28 | Batch: 008 / 011 | Total loss: 2.982 | Reg loss: 0.028 | Tree loss: 2.982 | Accuracy: 0.156000 | 0.947 sec/iter\n",
      "Epoch: 28 | Batch: 009 / 011 | Total loss: 2.961 | Reg loss: 0.028 | Tree loss: 2.961 | Accuracy: 0.163500 | 0.947 sec/iter\n",
      "Epoch: 28 | Batch: 010 / 011 | Total loss: 2.945 | Reg loss: 0.028 | Tree loss: 2.945 | Accuracy: 0.180887 | 0.946 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 29 | Batch: 000 / 011 | Total loss: 3.214 | Reg loss: 0.027 | Tree loss: 3.214 | Accuracy: 0.205000 | 0.946 sec/iter\n",
      "Epoch: 29 | Batch: 001 / 011 | Total loss: 3.156 | Reg loss: 0.027 | Tree loss: 3.156 | Accuracy: 0.215000 | 0.946 sec/iter\n",
      "Epoch: 29 | Batch: 002 / 011 | Total loss: 3.110 | Reg loss: 0.027 | Tree loss: 3.110 | Accuracy: 0.226500 | 0.946 sec/iter\n",
      "Epoch: 29 | Batch: 003 / 011 | Total loss: 3.096 | Reg loss: 0.027 | Tree loss: 3.096 | Accuracy: 0.203500 | 0.945 sec/iter\n",
      "Epoch: 29 | Batch: 004 / 011 | Total loss: 3.052 | Reg loss: 0.028 | Tree loss: 3.052 | Accuracy: 0.221500 | 0.945 sec/iter\n",
      "Epoch: 29 | Batch: 005 / 011 | Total loss: 3.006 | Reg loss: 0.028 | Tree loss: 3.006 | Accuracy: 0.216000 | 0.945 sec/iter\n",
      "Epoch: 29 | Batch: 006 / 011 | Total loss: 2.999 | Reg loss: 0.028 | Tree loss: 2.999 | Accuracy: 0.198000 | 0.945 sec/iter\n",
      "Epoch: 29 | Batch: 007 / 011 | Total loss: 2.965 | Reg loss: 0.028 | Tree loss: 2.965 | Accuracy: 0.200500 | 0.944 sec/iter\n",
      "Epoch: 29 | Batch: 008 / 011 | Total loss: 2.952 | Reg loss: 0.028 | Tree loss: 2.952 | Accuracy: 0.193500 | 0.944 sec/iter\n",
      "Epoch: 29 | Batch: 009 / 011 | Total loss: 2.943 | Reg loss: 0.028 | Tree loss: 2.943 | Accuracy: 0.169500 | 0.944 sec/iter\n",
      "Epoch: 29 | Batch: 010 / 011 | Total loss: 2.890 | Reg loss: 0.028 | Tree loss: 2.890 | Accuracy: 0.174061 | 0.943 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Batch: 000 / 011 | Total loss: 3.172 | Reg loss: 0.028 | Tree loss: 3.172 | Accuracy: 0.207000 | 0.944 sec/iter\n",
      "Epoch: 30 | Batch: 001 / 011 | Total loss: 3.147 | Reg loss: 0.028 | Tree loss: 3.147 | Accuracy: 0.212000 | 0.943 sec/iter\n",
      "Epoch: 30 | Batch: 002 / 011 | Total loss: 3.090 | Reg loss: 0.028 | Tree loss: 3.090 | Accuracy: 0.220000 | 0.943 sec/iter\n",
      "Epoch: 30 | Batch: 003 / 011 | Total loss: 3.070 | Reg loss: 0.028 | Tree loss: 3.070 | Accuracy: 0.208500 | 0.943 sec/iter\n",
      "Epoch: 30 | Batch: 004 / 011 | Total loss: 3.021 | Reg loss: 0.028 | Tree loss: 3.021 | Accuracy: 0.222500 | 0.943 sec/iter\n",
      "Epoch: 30 | Batch: 005 / 011 | Total loss: 3.006 | Reg loss: 0.028 | Tree loss: 3.006 | Accuracy: 0.218500 | 0.942 sec/iter\n",
      "Epoch: 30 | Batch: 006 / 011 | Total loss: 2.964 | Reg loss: 0.028 | Tree loss: 2.964 | Accuracy: 0.217500 | 0.942 sec/iter\n",
      "Epoch: 30 | Batch: 007 / 011 | Total loss: 2.959 | Reg loss: 0.028 | Tree loss: 2.959 | Accuracy: 0.178500 | 0.942 sec/iter\n",
      "Epoch: 30 | Batch: 008 / 011 | Total loss: 2.941 | Reg loss: 0.028 | Tree loss: 2.941 | Accuracy: 0.192500 | 0.942 sec/iter\n",
      "Epoch: 30 | Batch: 009 / 011 | Total loss: 2.935 | Reg loss: 0.028 | Tree loss: 2.935 | Accuracy: 0.170500 | 0.942 sec/iter\n",
      "Epoch: 30 | Batch: 010 / 011 | Total loss: 2.937 | Reg loss: 0.028 | Tree loss: 2.937 | Accuracy: 0.174061 | 0.941 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 31 | Batch: 000 / 011 | Total loss: 3.161 | Reg loss: 0.028 | Tree loss: 3.161 | Accuracy: 0.204000 | 0.941 sec/iter\n",
      "Epoch: 31 | Batch: 001 / 011 | Total loss: 3.124 | Reg loss: 0.028 | Tree loss: 3.124 | Accuracy: 0.206500 | 0.941 sec/iter\n",
      "Epoch: 31 | Batch: 002 / 011 | Total loss: 3.086 | Reg loss: 0.028 | Tree loss: 3.086 | Accuracy: 0.230500 | 0.941 sec/iter\n",
      "Epoch: 31 | Batch: 003 / 011 | Total loss: 3.061 | Reg loss: 0.028 | Tree loss: 3.061 | Accuracy: 0.206000 | 0.941 sec/iter\n",
      "Epoch: 31 | Batch: 004 / 011 | Total loss: 3.011 | Reg loss: 0.028 | Tree loss: 3.011 | Accuracy: 0.231500 | 0.94 sec/iter\n",
      "Epoch: 31 | Batch: 005 / 011 | Total loss: 2.969 | Reg loss: 0.028 | Tree loss: 2.969 | Accuracy: 0.220500 | 0.94 sec/iter\n",
      "Epoch: 31 | Batch: 006 / 011 | Total loss: 2.972 | Reg loss: 0.028 | Tree loss: 2.972 | Accuracy: 0.209500 | 0.94 sec/iter\n",
      "Epoch: 31 | Batch: 007 / 011 | Total loss: 2.942 | Reg loss: 0.028 | Tree loss: 2.942 | Accuracy: 0.207000 | 0.94 sec/iter\n",
      "Epoch: 31 | Batch: 008 / 011 | Total loss: 2.931 | Reg loss: 0.028 | Tree loss: 2.931 | Accuracy: 0.195500 | 0.94 sec/iter\n",
      "Epoch: 31 | Batch: 009 / 011 | Total loss: 2.904 | Reg loss: 0.028 | Tree loss: 2.904 | Accuracy: 0.192500 | 0.94 sec/iter\n",
      "Epoch: 31 | Batch: 010 / 011 | Total loss: 2.921 | Reg loss: 0.028 | Tree loss: 2.921 | Accuracy: 0.187713 | 0.939 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 32 | Batch: 000 / 011 | Total loss: 3.141 | Reg loss: 0.028 | Tree loss: 3.141 | Accuracy: 0.196500 | 0.939 sec/iter\n",
      "Epoch: 32 | Batch: 001 / 011 | Total loss: 3.107 | Reg loss: 0.028 | Tree loss: 3.107 | Accuracy: 0.206500 | 0.939 sec/iter\n",
      "Epoch: 32 | Batch: 002 / 011 | Total loss: 3.055 | Reg loss: 0.028 | Tree loss: 3.055 | Accuracy: 0.223000 | 0.939 sec/iter\n",
      "Epoch: 32 | Batch: 003 / 011 | Total loss: 3.029 | Reg loss: 0.028 | Tree loss: 3.029 | Accuracy: 0.225000 | 0.938 sec/iter\n",
      "Epoch: 32 | Batch: 004 / 011 | Total loss: 2.985 | Reg loss: 0.028 | Tree loss: 2.985 | Accuracy: 0.231000 | 0.938 sec/iter\n",
      "Epoch: 32 | Batch: 005 / 011 | Total loss: 2.976 | Reg loss: 0.028 | Tree loss: 2.976 | Accuracy: 0.223500 | 0.938 sec/iter\n",
      "Epoch: 32 | Batch: 006 / 011 | Total loss: 2.940 | Reg loss: 0.028 | Tree loss: 2.940 | Accuracy: 0.213000 | 0.938 sec/iter\n",
      "Epoch: 32 | Batch: 007 / 011 | Total loss: 2.913 | Reg loss: 0.028 | Tree loss: 2.913 | Accuracy: 0.203500 | 0.938 sec/iter\n",
      "Epoch: 32 | Batch: 008 / 011 | Total loss: 2.921 | Reg loss: 0.028 | Tree loss: 2.921 | Accuracy: 0.187000 | 0.937 sec/iter\n",
      "Epoch: 32 | Batch: 009 / 011 | Total loss: 2.898 | Reg loss: 0.028 | Tree loss: 2.898 | Accuracy: 0.187000 | 0.937 sec/iter\n",
      "Epoch: 32 | Batch: 010 / 011 | Total loss: 2.926 | Reg loss: 0.029 | Tree loss: 2.926 | Accuracy: 0.184300 | 0.937 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 33 | Batch: 000 / 011 | Total loss: 3.115 | Reg loss: 0.028 | Tree loss: 3.115 | Accuracy: 0.203000 | 0.937 sec/iter\n",
      "Epoch: 33 | Batch: 001 / 011 | Total loss: 3.100 | Reg loss: 0.028 | Tree loss: 3.100 | Accuracy: 0.198000 | 0.937 sec/iter\n",
      "Epoch: 33 | Batch: 002 / 011 | Total loss: 3.071 | Reg loss: 0.028 | Tree loss: 3.071 | Accuracy: 0.204000 | 0.936 sec/iter\n",
      "Epoch: 33 | Batch: 003 / 011 | Total loss: 3.012 | Reg loss: 0.028 | Tree loss: 3.012 | Accuracy: 0.210000 | 0.936 sec/iter\n",
      "Epoch: 33 | Batch: 004 / 011 | Total loss: 2.976 | Reg loss: 0.028 | Tree loss: 2.976 | Accuracy: 0.228500 | 0.936 sec/iter\n",
      "Epoch: 33 | Batch: 005 / 011 | Total loss: 2.959 | Reg loss: 0.028 | Tree loss: 2.959 | Accuracy: 0.216000 | 0.936 sec/iter\n",
      "Epoch: 33 | Batch: 006 / 011 | Total loss: 2.935 | Reg loss: 0.028 | Tree loss: 2.935 | Accuracy: 0.217000 | 0.936 sec/iter\n",
      "Epoch: 33 | Batch: 007 / 011 | Total loss: 2.918 | Reg loss: 0.028 | Tree loss: 2.918 | Accuracy: 0.208500 | 0.936 sec/iter\n",
      "Epoch: 33 | Batch: 008 / 011 | Total loss: 2.891 | Reg loss: 0.029 | Tree loss: 2.891 | Accuracy: 0.201500 | 0.935 sec/iter\n",
      "Epoch: 33 | Batch: 009 / 011 | Total loss: 2.880 | Reg loss: 0.029 | Tree loss: 2.880 | Accuracy: 0.203500 | 0.935 sec/iter\n",
      "Epoch: 33 | Batch: 010 / 011 | Total loss: 2.843 | Reg loss: 0.029 | Tree loss: 2.843 | Accuracy: 0.194539 | 0.935 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 34 | Batch: 000 / 011 | Total loss: 3.115 | Reg loss: 0.028 | Tree loss: 3.115 | Accuracy: 0.192500 | 0.935 sec/iter\n",
      "Epoch: 34 | Batch: 001 / 011 | Total loss: 3.070 | Reg loss: 0.028 | Tree loss: 3.070 | Accuracy: 0.209000 | 0.935 sec/iter\n",
      "Epoch: 34 | Batch: 002 / 011 | Total loss: 3.029 | Reg loss: 0.028 | Tree loss: 3.029 | Accuracy: 0.205000 | 0.935 sec/iter\n",
      "Epoch: 34 | Batch: 003 / 011 | Total loss: 2.996 | Reg loss: 0.028 | Tree loss: 2.996 | Accuracy: 0.220000 | 0.934 sec/iter\n",
      "Epoch: 34 | Batch: 004 / 011 | Total loss: 2.948 | Reg loss: 0.028 | Tree loss: 2.948 | Accuracy: 0.230500 | 0.934 sec/iter\n",
      "Epoch: 34 | Batch: 005 / 011 | Total loss: 2.953 | Reg loss: 0.029 | Tree loss: 2.953 | Accuracy: 0.219000 | 0.934 sec/iter\n",
      "Epoch: 34 | Batch: 006 / 011 | Total loss: 2.911 | Reg loss: 0.029 | Tree loss: 2.911 | Accuracy: 0.232000 | 0.934 sec/iter\n",
      "Epoch: 34 | Batch: 007 / 011 | Total loss: 2.890 | Reg loss: 0.029 | Tree loss: 2.890 | Accuracy: 0.213500 | 0.934 sec/iter\n",
      "Epoch: 34 | Batch: 008 / 011 | Total loss: 2.879 | Reg loss: 0.029 | Tree loss: 2.879 | Accuracy: 0.218500 | 0.933 sec/iter\n",
      "Epoch: 34 | Batch: 009 / 011 | Total loss: 2.884 | Reg loss: 0.029 | Tree loss: 2.884 | Accuracy: 0.171500 | 0.933 sec/iter\n",
      "Epoch: 34 | Batch: 010 / 011 | Total loss: 2.863 | Reg loss: 0.029 | Tree loss: 2.863 | Accuracy: 0.170648 | 0.933 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Batch: 000 / 011 | Total loss: 3.104 | Reg loss: 0.029 | Tree loss: 3.104 | Accuracy: 0.214000 | 0.933 sec/iter\n",
      "Epoch: 35 | Batch: 001 / 011 | Total loss: 3.077 | Reg loss: 0.029 | Tree loss: 3.077 | Accuracy: 0.187000 | 0.933 sec/iter\n",
      "Epoch: 35 | Batch: 002 / 011 | Total loss: 3.018 | Reg loss: 0.029 | Tree loss: 3.018 | Accuracy: 0.220500 | 0.933 sec/iter\n",
      "Epoch: 35 | Batch: 003 / 011 | Total loss: 2.981 | Reg loss: 0.029 | Tree loss: 2.981 | Accuracy: 0.207000 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 004 / 011 | Total loss: 2.940 | Reg loss: 0.029 | Tree loss: 2.940 | Accuracy: 0.237500 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 005 / 011 | Total loss: 2.919 | Reg loss: 0.029 | Tree loss: 2.919 | Accuracy: 0.206000 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 006 / 011 | Total loss: 2.908 | Reg loss: 0.029 | Tree loss: 2.908 | Accuracy: 0.227000 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 007 / 011 | Total loss: 2.885 | Reg loss: 0.029 | Tree loss: 2.885 | Accuracy: 0.239500 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 008 / 011 | Total loss: 2.868 | Reg loss: 0.029 | Tree loss: 2.868 | Accuracy: 0.196500 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 009 / 011 | Total loss: 2.868 | Reg loss: 0.029 | Tree loss: 2.868 | Accuracy: 0.202500 | 0.932 sec/iter\n",
      "Epoch: 35 | Batch: 010 / 011 | Total loss: 2.832 | Reg loss: 0.029 | Tree loss: 2.832 | Accuracy: 0.204778 | 0.931 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 36 | Batch: 000 / 011 | Total loss: 3.086 | Reg loss: 0.029 | Tree loss: 3.086 | Accuracy: 0.199500 | 0.931 sec/iter\n",
      "Epoch: 36 | Batch: 001 / 011 | Total loss: 3.061 | Reg loss: 0.029 | Tree loss: 3.061 | Accuracy: 0.198500 | 0.931 sec/iter\n",
      "Epoch: 36 | Batch: 002 / 011 | Total loss: 3.012 | Reg loss: 0.029 | Tree loss: 3.012 | Accuracy: 0.212000 | 0.931 sec/iter\n",
      "Epoch: 36 | Batch: 003 / 011 | Total loss: 2.961 | Reg loss: 0.029 | Tree loss: 2.961 | Accuracy: 0.216500 | 0.931 sec/iter\n",
      "Epoch: 36 | Batch: 004 / 011 | Total loss: 2.935 | Reg loss: 0.029 | Tree loss: 2.935 | Accuracy: 0.221000 | 0.931 sec/iter\n",
      "Epoch: 36 | Batch: 005 / 011 | Total loss: 2.896 | Reg loss: 0.029 | Tree loss: 2.896 | Accuracy: 0.230500 | 0.93 sec/iter\n",
      "Epoch: 36 | Batch: 006 / 011 | Total loss: 2.876 | Reg loss: 0.029 | Tree loss: 2.876 | Accuracy: 0.226500 | 0.93 sec/iter\n",
      "Epoch: 36 | Batch: 007 / 011 | Total loss: 2.851 | Reg loss: 0.029 | Tree loss: 2.851 | Accuracy: 0.234500 | 0.93 sec/iter\n",
      "Epoch: 36 | Batch: 008 / 011 | Total loss: 2.845 | Reg loss: 0.029 | Tree loss: 2.845 | Accuracy: 0.210000 | 0.93 sec/iter\n",
      "Epoch: 36 | Batch: 009 / 011 | Total loss: 2.865 | Reg loss: 0.029 | Tree loss: 2.865 | Accuracy: 0.192000 | 0.93 sec/iter\n",
      "Epoch: 36 | Batch: 010 / 011 | Total loss: 2.866 | Reg loss: 0.029 | Tree loss: 2.866 | Accuracy: 0.163823 | 0.929 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 37 | Batch: 000 / 011 | Total loss: 3.070 | Reg loss: 0.029 | Tree loss: 3.070 | Accuracy: 0.189000 | 0.93 sec/iter\n",
      "Epoch: 37 | Batch: 001 / 011 | Total loss: 3.035 | Reg loss: 0.029 | Tree loss: 3.035 | Accuracy: 0.199000 | 0.929 sec/iter\n",
      "Epoch: 37 | Batch: 002 / 011 | Total loss: 2.998 | Reg loss: 0.029 | Tree loss: 2.998 | Accuracy: 0.209500 | 0.929 sec/iter\n",
      "Epoch: 37 | Batch: 003 / 011 | Total loss: 2.966 | Reg loss: 0.029 | Tree loss: 2.966 | Accuracy: 0.226000 | 0.929 sec/iter\n",
      "Epoch: 37 | Batch: 004 / 011 | Total loss: 2.939 | Reg loss: 0.029 | Tree loss: 2.939 | Accuracy: 0.232000 | 0.929 sec/iter\n",
      "Epoch: 37 | Batch: 005 / 011 | Total loss: 2.903 | Reg loss: 0.029 | Tree loss: 2.903 | Accuracy: 0.235000 | 0.929 sec/iter\n",
      "Epoch: 37 | Batch: 006 / 011 | Total loss: 2.886 | Reg loss: 0.029 | Tree loss: 2.886 | Accuracy: 0.218000 | 0.928 sec/iter\n",
      "Epoch: 37 | Batch: 007 / 011 | Total loss: 2.854 | Reg loss: 0.029 | Tree loss: 2.854 | Accuracy: 0.215500 | 0.928 sec/iter\n",
      "Epoch: 37 | Batch: 008 / 011 | Total loss: 2.830 | Reg loss: 0.029 | Tree loss: 2.830 | Accuracy: 0.214000 | 0.928 sec/iter\n",
      "Epoch: 37 | Batch: 009 / 011 | Total loss: 2.830 | Reg loss: 0.029 | Tree loss: 2.830 | Accuracy: 0.207500 | 0.928 sec/iter\n",
      "Epoch: 37 | Batch: 010 / 011 | Total loss: 2.891 | Reg loss: 0.029 | Tree loss: 2.891 | Accuracy: 0.156997 | 0.927 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 38 | Batch: 000 / 011 | Total loss: 3.061 | Reg loss: 0.029 | Tree loss: 3.061 | Accuracy: 0.191500 | 0.928 sec/iter\n",
      "Epoch: 38 | Batch: 001 / 011 | Total loss: 3.027 | Reg loss: 0.029 | Tree loss: 3.027 | Accuracy: 0.194000 | 0.927 sec/iter\n",
      "Epoch: 38 | Batch: 002 / 011 | Total loss: 2.989 | Reg loss: 0.029 | Tree loss: 2.989 | Accuracy: 0.208500 | 0.927 sec/iter\n",
      "Epoch: 38 | Batch: 003 / 011 | Total loss: 2.930 | Reg loss: 0.029 | Tree loss: 2.930 | Accuracy: 0.233500 | 0.927 sec/iter\n",
      "Epoch: 38 | Batch: 004 / 011 | Total loss: 2.907 | Reg loss: 0.029 | Tree loss: 2.907 | Accuracy: 0.255500 | 0.927 sec/iter\n",
      "Epoch: 38 | Batch: 005 / 011 | Total loss: 2.904 | Reg loss: 0.029 | Tree loss: 2.904 | Accuracy: 0.225000 | 0.927 sec/iter\n",
      "Epoch: 38 | Batch: 006 / 011 | Total loss: 2.853 | Reg loss: 0.029 | Tree loss: 2.853 | Accuracy: 0.244000 | 0.926 sec/iter\n",
      "Epoch: 38 | Batch: 007 / 011 | Total loss: 2.834 | Reg loss: 0.029 | Tree loss: 2.834 | Accuracy: 0.217500 | 0.926 sec/iter\n",
      "Epoch: 38 | Batch: 008 / 011 | Total loss: 2.831 | Reg loss: 0.029 | Tree loss: 2.831 | Accuracy: 0.193500 | 0.926 sec/iter\n",
      "Epoch: 38 | Batch: 009 / 011 | Total loss: 2.821 | Reg loss: 0.029 | Tree loss: 2.821 | Accuracy: 0.192500 | 0.926 sec/iter\n",
      "Epoch: 38 | Batch: 010 / 011 | Total loss: 2.849 | Reg loss: 0.029 | Tree loss: 2.849 | Accuracy: 0.194539 | 0.925 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 39 | Batch: 000 / 011 | Total loss: 3.060 | Reg loss: 0.029 | Tree loss: 3.060 | Accuracy: 0.197000 | 0.925 sec/iter\n",
      "Epoch: 39 | Batch: 001 / 011 | Total loss: 3.021 | Reg loss: 0.029 | Tree loss: 3.021 | Accuracy: 0.194500 | 0.925 sec/iter\n",
      "Epoch: 39 | Batch: 002 / 011 | Total loss: 2.969 | Reg loss: 0.029 | Tree loss: 2.969 | Accuracy: 0.222500 | 0.925 sec/iter\n",
      "Epoch: 39 | Batch: 003 / 011 | Total loss: 2.937 | Reg loss: 0.029 | Tree loss: 2.937 | Accuracy: 0.215500 | 0.925 sec/iter\n",
      "Epoch: 39 | Batch: 004 / 011 | Total loss: 2.907 | Reg loss: 0.029 | Tree loss: 2.907 | Accuracy: 0.237000 | 0.925 sec/iter\n",
      "Epoch: 39 | Batch: 005 / 011 | Total loss: 2.884 | Reg loss: 0.029 | Tree loss: 2.884 | Accuracy: 0.227000 | 0.925 sec/iter\n",
      "Epoch: 39 | Batch: 006 / 011 | Total loss: 2.844 | Reg loss: 0.029 | Tree loss: 2.844 | Accuracy: 0.242000 | 0.924 sec/iter\n",
      "Epoch: 39 | Batch: 007 / 011 | Total loss: 2.827 | Reg loss: 0.029 | Tree loss: 2.827 | Accuracy: 0.221500 | 0.924 sec/iter\n",
      "Epoch: 39 | Batch: 008 / 011 | Total loss: 2.826 | Reg loss: 0.029 | Tree loss: 2.826 | Accuracy: 0.213500 | 0.924 sec/iter\n",
      "Epoch: 39 | Batch: 009 / 011 | Total loss: 2.808 | Reg loss: 0.030 | Tree loss: 2.808 | Accuracy: 0.189000 | 0.924 sec/iter\n",
      "Epoch: 39 | Batch: 010 / 011 | Total loss: 2.812 | Reg loss: 0.030 | Tree loss: 2.812 | Accuracy: 0.180887 | 0.923 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Batch: 000 / 011 | Total loss: 3.041 | Reg loss: 0.029 | Tree loss: 3.041 | Accuracy: 0.190500 | 0.924 sec/iter\n",
      "Epoch: 40 | Batch: 001 / 011 | Total loss: 3.002 | Reg loss: 0.029 | Tree loss: 3.002 | Accuracy: 0.202000 | 0.923 sec/iter\n",
      "Epoch: 40 | Batch: 002 / 011 | Total loss: 2.960 | Reg loss: 0.029 | Tree loss: 2.960 | Accuracy: 0.217000 | 0.923 sec/iter\n",
      "Epoch: 40 | Batch: 003 / 011 | Total loss: 2.925 | Reg loss: 0.029 | Tree loss: 2.925 | Accuracy: 0.219000 | 0.923 sec/iter\n",
      "Epoch: 40 | Batch: 004 / 011 | Total loss: 2.876 | Reg loss: 0.029 | Tree loss: 2.876 | Accuracy: 0.249500 | 0.923 sec/iter\n",
      "Epoch: 40 | Batch: 005 / 011 | Total loss: 2.847 | Reg loss: 0.029 | Tree loss: 2.847 | Accuracy: 0.252500 | 0.923 sec/iter\n",
      "Epoch: 40 | Batch: 006 / 011 | Total loss: 2.835 | Reg loss: 0.029 | Tree loss: 2.835 | Accuracy: 0.244500 | 0.923 sec/iter\n",
      "Epoch: 40 | Batch: 007 / 011 | Total loss: 2.804 | Reg loss: 0.030 | Tree loss: 2.804 | Accuracy: 0.214000 | 0.922 sec/iter\n",
      "Epoch: 40 | Batch: 008 / 011 | Total loss: 2.823 | Reg loss: 0.030 | Tree loss: 2.823 | Accuracy: 0.192500 | 0.922 sec/iter\n",
      "Epoch: 40 | Batch: 009 / 011 | Total loss: 2.815 | Reg loss: 0.030 | Tree loss: 2.815 | Accuracy: 0.190500 | 0.922 sec/iter\n",
      "Epoch: 40 | Batch: 010 / 011 | Total loss: 2.769 | Reg loss: 0.030 | Tree loss: 2.769 | Accuracy: 0.163823 | 0.922 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 41 | Batch: 000 / 011 | Total loss: 3.023 | Reg loss: 0.029 | Tree loss: 3.023 | Accuracy: 0.186000 | 0.922 sec/iter\n",
      "Epoch: 41 | Batch: 001 / 011 | Total loss: 3.007 | Reg loss: 0.029 | Tree loss: 3.007 | Accuracy: 0.208500 | 0.922 sec/iter\n",
      "Epoch: 41 | Batch: 002 / 011 | Total loss: 2.940 | Reg loss: 0.029 | Tree loss: 2.940 | Accuracy: 0.218000 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 003 / 011 | Total loss: 2.931 | Reg loss: 0.029 | Tree loss: 2.931 | Accuracy: 0.223000 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 004 / 011 | Total loss: 2.869 | Reg loss: 0.030 | Tree loss: 2.869 | Accuracy: 0.257500 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 005 / 011 | Total loss: 2.829 | Reg loss: 0.030 | Tree loss: 2.829 | Accuracy: 0.263500 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 006 / 011 | Total loss: 2.818 | Reg loss: 0.030 | Tree loss: 2.818 | Accuracy: 0.236500 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 007 / 011 | Total loss: 2.829 | Reg loss: 0.030 | Tree loss: 2.829 | Accuracy: 0.232500 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 008 / 011 | Total loss: 2.806 | Reg loss: 0.030 | Tree loss: 2.806 | Accuracy: 0.216000 | 0.921 sec/iter\n",
      "Epoch: 41 | Batch: 009 / 011 | Total loss: 2.799 | Reg loss: 0.030 | Tree loss: 2.799 | Accuracy: 0.208500 | 0.92 sec/iter\n",
      "Epoch: 41 | Batch: 010 / 011 | Total loss: 2.830 | Reg loss: 0.030 | Tree loss: 2.830 | Accuracy: 0.146758 | 0.92 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 42 | Batch: 000 / 011 | Total loss: 3.008 | Reg loss: 0.030 | Tree loss: 3.008 | Accuracy: 0.205000 | 0.92 sec/iter\n",
      "Epoch: 42 | Batch: 001 / 011 | Total loss: 3.003 | Reg loss: 0.030 | Tree loss: 3.003 | Accuracy: 0.204500 | 0.92 sec/iter\n",
      "Epoch: 42 | Batch: 002 / 011 | Total loss: 2.948 | Reg loss: 0.030 | Tree loss: 2.948 | Accuracy: 0.216000 | 0.92 sec/iter\n",
      "Epoch: 42 | Batch: 003 / 011 | Total loss: 2.909 | Reg loss: 0.030 | Tree loss: 2.909 | Accuracy: 0.219000 | 0.92 sec/iter\n",
      "Epoch: 42 | Batch: 004 / 011 | Total loss: 2.887 | Reg loss: 0.030 | Tree loss: 2.887 | Accuracy: 0.251000 | 0.919 sec/iter\n",
      "Epoch: 42 | Batch: 005 / 011 | Total loss: 2.825 | Reg loss: 0.030 | Tree loss: 2.825 | Accuracy: 0.253500 | 0.919 sec/iter\n",
      "Epoch: 42 | Batch: 006 / 011 | Total loss: 2.800 | Reg loss: 0.030 | Tree loss: 2.800 | Accuracy: 0.249000 | 0.919 sec/iter\n",
      "Epoch: 42 | Batch: 007 / 011 | Total loss: 2.772 | Reg loss: 0.030 | Tree loss: 2.772 | Accuracy: 0.241500 | 0.919 sec/iter\n",
      "Epoch: 42 | Batch: 008 / 011 | Total loss: 2.786 | Reg loss: 0.030 | Tree loss: 2.786 | Accuracy: 0.233000 | 0.919 sec/iter\n",
      "Epoch: 42 | Batch: 009 / 011 | Total loss: 2.803 | Reg loss: 0.030 | Tree loss: 2.803 | Accuracy: 0.201500 | 0.919 sec/iter\n",
      "Epoch: 42 | Batch: 010 / 011 | Total loss: 2.766 | Reg loss: 0.030 | Tree loss: 2.766 | Accuracy: 0.218430 | 0.918 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 43 | Batch: 000 / 011 | Total loss: 3.017 | Reg loss: 0.030 | Tree loss: 3.017 | Accuracy: 0.196500 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 001 / 011 | Total loss: 2.984 | Reg loss: 0.030 | Tree loss: 2.984 | Accuracy: 0.205000 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 002 / 011 | Total loss: 2.921 | Reg loss: 0.030 | Tree loss: 2.921 | Accuracy: 0.217000 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 003 / 011 | Total loss: 2.913 | Reg loss: 0.030 | Tree loss: 2.913 | Accuracy: 0.208500 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 004 / 011 | Total loss: 2.867 | Reg loss: 0.030 | Tree loss: 2.867 | Accuracy: 0.252000 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 005 / 011 | Total loss: 2.827 | Reg loss: 0.030 | Tree loss: 2.827 | Accuracy: 0.280000 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 006 / 011 | Total loss: 2.791 | Reg loss: 0.030 | Tree loss: 2.791 | Accuracy: 0.251000 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 007 / 011 | Total loss: 2.790 | Reg loss: 0.030 | Tree loss: 2.790 | Accuracy: 0.236500 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 008 / 011 | Total loss: 2.796 | Reg loss: 0.030 | Tree loss: 2.796 | Accuracy: 0.214500 | 0.918 sec/iter\n",
      "Epoch: 43 | Batch: 009 / 011 | Total loss: 2.764 | Reg loss: 0.030 | Tree loss: 2.764 | Accuracy: 0.217500 | 0.917 sec/iter\n",
      "Epoch: 43 | Batch: 010 / 011 | Total loss: 2.726 | Reg loss: 0.030 | Tree loss: 2.726 | Accuracy: 0.235495 | 0.917 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 44 | Batch: 000 / 011 | Total loss: 3.017 | Reg loss: 0.030 | Tree loss: 3.017 | Accuracy: 0.196000 | 0.917 sec/iter\n",
      "Epoch: 44 | Batch: 001 / 011 | Total loss: 2.954 | Reg loss: 0.030 | Tree loss: 2.954 | Accuracy: 0.214000 | 0.917 sec/iter\n",
      "Epoch: 44 | Batch: 002 / 011 | Total loss: 2.931 | Reg loss: 0.030 | Tree loss: 2.931 | Accuracy: 0.210500 | 0.917 sec/iter\n",
      "Epoch: 44 | Batch: 003 / 011 | Total loss: 2.884 | Reg loss: 0.030 | Tree loss: 2.884 | Accuracy: 0.213500 | 0.917 sec/iter\n",
      "Epoch: 44 | Batch: 004 / 011 | Total loss: 2.855 | Reg loss: 0.030 | Tree loss: 2.855 | Accuracy: 0.248500 | 0.917 sec/iter\n",
      "Epoch: 44 | Batch: 005 / 011 | Total loss: 2.805 | Reg loss: 0.030 | Tree loss: 2.805 | Accuracy: 0.253000 | 0.916 sec/iter\n",
      "Epoch: 44 | Batch: 006 / 011 | Total loss: 2.779 | Reg loss: 0.030 | Tree loss: 2.779 | Accuracy: 0.256500 | 0.916 sec/iter\n",
      "Epoch: 44 | Batch: 007 / 011 | Total loss: 2.779 | Reg loss: 0.030 | Tree loss: 2.779 | Accuracy: 0.247500 | 0.916 sec/iter\n",
      "Epoch: 44 | Batch: 008 / 011 | Total loss: 2.754 | Reg loss: 0.030 | Tree loss: 2.754 | Accuracy: 0.228500 | 0.916 sec/iter\n",
      "Epoch: 44 | Batch: 009 / 011 | Total loss: 2.773 | Reg loss: 0.030 | Tree loss: 2.773 | Accuracy: 0.202500 | 0.916 sec/iter\n",
      "Epoch: 44 | Batch: 010 / 011 | Total loss: 2.762 | Reg loss: 0.030 | Tree loss: 2.762 | Accuracy: 0.184300 | 0.916 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Batch: 000 / 011 | Total loss: 3.005 | Reg loss: 0.030 | Tree loss: 3.005 | Accuracy: 0.203000 | 0.916 sec/iter\n",
      "Epoch: 45 | Batch: 001 / 011 | Total loss: 2.941 | Reg loss: 0.030 | Tree loss: 2.941 | Accuracy: 0.207000 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 002 / 011 | Total loss: 2.912 | Reg loss: 0.030 | Tree loss: 2.912 | Accuracy: 0.216500 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 003 / 011 | Total loss: 2.875 | Reg loss: 0.030 | Tree loss: 2.875 | Accuracy: 0.241000 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 004 / 011 | Total loss: 2.855 | Reg loss: 0.030 | Tree loss: 2.855 | Accuracy: 0.229000 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 005 / 011 | Total loss: 2.816 | Reg loss: 0.030 | Tree loss: 2.816 | Accuracy: 0.252000 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 006 / 011 | Total loss: 2.775 | Reg loss: 0.030 | Tree loss: 2.775 | Accuracy: 0.265000 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 007 / 011 | Total loss: 2.766 | Reg loss: 0.030 | Tree loss: 2.766 | Accuracy: 0.235500 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 008 / 011 | Total loss: 2.748 | Reg loss: 0.030 | Tree loss: 2.748 | Accuracy: 0.251500 | 0.915 sec/iter\n",
      "Epoch: 45 | Batch: 009 / 011 | Total loss: 2.775 | Reg loss: 0.030 | Tree loss: 2.775 | Accuracy: 0.189500 | 0.914 sec/iter\n",
      "Epoch: 45 | Batch: 010 / 011 | Total loss: 2.822 | Reg loss: 0.030 | Tree loss: 2.822 | Accuracy: 0.167235 | 0.914 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 46 | Batch: 000 / 011 | Total loss: 2.981 | Reg loss: 0.030 | Tree loss: 2.981 | Accuracy: 0.206000 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 001 / 011 | Total loss: 2.932 | Reg loss: 0.030 | Tree loss: 2.932 | Accuracy: 0.219500 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 002 / 011 | Total loss: 2.914 | Reg loss: 0.030 | Tree loss: 2.914 | Accuracy: 0.218000 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 003 / 011 | Total loss: 2.867 | Reg loss: 0.030 | Tree loss: 2.867 | Accuracy: 0.232000 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 004 / 011 | Total loss: 2.835 | Reg loss: 0.030 | Tree loss: 2.835 | Accuracy: 0.255500 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 005 / 011 | Total loss: 2.800 | Reg loss: 0.030 | Tree loss: 2.800 | Accuracy: 0.246000 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 006 / 011 | Total loss: 2.769 | Reg loss: 0.030 | Tree loss: 2.769 | Accuracy: 0.258500 | 0.914 sec/iter\n",
      "Epoch: 46 | Batch: 007 / 011 | Total loss: 2.757 | Reg loss: 0.030 | Tree loss: 2.757 | Accuracy: 0.246500 | 0.913 sec/iter\n",
      "Epoch: 46 | Batch: 008 / 011 | Total loss: 2.771 | Reg loss: 0.030 | Tree loss: 2.771 | Accuracy: 0.213500 | 0.913 sec/iter\n",
      "Epoch: 46 | Batch: 009 / 011 | Total loss: 2.746 | Reg loss: 0.030 | Tree loss: 2.746 | Accuracy: 0.199500 | 0.913 sec/iter\n",
      "Epoch: 46 | Batch: 010 / 011 | Total loss: 2.777 | Reg loss: 0.030 | Tree loss: 2.777 | Accuracy: 0.167235 | 0.913 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 47 | Batch: 000 / 011 | Total loss: 2.989 | Reg loss: 0.030 | Tree loss: 2.989 | Accuracy: 0.209500 | 0.913 sec/iter\n",
      "Epoch: 47 | Batch: 001 / 011 | Total loss: 2.968 | Reg loss: 0.030 | Tree loss: 2.968 | Accuracy: 0.201000 | 0.913 sec/iter\n",
      "Epoch: 47 | Batch: 002 / 011 | Total loss: 2.879 | Reg loss: 0.030 | Tree loss: 2.879 | Accuracy: 0.235500 | 0.913 sec/iter\n",
      "Epoch: 47 | Batch: 003 / 011 | Total loss: 2.870 | Reg loss: 0.030 | Tree loss: 2.870 | Accuracy: 0.211000 | 0.913 sec/iter\n",
      "Epoch: 47 | Batch: 004 / 011 | Total loss: 2.823 | Reg loss: 0.030 | Tree loss: 2.823 | Accuracy: 0.252500 | 0.912 sec/iter\n",
      "Epoch: 47 | Batch: 005 / 011 | Total loss: 2.783 | Reg loss: 0.030 | Tree loss: 2.783 | Accuracy: 0.271000 | 0.912 sec/iter\n",
      "Epoch: 47 | Batch: 006 / 011 | Total loss: 2.762 | Reg loss: 0.030 | Tree loss: 2.762 | Accuracy: 0.250000 | 0.912 sec/iter\n",
      "Epoch: 47 | Batch: 007 / 011 | Total loss: 2.757 | Reg loss: 0.030 | Tree loss: 2.757 | Accuracy: 0.242000 | 0.912 sec/iter\n",
      "Epoch: 47 | Batch: 008 / 011 | Total loss: 2.756 | Reg loss: 0.030 | Tree loss: 2.756 | Accuracy: 0.232500 | 0.912 sec/iter\n",
      "Epoch: 47 | Batch: 009 / 011 | Total loss: 2.735 | Reg loss: 0.030 | Tree loss: 2.735 | Accuracy: 0.211000 | 0.912 sec/iter\n",
      "Epoch: 47 | Batch: 010 / 011 | Total loss: 2.684 | Reg loss: 0.031 | Tree loss: 2.684 | Accuracy: 0.221843 | 0.911 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 48 | Batch: 000 / 011 | Total loss: 2.954 | Reg loss: 0.030 | Tree loss: 2.954 | Accuracy: 0.207500 | 0.912 sec/iter\n",
      "Epoch: 48 | Batch: 001 / 011 | Total loss: 2.937 | Reg loss: 0.030 | Tree loss: 2.937 | Accuracy: 0.231000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 002 / 011 | Total loss: 2.900 | Reg loss: 0.030 | Tree loss: 2.900 | Accuracy: 0.208500 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 003 / 011 | Total loss: 2.861 | Reg loss: 0.030 | Tree loss: 2.861 | Accuracy: 0.223500 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 004 / 011 | Total loss: 2.818 | Reg loss: 0.030 | Tree loss: 2.818 | Accuracy: 0.247000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 005 / 011 | Total loss: 2.763 | Reg loss: 0.030 | Tree loss: 2.763 | Accuracy: 0.273000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 006 / 011 | Total loss: 2.745 | Reg loss: 0.030 | Tree loss: 2.745 | Accuracy: 0.285000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 007 / 011 | Total loss: 2.750 | Reg loss: 0.030 | Tree loss: 2.750 | Accuracy: 0.240000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 008 / 011 | Total loss: 2.752 | Reg loss: 0.031 | Tree loss: 2.752 | Accuracy: 0.219000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 009 / 011 | Total loss: 2.736 | Reg loss: 0.031 | Tree loss: 2.736 | Accuracy: 0.212000 | 0.911 sec/iter\n",
      "Epoch: 48 | Batch: 010 / 011 | Total loss: 2.752 | Reg loss: 0.031 | Tree loss: 2.752 | Accuracy: 0.208191 | 0.91 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 49 | Batch: 000 / 011 | Total loss: 2.980 | Reg loss: 0.030 | Tree loss: 2.980 | Accuracy: 0.195500 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 001 / 011 | Total loss: 2.901 | Reg loss: 0.030 | Tree loss: 2.901 | Accuracy: 0.232000 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 002 / 011 | Total loss: 2.902 | Reg loss: 0.030 | Tree loss: 2.902 | Accuracy: 0.209500 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 003 / 011 | Total loss: 2.830 | Reg loss: 0.030 | Tree loss: 2.830 | Accuracy: 0.231500 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 004 / 011 | Total loss: 2.819 | Reg loss: 0.030 | Tree loss: 2.819 | Accuracy: 0.248500 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 005 / 011 | Total loss: 2.779 | Reg loss: 0.030 | Tree loss: 2.779 | Accuracy: 0.259000 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 006 / 011 | Total loss: 2.756 | Reg loss: 0.031 | Tree loss: 2.756 | Accuracy: 0.265500 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 007 / 011 | Total loss: 2.731 | Reg loss: 0.031 | Tree loss: 2.731 | Accuracy: 0.260000 | 0.91 sec/iter\n",
      "Epoch: 49 | Batch: 008 / 011 | Total loss: 2.750 | Reg loss: 0.031 | Tree loss: 2.750 | Accuracy: 0.241000 | 0.909 sec/iter\n",
      "Epoch: 49 | Batch: 009 / 011 | Total loss: 2.722 | Reg loss: 0.031 | Tree loss: 2.722 | Accuracy: 0.231500 | 0.909 sec/iter\n",
      "Epoch: 49 | Batch: 010 / 011 | Total loss: 2.728 | Reg loss: 0.031 | Tree loss: 2.728 | Accuracy: 0.184300 | 0.909 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | Batch: 000 / 011 | Total loss: 2.963 | Reg loss: 0.030 | Tree loss: 2.963 | Accuracy: 0.212000 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 001 / 011 | Total loss: 2.924 | Reg loss: 0.030 | Tree loss: 2.924 | Accuracy: 0.213000 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 002 / 011 | Total loss: 2.870 | Reg loss: 0.030 | Tree loss: 2.870 | Accuracy: 0.227000 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 003 / 011 | Total loss: 2.839 | Reg loss: 0.031 | Tree loss: 2.839 | Accuracy: 0.232500 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 004 / 011 | Total loss: 2.796 | Reg loss: 0.031 | Tree loss: 2.796 | Accuracy: 0.246000 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 005 / 011 | Total loss: 2.767 | Reg loss: 0.031 | Tree loss: 2.767 | Accuracy: 0.272500 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 006 / 011 | Total loss: 2.746 | Reg loss: 0.031 | Tree loss: 2.746 | Accuracy: 0.248500 | 0.909 sec/iter\n",
      "Epoch: 50 | Batch: 007 / 011 | Total loss: 2.713 | Reg loss: 0.031 | Tree loss: 2.713 | Accuracy: 0.248000 | 0.908 sec/iter\n",
      "Epoch: 50 | Batch: 008 / 011 | Total loss: 2.712 | Reg loss: 0.031 | Tree loss: 2.712 | Accuracy: 0.227000 | 0.908 sec/iter\n",
      "Epoch: 50 | Batch: 009 / 011 | Total loss: 2.723 | Reg loss: 0.031 | Tree loss: 2.723 | Accuracy: 0.218000 | 0.908 sec/iter\n",
      "Epoch: 50 | Batch: 010 / 011 | Total loss: 2.757 | Reg loss: 0.031 | Tree loss: 2.757 | Accuracy: 0.215017 | 0.908 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 51 | Batch: 000 / 011 | Total loss: 2.953 | Reg loss: 0.031 | Tree loss: 2.953 | Accuracy: 0.217500 | 0.908 sec/iter\n",
      "Epoch: 51 | Batch: 001 / 011 | Total loss: 2.923 | Reg loss: 0.031 | Tree loss: 2.923 | Accuracy: 0.210500 | 0.908 sec/iter\n",
      "Epoch: 51 | Batch: 002 / 011 | Total loss: 2.876 | Reg loss: 0.031 | Tree loss: 2.876 | Accuracy: 0.220000 | 0.908 sec/iter\n",
      "Epoch: 51 | Batch: 003 / 011 | Total loss: 2.832 | Reg loss: 0.031 | Tree loss: 2.832 | Accuracy: 0.227000 | 0.908 sec/iter\n",
      "Epoch: 51 | Batch: 004 / 011 | Total loss: 2.788 | Reg loss: 0.031 | Tree loss: 2.788 | Accuracy: 0.246000 | 0.908 sec/iter\n",
      "Epoch: 51 | Batch: 005 / 011 | Total loss: 2.772 | Reg loss: 0.031 | Tree loss: 2.772 | Accuracy: 0.267500 | 0.908 sec/iter\n",
      "Epoch: 51 | Batch: 006 / 011 | Total loss: 2.752 | Reg loss: 0.031 | Tree loss: 2.752 | Accuracy: 0.262500 | 0.907 sec/iter\n",
      "Epoch: 51 | Batch: 007 / 011 | Total loss: 2.696 | Reg loss: 0.031 | Tree loss: 2.696 | Accuracy: 0.267000 | 0.907 sec/iter\n",
      "Epoch: 51 | Batch: 008 / 011 | Total loss: 2.711 | Reg loss: 0.031 | Tree loss: 2.711 | Accuracy: 0.236000 | 0.907 sec/iter\n",
      "Epoch: 51 | Batch: 009 / 011 | Total loss: 2.706 | Reg loss: 0.031 | Tree loss: 2.706 | Accuracy: 0.230500 | 0.907 sec/iter\n",
      "Epoch: 51 | Batch: 010 / 011 | Total loss: 2.758 | Reg loss: 0.031 | Tree loss: 2.758 | Accuracy: 0.180887 | 0.907 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 52 | Batch: 000 / 011 | Total loss: 2.939 | Reg loss: 0.031 | Tree loss: 2.939 | Accuracy: 0.218500 | 0.907 sec/iter\n",
      "Epoch: 52 | Batch: 001 / 011 | Total loss: 2.900 | Reg loss: 0.031 | Tree loss: 2.900 | Accuracy: 0.225500 | 0.907 sec/iter\n",
      "Epoch: 52 | Batch: 002 / 011 | Total loss: 2.891 | Reg loss: 0.031 | Tree loss: 2.891 | Accuracy: 0.221500 | 0.907 sec/iter\n",
      "Epoch: 52 | Batch: 003 / 011 | Total loss: 2.812 | Reg loss: 0.031 | Tree loss: 2.812 | Accuracy: 0.254500 | 0.907 sec/iter\n",
      "Epoch: 52 | Batch: 004 / 011 | Total loss: 2.787 | Reg loss: 0.031 | Tree loss: 2.787 | Accuracy: 0.263500 | 0.907 sec/iter\n",
      "Epoch: 52 | Batch: 005 / 011 | Total loss: 2.757 | Reg loss: 0.031 | Tree loss: 2.757 | Accuracy: 0.272500 | 0.906 sec/iter\n",
      "Epoch: 52 | Batch: 006 / 011 | Total loss: 2.730 | Reg loss: 0.031 | Tree loss: 2.730 | Accuracy: 0.265000 | 0.906 sec/iter\n",
      "Epoch: 52 | Batch: 007 / 011 | Total loss: 2.708 | Reg loss: 0.031 | Tree loss: 2.708 | Accuracy: 0.229000 | 0.906 sec/iter\n",
      "Epoch: 52 | Batch: 008 / 011 | Total loss: 2.705 | Reg loss: 0.031 | Tree loss: 2.705 | Accuracy: 0.251000 | 0.906 sec/iter\n",
      "Epoch: 52 | Batch: 009 / 011 | Total loss: 2.703 | Reg loss: 0.031 | Tree loss: 2.703 | Accuracy: 0.204000 | 0.906 sec/iter\n",
      "Epoch: 52 | Batch: 010 / 011 | Total loss: 2.728 | Reg loss: 0.031 | Tree loss: 2.728 | Accuracy: 0.208191 | 0.906 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 53 | Batch: 000 / 011 | Total loss: 2.931 | Reg loss: 0.031 | Tree loss: 2.931 | Accuracy: 0.210000 | 0.906 sec/iter\n",
      "Epoch: 53 | Batch: 001 / 011 | Total loss: 2.881 | Reg loss: 0.031 | Tree loss: 2.881 | Accuracy: 0.229500 | 0.906 sec/iter\n",
      "Epoch: 53 | Batch: 002 / 011 | Total loss: 2.862 | Reg loss: 0.031 | Tree loss: 2.862 | Accuracy: 0.241500 | 0.906 sec/iter\n",
      "Epoch: 53 | Batch: 003 / 011 | Total loss: 2.842 | Reg loss: 0.031 | Tree loss: 2.842 | Accuracy: 0.221000 | 0.906 sec/iter\n",
      "Epoch: 53 | Batch: 004 / 011 | Total loss: 2.769 | Reg loss: 0.031 | Tree loss: 2.769 | Accuracy: 0.261000 | 0.905 sec/iter\n",
      "Epoch: 53 | Batch: 005 / 011 | Total loss: 2.767 | Reg loss: 0.031 | Tree loss: 2.767 | Accuracy: 0.249500 | 0.905 sec/iter\n",
      "Epoch: 53 | Batch: 006 / 011 | Total loss: 2.718 | Reg loss: 0.031 | Tree loss: 2.718 | Accuracy: 0.271500 | 0.905 sec/iter\n",
      "Epoch: 53 | Batch: 007 / 011 | Total loss: 2.729 | Reg loss: 0.031 | Tree loss: 2.729 | Accuracy: 0.241500 | 0.905 sec/iter\n",
      "Epoch: 53 | Batch: 008 / 011 | Total loss: 2.681 | Reg loss: 0.031 | Tree loss: 2.681 | Accuracy: 0.240000 | 0.905 sec/iter\n",
      "Epoch: 53 | Batch: 009 / 011 | Total loss: 2.679 | Reg loss: 0.031 | Tree loss: 2.679 | Accuracy: 0.232500 | 0.905 sec/iter\n",
      "Epoch: 53 | Batch: 010 / 011 | Total loss: 2.710 | Reg loss: 0.031 | Tree loss: 2.710 | Accuracy: 0.201365 | 0.905 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 54 | Batch: 000 / 011 | Total loss: 2.933 | Reg loss: 0.031 | Tree loss: 2.933 | Accuracy: 0.208000 | 0.905 sec/iter\n",
      "Epoch: 54 | Batch: 001 / 011 | Total loss: 2.887 | Reg loss: 0.031 | Tree loss: 2.887 | Accuracy: 0.209500 | 0.905 sec/iter\n",
      "Epoch: 54 | Batch: 002 / 011 | Total loss: 2.864 | Reg loss: 0.031 | Tree loss: 2.864 | Accuracy: 0.228500 | 0.905 sec/iter\n",
      "Epoch: 54 | Batch: 003 / 011 | Total loss: 2.803 | Reg loss: 0.031 | Tree loss: 2.803 | Accuracy: 0.231500 | 0.905 sec/iter\n",
      "Epoch: 54 | Batch: 004 / 011 | Total loss: 2.782 | Reg loss: 0.031 | Tree loss: 2.782 | Accuracy: 0.252500 | 0.904 sec/iter\n",
      "Epoch: 54 | Batch: 005 / 011 | Total loss: 2.745 | Reg loss: 0.031 | Tree loss: 2.745 | Accuracy: 0.259500 | 0.904 sec/iter\n",
      "Epoch: 54 | Batch: 006 / 011 | Total loss: 2.711 | Reg loss: 0.031 | Tree loss: 2.711 | Accuracy: 0.261000 | 0.904 sec/iter\n",
      "Epoch: 54 | Batch: 007 / 011 | Total loss: 2.688 | Reg loss: 0.031 | Tree loss: 2.688 | Accuracy: 0.270000 | 0.904 sec/iter\n",
      "Epoch: 54 | Batch: 008 / 011 | Total loss: 2.662 | Reg loss: 0.031 | Tree loss: 2.662 | Accuracy: 0.258500 | 0.904 sec/iter\n",
      "Epoch: 54 | Batch: 009 / 011 | Total loss: 2.707 | Reg loss: 0.031 | Tree loss: 2.707 | Accuracy: 0.235000 | 0.904 sec/iter\n",
      "Epoch: 54 | Batch: 010 / 011 | Total loss: 2.681 | Reg loss: 0.031 | Tree loss: 2.681 | Accuracy: 0.197952 | 0.904 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 | Batch: 000 / 011 | Total loss: 2.932 | Reg loss: 0.031 | Tree loss: 2.932 | Accuracy: 0.209000 | 0.904 sec/iter\n",
      "Epoch: 55 | Batch: 001 / 011 | Total loss: 2.875 | Reg loss: 0.031 | Tree loss: 2.875 | Accuracy: 0.237500 | 0.904 sec/iter\n",
      "Epoch: 55 | Batch: 002 / 011 | Total loss: 2.834 | Reg loss: 0.031 | Tree loss: 2.834 | Accuracy: 0.240500 | 0.904 sec/iter\n",
      "Epoch: 55 | Batch: 003 / 011 | Total loss: 2.804 | Reg loss: 0.031 | Tree loss: 2.804 | Accuracy: 0.252000 | 0.904 sec/iter\n",
      "Epoch: 55 | Batch: 004 / 011 | Total loss: 2.773 | Reg loss: 0.031 | Tree loss: 2.773 | Accuracy: 0.244500 | 0.904 sec/iter\n",
      "Epoch: 55 | Batch: 005 / 011 | Total loss: 2.753 | Reg loss: 0.031 | Tree loss: 2.753 | Accuracy: 0.245000 | 0.903 sec/iter\n",
      "Epoch: 55 | Batch: 006 / 011 | Total loss: 2.704 | Reg loss: 0.031 | Tree loss: 2.704 | Accuracy: 0.257000 | 0.903 sec/iter\n",
      "Epoch: 55 | Batch: 007 / 011 | Total loss: 2.677 | Reg loss: 0.031 | Tree loss: 2.677 | Accuracy: 0.244000 | 0.903 sec/iter\n",
      "Epoch: 55 | Batch: 008 / 011 | Total loss: 2.693 | Reg loss: 0.031 | Tree loss: 2.693 | Accuracy: 0.239500 | 0.903 sec/iter\n",
      "Epoch: 55 | Batch: 009 / 011 | Total loss: 2.694 | Reg loss: 0.031 | Tree loss: 2.694 | Accuracy: 0.204500 | 0.903 sec/iter\n",
      "Epoch: 55 | Batch: 010 / 011 | Total loss: 2.685 | Reg loss: 0.031 | Tree loss: 2.685 | Accuracy: 0.215017 | 0.903 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 56 | Batch: 000 / 011 | Total loss: 2.915 | Reg loss: 0.031 | Tree loss: 2.915 | Accuracy: 0.205000 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 001 / 011 | Total loss: 2.888 | Reg loss: 0.031 | Tree loss: 2.888 | Accuracy: 0.231500 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 002 / 011 | Total loss: 2.839 | Reg loss: 0.031 | Tree loss: 2.839 | Accuracy: 0.221500 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 003 / 011 | Total loss: 2.805 | Reg loss: 0.031 | Tree loss: 2.805 | Accuracy: 0.246500 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 004 / 011 | Total loss: 2.801 | Reg loss: 0.031 | Tree loss: 2.801 | Accuracy: 0.210500 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 005 / 011 | Total loss: 2.721 | Reg loss: 0.031 | Tree loss: 2.721 | Accuracy: 0.259500 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 006 / 011 | Total loss: 2.707 | Reg loss: 0.031 | Tree loss: 2.707 | Accuracy: 0.247000 | 0.903 sec/iter\n",
      "Epoch: 56 | Batch: 007 / 011 | Total loss: 2.686 | Reg loss: 0.031 | Tree loss: 2.686 | Accuracy: 0.271000 | 0.902 sec/iter\n",
      "Epoch: 56 | Batch: 008 / 011 | Total loss: 2.660 | Reg loss: 0.031 | Tree loss: 2.660 | Accuracy: 0.264000 | 0.902 sec/iter\n",
      "Epoch: 56 | Batch: 009 / 011 | Total loss: 2.663 | Reg loss: 0.031 | Tree loss: 2.663 | Accuracy: 0.236000 | 0.902 sec/iter\n",
      "Epoch: 56 | Batch: 010 / 011 | Total loss: 2.674 | Reg loss: 0.031 | Tree loss: 2.674 | Accuracy: 0.228669 | 0.902 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 57 | Batch: 000 / 011 | Total loss: 2.903 | Reg loss: 0.031 | Tree loss: 2.903 | Accuracy: 0.227500 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 001 / 011 | Total loss: 2.866 | Reg loss: 0.031 | Tree loss: 2.866 | Accuracy: 0.237000 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 002 / 011 | Total loss: 2.826 | Reg loss: 0.031 | Tree loss: 2.826 | Accuracy: 0.232500 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 003 / 011 | Total loss: 2.796 | Reg loss: 0.031 | Tree loss: 2.796 | Accuracy: 0.243000 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 004 / 011 | Total loss: 2.772 | Reg loss: 0.031 | Tree loss: 2.772 | Accuracy: 0.235500 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 005 / 011 | Total loss: 2.733 | Reg loss: 0.031 | Tree loss: 2.733 | Accuracy: 0.255500 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 006 / 011 | Total loss: 2.685 | Reg loss: 0.031 | Tree loss: 2.685 | Accuracy: 0.272000 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 007 / 011 | Total loss: 2.687 | Reg loss: 0.031 | Tree loss: 2.687 | Accuracy: 0.247500 | 0.902 sec/iter\n",
      "Epoch: 57 | Batch: 008 / 011 | Total loss: 2.662 | Reg loss: 0.031 | Tree loss: 2.662 | Accuracy: 0.255000 | 0.901 sec/iter\n",
      "Epoch: 57 | Batch: 009 / 011 | Total loss: 2.676 | Reg loss: 0.031 | Tree loss: 2.676 | Accuracy: 0.233000 | 0.901 sec/iter\n",
      "Epoch: 57 | Batch: 010 / 011 | Total loss: 2.682 | Reg loss: 0.031 | Tree loss: 2.682 | Accuracy: 0.232082 | 0.901 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 58 | Batch: 000 / 011 | Total loss: 2.914 | Reg loss: 0.031 | Tree loss: 2.914 | Accuracy: 0.199500 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 001 / 011 | Total loss: 2.856 | Reg loss: 0.031 | Tree loss: 2.856 | Accuracy: 0.231000 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 002 / 011 | Total loss: 2.810 | Reg loss: 0.031 | Tree loss: 2.810 | Accuracy: 0.255500 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 003 / 011 | Total loss: 2.790 | Reg loss: 0.031 | Tree loss: 2.790 | Accuracy: 0.257000 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 004 / 011 | Total loss: 2.754 | Reg loss: 0.031 | Tree loss: 2.754 | Accuracy: 0.249500 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 005 / 011 | Total loss: 2.719 | Reg loss: 0.031 | Tree loss: 2.719 | Accuracy: 0.246500 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 006 / 011 | Total loss: 2.686 | Reg loss: 0.031 | Tree loss: 2.686 | Accuracy: 0.254000 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 007 / 011 | Total loss: 2.706 | Reg loss: 0.031 | Tree loss: 2.706 | Accuracy: 0.250500 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 008 / 011 | Total loss: 2.667 | Reg loss: 0.031 | Tree loss: 2.667 | Accuracy: 0.241500 | 0.901 sec/iter\n",
      "Epoch: 58 | Batch: 009 / 011 | Total loss: 2.655 | Reg loss: 0.031 | Tree loss: 2.655 | Accuracy: 0.241500 | 0.9 sec/iter\n",
      "Epoch: 58 | Batch: 010 / 011 | Total loss: 2.685 | Reg loss: 0.032 | Tree loss: 2.685 | Accuracy: 0.194539 | 0.9 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 59 | Batch: 000 / 011 | Total loss: 2.904 | Reg loss: 0.031 | Tree loss: 2.904 | Accuracy: 0.222000 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 001 / 011 | Total loss: 2.860 | Reg loss: 0.031 | Tree loss: 2.860 | Accuracy: 0.223500 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 002 / 011 | Total loss: 2.836 | Reg loss: 0.031 | Tree loss: 2.836 | Accuracy: 0.233500 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 003 / 011 | Total loss: 2.776 | Reg loss: 0.031 | Tree loss: 2.776 | Accuracy: 0.246000 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 004 / 011 | Total loss: 2.737 | Reg loss: 0.031 | Tree loss: 2.737 | Accuracy: 0.253500 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 005 / 011 | Total loss: 2.700 | Reg loss: 0.031 | Tree loss: 2.700 | Accuracy: 0.255000 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 006 / 011 | Total loss: 2.688 | Reg loss: 0.031 | Tree loss: 2.688 | Accuracy: 0.262500 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 007 / 011 | Total loss: 2.671 | Reg loss: 0.031 | Tree loss: 2.671 | Accuracy: 0.254000 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 008 / 011 | Total loss: 2.658 | Reg loss: 0.032 | Tree loss: 2.658 | Accuracy: 0.255000 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 009 / 011 | Total loss: 2.653 | Reg loss: 0.032 | Tree loss: 2.653 | Accuracy: 0.237500 | 0.9 sec/iter\n",
      "Epoch: 59 | Batch: 010 / 011 | Total loss: 2.617 | Reg loss: 0.032 | Tree loss: 2.617 | Accuracy: 0.238908 | 0.899 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | Batch: 000 / 011 | Total loss: 2.898 | Reg loss: 0.031 | Tree loss: 2.898 | Accuracy: 0.224500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 001 / 011 | Total loss: 2.875 | Reg loss: 0.031 | Tree loss: 2.875 | Accuracy: 0.216500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 002 / 011 | Total loss: 2.812 | Reg loss: 0.031 | Tree loss: 2.812 | Accuracy: 0.234500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 003 / 011 | Total loss: 2.772 | Reg loss: 0.031 | Tree loss: 2.772 | Accuracy: 0.236500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 004 / 011 | Total loss: 2.700 | Reg loss: 0.031 | Tree loss: 2.700 | Accuracy: 0.253500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 005 / 011 | Total loss: 2.695 | Reg loss: 0.032 | Tree loss: 2.695 | Accuracy: 0.263000 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 006 / 011 | Total loss: 2.673 | Reg loss: 0.032 | Tree loss: 2.673 | Accuracy: 0.267500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 007 / 011 | Total loss: 2.651 | Reg loss: 0.032 | Tree loss: 2.651 | Accuracy: 0.271000 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 008 / 011 | Total loss: 2.671 | Reg loss: 0.032 | Tree loss: 2.671 | Accuracy: 0.250000 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 009 / 011 | Total loss: 2.678 | Reg loss: 0.032 | Tree loss: 2.678 | Accuracy: 0.236500 | 0.899 sec/iter\n",
      "Epoch: 60 | Batch: 010 / 011 | Total loss: 2.596 | Reg loss: 0.032 | Tree loss: 2.596 | Accuracy: 0.221843 | 0.898 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 61 | Batch: 000 / 011 | Total loss: 2.878 | Reg loss: 0.031 | Tree loss: 2.878 | Accuracy: 0.224500 | 0.899 sec/iter\n",
      "Epoch: 61 | Batch: 001 / 011 | Total loss: 2.864 | Reg loss: 0.032 | Tree loss: 2.864 | Accuracy: 0.217500 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 002 / 011 | Total loss: 2.797 | Reg loss: 0.032 | Tree loss: 2.797 | Accuracy: 0.237000 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 003 / 011 | Total loss: 2.769 | Reg loss: 0.032 | Tree loss: 2.769 | Accuracy: 0.252500 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 004 / 011 | Total loss: 2.711 | Reg loss: 0.032 | Tree loss: 2.711 | Accuracy: 0.257000 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 005 / 011 | Total loss: 2.710 | Reg loss: 0.032 | Tree loss: 2.710 | Accuracy: 0.247500 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 006 / 011 | Total loss: 2.678 | Reg loss: 0.032 | Tree loss: 2.678 | Accuracy: 0.282000 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 007 / 011 | Total loss: 2.662 | Reg loss: 0.032 | Tree loss: 2.662 | Accuracy: 0.263000 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 008 / 011 | Total loss: 2.651 | Reg loss: 0.032 | Tree loss: 2.651 | Accuracy: 0.260500 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 009 / 011 | Total loss: 2.638 | Reg loss: 0.032 | Tree loss: 2.638 | Accuracy: 0.237000 | 0.898 sec/iter\n",
      "Epoch: 61 | Batch: 010 / 011 | Total loss: 2.616 | Reg loss: 0.032 | Tree loss: 2.616 | Accuracy: 0.269625 | 0.898 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 62 | Batch: 000 / 011 | Total loss: 2.871 | Reg loss: 0.032 | Tree loss: 2.871 | Accuracy: 0.222500 | 0.898 sec/iter\n",
      "Epoch: 62 | Batch: 001 / 011 | Total loss: 2.839 | Reg loss: 0.032 | Tree loss: 2.839 | Accuracy: 0.219500 | 0.898 sec/iter\n",
      "Epoch: 62 | Batch: 002 / 011 | Total loss: 2.782 | Reg loss: 0.032 | Tree loss: 2.782 | Accuracy: 0.242000 | 0.898 sec/iter\n",
      "Epoch: 62 | Batch: 003 / 011 | Total loss: 2.771 | Reg loss: 0.032 | Tree loss: 2.771 | Accuracy: 0.248500 | 0.898 sec/iter\n",
      "Epoch: 62 | Batch: 004 / 011 | Total loss: 2.727 | Reg loss: 0.032 | Tree loss: 2.727 | Accuracy: 0.255000 | 0.897 sec/iter\n",
      "Epoch: 62 | Batch: 005 / 011 | Total loss: 2.693 | Reg loss: 0.032 | Tree loss: 2.693 | Accuracy: 0.254500 | 0.897 sec/iter\n",
      "Epoch: 62 | Batch: 006 / 011 | Total loss: 2.684 | Reg loss: 0.032 | Tree loss: 2.684 | Accuracy: 0.255000 | 0.897 sec/iter\n",
      "Epoch: 62 | Batch: 007 / 011 | Total loss: 2.644 | Reg loss: 0.032 | Tree loss: 2.644 | Accuracy: 0.265000 | 0.897 sec/iter\n",
      "Epoch: 62 | Batch: 008 / 011 | Total loss: 2.643 | Reg loss: 0.032 | Tree loss: 2.643 | Accuracy: 0.253500 | 0.897 sec/iter\n",
      "Epoch: 62 | Batch: 009 / 011 | Total loss: 2.638 | Reg loss: 0.032 | Tree loss: 2.638 | Accuracy: 0.249500 | 0.897 sec/iter\n",
      "Epoch: 62 | Batch: 010 / 011 | Total loss: 2.655 | Reg loss: 0.032 | Tree loss: 2.655 | Accuracy: 0.211604 | 0.897 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 63 | Batch: 000 / 011 | Total loss: 2.869 | Reg loss: 0.032 | Tree loss: 2.869 | Accuracy: 0.228000 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 001 / 011 | Total loss: 2.837 | Reg loss: 0.032 | Tree loss: 2.837 | Accuracy: 0.228000 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 002 / 011 | Total loss: 2.811 | Reg loss: 0.032 | Tree loss: 2.811 | Accuracy: 0.232000 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 003 / 011 | Total loss: 2.742 | Reg loss: 0.032 | Tree loss: 2.742 | Accuracy: 0.257500 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 004 / 011 | Total loss: 2.710 | Reg loss: 0.032 | Tree loss: 2.710 | Accuracy: 0.253000 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 005 / 011 | Total loss: 2.702 | Reg loss: 0.032 | Tree loss: 2.702 | Accuracy: 0.257500 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 006 / 011 | Total loss: 2.663 | Reg loss: 0.032 | Tree loss: 2.663 | Accuracy: 0.282000 | 0.897 sec/iter\n",
      "Epoch: 63 | Batch: 007 / 011 | Total loss: 2.637 | Reg loss: 0.032 | Tree loss: 2.637 | Accuracy: 0.259000 | 0.896 sec/iter\n",
      "Epoch: 63 | Batch: 008 / 011 | Total loss: 2.642 | Reg loss: 0.032 | Tree loss: 2.642 | Accuracy: 0.255500 | 0.896 sec/iter\n",
      "Epoch: 63 | Batch: 009 / 011 | Total loss: 2.635 | Reg loss: 0.032 | Tree loss: 2.635 | Accuracy: 0.241500 | 0.896 sec/iter\n",
      "Epoch: 63 | Batch: 010 / 011 | Total loss: 2.553 | Reg loss: 0.032 | Tree loss: 2.553 | Accuracy: 0.273038 | 0.896 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 64 | Batch: 000 / 011 | Total loss: 2.855 | Reg loss: 0.032 | Tree loss: 2.855 | Accuracy: 0.218000 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 001 / 011 | Total loss: 2.842 | Reg loss: 0.032 | Tree loss: 2.842 | Accuracy: 0.209500 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 002 / 011 | Total loss: 2.798 | Reg loss: 0.032 | Tree loss: 2.798 | Accuracy: 0.226000 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 003 / 011 | Total loss: 2.742 | Reg loss: 0.032 | Tree loss: 2.742 | Accuracy: 0.262000 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 004 / 011 | Total loss: 2.678 | Reg loss: 0.032 | Tree loss: 2.678 | Accuracy: 0.262000 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 005 / 011 | Total loss: 2.706 | Reg loss: 0.032 | Tree loss: 2.706 | Accuracy: 0.258500 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 006 / 011 | Total loss: 2.616 | Reg loss: 0.032 | Tree loss: 2.616 | Accuracy: 0.301000 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 007 / 011 | Total loss: 2.640 | Reg loss: 0.032 | Tree loss: 2.640 | Accuracy: 0.258000 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 008 / 011 | Total loss: 2.622 | Reg loss: 0.032 | Tree loss: 2.622 | Accuracy: 0.268500 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 009 / 011 | Total loss: 2.635 | Reg loss: 0.032 | Tree loss: 2.635 | Accuracy: 0.238500 | 0.896 sec/iter\n",
      "Epoch: 64 | Batch: 010 / 011 | Total loss: 2.602 | Reg loss: 0.032 | Tree loss: 2.602 | Accuracy: 0.221843 | 0.895 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 | Batch: 000 / 011 | Total loss: 2.860 | Reg loss: 0.032 | Tree loss: 2.860 | Accuracy: 0.212500 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 001 / 011 | Total loss: 2.795 | Reg loss: 0.032 | Tree loss: 2.795 | Accuracy: 0.235000 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 002 / 011 | Total loss: 2.784 | Reg loss: 0.032 | Tree loss: 2.784 | Accuracy: 0.249500 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 003 / 011 | Total loss: 2.754 | Reg loss: 0.032 | Tree loss: 2.754 | Accuracy: 0.243500 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 004 / 011 | Total loss: 2.721 | Reg loss: 0.032 | Tree loss: 2.721 | Accuracy: 0.243500 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 005 / 011 | Total loss: 2.645 | Reg loss: 0.032 | Tree loss: 2.645 | Accuracy: 0.275000 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 006 / 011 | Total loss: 2.648 | Reg loss: 0.032 | Tree loss: 2.648 | Accuracy: 0.292500 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 007 / 011 | Total loss: 2.616 | Reg loss: 0.032 | Tree loss: 2.616 | Accuracy: 0.285000 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 008 / 011 | Total loss: 2.619 | Reg loss: 0.032 | Tree loss: 2.619 | Accuracy: 0.260500 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 009 / 011 | Total loss: 2.653 | Reg loss: 0.032 | Tree loss: 2.653 | Accuracy: 0.225000 | 0.895 sec/iter\n",
      "Epoch: 65 | Batch: 010 / 011 | Total loss: 2.629 | Reg loss: 0.032 | Tree loss: 2.629 | Accuracy: 0.266212 | 0.895 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 66 | Batch: 000 / 011 | Total loss: 2.863 | Reg loss: 0.032 | Tree loss: 2.863 | Accuracy: 0.221500 | 0.895 sec/iter\n",
      "Epoch: 66 | Batch: 001 / 011 | Total loss: 2.795 | Reg loss: 0.032 | Tree loss: 2.795 | Accuracy: 0.223000 | 0.895 sec/iter\n",
      "Epoch: 66 | Batch: 002 / 011 | Total loss: 2.785 | Reg loss: 0.032 | Tree loss: 2.785 | Accuracy: 0.243000 | 0.895 sec/iter\n",
      "Epoch: 66 | Batch: 003 / 011 | Total loss: 2.747 | Reg loss: 0.032 | Tree loss: 2.747 | Accuracy: 0.241500 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 004 / 011 | Total loss: 2.714 | Reg loss: 0.032 | Tree loss: 2.714 | Accuracy: 0.246500 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 005 / 011 | Total loss: 2.659 | Reg loss: 0.032 | Tree loss: 2.659 | Accuracy: 0.261000 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 006 / 011 | Total loss: 2.632 | Reg loss: 0.032 | Tree loss: 2.632 | Accuracy: 0.278500 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 007 / 011 | Total loss: 2.599 | Reg loss: 0.032 | Tree loss: 2.599 | Accuracy: 0.267500 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 008 / 011 | Total loss: 2.637 | Reg loss: 0.032 | Tree loss: 2.637 | Accuracy: 0.246500 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 009 / 011 | Total loss: 2.602 | Reg loss: 0.032 | Tree loss: 2.602 | Accuracy: 0.251500 | 0.894 sec/iter\n",
      "Epoch: 66 | Batch: 010 / 011 | Total loss: 2.570 | Reg loss: 0.032 | Tree loss: 2.570 | Accuracy: 0.221843 | 0.894 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 67 | Batch: 000 / 011 | Total loss: 2.835 | Reg loss: 0.032 | Tree loss: 2.835 | Accuracy: 0.219500 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 001 / 011 | Total loss: 2.796 | Reg loss: 0.032 | Tree loss: 2.796 | Accuracy: 0.238500 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 002 / 011 | Total loss: 2.771 | Reg loss: 0.032 | Tree loss: 2.771 | Accuracy: 0.246500 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 003 / 011 | Total loss: 2.723 | Reg loss: 0.032 | Tree loss: 2.723 | Accuracy: 0.256000 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 004 / 011 | Total loss: 2.707 | Reg loss: 0.032 | Tree loss: 2.707 | Accuracy: 0.251000 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 005 / 011 | Total loss: 2.665 | Reg loss: 0.032 | Tree loss: 2.665 | Accuracy: 0.263000 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 006 / 011 | Total loss: 2.623 | Reg loss: 0.032 | Tree loss: 2.623 | Accuracy: 0.279500 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 007 / 011 | Total loss: 2.643 | Reg loss: 0.032 | Tree loss: 2.643 | Accuracy: 0.257500 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 008 / 011 | Total loss: 2.599 | Reg loss: 0.032 | Tree loss: 2.599 | Accuracy: 0.256000 | 0.894 sec/iter\n",
      "Epoch: 67 | Batch: 009 / 011 | Total loss: 2.618 | Reg loss: 0.032 | Tree loss: 2.618 | Accuracy: 0.251000 | 0.893 sec/iter\n",
      "Epoch: 67 | Batch: 010 / 011 | Total loss: 2.635 | Reg loss: 0.032 | Tree loss: 2.635 | Accuracy: 0.232082 | 0.893 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 68 | Batch: 000 / 011 | Total loss: 2.844 | Reg loss: 0.032 | Tree loss: 2.844 | Accuracy: 0.207500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 001 / 011 | Total loss: 2.808 | Reg loss: 0.032 | Tree loss: 2.808 | Accuracy: 0.234500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 002 / 011 | Total loss: 2.750 | Reg loss: 0.032 | Tree loss: 2.750 | Accuracy: 0.240500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 003 / 011 | Total loss: 2.722 | Reg loss: 0.032 | Tree loss: 2.722 | Accuracy: 0.247000 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 004 / 011 | Total loss: 2.676 | Reg loss: 0.032 | Tree loss: 2.676 | Accuracy: 0.273500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 005 / 011 | Total loss: 2.653 | Reg loss: 0.032 | Tree loss: 2.653 | Accuracy: 0.257000 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 006 / 011 | Total loss: 2.626 | Reg loss: 0.032 | Tree loss: 2.626 | Accuracy: 0.282500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 007 / 011 | Total loss: 2.618 | Reg loss: 0.032 | Tree loss: 2.618 | Accuracy: 0.272500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 008 / 011 | Total loss: 2.622 | Reg loss: 0.032 | Tree loss: 2.622 | Accuracy: 0.260000 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 009 / 011 | Total loss: 2.603 | Reg loss: 0.032 | Tree loss: 2.603 | Accuracy: 0.240500 | 0.893 sec/iter\n",
      "Epoch: 68 | Batch: 010 / 011 | Total loss: 2.591 | Reg loss: 0.032 | Tree loss: 2.591 | Accuracy: 0.252560 | 0.893 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 69 | Batch: 000 / 011 | Total loss: 2.844 | Reg loss: 0.032 | Tree loss: 2.844 | Accuracy: 0.222000 | 0.893 sec/iter\n",
      "Epoch: 69 | Batch: 001 / 011 | Total loss: 2.780 | Reg loss: 0.032 | Tree loss: 2.780 | Accuracy: 0.242500 | 0.893 sec/iter\n",
      "Epoch: 69 | Batch: 002 / 011 | Total loss: 2.741 | Reg loss: 0.032 | Tree loss: 2.741 | Accuracy: 0.247500 | 0.893 sec/iter\n",
      "Epoch: 69 | Batch: 003 / 011 | Total loss: 2.718 | Reg loss: 0.032 | Tree loss: 2.718 | Accuracy: 0.242000 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 004 / 011 | Total loss: 2.689 | Reg loss: 0.032 | Tree loss: 2.689 | Accuracy: 0.253000 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 005 / 011 | Total loss: 2.669 | Reg loss: 0.032 | Tree loss: 2.669 | Accuracy: 0.256000 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 006 / 011 | Total loss: 2.611 | Reg loss: 0.032 | Tree loss: 2.611 | Accuracy: 0.280500 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 007 / 011 | Total loss: 2.597 | Reg loss: 0.032 | Tree loss: 2.597 | Accuracy: 0.265000 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 008 / 011 | Total loss: 2.627 | Reg loss: 0.032 | Tree loss: 2.627 | Accuracy: 0.250000 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 009 / 011 | Total loss: 2.599 | Reg loss: 0.033 | Tree loss: 2.599 | Accuracy: 0.248500 | 0.892 sec/iter\n",
      "Epoch: 69 | Batch: 010 / 011 | Total loss: 2.548 | Reg loss: 0.033 | Tree loss: 2.548 | Accuracy: 0.269625 | 0.892 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 | Batch: 000 / 011 | Total loss: 2.815 | Reg loss: 0.032 | Tree loss: 2.815 | Accuracy: 0.224000 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 001 / 011 | Total loss: 2.797 | Reg loss: 0.032 | Tree loss: 2.797 | Accuracy: 0.213500 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 002 / 011 | Total loss: 2.771 | Reg loss: 0.032 | Tree loss: 2.771 | Accuracy: 0.242500 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 003 / 011 | Total loss: 2.705 | Reg loss: 0.032 | Tree loss: 2.705 | Accuracy: 0.246000 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 004 / 011 | Total loss: 2.671 | Reg loss: 0.032 | Tree loss: 2.671 | Accuracy: 0.263500 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 005 / 011 | Total loss: 2.640 | Reg loss: 0.032 | Tree loss: 2.640 | Accuracy: 0.262500 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 006 / 011 | Total loss: 2.633 | Reg loss: 0.032 | Tree loss: 2.633 | Accuracy: 0.279000 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 007 / 011 | Total loss: 2.585 | Reg loss: 0.033 | Tree loss: 2.585 | Accuracy: 0.291500 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 008 / 011 | Total loss: 2.619 | Reg loss: 0.033 | Tree loss: 2.619 | Accuracy: 0.247000 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 009 / 011 | Total loss: 2.569 | Reg loss: 0.033 | Tree loss: 2.569 | Accuracy: 0.258500 | 0.892 sec/iter\n",
      "Epoch: 70 | Batch: 010 / 011 | Total loss: 2.645 | Reg loss: 0.033 | Tree loss: 2.645 | Accuracy: 0.204778 | 0.891 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 71 | Batch: 000 / 011 | Total loss: 2.847 | Reg loss: 0.032 | Tree loss: 2.847 | Accuracy: 0.219500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 001 / 011 | Total loss: 2.775 | Reg loss: 0.032 | Tree loss: 2.775 | Accuracy: 0.237500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 002 / 011 | Total loss: 2.754 | Reg loss: 0.032 | Tree loss: 2.754 | Accuracy: 0.233500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 003 / 011 | Total loss: 2.695 | Reg loss: 0.032 | Tree loss: 2.695 | Accuracy: 0.256500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 004 / 011 | Total loss: 2.669 | Reg loss: 0.032 | Tree loss: 2.669 | Accuracy: 0.268500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 005 / 011 | Total loss: 2.614 | Reg loss: 0.033 | Tree loss: 2.614 | Accuracy: 0.282000 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 006 / 011 | Total loss: 2.615 | Reg loss: 0.033 | Tree loss: 2.615 | Accuracy: 0.265000 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 007 / 011 | Total loss: 2.607 | Reg loss: 0.033 | Tree loss: 2.607 | Accuracy: 0.258500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 008 / 011 | Total loss: 2.582 | Reg loss: 0.033 | Tree loss: 2.582 | Accuracy: 0.262000 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 009 / 011 | Total loss: 2.603 | Reg loss: 0.033 | Tree loss: 2.603 | Accuracy: 0.245500 | 0.891 sec/iter\n",
      "Epoch: 71 | Batch: 010 / 011 | Total loss: 2.642 | Reg loss: 0.033 | Tree loss: 2.642 | Accuracy: 0.211604 | 0.891 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 72 | Batch: 000 / 011 | Total loss: 2.849 | Reg loss: 0.033 | Tree loss: 2.849 | Accuracy: 0.214500 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 001 / 011 | Total loss: 2.785 | Reg loss: 0.033 | Tree loss: 2.785 | Accuracy: 0.222000 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 002 / 011 | Total loss: 2.751 | Reg loss: 0.033 | Tree loss: 2.751 | Accuracy: 0.238000 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 003 / 011 | Total loss: 2.687 | Reg loss: 0.033 | Tree loss: 2.687 | Accuracy: 0.282500 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 004 / 011 | Total loss: 2.675 | Reg loss: 0.033 | Tree loss: 2.675 | Accuracy: 0.267000 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 005 / 011 | Total loss: 2.620 | Reg loss: 0.033 | Tree loss: 2.620 | Accuracy: 0.282000 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 006 / 011 | Total loss: 2.608 | Reg loss: 0.033 | Tree loss: 2.608 | Accuracy: 0.276500 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 007 / 011 | Total loss: 2.601 | Reg loss: 0.033 | Tree loss: 2.601 | Accuracy: 0.265000 | 0.891 sec/iter\n",
      "Epoch: 72 | Batch: 008 / 011 | Total loss: 2.576 | Reg loss: 0.033 | Tree loss: 2.576 | Accuracy: 0.253500 | 0.89 sec/iter\n",
      "Epoch: 72 | Batch: 009 / 011 | Total loss: 2.589 | Reg loss: 0.033 | Tree loss: 2.589 | Accuracy: 0.265000 | 0.89 sec/iter\n",
      "Epoch: 72 | Batch: 010 / 011 | Total loss: 2.559 | Reg loss: 0.033 | Tree loss: 2.559 | Accuracy: 0.242321 | 0.89 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 73 | Batch: 000 / 011 | Total loss: 2.809 | Reg loss: 0.033 | Tree loss: 2.809 | Accuracy: 0.236000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 001 / 011 | Total loss: 2.804 | Reg loss: 0.033 | Tree loss: 2.804 | Accuracy: 0.206000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 002 / 011 | Total loss: 2.759 | Reg loss: 0.033 | Tree loss: 2.759 | Accuracy: 0.242500 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 003 / 011 | Total loss: 2.699 | Reg loss: 0.033 | Tree loss: 2.699 | Accuracy: 0.270000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 004 / 011 | Total loss: 2.656 | Reg loss: 0.033 | Tree loss: 2.656 | Accuracy: 0.269000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 005 / 011 | Total loss: 2.623 | Reg loss: 0.033 | Tree loss: 2.623 | Accuracy: 0.265000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 006 / 011 | Total loss: 2.600 | Reg loss: 0.033 | Tree loss: 2.600 | Accuracy: 0.289500 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 007 / 011 | Total loss: 2.564 | Reg loss: 0.033 | Tree loss: 2.564 | Accuracy: 0.272000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 008 / 011 | Total loss: 2.581 | Reg loss: 0.033 | Tree loss: 2.581 | Accuracy: 0.251500 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 009 / 011 | Total loss: 2.565 | Reg loss: 0.033 | Tree loss: 2.565 | Accuracy: 0.252000 | 0.89 sec/iter\n",
      "Epoch: 73 | Batch: 010 / 011 | Total loss: 2.539 | Reg loss: 0.033 | Tree loss: 2.539 | Accuracy: 0.228669 | 0.89 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 74 | Batch: 000 / 011 | Total loss: 2.808 | Reg loss: 0.033 | Tree loss: 2.808 | Accuracy: 0.221500 | 0.89 sec/iter\n",
      "Epoch: 74 | Batch: 001 / 011 | Total loss: 2.774 | Reg loss: 0.033 | Tree loss: 2.774 | Accuracy: 0.236500 | 0.89 sec/iter\n",
      "Epoch: 74 | Batch: 002 / 011 | Total loss: 2.722 | Reg loss: 0.033 | Tree loss: 2.722 | Accuracy: 0.259000 | 0.89 sec/iter\n",
      "Epoch: 74 | Batch: 003 / 011 | Total loss: 2.695 | Reg loss: 0.033 | Tree loss: 2.695 | Accuracy: 0.252500 | 0.89 sec/iter\n",
      "Epoch: 74 | Batch: 004 / 011 | Total loss: 2.679 | Reg loss: 0.033 | Tree loss: 2.679 | Accuracy: 0.269500 | 0.89 sec/iter\n",
      "Epoch: 74 | Batch: 005 / 011 | Total loss: 2.627 | Reg loss: 0.033 | Tree loss: 2.627 | Accuracy: 0.280500 | 0.889 sec/iter\n",
      "Epoch: 74 | Batch: 006 / 011 | Total loss: 2.591 | Reg loss: 0.033 | Tree loss: 2.591 | Accuracy: 0.281000 | 0.889 sec/iter\n",
      "Epoch: 74 | Batch: 007 / 011 | Total loss: 2.582 | Reg loss: 0.033 | Tree loss: 2.582 | Accuracy: 0.289000 | 0.889 sec/iter\n",
      "Epoch: 74 | Batch: 008 / 011 | Total loss: 2.577 | Reg loss: 0.033 | Tree loss: 2.577 | Accuracy: 0.266000 | 0.889 sec/iter\n",
      "Epoch: 74 | Batch: 009 / 011 | Total loss: 2.567 | Reg loss: 0.033 | Tree loss: 2.567 | Accuracy: 0.262500 | 0.889 sec/iter\n",
      "Epoch: 74 | Batch: 010 / 011 | Total loss: 2.563 | Reg loss: 0.033 | Tree loss: 2.563 | Accuracy: 0.242321 | 0.889 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 | Batch: 000 / 011 | Total loss: 2.813 | Reg loss: 0.033 | Tree loss: 2.813 | Accuracy: 0.231000 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 001 / 011 | Total loss: 2.782 | Reg loss: 0.033 | Tree loss: 2.782 | Accuracy: 0.233000 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 002 / 011 | Total loss: 2.750 | Reg loss: 0.033 | Tree loss: 2.750 | Accuracy: 0.243000 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 003 / 011 | Total loss: 2.675 | Reg loss: 0.033 | Tree loss: 2.675 | Accuracy: 0.264500 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 004 / 011 | Total loss: 2.626 | Reg loss: 0.033 | Tree loss: 2.626 | Accuracy: 0.270500 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 005 / 011 | Total loss: 2.610 | Reg loss: 0.033 | Tree loss: 2.610 | Accuracy: 0.274000 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 006 / 011 | Total loss: 2.597 | Reg loss: 0.033 | Tree loss: 2.597 | Accuracy: 0.278500 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 007 / 011 | Total loss: 2.574 | Reg loss: 0.033 | Tree loss: 2.574 | Accuracy: 0.277000 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 008 / 011 | Total loss: 2.586 | Reg loss: 0.033 | Tree loss: 2.586 | Accuracy: 0.244500 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 009 / 011 | Total loss: 2.549 | Reg loss: 0.033 | Tree loss: 2.549 | Accuracy: 0.271500 | 0.889 sec/iter\n",
      "Epoch: 75 | Batch: 010 / 011 | Total loss: 2.600 | Reg loss: 0.033 | Tree loss: 2.600 | Accuracy: 0.232082 | 0.889 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 76 | Batch: 000 / 011 | Total loss: 2.816 | Reg loss: 0.033 | Tree loss: 2.816 | Accuracy: 0.235500 | 0.889 sec/iter\n",
      "Epoch: 76 | Batch: 001 / 011 | Total loss: 2.754 | Reg loss: 0.033 | Tree loss: 2.754 | Accuracy: 0.247500 | 0.889 sec/iter\n",
      "Epoch: 76 | Batch: 002 / 011 | Total loss: 2.735 | Reg loss: 0.033 | Tree loss: 2.735 | Accuracy: 0.257000 | 0.889 sec/iter\n",
      "Epoch: 76 | Batch: 003 / 011 | Total loss: 2.686 | Reg loss: 0.033 | Tree loss: 2.686 | Accuracy: 0.261000 | 0.889 sec/iter\n",
      "Epoch: 76 | Batch: 004 / 011 | Total loss: 2.638 | Reg loss: 0.033 | Tree loss: 2.638 | Accuracy: 0.280000 | 0.888 sec/iter\n",
      "Epoch: 76 | Batch: 005 / 011 | Total loss: 2.616 | Reg loss: 0.033 | Tree loss: 2.616 | Accuracy: 0.271000 | 0.888 sec/iter\n",
      "Epoch: 76 | Batch: 006 / 011 | Total loss: 2.580 | Reg loss: 0.033 | Tree loss: 2.580 | Accuracy: 0.289000 | 0.888 sec/iter\n",
      "Epoch: 76 | Batch: 007 / 011 | Total loss: 2.578 | Reg loss: 0.033 | Tree loss: 2.578 | Accuracy: 0.280500 | 0.888 sec/iter\n",
      "Epoch: 76 | Batch: 008 / 011 | Total loss: 2.573 | Reg loss: 0.033 | Tree loss: 2.573 | Accuracy: 0.250000 | 0.888 sec/iter\n",
      "Epoch: 76 | Batch: 009 / 011 | Total loss: 2.547 | Reg loss: 0.033 | Tree loss: 2.547 | Accuracy: 0.268500 | 0.888 sec/iter\n",
      "Epoch: 76 | Batch: 010 / 011 | Total loss: 2.587 | Reg loss: 0.033 | Tree loss: 2.587 | Accuracy: 0.245734 | 0.888 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 77 | Batch: 000 / 011 | Total loss: 2.816 | Reg loss: 0.033 | Tree loss: 2.816 | Accuracy: 0.224500 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 001 / 011 | Total loss: 2.772 | Reg loss: 0.033 | Tree loss: 2.772 | Accuracy: 0.248000 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 002 / 011 | Total loss: 2.719 | Reg loss: 0.033 | Tree loss: 2.719 | Accuracy: 0.252000 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 003 / 011 | Total loss: 2.693 | Reg loss: 0.033 | Tree loss: 2.693 | Accuracy: 0.259500 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 004 / 011 | Total loss: 2.626 | Reg loss: 0.033 | Tree loss: 2.626 | Accuracy: 0.277000 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 005 / 011 | Total loss: 2.612 | Reg loss: 0.033 | Tree loss: 2.612 | Accuracy: 0.266500 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 006 / 011 | Total loss: 2.589 | Reg loss: 0.033 | Tree loss: 2.589 | Accuracy: 0.283000 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 007 / 011 | Total loss: 2.555 | Reg loss: 0.033 | Tree loss: 2.555 | Accuracy: 0.267500 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 008 / 011 | Total loss: 2.553 | Reg loss: 0.033 | Tree loss: 2.553 | Accuracy: 0.276500 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 009 / 011 | Total loss: 2.537 | Reg loss: 0.033 | Tree loss: 2.537 | Accuracy: 0.265000 | 0.888 sec/iter\n",
      "Epoch: 77 | Batch: 010 / 011 | Total loss: 2.536 | Reg loss: 0.033 | Tree loss: 2.536 | Accuracy: 0.290102 | 0.888 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 78 | Batch: 000 / 011 | Total loss: 2.785 | Reg loss: 0.033 | Tree loss: 2.785 | Accuracy: 0.242500 | 0.888 sec/iter\n",
      "Epoch: 78 | Batch: 001 / 011 | Total loss: 2.750 | Reg loss: 0.033 | Tree loss: 2.750 | Accuracy: 0.248000 | 0.888 sec/iter\n",
      "Epoch: 78 | Batch: 002 / 011 | Total loss: 2.695 | Reg loss: 0.033 | Tree loss: 2.695 | Accuracy: 0.245500 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 003 / 011 | Total loss: 2.664 | Reg loss: 0.033 | Tree loss: 2.664 | Accuracy: 0.271000 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 004 / 011 | Total loss: 2.647 | Reg loss: 0.033 | Tree loss: 2.647 | Accuracy: 0.275500 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 005 / 011 | Total loss: 2.599 | Reg loss: 0.033 | Tree loss: 2.599 | Accuracy: 0.279500 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 006 / 011 | Total loss: 2.603 | Reg loss: 0.033 | Tree loss: 2.603 | Accuracy: 0.268000 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 007 / 011 | Total loss: 2.574 | Reg loss: 0.033 | Tree loss: 2.574 | Accuracy: 0.258500 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 008 / 011 | Total loss: 2.550 | Reg loss: 0.033 | Tree loss: 2.550 | Accuracy: 0.273500 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 009 / 011 | Total loss: 2.562 | Reg loss: 0.033 | Tree loss: 2.562 | Accuracy: 0.265000 | 0.887 sec/iter\n",
      "Epoch: 78 | Batch: 010 / 011 | Total loss: 2.543 | Reg loss: 0.033 | Tree loss: 2.543 | Accuracy: 0.262799 | 0.887 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 79 | Batch: 000 / 011 | Total loss: 2.779 | Reg loss: 0.033 | Tree loss: 2.779 | Accuracy: 0.232500 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 001 / 011 | Total loss: 2.745 | Reg loss: 0.033 | Tree loss: 2.745 | Accuracy: 0.232500 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 002 / 011 | Total loss: 2.707 | Reg loss: 0.033 | Tree loss: 2.707 | Accuracy: 0.272000 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 003 / 011 | Total loss: 2.680 | Reg loss: 0.033 | Tree loss: 2.680 | Accuracy: 0.263500 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 004 / 011 | Total loss: 2.635 | Reg loss: 0.033 | Tree loss: 2.635 | Accuracy: 0.284500 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 005 / 011 | Total loss: 2.598 | Reg loss: 0.033 | Tree loss: 2.598 | Accuracy: 0.280000 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 006 / 011 | Total loss: 2.575 | Reg loss: 0.033 | Tree loss: 2.575 | Accuracy: 0.280000 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 007 / 011 | Total loss: 2.564 | Reg loss: 0.033 | Tree loss: 2.564 | Accuracy: 0.281500 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 008 / 011 | Total loss: 2.521 | Reg loss: 0.033 | Tree loss: 2.521 | Accuracy: 0.270500 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 009 / 011 | Total loss: 2.554 | Reg loss: 0.033 | Tree loss: 2.554 | Accuracy: 0.243000 | 0.887 sec/iter\n",
      "Epoch: 79 | Batch: 010 / 011 | Total loss: 2.602 | Reg loss: 0.033 | Tree loss: 2.602 | Accuracy: 0.225256 | 0.887 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Batch: 000 / 011 | Total loss: 2.793 | Reg loss: 0.033 | Tree loss: 2.793 | Accuracy: 0.212000 | 0.887 sec/iter\n",
      "Epoch: 80 | Batch: 001 / 011 | Total loss: 2.763 | Reg loss: 0.033 | Tree loss: 2.763 | Accuracy: 0.241000 | 0.887 sec/iter\n",
      "Epoch: 80 | Batch: 002 / 011 | Total loss: 2.722 | Reg loss: 0.033 | Tree loss: 2.722 | Accuracy: 0.259000 | 0.887 sec/iter\n",
      "Epoch: 80 | Batch: 003 / 011 | Total loss: 2.647 | Reg loss: 0.033 | Tree loss: 2.647 | Accuracy: 0.281000 | 0.887 sec/iter\n",
      "Epoch: 80 | Batch: 004 / 011 | Total loss: 2.628 | Reg loss: 0.033 | Tree loss: 2.628 | Accuracy: 0.277500 | 0.887 sec/iter\n",
      "Epoch: 80 | Batch: 005 / 011 | Total loss: 2.592 | Reg loss: 0.033 | Tree loss: 2.592 | Accuracy: 0.292500 | 0.886 sec/iter\n",
      "Epoch: 80 | Batch: 006 / 011 | Total loss: 2.576 | Reg loss: 0.033 | Tree loss: 2.576 | Accuracy: 0.294000 | 0.886 sec/iter\n",
      "Epoch: 80 | Batch: 007 / 011 | Total loss: 2.561 | Reg loss: 0.033 | Tree loss: 2.561 | Accuracy: 0.273500 | 0.886 sec/iter\n",
      "Epoch: 80 | Batch: 008 / 011 | Total loss: 2.536 | Reg loss: 0.033 | Tree loss: 2.536 | Accuracy: 0.270500 | 0.886 sec/iter\n",
      "Epoch: 80 | Batch: 009 / 011 | Total loss: 2.548 | Reg loss: 0.033 | Tree loss: 2.548 | Accuracy: 0.277000 | 0.886 sec/iter\n",
      "Epoch: 80 | Batch: 010 / 011 | Total loss: 2.507 | Reg loss: 0.033 | Tree loss: 2.507 | Accuracy: 0.225256 | 0.886 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 81 | Batch: 000 / 011 | Total loss: 2.769 | Reg loss: 0.033 | Tree loss: 2.769 | Accuracy: 0.251500 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 001 / 011 | Total loss: 2.742 | Reg loss: 0.033 | Tree loss: 2.742 | Accuracy: 0.231500 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 002 / 011 | Total loss: 2.712 | Reg loss: 0.033 | Tree loss: 2.712 | Accuracy: 0.264000 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 003 / 011 | Total loss: 2.678 | Reg loss: 0.033 | Tree loss: 2.678 | Accuracy: 0.267000 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 004 / 011 | Total loss: 2.620 | Reg loss: 0.033 | Tree loss: 2.620 | Accuracy: 0.283000 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 005 / 011 | Total loss: 2.594 | Reg loss: 0.033 | Tree loss: 2.594 | Accuracy: 0.282500 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 006 / 011 | Total loss: 2.582 | Reg loss: 0.033 | Tree loss: 2.582 | Accuracy: 0.288500 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 007 / 011 | Total loss: 2.539 | Reg loss: 0.033 | Tree loss: 2.539 | Accuracy: 0.271000 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 008 / 011 | Total loss: 2.542 | Reg loss: 0.033 | Tree loss: 2.542 | Accuracy: 0.271500 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 009 / 011 | Total loss: 2.533 | Reg loss: 0.034 | Tree loss: 2.533 | Accuracy: 0.273500 | 0.886 sec/iter\n",
      "Epoch: 81 | Batch: 010 / 011 | Total loss: 2.556 | Reg loss: 0.034 | Tree loss: 2.556 | Accuracy: 0.242321 | 0.886 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 82 | Batch: 000 / 011 | Total loss: 2.766 | Reg loss: 0.033 | Tree loss: 2.766 | Accuracy: 0.253500 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 001 / 011 | Total loss: 2.708 | Reg loss: 0.033 | Tree loss: 2.708 | Accuracy: 0.249500 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 002 / 011 | Total loss: 2.704 | Reg loss: 0.033 | Tree loss: 2.704 | Accuracy: 0.262500 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 003 / 011 | Total loss: 2.655 | Reg loss: 0.033 | Tree loss: 2.655 | Accuracy: 0.289500 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 004 / 011 | Total loss: 2.626 | Reg loss: 0.033 | Tree loss: 2.626 | Accuracy: 0.263000 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 005 / 011 | Total loss: 2.598 | Reg loss: 0.033 | Tree loss: 2.598 | Accuracy: 0.284500 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 006 / 011 | Total loss: 2.566 | Reg loss: 0.033 | Tree loss: 2.566 | Accuracy: 0.271000 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 007 / 011 | Total loss: 2.542 | Reg loss: 0.034 | Tree loss: 2.542 | Accuracy: 0.271000 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 008 / 011 | Total loss: 2.550 | Reg loss: 0.034 | Tree loss: 2.550 | Accuracy: 0.265000 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 009 / 011 | Total loss: 2.537 | Reg loss: 0.034 | Tree loss: 2.537 | Accuracy: 0.263500 | 0.886 sec/iter\n",
      "Epoch: 82 | Batch: 010 / 011 | Total loss: 2.569 | Reg loss: 0.034 | Tree loss: 2.569 | Accuracy: 0.245734 | 0.885 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 83 | Batch: 000 / 011 | Total loss: 2.768 | Reg loss: 0.033 | Tree loss: 2.768 | Accuracy: 0.244500 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 001 / 011 | Total loss: 2.736 | Reg loss: 0.033 | Tree loss: 2.736 | Accuracy: 0.239000 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 002 / 011 | Total loss: 2.684 | Reg loss: 0.033 | Tree loss: 2.684 | Accuracy: 0.262000 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 003 / 011 | Total loss: 2.649 | Reg loss: 0.033 | Tree loss: 2.649 | Accuracy: 0.262500 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 004 / 011 | Total loss: 2.614 | Reg loss: 0.033 | Tree loss: 2.614 | Accuracy: 0.277500 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 005 / 011 | Total loss: 2.593 | Reg loss: 0.034 | Tree loss: 2.593 | Accuracy: 0.292000 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 006 / 011 | Total loss: 2.550 | Reg loss: 0.034 | Tree loss: 2.550 | Accuracy: 0.294000 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 007 / 011 | Total loss: 2.556 | Reg loss: 0.034 | Tree loss: 2.556 | Accuracy: 0.264500 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 008 / 011 | Total loss: 2.543 | Reg loss: 0.034 | Tree loss: 2.543 | Accuracy: 0.265000 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 009 / 011 | Total loss: 2.531 | Reg loss: 0.034 | Tree loss: 2.531 | Accuracy: 0.271500 | 0.885 sec/iter\n",
      "Epoch: 83 | Batch: 010 / 011 | Total loss: 2.508 | Reg loss: 0.034 | Tree loss: 2.508 | Accuracy: 0.296928 | 0.885 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 84 | Batch: 000 / 011 | Total loss: 2.745 | Reg loss: 0.033 | Tree loss: 2.745 | Accuracy: 0.251000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 001 / 011 | Total loss: 2.750 | Reg loss: 0.034 | Tree loss: 2.750 | Accuracy: 0.242000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 002 / 011 | Total loss: 2.691 | Reg loss: 0.034 | Tree loss: 2.691 | Accuracy: 0.260500 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 003 / 011 | Total loss: 2.639 | Reg loss: 0.034 | Tree loss: 2.639 | Accuracy: 0.281000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 004 / 011 | Total loss: 2.618 | Reg loss: 0.034 | Tree loss: 2.618 | Accuracy: 0.271000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 005 / 011 | Total loss: 2.584 | Reg loss: 0.034 | Tree loss: 2.584 | Accuracy: 0.282500 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 006 / 011 | Total loss: 2.563 | Reg loss: 0.034 | Tree loss: 2.563 | Accuracy: 0.273500 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 007 / 011 | Total loss: 2.539 | Reg loss: 0.034 | Tree loss: 2.539 | Accuracy: 0.275000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 008 / 011 | Total loss: 2.524 | Reg loss: 0.034 | Tree loss: 2.524 | Accuracy: 0.283000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 009 / 011 | Total loss: 2.525 | Reg loss: 0.034 | Tree loss: 2.525 | Accuracy: 0.273000 | 0.885 sec/iter\n",
      "Epoch: 84 | Batch: 010 / 011 | Total loss: 2.554 | Reg loss: 0.034 | Tree loss: 2.554 | Accuracy: 0.242321 | 0.884 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 | Batch: 000 / 011 | Total loss: 2.781 | Reg loss: 0.034 | Tree loss: 2.781 | Accuracy: 0.253000 | 0.885 sec/iter\n",
      "Epoch: 85 | Batch: 001 / 011 | Total loss: 2.739 | Reg loss: 0.034 | Tree loss: 2.739 | Accuracy: 0.241500 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 002 / 011 | Total loss: 2.689 | Reg loss: 0.034 | Tree loss: 2.689 | Accuracy: 0.269500 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 003 / 011 | Total loss: 2.631 | Reg loss: 0.034 | Tree loss: 2.631 | Accuracy: 0.291500 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 004 / 011 | Total loss: 2.611 | Reg loss: 0.034 | Tree loss: 2.611 | Accuracy: 0.261000 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 005 / 011 | Total loss: 2.586 | Reg loss: 0.034 | Tree loss: 2.586 | Accuracy: 0.256000 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 006 / 011 | Total loss: 2.559 | Reg loss: 0.034 | Tree loss: 2.559 | Accuracy: 0.278500 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 007 / 011 | Total loss: 2.536 | Reg loss: 0.034 | Tree loss: 2.536 | Accuracy: 0.279000 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 008 / 011 | Total loss: 2.502 | Reg loss: 0.034 | Tree loss: 2.502 | Accuracy: 0.271500 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 009 / 011 | Total loss: 2.522 | Reg loss: 0.034 | Tree loss: 2.522 | Accuracy: 0.255500 | 0.884 sec/iter\n",
      "Epoch: 85 | Batch: 010 / 011 | Total loss: 2.502 | Reg loss: 0.034 | Tree loss: 2.502 | Accuracy: 0.273038 | 0.884 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 86 | Batch: 000 / 011 | Total loss: 2.749 | Reg loss: 0.034 | Tree loss: 2.749 | Accuracy: 0.261000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 001 / 011 | Total loss: 2.725 | Reg loss: 0.034 | Tree loss: 2.725 | Accuracy: 0.270500 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 002 / 011 | Total loss: 2.711 | Reg loss: 0.034 | Tree loss: 2.711 | Accuracy: 0.261000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 003 / 011 | Total loss: 2.655 | Reg loss: 0.034 | Tree loss: 2.655 | Accuracy: 0.283000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 004 / 011 | Total loss: 2.635 | Reg loss: 0.034 | Tree loss: 2.635 | Accuracy: 0.262000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 005 / 011 | Total loss: 2.564 | Reg loss: 0.034 | Tree loss: 2.564 | Accuracy: 0.295000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 006 / 011 | Total loss: 2.554 | Reg loss: 0.034 | Tree loss: 2.554 | Accuracy: 0.266500 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 007 / 011 | Total loss: 2.508 | Reg loss: 0.034 | Tree loss: 2.508 | Accuracy: 0.284000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 008 / 011 | Total loss: 2.524 | Reg loss: 0.034 | Tree loss: 2.524 | Accuracy: 0.267000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 009 / 011 | Total loss: 2.506 | Reg loss: 0.034 | Tree loss: 2.506 | Accuracy: 0.279000 | 0.884 sec/iter\n",
      "Epoch: 86 | Batch: 010 / 011 | Total loss: 2.517 | Reg loss: 0.034 | Tree loss: 2.517 | Accuracy: 0.232082 | 0.884 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 87 | Batch: 000 / 011 | Total loss: 2.762 | Reg loss: 0.034 | Tree loss: 2.762 | Accuracy: 0.259000 | 0.884 sec/iter\n",
      "Epoch: 87 | Batch: 001 / 011 | Total loss: 2.703 | Reg loss: 0.034 | Tree loss: 2.703 | Accuracy: 0.263000 | 0.884 sec/iter\n",
      "Epoch: 87 | Batch: 002 / 011 | Total loss: 2.673 | Reg loss: 0.034 | Tree loss: 2.673 | Accuracy: 0.270500 | 0.884 sec/iter\n",
      "Epoch: 87 | Batch: 003 / 011 | Total loss: 2.635 | Reg loss: 0.034 | Tree loss: 2.635 | Accuracy: 0.275000 | 0.884 sec/iter\n",
      "Epoch: 87 | Batch: 004 / 011 | Total loss: 2.594 | Reg loss: 0.034 | Tree loss: 2.594 | Accuracy: 0.290000 | 0.883 sec/iter\n",
      "Epoch: 87 | Batch: 005 / 011 | Total loss: 2.551 | Reg loss: 0.034 | Tree loss: 2.551 | Accuracy: 0.301000 | 0.883 sec/iter\n",
      "Epoch: 87 | Batch: 006 / 011 | Total loss: 2.556 | Reg loss: 0.034 | Tree loss: 2.556 | Accuracy: 0.269500 | 0.883 sec/iter\n",
      "Epoch: 87 | Batch: 007 / 011 | Total loss: 2.538 | Reg loss: 0.034 | Tree loss: 2.538 | Accuracy: 0.265500 | 0.883 sec/iter\n",
      "Epoch: 87 | Batch: 008 / 011 | Total loss: 2.524 | Reg loss: 0.034 | Tree loss: 2.524 | Accuracy: 0.255000 | 0.883 sec/iter\n",
      "Epoch: 87 | Batch: 009 / 011 | Total loss: 2.525 | Reg loss: 0.034 | Tree loss: 2.525 | Accuracy: 0.264000 | 0.883 sec/iter\n",
      "Epoch: 87 | Batch: 010 / 011 | Total loss: 2.534 | Reg loss: 0.034 | Tree loss: 2.534 | Accuracy: 0.218430 | 0.883 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 88 | Batch: 000 / 011 | Total loss: 2.750 | Reg loss: 0.034 | Tree loss: 2.750 | Accuracy: 0.257500 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 001 / 011 | Total loss: 2.717 | Reg loss: 0.034 | Tree loss: 2.717 | Accuracy: 0.264500 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 002 / 011 | Total loss: 2.661 | Reg loss: 0.034 | Tree loss: 2.661 | Accuracy: 0.283500 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 003 / 011 | Total loss: 2.647 | Reg loss: 0.034 | Tree loss: 2.647 | Accuracy: 0.275000 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 004 / 011 | Total loss: 2.603 | Reg loss: 0.034 | Tree loss: 2.603 | Accuracy: 0.265500 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 005 / 011 | Total loss: 2.550 | Reg loss: 0.034 | Tree loss: 2.550 | Accuracy: 0.299000 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 006 / 011 | Total loss: 2.567 | Reg loss: 0.034 | Tree loss: 2.567 | Accuracy: 0.271500 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 007 / 011 | Total loss: 2.517 | Reg loss: 0.034 | Tree loss: 2.517 | Accuracy: 0.297000 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 008 / 011 | Total loss: 2.518 | Reg loss: 0.034 | Tree loss: 2.518 | Accuracy: 0.268000 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 009 / 011 | Total loss: 2.525 | Reg loss: 0.034 | Tree loss: 2.525 | Accuracy: 0.267500 | 0.883 sec/iter\n",
      "Epoch: 88 | Batch: 010 / 011 | Total loss: 2.502 | Reg loss: 0.034 | Tree loss: 2.502 | Accuracy: 0.266212 | 0.883 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 89 | Batch: 000 / 011 | Total loss: 2.741 | Reg loss: 0.034 | Tree loss: 2.741 | Accuracy: 0.263000 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 001 / 011 | Total loss: 2.709 | Reg loss: 0.034 | Tree loss: 2.709 | Accuracy: 0.256500 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 002 / 011 | Total loss: 2.658 | Reg loss: 0.034 | Tree loss: 2.658 | Accuracy: 0.267000 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 003 / 011 | Total loss: 2.664 | Reg loss: 0.034 | Tree loss: 2.664 | Accuracy: 0.247500 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 004 / 011 | Total loss: 2.599 | Reg loss: 0.034 | Tree loss: 2.599 | Accuracy: 0.283000 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 005 / 011 | Total loss: 2.548 | Reg loss: 0.034 | Tree loss: 2.548 | Accuracy: 0.305000 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 006 / 011 | Total loss: 2.538 | Reg loss: 0.034 | Tree loss: 2.538 | Accuracy: 0.282000 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 007 / 011 | Total loss: 2.526 | Reg loss: 0.034 | Tree loss: 2.526 | Accuracy: 0.264500 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 008 / 011 | Total loss: 2.524 | Reg loss: 0.034 | Tree loss: 2.524 | Accuracy: 0.253000 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 009 / 011 | Total loss: 2.508 | Reg loss: 0.034 | Tree loss: 2.508 | Accuracy: 0.281500 | 0.883 sec/iter\n",
      "Epoch: 89 | Batch: 010 / 011 | Total loss: 2.521 | Reg loss: 0.034 | Tree loss: 2.521 | Accuracy: 0.279863 | 0.882 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | Batch: 000 / 011 | Total loss: 2.765 | Reg loss: 0.034 | Tree loss: 2.765 | Accuracy: 0.245500 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 001 / 011 | Total loss: 2.716 | Reg loss: 0.034 | Tree loss: 2.716 | Accuracy: 0.250500 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 002 / 011 | Total loss: 2.671 | Reg loss: 0.034 | Tree loss: 2.671 | Accuracy: 0.275000 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 003 / 011 | Total loss: 2.608 | Reg loss: 0.034 | Tree loss: 2.608 | Accuracy: 0.300000 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 004 / 011 | Total loss: 2.598 | Reg loss: 0.034 | Tree loss: 2.598 | Accuracy: 0.275500 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 005 / 011 | Total loss: 2.568 | Reg loss: 0.034 | Tree loss: 2.568 | Accuracy: 0.272500 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 006 / 011 | Total loss: 2.553 | Reg loss: 0.034 | Tree loss: 2.553 | Accuracy: 0.280500 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 007 / 011 | Total loss: 2.520 | Reg loss: 0.034 | Tree loss: 2.520 | Accuracy: 0.270000 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 008 / 011 | Total loss: 2.488 | Reg loss: 0.034 | Tree loss: 2.488 | Accuracy: 0.292500 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 009 / 011 | Total loss: 2.498 | Reg loss: 0.034 | Tree loss: 2.498 | Accuracy: 0.273000 | 0.882 sec/iter\n",
      "Epoch: 90 | Batch: 010 / 011 | Total loss: 2.434 | Reg loss: 0.034 | Tree loss: 2.434 | Accuracy: 0.303754 | 0.882 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 91 | Batch: 000 / 011 | Total loss: 2.735 | Reg loss: 0.034 | Tree loss: 2.735 | Accuracy: 0.261000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 001 / 011 | Total loss: 2.721 | Reg loss: 0.034 | Tree loss: 2.721 | Accuracy: 0.244500 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 002 / 011 | Total loss: 2.656 | Reg loss: 0.034 | Tree loss: 2.656 | Accuracy: 0.271000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 003 / 011 | Total loss: 2.614 | Reg loss: 0.034 | Tree loss: 2.614 | Accuracy: 0.297000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 004 / 011 | Total loss: 2.575 | Reg loss: 0.034 | Tree loss: 2.575 | Accuracy: 0.255500 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 005 / 011 | Total loss: 2.540 | Reg loss: 0.034 | Tree loss: 2.540 | Accuracy: 0.270000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 006 / 011 | Total loss: 2.540 | Reg loss: 0.034 | Tree loss: 2.540 | Accuracy: 0.277000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 007 / 011 | Total loss: 2.534 | Reg loss: 0.034 | Tree loss: 2.534 | Accuracy: 0.262000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 008 / 011 | Total loss: 2.518 | Reg loss: 0.034 | Tree loss: 2.518 | Accuracy: 0.260000 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 009 / 011 | Total loss: 2.510 | Reg loss: 0.034 | Tree loss: 2.510 | Accuracy: 0.269500 | 0.882 sec/iter\n",
      "Epoch: 91 | Batch: 010 / 011 | Total loss: 2.537 | Reg loss: 0.034 | Tree loss: 2.537 | Accuracy: 0.225256 | 0.882 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 92 | Batch: 000 / 011 | Total loss: 2.731 | Reg loss: 0.034 | Tree loss: 2.731 | Accuracy: 0.261000 | 0.882 sec/iter\n",
      "Epoch: 92 | Batch: 001 / 011 | Total loss: 2.701 | Reg loss: 0.034 | Tree loss: 2.701 | Accuracy: 0.257500 | 0.882 sec/iter\n",
      "Epoch: 92 | Batch: 002 / 011 | Total loss: 2.661 | Reg loss: 0.034 | Tree loss: 2.661 | Accuracy: 0.286000 | 0.882 sec/iter\n",
      "Epoch: 92 | Batch: 003 / 011 | Total loss: 2.636 | Reg loss: 0.034 | Tree loss: 2.636 | Accuracy: 0.280000 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 004 / 011 | Total loss: 2.583 | Reg loss: 0.034 | Tree loss: 2.583 | Accuracy: 0.285000 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 005 / 011 | Total loss: 2.565 | Reg loss: 0.034 | Tree loss: 2.565 | Accuracy: 0.282500 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 006 / 011 | Total loss: 2.531 | Reg loss: 0.034 | Tree loss: 2.531 | Accuracy: 0.293500 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 007 / 011 | Total loss: 2.509 | Reg loss: 0.034 | Tree loss: 2.509 | Accuracy: 0.283000 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 008 / 011 | Total loss: 2.514 | Reg loss: 0.034 | Tree loss: 2.514 | Accuracy: 0.257500 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 009 / 011 | Total loss: 2.484 | Reg loss: 0.034 | Tree loss: 2.484 | Accuracy: 0.269500 | 0.881 sec/iter\n",
      "Epoch: 92 | Batch: 010 / 011 | Total loss: 2.514 | Reg loss: 0.034 | Tree loss: 2.514 | Accuracy: 0.218430 | 0.881 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 93 | Batch: 000 / 011 | Total loss: 2.737 | Reg loss: 0.034 | Tree loss: 2.737 | Accuracy: 0.254000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 001 / 011 | Total loss: 2.689 | Reg loss: 0.034 | Tree loss: 2.689 | Accuracy: 0.266500 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 002 / 011 | Total loss: 2.675 | Reg loss: 0.034 | Tree loss: 2.675 | Accuracy: 0.262000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 003 / 011 | Total loss: 2.626 | Reg loss: 0.034 | Tree loss: 2.626 | Accuracy: 0.277000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 004 / 011 | Total loss: 2.568 | Reg loss: 0.034 | Tree loss: 2.568 | Accuracy: 0.275000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 005 / 011 | Total loss: 2.572 | Reg loss: 0.034 | Tree loss: 2.572 | Accuracy: 0.270500 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 006 / 011 | Total loss: 2.533 | Reg loss: 0.034 | Tree loss: 2.533 | Accuracy: 0.274500 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 007 / 011 | Total loss: 2.502 | Reg loss: 0.034 | Tree loss: 2.502 | Accuracy: 0.263000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 008 / 011 | Total loss: 2.496 | Reg loss: 0.034 | Tree loss: 2.496 | Accuracy: 0.280000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 009 / 011 | Total loss: 2.498 | Reg loss: 0.034 | Tree loss: 2.498 | Accuracy: 0.265000 | 0.881 sec/iter\n",
      "Epoch: 93 | Batch: 010 / 011 | Total loss: 2.518 | Reg loss: 0.034 | Tree loss: 2.518 | Accuracy: 0.259386 | 0.881 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 94 | Batch: 000 / 011 | Total loss: 2.729 | Reg loss: 0.034 | Tree loss: 2.729 | Accuracy: 0.263000 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 001 / 011 | Total loss: 2.709 | Reg loss: 0.034 | Tree loss: 2.709 | Accuracy: 0.260500 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 002 / 011 | Total loss: 2.655 | Reg loss: 0.034 | Tree loss: 2.655 | Accuracy: 0.265500 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 003 / 011 | Total loss: 2.620 | Reg loss: 0.034 | Tree loss: 2.620 | Accuracy: 0.298000 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 004 / 011 | Total loss: 2.567 | Reg loss: 0.034 | Tree loss: 2.567 | Accuracy: 0.281500 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 005 / 011 | Total loss: 2.548 | Reg loss: 0.034 | Tree loss: 2.548 | Accuracy: 0.309500 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 006 / 011 | Total loss: 2.507 | Reg loss: 0.034 | Tree loss: 2.507 | Accuracy: 0.272000 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 007 / 011 | Total loss: 2.526 | Reg loss: 0.034 | Tree loss: 2.526 | Accuracy: 0.270500 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 008 / 011 | Total loss: 2.497 | Reg loss: 0.034 | Tree loss: 2.497 | Accuracy: 0.280000 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 009 / 011 | Total loss: 2.495 | Reg loss: 0.035 | Tree loss: 2.495 | Accuracy: 0.271000 | 0.881 sec/iter\n",
      "Epoch: 94 | Batch: 010 / 011 | Total loss: 2.444 | Reg loss: 0.035 | Tree loss: 2.444 | Accuracy: 0.283276 | 0.88 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95 | Batch: 000 / 011 | Total loss: 2.742 | Reg loss: 0.034 | Tree loss: 2.742 | Accuracy: 0.257500 | 0.881 sec/iter\n",
      "Epoch: 95 | Batch: 001 / 011 | Total loss: 2.680 | Reg loss: 0.034 | Tree loss: 2.680 | Accuracy: 0.264000 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 002 / 011 | Total loss: 2.649 | Reg loss: 0.034 | Tree loss: 2.649 | Accuracy: 0.274000 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 003 / 011 | Total loss: 2.621 | Reg loss: 0.034 | Tree loss: 2.621 | Accuracy: 0.269500 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 004 / 011 | Total loss: 2.567 | Reg loss: 0.034 | Tree loss: 2.567 | Accuracy: 0.283500 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 005 / 011 | Total loss: 2.531 | Reg loss: 0.034 | Tree loss: 2.531 | Accuracy: 0.289500 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 006 / 011 | Total loss: 2.533 | Reg loss: 0.034 | Tree loss: 2.533 | Accuracy: 0.267000 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 007 / 011 | Total loss: 2.491 | Reg loss: 0.035 | Tree loss: 2.491 | Accuracy: 0.286000 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 008 / 011 | Total loss: 2.502 | Reg loss: 0.035 | Tree loss: 2.502 | Accuracy: 0.265500 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 009 / 011 | Total loss: 2.503 | Reg loss: 0.035 | Tree loss: 2.503 | Accuracy: 0.257000 | 0.88 sec/iter\n",
      "Epoch: 95 | Batch: 010 / 011 | Total loss: 2.533 | Reg loss: 0.035 | Tree loss: 2.533 | Accuracy: 0.255973 | 0.88 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 96 | Batch: 000 / 011 | Total loss: 2.746 | Reg loss: 0.034 | Tree loss: 2.746 | Accuracy: 0.255500 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 001 / 011 | Total loss: 2.691 | Reg loss: 0.034 | Tree loss: 2.691 | Accuracy: 0.257000 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 002 / 011 | Total loss: 2.648 | Reg loss: 0.034 | Tree loss: 2.648 | Accuracy: 0.280000 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 003 / 011 | Total loss: 2.628 | Reg loss: 0.034 | Tree loss: 2.628 | Accuracy: 0.265500 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 004 / 011 | Total loss: 2.561 | Reg loss: 0.034 | Tree loss: 2.561 | Accuracy: 0.295000 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 005 / 011 | Total loss: 2.549 | Reg loss: 0.034 | Tree loss: 2.549 | Accuracy: 0.287000 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 006 / 011 | Total loss: 2.503 | Reg loss: 0.035 | Tree loss: 2.503 | Accuracy: 0.283500 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 007 / 011 | Total loss: 2.503 | Reg loss: 0.035 | Tree loss: 2.503 | Accuracy: 0.293500 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 008 / 011 | Total loss: 2.491 | Reg loss: 0.035 | Tree loss: 2.491 | Accuracy: 0.280000 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 009 / 011 | Total loss: 2.459 | Reg loss: 0.035 | Tree loss: 2.459 | Accuracy: 0.264000 | 0.88 sec/iter\n",
      "Epoch: 96 | Batch: 010 / 011 | Total loss: 2.505 | Reg loss: 0.035 | Tree loss: 2.505 | Accuracy: 0.208191 | 0.88 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 97 | Batch: 000 / 011 | Total loss: 2.720 | Reg loss: 0.034 | Tree loss: 2.720 | Accuracy: 0.256000 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 001 / 011 | Total loss: 2.694 | Reg loss: 0.034 | Tree loss: 2.694 | Accuracy: 0.247000 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 002 / 011 | Total loss: 2.651 | Reg loss: 0.035 | Tree loss: 2.651 | Accuracy: 0.278500 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 003 / 011 | Total loss: 2.598 | Reg loss: 0.035 | Tree loss: 2.598 | Accuracy: 0.282000 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 004 / 011 | Total loss: 2.570 | Reg loss: 0.035 | Tree loss: 2.570 | Accuracy: 0.289000 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 005 / 011 | Total loss: 2.538 | Reg loss: 0.035 | Tree loss: 2.538 | Accuracy: 0.283000 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 006 / 011 | Total loss: 2.511 | Reg loss: 0.035 | Tree loss: 2.511 | Accuracy: 0.286500 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 007 / 011 | Total loss: 2.458 | Reg loss: 0.035 | Tree loss: 2.458 | Accuracy: 0.286500 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 008 / 011 | Total loss: 2.510 | Reg loss: 0.035 | Tree loss: 2.510 | Accuracy: 0.249500 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 009 / 011 | Total loss: 2.509 | Reg loss: 0.035 | Tree loss: 2.509 | Accuracy: 0.244500 | 0.88 sec/iter\n",
      "Epoch: 97 | Batch: 010 / 011 | Total loss: 2.515 | Reg loss: 0.035 | Tree loss: 2.515 | Accuracy: 0.218430 | 0.88 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 98 | Batch: 000 / 011 | Total loss: 2.712 | Reg loss: 0.035 | Tree loss: 2.712 | Accuracy: 0.258000 | 0.88 sec/iter\n",
      "Epoch: 98 | Batch: 001 / 011 | Total loss: 2.683 | Reg loss: 0.035 | Tree loss: 2.683 | Accuracy: 0.268000 | 0.88 sec/iter\n",
      "Epoch: 98 | Batch: 002 / 011 | Total loss: 2.644 | Reg loss: 0.035 | Tree loss: 2.644 | Accuracy: 0.274000 | 0.88 sec/iter\n",
      "Epoch: 98 | Batch: 003 / 011 | Total loss: 2.618 | Reg loss: 0.035 | Tree loss: 2.618 | Accuracy: 0.274500 | 0.88 sec/iter\n",
      "Epoch: 98 | Batch: 004 / 011 | Total loss: 2.541 | Reg loss: 0.035 | Tree loss: 2.541 | Accuracy: 0.308500 | 0.879 sec/iter\n",
      "Epoch: 98 | Batch: 005 / 011 | Total loss: 2.524 | Reg loss: 0.035 | Tree loss: 2.524 | Accuracy: 0.313500 | 0.879 sec/iter\n",
      "Epoch: 98 | Batch: 006 / 011 | Total loss: 2.507 | Reg loss: 0.035 | Tree loss: 2.507 | Accuracy: 0.280000 | 0.879 sec/iter\n",
      "Epoch: 98 | Batch: 007 / 011 | Total loss: 2.529 | Reg loss: 0.035 | Tree loss: 2.529 | Accuracy: 0.280000 | 0.879 sec/iter\n",
      "Epoch: 98 | Batch: 008 / 011 | Total loss: 2.505 | Reg loss: 0.035 | Tree loss: 2.505 | Accuracy: 0.263000 | 0.879 sec/iter\n",
      "Epoch: 98 | Batch: 009 / 011 | Total loss: 2.488 | Reg loss: 0.035 | Tree loss: 2.488 | Accuracy: 0.271500 | 0.879 sec/iter\n",
      "Epoch: 98 | Batch: 010 / 011 | Total loss: 2.459 | Reg loss: 0.035 | Tree loss: 2.459 | Accuracy: 0.262799 | 0.879 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 99 | Batch: 000 / 011 | Total loss: 2.715 | Reg loss: 0.035 | Tree loss: 2.715 | Accuracy: 0.261500 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 001 / 011 | Total loss: 2.682 | Reg loss: 0.035 | Tree loss: 2.682 | Accuracy: 0.256000 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 002 / 011 | Total loss: 2.665 | Reg loss: 0.035 | Tree loss: 2.665 | Accuracy: 0.269000 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 003 / 011 | Total loss: 2.609 | Reg loss: 0.035 | Tree loss: 2.609 | Accuracy: 0.274000 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 004 / 011 | Total loss: 2.576 | Reg loss: 0.035 | Tree loss: 2.576 | Accuracy: 0.278500 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 005 / 011 | Total loss: 2.529 | Reg loss: 0.035 | Tree loss: 2.529 | Accuracy: 0.285500 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 006 / 011 | Total loss: 2.508 | Reg loss: 0.035 | Tree loss: 2.508 | Accuracy: 0.259500 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 007 / 011 | Total loss: 2.497 | Reg loss: 0.035 | Tree loss: 2.497 | Accuracy: 0.256000 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 008 / 011 | Total loss: 2.481 | Reg loss: 0.035 | Tree loss: 2.481 | Accuracy: 0.255500 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 009 / 011 | Total loss: 2.463 | Reg loss: 0.035 | Tree loss: 2.463 | Accuracy: 0.270500 | 0.879 sec/iter\n",
      "Epoch: 99 | Batch: 010 / 011 | Total loss: 2.448 | Reg loss: 0.035 | Tree loss: 2.448 | Accuracy: 0.283276 | 0.879 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Batch: 000 / 011 | Total loss: 2.714 | Reg loss: 0.035 | Tree loss: 2.714 | Accuracy: 0.269000 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 001 / 011 | Total loss: 2.680 | Reg loss: 0.035 | Tree loss: 2.680 | Accuracy: 0.254000 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 002 / 011 | Total loss: 2.629 | Reg loss: 0.035 | Tree loss: 2.629 | Accuracy: 0.277000 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 003 / 011 | Total loss: 2.591 | Reg loss: 0.035 | Tree loss: 2.591 | Accuracy: 0.294500 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 004 / 011 | Total loss: 2.528 | Reg loss: 0.035 | Tree loss: 2.528 | Accuracy: 0.317000 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 005 / 011 | Total loss: 2.541 | Reg loss: 0.035 | Tree loss: 2.541 | Accuracy: 0.291500 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 006 / 011 | Total loss: 2.513 | Reg loss: 0.035 | Tree loss: 2.513 | Accuracy: 0.301000 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 007 / 011 | Total loss: 2.490 | Reg loss: 0.035 | Tree loss: 2.490 | Accuracy: 0.288500 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 008 / 011 | Total loss: 2.520 | Reg loss: 0.035 | Tree loss: 2.520 | Accuracy: 0.257500 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 009 / 011 | Total loss: 2.479 | Reg loss: 0.035 | Tree loss: 2.479 | Accuracy: 0.257000 | 0.879 sec/iter\n",
      "Epoch: 100 | Batch: 010 / 011 | Total loss: 2.504 | Reg loss: 0.035 | Tree loss: 2.504 | Accuracy: 0.242321 | 0.879 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 101 | Batch: 000 / 011 | Total loss: 2.712 | Reg loss: 0.035 | Tree loss: 2.712 | Accuracy: 0.256000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 001 / 011 | Total loss: 2.691 | Reg loss: 0.035 | Tree loss: 2.691 | Accuracy: 0.265000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 002 / 011 | Total loss: 2.615 | Reg loss: 0.035 | Tree loss: 2.615 | Accuracy: 0.277000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 003 / 011 | Total loss: 2.577 | Reg loss: 0.035 | Tree loss: 2.577 | Accuracy: 0.291000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 004 / 011 | Total loss: 2.565 | Reg loss: 0.035 | Tree loss: 2.565 | Accuracy: 0.303000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 005 / 011 | Total loss: 2.529 | Reg loss: 0.035 | Tree loss: 2.529 | Accuracy: 0.282000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 006 / 011 | Total loss: 2.504 | Reg loss: 0.035 | Tree loss: 2.504 | Accuracy: 0.288500 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 007 / 011 | Total loss: 2.474 | Reg loss: 0.035 | Tree loss: 2.474 | Accuracy: 0.312500 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 008 / 011 | Total loss: 2.515 | Reg loss: 0.035 | Tree loss: 2.515 | Accuracy: 0.250000 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 009 / 011 | Total loss: 2.505 | Reg loss: 0.035 | Tree loss: 2.505 | Accuracy: 0.269500 | 0.879 sec/iter\n",
      "Epoch: 101 | Batch: 010 / 011 | Total loss: 2.386 | Reg loss: 0.035 | Tree loss: 2.386 | Accuracy: 0.296928 | 0.878 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 102 | Batch: 000 / 011 | Total loss: 2.716 | Reg loss: 0.035 | Tree loss: 2.716 | Accuracy: 0.253500 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 001 / 011 | Total loss: 2.674 | Reg loss: 0.035 | Tree loss: 2.674 | Accuracy: 0.258000 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 002 / 011 | Total loss: 2.643 | Reg loss: 0.035 | Tree loss: 2.643 | Accuracy: 0.277500 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 003 / 011 | Total loss: 2.573 | Reg loss: 0.035 | Tree loss: 2.573 | Accuracy: 0.295000 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 004 / 011 | Total loss: 2.585 | Reg loss: 0.035 | Tree loss: 2.585 | Accuracy: 0.278500 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 005 / 011 | Total loss: 2.523 | Reg loss: 0.035 | Tree loss: 2.523 | Accuracy: 0.277500 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 006 / 011 | Total loss: 2.498 | Reg loss: 0.035 | Tree loss: 2.498 | Accuracy: 0.288000 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 007 / 011 | Total loss: 2.489 | Reg loss: 0.035 | Tree loss: 2.489 | Accuracy: 0.280000 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 008 / 011 | Total loss: 2.487 | Reg loss: 0.035 | Tree loss: 2.487 | Accuracy: 0.267500 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 009 / 011 | Total loss: 2.461 | Reg loss: 0.035 | Tree loss: 2.461 | Accuracy: 0.278500 | 0.878 sec/iter\n",
      "Epoch: 102 | Batch: 010 / 011 | Total loss: 2.496 | Reg loss: 0.035 | Tree loss: 2.496 | Accuracy: 0.296928 | 0.878 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 103 | Batch: 000 / 011 | Total loss: 2.697 | Reg loss: 0.035 | Tree loss: 2.697 | Accuracy: 0.245500 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 001 / 011 | Total loss: 2.673 | Reg loss: 0.035 | Tree loss: 2.673 | Accuracy: 0.253000 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 002 / 011 | Total loss: 2.624 | Reg loss: 0.035 | Tree loss: 2.624 | Accuracy: 0.283000 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 003 / 011 | Total loss: 2.596 | Reg loss: 0.035 | Tree loss: 2.596 | Accuracy: 0.280500 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 004 / 011 | Total loss: 2.540 | Reg loss: 0.035 | Tree loss: 2.540 | Accuracy: 0.290500 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 005 / 011 | Total loss: 2.524 | Reg loss: 0.035 | Tree loss: 2.524 | Accuracy: 0.330000 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 006 / 011 | Total loss: 2.519 | Reg loss: 0.035 | Tree loss: 2.519 | Accuracy: 0.289500 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 007 / 011 | Total loss: 2.492 | Reg loss: 0.035 | Tree loss: 2.492 | Accuracy: 0.290000 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 008 / 011 | Total loss: 2.478 | Reg loss: 0.035 | Tree loss: 2.478 | Accuracy: 0.265500 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 009 / 011 | Total loss: 2.487 | Reg loss: 0.035 | Tree loss: 2.487 | Accuracy: 0.246000 | 0.878 sec/iter\n",
      "Epoch: 103 | Batch: 010 / 011 | Total loss: 2.449 | Reg loss: 0.035 | Tree loss: 2.449 | Accuracy: 0.286689 | 0.878 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 104 | Batch: 000 / 011 | Total loss: 2.704 | Reg loss: 0.035 | Tree loss: 2.704 | Accuracy: 0.259000 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 001 / 011 | Total loss: 2.666 | Reg loss: 0.035 | Tree loss: 2.666 | Accuracy: 0.260500 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 002 / 011 | Total loss: 2.618 | Reg loss: 0.035 | Tree loss: 2.618 | Accuracy: 0.268500 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 003 / 011 | Total loss: 2.594 | Reg loss: 0.035 | Tree loss: 2.594 | Accuracy: 0.286000 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 004 / 011 | Total loss: 2.557 | Reg loss: 0.035 | Tree loss: 2.557 | Accuracy: 0.304000 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 005 / 011 | Total loss: 2.529 | Reg loss: 0.035 | Tree loss: 2.529 | Accuracy: 0.280500 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 006 / 011 | Total loss: 2.511 | Reg loss: 0.035 | Tree loss: 2.511 | Accuracy: 0.294000 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 007 / 011 | Total loss: 2.488 | Reg loss: 0.035 | Tree loss: 2.488 | Accuracy: 0.275500 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 008 / 011 | Total loss: 2.468 | Reg loss: 0.035 | Tree loss: 2.468 | Accuracy: 0.272500 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 009 / 011 | Total loss: 2.470 | Reg loss: 0.035 | Tree loss: 2.470 | Accuracy: 0.250000 | 0.878 sec/iter\n",
      "Epoch: 104 | Batch: 010 / 011 | Total loss: 2.437 | Reg loss: 0.035 | Tree loss: 2.437 | Accuracy: 0.249147 | 0.878 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105 | Batch: 000 / 011 | Total loss: 2.691 | Reg loss: 0.035 | Tree loss: 2.691 | Accuracy: 0.273000 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 001 / 011 | Total loss: 2.662 | Reg loss: 0.035 | Tree loss: 2.662 | Accuracy: 0.264000 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 002 / 011 | Total loss: 2.629 | Reg loss: 0.035 | Tree loss: 2.629 | Accuracy: 0.278500 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 003 / 011 | Total loss: 2.582 | Reg loss: 0.035 | Tree loss: 2.582 | Accuracy: 0.297000 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 004 / 011 | Total loss: 2.546 | Reg loss: 0.035 | Tree loss: 2.546 | Accuracy: 0.281000 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 005 / 011 | Total loss: 2.538 | Reg loss: 0.035 | Tree loss: 2.538 | Accuracy: 0.287500 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 006 / 011 | Total loss: 2.506 | Reg loss: 0.035 | Tree loss: 2.506 | Accuracy: 0.278000 | 0.878 sec/iter\n",
      "Epoch: 105 | Batch: 007 / 011 | Total loss: 2.478 | Reg loss: 0.035 | Tree loss: 2.478 | Accuracy: 0.287500 | 0.877 sec/iter\n",
      "Epoch: 105 | Batch: 008 / 011 | Total loss: 2.475 | Reg loss: 0.035 | Tree loss: 2.475 | Accuracy: 0.275500 | 0.877 sec/iter\n",
      "Epoch: 105 | Batch: 009 / 011 | Total loss: 2.467 | Reg loss: 0.035 | Tree loss: 2.467 | Accuracy: 0.263500 | 0.877 sec/iter\n",
      "Epoch: 105 | Batch: 010 / 011 | Total loss: 2.540 | Reg loss: 0.035 | Tree loss: 2.540 | Accuracy: 0.225256 | 0.877 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 106 | Batch: 000 / 011 | Total loss: 2.700 | Reg loss: 0.035 | Tree loss: 2.700 | Accuracy: 0.255500 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 001 / 011 | Total loss: 2.694 | Reg loss: 0.035 | Tree loss: 2.694 | Accuracy: 0.261500 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 002 / 011 | Total loss: 2.630 | Reg loss: 0.035 | Tree loss: 2.630 | Accuracy: 0.255000 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 003 / 011 | Total loss: 2.584 | Reg loss: 0.035 | Tree loss: 2.584 | Accuracy: 0.298000 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 004 / 011 | Total loss: 2.545 | Reg loss: 0.035 | Tree loss: 2.545 | Accuracy: 0.298000 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 005 / 011 | Total loss: 2.514 | Reg loss: 0.035 | Tree loss: 2.514 | Accuracy: 0.286500 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 006 / 011 | Total loss: 2.494 | Reg loss: 0.035 | Tree loss: 2.494 | Accuracy: 0.292000 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 007 / 011 | Total loss: 2.495 | Reg loss: 0.035 | Tree loss: 2.495 | Accuracy: 0.269500 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 008 / 011 | Total loss: 2.445 | Reg loss: 0.035 | Tree loss: 2.445 | Accuracy: 0.281000 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 009 / 011 | Total loss: 2.449 | Reg loss: 0.035 | Tree loss: 2.449 | Accuracy: 0.258000 | 0.877 sec/iter\n",
      "Epoch: 106 | Batch: 010 / 011 | Total loss: 2.429 | Reg loss: 0.035 | Tree loss: 2.429 | Accuracy: 0.276451 | 0.877 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 107 | Batch: 000 / 011 | Total loss: 2.685 | Reg loss: 0.035 | Tree loss: 2.685 | Accuracy: 0.270500 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 001 / 011 | Total loss: 2.658 | Reg loss: 0.035 | Tree loss: 2.658 | Accuracy: 0.245500 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 002 / 011 | Total loss: 2.654 | Reg loss: 0.035 | Tree loss: 2.654 | Accuracy: 0.260000 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 003 / 011 | Total loss: 2.574 | Reg loss: 0.035 | Tree loss: 2.574 | Accuracy: 0.290500 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 004 / 011 | Total loss: 2.545 | Reg loss: 0.035 | Tree loss: 2.545 | Accuracy: 0.312000 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 005 / 011 | Total loss: 2.488 | Reg loss: 0.035 | Tree loss: 2.488 | Accuracy: 0.294500 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 006 / 011 | Total loss: 2.502 | Reg loss: 0.035 | Tree loss: 2.502 | Accuracy: 0.296000 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 007 / 011 | Total loss: 2.473 | Reg loss: 0.035 | Tree loss: 2.473 | Accuracy: 0.299000 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 008 / 011 | Total loss: 2.455 | Reg loss: 0.035 | Tree loss: 2.455 | Accuracy: 0.284000 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 009 / 011 | Total loss: 2.491 | Reg loss: 0.035 | Tree loss: 2.491 | Accuracy: 0.245000 | 0.877 sec/iter\n",
      "Epoch: 107 | Batch: 010 / 011 | Total loss: 2.478 | Reg loss: 0.035 | Tree loss: 2.478 | Accuracy: 0.262799 | 0.877 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 108 | Batch: 000 / 011 | Total loss: 2.695 | Reg loss: 0.035 | Tree loss: 2.695 | Accuracy: 0.265000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 001 / 011 | Total loss: 2.653 | Reg loss: 0.035 | Tree loss: 2.653 | Accuracy: 0.276000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 002 / 011 | Total loss: 2.612 | Reg loss: 0.035 | Tree loss: 2.612 | Accuracy: 0.279000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 003 / 011 | Total loss: 2.600 | Reg loss: 0.035 | Tree loss: 2.600 | Accuracy: 0.293000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 004 / 011 | Total loss: 2.549 | Reg loss: 0.035 | Tree loss: 2.549 | Accuracy: 0.285000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 005 / 011 | Total loss: 2.520 | Reg loss: 0.035 | Tree loss: 2.520 | Accuracy: 0.293500 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 006 / 011 | Total loss: 2.497 | Reg loss: 0.035 | Tree loss: 2.497 | Accuracy: 0.285500 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 007 / 011 | Total loss: 2.458 | Reg loss: 0.035 | Tree loss: 2.458 | Accuracy: 0.279000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 008 / 011 | Total loss: 2.475 | Reg loss: 0.035 | Tree loss: 2.475 | Accuracy: 0.260000 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 009 / 011 | Total loss: 2.452 | Reg loss: 0.035 | Tree loss: 2.452 | Accuracy: 0.263500 | 0.877 sec/iter\n",
      "Epoch: 108 | Batch: 010 / 011 | Total loss: 2.416 | Reg loss: 0.035 | Tree loss: 2.416 | Accuracy: 0.283276 | 0.877 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 109 | Batch: 000 / 011 | Total loss: 2.704 | Reg loss: 0.035 | Tree loss: 2.704 | Accuracy: 0.261000 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 001 / 011 | Total loss: 2.649 | Reg loss: 0.035 | Tree loss: 2.649 | Accuracy: 0.263500 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 002 / 011 | Total loss: 2.633 | Reg loss: 0.035 | Tree loss: 2.633 | Accuracy: 0.273000 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 003 / 011 | Total loss: 2.583 | Reg loss: 0.035 | Tree loss: 2.583 | Accuracy: 0.280000 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 004 / 011 | Total loss: 2.542 | Reg loss: 0.035 | Tree loss: 2.542 | Accuracy: 0.298000 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 005 / 011 | Total loss: 2.504 | Reg loss: 0.035 | Tree loss: 2.504 | Accuracy: 0.300500 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 006 / 011 | Total loss: 2.495 | Reg loss: 0.035 | Tree loss: 2.495 | Accuracy: 0.302000 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 007 / 011 | Total loss: 2.468 | Reg loss: 0.035 | Tree loss: 2.468 | Accuracy: 0.280500 | 0.877 sec/iter\n",
      "Epoch: 109 | Batch: 008 / 011 | Total loss: 2.456 | Reg loss: 0.035 | Tree loss: 2.456 | Accuracy: 0.268500 | 0.876 sec/iter\n",
      "Epoch: 109 | Batch: 009 / 011 | Total loss: 2.457 | Reg loss: 0.035 | Tree loss: 2.457 | Accuracy: 0.257500 | 0.876 sec/iter\n",
      "Epoch: 109 | Batch: 010 / 011 | Total loss: 2.437 | Reg loss: 0.035 | Tree loss: 2.437 | Accuracy: 0.232082 | 0.876 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110 | Batch: 000 / 011 | Total loss: 2.714 | Reg loss: 0.035 | Tree loss: 2.714 | Accuracy: 0.255500 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 001 / 011 | Total loss: 2.653 | Reg loss: 0.035 | Tree loss: 2.653 | Accuracy: 0.269000 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 002 / 011 | Total loss: 2.613 | Reg loss: 0.035 | Tree loss: 2.613 | Accuracy: 0.271500 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 003 / 011 | Total loss: 2.581 | Reg loss: 0.035 | Tree loss: 2.581 | Accuracy: 0.288000 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 004 / 011 | Total loss: 2.522 | Reg loss: 0.035 | Tree loss: 2.522 | Accuracy: 0.308500 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 005 / 011 | Total loss: 2.505 | Reg loss: 0.035 | Tree loss: 2.505 | Accuracy: 0.301000 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 006 / 011 | Total loss: 2.498 | Reg loss: 0.035 | Tree loss: 2.498 | Accuracy: 0.281500 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 007 / 011 | Total loss: 2.467 | Reg loss: 0.035 | Tree loss: 2.467 | Accuracy: 0.279500 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 008 / 011 | Total loss: 2.469 | Reg loss: 0.035 | Tree loss: 2.469 | Accuracy: 0.257000 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 009 / 011 | Total loss: 2.438 | Reg loss: 0.036 | Tree loss: 2.438 | Accuracy: 0.258500 | 0.876 sec/iter\n",
      "Epoch: 110 | Batch: 010 / 011 | Total loss: 2.503 | Reg loss: 0.036 | Tree loss: 2.503 | Accuracy: 0.255973 | 0.876 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 111 | Batch: 000 / 011 | Total loss: 2.692 | Reg loss: 0.035 | Tree loss: 2.692 | Accuracy: 0.260000 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 001 / 011 | Total loss: 2.653 | Reg loss: 0.035 | Tree loss: 2.653 | Accuracy: 0.266500 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 002 / 011 | Total loss: 2.621 | Reg loss: 0.035 | Tree loss: 2.621 | Accuracy: 0.273500 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 003 / 011 | Total loss: 2.564 | Reg loss: 0.035 | Tree loss: 2.564 | Accuracy: 0.293500 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 004 / 011 | Total loss: 2.546 | Reg loss: 0.035 | Tree loss: 2.546 | Accuracy: 0.295000 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 005 / 011 | Total loss: 2.507 | Reg loss: 0.035 | Tree loss: 2.507 | Accuracy: 0.309500 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 006 / 011 | Total loss: 2.489 | Reg loss: 0.035 | Tree loss: 2.489 | Accuracy: 0.301000 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 007 / 011 | Total loss: 2.452 | Reg loss: 0.036 | Tree loss: 2.452 | Accuracy: 0.284500 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 008 / 011 | Total loss: 2.446 | Reg loss: 0.036 | Tree loss: 2.446 | Accuracy: 0.273000 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 009 / 011 | Total loss: 2.479 | Reg loss: 0.036 | Tree loss: 2.479 | Accuracy: 0.269500 | 0.876 sec/iter\n",
      "Epoch: 111 | Batch: 010 / 011 | Total loss: 2.449 | Reg loss: 0.036 | Tree loss: 2.449 | Accuracy: 0.249147 | 0.876 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 112 | Batch: 000 / 011 | Total loss: 2.695 | Reg loss: 0.035 | Tree loss: 2.695 | Accuracy: 0.271500 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 001 / 011 | Total loss: 2.649 | Reg loss: 0.035 | Tree loss: 2.649 | Accuracy: 0.277500 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 002 / 011 | Total loss: 2.606 | Reg loss: 0.035 | Tree loss: 2.606 | Accuracy: 0.293000 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 003 / 011 | Total loss: 2.565 | Reg loss: 0.035 | Tree loss: 2.565 | Accuracy: 0.295000 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 004 / 011 | Total loss: 2.532 | Reg loss: 0.035 | Tree loss: 2.532 | Accuracy: 0.285000 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 005 / 011 | Total loss: 2.486 | Reg loss: 0.035 | Tree loss: 2.486 | Accuracy: 0.297500 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 006 / 011 | Total loss: 2.480 | Reg loss: 0.036 | Tree loss: 2.480 | Accuracy: 0.270000 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 007 / 011 | Total loss: 2.494 | Reg loss: 0.036 | Tree loss: 2.494 | Accuracy: 0.262500 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 008 / 011 | Total loss: 2.467 | Reg loss: 0.036 | Tree loss: 2.467 | Accuracy: 0.257000 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 009 / 011 | Total loss: 2.455 | Reg loss: 0.036 | Tree loss: 2.455 | Accuracy: 0.250500 | 0.876 sec/iter\n",
      "Epoch: 112 | Batch: 010 / 011 | Total loss: 2.517 | Reg loss: 0.036 | Tree loss: 2.517 | Accuracy: 0.235495 | 0.876 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 113 | Batch: 000 / 011 | Total loss: 2.668 | Reg loss: 0.035 | Tree loss: 2.668 | Accuracy: 0.276500 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 001 / 011 | Total loss: 2.645 | Reg loss: 0.035 | Tree loss: 2.645 | Accuracy: 0.274500 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 002 / 011 | Total loss: 2.632 | Reg loss: 0.035 | Tree loss: 2.632 | Accuracy: 0.257000 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 003 / 011 | Total loss: 2.567 | Reg loss: 0.036 | Tree loss: 2.567 | Accuracy: 0.281500 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 004 / 011 | Total loss: 2.540 | Reg loss: 0.036 | Tree loss: 2.540 | Accuracy: 0.303500 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 005 / 011 | Total loss: 2.507 | Reg loss: 0.036 | Tree loss: 2.507 | Accuracy: 0.286000 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 006 / 011 | Total loss: 2.494 | Reg loss: 0.036 | Tree loss: 2.494 | Accuracy: 0.266500 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 007 / 011 | Total loss: 2.477 | Reg loss: 0.036 | Tree loss: 2.477 | Accuracy: 0.296000 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 008 / 011 | Total loss: 2.452 | Reg loss: 0.036 | Tree loss: 2.452 | Accuracy: 0.281000 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 009 / 011 | Total loss: 2.456 | Reg loss: 0.036 | Tree loss: 2.456 | Accuracy: 0.256500 | 0.876 sec/iter\n",
      "Epoch: 113 | Batch: 010 / 011 | Total loss: 2.389 | Reg loss: 0.036 | Tree loss: 2.389 | Accuracy: 0.276451 | 0.875 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 114 | Batch: 000 / 011 | Total loss: 2.688 | Reg loss: 0.036 | Tree loss: 2.688 | Accuracy: 0.265500 | 0.876 sec/iter\n",
      "Epoch: 114 | Batch: 001 / 011 | Total loss: 2.638 | Reg loss: 0.036 | Tree loss: 2.638 | Accuracy: 0.265000 | 0.876 sec/iter\n",
      "Epoch: 114 | Batch: 002 / 011 | Total loss: 2.615 | Reg loss: 0.036 | Tree loss: 2.615 | Accuracy: 0.274500 | 0.876 sec/iter\n",
      "Epoch: 114 | Batch: 003 / 011 | Total loss: 2.572 | Reg loss: 0.036 | Tree loss: 2.572 | Accuracy: 0.284000 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 004 / 011 | Total loss: 2.533 | Reg loss: 0.036 | Tree loss: 2.533 | Accuracy: 0.289500 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 005 / 011 | Total loss: 2.509 | Reg loss: 0.036 | Tree loss: 2.509 | Accuracy: 0.285500 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 006 / 011 | Total loss: 2.452 | Reg loss: 0.036 | Tree loss: 2.452 | Accuracy: 0.307500 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 007 / 011 | Total loss: 2.471 | Reg loss: 0.036 | Tree loss: 2.471 | Accuracy: 0.269000 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 008 / 011 | Total loss: 2.469 | Reg loss: 0.036 | Tree loss: 2.469 | Accuracy: 0.253000 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 009 / 011 | Total loss: 2.447 | Reg loss: 0.036 | Tree loss: 2.447 | Accuracy: 0.252000 | 0.875 sec/iter\n",
      "Epoch: 114 | Batch: 010 / 011 | Total loss: 2.373 | Reg loss: 0.036 | Tree loss: 2.373 | Accuracy: 0.269625 | 0.875 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115 | Batch: 000 / 011 | Total loss: 2.667 | Reg loss: 0.036 | Tree loss: 2.667 | Accuracy: 0.284500 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 001 / 011 | Total loss: 2.656 | Reg loss: 0.036 | Tree loss: 2.656 | Accuracy: 0.277500 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 002 / 011 | Total loss: 2.605 | Reg loss: 0.036 | Tree loss: 2.605 | Accuracy: 0.290000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 003 / 011 | Total loss: 2.558 | Reg loss: 0.036 | Tree loss: 2.558 | Accuracy: 0.280000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 004 / 011 | Total loss: 2.521 | Reg loss: 0.036 | Tree loss: 2.521 | Accuracy: 0.300000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 005 / 011 | Total loss: 2.491 | Reg loss: 0.036 | Tree loss: 2.491 | Accuracy: 0.288000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 006 / 011 | Total loss: 2.503 | Reg loss: 0.036 | Tree loss: 2.503 | Accuracy: 0.247000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 007 / 011 | Total loss: 2.478 | Reg loss: 0.036 | Tree loss: 2.478 | Accuracy: 0.275000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 008 / 011 | Total loss: 2.450 | Reg loss: 0.036 | Tree loss: 2.450 | Accuracy: 0.257500 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 009 / 011 | Total loss: 2.452 | Reg loss: 0.036 | Tree loss: 2.452 | Accuracy: 0.260000 | 0.875 sec/iter\n",
      "Epoch: 115 | Batch: 010 / 011 | Total loss: 2.465 | Reg loss: 0.036 | Tree loss: 2.465 | Accuracy: 0.286689 | 0.875 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 116 | Batch: 000 / 011 | Total loss: 2.698 | Reg loss: 0.036 | Tree loss: 2.698 | Accuracy: 0.265000 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 001 / 011 | Total loss: 2.654 | Reg loss: 0.036 | Tree loss: 2.654 | Accuracy: 0.270500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 002 / 011 | Total loss: 2.606 | Reg loss: 0.036 | Tree loss: 2.606 | Accuracy: 0.280500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 003 / 011 | Total loss: 2.575 | Reg loss: 0.036 | Tree loss: 2.575 | Accuracy: 0.276500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 004 / 011 | Total loss: 2.532 | Reg loss: 0.036 | Tree loss: 2.532 | Accuracy: 0.295500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 005 / 011 | Total loss: 2.494 | Reg loss: 0.036 | Tree loss: 2.494 | Accuracy: 0.278500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 006 / 011 | Total loss: 2.470 | Reg loss: 0.036 | Tree loss: 2.470 | Accuracy: 0.296000 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 007 / 011 | Total loss: 2.462 | Reg loss: 0.036 | Tree loss: 2.462 | Accuracy: 0.306500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 008 / 011 | Total loss: 2.425 | Reg loss: 0.036 | Tree loss: 2.425 | Accuracy: 0.276500 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 009 / 011 | Total loss: 2.445 | Reg loss: 0.036 | Tree loss: 2.445 | Accuracy: 0.254000 | 0.875 sec/iter\n",
      "Epoch: 116 | Batch: 010 / 011 | Total loss: 2.482 | Reg loss: 0.036 | Tree loss: 2.482 | Accuracy: 0.228669 | 0.875 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 117 | Batch: 000 / 011 | Total loss: 2.678 | Reg loss: 0.036 | Tree loss: 2.678 | Accuracy: 0.282000 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 001 / 011 | Total loss: 2.620 | Reg loss: 0.036 | Tree loss: 2.620 | Accuracy: 0.266000 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 002 / 011 | Total loss: 2.615 | Reg loss: 0.036 | Tree loss: 2.615 | Accuracy: 0.268500 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 003 / 011 | Total loss: 2.570 | Reg loss: 0.036 | Tree loss: 2.570 | Accuracy: 0.287500 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 004 / 011 | Total loss: 2.556 | Reg loss: 0.036 | Tree loss: 2.556 | Accuracy: 0.280500 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 005 / 011 | Total loss: 2.506 | Reg loss: 0.036 | Tree loss: 2.506 | Accuracy: 0.284500 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 006 / 011 | Total loss: 2.456 | Reg loss: 0.036 | Tree loss: 2.456 | Accuracy: 0.285000 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 007 / 011 | Total loss: 2.462 | Reg loss: 0.036 | Tree loss: 2.462 | Accuracy: 0.282500 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 008 / 011 | Total loss: 2.432 | Reg loss: 0.036 | Tree loss: 2.432 | Accuracy: 0.272500 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 009 / 011 | Total loss: 2.460 | Reg loss: 0.036 | Tree loss: 2.460 | Accuracy: 0.260000 | 0.875 sec/iter\n",
      "Epoch: 117 | Batch: 010 / 011 | Total loss: 2.449 | Reg loss: 0.036 | Tree loss: 2.449 | Accuracy: 0.255973 | 0.875 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 118 | Batch: 000 / 011 | Total loss: 2.652 | Reg loss: 0.036 | Tree loss: 2.652 | Accuracy: 0.281500 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 001 / 011 | Total loss: 2.651 | Reg loss: 0.036 | Tree loss: 2.651 | Accuracy: 0.262500 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 002 / 011 | Total loss: 2.583 | Reg loss: 0.036 | Tree loss: 2.583 | Accuracy: 0.265000 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 003 / 011 | Total loss: 2.557 | Reg loss: 0.036 | Tree loss: 2.557 | Accuracy: 0.303000 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 004 / 011 | Total loss: 2.556 | Reg loss: 0.036 | Tree loss: 2.556 | Accuracy: 0.269500 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 005 / 011 | Total loss: 2.503 | Reg loss: 0.036 | Tree loss: 2.503 | Accuracy: 0.285000 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 006 / 011 | Total loss: 2.486 | Reg loss: 0.036 | Tree loss: 2.486 | Accuracy: 0.290500 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 007 / 011 | Total loss: 2.458 | Reg loss: 0.036 | Tree loss: 2.458 | Accuracy: 0.292500 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 008 / 011 | Total loss: 2.443 | Reg loss: 0.036 | Tree loss: 2.443 | Accuracy: 0.284000 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 009 / 011 | Total loss: 2.445 | Reg loss: 0.036 | Tree loss: 2.445 | Accuracy: 0.260000 | 0.875 sec/iter\n",
      "Epoch: 118 | Batch: 010 / 011 | Total loss: 2.416 | Reg loss: 0.036 | Tree loss: 2.416 | Accuracy: 0.252560 | 0.874 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 119 | Batch: 000 / 011 | Total loss: 2.680 | Reg loss: 0.036 | Tree loss: 2.680 | Accuracy: 0.276000 | 0.875 sec/iter\n",
      "Epoch: 119 | Batch: 001 / 011 | Total loss: 2.647 | Reg loss: 0.036 | Tree loss: 2.647 | Accuracy: 0.274000 | 0.875 sec/iter\n",
      "Epoch: 119 | Batch: 002 / 011 | Total loss: 2.599 | Reg loss: 0.036 | Tree loss: 2.599 | Accuracy: 0.282500 | 0.875 sec/iter\n",
      "Epoch: 119 | Batch: 003 / 011 | Total loss: 2.565 | Reg loss: 0.036 | Tree loss: 2.565 | Accuracy: 0.278000 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 004 / 011 | Total loss: 2.515 | Reg loss: 0.036 | Tree loss: 2.515 | Accuracy: 0.294000 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 005 / 011 | Total loss: 2.491 | Reg loss: 0.036 | Tree loss: 2.491 | Accuracy: 0.298000 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 006 / 011 | Total loss: 2.469 | Reg loss: 0.036 | Tree loss: 2.469 | Accuracy: 0.285000 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 007 / 011 | Total loss: 2.464 | Reg loss: 0.036 | Tree loss: 2.464 | Accuracy: 0.263000 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 008 / 011 | Total loss: 2.445 | Reg loss: 0.036 | Tree loss: 2.445 | Accuracy: 0.267500 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 009 / 011 | Total loss: 2.446 | Reg loss: 0.036 | Tree loss: 2.446 | Accuracy: 0.247500 | 0.874 sec/iter\n",
      "Epoch: 119 | Batch: 010 / 011 | Total loss: 2.496 | Reg loss: 0.036 | Tree loss: 2.496 | Accuracy: 0.255973 | 0.874 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 | Batch: 000 / 011 | Total loss: 2.672 | Reg loss: 0.036 | Tree loss: 2.672 | Accuracy: 0.266000 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 001 / 011 | Total loss: 2.662 | Reg loss: 0.036 | Tree loss: 2.662 | Accuracy: 0.280000 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 002 / 011 | Total loss: 2.608 | Reg loss: 0.036 | Tree loss: 2.608 | Accuracy: 0.270500 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 003 / 011 | Total loss: 2.536 | Reg loss: 0.036 | Tree loss: 2.536 | Accuracy: 0.289500 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 004 / 011 | Total loss: 2.535 | Reg loss: 0.036 | Tree loss: 2.535 | Accuracy: 0.294500 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 005 / 011 | Total loss: 2.507 | Reg loss: 0.036 | Tree loss: 2.507 | Accuracy: 0.285000 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 006 / 011 | Total loss: 2.484 | Reg loss: 0.036 | Tree loss: 2.484 | Accuracy: 0.272500 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 007 / 011 | Total loss: 2.447 | Reg loss: 0.036 | Tree loss: 2.447 | Accuracy: 0.279000 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 008 / 011 | Total loss: 2.425 | Reg loss: 0.036 | Tree loss: 2.425 | Accuracy: 0.257000 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 009 / 011 | Total loss: 2.439 | Reg loss: 0.036 | Tree loss: 2.439 | Accuracy: 0.260500 | 0.874 sec/iter\n",
      "Epoch: 120 | Batch: 010 / 011 | Total loss: 2.473 | Reg loss: 0.036 | Tree loss: 2.473 | Accuracy: 0.221843 | 0.874 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 121 | Batch: 000 / 011 | Total loss: 2.673 | Reg loss: 0.036 | Tree loss: 2.673 | Accuracy: 0.266500 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 001 / 011 | Total loss: 2.635 | Reg loss: 0.036 | Tree loss: 2.635 | Accuracy: 0.274000 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 002 / 011 | Total loss: 2.596 | Reg loss: 0.036 | Tree loss: 2.596 | Accuracy: 0.290000 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 003 / 011 | Total loss: 2.566 | Reg loss: 0.036 | Tree loss: 2.566 | Accuracy: 0.276500 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 004 / 011 | Total loss: 2.514 | Reg loss: 0.036 | Tree loss: 2.514 | Accuracy: 0.304000 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 005 / 011 | Total loss: 2.490 | Reg loss: 0.036 | Tree loss: 2.490 | Accuracy: 0.288500 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 006 / 011 | Total loss: 2.481 | Reg loss: 0.036 | Tree loss: 2.481 | Accuracy: 0.285500 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 007 / 011 | Total loss: 2.457 | Reg loss: 0.036 | Tree loss: 2.457 | Accuracy: 0.281000 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 008 / 011 | Total loss: 2.443 | Reg loss: 0.036 | Tree loss: 2.443 | Accuracy: 0.283000 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 009 / 011 | Total loss: 2.450 | Reg loss: 0.036 | Tree loss: 2.450 | Accuracy: 0.264000 | 0.874 sec/iter\n",
      "Epoch: 121 | Batch: 010 / 011 | Total loss: 2.412 | Reg loss: 0.036 | Tree loss: 2.412 | Accuracy: 0.286689 | 0.874 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 122 | Batch: 000 / 011 | Total loss: 2.658 | Reg loss: 0.036 | Tree loss: 2.658 | Accuracy: 0.277500 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 001 / 011 | Total loss: 2.657 | Reg loss: 0.036 | Tree loss: 2.657 | Accuracy: 0.259500 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 002 / 011 | Total loss: 2.578 | Reg loss: 0.036 | Tree loss: 2.578 | Accuracy: 0.296500 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 003 / 011 | Total loss: 2.539 | Reg loss: 0.036 | Tree loss: 2.539 | Accuracy: 0.290000 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 004 / 011 | Total loss: 2.523 | Reg loss: 0.036 | Tree loss: 2.523 | Accuracy: 0.283000 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 005 / 011 | Total loss: 2.498 | Reg loss: 0.036 | Tree loss: 2.498 | Accuracy: 0.286500 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 006 / 011 | Total loss: 2.482 | Reg loss: 0.036 | Tree loss: 2.482 | Accuracy: 0.278000 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 007 / 011 | Total loss: 2.458 | Reg loss: 0.036 | Tree loss: 2.458 | Accuracy: 0.280000 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 008 / 011 | Total loss: 2.431 | Reg loss: 0.036 | Tree loss: 2.431 | Accuracy: 0.265000 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 009 / 011 | Total loss: 2.461 | Reg loss: 0.036 | Tree loss: 2.461 | Accuracy: 0.251000 | 0.874 sec/iter\n",
      "Epoch: 122 | Batch: 010 / 011 | Total loss: 2.479 | Reg loss: 0.036 | Tree loss: 2.479 | Accuracy: 0.279863 | 0.874 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 123 | Batch: 000 / 011 | Total loss: 2.653 | Reg loss: 0.036 | Tree loss: 2.653 | Accuracy: 0.281000 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 001 / 011 | Total loss: 2.656 | Reg loss: 0.036 | Tree loss: 2.656 | Accuracy: 0.261000 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 002 / 011 | Total loss: 2.587 | Reg loss: 0.036 | Tree loss: 2.587 | Accuracy: 0.271500 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 003 / 011 | Total loss: 2.555 | Reg loss: 0.036 | Tree loss: 2.555 | Accuracy: 0.291500 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 004 / 011 | Total loss: 2.538 | Reg loss: 0.036 | Tree loss: 2.538 | Accuracy: 0.293000 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 005 / 011 | Total loss: 2.496 | Reg loss: 0.036 | Tree loss: 2.496 | Accuracy: 0.280500 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 006 / 011 | Total loss: 2.464 | Reg loss: 0.036 | Tree loss: 2.464 | Accuracy: 0.297500 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 007 / 011 | Total loss: 2.448 | Reg loss: 0.036 | Tree loss: 2.448 | Accuracy: 0.292500 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 008 / 011 | Total loss: 2.451 | Reg loss: 0.036 | Tree loss: 2.451 | Accuracy: 0.265000 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 009 / 011 | Total loss: 2.435 | Reg loss: 0.036 | Tree loss: 2.435 | Accuracy: 0.244500 | 0.874 sec/iter\n",
      "Epoch: 123 | Batch: 010 / 011 | Total loss: 2.421 | Reg loss: 0.036 | Tree loss: 2.421 | Accuracy: 0.273038 | 0.874 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 124 | Batch: 000 / 011 | Total loss: 2.653 | Reg loss: 0.036 | Tree loss: 2.653 | Accuracy: 0.274500 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 001 / 011 | Total loss: 2.642 | Reg loss: 0.036 | Tree loss: 2.642 | Accuracy: 0.271500 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 002 / 011 | Total loss: 2.592 | Reg loss: 0.036 | Tree loss: 2.592 | Accuracy: 0.269000 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 003 / 011 | Total loss: 2.548 | Reg loss: 0.036 | Tree loss: 2.548 | Accuracy: 0.289500 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 004 / 011 | Total loss: 2.502 | Reg loss: 0.036 | Tree loss: 2.502 | Accuracy: 0.303500 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 005 / 011 | Total loss: 2.494 | Reg loss: 0.036 | Tree loss: 2.494 | Accuracy: 0.291500 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 006 / 011 | Total loss: 2.479 | Reg loss: 0.036 | Tree loss: 2.479 | Accuracy: 0.253000 | 0.874 sec/iter\n",
      "Epoch: 124 | Batch: 007 / 011 | Total loss: 2.465 | Reg loss: 0.036 | Tree loss: 2.465 | Accuracy: 0.261000 | 0.873 sec/iter\n",
      "Epoch: 124 | Batch: 008 / 011 | Total loss: 2.435 | Reg loss: 0.036 | Tree loss: 2.435 | Accuracy: 0.274500 | 0.873 sec/iter\n",
      "Epoch: 124 | Batch: 009 / 011 | Total loss: 2.434 | Reg loss: 0.036 | Tree loss: 2.434 | Accuracy: 0.251500 | 0.873 sec/iter\n",
      "Epoch: 124 | Batch: 010 / 011 | Total loss: 2.461 | Reg loss: 0.036 | Tree loss: 2.461 | Accuracy: 0.238908 | 0.873 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125 | Batch: 000 / 011 | Total loss: 2.659 | Reg loss: 0.036 | Tree loss: 2.659 | Accuracy: 0.258000 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 001 / 011 | Total loss: 2.635 | Reg loss: 0.036 | Tree loss: 2.635 | Accuracy: 0.274000 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 002 / 011 | Total loss: 2.601 | Reg loss: 0.036 | Tree loss: 2.601 | Accuracy: 0.270000 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 003 / 011 | Total loss: 2.559 | Reg loss: 0.036 | Tree loss: 2.559 | Accuracy: 0.279500 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 004 / 011 | Total loss: 2.512 | Reg loss: 0.036 | Tree loss: 2.512 | Accuracy: 0.297500 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 005 / 011 | Total loss: 2.487 | Reg loss: 0.036 | Tree loss: 2.487 | Accuracy: 0.295500 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 006 / 011 | Total loss: 2.471 | Reg loss: 0.036 | Tree loss: 2.471 | Accuracy: 0.284500 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 007 / 011 | Total loss: 2.455 | Reg loss: 0.036 | Tree loss: 2.455 | Accuracy: 0.279000 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 008 / 011 | Total loss: 2.432 | Reg loss: 0.036 | Tree loss: 2.432 | Accuracy: 0.285000 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 009 / 011 | Total loss: 2.425 | Reg loss: 0.036 | Tree loss: 2.425 | Accuracy: 0.263000 | 0.873 sec/iter\n",
      "Epoch: 125 | Batch: 010 / 011 | Total loss: 2.466 | Reg loss: 0.036 | Tree loss: 2.466 | Accuracy: 0.262799 | 0.873 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 126 | Batch: 000 / 011 | Total loss: 2.663 | Reg loss: 0.036 | Tree loss: 2.663 | Accuracy: 0.247000 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 001 / 011 | Total loss: 2.594 | Reg loss: 0.036 | Tree loss: 2.594 | Accuracy: 0.288500 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 002 / 011 | Total loss: 2.597 | Reg loss: 0.036 | Tree loss: 2.597 | Accuracy: 0.283500 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 003 / 011 | Total loss: 2.558 | Reg loss: 0.036 | Tree loss: 2.558 | Accuracy: 0.277000 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 004 / 011 | Total loss: 2.505 | Reg loss: 0.036 | Tree loss: 2.505 | Accuracy: 0.304000 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 005 / 011 | Total loss: 2.498 | Reg loss: 0.036 | Tree loss: 2.498 | Accuracy: 0.269500 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 006 / 011 | Total loss: 2.462 | Reg loss: 0.036 | Tree loss: 2.462 | Accuracy: 0.298500 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 007 / 011 | Total loss: 2.445 | Reg loss: 0.036 | Tree loss: 2.445 | Accuracy: 0.292500 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 008 / 011 | Total loss: 2.457 | Reg loss: 0.036 | Tree loss: 2.457 | Accuracy: 0.250000 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 009 / 011 | Total loss: 2.436 | Reg loss: 0.036 | Tree loss: 2.436 | Accuracy: 0.262500 | 0.873 sec/iter\n",
      "Epoch: 126 | Batch: 010 / 011 | Total loss: 2.457 | Reg loss: 0.036 | Tree loss: 2.457 | Accuracy: 0.252560 | 0.873 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 127 | Batch: 000 / 011 | Total loss: 2.662 | Reg loss: 0.036 | Tree loss: 2.662 | Accuracy: 0.264500 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 001 / 011 | Total loss: 2.613 | Reg loss: 0.036 | Tree loss: 2.613 | Accuracy: 0.273000 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 002 / 011 | Total loss: 2.603 | Reg loss: 0.036 | Tree loss: 2.603 | Accuracy: 0.292500 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 003 / 011 | Total loss: 2.535 | Reg loss: 0.036 | Tree loss: 2.535 | Accuracy: 0.304000 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 004 / 011 | Total loss: 2.517 | Reg loss: 0.036 | Tree loss: 2.517 | Accuracy: 0.296500 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 005 / 011 | Total loss: 2.515 | Reg loss: 0.036 | Tree loss: 2.515 | Accuracy: 0.283000 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 006 / 011 | Total loss: 2.464 | Reg loss: 0.036 | Tree loss: 2.464 | Accuracy: 0.298000 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 007 / 011 | Total loss: 2.463 | Reg loss: 0.036 | Tree loss: 2.463 | Accuracy: 0.274500 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 008 / 011 | Total loss: 2.422 | Reg loss: 0.036 | Tree loss: 2.422 | Accuracy: 0.264500 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 009 / 011 | Total loss: 2.428 | Reg loss: 0.036 | Tree loss: 2.428 | Accuracy: 0.263000 | 0.873 sec/iter\n",
      "Epoch: 127 | Batch: 010 / 011 | Total loss: 2.363 | Reg loss: 0.036 | Tree loss: 2.363 | Accuracy: 0.303754 | 0.873 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 128 | Batch: 000 / 011 | Total loss: 2.662 | Reg loss: 0.036 | Tree loss: 2.662 | Accuracy: 0.263000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 001 / 011 | Total loss: 2.616 | Reg loss: 0.036 | Tree loss: 2.616 | Accuracy: 0.277000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 002 / 011 | Total loss: 2.592 | Reg loss: 0.036 | Tree loss: 2.592 | Accuracy: 0.299000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 003 / 011 | Total loss: 2.544 | Reg loss: 0.036 | Tree loss: 2.544 | Accuracy: 0.288000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 004 / 011 | Total loss: 2.527 | Reg loss: 0.036 | Tree loss: 2.527 | Accuracy: 0.287500 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 005 / 011 | Total loss: 2.491 | Reg loss: 0.036 | Tree loss: 2.491 | Accuracy: 0.264500 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 006 / 011 | Total loss: 2.461 | Reg loss: 0.036 | Tree loss: 2.461 | Accuracy: 0.290500 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 007 / 011 | Total loss: 2.456 | Reg loss: 0.036 | Tree loss: 2.456 | Accuracy: 0.283000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 008 / 011 | Total loss: 2.422 | Reg loss: 0.036 | Tree loss: 2.422 | Accuracy: 0.261000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 009 / 011 | Total loss: 2.430 | Reg loss: 0.036 | Tree loss: 2.430 | Accuracy: 0.256000 | 0.873 sec/iter\n",
      "Epoch: 128 | Batch: 010 / 011 | Total loss: 2.398 | Reg loss: 0.036 | Tree loss: 2.398 | Accuracy: 0.259386 | 0.873 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 129 | Batch: 000 / 011 | Total loss: 2.633 | Reg loss: 0.036 | Tree loss: 2.633 | Accuracy: 0.272000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 001 / 011 | Total loss: 2.619 | Reg loss: 0.036 | Tree loss: 2.619 | Accuracy: 0.278500 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 002 / 011 | Total loss: 2.605 | Reg loss: 0.036 | Tree loss: 2.605 | Accuracy: 0.286000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 003 / 011 | Total loss: 2.540 | Reg loss: 0.036 | Tree loss: 2.540 | Accuracy: 0.289000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 004 / 011 | Total loss: 2.499 | Reg loss: 0.036 | Tree loss: 2.499 | Accuracy: 0.300500 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 005 / 011 | Total loss: 2.474 | Reg loss: 0.036 | Tree loss: 2.474 | Accuracy: 0.307500 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 006 / 011 | Total loss: 2.460 | Reg loss: 0.036 | Tree loss: 2.460 | Accuracy: 0.289000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 007 / 011 | Total loss: 2.483 | Reg loss: 0.036 | Tree loss: 2.483 | Accuracy: 0.269000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 008 / 011 | Total loss: 2.449 | Reg loss: 0.036 | Tree loss: 2.449 | Accuracy: 0.258000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 009 / 011 | Total loss: 2.423 | Reg loss: 0.036 | Tree loss: 2.423 | Accuracy: 0.255000 | 0.873 sec/iter\n",
      "Epoch: 129 | Batch: 010 / 011 | Total loss: 2.412 | Reg loss: 0.037 | Tree loss: 2.412 | Accuracy: 0.249147 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130 | Batch: 000 / 011 | Total loss: 2.649 | Reg loss: 0.036 | Tree loss: 2.649 | Accuracy: 0.275500 | 0.873 sec/iter\n",
      "Epoch: 130 | Batch: 001 / 011 | Total loss: 2.625 | Reg loss: 0.036 | Tree loss: 2.625 | Accuracy: 0.279000 | 0.873 sec/iter\n",
      "Epoch: 130 | Batch: 002 / 011 | Total loss: 2.599 | Reg loss: 0.036 | Tree loss: 2.599 | Accuracy: 0.272000 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 003 / 011 | Total loss: 2.544 | Reg loss: 0.036 | Tree loss: 2.544 | Accuracy: 0.267000 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 004 / 011 | Total loss: 2.520 | Reg loss: 0.036 | Tree loss: 2.520 | Accuracy: 0.284500 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 005 / 011 | Total loss: 2.477 | Reg loss: 0.036 | Tree loss: 2.477 | Accuracy: 0.288000 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 006 / 011 | Total loss: 2.472 | Reg loss: 0.036 | Tree loss: 2.472 | Accuracy: 0.274000 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 007 / 011 | Total loss: 2.430 | Reg loss: 0.036 | Tree loss: 2.430 | Accuracy: 0.290000 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 008 / 011 | Total loss: 2.428 | Reg loss: 0.036 | Tree loss: 2.428 | Accuracy: 0.271000 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 009 / 011 | Total loss: 2.426 | Reg loss: 0.037 | Tree loss: 2.426 | Accuracy: 0.254500 | 0.872 sec/iter\n",
      "Epoch: 130 | Batch: 010 / 011 | Total loss: 2.473 | Reg loss: 0.037 | Tree loss: 2.473 | Accuracy: 0.232082 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 131 | Batch: 000 / 011 | Total loss: 2.640 | Reg loss: 0.036 | Tree loss: 2.640 | Accuracy: 0.280000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 001 / 011 | Total loss: 2.634 | Reg loss: 0.036 | Tree loss: 2.634 | Accuracy: 0.265500 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 002 / 011 | Total loss: 2.601 | Reg loss: 0.036 | Tree loss: 2.601 | Accuracy: 0.277000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 003 / 011 | Total loss: 2.551 | Reg loss: 0.036 | Tree loss: 2.551 | Accuracy: 0.279000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 004 / 011 | Total loss: 2.507 | Reg loss: 0.036 | Tree loss: 2.507 | Accuracy: 0.290500 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 005 / 011 | Total loss: 2.459 | Reg loss: 0.036 | Tree loss: 2.459 | Accuracy: 0.302500 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 006 / 011 | Total loss: 2.440 | Reg loss: 0.036 | Tree loss: 2.440 | Accuracy: 0.295000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 007 / 011 | Total loss: 2.469 | Reg loss: 0.037 | Tree loss: 2.469 | Accuracy: 0.260000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 008 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.276000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 009 / 011 | Total loss: 2.436 | Reg loss: 0.037 | Tree loss: 2.436 | Accuracy: 0.266000 | 0.872 sec/iter\n",
      "Epoch: 131 | Batch: 010 / 011 | Total loss: 2.507 | Reg loss: 0.037 | Tree loss: 2.507 | Accuracy: 0.273038 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 132 | Batch: 000 / 011 | Total loss: 2.657 | Reg loss: 0.036 | Tree loss: 2.657 | Accuracy: 0.261000 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 001 / 011 | Total loss: 2.609 | Reg loss: 0.036 | Tree loss: 2.609 | Accuracy: 0.267500 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 002 / 011 | Total loss: 2.581 | Reg loss: 0.036 | Tree loss: 2.581 | Accuracy: 0.283500 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 003 / 011 | Total loss: 2.560 | Reg loss: 0.036 | Tree loss: 2.560 | Accuracy: 0.276000 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 004 / 011 | Total loss: 2.523 | Reg loss: 0.036 | Tree loss: 2.523 | Accuracy: 0.279000 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 005 / 011 | Total loss: 2.483 | Reg loss: 0.036 | Tree loss: 2.483 | Accuracy: 0.283500 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 006 / 011 | Total loss: 2.441 | Reg loss: 0.036 | Tree loss: 2.441 | Accuracy: 0.290500 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.037 | Tree loss: 2.419 | Accuracy: 0.280000 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 008 / 011 | Total loss: 2.449 | Reg loss: 0.037 | Tree loss: 2.449 | Accuracy: 0.234000 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 009 / 011 | Total loss: 2.434 | Reg loss: 0.037 | Tree loss: 2.434 | Accuracy: 0.258500 | 0.872 sec/iter\n",
      "Epoch: 132 | Batch: 010 / 011 | Total loss: 2.346 | Reg loss: 0.037 | Tree loss: 2.346 | Accuracy: 0.245734 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 133 | Batch: 000 / 011 | Total loss: 2.646 | Reg loss: 0.036 | Tree loss: 2.646 | Accuracy: 0.249500 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 001 / 011 | Total loss: 2.624 | Reg loss: 0.036 | Tree loss: 2.624 | Accuracy: 0.269000 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 002 / 011 | Total loss: 2.575 | Reg loss: 0.036 | Tree loss: 2.575 | Accuracy: 0.291000 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 003 / 011 | Total loss: 2.546 | Reg loss: 0.036 | Tree loss: 2.546 | Accuracy: 0.290500 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 004 / 011 | Total loss: 2.525 | Reg loss: 0.037 | Tree loss: 2.525 | Accuracy: 0.302000 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 005 / 011 | Total loss: 2.471 | Reg loss: 0.037 | Tree loss: 2.471 | Accuracy: 0.306000 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 006 / 011 | Total loss: 2.463 | Reg loss: 0.037 | Tree loss: 2.463 | Accuracy: 0.281000 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 007 / 011 | Total loss: 2.462 | Reg loss: 0.037 | Tree loss: 2.462 | Accuracy: 0.289000 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 008 / 011 | Total loss: 2.427 | Reg loss: 0.037 | Tree loss: 2.427 | Accuracy: 0.271500 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 009 / 011 | Total loss: 2.416 | Reg loss: 0.037 | Tree loss: 2.416 | Accuracy: 0.247500 | 0.872 sec/iter\n",
      "Epoch: 133 | Batch: 010 / 011 | Total loss: 2.456 | Reg loss: 0.037 | Tree loss: 2.456 | Accuracy: 0.235495 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 134 | Batch: 000 / 011 | Total loss: 2.651 | Reg loss: 0.036 | Tree loss: 2.651 | Accuracy: 0.268000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 001 / 011 | Total loss: 2.614 | Reg loss: 0.037 | Tree loss: 2.614 | Accuracy: 0.289000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 002 / 011 | Total loss: 2.568 | Reg loss: 0.037 | Tree loss: 2.568 | Accuracy: 0.283000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 003 / 011 | Total loss: 2.559 | Reg loss: 0.037 | Tree loss: 2.559 | Accuracy: 0.265000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 004 / 011 | Total loss: 2.498 | Reg loss: 0.037 | Tree loss: 2.498 | Accuracy: 0.293000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 005 / 011 | Total loss: 2.460 | Reg loss: 0.037 | Tree loss: 2.460 | Accuracy: 0.292000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 006 / 011 | Total loss: 2.491 | Reg loss: 0.037 | Tree loss: 2.491 | Accuracy: 0.268500 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 007 / 011 | Total loss: 2.442 | Reg loss: 0.037 | Tree loss: 2.442 | Accuracy: 0.271000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 008 / 011 | Total loss: 2.433 | Reg loss: 0.037 | Tree loss: 2.433 | Accuracy: 0.268000 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 009 / 011 | Total loss: 2.429 | Reg loss: 0.037 | Tree loss: 2.429 | Accuracy: 0.249500 | 0.872 sec/iter\n",
      "Epoch: 134 | Batch: 010 / 011 | Total loss: 2.390 | Reg loss: 0.037 | Tree loss: 2.390 | Accuracy: 0.249147 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135 | Batch: 000 / 011 | Total loss: 2.637 | Reg loss: 0.037 | Tree loss: 2.637 | Accuracy: 0.264000 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 001 / 011 | Total loss: 2.611 | Reg loss: 0.037 | Tree loss: 2.611 | Accuracy: 0.264000 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 002 / 011 | Total loss: 2.582 | Reg loss: 0.037 | Tree loss: 2.582 | Accuracy: 0.276000 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 003 / 011 | Total loss: 2.580 | Reg loss: 0.037 | Tree loss: 2.580 | Accuracy: 0.278500 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 004 / 011 | Total loss: 2.497 | Reg loss: 0.037 | Tree loss: 2.497 | Accuracy: 0.303000 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 005 / 011 | Total loss: 2.485 | Reg loss: 0.037 | Tree loss: 2.485 | Accuracy: 0.281500 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 006 / 011 | Total loss: 2.462 | Reg loss: 0.037 | Tree loss: 2.462 | Accuracy: 0.284500 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.037 | Tree loss: 2.419 | Accuracy: 0.311500 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.037 | Tree loss: 2.403 | Accuracy: 0.277500 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 009 / 011 | Total loss: 2.444 | Reg loss: 0.037 | Tree loss: 2.444 | Accuracy: 0.257500 | 0.872 sec/iter\n",
      "Epoch: 135 | Batch: 010 / 011 | Total loss: 2.457 | Reg loss: 0.037 | Tree loss: 2.457 | Accuracy: 0.259386 | 0.872 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 136 | Batch: 000 / 011 | Total loss: 2.636 | Reg loss: 0.037 | Tree loss: 2.636 | Accuracy: 0.270000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 001 / 011 | Total loss: 2.594 | Reg loss: 0.037 | Tree loss: 2.594 | Accuracy: 0.288000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 002 / 011 | Total loss: 2.573 | Reg loss: 0.037 | Tree loss: 2.573 | Accuracy: 0.287500 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 003 / 011 | Total loss: 2.548 | Reg loss: 0.037 | Tree loss: 2.548 | Accuracy: 0.293000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 004 / 011 | Total loss: 2.509 | Reg loss: 0.037 | Tree loss: 2.509 | Accuracy: 0.283500 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 005 / 011 | Total loss: 2.472 | Reg loss: 0.037 | Tree loss: 2.472 | Accuracy: 0.281000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 006 / 011 | Total loss: 2.474 | Reg loss: 0.037 | Tree loss: 2.474 | Accuracy: 0.272500 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 007 / 011 | Total loss: 2.433 | Reg loss: 0.037 | Tree loss: 2.433 | Accuracy: 0.262000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 008 / 011 | Total loss: 2.431 | Reg loss: 0.037 | Tree loss: 2.431 | Accuracy: 0.261000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 009 / 011 | Total loss: 2.429 | Reg loss: 0.037 | Tree loss: 2.429 | Accuracy: 0.249000 | 0.872 sec/iter\n",
      "Epoch: 136 | Batch: 010 / 011 | Total loss: 2.399 | Reg loss: 0.037 | Tree loss: 2.399 | Accuracy: 0.242321 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 137 | Batch: 000 / 011 | Total loss: 2.650 | Reg loss: 0.037 | Tree loss: 2.650 | Accuracy: 0.260000 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 001 / 011 | Total loss: 2.626 | Reg loss: 0.037 | Tree loss: 2.626 | Accuracy: 0.269000 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 002 / 011 | Total loss: 2.576 | Reg loss: 0.037 | Tree loss: 2.576 | Accuracy: 0.291000 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 003 / 011 | Total loss: 2.518 | Reg loss: 0.037 | Tree loss: 2.518 | Accuracy: 0.301000 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 004 / 011 | Total loss: 2.502 | Reg loss: 0.037 | Tree loss: 2.502 | Accuracy: 0.283500 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 005 / 011 | Total loss: 2.487 | Reg loss: 0.037 | Tree loss: 2.487 | Accuracy: 0.300500 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 006 / 011 | Total loss: 2.450 | Reg loss: 0.037 | Tree loss: 2.450 | Accuracy: 0.296500 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 007 / 011 | Total loss: 2.459 | Reg loss: 0.037 | Tree loss: 2.459 | Accuracy: 0.274000 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.037 | Tree loss: 2.398 | Accuracy: 0.279500 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 009 / 011 | Total loss: 2.430 | Reg loss: 0.037 | Tree loss: 2.430 | Accuracy: 0.259000 | 0.871 sec/iter\n",
      "Epoch: 137 | Batch: 010 / 011 | Total loss: 2.493 | Reg loss: 0.037 | Tree loss: 2.493 | Accuracy: 0.238908 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 138 | Batch: 000 / 011 | Total loss: 2.648 | Reg loss: 0.037 | Tree loss: 2.648 | Accuracy: 0.271500 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 001 / 011 | Total loss: 2.631 | Reg loss: 0.037 | Tree loss: 2.631 | Accuracy: 0.263500 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 002 / 011 | Total loss: 2.565 | Reg loss: 0.037 | Tree loss: 2.565 | Accuracy: 0.286500 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 003 / 011 | Total loss: 2.521 | Reg loss: 0.037 | Tree loss: 2.521 | Accuracy: 0.297500 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 004 / 011 | Total loss: 2.507 | Reg loss: 0.037 | Tree loss: 2.507 | Accuracy: 0.289000 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 005 / 011 | Total loss: 2.469 | Reg loss: 0.037 | Tree loss: 2.469 | Accuracy: 0.300000 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 006 / 011 | Total loss: 2.452 | Reg loss: 0.037 | Tree loss: 2.452 | Accuracy: 0.289500 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.037 | Tree loss: 2.425 | Accuracy: 0.281500 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 008 / 011 | Total loss: 2.463 | Reg loss: 0.037 | Tree loss: 2.463 | Accuracy: 0.244000 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 009 / 011 | Total loss: 2.421 | Reg loss: 0.037 | Tree loss: 2.421 | Accuracy: 0.252000 | 0.871 sec/iter\n",
      "Epoch: 138 | Batch: 010 / 011 | Total loss: 2.353 | Reg loss: 0.037 | Tree loss: 2.353 | Accuracy: 0.300341 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 139 | Batch: 000 / 011 | Total loss: 2.647 | Reg loss: 0.037 | Tree loss: 2.647 | Accuracy: 0.261500 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 001 / 011 | Total loss: 2.604 | Reg loss: 0.037 | Tree loss: 2.604 | Accuracy: 0.255000 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 002 / 011 | Total loss: 2.559 | Reg loss: 0.037 | Tree loss: 2.559 | Accuracy: 0.293000 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 003 / 011 | Total loss: 2.543 | Reg loss: 0.037 | Tree loss: 2.543 | Accuracy: 0.258500 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 004 / 011 | Total loss: 2.496 | Reg loss: 0.037 | Tree loss: 2.496 | Accuracy: 0.293500 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.037 | Tree loss: 2.461 | Accuracy: 0.290500 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 006 / 011 | Total loss: 2.478 | Reg loss: 0.037 | Tree loss: 2.478 | Accuracy: 0.282500 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 007 / 011 | Total loss: 2.469 | Reg loss: 0.037 | Tree loss: 2.469 | Accuracy: 0.284000 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 008 / 011 | Total loss: 2.406 | Reg loss: 0.037 | Tree loss: 2.406 | Accuracy: 0.281500 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 009 / 011 | Total loss: 2.412 | Reg loss: 0.037 | Tree loss: 2.412 | Accuracy: 0.256000 | 0.871 sec/iter\n",
      "Epoch: 139 | Batch: 010 / 011 | Total loss: 2.453 | Reg loss: 0.037 | Tree loss: 2.453 | Accuracy: 0.269625 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 | Batch: 000 / 011 | Total loss: 2.643 | Reg loss: 0.037 | Tree loss: 2.643 | Accuracy: 0.268000 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 001 / 011 | Total loss: 2.627 | Reg loss: 0.037 | Tree loss: 2.627 | Accuracy: 0.279000 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 002 / 011 | Total loss: 2.562 | Reg loss: 0.037 | Tree loss: 2.562 | Accuracy: 0.286000 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 003 / 011 | Total loss: 2.526 | Reg loss: 0.037 | Tree loss: 2.526 | Accuracy: 0.290500 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 004 / 011 | Total loss: 2.508 | Reg loss: 0.037 | Tree loss: 2.508 | Accuracy: 0.288000 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 005 / 011 | Total loss: 2.460 | Reg loss: 0.037 | Tree loss: 2.460 | Accuracy: 0.303500 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 006 / 011 | Total loss: 2.449 | Reg loss: 0.037 | Tree loss: 2.449 | Accuracy: 0.300500 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 007 / 011 | Total loss: 2.445 | Reg loss: 0.037 | Tree loss: 2.445 | Accuracy: 0.281500 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 008 / 011 | Total loss: 2.429 | Reg loss: 0.037 | Tree loss: 2.429 | Accuracy: 0.263000 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 009 / 011 | Total loss: 2.413 | Reg loss: 0.037 | Tree loss: 2.413 | Accuracy: 0.252000 | 0.871 sec/iter\n",
      "Epoch: 140 | Batch: 010 / 011 | Total loss: 2.446 | Reg loss: 0.037 | Tree loss: 2.446 | Accuracy: 0.245734 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 141 | Batch: 000 / 011 | Total loss: 2.645 | Reg loss: 0.037 | Tree loss: 2.645 | Accuracy: 0.259000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 001 / 011 | Total loss: 2.607 | Reg loss: 0.037 | Tree loss: 2.607 | Accuracy: 0.267000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 002 / 011 | Total loss: 2.582 | Reg loss: 0.037 | Tree loss: 2.582 | Accuracy: 0.278000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 003 / 011 | Total loss: 2.526 | Reg loss: 0.037 | Tree loss: 2.526 | Accuracy: 0.285000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 004 / 011 | Total loss: 2.505 | Reg loss: 0.037 | Tree loss: 2.505 | Accuracy: 0.290500 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 005 / 011 | Total loss: 2.488 | Reg loss: 0.037 | Tree loss: 2.488 | Accuracy: 0.291000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.037 | Tree loss: 2.433 | Accuracy: 0.285000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 007 / 011 | Total loss: 2.438 | Reg loss: 0.037 | Tree loss: 2.438 | Accuracy: 0.294500 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.037 | Tree loss: 2.402 | Accuracy: 0.267000 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 009 / 011 | Total loss: 2.441 | Reg loss: 0.037 | Tree loss: 2.441 | Accuracy: 0.244500 | 0.871 sec/iter\n",
      "Epoch: 141 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.037 | Tree loss: 2.372 | Accuracy: 0.300341 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 142 | Batch: 000 / 011 | Total loss: 2.637 | Reg loss: 0.037 | Tree loss: 2.637 | Accuracy: 0.279000 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 001 / 011 | Total loss: 2.605 | Reg loss: 0.037 | Tree loss: 2.605 | Accuracy: 0.281500 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 002 / 011 | Total loss: 2.565 | Reg loss: 0.037 | Tree loss: 2.565 | Accuracy: 0.275500 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.037 | Tree loss: 2.498 | Accuracy: 0.323000 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 004 / 011 | Total loss: 2.494 | Reg loss: 0.037 | Tree loss: 2.494 | Accuracy: 0.284000 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 005 / 011 | Total loss: 2.471 | Reg loss: 0.037 | Tree loss: 2.471 | Accuracy: 0.282000 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 006 / 011 | Total loss: 2.457 | Reg loss: 0.037 | Tree loss: 2.457 | Accuracy: 0.279000 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 007 / 011 | Total loss: 2.435 | Reg loss: 0.037 | Tree loss: 2.435 | Accuracy: 0.276500 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 008 / 011 | Total loss: 2.445 | Reg loss: 0.037 | Tree loss: 2.445 | Accuracy: 0.270000 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 009 / 011 | Total loss: 2.446 | Reg loss: 0.037 | Tree loss: 2.446 | Accuracy: 0.242500 | 0.871 sec/iter\n",
      "Epoch: 142 | Batch: 010 / 011 | Total loss: 2.491 | Reg loss: 0.037 | Tree loss: 2.491 | Accuracy: 0.225256 | 0.871 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 143 | Batch: 000 / 011 | Total loss: 2.632 | Reg loss: 0.037 | Tree loss: 2.632 | Accuracy: 0.270500 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 001 / 011 | Total loss: 2.605 | Reg loss: 0.037 | Tree loss: 2.605 | Accuracy: 0.270500 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 002 / 011 | Total loss: 2.586 | Reg loss: 0.037 | Tree loss: 2.586 | Accuracy: 0.273500 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 003 / 011 | Total loss: 2.534 | Reg loss: 0.037 | Tree loss: 2.534 | Accuracy: 0.268000 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 004 / 011 | Total loss: 2.491 | Reg loss: 0.037 | Tree loss: 2.491 | Accuracy: 0.292000 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 005 / 011 | Total loss: 2.472 | Reg loss: 0.037 | Tree loss: 2.472 | Accuracy: 0.305000 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 006 / 011 | Total loss: 2.448 | Reg loss: 0.037 | Tree loss: 2.448 | Accuracy: 0.302000 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 007 / 011 | Total loss: 2.444 | Reg loss: 0.037 | Tree loss: 2.444 | Accuracy: 0.274000 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 008 / 011 | Total loss: 2.428 | Reg loss: 0.037 | Tree loss: 2.428 | Accuracy: 0.280500 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.253500 | 0.871 sec/iter\n",
      "Epoch: 143 | Batch: 010 / 011 | Total loss: 2.405 | Reg loss: 0.037 | Tree loss: 2.405 | Accuracy: 0.262799 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 144 | Batch: 000 / 011 | Total loss: 2.615 | Reg loss: 0.037 | Tree loss: 2.615 | Accuracy: 0.269000 | 0.871 sec/iter\n",
      "Epoch: 144 | Batch: 001 / 011 | Total loss: 2.589 | Reg loss: 0.037 | Tree loss: 2.589 | Accuracy: 0.271000 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 002 / 011 | Total loss: 2.588 | Reg loss: 0.037 | Tree loss: 2.588 | Accuracy: 0.276500 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 003 / 011 | Total loss: 2.549 | Reg loss: 0.037 | Tree loss: 2.549 | Accuracy: 0.294000 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 004 / 011 | Total loss: 2.522 | Reg loss: 0.037 | Tree loss: 2.522 | Accuracy: 0.287000 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 005 / 011 | Total loss: 2.471 | Reg loss: 0.037 | Tree loss: 2.471 | Accuracy: 0.290500 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 006 / 011 | Total loss: 2.429 | Reg loss: 0.037 | Tree loss: 2.429 | Accuracy: 0.298000 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 007 / 011 | Total loss: 2.439 | Reg loss: 0.037 | Tree loss: 2.439 | Accuracy: 0.298500 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.037 | Tree loss: 2.405 | Accuracy: 0.275000 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 009 / 011 | Total loss: 2.411 | Reg loss: 0.037 | Tree loss: 2.411 | Accuracy: 0.252500 | 0.87 sec/iter\n",
      "Epoch: 144 | Batch: 010 / 011 | Total loss: 2.440 | Reg loss: 0.037 | Tree loss: 2.440 | Accuracy: 0.238908 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145 | Batch: 000 / 011 | Total loss: 2.649 | Reg loss: 0.037 | Tree loss: 2.649 | Accuracy: 0.253500 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 001 / 011 | Total loss: 2.602 | Reg loss: 0.037 | Tree loss: 2.602 | Accuracy: 0.256500 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 002 / 011 | Total loss: 2.571 | Reg loss: 0.037 | Tree loss: 2.571 | Accuracy: 0.290000 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 003 / 011 | Total loss: 2.547 | Reg loss: 0.037 | Tree loss: 2.547 | Accuracy: 0.265500 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 004 / 011 | Total loss: 2.482 | Reg loss: 0.037 | Tree loss: 2.482 | Accuracy: 0.295000 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.037 | Tree loss: 2.461 | Accuracy: 0.302000 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 006 / 011 | Total loss: 2.446 | Reg loss: 0.037 | Tree loss: 2.446 | Accuracy: 0.301500 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 007 / 011 | Total loss: 2.424 | Reg loss: 0.037 | Tree loss: 2.424 | Accuracy: 0.306500 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 008 / 011 | Total loss: 2.437 | Reg loss: 0.037 | Tree loss: 2.437 | Accuracy: 0.256000 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.252500 | 0.87 sec/iter\n",
      "Epoch: 145 | Batch: 010 / 011 | Total loss: 2.397 | Reg loss: 0.037 | Tree loss: 2.397 | Accuracy: 0.245734 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 146 | Batch: 000 / 011 | Total loss: 2.626 | Reg loss: 0.037 | Tree loss: 2.626 | Accuracy: 0.271500 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 001 / 011 | Total loss: 2.599 | Reg loss: 0.037 | Tree loss: 2.599 | Accuracy: 0.269000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 002 / 011 | Total loss: 2.568 | Reg loss: 0.037 | Tree loss: 2.568 | Accuracy: 0.273000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 003 / 011 | Total loss: 2.529 | Reg loss: 0.037 | Tree loss: 2.529 | Accuracy: 0.268000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 004 / 011 | Total loss: 2.500 | Reg loss: 0.037 | Tree loss: 2.500 | Accuracy: 0.301000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.037 | Tree loss: 2.461 | Accuracy: 0.289500 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 006 / 011 | Total loss: 2.452 | Reg loss: 0.037 | Tree loss: 2.452 | Accuracy: 0.283000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.037 | Tree loss: 2.407 | Accuracy: 0.293000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 008 / 011 | Total loss: 2.434 | Reg loss: 0.037 | Tree loss: 2.434 | Accuracy: 0.258000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 009 / 011 | Total loss: 2.432 | Reg loss: 0.037 | Tree loss: 2.432 | Accuracy: 0.255000 | 0.87 sec/iter\n",
      "Epoch: 146 | Batch: 010 / 011 | Total loss: 2.422 | Reg loss: 0.037 | Tree loss: 2.422 | Accuracy: 0.245734 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 147 | Batch: 000 / 011 | Total loss: 2.653 | Reg loss: 0.037 | Tree loss: 2.653 | Accuracy: 0.253000 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 001 / 011 | Total loss: 2.596 | Reg loss: 0.037 | Tree loss: 2.596 | Accuracy: 0.266000 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 002 / 011 | Total loss: 2.562 | Reg loss: 0.037 | Tree loss: 2.562 | Accuracy: 0.302000 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 003 / 011 | Total loss: 2.525 | Reg loss: 0.037 | Tree loss: 2.525 | Accuracy: 0.286500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 004 / 011 | Total loss: 2.496 | Reg loss: 0.037 | Tree loss: 2.496 | Accuracy: 0.298500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 005 / 011 | Total loss: 2.481 | Reg loss: 0.037 | Tree loss: 2.481 | Accuracy: 0.299500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 006 / 011 | Total loss: 2.467 | Reg loss: 0.037 | Tree loss: 2.467 | Accuracy: 0.282500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 007 / 011 | Total loss: 2.413 | Reg loss: 0.037 | Tree loss: 2.413 | Accuracy: 0.299500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 008 / 011 | Total loss: 2.412 | Reg loss: 0.037 | Tree loss: 2.412 | Accuracy: 0.271500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 009 / 011 | Total loss: 2.409 | Reg loss: 0.037 | Tree loss: 2.409 | Accuracy: 0.251500 | 0.87 sec/iter\n",
      "Epoch: 147 | Batch: 010 / 011 | Total loss: 2.403 | Reg loss: 0.037 | Tree loss: 2.403 | Accuracy: 0.273038 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 148 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.037 | Tree loss: 2.624 | Accuracy: 0.274000 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 001 / 011 | Total loss: 2.636 | Reg loss: 0.037 | Tree loss: 2.636 | Accuracy: 0.263000 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 002 / 011 | Total loss: 2.575 | Reg loss: 0.037 | Tree loss: 2.575 | Accuracy: 0.276500 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.037 | Tree loss: 2.487 | Accuracy: 0.307500 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 004 / 011 | Total loss: 2.485 | Reg loss: 0.037 | Tree loss: 2.485 | Accuracy: 0.291000 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 005 / 011 | Total loss: 2.478 | Reg loss: 0.037 | Tree loss: 2.478 | Accuracy: 0.296000 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 006 / 011 | Total loss: 2.446 | Reg loss: 0.037 | Tree loss: 2.446 | Accuracy: 0.266500 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 007 / 011 | Total loss: 2.426 | Reg loss: 0.037 | Tree loss: 2.426 | Accuracy: 0.279000 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 008 / 011 | Total loss: 2.425 | Reg loss: 0.037 | Tree loss: 2.425 | Accuracy: 0.260500 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 009 / 011 | Total loss: 2.420 | Reg loss: 0.037 | Tree loss: 2.420 | Accuracy: 0.255500 | 0.87 sec/iter\n",
      "Epoch: 148 | Batch: 010 / 011 | Total loss: 2.390 | Reg loss: 0.037 | Tree loss: 2.390 | Accuracy: 0.221843 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 149 | Batch: 000 / 011 | Total loss: 2.623 | Reg loss: 0.037 | Tree loss: 2.623 | Accuracy: 0.270000 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 001 / 011 | Total loss: 2.614 | Reg loss: 0.037 | Tree loss: 2.614 | Accuracy: 0.255500 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 002 / 011 | Total loss: 2.585 | Reg loss: 0.037 | Tree loss: 2.585 | Accuracy: 0.260000 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 003 / 011 | Total loss: 2.522 | Reg loss: 0.037 | Tree loss: 2.522 | Accuracy: 0.294500 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 004 / 011 | Total loss: 2.488 | Reg loss: 0.037 | Tree loss: 2.488 | Accuracy: 0.308500 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 005 / 011 | Total loss: 2.455 | Reg loss: 0.037 | Tree loss: 2.455 | Accuracy: 0.287500 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 006 / 011 | Total loss: 2.446 | Reg loss: 0.037 | Tree loss: 2.446 | Accuracy: 0.300000 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 007 / 011 | Total loss: 2.447 | Reg loss: 0.037 | Tree loss: 2.447 | Accuracy: 0.283000 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 008 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.294000 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.265000 | 0.87 sec/iter\n",
      "Epoch: 149 | Batch: 010 / 011 | Total loss: 2.454 | Reg loss: 0.037 | Tree loss: 2.454 | Accuracy: 0.221843 | 0.87 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150 | Batch: 000 / 011 | Total loss: 2.623 | Reg loss: 0.037 | Tree loss: 2.623 | Accuracy: 0.268500 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 001 / 011 | Total loss: 2.600 | Reg loss: 0.037 | Tree loss: 2.600 | Accuracy: 0.276500 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 002 / 011 | Total loss: 2.574 | Reg loss: 0.037 | Tree loss: 2.574 | Accuracy: 0.267500 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 003 / 011 | Total loss: 2.537 | Reg loss: 0.037 | Tree loss: 2.537 | Accuracy: 0.270000 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 004 / 011 | Total loss: 2.474 | Reg loss: 0.037 | Tree loss: 2.474 | Accuracy: 0.302000 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 005 / 011 | Total loss: 2.455 | Reg loss: 0.037 | Tree loss: 2.455 | Accuracy: 0.307000 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 006 / 011 | Total loss: 2.439 | Reg loss: 0.037 | Tree loss: 2.439 | Accuracy: 0.300500 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 007 / 011 | Total loss: 2.434 | Reg loss: 0.037 | Tree loss: 2.434 | Accuracy: 0.282000 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 008 / 011 | Total loss: 2.415 | Reg loss: 0.037 | Tree loss: 2.415 | Accuracy: 0.270000 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 009 / 011 | Total loss: 2.428 | Reg loss: 0.037 | Tree loss: 2.428 | Accuracy: 0.254500 | 0.87 sec/iter\n",
      "Epoch: 150 | Batch: 010 / 011 | Total loss: 2.370 | Reg loss: 0.037 | Tree loss: 2.370 | Accuracy: 0.269625 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 151 | Batch: 000 / 011 | Total loss: 2.627 | Reg loss: 0.037 | Tree loss: 2.627 | Accuracy: 0.267000 | 0.87 sec/iter\n",
      "Epoch: 151 | Batch: 001 / 011 | Total loss: 2.585 | Reg loss: 0.037 | Tree loss: 2.585 | Accuracy: 0.283500 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 002 / 011 | Total loss: 2.540 | Reg loss: 0.037 | Tree loss: 2.540 | Accuracy: 0.272000 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 003 / 011 | Total loss: 2.529 | Reg loss: 0.037 | Tree loss: 2.529 | Accuracy: 0.287500 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 004 / 011 | Total loss: 2.495 | Reg loss: 0.037 | Tree loss: 2.495 | Accuracy: 0.298500 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 005 / 011 | Total loss: 2.474 | Reg loss: 0.037 | Tree loss: 2.474 | Accuracy: 0.296000 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 006 / 011 | Total loss: 2.450 | Reg loss: 0.037 | Tree loss: 2.450 | Accuracy: 0.277500 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 007 / 011 | Total loss: 2.424 | Reg loss: 0.037 | Tree loss: 2.424 | Accuracy: 0.293000 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 008 / 011 | Total loss: 2.421 | Reg loss: 0.037 | Tree loss: 2.421 | Accuracy: 0.273500 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 009 / 011 | Total loss: 2.430 | Reg loss: 0.037 | Tree loss: 2.430 | Accuracy: 0.245500 | 0.869 sec/iter\n",
      "Epoch: 151 | Batch: 010 / 011 | Total loss: 2.393 | Reg loss: 0.037 | Tree loss: 2.393 | Accuracy: 0.252560 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 152 | Batch: 000 / 011 | Total loss: 2.639 | Reg loss: 0.037 | Tree loss: 2.639 | Accuracy: 0.267000 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 001 / 011 | Total loss: 2.598 | Reg loss: 0.037 | Tree loss: 2.598 | Accuracy: 0.276500 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 002 / 011 | Total loss: 2.572 | Reg loss: 0.037 | Tree loss: 2.572 | Accuracy: 0.276500 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 003 / 011 | Total loss: 2.508 | Reg loss: 0.037 | Tree loss: 2.508 | Accuracy: 0.309000 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 004 / 011 | Total loss: 2.494 | Reg loss: 0.037 | Tree loss: 2.494 | Accuracy: 0.292000 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 005 / 011 | Total loss: 2.472 | Reg loss: 0.037 | Tree loss: 2.472 | Accuracy: 0.299000 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 006 / 011 | Total loss: 2.428 | Reg loss: 0.037 | Tree loss: 2.428 | Accuracy: 0.291500 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.037 | Tree loss: 2.418 | Accuracy: 0.298500 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 008 / 011 | Total loss: 2.439 | Reg loss: 0.037 | Tree loss: 2.439 | Accuracy: 0.270500 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.037 | Tree loss: 2.403 | Accuracy: 0.263500 | 0.869 sec/iter\n",
      "Epoch: 152 | Batch: 010 / 011 | Total loss: 2.361 | Reg loss: 0.037 | Tree loss: 2.361 | Accuracy: 0.255973 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 153 | Batch: 000 / 011 | Total loss: 2.610 | Reg loss: 0.037 | Tree loss: 2.610 | Accuracy: 0.270500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 001 / 011 | Total loss: 2.601 | Reg loss: 0.037 | Tree loss: 2.601 | Accuracy: 0.265500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 002 / 011 | Total loss: 2.544 | Reg loss: 0.037 | Tree loss: 2.544 | Accuracy: 0.297500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 003 / 011 | Total loss: 2.533 | Reg loss: 0.037 | Tree loss: 2.533 | Accuracy: 0.304500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 004 / 011 | Total loss: 2.497 | Reg loss: 0.037 | Tree loss: 2.497 | Accuracy: 0.285500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 005 / 011 | Total loss: 2.470 | Reg loss: 0.037 | Tree loss: 2.470 | Accuracy: 0.289500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 006 / 011 | Total loss: 2.437 | Reg loss: 0.037 | Tree loss: 2.437 | Accuracy: 0.294000 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 007 / 011 | Total loss: 2.439 | Reg loss: 0.037 | Tree loss: 2.439 | Accuracy: 0.272000 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 008 / 011 | Total loss: 2.435 | Reg loss: 0.037 | Tree loss: 2.435 | Accuracy: 0.261000 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 009 / 011 | Total loss: 2.406 | Reg loss: 0.037 | Tree loss: 2.406 | Accuracy: 0.264500 | 0.869 sec/iter\n",
      "Epoch: 153 | Batch: 010 / 011 | Total loss: 2.368 | Reg loss: 0.037 | Tree loss: 2.368 | Accuracy: 0.269625 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 154 | Batch: 000 / 011 | Total loss: 2.630 | Reg loss: 0.037 | Tree loss: 2.630 | Accuracy: 0.267000 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 001 / 011 | Total loss: 2.612 | Reg loss: 0.037 | Tree loss: 2.612 | Accuracy: 0.256000 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 002 / 011 | Total loss: 2.576 | Reg loss: 0.037 | Tree loss: 2.576 | Accuracy: 0.265000 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 003 / 011 | Total loss: 2.530 | Reg loss: 0.037 | Tree loss: 2.530 | Accuracy: 0.284500 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 004 / 011 | Total loss: 2.502 | Reg loss: 0.037 | Tree loss: 2.502 | Accuracy: 0.294500 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 005 / 011 | Total loss: 2.430 | Reg loss: 0.037 | Tree loss: 2.430 | Accuracy: 0.321000 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.037 | Tree loss: 2.433 | Accuracy: 0.291500 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 007 / 011 | Total loss: 2.420 | Reg loss: 0.037 | Tree loss: 2.420 | Accuracy: 0.297500 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 008 / 011 | Total loss: 2.407 | Reg loss: 0.037 | Tree loss: 2.407 | Accuracy: 0.284500 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 009 / 011 | Total loss: 2.428 | Reg loss: 0.037 | Tree loss: 2.428 | Accuracy: 0.253000 | 0.869 sec/iter\n",
      "Epoch: 154 | Batch: 010 / 011 | Total loss: 2.404 | Reg loss: 0.037 | Tree loss: 2.404 | Accuracy: 0.273038 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.037 | Tree loss: 2.624 | Accuracy: 0.261000 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 001 / 011 | Total loss: 2.579 | Reg loss: 0.037 | Tree loss: 2.579 | Accuracy: 0.276500 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 002 / 011 | Total loss: 2.552 | Reg loss: 0.037 | Tree loss: 2.552 | Accuracy: 0.282500 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 003 / 011 | Total loss: 2.525 | Reg loss: 0.037 | Tree loss: 2.525 | Accuracy: 0.295500 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 004 / 011 | Total loss: 2.502 | Reg loss: 0.037 | Tree loss: 2.502 | Accuracy: 0.292000 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 005 / 011 | Total loss: 2.454 | Reg loss: 0.037 | Tree loss: 2.454 | Accuracy: 0.292000 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.037 | Tree loss: 2.438 | Accuracy: 0.283000 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 007 / 011 | Total loss: 2.450 | Reg loss: 0.037 | Tree loss: 2.450 | Accuracy: 0.265500 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.037 | Tree loss: 2.402 | Accuracy: 0.293000 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.258500 | 0.869 sec/iter\n",
      "Epoch: 155 | Batch: 010 / 011 | Total loss: 2.466 | Reg loss: 0.037 | Tree loss: 2.466 | Accuracy: 0.218430 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 156 | Batch: 000 / 011 | Total loss: 2.623 | Reg loss: 0.037 | Tree loss: 2.623 | Accuracy: 0.263500 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 001 / 011 | Total loss: 2.589 | Reg loss: 0.037 | Tree loss: 2.589 | Accuracy: 0.276000 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 002 / 011 | Total loss: 2.561 | Reg loss: 0.037 | Tree loss: 2.561 | Accuracy: 0.286500 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 003 / 011 | Total loss: 2.514 | Reg loss: 0.037 | Tree loss: 2.514 | Accuracy: 0.307000 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.037 | Tree loss: 2.470 | Accuracy: 0.298000 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 005 / 011 | Total loss: 2.478 | Reg loss: 0.037 | Tree loss: 2.478 | Accuracy: 0.262500 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 006 / 011 | Total loss: 2.466 | Reg loss: 0.037 | Tree loss: 2.466 | Accuracy: 0.279500 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 007 / 011 | Total loss: 2.421 | Reg loss: 0.037 | Tree loss: 2.421 | Accuracy: 0.288500 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 008 / 011 | Total loss: 2.415 | Reg loss: 0.037 | Tree loss: 2.415 | Accuracy: 0.268000 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 009 / 011 | Total loss: 2.407 | Reg loss: 0.037 | Tree loss: 2.407 | Accuracy: 0.263000 | 0.869 sec/iter\n",
      "Epoch: 156 | Batch: 010 / 011 | Total loss: 2.414 | Reg loss: 0.037 | Tree loss: 2.414 | Accuracy: 0.245734 | 0.869 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 157 | Batch: 000 / 011 | Total loss: 2.589 | Reg loss: 0.037 | Tree loss: 2.589 | Accuracy: 0.291000 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 001 / 011 | Total loss: 2.582 | Reg loss: 0.037 | Tree loss: 2.582 | Accuracy: 0.271000 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 002 / 011 | Total loss: 2.558 | Reg loss: 0.037 | Tree loss: 2.558 | Accuracy: 0.281500 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 003 / 011 | Total loss: 2.517 | Reg loss: 0.037 | Tree loss: 2.517 | Accuracy: 0.279000 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 004 / 011 | Total loss: 2.507 | Reg loss: 0.037 | Tree loss: 2.507 | Accuracy: 0.292500 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 005 / 011 | Total loss: 2.470 | Reg loss: 0.037 | Tree loss: 2.470 | Accuracy: 0.290000 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 006 / 011 | Total loss: 2.440 | Reg loss: 0.037 | Tree loss: 2.440 | Accuracy: 0.294000 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 007 / 011 | Total loss: 2.424 | Reg loss: 0.037 | Tree loss: 2.424 | Accuracy: 0.295000 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 008 / 011 | Total loss: 2.430 | Reg loss: 0.037 | Tree loss: 2.430 | Accuracy: 0.255500 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 009 / 011 | Total loss: 2.434 | Reg loss: 0.037 | Tree loss: 2.434 | Accuracy: 0.260500 | 0.869 sec/iter\n",
      "Epoch: 157 | Batch: 010 / 011 | Total loss: 2.324 | Reg loss: 0.037 | Tree loss: 2.324 | Accuracy: 0.286689 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 158 | Batch: 000 / 011 | Total loss: 2.597 | Reg loss: 0.037 | Tree loss: 2.597 | Accuracy: 0.288500 | 0.869 sec/iter\n",
      "Epoch: 158 | Batch: 001 / 011 | Total loss: 2.620 | Reg loss: 0.037 | Tree loss: 2.620 | Accuracy: 0.271000 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 002 / 011 | Total loss: 2.541 | Reg loss: 0.037 | Tree loss: 2.541 | Accuracy: 0.255500 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 003 / 011 | Total loss: 2.539 | Reg loss: 0.037 | Tree loss: 2.539 | Accuracy: 0.273000 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.037 | Tree loss: 2.464 | Accuracy: 0.304000 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 005 / 011 | Total loss: 2.453 | Reg loss: 0.037 | Tree loss: 2.453 | Accuracy: 0.295500 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 006 / 011 | Total loss: 2.441 | Reg loss: 0.037 | Tree loss: 2.441 | Accuracy: 0.282000 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 007 / 011 | Total loss: 2.442 | Reg loss: 0.037 | Tree loss: 2.442 | Accuracy: 0.275500 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 008 / 011 | Total loss: 2.414 | Reg loss: 0.037 | Tree loss: 2.414 | Accuracy: 0.280000 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.037 | Tree loss: 2.410 | Accuracy: 0.269000 | 0.868 sec/iter\n",
      "Epoch: 158 | Batch: 010 / 011 | Total loss: 2.427 | Reg loss: 0.037 | Tree loss: 2.427 | Accuracy: 0.286689 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 159 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.037 | Tree loss: 2.618 | Accuracy: 0.267500 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 001 / 011 | Total loss: 2.604 | Reg loss: 0.037 | Tree loss: 2.604 | Accuracy: 0.251500 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 002 / 011 | Total loss: 2.558 | Reg loss: 0.037 | Tree loss: 2.558 | Accuracy: 0.266000 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.037 | Tree loss: 2.507 | Accuracy: 0.307500 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 004 / 011 | Total loss: 2.512 | Reg loss: 0.037 | Tree loss: 2.512 | Accuracy: 0.280000 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 005 / 011 | Total loss: 2.474 | Reg loss: 0.037 | Tree loss: 2.474 | Accuracy: 0.278000 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 006 / 011 | Total loss: 2.392 | Reg loss: 0.037 | Tree loss: 2.392 | Accuracy: 0.295500 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 007 / 011 | Total loss: 2.427 | Reg loss: 0.037 | Tree loss: 2.427 | Accuracy: 0.301000 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 008 / 011 | Total loss: 2.421 | Reg loss: 0.037 | Tree loss: 2.421 | Accuracy: 0.266500 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 009 / 011 | Total loss: 2.399 | Reg loss: 0.037 | Tree loss: 2.399 | Accuracy: 0.282500 | 0.868 sec/iter\n",
      "Epoch: 159 | Batch: 010 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.266212 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.037 | Tree loss: 2.602 | Accuracy: 0.281500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 001 / 011 | Total loss: 2.598 | Reg loss: 0.037 | Tree loss: 2.598 | Accuracy: 0.281000 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 002 / 011 | Total loss: 2.554 | Reg loss: 0.037 | Tree loss: 2.554 | Accuracy: 0.291500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.037 | Tree loss: 2.507 | Accuracy: 0.275500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.037 | Tree loss: 2.460 | Accuracy: 0.313500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 005 / 011 | Total loss: 2.460 | Reg loss: 0.037 | Tree loss: 2.460 | Accuracy: 0.274500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 006 / 011 | Total loss: 2.453 | Reg loss: 0.037 | Tree loss: 2.453 | Accuracy: 0.277500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 007 / 011 | Total loss: 2.461 | Reg loss: 0.037 | Tree loss: 2.461 | Accuracy: 0.267000 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 008 / 011 | Total loss: 2.422 | Reg loss: 0.037 | Tree loss: 2.422 | Accuracy: 0.263000 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 009 / 011 | Total loss: 2.404 | Reg loss: 0.037 | Tree loss: 2.404 | Accuracy: 0.255500 | 0.868 sec/iter\n",
      "Epoch: 160 | Batch: 010 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.255973 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 161 | Batch: 000 / 011 | Total loss: 2.639 | Reg loss: 0.037 | Tree loss: 2.639 | Accuracy: 0.267000 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 001 / 011 | Total loss: 2.607 | Reg loss: 0.037 | Tree loss: 2.607 | Accuracy: 0.260000 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 002 / 011 | Total loss: 2.539 | Reg loss: 0.037 | Tree loss: 2.539 | Accuracy: 0.286000 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 003 / 011 | Total loss: 2.526 | Reg loss: 0.037 | Tree loss: 2.526 | Accuracy: 0.285500 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.037 | Tree loss: 2.465 | Accuracy: 0.306000 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 005 / 011 | Total loss: 2.469 | Reg loss: 0.037 | Tree loss: 2.469 | Accuracy: 0.289000 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 006 / 011 | Total loss: 2.456 | Reg loss: 0.037 | Tree loss: 2.456 | Accuracy: 0.291500 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 007 / 011 | Total loss: 2.413 | Reg loss: 0.037 | Tree loss: 2.413 | Accuracy: 0.291500 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 008 / 011 | Total loss: 2.409 | Reg loss: 0.037 | Tree loss: 2.409 | Accuracy: 0.287500 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.258500 | 0.868 sec/iter\n",
      "Epoch: 161 | Batch: 010 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.266212 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 162 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.037 | Tree loss: 2.606 | Accuracy: 0.266000 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 001 / 011 | Total loss: 2.602 | Reg loss: 0.037 | Tree loss: 2.602 | Accuracy: 0.273500 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 002 / 011 | Total loss: 2.560 | Reg loss: 0.037 | Tree loss: 2.560 | Accuracy: 0.271000 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.037 | Tree loss: 2.510 | Accuracy: 0.291000 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.037 | Tree loss: 2.478 | Accuracy: 0.288500 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 005 / 011 | Total loss: 2.463 | Reg loss: 0.037 | Tree loss: 2.463 | Accuracy: 0.270000 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 006 / 011 | Total loss: 2.437 | Reg loss: 0.037 | Tree loss: 2.437 | Accuracy: 0.272500 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 007 / 011 | Total loss: 2.421 | Reg loss: 0.037 | Tree loss: 2.421 | Accuracy: 0.273500 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 008 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.257500 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 009 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.255000 | 0.868 sec/iter\n",
      "Epoch: 162 | Batch: 010 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.252560 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 163 | Batch: 000 / 011 | Total loss: 2.604 | Reg loss: 0.037 | Tree loss: 2.604 | Accuracy: 0.267000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 001 / 011 | Total loss: 2.590 | Reg loss: 0.037 | Tree loss: 2.590 | Accuracy: 0.285000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 002 / 011 | Total loss: 2.585 | Reg loss: 0.037 | Tree loss: 2.585 | Accuracy: 0.270000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 003 / 011 | Total loss: 2.502 | Reg loss: 0.037 | Tree loss: 2.502 | Accuracy: 0.306000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 004 / 011 | Total loss: 2.480 | Reg loss: 0.037 | Tree loss: 2.480 | Accuracy: 0.302000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.037 | Tree loss: 2.457 | Accuracy: 0.292000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 006 / 011 | Total loss: 2.444 | Reg loss: 0.037 | Tree loss: 2.444 | Accuracy: 0.303000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 007 / 011 | Total loss: 2.437 | Reg loss: 0.037 | Tree loss: 2.437 | Accuracy: 0.271000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 008 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.257000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 009 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.245000 | 0.868 sec/iter\n",
      "Epoch: 163 | Batch: 010 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.252560 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 164 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.037 | Tree loss: 2.624 | Accuracy: 0.299500 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 001 / 011 | Total loss: 2.592 | Reg loss: 0.037 | Tree loss: 2.592 | Accuracy: 0.278500 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 002 / 011 | Total loss: 2.564 | Reg loss: 0.037 | Tree loss: 2.564 | Accuracy: 0.272500 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 003 / 011 | Total loss: 2.516 | Reg loss: 0.037 | Tree loss: 2.516 | Accuracy: 0.283000 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 004 / 011 | Total loss: 2.484 | Reg loss: 0.037 | Tree loss: 2.484 | Accuracy: 0.296000 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 005 / 011 | Total loss: 2.453 | Reg loss: 0.037 | Tree loss: 2.453 | Accuracy: 0.279500 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.037 | Tree loss: 2.427 | Accuracy: 0.278000 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 007 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.265000 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 008 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.257000 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.241500 | 0.868 sec/iter\n",
      "Epoch: 164 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.259386 | 0.868 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165 | Batch: 000 / 011 | Total loss: 2.615 | Reg loss: 0.037 | Tree loss: 2.615 | Accuracy: 0.276000 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 001 / 011 | Total loss: 2.574 | Reg loss: 0.037 | Tree loss: 2.574 | Accuracy: 0.286500 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 002 / 011 | Total loss: 2.571 | Reg loss: 0.037 | Tree loss: 2.571 | Accuracy: 0.260000 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.037 | Tree loss: 2.507 | Accuracy: 0.284000 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 004 / 011 | Total loss: 2.484 | Reg loss: 0.037 | Tree loss: 2.484 | Accuracy: 0.287500 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 005 / 011 | Total loss: 2.481 | Reg loss: 0.037 | Tree loss: 2.481 | Accuracy: 0.285500 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 006 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.292000 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.287500 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 008 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.270000 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 009 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.263500 | 0.868 sec/iter\n",
      "Epoch: 165 | Batch: 010 / 011 | Total loss: 2.355 | Reg loss: 0.038 | Tree loss: 2.355 | Accuracy: 0.262799 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 166 | Batch: 000 / 011 | Total loss: 2.614 | Reg loss: 0.037 | Tree loss: 2.614 | Accuracy: 0.285000 | 0.868 sec/iter\n",
      "Epoch: 166 | Batch: 001 / 011 | Total loss: 2.565 | Reg loss: 0.037 | Tree loss: 2.565 | Accuracy: 0.276500 | 0.868 sec/iter\n",
      "Epoch: 166 | Batch: 002 / 011 | Total loss: 2.548 | Reg loss: 0.037 | Tree loss: 2.548 | Accuracy: 0.303500 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 003 / 011 | Total loss: 2.537 | Reg loss: 0.037 | Tree loss: 2.537 | Accuracy: 0.280500 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.037 | Tree loss: 2.478 | Accuracy: 0.301500 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 005 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.277500 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 006 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.300000 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 007 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.262500 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.243500 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 009 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.230000 | 0.867 sec/iter\n",
      "Epoch: 166 | Batch: 010 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.266212 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 167 | Batch: 000 / 011 | Total loss: 2.641 | Reg loss: 0.037 | Tree loss: 2.641 | Accuracy: 0.256000 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 001 / 011 | Total loss: 2.578 | Reg loss: 0.037 | Tree loss: 2.578 | Accuracy: 0.281500 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 002 / 011 | Total loss: 2.564 | Reg loss: 0.037 | Tree loss: 2.564 | Accuracy: 0.278500 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.037 | Tree loss: 2.498 | Accuracy: 0.301500 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 004 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.267000 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 005 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.292500 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.287500 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 007 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.292000 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 008 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.284000 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.259500 | 0.867 sec/iter\n",
      "Epoch: 167 | Batch: 010 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.218430 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 168 | Batch: 000 / 011 | Total loss: 2.616 | Reg loss: 0.037 | Tree loss: 2.616 | Accuracy: 0.272000 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 001 / 011 | Total loss: 2.606 | Reg loss: 0.037 | Tree loss: 2.606 | Accuracy: 0.271000 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 002 / 011 | Total loss: 2.563 | Reg loss: 0.037 | Tree loss: 2.563 | Accuracy: 0.290500 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.037 | Tree loss: 2.511 | Accuracy: 0.297500 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 004 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.289000 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.299500 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.277500 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.290500 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 008 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.258000 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 009 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.256000 | 0.867 sec/iter\n",
      "Epoch: 168 | Batch: 010 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.215017 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 169 | Batch: 000 / 011 | Total loss: 2.601 | Reg loss: 0.037 | Tree loss: 2.601 | Accuracy: 0.283000 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 001 / 011 | Total loss: 2.587 | Reg loss: 0.037 | Tree loss: 2.587 | Accuracy: 0.274000 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.037 | Tree loss: 2.535 | Accuracy: 0.282500 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 003 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.302000 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 004 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.285000 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 005 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.290000 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 006 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.285500 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 007 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.289500 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 008 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.257000 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.254500 | 0.867 sec/iter\n",
      "Epoch: 169 | Batch: 010 / 011 | Total loss: 2.365 | Reg loss: 0.038 | Tree loss: 2.365 | Accuracy: 0.242321 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170 | Batch: 000 / 011 | Total loss: 2.607 | Reg loss: 0.037 | Tree loss: 2.607 | Accuracy: 0.266500 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 001 / 011 | Total loss: 2.586 | Reg loss: 0.037 | Tree loss: 2.586 | Accuracy: 0.271000 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 002 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.287500 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.316500 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.293000 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 005 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.287500 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 006 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.284000 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 007 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.264000 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.274000 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 009 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.251000 | 0.867 sec/iter\n",
      "Epoch: 170 | Batch: 010 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.242321 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 171 | Batch: 000 / 011 | Total loss: 2.628 | Reg loss: 0.038 | Tree loss: 2.628 | Accuracy: 0.265000 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 001 / 011 | Total loss: 2.568 | Reg loss: 0.038 | Tree loss: 2.568 | Accuracy: 0.287500 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 002 / 011 | Total loss: 2.550 | Reg loss: 0.038 | Tree loss: 2.550 | Accuracy: 0.272500 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 003 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.274000 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.306000 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 005 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.312500 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.283000 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 007 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.293500 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 008 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.259500 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.263500 | 0.867 sec/iter\n",
      "Epoch: 171 | Batch: 010 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.269625 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 172 | Batch: 000 / 011 | Total loss: 2.626 | Reg loss: 0.038 | Tree loss: 2.626 | Accuracy: 0.260000 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 001 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.268000 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.286500 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 003 / 011 | Total loss: 2.534 | Reg loss: 0.038 | Tree loss: 2.534 | Accuracy: 0.286500 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.296500 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 005 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.295000 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 006 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.293500 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 007 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.267500 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 008 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.255000 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.263000 | 0.867 sec/iter\n",
      "Epoch: 172 | Batch: 010 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.286689 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 173 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.038 | Tree loss: 2.624 | Accuracy: 0.255000 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 001 / 011 | Total loss: 2.591 | Reg loss: 0.038 | Tree loss: 2.591 | Accuracy: 0.290500 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 002 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.273500 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.283000 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 004 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.304000 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.290500 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 006 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.272500 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 007 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.304000 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 008 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.289000 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 009 / 011 | Total loss: 2.359 | Reg loss: 0.038 | Tree loss: 2.359 | Accuracy: 0.276000 | 0.867 sec/iter\n",
      "Epoch: 173 | Batch: 010 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.232082 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 174 | Batch: 000 / 011 | Total loss: 2.617 | Reg loss: 0.038 | Tree loss: 2.617 | Accuracy: 0.263500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 001 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.262500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 002 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.302500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 003 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.268500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.305500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 005 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.291000 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 006 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.288000 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 007 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.281000 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.263500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 009 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.239500 | 0.867 sec/iter\n",
      "Epoch: 174 | Batch: 010 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.197952 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175 | Batch: 000 / 011 | Total loss: 2.616 | Reg loss: 0.038 | Tree loss: 2.616 | Accuracy: 0.265000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 001 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.283000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 002 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.268500 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 003 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.276500 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 004 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.301000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 005 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.288000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 006 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.288000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 007 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.294000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.277000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.266000 | 0.867 sec/iter\n",
      "Epoch: 175 | Batch: 010 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.269625 | 0.867 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 176 | Batch: 000 / 011 | Total loss: 2.608 | Reg loss: 0.038 | Tree loss: 2.608 | Accuracy: 0.273500 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 001 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.283000 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 002 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.281500 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.297000 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 004 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.277500 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 005 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.291500 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.305000 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 007 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.261500 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.275500 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 009 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.256000 | 0.867 sec/iter\n",
      "Epoch: 176 | Batch: 010 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.249147 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 177 | Batch: 000 / 011 | Total loss: 2.611 | Reg loss: 0.038 | Tree loss: 2.611 | Accuracy: 0.270000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 001 / 011 | Total loss: 2.615 | Reg loss: 0.038 | Tree loss: 2.615 | Accuracy: 0.264000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 002 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.295000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.299000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 004 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.293500 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 005 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.295500 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.296000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.304500 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 008 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.286000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.259000 | 0.866 sec/iter\n",
      "Epoch: 177 | Batch: 010 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.286689 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 178 | Batch: 000 / 011 | Total loss: 2.652 | Reg loss: 0.038 | Tree loss: 2.652 | Accuracy: 0.258500 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.278500 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 002 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.279500 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 003 / 011 | Total loss: 2.505 | Reg loss: 0.038 | Tree loss: 2.505 | Accuracy: 0.304000 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.297000 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.311000 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 006 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.280500 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 007 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.279500 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 008 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.265000 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 009 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.240500 | 0.866 sec/iter\n",
      "Epoch: 178 | Batch: 010 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.269625 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 179 | Batch: 000 / 011 | Total loss: 2.623 | Reg loss: 0.038 | Tree loss: 2.623 | Accuracy: 0.264500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.276500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 002 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.294500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.295000 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.309000 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 005 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.296500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 006 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.282000 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.282500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 008 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.277500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.262500 | 0.866 sec/iter\n",
      "Epoch: 179 | Batch: 010 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.218430 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 | Batch: 000 / 011 | Total loss: 2.645 | Reg loss: 0.038 | Tree loss: 2.645 | Accuracy: 0.255000 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 001 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.252500 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.293500 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.281500 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 004 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.307000 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.290000 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.289000 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 007 / 011 | Total loss: 2.365 | Reg loss: 0.038 | Tree loss: 2.365 | Accuracy: 0.304000 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 008 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.254500 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 009 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.249000 | 0.866 sec/iter\n",
      "Epoch: 180 | Batch: 010 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.283276 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 181 | Batch: 000 / 011 | Total loss: 2.614 | Reg loss: 0.038 | Tree loss: 2.614 | Accuracy: 0.266500 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 001 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.274000 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 002 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.285000 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.290000 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.289500 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.282500 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.298500 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 007 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.277000 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.273500 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 009 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.268000 | 0.866 sec/iter\n",
      "Epoch: 181 | Batch: 010 / 011 | Total loss: 2.340 | Reg loss: 0.038 | Tree loss: 2.340 | Accuracy: 0.266212 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 182 | Batch: 000 / 011 | Total loss: 2.607 | Reg loss: 0.038 | Tree loss: 2.607 | Accuracy: 0.283000 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 001 / 011 | Total loss: 2.591 | Reg loss: 0.038 | Tree loss: 2.591 | Accuracy: 0.252000 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 002 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.274500 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 003 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.289500 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.291500 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 005 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.302500 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 006 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.285000 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 007 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.291500 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 008 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.266000 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.250000 | 0.866 sec/iter\n",
      "Epoch: 182 | Batch: 010 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.249147 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 183 | Batch: 000 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.272000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 001 / 011 | Total loss: 2.601 | Reg loss: 0.038 | Tree loss: 2.601 | Accuracy: 0.267000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 002 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.262000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.295000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 004 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.293000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 005 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.280000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.294000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.303000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.291500 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.262000 | 0.866 sec/iter\n",
      "Epoch: 183 | Batch: 010 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.266212 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 184 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.038 | Tree loss: 2.602 | Accuracy: 0.274500 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 001 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.279000 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 002 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.276000 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 003 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.275500 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.296000 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 005 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.277000 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 006 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.305500 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 007 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.289000 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 008 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.270500 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 009 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.262500 | 0.866 sec/iter\n",
      "Epoch: 184 | Batch: 010 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.259386 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.038 | Tree loss: 2.618 | Accuracy: 0.250000 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.277500 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.294500 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 003 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.294500 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.295500 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 005 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.301000 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 006 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.311000 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.279000 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 008 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.266000 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 009 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.247000 | 0.866 sec/iter\n",
      "Epoch: 185 | Batch: 010 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.255973 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 186 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.261500 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 001 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.281500 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.289000 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.311500 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 004 / 011 | Total loss: 2.476 | Reg loss: 0.038 | Tree loss: 2.476 | Accuracy: 0.296000 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 005 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.294500 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.276000 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 007 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.272500 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 008 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.264000 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.244500 | 0.866 sec/iter\n",
      "Epoch: 186 | Batch: 010 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.286689 | 0.866 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 187 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.038 | Tree loss: 2.624 | Accuracy: 0.263500 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 001 / 011 | Total loss: 2.541 | Reg loss: 0.038 | Tree loss: 2.541 | Accuracy: 0.295000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 002 / 011 | Total loss: 2.568 | Reg loss: 0.038 | Tree loss: 2.568 | Accuracy: 0.270000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.297000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.303500 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.294000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 006 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.285500 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 007 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.283000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 008 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.279000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 009 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.266000 | 0.866 sec/iter\n",
      "Epoch: 187 | Batch: 010 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.242321 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 188 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.038 | Tree loss: 2.618 | Accuracy: 0.270000 | 0.866 sec/iter\n",
      "Epoch: 188 | Batch: 001 / 011 | Total loss: 2.569 | Reg loss: 0.038 | Tree loss: 2.569 | Accuracy: 0.287000 | 0.866 sec/iter\n",
      "Epoch: 188 | Batch: 002 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.286000 | 0.866 sec/iter\n",
      "Epoch: 188 | Batch: 003 / 011 | Total loss: 2.504 | Reg loss: 0.038 | Tree loss: 2.504 | Accuracy: 0.312000 | 0.866 sec/iter\n",
      "Epoch: 188 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.294500 | 0.865 sec/iter\n",
      "Epoch: 188 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.290500 | 0.865 sec/iter\n",
      "Epoch: 188 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.280500 | 0.865 sec/iter\n",
      "Epoch: 188 | Batch: 007 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.283000 | 0.865 sec/iter\n",
      "Epoch: 188 | Batch: 008 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.257000 | 0.865 sec/iter\n",
      "Epoch: 188 | Batch: 009 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.255000 | 0.865 sec/iter\n",
      "Epoch: 188 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.215017 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 189 | Batch: 000 / 011 | Total loss: 2.616 | Reg loss: 0.038 | Tree loss: 2.616 | Accuracy: 0.266500 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 001 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.294000 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.294000 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.286500 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.297000 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 005 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.292500 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.292500 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 007 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.277500 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 008 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.275500 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.248000 | 0.865 sec/iter\n",
      "Epoch: 189 | Batch: 010 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.218430 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.283000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 001 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.268000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 002 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.275000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.293500 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 004 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.291500 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.277000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.303000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 007 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.284000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.282000 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.267500 | 0.865 sec/iter\n",
      "Epoch: 190 | Batch: 010 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.242321 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 191 | Batch: 000 / 011 | Total loss: 2.597 | Reg loss: 0.038 | Tree loss: 2.597 | Accuracy: 0.268500 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 001 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.269000 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.289000 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 003 / 011 | Total loss: 2.514 | Reg loss: 0.038 | Tree loss: 2.514 | Accuracy: 0.280500 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.298500 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.287500 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.298000 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 007 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.299000 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 008 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.240500 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.259500 | 0.865 sec/iter\n",
      "Epoch: 191 | Batch: 010 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.283276 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 192 | Batch: 000 / 011 | Total loss: 2.632 | Reg loss: 0.038 | Tree loss: 2.632 | Accuracy: 0.268500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 001 / 011 | Total loss: 2.569 | Reg loss: 0.038 | Tree loss: 2.569 | Accuracy: 0.269500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.300000 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.322500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 004 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.287500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 005 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.283000 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.296500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 007 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.279500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.272500 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 009 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.249000 | 0.865 sec/iter\n",
      "Epoch: 192 | Batch: 010 / 011 | Total loss: 2.352 | Reg loss: 0.038 | Tree loss: 2.352 | Accuracy: 0.242321 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 193 | Batch: 000 / 011 | Total loss: 2.617 | Reg loss: 0.038 | Tree loss: 2.617 | Accuracy: 0.272500 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 001 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.278500 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 002 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.273500 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.297000 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 004 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.276000 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 005 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.271000 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.300000 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.303500 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 008 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.275500 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.255000 | 0.865 sec/iter\n",
      "Epoch: 193 | Batch: 010 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.211604 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 194 | Batch: 000 / 011 | Total loss: 2.616 | Reg loss: 0.038 | Tree loss: 2.616 | Accuracy: 0.267500 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.289500 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 002 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.281000 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.292000 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 004 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.277000 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 005 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.285500 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.298500 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 007 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.300000 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.260000 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.250000 | 0.865 sec/iter\n",
      "Epoch: 194 | Batch: 010 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.293515 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195 | Batch: 000 / 011 | Total loss: 2.608 | Reg loss: 0.038 | Tree loss: 2.608 | Accuracy: 0.273000 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 001 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.277500 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.281500 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 003 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.293500 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 004 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.318000 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.303500 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.285000 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.290000 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 008 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.244000 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.252000 | 0.865 sec/iter\n",
      "Epoch: 195 | Batch: 010 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.273038 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 196 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.038 | Tree loss: 2.618 | Accuracy: 0.252000 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.277000 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.290000 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.301500 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.293000 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.294500 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.281500 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 007 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.287000 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.264500 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 009 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.258500 | 0.865 sec/iter\n",
      "Epoch: 196 | Batch: 010 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.249147 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 197 | Batch: 000 / 011 | Total loss: 2.613 | Reg loss: 0.038 | Tree loss: 2.613 | Accuracy: 0.261500 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 001 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.268500 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.289000 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.307000 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.294500 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.292500 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.298000 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 007 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.287000 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.275000 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.269500 | 0.865 sec/iter\n",
      "Epoch: 197 | Batch: 010 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.252560 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 198 | Batch: 000 / 011 | Total loss: 2.632 | Reg loss: 0.038 | Tree loss: 2.632 | Accuracy: 0.251500 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.281500 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.301500 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.296000 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.312000 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.284500 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.275500 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.283500 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.275000 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 009 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.249000 | 0.865 sec/iter\n",
      "Epoch: 198 | Batch: 010 / 011 | Total loss: 2.348 | Reg loss: 0.038 | Tree loss: 2.348 | Accuracy: 0.273038 | 0.865 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 199 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.280500 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 001 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.271000 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 002 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.285000 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 003 / 011 | Total loss: 2.504 | Reg loss: 0.038 | Tree loss: 2.504 | Accuracy: 0.292500 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 004 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.280500 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.299000 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.297500 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.274000 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.281500 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.264000 | 0.865 sec/iter\n",
      "Epoch: 199 | Batch: 010 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.238908 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200 | Batch: 000 / 011 | Total loss: 2.630 | Reg loss: 0.038 | Tree loss: 2.630 | Accuracy: 0.266000 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 001 / 011 | Total loss: 2.591 | Reg loss: 0.038 | Tree loss: 2.591 | Accuracy: 0.274000 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 002 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.275500 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.302000 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.302000 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 005 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.283500 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 006 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.286500 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.283500 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.270000 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.265000 | 0.864 sec/iter\n",
      "Epoch: 200 | Batch: 010 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.225256 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 201 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.038 | Tree loss: 2.602 | Accuracy: 0.274000 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.272500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 002 / 011 | Total loss: 2.552 | Reg loss: 0.038 | Tree loss: 2.552 | Accuracy: 0.278500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.288500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 004 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.281000 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 005 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.288500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 006 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.308500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 007 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.280500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.279000 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.260500 | 0.864 sec/iter\n",
      "Epoch: 201 | Batch: 010 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.283276 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 202 | Batch: 000 / 011 | Total loss: 2.629 | Reg loss: 0.038 | Tree loss: 2.629 | Accuracy: 0.266000 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.272000 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.288000 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 003 / 011 | Total loss: 2.492 | Reg loss: 0.038 | Tree loss: 2.492 | Accuracy: 0.294500 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.289500 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 005 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.283500 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 006 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.264000 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 007 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.314500 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 008 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.291500 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.249500 | 0.864 sec/iter\n",
      "Epoch: 202 | Batch: 010 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.204778 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 203 | Batch: 000 / 011 | Total loss: 2.613 | Reg loss: 0.038 | Tree loss: 2.613 | Accuracy: 0.268500 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 001 / 011 | Total loss: 2.568 | Reg loss: 0.038 | Tree loss: 2.568 | Accuracy: 0.273000 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.288000 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.286000 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.298000 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 005 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.297500 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.297000 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.270500 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 008 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.256500 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.251000 | 0.864 sec/iter\n",
      "Epoch: 203 | Batch: 010 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.238908 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 204 | Batch: 000 / 011 | Total loss: 2.630 | Reg loss: 0.038 | Tree loss: 2.630 | Accuracy: 0.250500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.273500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 002 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.302500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 003 / 011 | Total loss: 2.508 | Reg loss: 0.038 | Tree loss: 2.508 | Accuracy: 0.283500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.308000 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.296500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 006 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.292500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 007 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.287000 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 008 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.269500 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 009 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.251000 | 0.864 sec/iter\n",
      "Epoch: 204 | Batch: 010 / 011 | Total loss: 2.345 | Reg loss: 0.038 | Tree loss: 2.345 | Accuracy: 0.296928 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 205 | Batch: 000 / 011 | Total loss: 2.604 | Reg loss: 0.038 | Tree loss: 2.604 | Accuracy: 0.274500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 001 / 011 | Total loss: 2.592 | Reg loss: 0.038 | Tree loss: 2.592 | Accuracy: 0.247500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.290000 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 003 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.289500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.292000 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 005 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.292500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 006 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.289500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.288500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.281500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.266500 | 0.864 sec/iter\n",
      "Epoch: 205 | Batch: 010 / 011 | Total loss: 2.328 | Reg loss: 0.038 | Tree loss: 2.328 | Accuracy: 0.303754 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 206 | Batch: 000 / 011 | Total loss: 2.617 | Reg loss: 0.038 | Tree loss: 2.617 | Accuracy: 0.265500 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 001 / 011 | Total loss: 2.574 | Reg loss: 0.038 | Tree loss: 2.574 | Accuracy: 0.264500 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 002 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.281000 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.285000 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 004 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.304000 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 005 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.296500 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.298500 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 007 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.279000 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.263500 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.272000 | 0.864 sec/iter\n",
      "Epoch: 206 | Batch: 010 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.245734 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 207 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.288500 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 001 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.262000 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 002 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.266000 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 003 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.286500 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.291500 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.310500 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.314000 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 007 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.278000 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 008 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.276500 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.258500 | 0.864 sec/iter\n",
      "Epoch: 207 | Batch: 010 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.238908 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 208 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.272000 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 001 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.270500 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 002 / 011 | Total loss: 2.568 | Reg loss: 0.038 | Tree loss: 2.568 | Accuracy: 0.276500 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 003 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.320000 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 004 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.267000 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 005 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.294500 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.290500 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.270500 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 008 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.267000 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 009 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.264500 | 0.864 sec/iter\n",
      "Epoch: 208 | Batch: 010 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.242321 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 209 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.038 | Tree loss: 2.624 | Accuracy: 0.251500 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 001 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.285000 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.285500 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.301500 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.281500 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 005 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.309000 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.284000 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 007 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.302000 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 008 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.255000 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.256500 | 0.864 sec/iter\n",
      "Epoch: 209 | Batch: 010 / 011 | Total loss: 2.361 | Reg loss: 0.038 | Tree loss: 2.361 | Accuracy: 0.249147 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210 | Batch: 000 / 011 | Total loss: 2.621 | Reg loss: 0.038 | Tree loss: 2.621 | Accuracy: 0.258000 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 001 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.270500 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.273500 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.288000 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 004 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.316000 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 005 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.315500 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 006 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.278500 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.284000 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.265000 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.272500 | 0.864 sec/iter\n",
      "Epoch: 210 | Batch: 010 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.221843 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 211 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.038 | Tree loss: 2.624 | Accuracy: 0.263000 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 001 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.270000 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.279500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.296500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.306500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 005 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.287500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.283500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 007 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.294000 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 008 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.274500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.276500 | 0.864 sec/iter\n",
      "Epoch: 211 | Batch: 010 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.262799 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 212 | Batch: 000 / 011 | Total loss: 2.603 | Reg loss: 0.038 | Tree loss: 2.603 | Accuracy: 0.264000 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.280500 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.279500 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 003 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.278500 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.314500 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 005 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.296000 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.274000 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 007 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.278000 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 008 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.247000 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 009 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.268500 | 0.864 sec/iter\n",
      "Epoch: 212 | Batch: 010 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.238908 | 0.864 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 213 | Batch: 000 / 011 | Total loss: 2.614 | Reg loss: 0.038 | Tree loss: 2.614 | Accuracy: 0.257500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 001 / 011 | Total loss: 2.569 | Reg loss: 0.038 | Tree loss: 2.569 | Accuracy: 0.280500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.282000 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.300000 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.295500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.298000 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 006 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.297500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.283500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 008 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.274500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 009 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.252500 | 0.864 sec/iter\n",
      "Epoch: 213 | Batch: 010 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.238908 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 214 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.277500 | 0.864 sec/iter\n",
      "Epoch: 214 | Batch: 001 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.280500 | 0.864 sec/iter\n",
      "Epoch: 214 | Batch: 002 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.292500 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.296500 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.303500 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 005 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.285500 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 006 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.257500 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.290000 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.258000 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 009 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.248500 | 0.863 sec/iter\n",
      "Epoch: 214 | Batch: 010 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.266212 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 215 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.272000 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 001 / 011 | Total loss: 2.604 | Reg loss: 0.038 | Tree loss: 2.604 | Accuracy: 0.278500 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 002 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.287500 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 003 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.295500 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.306500 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 005 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.290000 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 006 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.292500 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.273000 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.280000 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.259000 | 0.863 sec/iter\n",
      "Epoch: 215 | Batch: 010 / 011 | Total loss: 2.351 | Reg loss: 0.038 | Tree loss: 2.351 | Accuracy: 0.283276 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 216 | Batch: 000 / 011 | Total loss: 2.605 | Reg loss: 0.038 | Tree loss: 2.605 | Accuracy: 0.287500 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 001 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.275000 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.269500 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.293000 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.292000 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 005 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.288500 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.293000 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 007 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.274000 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 008 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.254000 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.266500 | 0.863 sec/iter\n",
      "Epoch: 216 | Batch: 010 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.238908 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 217 | Batch: 000 / 011 | Total loss: 2.591 | Reg loss: 0.038 | Tree loss: 2.591 | Accuracy: 0.270500 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.288000 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.282500 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.288000 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 004 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.297500 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 005 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.294000 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.286500 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.298000 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.284500 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.265000 | 0.863 sec/iter\n",
      "Epoch: 217 | Batch: 010 / 011 | Total loss: 2.318 | Reg loss: 0.038 | Tree loss: 2.318 | Accuracy: 0.283276 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 218 | Batch: 000 / 011 | Total loss: 2.605 | Reg loss: 0.038 | Tree loss: 2.605 | Accuracy: 0.256000 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.290500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 002 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.280000 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 003 / 011 | Total loss: 2.504 | Reg loss: 0.038 | Tree loss: 2.504 | Accuracy: 0.295500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.288500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 005 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.320000 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.284500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.288500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.253500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 009 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.242500 | 0.863 sec/iter\n",
      "Epoch: 218 | Batch: 010 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.249147 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 219 | Batch: 000 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.277000 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 001 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.270500 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.289000 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.310500 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.299500 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.292000 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.273500 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 007 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.282000 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.268000 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.261500 | 0.863 sec/iter\n",
      "Epoch: 219 | Batch: 010 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.225256 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.038 | Tree loss: 2.618 | Accuracy: 0.265000 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 001 / 011 | Total loss: 2.565 | Reg loss: 0.038 | Tree loss: 2.565 | Accuracy: 0.296500 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.280000 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 003 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.304000 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.285000 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.279000 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 006 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.286500 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.270000 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.278500 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.266500 | 0.863 sec/iter\n",
      "Epoch: 220 | Batch: 010 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.276451 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 221 | Batch: 000 / 011 | Total loss: 2.610 | Reg loss: 0.038 | Tree loss: 2.610 | Accuracy: 0.270500 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 001 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.272500 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.289000 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.291000 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 004 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.287000 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.307500 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 006 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.289500 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 007 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.275500 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.271000 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 009 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.253500 | 0.863 sec/iter\n",
      "Epoch: 221 | Batch: 010 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.225256 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 222 | Batch: 000 / 011 | Total loss: 2.610 | Reg loss: 0.038 | Tree loss: 2.610 | Accuracy: 0.270000 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.267000 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 002 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.278500 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 003 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.324000 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.293500 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 005 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.315500 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.283000 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.279500 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 008 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.260000 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 009 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.260000 | 0.863 sec/iter\n",
      "Epoch: 222 | Batch: 010 / 011 | Total loss: 2.342 | Reg loss: 0.038 | Tree loss: 2.342 | Accuracy: 0.286689 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 223 | Batch: 000 / 011 | Total loss: 2.610 | Reg loss: 0.038 | Tree loss: 2.610 | Accuracy: 0.280500 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 001 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.273500 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.284000 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 003 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.292000 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.290500 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 005 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.290000 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.280500 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.285000 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.260000 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.246000 | 0.863 sec/iter\n",
      "Epoch: 223 | Batch: 010 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.225256 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 224 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.038 | Tree loss: 2.606 | Accuracy: 0.266500 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 001 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.280000 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 002 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.261500 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.287500 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.287000 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.288500 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.287500 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 007 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.295000 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 008 / 011 | Total loss: 2.351 | Reg loss: 0.038 | Tree loss: 2.351 | Accuracy: 0.291000 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 009 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.255000 | 0.863 sec/iter\n",
      "Epoch: 224 | Batch: 010 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.283276 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 225 | Batch: 000 / 011 | Total loss: 2.599 | Reg loss: 0.038 | Tree loss: 2.599 | Accuracy: 0.269500 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 001 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.291500 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.289500 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 003 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.290000 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.294500 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.291000 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 006 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.276500 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 007 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.277000 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.266000 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 009 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.239000 | 0.863 sec/iter\n",
      "Epoch: 225 | Batch: 010 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.238908 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 226 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.038 | Tree loss: 2.602 | Accuracy: 0.264000 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.291500 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.283500 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.292500 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.308000 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.277000 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.296000 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.284500 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.271000 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 009 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.251500 | 0.863 sec/iter\n",
      "Epoch: 226 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.252560 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 227 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.278500 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.284000 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.298000 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.289500 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.285500 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 005 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.283500 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.294000 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.258500 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 008 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.260500 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.252000 | 0.863 sec/iter\n",
      "Epoch: 227 | Batch: 010 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.215017 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 228 | Batch: 000 / 011 | Total loss: 2.592 | Reg loss: 0.038 | Tree loss: 2.592 | Accuracy: 0.252000 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 001 / 011 | Total loss: 2.565 | Reg loss: 0.038 | Tree loss: 2.565 | Accuracy: 0.269000 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.297000 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 003 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.293500 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.311500 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.299500 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 006 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.308500 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 007 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.292500 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 008 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.247000 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.262500 | 0.863 sec/iter\n",
      "Epoch: 228 | Batch: 010 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.245734 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 229 | Batch: 000 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.269000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 001 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.279000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 002 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.278000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.274500 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 004 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.314000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 005 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.285500 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.293500 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.283000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 008 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.257000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.251000 | 0.863 sec/iter\n",
      "Epoch: 229 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.262799 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230 | Batch: 000 / 011 | Total loss: 2.627 | Reg loss: 0.038 | Tree loss: 2.627 | Accuracy: 0.249500 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 001 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.292500 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.296000 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.291000 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 004 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.280000 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 005 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.293500 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.280500 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.289000 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 008 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.286500 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.273500 | 0.863 sec/iter\n",
      "Epoch: 230 | Batch: 010 / 011 | Total loss: 2.364 | Reg loss: 0.038 | Tree loss: 2.364 | Accuracy: 0.269625 | 0.863 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 231 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.038 | Tree loss: 2.606 | Accuracy: 0.266000 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.269000 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.269500 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 003 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.280000 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.303000 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 005 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.296500 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 006 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.286500 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 007 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.285500 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 008 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.277000 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.265000 | 0.863 sec/iter\n",
      "Epoch: 231 | Batch: 010 / 011 | Total loss: 2.351 | Reg loss: 0.038 | Tree loss: 2.351 | Accuracy: 0.286689 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 232 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.279000 | 0.863 sec/iter\n",
      "Epoch: 232 | Batch: 001 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.270500 | 0.863 sec/iter\n",
      "Epoch: 232 | Batch: 002 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.270000 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.038 | Tree loss: 2.487 | Accuracy: 0.306000 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 004 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.276500 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 005 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.284500 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.283500 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 007 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.279000 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.278000 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 009 / 011 | Total loss: 2.363 | Reg loss: 0.038 | Tree loss: 2.363 | Accuracy: 0.265500 | 0.862 sec/iter\n",
      "Epoch: 232 | Batch: 010 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.228669 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 233 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.266500 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 001 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.266000 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.301500 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 003 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.298500 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 004 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.310000 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 005 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.287000 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.286000 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.290500 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 008 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.248500 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 009 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.244000 | 0.862 sec/iter\n",
      "Epoch: 233 | Batch: 010 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.303754 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 234 | Batch: 000 / 011 | Total loss: 2.609 | Reg loss: 0.038 | Tree loss: 2.609 | Accuracy: 0.277000 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 001 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.274500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.269500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.297500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 004 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.293500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.283500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 006 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.298500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.289500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 008 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.271500 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 009 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.255000 | 0.862 sec/iter\n",
      "Epoch: 234 | Batch: 010 / 011 | Total loss: 2.352 | Reg loss: 0.038 | Tree loss: 2.352 | Accuracy: 0.232082 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 235 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.267500 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 001 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.270000 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.287000 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.296500 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.303000 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.285500 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.283500 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 007 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.291000 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.277000 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 009 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.247500 | 0.862 sec/iter\n",
      "Epoch: 235 | Batch: 010 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.269625 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 236 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.038 | Tree loss: 2.618 | Accuracy: 0.257500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.282500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 002 / 011 | Total loss: 2.534 | Reg loss: 0.038 | Tree loss: 2.534 | Accuracy: 0.281000 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.038 | Tree loss: 2.487 | Accuracy: 0.304000 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.282000 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 005 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.285500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.298500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 007 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.278500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.259500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 009 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.269500 | 0.862 sec/iter\n",
      "Epoch: 236 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.273038 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 237 | Batch: 000 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.267000 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 001 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.260500 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.274000 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 003 / 011 | Total loss: 2.504 | Reg loss: 0.038 | Tree loss: 2.504 | Accuracy: 0.294000 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.297000 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 005 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.290500 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 006 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.295000 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.280500 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.268000 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 009 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.287500 | 0.862 sec/iter\n",
      "Epoch: 237 | Batch: 010 / 011 | Total loss: 2.344 | Reg loss: 0.038 | Tree loss: 2.344 | Accuracy: 0.273038 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 238 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.263500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 001 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.256500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.288500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 003 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.290500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.288500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 005 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.291500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 006 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.297500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.294000 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.276500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 009 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.263500 | 0.862 sec/iter\n",
      "Epoch: 238 | Batch: 010 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.269625 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 239 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.038 | Tree loss: 2.606 | Accuracy: 0.274000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.269500 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 002 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.282000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.302000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.305500 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.282000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.295500 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.279000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.268000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 009 / 011 | Total loss: 2.359 | Reg loss: 0.038 | Tree loss: 2.359 | Accuracy: 0.262000 | 0.862 sec/iter\n",
      "Epoch: 239 | Batch: 010 / 011 | Total loss: 2.314 | Reg loss: 0.038 | Tree loss: 2.314 | Accuracy: 0.276451 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240 | Batch: 000 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.283000 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.273500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 002 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.272500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 003 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.288500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.282500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.268500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.292000 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 007 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.272500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.286500 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.264000 | 0.862 sec/iter\n",
      "Epoch: 240 | Batch: 010 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.228669 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 241 | Batch: 000 / 011 | Total loss: 2.604 | Reg loss: 0.038 | Tree loss: 2.604 | Accuracy: 0.277500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 001 / 011 | Total loss: 2.574 | Reg loss: 0.038 | Tree loss: 2.574 | Accuracy: 0.269000 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.292500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.291000 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.274500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.281500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 006 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.283000 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 007 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.295500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.263500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.262500 | 0.862 sec/iter\n",
      "Epoch: 241 | Batch: 010 / 011 | Total loss: 2.363 | Reg loss: 0.038 | Tree loss: 2.363 | Accuracy: 0.255973 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 242 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.273000 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 001 / 011 | Total loss: 2.574 | Reg loss: 0.038 | Tree loss: 2.574 | Accuracy: 0.273500 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 002 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.302000 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 003 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.284000 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.286500 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 005 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.282500 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 006 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.287500 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.283000 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.273000 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.262000 | 0.862 sec/iter\n",
      "Epoch: 242 | Batch: 010 / 011 | Total loss: 2.363 | Reg loss: 0.038 | Tree loss: 2.363 | Accuracy: 0.232082 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 243 | Batch: 000 / 011 | Total loss: 2.601 | Reg loss: 0.038 | Tree loss: 2.601 | Accuracy: 0.260000 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.280500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.287000 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 003 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.298500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 004 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.285500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.291000 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.297500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 007 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.288500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 008 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.267500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 009 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.252500 | 0.862 sec/iter\n",
      "Epoch: 243 | Batch: 010 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.279863 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 244 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.268500 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.281000 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 002 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.268500 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.293500 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.285000 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.293500 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.293000 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.288500 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.275500 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.258000 | 0.862 sec/iter\n",
      "Epoch: 244 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.249147 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 245 | Batch: 000 / 011 | Total loss: 2.605 | Reg loss: 0.038 | Tree loss: 2.605 | Accuracy: 0.272500 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.275000 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 002 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.263000 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 003 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.302500 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 004 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.311500 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.280000 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 006 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.300500 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.266000 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.282000 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.254500 | 0.862 sec/iter\n",
      "Epoch: 245 | Batch: 010 / 011 | Total loss: 2.313 | Reg loss: 0.038 | Tree loss: 2.313 | Accuracy: 0.266212 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 246 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.262500 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.267000 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.267500 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 003 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.298500 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 004 / 011 | Total loss: 2.476 | Reg loss: 0.038 | Tree loss: 2.476 | Accuracy: 0.294000 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 005 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.287000 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.295000 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.295000 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.265000 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.270500 | 0.862 sec/iter\n",
      "Epoch: 246 | Batch: 010 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.235495 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 247 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.267000 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.278000 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 002 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.278000 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.307500 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 004 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.279000 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.297500 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.290000 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 007 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.292500 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.288500 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.256500 | 0.862 sec/iter\n",
      "Epoch: 247 | Batch: 010 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.276451 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 248 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.282000 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 001 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.260500 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.277000 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 003 / 011 | Total loss: 2.504 | Reg loss: 0.038 | Tree loss: 2.504 | Accuracy: 0.297000 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 004 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.286000 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 005 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.300500 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 006 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.295500 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.282000 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 008 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.272000 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.271500 | 0.862 sec/iter\n",
      "Epoch: 248 | Batch: 010 / 011 | Total loss: 2.338 | Reg loss: 0.038 | Tree loss: 2.338 | Accuracy: 0.276451 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 249 | Batch: 000 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.272000 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 001 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.286000 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.279000 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.305500 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.297000 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 005 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.300000 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.285500 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.293000 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 008 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.260500 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 009 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.251500 | 0.862 sec/iter\n",
      "Epoch: 249 | Batch: 010 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.238908 | 0.862 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.285500 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 001 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.272500 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.280000 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.294000 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.320000 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 005 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.306000 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 006 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.296500 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 007 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.278000 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 008 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.263000 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 009 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.258500 | 0.862 sec/iter\n",
      "Epoch: 250 | Batch: 010 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.191126 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 251 | Batch: 000 / 011 | Total loss: 2.605 | Reg loss: 0.038 | Tree loss: 2.605 | Accuracy: 0.260000 | 0.862 sec/iter\n",
      "Epoch: 251 | Batch: 001 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.270500 | 0.862 sec/iter\n",
      "Epoch: 251 | Batch: 002 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.291500 | 0.862 sec/iter\n",
      "Epoch: 251 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.294500 | 0.862 sec/iter\n",
      "Epoch: 251 | Batch: 004 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.286500 | 0.862 sec/iter\n",
      "Epoch: 251 | Batch: 005 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.291000 | 0.862 sec/iter\n",
      "Epoch: 251 | Batch: 006 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.292000 | 0.861 sec/iter\n",
      "Epoch: 251 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.276000 | 0.861 sec/iter\n",
      "Epoch: 251 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.284000 | 0.861 sec/iter\n",
      "Epoch: 251 | Batch: 009 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.285500 | 0.861 sec/iter\n",
      "Epoch: 251 | Batch: 010 / 011 | Total loss: 2.252 | Reg loss: 0.038 | Tree loss: 2.252 | Accuracy: 0.303754 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 252 | Batch: 000 / 011 | Total loss: 2.615 | Reg loss: 0.038 | Tree loss: 2.615 | Accuracy: 0.263500 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.286000 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.295000 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 003 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.282000 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 004 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.312500 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 005 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.280000 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 006 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.287000 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.281500 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.260000 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.258500 | 0.861 sec/iter\n",
      "Epoch: 252 | Batch: 010 / 011 | Total loss: 2.354 | Reg loss: 0.038 | Tree loss: 2.354 | Accuracy: 0.276451 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 253 | Batch: 000 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.285500 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 001 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.289500 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.278500 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.295000 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 004 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.279500 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.288500 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.294000 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.291000 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.261000 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.244500 | 0.861 sec/iter\n",
      "Epoch: 253 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.252560 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 254 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.288500 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 001 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.279000 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 002 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.283500 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.287000 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.289000 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.282000 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 006 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.312500 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.280500 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 008 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.269000 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 009 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.269000 | 0.861 sec/iter\n",
      "Epoch: 254 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.235495 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 255 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.278500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.269000 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 002 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.281000 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.289500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.301500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.288500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.296500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 007 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.276500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.276500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.269500 | 0.861 sec/iter\n",
      "Epoch: 255 | Batch: 010 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.228669 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 256 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.266500 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.273500 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.283500 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 003 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.292500 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.296500 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 005 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.318000 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.299000 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 007 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.274500 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 008 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.286000 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 009 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.243000 | 0.861 sec/iter\n",
      "Epoch: 256 | Batch: 010 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.262799 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 257 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.262500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 001 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.279500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.282500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.276000 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 004 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.316500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.306000 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.292500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.287500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 008 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.254000 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.266500 | 0.861 sec/iter\n",
      "Epoch: 257 | Batch: 010 / 011 | Total loss: 2.354 | Reg loss: 0.038 | Tree loss: 2.354 | Accuracy: 0.273038 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 258 | Batch: 000 / 011 | Total loss: 2.603 | Reg loss: 0.038 | Tree loss: 2.603 | Accuracy: 0.254500 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 001 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.277000 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 002 / 011 | Total loss: 2.514 | Reg loss: 0.038 | Tree loss: 2.514 | Accuracy: 0.300000 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.299500 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 004 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.293500 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.300000 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.301000 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.281500 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 008 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.242500 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 009 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.263500 | 0.861 sec/iter\n",
      "Epoch: 258 | Batch: 010 / 011 | Total loss: 2.365 | Reg loss: 0.038 | Tree loss: 2.365 | Accuracy: 0.276451 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 259 | Batch: 000 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.266000 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.268000 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.276000 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.299500 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.292500 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.297000 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.300000 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.274000 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 008 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.268500 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.281500 | 0.861 sec/iter\n",
      "Epoch: 259 | Batch: 010 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.283276 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260 | Batch: 000 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.270000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.281000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 002 / 011 | Total loss: 2.534 | Reg loss: 0.038 | Tree loss: 2.534 | Accuracy: 0.294000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.287000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 004 / 011 | Total loss: 2.476 | Reg loss: 0.038 | Tree loss: 2.476 | Accuracy: 0.299500 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 005 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.299500 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.274000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 007 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.279000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.254000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 009 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.259000 | 0.861 sec/iter\n",
      "Epoch: 260 | Batch: 010 / 011 | Total loss: 2.344 | Reg loss: 0.038 | Tree loss: 2.344 | Accuracy: 0.273038 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 261 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.269000 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 001 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.286000 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.293000 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 003 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.291000 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 004 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.282500 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 005 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.295500 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 006 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.284000 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.280500 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 008 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.287500 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 009 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.256500 | 0.861 sec/iter\n",
      "Epoch: 261 | Batch: 010 / 011 | Total loss: 2.303 | Reg loss: 0.038 | Tree loss: 2.303 | Accuracy: 0.242321 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 262 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.267500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 001 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.295500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.262500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 003 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.281000 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.303500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.297500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.278500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 007 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.272500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.285500 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.266000 | 0.861 sec/iter\n",
      "Epoch: 262 | Batch: 010 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.286689 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 263 | Batch: 000 / 011 | Total loss: 2.608 | Reg loss: 0.038 | Tree loss: 2.608 | Accuracy: 0.244500 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.288000 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.300000 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 003 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.290000 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.288000 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.291500 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 006 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.284000 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 007 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.297500 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.287500 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.256000 | 0.861 sec/iter\n",
      "Epoch: 263 | Batch: 010 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.279863 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 264 | Batch: 000 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.285000 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.274000 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.289500 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.288000 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 004 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.307000 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 005 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.283500 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.277000 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.281500 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.269500 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.272500 | 0.861 sec/iter\n",
      "Epoch: 264 | Batch: 010 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.228669 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 265 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.261000 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 001 / 011 | Total loss: 2.574 | Reg loss: 0.038 | Tree loss: 2.574 | Accuracy: 0.266500 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 002 / 011 | Total loss: 2.541 | Reg loss: 0.038 | Tree loss: 2.541 | Accuracy: 0.300500 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 003 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.287500 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 004 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.287000 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 005 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.304000 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 006 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.290000 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.290000 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.268500 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.255000 | 0.861 sec/iter\n",
      "Epoch: 265 | Batch: 010 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.269625 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 266 | Batch: 000 / 011 | Total loss: 2.600 | Reg loss: 0.038 | Tree loss: 2.600 | Accuracy: 0.269500 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.264500 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.293000 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.291500 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 004 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.293000 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.302000 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.284000 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.284500 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 008 / 011 | Total loss: 2.356 | Reg loss: 0.038 | Tree loss: 2.356 | Accuracy: 0.280000 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 009 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.240000 | 0.861 sec/iter\n",
      "Epoch: 266 | Batch: 010 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.252560 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 267 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.038 | Tree loss: 2.624 | Accuracy: 0.244000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 001 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.275000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.272500 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.294000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.301000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 005 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.298000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 006 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.315500 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.293000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.281000 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.269500 | 0.861 sec/iter\n",
      "Epoch: 267 | Batch: 010 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.286689 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 268 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.272500 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.277000 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 002 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.288500 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 003 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.291500 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.282000 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.276500 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.297500 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.289500 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.273000 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 009 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.263000 | 0.861 sec/iter\n",
      "Epoch: 268 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.262799 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 269 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.269000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 001 / 011 | Total loss: 2.550 | Reg loss: 0.038 | Tree loss: 2.550 | Accuracy: 0.270500 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.294000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 003 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.294000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 004 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.287000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 005 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.296000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.288500 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.288000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.271000 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.264500 | 0.861 sec/iter\n",
      "Epoch: 269 | Batch: 010 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.252560 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.275500 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.281500 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.291500 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 003 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.299000 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 004 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.270000 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.285500 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 006 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.295000 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.277000 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.271000 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.242000 | 0.861 sec/iter\n",
      "Epoch: 270 | Batch: 010 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.249147 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 271 | Batch: 000 / 011 | Total loss: 2.597 | Reg loss: 0.038 | Tree loss: 2.597 | Accuracy: 0.280000 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 001 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.287500 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.287000 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 003 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.279000 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.284000 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.282500 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.286000 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.289500 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.272000 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.267500 | 0.861 sec/iter\n",
      "Epoch: 271 | Batch: 010 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.255973 | 0.861 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 272 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.275000 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 001 / 011 | Total loss: 2.599 | Reg loss: 0.038 | Tree loss: 2.599 | Accuracy: 0.254500 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.289500 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.303500 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.288500 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.292000 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.274000 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 007 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.290500 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 008 / 011 | Total loss: 2.364 | Reg loss: 0.038 | Tree loss: 2.364 | Accuracy: 0.283500 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 009 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.271000 | 0.861 sec/iter\n",
      "Epoch: 272 | Batch: 010 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.235495 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 273 | Batch: 000 / 011 | Total loss: 2.608 | Reg loss: 0.038 | Tree loss: 2.608 | Accuracy: 0.274000 | 0.861 sec/iter\n",
      "Epoch: 273 | Batch: 001 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.289000 | 0.861 sec/iter\n",
      "Epoch: 273 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.283000 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 003 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.296500 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 005 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.289500 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.275500 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 007 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.271500 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.257500 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.258500 | 0.86 sec/iter\n",
      "Epoch: 273 | Batch: 010 / 011 | Total loss: 2.364 | Reg loss: 0.038 | Tree loss: 2.364 | Accuracy: 0.252560 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 274 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.038 | Tree loss: 2.606 | Accuracy: 0.274500 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 001 / 011 | Total loss: 2.552 | Reg loss: 0.038 | Tree loss: 2.552 | Accuracy: 0.283000 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.270000 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.307500 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.280500 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 005 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.282500 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 007 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.298000 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 008 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.287000 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 009 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.261000 | 0.86 sec/iter\n",
      "Epoch: 274 | Batch: 010 / 011 | Total loss: 2.340 | Reg loss: 0.038 | Tree loss: 2.340 | Accuracy: 0.279863 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 275 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.263000 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 001 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.266500 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.290500 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 003 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.293000 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.314500 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 005 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.297500 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 006 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.283000 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.277000 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 008 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.261500 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.247500 | 0.86 sec/iter\n",
      "Epoch: 275 | Batch: 010 / 011 | Total loss: 2.332 | Reg loss: 0.038 | Tree loss: 2.332 | Accuracy: 0.290102 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 276 | Batch: 000 / 011 | Total loss: 2.600 | Reg loss: 0.038 | Tree loss: 2.600 | Accuracy: 0.271500 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.280000 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.293500 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 003 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.280500 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.293000 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.285000 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.265000 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 007 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.288500 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.281000 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 009 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.269000 | 0.86 sec/iter\n",
      "Epoch: 276 | Batch: 010 / 011 | Total loss: 2.308 | Reg loss: 0.038 | Tree loss: 2.308 | Accuracy: 0.249147 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 277 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.275000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.290000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.287500 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.281000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.287000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 005 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.287000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.303000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.279000 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.271500 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.258500 | 0.86 sec/iter\n",
      "Epoch: 277 | Batch: 010 / 011 | Total loss: 2.354 | Reg loss: 0.038 | Tree loss: 2.354 | Accuracy: 0.276451 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 278 | Batch: 000 / 011 | Total loss: 2.605 | Reg loss: 0.038 | Tree loss: 2.605 | Accuracy: 0.278000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.294500 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 003 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.312000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.293000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.284500 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 006 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 007 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.279000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 008 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.253500 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.244000 | 0.86 sec/iter\n",
      "Epoch: 278 | Batch: 010 / 011 | Total loss: 2.333 | Reg loss: 0.038 | Tree loss: 2.333 | Accuracy: 0.228669 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 279 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.275000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 001 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.273500 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 002 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.276500 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 003 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.304500 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 004 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.291000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 005 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.281000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.284000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.291000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 008 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.277000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 009 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.257000 | 0.86 sec/iter\n",
      "Epoch: 279 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.286689 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.263500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 001 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.300500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.288000 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 004 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.262500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.293500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.280500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.285500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 008 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.266500 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.267000 | 0.86 sec/iter\n",
      "Epoch: 280 | Batch: 010 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.225256 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 281 | Batch: 000 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.272000 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.278500 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.268500 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 003 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.296000 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.282500 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.306000 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 006 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.295500 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 008 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.261500 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.263000 | 0.86 sec/iter\n",
      "Epoch: 281 | Batch: 010 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.252560 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 282 | Batch: 000 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.278500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 001 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.281000 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 002 / 011 | Total loss: 2.529 | Reg loss: 0.038 | Tree loss: 2.529 | Accuracy: 0.291500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.283500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.304500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 005 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.290000 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 006 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.281500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.288500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.262000 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.260500 | 0.86 sec/iter\n",
      "Epoch: 282 | Batch: 010 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.221843 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 283 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.261000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 001 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.266500 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.305000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.298000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 005 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.300000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.282000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.290500 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.268000 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 009 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.252500 | 0.86 sec/iter\n",
      "Epoch: 283 | Batch: 010 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.259386 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 284 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.038 | Tree loss: 2.602 | Accuracy: 0.260000 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 001 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 002 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.294000 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.285000 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 004 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.303500 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.297000 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.301500 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 007 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.292500 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 008 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.264500 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.247000 | 0.86 sec/iter\n",
      "Epoch: 284 | Batch: 010 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.245734 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285 | Batch: 000 / 011 | Total loss: 2.610 | Reg loss: 0.038 | Tree loss: 2.610 | Accuracy: 0.273000 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.276500 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 002 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.272500 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 003 / 011 | Total loss: 2.505 | Reg loss: 0.038 | Tree loss: 2.505 | Accuracy: 0.295000 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.290000 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 005 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.297500 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 006 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.303500 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.271000 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.272000 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 009 / 011 | Total loss: 2.358 | Reg loss: 0.038 | Tree loss: 2.358 | Accuracy: 0.279000 | 0.86 sec/iter\n",
      "Epoch: 285 | Batch: 010 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.232082 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 286 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.275500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.276500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.295500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.285500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 004 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.294500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.302500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 006 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.273500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 007 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.280500 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.277000 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.267000 | 0.86 sec/iter\n",
      "Epoch: 286 | Batch: 010 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.215017 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 287 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.266000 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.283000 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.293500 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.298000 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.299500 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 005 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.284000 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 006 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.316500 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 007 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.283000 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 008 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.268500 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 009 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.248500 | 0.86 sec/iter\n",
      "Epoch: 287 | Batch: 010 / 011 | Total loss: 2.354 | Reg loss: 0.038 | Tree loss: 2.354 | Accuracy: 0.283276 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 288 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.272500 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 001 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.279000 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 003 / 011 | Total loss: 2.492 | Reg loss: 0.038 | Tree loss: 2.492 | Accuracy: 0.300500 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.309000 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 005 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.288000 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.287500 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.292500 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.282500 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 009 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.273500 | 0.86 sec/iter\n",
      "Epoch: 288 | Batch: 010 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.215017 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 289 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.282000 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 001 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.280000 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.265000 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.291500 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 004 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.287000 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.311000 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.280500 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 007 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.281500 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 008 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.261000 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.274500 | 0.86 sec/iter\n",
      "Epoch: 289 | Batch: 010 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.252560 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290 | Batch: 000 / 011 | Total loss: 2.615 | Reg loss: 0.038 | Tree loss: 2.615 | Accuracy: 0.262000 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.280500 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.282500 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.291500 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.284500 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.294000 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.292000 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 007 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.310000 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.275000 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 009 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.256500 | 0.86 sec/iter\n",
      "Epoch: 290 | Batch: 010 / 011 | Total loss: 2.348 | Reg loss: 0.038 | Tree loss: 2.348 | Accuracy: 0.273038 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 291 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.269500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 001 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.286500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.283000 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.309500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.282000 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.309500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.284500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 007 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.289500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.265500 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.261000 | 0.86 sec/iter\n",
      "Epoch: 291 | Batch: 010 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.255973 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 292 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.265000 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.282000 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 002 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.286500 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.300000 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.301000 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.310000 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.288500 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.288000 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.286500 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 009 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.255500 | 0.86 sec/iter\n",
      "Epoch: 292 | Batch: 010 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.252560 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 293 | Batch: 000 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.283500 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.264500 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.284000 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.298000 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.292000 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 005 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.308500 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.296500 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.268000 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 008 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.253000 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.258000 | 0.86 sec/iter\n",
      "Epoch: 293 | Batch: 010 / 011 | Total loss: 2.349 | Reg loss: 0.038 | Tree loss: 2.349 | Accuracy: 0.252560 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 294 | Batch: 000 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.267500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 001 / 011 | Total loss: 2.569 | Reg loss: 0.038 | Tree loss: 2.569 | Accuracy: 0.274500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.284500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.310500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 004 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.303500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 005 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.277000 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.287500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.293000 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 008 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.289500 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.256000 | 0.86 sec/iter\n",
      "Epoch: 294 | Batch: 010 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.259386 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 295 | Batch: 000 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.276500 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.269000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 002 / 011 | Total loss: 2.505 | Reg loss: 0.038 | Tree loss: 2.505 | Accuracy: 0.286000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 003 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.304000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.305000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.282500 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 006 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.278000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.276000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.266000 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.254500 | 0.86 sec/iter\n",
      "Epoch: 295 | Batch: 010 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.245734 | 0.86 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 296 | Batch: 000 / 011 | Total loss: 2.603 | Reg loss: 0.038 | Tree loss: 2.603 | Accuracy: 0.285000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.285000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.288000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.291000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.284000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.277000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 006 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.297500 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.273500 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 008 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.291000 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.259500 | 0.86 sec/iter\n",
      "Epoch: 296 | Batch: 010 / 011 | Total loss: 2.339 | Reg loss: 0.038 | Tree loss: 2.339 | Accuracy: 0.252560 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 297 | Batch: 000 / 011 | Total loss: 2.603 | Reg loss: 0.038 | Tree loss: 2.603 | Accuracy: 0.269500 | 0.86 sec/iter\n",
      "Epoch: 297 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.292500 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.269500 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.296000 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 004 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.296500 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 005 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.292500 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.277500 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 007 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.258000 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.254000 | 0.859 sec/iter\n",
      "Epoch: 297 | Batch: 010 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.255973 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 298 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.270500 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 001 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.278000 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.281000 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 003 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.293500 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.287500 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 005 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.298500 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.292000 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.296500 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.277000 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 009 / 011 | Total loss: 2.365 | Reg loss: 0.038 | Tree loss: 2.365 | Accuracy: 0.257500 | 0.859 sec/iter\n",
      "Epoch: 298 | Batch: 010 / 011 | Total loss: 2.352 | Reg loss: 0.038 | Tree loss: 2.352 | Accuracy: 0.283276 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 299 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.281500 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 001 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.300000 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 003 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.318500 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.291000 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 005 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.290000 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 006 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.275500 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 007 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.253000 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 008 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.241500 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 009 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.276500 | 0.859 sec/iter\n",
      "Epoch: 299 | Batch: 010 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.276451 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.262500 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.282000 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.285500 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.287500 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.301500 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.310000 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.296000 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.299500 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 009 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.268000 | 0.859 sec/iter\n",
      "Epoch: 300 | Batch: 010 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.238908 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 301 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.038 | Tree loss: 2.606 | Accuracy: 0.277000 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.275000 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 002 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.305500 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.291000 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.303500 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.292000 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 006 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.278000 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.287500 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.271000 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.248500 | 0.859 sec/iter\n",
      "Epoch: 301 | Batch: 010 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.191126 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 302 | Batch: 000 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.270000 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.285500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 002 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.275500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 004 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.297000 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 005 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.310500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 006 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.296500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.290500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.282500 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 009 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.243000 | 0.859 sec/iter\n",
      "Epoch: 302 | Batch: 010 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.228669 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 303 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.280000 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 001 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.291500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 002 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.291000 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 003 / 011 | Total loss: 2.503 | Reg loss: 0.038 | Tree loss: 2.503 | Accuracy: 0.282500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 004 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.295500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 005 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.286500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.274500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 007 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.280500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.261500 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 009 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.258000 | 0.859 sec/iter\n",
      "Epoch: 303 | Batch: 010 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.262799 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 304 | Batch: 000 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.272000 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 001 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.264000 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.303500 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 003 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.304500 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 004 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.282500 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.287500 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.299500 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.295000 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.262000 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.251500 | 0.859 sec/iter\n",
      "Epoch: 304 | Batch: 010 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.225256 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 305 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.277000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.281500 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 002 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.281500 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.284000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.295000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 005 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.290000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 006 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.293000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 007 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.280000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.272000 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.256500 | 0.859 sec/iter\n",
      "Epoch: 305 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.290102 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 306 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.290000 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.273500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 002 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.301500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 003 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 004 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.280500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.273500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.311500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 007 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.268500 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.240000 | 0.859 sec/iter\n",
      "Epoch: 306 | Batch: 010 / 011 | Total loss: 2.327 | Reg loss: 0.038 | Tree loss: 2.327 | Accuracy: 0.249147 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 307 | Batch: 000 / 011 | Total loss: 2.610 | Reg loss: 0.038 | Tree loss: 2.610 | Accuracy: 0.265500 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.274500 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 002 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.295000 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 003 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.292500 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.280000 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 005 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.308500 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 006 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.270500 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.267000 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 008 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 009 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.270000 | 0.859 sec/iter\n",
      "Epoch: 307 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.269625 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 308 | Batch: 000 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.273500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 002 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.293500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.295500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.301000 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.288500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.273500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.279500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 008 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.264500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 009 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.259500 | 0.859 sec/iter\n",
      "Epoch: 308 | Batch: 010 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.215017 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 309 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.260500 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.272000 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.309500 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 003 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.306000 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.280500 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 005 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.267500 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.301500 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.299500 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 008 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.288000 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 009 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.267000 | 0.859 sec/iter\n",
      "Epoch: 309 | Batch: 010 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.232082 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310 | Batch: 000 / 011 | Total loss: 2.624 | Reg loss: 0.038 | Tree loss: 2.624 | Accuracy: 0.256500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.295000 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.301000 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.293500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.275500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.274000 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.288500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.261500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 008 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.258500 | 0.859 sec/iter\n",
      "Epoch: 310 | Batch: 010 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.238908 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 311 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.271000 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.293500 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.276000 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 003 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.289500 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.292500 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 005 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.286500 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.287500 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 007 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.288000 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.287000 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 009 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.267500 | 0.859 sec/iter\n",
      "Epoch: 311 | Batch: 010 / 011 | Total loss: 2.355 | Reg loss: 0.038 | Tree loss: 2.355 | Accuracy: 0.221843 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 312 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.270500 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.290000 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.284000 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 003 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.295500 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 004 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.281000 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 005 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.284500 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 006 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.290500 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 007 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.271000 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 008 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.253500 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.259500 | 0.859 sec/iter\n",
      "Epoch: 312 | Batch: 010 / 011 | Total loss: 2.350 | Reg loss: 0.038 | Tree loss: 2.350 | Accuracy: 0.238908 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 313 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.264500 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 001 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.278000 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.276000 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 003 / 011 | Total loss: 2.482 | Reg loss: 0.038 | Tree loss: 2.482 | Accuracy: 0.295000 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 004 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.296500 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 005 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.300500 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 006 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.298500 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 007 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.290000 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 008 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.264000 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.274000 | 0.859 sec/iter\n",
      "Epoch: 313 | Batch: 010 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.242321 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 314 | Batch: 000 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.277000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 001 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.279000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.298000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.271500 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.290500 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 005 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.300000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.270500 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.268000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 008 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.264000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.263000 | 0.859 sec/iter\n",
      "Epoch: 314 | Batch: 010 / 011 | Total loss: 2.316 | Reg loss: 0.038 | Tree loss: 2.316 | Accuracy: 0.276451 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 315 | Batch: 000 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 001 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.257500 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 002 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.284500 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.297500 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.285000 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.290500 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.294500 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.272500 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 008 / 011 | Total loss: 2.368 | Reg loss: 0.038 | Tree loss: 2.368 | Accuracy: 0.288000 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.251000 | 0.859 sec/iter\n",
      "Epoch: 315 | Batch: 010 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.262799 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 316 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.270500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.266500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.277500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 003 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.284500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.289500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 005 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.287000 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.268500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 008 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.257500 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.258000 | 0.859 sec/iter\n",
      "Epoch: 316 | Batch: 010 / 011 | Total loss: 2.336 | Reg loss: 0.038 | Tree loss: 2.336 | Accuracy: 0.242321 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 317 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.269000 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.292500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 002 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 003 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.298500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.280500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.295000 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 006 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.280500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.284500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.279500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 009 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.265500 | 0.859 sec/iter\n",
      "Epoch: 317 | Batch: 010 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.218430 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 318 | Batch: 000 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.286000 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 001 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.280500 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.283500 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 003 / 011 | Total loss: 2.492 | Reg loss: 0.038 | Tree loss: 2.492 | Accuracy: 0.293000 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 004 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.303500 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.300000 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.300500 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 008 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.268000 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 009 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.254000 | 0.859 sec/iter\n",
      "Epoch: 318 | Batch: 010 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.262799 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 319 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.266000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.278000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.274000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 003 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.308500 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.283500 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 005 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.291000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.288000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 007 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.303000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 008 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.262000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 009 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.234000 | 0.859 sec/iter\n",
      "Epoch: 319 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.310580 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.276500 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 001 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.287000 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.288000 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.298500 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 004 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.303500 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.297000 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.286000 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.282000 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.269500 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.265000 | 0.859 sec/iter\n",
      "Epoch: 320 | Batch: 010 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.225256 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 321 | Batch: 000 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.274500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.286500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.276500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.293000 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.301500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 005 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.281500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 006 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.283500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.291500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.288000 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.251500 | 0.859 sec/iter\n",
      "Epoch: 321 | Batch: 010 / 011 | Total loss: 2.339 | Reg loss: 0.038 | Tree loss: 2.339 | Accuracy: 0.262799 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 322 | Batch: 000 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.279000 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 001 / 011 | Total loss: 2.565 | Reg loss: 0.038 | Tree loss: 2.565 | Accuracy: 0.278500 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.279500 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 003 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.308000 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 004 / 011 | Total loss: 2.476 | Reg loss: 0.038 | Tree loss: 2.476 | Accuracy: 0.277000 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.289000 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 007 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.297500 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 008 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.262500 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.258500 | 0.859 sec/iter\n",
      "Epoch: 322 | Batch: 010 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.276451 | 0.859 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 323 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.271000 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.273000 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.289000 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.305000 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.291000 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 005 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.286500 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 006 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.297500 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 007 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.289000 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.269500 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.255500 | 0.859 sec/iter\n",
      "Epoch: 323 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.218430 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 324 | Batch: 000 / 011 | Total loss: 2.597 | Reg loss: 0.038 | Tree loss: 2.597 | Accuracy: 0.270500 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 001 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.288000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.038 | Tree loss: 2.487 | Accuracy: 0.273000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 004 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.278000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.279000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 006 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.276500 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.275500 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 008 / 011 | Total loss: 2.356 | Reg loss: 0.038 | Tree loss: 2.356 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 324 | Batch: 010 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.252560 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 325 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.266000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.277000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 002 / 011 | Total loss: 2.514 | Reg loss: 0.038 | Tree loss: 2.514 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 003 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.287000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 004 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.297000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 005 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.298500 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.291500 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.270000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 009 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.248000 | 0.858 sec/iter\n",
      "Epoch: 325 | Batch: 010 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.259386 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 326 | Batch: 000 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.298000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.265000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.274500 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.269000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 005 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.310000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.278000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 008 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.270000 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.262500 | 0.858 sec/iter\n",
      "Epoch: 326 | Batch: 010 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.228669 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 327 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 001 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.270000 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 002 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.262500 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.303500 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 004 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 005 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.285000 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 006 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.273500 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.286500 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 008 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.300500 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 009 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.274000 | 0.858 sec/iter\n",
      "Epoch: 327 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.242321 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 328 | Batch: 000 / 011 | Total loss: 2.600 | Reg loss: 0.038 | Tree loss: 2.600 | Accuracy: 0.274000 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.287000 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.280500 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.275000 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.279500 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 005 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.294000 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 006 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.300500 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.261000 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 008 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.279000 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 009 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.266500 | 0.858 sec/iter\n",
      "Epoch: 328 | Batch: 010 / 011 | Total loss: 2.345 | Reg loss: 0.038 | Tree loss: 2.345 | Accuracy: 0.276451 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 329 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.268000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 001 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.279500 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 002 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.276000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 003 / 011 | Total loss: 2.482 | Reg loss: 0.038 | Tree loss: 2.482 | Accuracy: 0.307500 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.285000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 006 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.283000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 008 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.258500 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 009 / 011 | Total loss: 2.363 | Reg loss: 0.038 | Tree loss: 2.363 | Accuracy: 0.262000 | 0.858 sec/iter\n",
      "Epoch: 329 | Batch: 010 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.245734 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330 | Batch: 000 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 001 / 011 | Total loss: 2.562 | Reg loss: 0.038 | Tree loss: 2.562 | Accuracy: 0.278000 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.292500 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.302500 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 005 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.285000 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 006 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.288000 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 007 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.288500 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.264500 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.252500 | 0.858 sec/iter\n",
      "Epoch: 330 | Batch: 010 / 011 | Total loss: 2.362 | Reg loss: 0.038 | Tree loss: 2.362 | Accuracy: 0.300341 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 331 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.260500 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 001 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.291500 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.273000 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 003 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.302500 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 004 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.292000 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.273500 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.290000 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 008 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.273000 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.263000 | 0.858 sec/iter\n",
      "Epoch: 331 | Batch: 010 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.283276 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 332 | Batch: 000 / 011 | Total loss: 2.601 | Reg loss: 0.038 | Tree loss: 2.601 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.287000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 003 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.311000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.298500 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.284500 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 007 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.294000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 009 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.260000 | 0.858 sec/iter\n",
      "Epoch: 332 | Batch: 010 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.245734 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 333 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.286500 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 001 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.261500 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 002 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.293000 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 003 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.306500 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.284500 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.298000 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.275500 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 008 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.244500 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.258000 | 0.858 sec/iter\n",
      "Epoch: 333 | Batch: 010 / 011 | Total loss: 2.333 | Reg loss: 0.038 | Tree loss: 2.333 | Accuracy: 0.279863 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 334 | Batch: 000 / 011 | Total loss: 2.604 | Reg loss: 0.038 | Tree loss: 2.604 | Accuracy: 0.250000 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.270000 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.294500 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.302500 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.295500 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.301500 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 007 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.300000 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.274500 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.263500 | 0.858 sec/iter\n",
      "Epoch: 334 | Batch: 010 / 011 | Total loss: 2.325 | Reg loss: 0.038 | Tree loss: 2.325 | Accuracy: 0.300341 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 335 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.270500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 001 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.275000 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 002 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.307500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 003 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.280500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 004 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.299500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.282500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.257500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.250000 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 335 | Batch: 010 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.225256 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 336 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.279500 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 001 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.283500 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.299000 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.296500 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.279000 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.298500 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 007 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.265000 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.294500 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.259000 | 0.858 sec/iter\n",
      "Epoch: 336 | Batch: 010 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.249147 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 337 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.275500 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.290000 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 004 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.300500 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 005 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.287000 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.287500 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 007 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.283500 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 008 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.283000 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.262500 | 0.858 sec/iter\n",
      "Epoch: 337 | Batch: 010 / 011 | Total loss: 2.351 | Reg loss: 0.038 | Tree loss: 2.351 | Accuracy: 0.245734 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 338 | Batch: 000 / 011 | Total loss: 2.606 | Reg loss: 0.038 | Tree loss: 2.606 | Accuracy: 0.263000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.272000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 002 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.294000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 003 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.310000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 004 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 005 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.293500 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.292000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 007 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.266000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.283500 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.263000 | 0.858 sec/iter\n",
      "Epoch: 338 | Batch: 010 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.252560 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 339 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 002 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.283500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.292000 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 004 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.277500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 005 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.294500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 006 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.312500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 007 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.286500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.275500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 009 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.270500 | 0.858 sec/iter\n",
      "Epoch: 339 | Batch: 010 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.252560 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.278500 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.278500 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.287000 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.295000 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.294000 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.290500 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.273500 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 008 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.288500 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 009 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.248000 | 0.858 sec/iter\n",
      "Epoch: 340 | Batch: 010 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.293515 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 341 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.265000 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 001 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.269500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.290500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 003 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.315000 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 004 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.274500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 005 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.291500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 006 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.288500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 007 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.291500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.284000 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.267500 | 0.858 sec/iter\n",
      "Epoch: 341 | Batch: 010 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.255973 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 342 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.274500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 001 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.280500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 003 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 004 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.309500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.311500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 006 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.289500 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.280000 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 008 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.257000 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 009 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.266000 | 0.858 sec/iter\n",
      "Epoch: 342 | Batch: 010 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.235495 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 343 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.280000 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 001 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.279500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.299500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 004 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 005 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.295000 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.290500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.288500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.279500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 009 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.263500 | 0.858 sec/iter\n",
      "Epoch: 343 | Batch: 010 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.218430 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 344 | Batch: 000 / 011 | Total loss: 2.603 | Reg loss: 0.038 | Tree loss: 2.603 | Accuracy: 0.268500 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 001 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 002 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.305500 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 003 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.280000 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 005 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.282500 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.290500 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 008 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.277000 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.269000 | 0.858 sec/iter\n",
      "Epoch: 344 | Batch: 010 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.228669 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 345 | Batch: 000 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 001 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.287500 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.273500 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.277500 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.288500 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 005 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.298500 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.285000 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 007 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.280500 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.255000 | 0.858 sec/iter\n",
      "Epoch: 345 | Batch: 010 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.249147 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 346 | Batch: 000 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.271000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 001 / 011 | Total loss: 2.565 | Reg loss: 0.038 | Tree loss: 2.565 | Accuracy: 0.299000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.282500 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 003 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.292000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.285500 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.283000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.294500 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 007 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.263000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 009 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.252000 | 0.858 sec/iter\n",
      "Epoch: 346 | Batch: 010 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.211604 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 347 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.277500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 001 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.280500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.283000 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 003 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.304500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 005 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.277500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 006 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.285500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.285500 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 008 / 011 | Total loss: 2.368 | Reg loss: 0.038 | Tree loss: 2.368 | Accuracy: 0.284000 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.274000 | 0.858 sec/iter\n",
      "Epoch: 347 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.259386 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 348 | Batch: 000 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.272000 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 003 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.294000 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 004 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.292500 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.293500 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.292500 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.279000 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.254500 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 009 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 348 | Batch: 010 / 011 | Total loss: 2.351 | Reg loss: 0.038 | Tree loss: 2.351 | Accuracy: 0.307167 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 349 | Batch: 000 / 011 | Total loss: 2.599 | Reg loss: 0.038 | Tree loss: 2.599 | Accuracy: 0.276500 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 001 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.283000 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.284000 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.296500 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.296000 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 005 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.273500 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.289000 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.269500 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.253500 | 0.858 sec/iter\n",
      "Epoch: 349 | Batch: 010 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.218430 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.270500 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 001 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.272000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.294500 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.302000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.285000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.284000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.298500 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 007 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.268000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.268000 | 0.858 sec/iter\n",
      "Epoch: 350 | Batch: 010 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.232082 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 351 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.272500 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.298000 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 003 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.310500 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.282000 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 006 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.293000 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 007 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.306500 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.264000 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 009 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.245500 | 0.858 sec/iter\n",
      "Epoch: 351 | Batch: 010 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.221843 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 352 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.281500 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.290500 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.288000 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.284500 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 004 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.299000 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.292500 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 006 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.288500 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 007 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.274000 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.250500 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.270000 | 0.858 sec/iter\n",
      "Epoch: 352 | Batch: 010 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.242321 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 353 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.254500 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.269500 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.288000 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.295000 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.294000 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 005 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.279500 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 007 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.278500 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 008 / 011 | Total loss: 2.349 | Reg loss: 0.038 | Tree loss: 2.349 | Accuracy: 0.286000 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.264000 | 0.858 sec/iter\n",
      "Epoch: 353 | Batch: 010 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.283276 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 354 | Batch: 000 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.270000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.287500 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 002 / 011 | Total loss: 2.508 | Reg loss: 0.038 | Tree loss: 2.508 | Accuracy: 0.299000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 003 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.308500 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 004 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.278500 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 006 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.265000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 008 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.280000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 009 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.230000 | 0.858 sec/iter\n",
      "Epoch: 354 | Batch: 010 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.242321 | 0.858 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 355 | Batch: 000 / 011 | Total loss: 2.617 | Reg loss: 0.038 | Tree loss: 2.617 | Accuracy: 0.261000 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.283500 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.277500 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.306000 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 004 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.283500 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 005 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.305000 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.291000 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 007 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.281000 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.292000 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 009 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.269500 | 0.858 sec/iter\n",
      "Epoch: 355 | Batch: 010 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.242321 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 356 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.278500 | 0.858 sec/iter\n",
      "Epoch: 356 | Batch: 001 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.291500 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.304500 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 005 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.308000 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 007 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.271500 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.240000 | 0.857 sec/iter\n",
      "Epoch: 356 | Batch: 010 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.238908 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 357 | Batch: 000 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.278000 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 003 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.296000 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 004 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 005 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 006 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.262500 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 007 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.294500 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 009 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.240500 | 0.857 sec/iter\n",
      "Epoch: 357 | Batch: 010 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.273038 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 358 | Batch: 000 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.268000 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.277500 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.285000 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.270000 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.285000 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.257500 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 358 | Batch: 010 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.245734 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 359 | Batch: 000 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.270000 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 001 / 011 | Total loss: 2.552 | Reg loss: 0.038 | Tree loss: 2.552 | Accuracy: 0.283500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 002 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.263000 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.297500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.275500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.293500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.275500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.283500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.256500 | 0.857 sec/iter\n",
      "Epoch: 359 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.235495 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360 | Batch: 000 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.269500 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.294500 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 003 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.283000 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.290000 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.295000 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 008 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.252500 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 009 / 011 | Total loss: 2.356 | Reg loss: 0.038 | Tree loss: 2.356 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 360 | Batch: 010 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.201365 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 361 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 001 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.294500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 005 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 006 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 007 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.283500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 008 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.279500 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 009 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.257000 | 0.857 sec/iter\n",
      "Epoch: 361 | Batch: 010 / 011 | Total loss: 2.364 | Reg loss: 0.038 | Tree loss: 2.364 | Accuracy: 0.235495 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 362 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.274000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 001 / 011 | Total loss: 2.550 | Reg loss: 0.038 | Tree loss: 2.550 | Accuracy: 0.302000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.303500 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 003 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.304000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 004 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.290000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.276000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.271000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 009 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.260000 | 0.857 sec/iter\n",
      "Epoch: 362 | Batch: 010 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.252560 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 363 | Batch: 000 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.270000 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.278500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 002 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.302500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 003 / 011 | Total loss: 2.503 | Reg loss: 0.038 | Tree loss: 2.503 | Accuracy: 0.268000 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.292500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 006 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.292500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 009 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.271000 | 0.857 sec/iter\n",
      "Epoch: 363 | Batch: 010 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.283276 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 364 | Batch: 000 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.264000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 002 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.300000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.293000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.298000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 005 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.303500 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.291000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.264000 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 009 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.254500 | 0.857 sec/iter\n",
      "Epoch: 364 | Batch: 010 / 011 | Total loss: 2.339 | Reg loss: 0.038 | Tree loss: 2.339 | Accuracy: 0.252560 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 365 | Batch: 000 / 011 | Total loss: 2.599 | Reg loss: 0.038 | Tree loss: 2.599 | Accuracy: 0.258500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 001 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.284000 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.299500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.294500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 005 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.309500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 007 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.272000 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 008 / 011 | Total loss: 2.359 | Reg loss: 0.038 | Tree loss: 2.359 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.277000 | 0.857 sec/iter\n",
      "Epoch: 365 | Batch: 010 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.252560 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 366 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.271500 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 001 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.291000 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.304500 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.277500 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 004 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.306500 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 005 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.300000 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.285000 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.262000 | 0.857 sec/iter\n",
      "Epoch: 366 | Batch: 010 / 011 | Total loss: 2.318 | Reg loss: 0.038 | Tree loss: 2.318 | Accuracy: 0.296928 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 367 | Batch: 000 / 011 | Total loss: 2.608 | Reg loss: 0.038 | Tree loss: 2.608 | Accuracy: 0.258500 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 001 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.293500 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 002 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 003 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.296000 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.306000 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 005 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.264000 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 006 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.275500 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 008 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.276000 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.261500 | 0.857 sec/iter\n",
      "Epoch: 367 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.255973 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 368 | Batch: 000 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.294500 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 004 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.315500 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 005 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 007 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.277500 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 009 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 368 | Batch: 010 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.266212 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 369 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.260500 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.293000 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 004 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.276000 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 005 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.285000 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 006 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 007 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.279500 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.262000 | 0.857 sec/iter\n",
      "Epoch: 369 | Batch: 010 / 011 | Total loss: 2.356 | Reg loss: 0.038 | Tree loss: 2.356 | Accuracy: 0.283276 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 001 / 011 | Total loss: 2.552 | Reg loss: 0.038 | Tree loss: 2.552 | Accuracy: 0.277500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.283500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 005 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.308500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.271500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 007 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.255500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 009 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.252500 | 0.857 sec/iter\n",
      "Epoch: 370 | Batch: 010 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.255973 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 371 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.263000 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 001 / 011 | Total loss: 2.565 | Reg loss: 0.038 | Tree loss: 2.565 | Accuracy: 0.283500 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.291500 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.301000 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.281000 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 005 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.281000 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.298500 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 008 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.268500 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.252000 | 0.857 sec/iter\n",
      "Epoch: 371 | Batch: 010 / 011 | Total loss: 2.340 | Reg loss: 0.038 | Tree loss: 2.340 | Accuracy: 0.269625 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 372 | Batch: 000 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.269500 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 002 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 003 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.283000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.300500 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.297000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 007 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 008 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.262000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 372 | Batch: 010 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.273038 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 373 | Batch: 000 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 001 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.279500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 004 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.298000 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 006 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.277500 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 373 | Batch: 010 / 011 | Total loss: 2.296 | Reg loss: 0.038 | Tree loss: 2.296 | Accuracy: 0.276451 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 374 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.267500 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 001 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.272000 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 002 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.295500 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.293000 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.289000 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.289000 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 007 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.288500 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 009 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.262000 | 0.857 sec/iter\n",
      "Epoch: 374 | Batch: 010 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.215017 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 375 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.272500 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 002 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.304500 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.277500 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 004 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.296500 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.285000 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.296500 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.276000 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.272000 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.263500 | 0.857 sec/iter\n",
      "Epoch: 375 | Batch: 010 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.221843 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 376 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.261500 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 001 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.297000 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.284000 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 003 / 011 | Total loss: 2.505 | Reg loss: 0.038 | Tree loss: 2.505 | Accuracy: 0.291000 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 004 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 005 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.293500 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 006 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.299500 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 007 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.265000 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 009 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.248000 | 0.857 sec/iter\n",
      "Epoch: 376 | Batch: 010 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.249147 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 377 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.275500 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 003 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 005 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.291500 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 006 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 007 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.290000 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.277000 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.254500 | 0.857 sec/iter\n",
      "Epoch: 377 | Batch: 010 / 011 | Total loss: 2.320 | Reg loss: 0.038 | Tree loss: 2.320 | Accuracy: 0.293515 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 378 | Batch: 000 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 001 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.299000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 005 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 006 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.296000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 009 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.255000 | 0.857 sec/iter\n",
      "Epoch: 378 | Batch: 010 / 011 | Total loss: 2.364 | Reg loss: 0.038 | Tree loss: 2.364 | Accuracy: 0.211604 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 379 | Batch: 000 / 011 | Total loss: 2.591 | Reg loss: 0.038 | Tree loss: 2.591 | Accuracy: 0.264000 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.292500 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.298000 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.294500 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 006 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.284000 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 007 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.268000 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 009 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.256000 | 0.857 sec/iter\n",
      "Epoch: 379 | Batch: 010 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.290102 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380 | Batch: 000 / 011 | Total loss: 2.619 | Reg loss: 0.038 | Tree loss: 2.619 | Accuracy: 0.252000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 001 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.297000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 005 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.302000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 006 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.287500 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 380 | Batch: 010 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.252560 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 381 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.287500 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.295000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.289000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 005 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.303500 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.264000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 007 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.274000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 009 / 011 | Total loss: 2.359 | Reg loss: 0.038 | Tree loss: 2.359 | Accuracy: 0.273000 | 0.857 sec/iter\n",
      "Epoch: 381 | Batch: 010 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.286689 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 382 | Batch: 000 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.288500 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.273500 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.275000 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 003 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.297000 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.297500 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.299500 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 008 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.269000 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 009 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.252500 | 0.857 sec/iter\n",
      "Epoch: 382 | Batch: 010 / 011 | Total loss: 2.361 | Reg loss: 0.038 | Tree loss: 2.361 | Accuracy: 0.273038 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 383 | Batch: 000 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.274000 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.293000 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.275000 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.288500 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.303000 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 008 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.278500 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 009 / 011 | Total loss: 2.368 | Reg loss: 0.038 | Tree loss: 2.368 | Accuracy: 0.268500 | 0.857 sec/iter\n",
      "Epoch: 383 | Batch: 010 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.225256 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 384 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 001 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.263500 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 004 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.304000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.288000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.273500 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 007 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.281000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.278000 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.260500 | 0.857 sec/iter\n",
      "Epoch: 384 | Batch: 010 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.228669 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 385 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.268500 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 001 / 011 | Total loss: 2.547 | Reg loss: 0.038 | Tree loss: 2.547 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 002 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 003 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.293000 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 005 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 006 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.293000 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 008 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.269500 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.249000 | 0.857 sec/iter\n",
      "Epoch: 385 | Batch: 010 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.259386 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 386 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.262500 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 003 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.299000 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 004 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.289000 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.291500 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 006 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.299500 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.274000 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.251000 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.262500 | 0.857 sec/iter\n",
      "Epoch: 386 | Batch: 010 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.218430 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 387 | Batch: 000 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.256500 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.272500 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.290000 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 003 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.298500 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.267000 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.291000 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.270000 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.252500 | 0.857 sec/iter\n",
      "Epoch: 387 | Batch: 010 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.266212 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 388 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.255500 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 001 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.289000 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.283500 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.299500 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 005 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.287500 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 006 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.274000 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.284000 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 008 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.269500 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 009 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.255000 | 0.857 sec/iter\n",
      "Epoch: 388 | Batch: 010 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.242321 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 389 | Batch: 000 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 001 / 011 | Total loss: 2.568 | Reg loss: 0.038 | Tree loss: 2.568 | Accuracy: 0.270500 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.283000 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.313500 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.276000 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.268000 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.260500 | 0.857 sec/iter\n",
      "Epoch: 389 | Batch: 010 / 011 | Total loss: 2.348 | Reg loss: 0.038 | Tree loss: 2.348 | Accuracy: 0.276451 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 390 | Batch: 000 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.275000 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.265500 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 002 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.300000 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.299000 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.260500 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 009 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.242500 | 0.857 sec/iter\n",
      "Epoch: 390 | Batch: 010 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.259386 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 391 | Batch: 000 / 011 | Total loss: 2.574 | Reg loss: 0.038 | Tree loss: 2.574 | Accuracy: 0.275000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 001 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 002 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.303000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 003 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.271000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 004 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.271000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 006 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.299000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 007 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.297500 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 009 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 391 | Batch: 010 / 011 | Total loss: 2.310 | Reg loss: 0.038 | Tree loss: 2.310 | Accuracy: 0.273038 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 392 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.296000 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.273500 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.287500 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 005 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.303000 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.262000 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 009 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.254000 | 0.857 sec/iter\n",
      "Epoch: 392 | Batch: 010 / 011 | Total loss: 2.353 | Reg loss: 0.038 | Tree loss: 2.353 | Accuracy: 0.252560 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 393 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.283000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 001 / 011 | Total loss: 2.562 | Reg loss: 0.038 | Tree loss: 2.562 | Accuracy: 0.282000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.038 | Tree loss: 2.487 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 005 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.296000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 007 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 009 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 393 | Batch: 010 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.276451 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 394 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 001 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.298500 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.271500 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.295500 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 004 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.296500 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.260000 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.245500 | 0.857 sec/iter\n",
      "Epoch: 394 | Batch: 010 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.266212 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 395 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.273500 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 001 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.299000 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.284000 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 003 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.284500 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 005 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.283000 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 006 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.296000 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 007 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.274000 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.268500 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.262500 | 0.857 sec/iter\n",
      "Epoch: 395 | Batch: 010 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.266212 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 396 | Batch: 000 / 011 | Total loss: 2.616 | Reg loss: 0.038 | Tree loss: 2.616 | Accuracy: 0.254000 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 002 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.292500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.293500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 005 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.278500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 007 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.281500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 008 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.279500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 009 / 011 | Total loss: 2.363 | Reg loss: 0.038 | Tree loss: 2.363 | Accuracy: 0.256500 | 0.857 sec/iter\n",
      "Epoch: 396 | Batch: 010 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.242321 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 397 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.266500 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 001 / 011 | Total loss: 2.562 | Reg loss: 0.038 | Tree loss: 2.562 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.295500 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.297500 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 004 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.304000 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.266000 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.281000 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 008 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.261500 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 009 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.261500 | 0.857 sec/iter\n",
      "Epoch: 397 | Batch: 010 / 011 | Total loss: 2.335 | Reg loss: 0.038 | Tree loss: 2.335 | Accuracy: 0.225256 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 398 | Batch: 000 / 011 | Total loss: 2.608 | Reg loss: 0.038 | Tree loss: 2.608 | Accuracy: 0.248000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.286000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.290500 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 003 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.287000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.307000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.286500 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.281000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 007 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.291000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 008 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.267500 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 009 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.239000 | 0.857 sec/iter\n",
      "Epoch: 398 | Batch: 010 / 011 | Total loss: 2.344 | Reg loss: 0.038 | Tree loss: 2.344 | Accuracy: 0.262799 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 399 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.275500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.280000 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.274500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 003 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.276500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.289500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.279000 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 006 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.294000 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 007 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.270500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 008 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.285500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 009 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.259500 | 0.857 sec/iter\n",
      "Epoch: 399 | Batch: 010 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.235495 | 0.857 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.280500 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.272000 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.292000 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.298500 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.290000 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.302000 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.279500 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.264500 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.268500 | 0.857 sec/iter\n",
      "Epoch: 400 | Batch: 010 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.232082 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 401 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.282500 | 0.857 sec/iter\n",
      "Epoch: 401 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.270000 | 0.857 sec/iter\n",
      "Epoch: 401 | Batch: 002 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.290000 | 0.857 sec/iter\n",
      "Epoch: 401 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.300000 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 006 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 008 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.278000 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 401 | Batch: 010 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.245734 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 402 | Batch: 000 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.292000 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 003 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 004 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.303500 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 007 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 008 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 009 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 402 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.249147 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 403 | Batch: 000 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 002 / 011 | Total loss: 2.502 | Reg loss: 0.038 | Tree loss: 2.502 | Accuracy: 0.291000 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 003 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 403 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.276451 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 404 | Batch: 000 / 011 | Total loss: 2.574 | Reg loss: 0.038 | Tree loss: 2.574 | Accuracy: 0.268000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.273500 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.278000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.313000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 004 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 007 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.265000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.268000 | 0.856 sec/iter\n",
      "Epoch: 404 | Batch: 010 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.242321 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 405 | Batch: 000 / 011 | Total loss: 2.604 | Reg loss: 0.038 | Tree loss: 2.604 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 001 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 003 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.304500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 006 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 007 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.278000 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 008 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 009 / 011 | Total loss: 2.357 | Reg loss: 0.038 | Tree loss: 2.357 | Accuracy: 0.276500 | 0.856 sec/iter\n",
      "Epoch: 405 | Batch: 010 / 011 | Total loss: 2.315 | Reg loss: 0.038 | Tree loss: 2.315 | Accuracy: 0.283276 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 406 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 001 / 011 | Total loss: 2.562 | Reg loss: 0.038 | Tree loss: 2.562 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 002 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.298500 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 003 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.271500 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 005 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 006 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 008 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 009 / 011 | Total loss: 2.354 | Reg loss: 0.038 | Tree loss: 2.354 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 406 | Batch: 010 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.255973 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 407 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.266000 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.305000 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 004 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.297500 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 008 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.252500 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.256500 | 0.856 sec/iter\n",
      "Epoch: 407 | Batch: 010 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.225256 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 408 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.273500 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 004 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 006 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.301000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 007 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 008 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.254000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 009 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.253000 | 0.856 sec/iter\n",
      "Epoch: 408 | Batch: 010 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.235495 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 409 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 001 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.264000 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 003 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.294500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 005 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.289500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.253500 | 0.856 sec/iter\n",
      "Epoch: 409 | Batch: 010 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.252560 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 410 | Batch: 000 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 001 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 002 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 004 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.270000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.285500 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 007 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 008 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 009 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.258000 | 0.856 sec/iter\n",
      "Epoch: 410 | Batch: 010 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.296928 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 411 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 001 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.038 | Tree loss: 2.487 | Accuracy: 0.295500 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.273500 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 005 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 006 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 008 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.271500 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.255500 | 0.856 sec/iter\n",
      "Epoch: 411 | Batch: 010 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.221843 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 412 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.263500 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 001 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.261500 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 002 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.270000 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 003 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.309500 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 004 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 006 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.298000 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.295000 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.265500 | 0.856 sec/iter\n",
      "Epoch: 412 | Batch: 010 / 011 | Total loss: 2.353 | Reg loss: 0.038 | Tree loss: 2.353 | Accuracy: 0.293515 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 413 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.298500 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.297500 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 009 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.266000 | 0.856 sec/iter\n",
      "Epoch: 413 | Batch: 010 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.273038 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 414 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.276500 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 005 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.298000 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.267000 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 009 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.247000 | 0.856 sec/iter\n",
      "Epoch: 414 | Batch: 010 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.266212 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 415 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.276500 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.309000 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.301500 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 006 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 007 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.250000 | 0.856 sec/iter\n",
      "Epoch: 415 | Batch: 010 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.283276 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 416 | Batch: 000 / 011 | Total loss: 2.597 | Reg loss: 0.038 | Tree loss: 2.597 | Accuracy: 0.256500 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 005 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 006 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 009 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.263500 | 0.856 sec/iter\n",
      "Epoch: 416 | Batch: 010 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.259386 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 417 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 001 / 011 | Total loss: 2.587 | Reg loss: 0.038 | Tree loss: 2.587 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 002 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 003 / 011 | Total loss: 2.492 | Reg loss: 0.038 | Tree loss: 2.492 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 004 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 005 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.303500 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 006 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 008 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.254500 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 417 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.286689 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 418 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 001 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.268500 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 007 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 009 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.266500 | 0.856 sec/iter\n",
      "Epoch: 418 | Batch: 010 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.238908 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 419 | Batch: 000 / 011 | Total loss: 2.599 | Reg loss: 0.038 | Tree loss: 2.599 | Accuracy: 0.268000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.309000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 005 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 007 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 008 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 009 / 011 | Total loss: 2.354 | Reg loss: 0.038 | Tree loss: 2.354 | Accuracy: 0.272000 | 0.856 sec/iter\n",
      "Epoch: 419 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.262799 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420 | Batch: 000 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 001 / 011 | Total loss: 2.544 | Reg loss: 0.038 | Tree loss: 2.544 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.289500 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 003 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.297500 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 005 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 006 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 007 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 008 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.256000 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.261000 | 0.856 sec/iter\n",
      "Epoch: 420 | Batch: 010 / 011 | Total loss: 2.335 | Reg loss: 0.038 | Tree loss: 2.335 | Accuracy: 0.279863 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 421 | Batch: 000 / 011 | Total loss: 2.611 | Reg loss: 0.038 | Tree loss: 2.611 | Accuracy: 0.271500 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.269500 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 003 / 011 | Total loss: 2.482 | Reg loss: 0.038 | Tree loss: 2.482 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 004 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 005 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 006 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 007 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.303000 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 008 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 009 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.262000 | 0.856 sec/iter\n",
      "Epoch: 421 | Batch: 010 / 011 | Total loss: 2.322 | Reg loss: 0.038 | Tree loss: 2.322 | Accuracy: 0.266212 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 422 | Batch: 000 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 002 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.301000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 003 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.291000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 006 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 007 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.248000 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.251500 | 0.856 sec/iter\n",
      "Epoch: 422 | Batch: 010 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.218430 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 423 | Batch: 000 / 011 | Total loss: 2.619 | Reg loss: 0.038 | Tree loss: 2.619 | Accuracy: 0.256500 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 001 / 011 | Total loss: 2.534 | Reg loss: 0.038 | Tree loss: 2.534 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.309000 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.278000 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 004 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 005 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.304500 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.269000 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 009 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.269500 | 0.856 sec/iter\n",
      "Epoch: 423 | Batch: 010 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.238908 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 424 | Batch: 000 / 011 | Total loss: 2.596 | Reg loss: 0.038 | Tree loss: 2.596 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 001 / 011 | Total loss: 2.534 | Reg loss: 0.038 | Tree loss: 2.534 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 002 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.269500 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 007 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.252500 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.254500 | 0.856 sec/iter\n",
      "Epoch: 424 | Batch: 010 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.259386 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 425 | Batch: 000 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.269500 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 001 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 002 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.300000 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 005 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.269000 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.302500 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 008 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.254500 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 009 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.253000 | 0.856 sec/iter\n",
      "Epoch: 425 | Batch: 010 / 011 | Total loss: 2.341 | Reg loss: 0.038 | Tree loss: 2.341 | Accuracy: 0.293515 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 426 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 001 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 002 / 011 | Total loss: 2.517 | Reg loss: 0.038 | Tree loss: 2.517 | Accuracy: 0.269000 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 003 / 011 | Total loss: 2.492 | Reg loss: 0.038 | Tree loss: 2.492 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 004 / 011 | Total loss: 2.466 | Reg loss: 0.038 | Tree loss: 2.466 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 005 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 006 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 009 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.255000 | 0.856 sec/iter\n",
      "Epoch: 426 | Batch: 010 / 011 | Total loss: 2.361 | Reg loss: 0.038 | Tree loss: 2.361 | Accuracy: 0.262799 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 427 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.259500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 001 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 002 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 003 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.300500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 004 / 011 | Total loss: 2.470 | Reg loss: 0.038 | Tree loss: 2.470 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 005 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.299000 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 007 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 008 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.299000 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 009 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.258500 | 0.856 sec/iter\n",
      "Epoch: 427 | Batch: 010 / 011 | Total loss: 2.338 | Reg loss: 0.038 | Tree loss: 2.338 | Accuracy: 0.252560 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 428 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 001 / 011 | Total loss: 2.576 | Reg loss: 0.038 | Tree loss: 2.576 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 002 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.305500 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 005 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 006 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.266500 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 008 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 428 | Batch: 010 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.242321 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 429 | Batch: 000 / 011 | Total loss: 2.567 | Reg loss: 0.038 | Tree loss: 2.567 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 001 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.295500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 005 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 006 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 007 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.285500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 008 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.246500 | 0.856 sec/iter\n",
      "Epoch: 429 | Batch: 010 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.208191 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 430 | Batch: 000 / 011 | Total loss: 2.565 | Reg loss: 0.038 | Tree loss: 2.565 | Accuracy: 0.263500 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.296500 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 005 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 006 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 009 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.256000 | 0.856 sec/iter\n",
      "Epoch: 430 | Batch: 010 / 011 | Total loss: 2.338 | Reg loss: 0.038 | Tree loss: 2.338 | Accuracy: 0.303754 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 431 | Batch: 000 / 011 | Total loss: 2.612 | Reg loss: 0.038 | Tree loss: 2.612 | Accuracy: 0.259000 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 001 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.266500 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.299500 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 003 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 004 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.298500 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.289500 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 007 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.295000 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 008 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.266500 | 0.856 sec/iter\n",
      "Epoch: 431 | Batch: 010 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.252560 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 432 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.299500 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 001 / 011 | Total loss: 2.569 | Reg loss: 0.038 | Tree loss: 2.569 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.295000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 007 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.268000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 009 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.260000 | 0.856 sec/iter\n",
      "Epoch: 432 | Batch: 010 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.262799 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 433 | Batch: 000 / 011 | Total loss: 2.577 | Reg loss: 0.038 | Tree loss: 2.577 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 001 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.249500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.294500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 003 / 011 | Total loss: 2.506 | Reg loss: 0.038 | Tree loss: 2.506 | Accuracy: 0.312000 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.306500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 006 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 007 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.294500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 008 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 009 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 433 | Batch: 010 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.273038 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 434 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.265500 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.299500 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.291000 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 005 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 006 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 008 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.271500 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 009 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 434 | Batch: 010 / 011 | Total loss: 2.362 | Reg loss: 0.038 | Tree loss: 2.362 | Accuracy: 0.232082 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 435 | Batch: 000 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 001 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.289500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 005 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 006 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.295500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.250500 | 0.856 sec/iter\n",
      "Epoch: 435 | Batch: 010 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.255973 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 436 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.276500 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 004 / 011 | Total loss: 2.477 | Reg loss: 0.038 | Tree loss: 2.477 | Accuracy: 0.287000 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 008 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 009 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.249500 | 0.856 sec/iter\n",
      "Epoch: 436 | Batch: 010 / 011 | Total loss: 2.329 | Reg loss: 0.038 | Tree loss: 2.329 | Accuracy: 0.283276 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 437 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.255000 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 001 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.260500 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 002 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.301000 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 004 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.270000 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 005 / 011 | Total loss: 2.429 | Reg loss: 0.038 | Tree loss: 2.429 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 006 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 007 / 011 | Total loss: 2.361 | Reg loss: 0.038 | Tree loss: 2.361 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 008 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.296500 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 009 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 437 | Batch: 010 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.249147 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 438 | Batch: 000 / 011 | Total loss: 2.602 | Reg loss: 0.038 | Tree loss: 2.602 | Accuracy: 0.269000 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 002 / 011 | Total loss: 2.505 | Reg loss: 0.038 | Tree loss: 2.505 | Accuracy: 0.294500 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.296500 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 006 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 007 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.266500 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 008 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.246500 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 009 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.255500 | 0.856 sec/iter\n",
      "Epoch: 438 | Batch: 010 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.235495 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 439 | Batch: 000 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.269500 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 001 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 002 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 005 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.267500 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.258000 | 0.856 sec/iter\n",
      "Epoch: 439 | Batch: 010 / 011 | Total loss: 2.331 | Reg loss: 0.038 | Tree loss: 2.331 | Accuracy: 0.286689 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440 | Batch: 000 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 001 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 002 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.301500 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.273500 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 004 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 005 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 007 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 008 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 009 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.246000 | 0.856 sec/iter\n",
      "Epoch: 440 | Batch: 010 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.232082 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 441 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.260000 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 002 / 011 | Total loss: 2.534 | Reg loss: 0.038 | Tree loss: 2.534 | Accuracy: 0.297000 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.308500 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 005 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.306000 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.300500 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 007 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.310500 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 008 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.251000 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.262000 | 0.856 sec/iter\n",
      "Epoch: 441 | Batch: 010 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.249147 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 442 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.271500 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 002 / 011 | Total loss: 2.529 | Reg loss: 0.038 | Tree loss: 2.529 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.309000 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 005 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.315500 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 007 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.265500 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 008 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.259000 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 009 / 011 | Total loss: 2.366 | Reg loss: 0.038 | Tree loss: 2.366 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 442 | Batch: 010 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.255973 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 443 | Batch: 000 / 011 | Total loss: 2.600 | Reg loss: 0.038 | Tree loss: 2.600 | Accuracy: 0.262500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 001 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.277500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 004 / 011 | Total loss: 2.476 | Reg loss: 0.038 | Tree loss: 2.476 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 006 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.299500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 007 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.275500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 009 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.265000 | 0.856 sec/iter\n",
      "Epoch: 443 | Batch: 010 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.221843 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 444 | Batch: 000 / 011 | Total loss: 2.600 | Reg loss: 0.038 | Tree loss: 2.600 | Accuracy: 0.254500 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 001 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.263000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.298000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.295000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 005 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.292000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 006 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 007 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.267000 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 009 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 444 | Batch: 010 / 011 | Total loss: 2.292 | Reg loss: 0.038 | Tree loss: 2.292 | Accuracy: 0.279863 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 445 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.265000 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.278000 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.295500 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.289500 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 004 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 005 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.260500 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 006 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 008 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 009 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.256500 | 0.856 sec/iter\n",
      "Epoch: 445 | Batch: 010 / 011 | Total loss: 2.342 | Reg loss: 0.038 | Tree loss: 2.342 | Accuracy: 0.252560 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 446 | Batch: 000 / 011 | Total loss: 2.586 | Reg loss: 0.038 | Tree loss: 2.586 | Accuracy: 0.258500 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.292000 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.256000 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.276500 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 005 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 007 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 008 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.267000 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 009 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.261000 | 0.856 sec/iter\n",
      "Epoch: 446 | Batch: 010 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.204778 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 447 | Batch: 000 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 001 / 011 | Total loss: 2.538 | Reg loss: 0.038 | Tree loss: 2.538 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 002 / 011 | Total loss: 2.527 | Reg loss: 0.038 | Tree loss: 2.527 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 003 / 011 | Total loss: 2.495 | Reg loss: 0.038 | Tree loss: 2.495 | Accuracy: 0.266000 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 004 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 006 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 007 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 008 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.267000 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 009 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.267500 | 0.856 sec/iter\n",
      "Epoch: 447 | Batch: 010 / 011 | Total loss: 2.348 | Reg loss: 0.038 | Tree loss: 2.348 | Accuracy: 0.255973 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 448 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 001 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.279500 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 002 / 011 | Total loss: 2.539 | Reg loss: 0.038 | Tree loss: 2.539 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 003 / 011 | Total loss: 2.492 | Reg loss: 0.038 | Tree loss: 2.492 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 004 / 011 | Total loss: 2.442 | Reg loss: 0.038 | Tree loss: 2.442 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 005 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.295000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 007 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 008 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.248000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 009 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.240000 | 0.856 sec/iter\n",
      "Epoch: 448 | Batch: 010 / 011 | Total loss: 2.340 | Reg loss: 0.038 | Tree loss: 2.340 | Accuracy: 0.242321 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 449 | Batch: 000 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 001 / 011 | Total loss: 2.563 | Reg loss: 0.038 | Tree loss: 2.563 | Accuracy: 0.273500 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 002 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.258000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 006 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.291000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 007 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.270000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 009 / 011 | Total loss: 2.355 | Reg loss: 0.038 | Tree loss: 2.355 | Accuracy: 0.274000 | 0.856 sec/iter\n",
      "Epoch: 449 | Batch: 010 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.255973 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450 | Batch: 000 / 011 | Total loss: 2.605 | Reg loss: 0.038 | Tree loss: 2.605 | Accuracy: 0.255000 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 001 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 002 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.265000 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 003 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 005 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.278500 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 008 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.266000 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 009 / 011 | Total loss: 2.359 | Reg loss: 0.038 | Tree loss: 2.359 | Accuracy: 0.264000 | 0.856 sec/iter\n",
      "Epoch: 450 | Batch: 010 / 011 | Total loss: 2.301 | Reg loss: 0.038 | Tree loss: 2.301 | Accuracy: 0.300341 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 451 | Batch: 000 / 011 | Total loss: 2.618 | Reg loss: 0.038 | Tree loss: 2.618 | Accuracy: 0.245500 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 001 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 003 / 011 | Total loss: 2.504 | Reg loss: 0.038 | Tree loss: 2.504 | Accuracy: 0.281000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 004 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 005 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.298000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.291500 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.289000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 009 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.249000 | 0.856 sec/iter\n",
      "Epoch: 451 | Batch: 010 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.252560 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 452 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.258000 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.268000 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 002 / 011 | Total loss: 2.503 | Reg loss: 0.038 | Tree loss: 2.503 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 003 / 011 | Total loss: 2.499 | Reg loss: 0.038 | Tree loss: 2.499 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 004 / 011 | Total loss: 2.462 | Reg loss: 0.038 | Tree loss: 2.462 | Accuracy: 0.282500 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 006 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.298500 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 007 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 008 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.255000 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.261500 | 0.856 sec/iter\n",
      "Epoch: 452 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.215017 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 453 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.268500 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 001 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 002 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.262500 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 003 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 004 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.269000 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.307000 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 007 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.295500 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 008 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.258000 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 009 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.265500 | 0.856 sec/iter\n",
      "Epoch: 453 | Batch: 010 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.293515 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 454 | Batch: 000 / 011 | Total loss: 2.593 | Reg loss: 0.038 | Tree loss: 2.593 | Accuracy: 0.267500 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 002 / 011 | Total loss: 2.535 | Reg loss: 0.038 | Tree loss: 2.535 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 003 / 011 | Total loss: 2.481 | Reg loss: 0.038 | Tree loss: 2.481 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 004 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.296000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 005 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 006 / 011 | Total loss: 2.436 | Reg loss: 0.038 | Tree loss: 2.436 | Accuracy: 0.278000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 008 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.245500 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.260000 | 0.856 sec/iter\n",
      "Epoch: 454 | Batch: 010 / 011 | Total loss: 2.357 | Reg loss: 0.038 | Tree loss: 2.357 | Accuracy: 0.259386 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 455 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.265000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 001 / 011 | Total loss: 2.583 | Reg loss: 0.038 | Tree loss: 2.583 | Accuracy: 0.263000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 002 / 011 | Total loss: 2.530 | Reg loss: 0.038 | Tree loss: 2.530 | Accuracy: 0.279000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 004 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.304000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.291000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 006 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.272000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 007 / 011 | Total loss: 2.367 | Reg loss: 0.038 | Tree loss: 2.367 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 008 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.263500 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.258000 | 0.856 sec/iter\n",
      "Epoch: 455 | Batch: 010 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.249147 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 456 | Batch: 000 / 011 | Total loss: 2.592 | Reg loss: 0.038 | Tree loss: 2.592 | Accuracy: 0.254000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 001 / 011 | Total loss: 2.550 | Reg loss: 0.038 | Tree loss: 2.550 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.299500 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 003 / 011 | Total loss: 2.483 | Reg loss: 0.038 | Tree loss: 2.483 | Accuracy: 0.290000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 004 / 011 | Total loss: 2.446 | Reg loss: 0.038 | Tree loss: 2.446 | Accuracy: 0.295000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 005 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 006 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.266500 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 008 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.259000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.251000 | 0.856 sec/iter\n",
      "Epoch: 456 | Batch: 010 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.252560 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 457 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 001 / 011 | Total loss: 2.555 | Reg loss: 0.038 | Tree loss: 2.555 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 002 / 011 | Total loss: 2.521 | Reg loss: 0.038 | Tree loss: 2.521 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.300000 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 005 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.302000 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 006 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 007 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 008 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 009 / 011 | Total loss: 2.379 | Reg loss: 0.038 | Tree loss: 2.379 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 457 | Batch: 010 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.228669 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 458 | Batch: 000 / 011 | Total loss: 2.613 | Reg loss: 0.038 | Tree loss: 2.613 | Accuracy: 0.263000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 001 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 002 / 011 | Total loss: 2.529 | Reg loss: 0.038 | Tree loss: 2.529 | Accuracy: 0.291000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 003 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.298000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 005 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.283500 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.281500 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 007 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.284000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.262000 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.247500 | 0.856 sec/iter\n",
      "Epoch: 458 | Batch: 010 / 011 | Total loss: 2.330 | Reg loss: 0.038 | Tree loss: 2.330 | Accuracy: 0.273038 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 459 | Batch: 000 / 011 | Total loss: 2.578 | Reg loss: 0.038 | Tree loss: 2.578 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 001 / 011 | Total loss: 2.554 | Reg loss: 0.038 | Tree loss: 2.554 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.275000 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 003 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.296500 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 004 / 011 | Total loss: 2.463 | Reg loss: 0.038 | Tree loss: 2.463 | Accuracy: 0.302500 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 005 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.294000 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 007 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.285500 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 008 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.274500 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.257500 | 0.856 sec/iter\n",
      "Epoch: 459 | Batch: 010 / 011 | Total loss: 2.347 | Reg loss: 0.038 | Tree loss: 2.347 | Accuracy: 0.286689 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.265000 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 003 / 011 | Total loss: 2.479 | Reg loss: 0.038 | Tree loss: 2.479 | Accuracy: 0.288000 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 004 / 011 | Total loss: 2.437 | Reg loss: 0.038 | Tree loss: 2.437 | Accuracy: 0.305500 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 005 / 011 | Total loss: 2.430 | Reg loss: 0.038 | Tree loss: 2.430 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 006 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 007 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.283000 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.264500 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 009 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.266000 | 0.856 sec/iter\n",
      "Epoch: 460 | Batch: 010 / 011 | Total loss: 2.300 | Reg loss: 0.038 | Tree loss: 2.300 | Accuracy: 0.286689 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 461 | Batch: 000 / 011 | Total loss: 2.566 | Reg loss: 0.038 | Tree loss: 2.566 | Accuracy: 0.287500 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 002 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.272000 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 003 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.303500 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 004 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.317000 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 005 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.280500 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 006 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.284500 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 007 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 008 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.270500 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 009 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.259000 | 0.856 sec/iter\n",
      "Epoch: 461 | Batch: 010 / 011 | Total loss: 2.361 | Reg loss: 0.038 | Tree loss: 2.361 | Accuracy: 0.276451 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 462 | Batch: 000 / 011 | Total loss: 2.591 | Reg loss: 0.038 | Tree loss: 2.591 | Accuracy: 0.267000 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 001 / 011 | Total loss: 2.559 | Reg loss: 0.038 | Tree loss: 2.559 | Accuracy: 0.266000 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 002 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.306500 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 003 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.304500 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 005 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.301500 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 006 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.280000 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 007 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.268000 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.272500 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 009 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.265500 | 0.856 sec/iter\n",
      "Epoch: 462 | Batch: 010 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.266212 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 463 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.271000 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 001 / 011 | Total loss: 2.543 | Reg loss: 0.038 | Tree loss: 2.543 | Accuracy: 0.285000 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.288500 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 003 / 011 | Total loss: 2.496 | Reg loss: 0.038 | Tree loss: 2.496 | Accuracy: 0.286000 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.286500 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 005 / 011 | Total loss: 2.443 | Reg loss: 0.038 | Tree loss: 2.443 | Accuracy: 0.282000 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 006 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.294500 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.293500 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 008 / 011 | Total loss: 2.398 | Reg loss: 0.038 | Tree loss: 2.398 | Accuracy: 0.276500 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.277000 | 0.856 sec/iter\n",
      "Epoch: 463 | Batch: 010 / 011 | Total loss: 2.350 | Reg loss: 0.038 | Tree loss: 2.350 | Accuracy: 0.269625 | 0.856 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 464 | Batch: 000 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.290500 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 002 / 011 | Total loss: 2.503 | Reg loss: 0.038 | Tree loss: 2.503 | Accuracy: 0.293000 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 003 / 011 | Total loss: 2.494 | Reg loss: 0.038 | Tree loss: 2.494 | Accuracy: 0.301500 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 004 / 011 | Total loss: 2.451 | Reg loss: 0.038 | Tree loss: 2.451 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 005 / 011 | Total loss: 2.416 | Reg loss: 0.038 | Tree loss: 2.416 | Accuracy: 0.285500 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 006 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.292500 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 007 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.272000 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 008 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.273000 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.267500 | 0.856 sec/iter\n",
      "Epoch: 464 | Batch: 010 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.221843 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 465 | Batch: 000 / 011 | Total loss: 2.580 | Reg loss: 0.038 | Tree loss: 2.580 | Accuracy: 0.276000 | 0.856 sec/iter\n",
      "Epoch: 465 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.262500 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.287000 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.295500 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.284500 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 005 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.311500 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 006 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.268500 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 007 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.291000 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.260000 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.258500 | 0.855 sec/iter\n",
      "Epoch: 465 | Batch: 010 / 011 | Total loss: 2.358 | Reg loss: 0.038 | Tree loss: 2.358 | Accuracy: 0.307167 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 466 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 001 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.285000 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 002 / 011 | Total loss: 2.510 | Reg loss: 0.038 | Tree loss: 2.510 | Accuracy: 0.297500 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.274500 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 004 / 011 | Total loss: 2.456 | Reg loss: 0.038 | Tree loss: 2.456 | Accuracy: 0.290000 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 005 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.313500 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 006 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.297000 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 007 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.282500 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.277000 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.260500 | 0.855 sec/iter\n",
      "Epoch: 466 | Batch: 010 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.249147 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 467 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.275500 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 001 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.268000 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 003 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.306500 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.287500 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.293500 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 006 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.287000 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 007 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.283000 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.263000 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 009 / 011 | Total loss: 2.372 | Reg loss: 0.038 | Tree loss: 2.372 | Accuracy: 0.261500 | 0.855 sec/iter\n",
      "Epoch: 467 | Batch: 010 / 011 | Total loss: 2.449 | Reg loss: 0.038 | Tree loss: 2.449 | Accuracy: 0.208191 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 468 | Batch: 000 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.268500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.289000 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.288000 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.287500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 005 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.273000 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 006 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.284500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 007 / 011 | Total loss: 2.418 | Reg loss: 0.038 | Tree loss: 2.418 | Accuracy: 0.292500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 008 / 011 | Total loss: 2.353 | Reg loss: 0.038 | Tree loss: 2.353 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.270500 | 0.855 sec/iter\n",
      "Epoch: 468 | Batch: 010 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.266212 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 469 | Batch: 000 / 011 | Total loss: 2.568 | Reg loss: 0.038 | Tree loss: 2.568 | Accuracy: 0.275000 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.277000 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 003 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.305000 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 004 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.305000 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 005 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.302000 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 006 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 007 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 008 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.256000 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 009 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.248500 | 0.855 sec/iter\n",
      "Epoch: 469 | Batch: 010 / 011 | Total loss: 2.292 | Reg loss: 0.038 | Tree loss: 2.292 | Accuracy: 0.279863 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470 | Batch: 000 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.285500 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 001 / 011 | Total loss: 2.545 | Reg loss: 0.038 | Tree loss: 2.545 | Accuracy: 0.287000 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 002 / 011 | Total loss: 2.537 | Reg loss: 0.038 | Tree loss: 2.537 | Accuracy: 0.296000 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 003 / 011 | Total loss: 2.457 | Reg loss: 0.038 | Tree loss: 2.457 | Accuracy: 0.295000 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 004 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.299000 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 005 / 011 | Total loss: 2.453 | Reg loss: 0.038 | Tree loss: 2.453 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 007 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 008 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.269500 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 009 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.255000 | 0.855 sec/iter\n",
      "Epoch: 470 | Batch: 010 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.225256 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 471 | Batch: 000 / 011 | Total loss: 2.592 | Reg loss: 0.038 | Tree loss: 2.592 | Accuracy: 0.267500 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.271000 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.291000 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.281500 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 004 / 011 | Total loss: 2.428 | Reg loss: 0.038 | Tree loss: 2.428 | Accuracy: 0.292000 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 005 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.276500 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 006 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.284000 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 008 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.279500 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 009 / 011 | Total loss: 2.370 | Reg loss: 0.038 | Tree loss: 2.370 | Accuracy: 0.255500 | 0.855 sec/iter\n",
      "Epoch: 471 | Batch: 010 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.255973 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 472 | Batch: 000 / 011 | Total loss: 2.575 | Reg loss: 0.038 | Tree loss: 2.575 | Accuracy: 0.267000 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 001 / 011 | Total loss: 2.570 | Reg loss: 0.038 | Tree loss: 2.570 | Accuracy: 0.289000 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 002 / 011 | Total loss: 2.533 | Reg loss: 0.038 | Tree loss: 2.533 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.284500 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 004 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.283000 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.290000 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 007 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.286000 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 008 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.264500 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 009 / 011 | Total loss: 2.359 | Reg loss: 0.038 | Tree loss: 2.359 | Accuracy: 0.263500 | 0.855 sec/iter\n",
      "Epoch: 472 | Batch: 010 / 011 | Total loss: 2.393 | Reg loss: 0.038 | Tree loss: 2.393 | Accuracy: 0.238908 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 473 | Batch: 000 / 011 | Total loss: 2.595 | Reg loss: 0.038 | Tree loss: 2.595 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 001 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.269000 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 002 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.281000 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.285000 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.291000 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.291500 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 007 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.267500 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.268500 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 009 / 011 | Total loss: 2.365 | Reg loss: 0.038 | Tree loss: 2.365 | Accuracy: 0.273500 | 0.855 sec/iter\n",
      "Epoch: 473 | Batch: 010 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.232082 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 474 | Batch: 000 / 011 | Total loss: 2.562 | Reg loss: 0.038 | Tree loss: 2.562 | Accuracy: 0.277000 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 001 / 011 | Total loss: 2.573 | Reg loss: 0.038 | Tree loss: 2.573 | Accuracy: 0.264500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 002 / 011 | Total loss: 2.513 | Reg loss: 0.038 | Tree loss: 2.513 | Accuracy: 0.274000 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 003 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.282500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.262500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.285500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 008 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.251500 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 009 / 011 | Total loss: 2.392 | Reg loss: 0.038 | Tree loss: 2.392 | Accuracy: 0.252000 | 0.855 sec/iter\n",
      "Epoch: 474 | Batch: 010 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.249147 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 475 | Batch: 000 / 011 | Total loss: 2.588 | Reg loss: 0.038 | Tree loss: 2.588 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 001 / 011 | Total loss: 2.550 | Reg loss: 0.038 | Tree loss: 2.550 | Accuracy: 0.276500 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.280000 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 003 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.282500 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.276000 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 005 / 011 | Total loss: 2.431 | Reg loss: 0.038 | Tree loss: 2.431 | Accuracy: 0.277500 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.296000 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 007 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.284500 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.265500 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.248000 | 0.855 sec/iter\n",
      "Epoch: 475 | Batch: 010 / 011 | Total loss: 2.340 | Reg loss: 0.038 | Tree loss: 2.340 | Accuracy: 0.273038 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 476 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.277500 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.276000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 002 / 011 | Total loss: 2.551 | Reg loss: 0.038 | Tree loss: 2.551 | Accuracy: 0.270000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 003 / 011 | Total loss: 2.487 | Reg loss: 0.038 | Tree loss: 2.487 | Accuracy: 0.291000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 004 / 011 | Total loss: 2.458 | Reg loss: 0.038 | Tree loss: 2.458 | Accuracy: 0.278000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 005 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 006 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.270000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.283500 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.253000 | 0.855 sec/iter\n",
      "Epoch: 476 | Batch: 010 / 011 | Total loss: 2.328 | Reg loss: 0.038 | Tree loss: 2.328 | Accuracy: 0.262799 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 477 | Batch: 000 / 011 | Total loss: 2.589 | Reg loss: 0.038 | Tree loss: 2.589 | Accuracy: 0.272000 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.301500 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 004 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.288500 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 006 / 011 | Total loss: 2.406 | Reg loss: 0.038 | Tree loss: 2.406 | Accuracy: 0.296000 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.281500 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.280000 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 009 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.261500 | 0.855 sec/iter\n",
      "Epoch: 477 | Batch: 010 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.215017 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 478 | Batch: 000 / 011 | Total loss: 2.592 | Reg loss: 0.038 | Tree loss: 2.592 | Accuracy: 0.272000 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 001 / 011 | Total loss: 2.549 | Reg loss: 0.038 | Tree loss: 2.549 | Accuracy: 0.271500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.265000 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 003 / 011 | Total loss: 2.485 | Reg loss: 0.038 | Tree loss: 2.485 | Accuracy: 0.281500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.305500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 005 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.268500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 006 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.301000 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 007 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.260500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 008 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.271500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 009 / 011 | Total loss: 2.383 | Reg loss: 0.038 | Tree loss: 2.383 | Accuracy: 0.263500 | 0.855 sec/iter\n",
      "Epoch: 478 | Batch: 010 / 011 | Total loss: 2.352 | Reg loss: 0.038 | Tree loss: 2.352 | Accuracy: 0.279863 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 479 | Batch: 000 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.291500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 001 / 011 | Total loss: 2.556 | Reg loss: 0.038 | Tree loss: 2.556 | Accuracy: 0.287500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.299500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 003 / 011 | Total loss: 2.473 | Reg loss: 0.038 | Tree loss: 2.473 | Accuracy: 0.303500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.297500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 005 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.273000 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 006 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.295500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 007 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.264500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.267500 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 009 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.256000 | 0.855 sec/iter\n",
      "Epoch: 479 | Batch: 010 / 011 | Total loss: 2.351 | Reg loss: 0.038 | Tree loss: 2.351 | Accuracy: 0.235495 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480 | Batch: 000 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.268500 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 001 / 011 | Total loss: 2.546 | Reg loss: 0.038 | Tree loss: 2.546 | Accuracy: 0.297000 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 002 / 011 | Total loss: 2.532 | Reg loss: 0.038 | Tree loss: 2.532 | Accuracy: 0.279500 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 003 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.309000 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 004 / 011 | Total loss: 2.454 | Reg loss: 0.038 | Tree loss: 2.454 | Accuracy: 0.295000 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.297500 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.267000 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 007 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 008 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.259500 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 009 / 011 | Total loss: 2.394 | Reg loss: 0.038 | Tree loss: 2.394 | Accuracy: 0.255000 | 0.855 sec/iter\n",
      "Epoch: 480 | Batch: 010 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.269625 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 481 | Batch: 000 / 011 | Total loss: 2.585 | Reg loss: 0.038 | Tree loss: 2.585 | Accuracy: 0.274500 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 001 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.291000 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 002 / 011 | Total loss: 2.518 | Reg loss: 0.038 | Tree loss: 2.518 | Accuracy: 0.267000 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 003 / 011 | Total loss: 2.516 | Reg loss: 0.038 | Tree loss: 2.516 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 004 / 011 | Total loss: 2.459 | Reg loss: 0.038 | Tree loss: 2.459 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 005 / 011 | Total loss: 2.413 | Reg loss: 0.038 | Tree loss: 2.413 | Accuracy: 0.291000 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 006 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.284000 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 007 / 011 | Total loss: 2.435 | Reg loss: 0.038 | Tree loss: 2.435 | Accuracy: 0.270000 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 008 / 011 | Total loss: 2.355 | Reg loss: 0.038 | Tree loss: 2.355 | Accuracy: 0.281000 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 481 | Batch: 010 / 011 | Total loss: 2.341 | Reg loss: 0.038 | Tree loss: 2.341 | Accuracy: 0.252560 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 482 | Batch: 000 / 011 | Total loss: 2.609 | Reg loss: 0.038 | Tree loss: 2.609 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 001 / 011 | Total loss: 2.519 | Reg loss: 0.038 | Tree loss: 2.519 | Accuracy: 0.283000 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 003 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.297000 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 005 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.286000 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 006 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.274500 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.280000 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 009 / 011 | Total loss: 2.371 | Reg loss: 0.038 | Tree loss: 2.371 | Accuracy: 0.267500 | 0.855 sec/iter\n",
      "Epoch: 482 | Batch: 010 / 011 | Total loss: 2.358 | Reg loss: 0.038 | Tree loss: 2.358 | Accuracy: 0.249147 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 483 | Batch: 000 / 011 | Total loss: 2.594 | Reg loss: 0.038 | Tree loss: 2.594 | Accuracy: 0.267000 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 002 / 011 | Total loss: 2.509 | Reg loss: 0.038 | Tree loss: 2.509 | Accuracy: 0.293000 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.302000 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 004 / 011 | Total loss: 2.461 | Reg loss: 0.038 | Tree loss: 2.461 | Accuracy: 0.293000 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 005 / 011 | Total loss: 2.408 | Reg loss: 0.038 | Tree loss: 2.408 | Accuracy: 0.301500 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 006 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 007 / 011 | Total loss: 2.409 | Reg loss: 0.038 | Tree loss: 2.409 | Accuracy: 0.287000 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 008 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 009 / 011 | Total loss: 2.381 | Reg loss: 0.038 | Tree loss: 2.381 | Accuracy: 0.256500 | 0.855 sec/iter\n",
      "Epoch: 483 | Batch: 010 / 011 | Total loss: 2.386 | Reg loss: 0.038 | Tree loss: 2.386 | Accuracy: 0.252560 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 484 | Batch: 000 / 011 | Total loss: 2.582 | Reg loss: 0.038 | Tree loss: 2.582 | Accuracy: 0.292000 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.265500 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 002 / 011 | Total loss: 2.520 | Reg loss: 0.038 | Tree loss: 2.520 | Accuracy: 0.286000 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 003 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.294500 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 004 / 011 | Total loss: 2.447 | Reg loss: 0.038 | Tree loss: 2.447 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 006 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.288000 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 008 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.254000 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 009 / 011 | Total loss: 2.380 | Reg loss: 0.038 | Tree loss: 2.380 | Accuracy: 0.269000 | 0.855 sec/iter\n",
      "Epoch: 484 | Batch: 010 / 011 | Total loss: 2.444 | Reg loss: 0.038 | Tree loss: 2.444 | Accuracy: 0.225256 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 485 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.275500 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 001 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 002 / 011 | Total loss: 2.500 | Reg loss: 0.038 | Tree loss: 2.500 | Accuracy: 0.300000 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 003 / 011 | Total loss: 2.491 | Reg loss: 0.038 | Tree loss: 2.491 | Accuracy: 0.299500 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 004 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.300500 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 005 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.277500 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 006 / 011 | Total loss: 2.432 | Reg loss: 0.038 | Tree loss: 2.432 | Accuracy: 0.279000 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 007 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.279000 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 008 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.272000 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 009 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.246000 | 0.855 sec/iter\n",
      "Epoch: 485 | Batch: 010 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.191126 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 486 | Batch: 000 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.299500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 001 / 011 | Total loss: 2.542 | Reg loss: 0.038 | Tree loss: 2.542 | Accuracy: 0.291500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 002 / 011 | Total loss: 2.526 | Reg loss: 0.038 | Tree loss: 2.526 | Accuracy: 0.282500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 003 / 011 | Total loss: 2.484 | Reg loss: 0.038 | Tree loss: 2.484 | Accuracy: 0.280500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 004 / 011 | Total loss: 2.464 | Reg loss: 0.038 | Tree loss: 2.464 | Accuracy: 0.270000 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 005 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.285500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 006 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.272000 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.291500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 008 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.269000 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.247500 | 0.855 sec/iter\n",
      "Epoch: 486 | Batch: 010 / 011 | Total loss: 2.357 | Reg loss: 0.038 | Tree loss: 2.357 | Accuracy: 0.320819 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 487 | Batch: 000 / 011 | Total loss: 2.590 | Reg loss: 0.038 | Tree loss: 2.590 | Accuracy: 0.258000 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 001 / 011 | Total loss: 2.528 | Reg loss: 0.038 | Tree loss: 2.528 | Accuracy: 0.298500 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 002 / 011 | Total loss: 2.529 | Reg loss: 0.038 | Tree loss: 2.529 | Accuracy: 0.298000 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 003 / 011 | Total loss: 2.503 | Reg loss: 0.038 | Tree loss: 2.503 | Accuracy: 0.278000 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 004 / 011 | Total loss: 2.455 | Reg loss: 0.038 | Tree loss: 2.455 | Accuracy: 0.279500 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 005 / 011 | Total loss: 2.448 | Reg loss: 0.038 | Tree loss: 2.448 | Accuracy: 0.279000 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 006 / 011 | Total loss: 2.407 | Reg loss: 0.038 | Tree loss: 2.407 | Accuracy: 0.293000 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 007 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.283500 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 008 / 011 | Total loss: 2.382 | Reg loss: 0.038 | Tree loss: 2.382 | Accuracy: 0.288500 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 009 / 011 | Total loss: 2.368 | Reg loss: 0.038 | Tree loss: 2.368 | Accuracy: 0.267000 | 0.855 sec/iter\n",
      "Epoch: 487 | Batch: 010 / 011 | Total loss: 2.369 | Reg loss: 0.038 | Tree loss: 2.369 | Accuracy: 0.286689 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 488 | Batch: 000 / 011 | Total loss: 2.558 | Reg loss: 0.038 | Tree loss: 2.558 | Accuracy: 0.287500 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 001 / 011 | Total loss: 2.536 | Reg loss: 0.038 | Tree loss: 2.536 | Accuracy: 0.279000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 002 / 011 | Total loss: 2.512 | Reg loss: 0.038 | Tree loss: 2.512 | Accuracy: 0.304000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 003 / 011 | Total loss: 2.507 | Reg loss: 0.038 | Tree loss: 2.507 | Accuracy: 0.278500 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 004 / 011 | Total loss: 2.465 | Reg loss: 0.038 | Tree loss: 2.465 | Accuracy: 0.283000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 005 / 011 | Total loss: 2.438 | Reg loss: 0.038 | Tree loss: 2.438 | Accuracy: 0.290000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 006 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.285000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 007 / 011 | Total loss: 2.405 | Reg loss: 0.038 | Tree loss: 2.405 | Accuracy: 0.277000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 008 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.278000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 009 / 011 | Total loss: 2.365 | Reg loss: 0.038 | Tree loss: 2.365 | Accuracy: 0.260000 | 0.855 sec/iter\n",
      "Epoch: 488 | Batch: 010 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.279863 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 489 | Batch: 000 / 011 | Total loss: 2.581 | Reg loss: 0.038 | Tree loss: 2.581 | Accuracy: 0.275500 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 001 / 011 | Total loss: 2.557 | Reg loss: 0.038 | Tree loss: 2.557 | Accuracy: 0.266500 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 002 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.301500 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 003 / 011 | Total loss: 2.480 | Reg loss: 0.038 | Tree loss: 2.480 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 004 / 011 | Total loss: 2.452 | Reg loss: 0.038 | Tree loss: 2.452 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 005 / 011 | Total loss: 2.395 | Reg loss: 0.038 | Tree loss: 2.395 | Accuracy: 0.299000 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 006 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.281500 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 007 / 011 | Total loss: 2.411 | Reg loss: 0.038 | Tree loss: 2.411 | Accuracy: 0.283500 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 008 / 011 | Total loss: 2.420 | Reg loss: 0.038 | Tree loss: 2.420 | Accuracy: 0.281000 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 009 / 011 | Total loss: 2.403 | Reg loss: 0.038 | Tree loss: 2.403 | Accuracy: 0.249500 | 0.855 sec/iter\n",
      "Epoch: 489 | Batch: 010 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.235495 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 490 | Batch: 000 / 011 | Total loss: 2.592 | Reg loss: 0.038 | Tree loss: 2.592 | Accuracy: 0.289000 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 002 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.293000 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 003 / 011 | Total loss: 2.488 | Reg loss: 0.038 | Tree loss: 2.488 | Accuracy: 0.290000 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.281000 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 005 / 011 | Total loss: 2.439 | Reg loss: 0.038 | Tree loss: 2.439 | Accuracy: 0.283000 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 006 / 011 | Total loss: 2.378 | Reg loss: 0.038 | Tree loss: 2.378 | Accuracy: 0.299500 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.274500 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 008 / 011 | Total loss: 2.391 | Reg loss: 0.038 | Tree loss: 2.391 | Accuracy: 0.259500 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 009 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.258500 | 0.855 sec/iter\n",
      "Epoch: 490 | Batch: 010 / 011 | Total loss: 2.350 | Reg loss: 0.038 | Tree loss: 2.350 | Accuracy: 0.286689 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 491 | Batch: 000 / 011 | Total loss: 2.569 | Reg loss: 0.038 | Tree loss: 2.569 | Accuracy: 0.269000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 001 / 011 | Total loss: 2.524 | Reg loss: 0.038 | Tree loss: 2.524 | Accuracy: 0.302000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 002 / 011 | Total loss: 2.525 | Reg loss: 0.038 | Tree loss: 2.525 | Accuracy: 0.305000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 003 / 011 | Total loss: 2.486 | Reg loss: 0.038 | Tree loss: 2.486 | Accuracy: 0.285000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.277000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 005 / 011 | Total loss: 2.417 | Reg loss: 0.038 | Tree loss: 2.417 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 006 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.286000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 007 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.272000 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.269500 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 009 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.268500 | 0.855 sec/iter\n",
      "Epoch: 491 | Batch: 010 / 011 | Total loss: 2.349 | Reg loss: 0.038 | Tree loss: 2.349 | Accuracy: 0.232082 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 492 | Batch: 000 / 011 | Total loss: 2.571 | Reg loss: 0.038 | Tree loss: 2.571 | Accuracy: 0.292500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 001 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.284500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 002 / 011 | Total loss: 2.522 | Reg loss: 0.038 | Tree loss: 2.522 | Accuracy: 0.290500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 003 / 011 | Total loss: 2.501 | Reg loss: 0.038 | Tree loss: 2.501 | Accuracy: 0.281500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 004 / 011 | Total loss: 2.441 | Reg loss: 0.038 | Tree loss: 2.441 | Accuracy: 0.296500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 005 / 011 | Total loss: 2.419 | Reg loss: 0.038 | Tree loss: 2.419 | Accuracy: 0.301000 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 007 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.275500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.264500 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 009 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.263000 | 0.855 sec/iter\n",
      "Epoch: 492 | Batch: 010 / 011 | Total loss: 2.474 | Reg loss: 0.038 | Tree loss: 2.474 | Accuracy: 0.204778 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 493 | Batch: 000 / 011 | Total loss: 2.584 | Reg loss: 0.038 | Tree loss: 2.584 | Accuracy: 0.279000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.287000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 002 / 011 | Total loss: 2.531 | Reg loss: 0.038 | Tree loss: 2.531 | Accuracy: 0.274500 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 003 / 011 | Total loss: 2.471 | Reg loss: 0.038 | Tree loss: 2.471 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 004 / 011 | Total loss: 2.478 | Reg loss: 0.038 | Tree loss: 2.478 | Accuracy: 0.292000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 005 / 011 | Total loss: 2.434 | Reg loss: 0.038 | Tree loss: 2.434 | Accuracy: 0.298500 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 006 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.297000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.284000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 008 / 011 | Total loss: 2.401 | Reg loss: 0.038 | Tree loss: 2.401 | Accuracy: 0.268000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 009 / 011 | Total loss: 2.384 | Reg loss: 0.038 | Tree loss: 2.384 | Accuracy: 0.271000 | 0.855 sec/iter\n",
      "Epoch: 493 | Batch: 010 / 011 | Total loss: 2.321 | Reg loss: 0.038 | Tree loss: 2.321 | Accuracy: 0.252560 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 494 | Batch: 000 / 011 | Total loss: 2.579 | Reg loss: 0.038 | Tree loss: 2.579 | Accuracy: 0.276000 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 001 / 011 | Total loss: 2.553 | Reg loss: 0.038 | Tree loss: 2.553 | Accuracy: 0.290500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 002 / 011 | Total loss: 2.511 | Reg loss: 0.038 | Tree loss: 2.511 | Accuracy: 0.305500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 003 / 011 | Total loss: 2.489 | Reg loss: 0.038 | Tree loss: 2.489 | Accuracy: 0.278000 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 004 / 011 | Total loss: 2.467 | Reg loss: 0.038 | Tree loss: 2.467 | Accuracy: 0.306500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 006 / 011 | Total loss: 2.375 | Reg loss: 0.038 | Tree loss: 2.375 | Accuracy: 0.298000 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 007 / 011 | Total loss: 2.387 | Reg loss: 0.038 | Tree loss: 2.387 | Accuracy: 0.275500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 008 / 011 | Total loss: 2.390 | Reg loss: 0.038 | Tree loss: 2.390 | Accuracy: 0.259500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 009 / 011 | Total loss: 2.421 | Reg loss: 0.038 | Tree loss: 2.421 | Accuracy: 0.248500 | 0.855 sec/iter\n",
      "Epoch: 494 | Batch: 010 / 011 | Total loss: 2.426 | Reg loss: 0.038 | Tree loss: 2.426 | Accuracy: 0.232082 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 495 | Batch: 000 / 011 | Total loss: 2.572 | Reg loss: 0.038 | Tree loss: 2.572 | Accuracy: 0.287500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 001 / 011 | Total loss: 2.564 | Reg loss: 0.038 | Tree loss: 2.564 | Accuracy: 0.264500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 002 / 011 | Total loss: 2.523 | Reg loss: 0.038 | Tree loss: 2.523 | Accuracy: 0.282500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 003 / 011 | Total loss: 2.498 | Reg loss: 0.038 | Tree loss: 2.498 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 004 / 011 | Total loss: 2.440 | Reg loss: 0.038 | Tree loss: 2.440 | Accuracy: 0.296000 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 005 / 011 | Total loss: 2.445 | Reg loss: 0.038 | Tree loss: 2.445 | Accuracy: 0.284500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 006 / 011 | Total loss: 2.385 | Reg loss: 0.038 | Tree loss: 2.385 | Accuracy: 0.295500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 007 / 011 | Total loss: 2.400 | Reg loss: 0.038 | Tree loss: 2.400 | Accuracy: 0.281000 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 008 / 011 | Total loss: 2.389 | Reg loss: 0.038 | Tree loss: 2.389 | Accuracy: 0.279500 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 009 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.247000 | 0.855 sec/iter\n",
      "Epoch: 495 | Batch: 010 / 011 | Total loss: 2.353 | Reg loss: 0.038 | Tree loss: 2.353 | Accuracy: 0.290102 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 496 | Batch: 000 / 011 | Total loss: 2.611 | Reg loss: 0.038 | Tree loss: 2.611 | Accuracy: 0.265500 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 001 / 011 | Total loss: 2.560 | Reg loss: 0.038 | Tree loss: 2.560 | Accuracy: 0.256000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 002 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.292000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 003 / 011 | Total loss: 2.469 | Reg loss: 0.038 | Tree loss: 2.469 | Accuracy: 0.288500 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 004 / 011 | Total loss: 2.468 | Reg loss: 0.038 | Tree loss: 2.468 | Accuracy: 0.294000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 005 / 011 | Total loss: 2.433 | Reg loss: 0.038 | Tree loss: 2.433 | Accuracy: 0.283500 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 006 / 011 | Total loss: 2.422 | Reg loss: 0.038 | Tree loss: 2.422 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 007 / 011 | Total loss: 2.414 | Reg loss: 0.038 | Tree loss: 2.414 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 008 / 011 | Total loss: 2.388 | Reg loss: 0.038 | Tree loss: 2.388 | Accuracy: 0.276000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 009 / 011 | Total loss: 2.355 | Reg loss: 0.038 | Tree loss: 2.355 | Accuracy: 0.253000 | 0.855 sec/iter\n",
      "Epoch: 496 | Batch: 010 / 011 | Total loss: 2.360 | Reg loss: 0.038 | Tree loss: 2.360 | Accuracy: 0.245734 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 497 | Batch: 000 / 011 | Total loss: 2.597 | Reg loss: 0.038 | Tree loss: 2.597 | Accuracy: 0.265000 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 002 / 011 | Total loss: 2.515 | Reg loss: 0.038 | Tree loss: 2.515 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 003 / 011 | Total loss: 2.497 | Reg loss: 0.038 | Tree loss: 2.497 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 004 / 011 | Total loss: 2.472 | Reg loss: 0.038 | Tree loss: 2.472 | Accuracy: 0.286000 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 005 / 011 | Total loss: 2.427 | Reg loss: 0.038 | Tree loss: 2.427 | Accuracy: 0.289000 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 006 / 011 | Total loss: 2.424 | Reg loss: 0.038 | Tree loss: 2.424 | Accuracy: 0.276500 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 007 / 011 | Total loss: 2.376 | Reg loss: 0.038 | Tree loss: 2.376 | Accuracy: 0.300500 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 008 / 011 | Total loss: 2.377 | Reg loss: 0.038 | Tree loss: 2.377 | Accuracy: 0.282000 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 009 / 011 | Total loss: 2.396 | Reg loss: 0.038 | Tree loss: 2.396 | Accuracy: 0.254500 | 0.855 sec/iter\n",
      "Epoch: 497 | Batch: 010 / 011 | Total loss: 2.355 | Reg loss: 0.038 | Tree loss: 2.355 | Accuracy: 0.262799 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 498 | Batch: 000 / 011 | Total loss: 2.598 | Reg loss: 0.038 | Tree loss: 2.598 | Accuracy: 0.274000 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 001 / 011 | Total loss: 2.561 | Reg loss: 0.038 | Tree loss: 2.561 | Accuracy: 0.271000 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 002 / 011 | Total loss: 2.490 | Reg loss: 0.038 | Tree loss: 2.490 | Accuracy: 0.283500 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 003 / 011 | Total loss: 2.503 | Reg loss: 0.038 | Tree loss: 2.503 | Accuracy: 0.293500 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 004 / 011 | Total loss: 2.475 | Reg loss: 0.038 | Tree loss: 2.475 | Accuracy: 0.289500 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 005 / 011 | Total loss: 2.404 | Reg loss: 0.038 | Tree loss: 2.404 | Accuracy: 0.300000 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 006 / 011 | Total loss: 2.415 | Reg loss: 0.038 | Tree loss: 2.415 | Accuracy: 0.290500 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 007 / 011 | Total loss: 2.399 | Reg loss: 0.038 | Tree loss: 2.399 | Accuracy: 0.277500 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 008 / 011 | Total loss: 2.402 | Reg loss: 0.038 | Tree loss: 2.402 | Accuracy: 0.276500 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 009 / 011 | Total loss: 2.373 | Reg loss: 0.038 | Tree loss: 2.373 | Accuracy: 0.246000 | 0.855 sec/iter\n",
      "Epoch: 498 | Batch: 010 / 011 | Total loss: 2.425 | Reg loss: 0.038 | Tree loss: 2.425 | Accuracy: 0.232082 | 0.855 sec/iter\n",
      "Average sparseness: 0.9723756906077345\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "layer 7: 0.9723756906077345\n",
      "layer 8: 0.9723756906077345\n",
      "Epoch: 499 | Batch: 000 / 011 | Total loss: 2.562 | Reg loss: 0.038 | Tree loss: 2.562 | Accuracy: 0.274500 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 001 / 011 | Total loss: 2.548 | Reg loss: 0.038 | Tree loss: 2.548 | Accuracy: 0.297500 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 002 / 011 | Total loss: 2.540 | Reg loss: 0.038 | Tree loss: 2.540 | Accuracy: 0.285500 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 003 / 011 | Total loss: 2.493 | Reg loss: 0.038 | Tree loss: 2.493 | Accuracy: 0.293000 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 004 / 011 | Total loss: 2.450 | Reg loss: 0.038 | Tree loss: 2.450 | Accuracy: 0.288500 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 005 / 011 | Total loss: 2.423 | Reg loss: 0.038 | Tree loss: 2.423 | Accuracy: 0.286500 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 006 / 011 | Total loss: 2.410 | Reg loss: 0.038 | Tree loss: 2.410 | Accuracy: 0.285500 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 007 / 011 | Total loss: 2.397 | Reg loss: 0.038 | Tree loss: 2.397 | Accuracy: 0.299000 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 008 / 011 | Total loss: 2.412 | Reg loss: 0.038 | Tree loss: 2.412 | Accuracy: 0.274000 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 009 / 011 | Total loss: 2.374 | Reg loss: 0.038 | Tree loss: 2.374 | Accuracy: 0.278000 | 0.855 sec/iter\n",
      "Epoch: 499 | Batch: 010 / 011 | Total loss: 2.460 | Reg loss: 0.038 | Tree loss: 2.460 | Accuracy: 0.194539 | 0.855 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 8.711206896551724\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 232\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'MLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "424\n",
      "============== Pattern 5 ==============\n",
      "251\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "68\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "16\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "============== Pattern 19 ==============\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "============== Pattern 25 ==============\n",
      "============== Pattern 26 ==============\n",
      "============== Pattern 27 ==============\n",
      "============== Pattern 28 ==============\n",
      "============== Pattern 29 ==============\n",
      "============== Pattern 30 ==============\n",
      "============== Pattern 31 ==============\n",
      "============== Pattern 32 ==============\n",
      "============== Pattern 33 ==============\n",
      "============== Pattern 34 ==============\n",
      "============== Pattern 35 ==============\n",
      "============== Pattern 36 ==============\n",
      "============== Pattern 37 ==============\n",
      "============== Pattern 38 ==============\n",
      "============== Pattern 39 ==============\n",
      "============== Pattern 40 ==============\n",
      "============== Pattern 41 ==============\n",
      "============== Pattern 42 ==============\n",
      "============== Pattern 43 ==============\n",
      "============== Pattern 44 ==============\n",
      "============== Pattern 45 ==============\n",
      "============== Pattern 46 ==============\n",
      "============== Pattern 47 ==============\n",
      "============== Pattern 48 ==============\n",
      "============== Pattern 49 ==============\n",
      "============== Pattern 50 ==============\n",
      "============== Pattern 51 ==============\n",
      "============== Pattern 52 ==============\n",
      "============== Pattern 53 ==============\n",
      "============== Pattern 54 ==============\n",
      "============== Pattern 55 ==============\n",
      "============== Pattern 56 ==============\n",
      "============== Pattern 57 ==============\n",
      "============== Pattern 58 ==============\n",
      "============== Pattern 59 ==============\n",
      "16465\n",
      "============== Pattern 60 ==============\n",
      "============== Pattern 61 ==============\n",
      "============== Pattern 62 ==============\n",
      "============== Pattern 63 ==============\n",
      "============== Pattern 64 ==============\n",
      "============== Pattern 65 ==============\n",
      "============== Pattern 66 ==============\n",
      "============== Pattern 67 ==============\n",
      "============== Pattern 68 ==============\n",
      "============== Pattern 69 ==============\n",
      "============== Pattern 70 ==============\n",
      "============== Pattern 71 ==============\n",
      "============== Pattern 72 ==============\n",
      "============== Pattern 73 ==============\n",
      "============== Pattern 74 ==============\n",
      "============== Pattern 75 ==============\n",
      "============== Pattern 76 ==============\n",
      "============== Pattern 77 ==============\n",
      "============== Pattern 78 ==============\n",
      "============== Pattern 79 ==============\n",
      "============== Pattern 80 ==============\n",
      "============== Pattern 81 ==============\n",
      "============== Pattern 82 ==============\n",
      "============== Pattern 83 ==============\n",
      "============== Pattern 84 ==============\n",
      "============== Pattern 85 ==============\n",
      "============== Pattern 86 ==============\n",
      "============== Pattern 87 ==============\n",
      "============== Pattern 88 ==============\n",
      "============== Pattern 89 ==============\n",
      "============== Pattern 90 ==============\n",
      "============== Pattern 91 ==============\n",
      "============== Pattern 92 ==============\n",
      "============== Pattern 93 ==============\n",
      "============== Pattern 94 ==============\n",
      "============== Pattern 95 ==============\n",
      "============== Pattern 96 ==============\n",
      "============== Pattern 97 ==============\n",
      "============== Pattern 98 ==============\n",
      "============== Pattern 99 ==============\n",
      "============== Pattern 100 ==============\n",
      "============== Pattern 101 ==============\n",
      "============== Pattern 102 ==============\n",
      "============== Pattern 103 ==============\n",
      "============== Pattern 104 ==============\n",
      "============== Pattern 105 ==============\n",
      "============== Pattern 106 ==============\n",
      "============== Pattern 107 ==============\n",
      "============== Pattern 108 ==============\n",
      "============== Pattern 109 ==============\n",
      "============== Pattern 110 ==============\n",
      "============== Pattern 111 ==============\n",
      "============== Pattern 112 ==============\n",
      "============== Pattern 113 ==============\n",
      "============== Pattern 114 ==============\n",
      "============== Pattern 115 ==============\n",
      "============== Pattern 116 ==============\n",
      "============== Pattern 117 ==============\n",
      "============== Pattern 118 ==============\n",
      "============== Pattern 119 ==============\n",
      "============== Pattern 120 ==============\n",
      "============== Pattern 121 ==============\n",
      "============== Pattern 122 ==============\n",
      "============== Pattern 123 ==============\n",
      "============== Pattern 124 ==============\n",
      "============== Pattern 125 ==============\n",
      "============== Pattern 126 ==============\n",
      "============== Pattern 127 ==============\n",
      "============== Pattern 128 ==============\n",
      "============== Pattern 129 ==============\n",
      "============== Pattern 130 ==============\n",
      "============== Pattern 131 ==============\n",
      "============== Pattern 132 ==============\n",
      "============== Pattern 133 ==============\n",
      "============== Pattern 134 ==============\n",
      "============== Pattern 135 ==============\n",
      "============== Pattern 136 ==============\n",
      "============== Pattern 137 ==============\n",
      "============== Pattern 138 ==============\n",
      "============== Pattern 139 ==============\n",
      "============== Pattern 140 ==============\n",
      "============== Pattern 141 ==============\n",
      "============== Pattern 142 ==============\n",
      "============== Pattern 143 ==============\n",
      "============== Pattern 144 ==============\n",
      "============== Pattern 145 ==============\n",
      "============== Pattern 146 ==============\n",
      "============== Pattern 147 ==============\n",
      "============== Pattern 148 ==============\n",
      "============== Pattern 149 ==============\n",
      "============== Pattern 150 ==============\n",
      "============== Pattern 151 ==============\n",
      "============== Pattern 152 ==============\n",
      "============== Pattern 153 ==============\n",
      "============== Pattern 154 ==============\n",
      "============== Pattern 155 ==============\n",
      "============== Pattern 156 ==============\n",
      "============== Pattern 157 ==============\n",
      "============== Pattern 158 ==============\n",
      "============== Pattern 159 ==============\n",
      "============== Pattern 160 ==============\n",
      "============== Pattern 161 ==============\n",
      "============== Pattern 162 ==============\n",
      "============== Pattern 163 ==============\n",
      "============== Pattern 164 ==============\n",
      "============== Pattern 165 ==============\n",
      "============== Pattern 166 ==============\n",
      "============== Pattern 167 ==============\n",
      "============== Pattern 168 ==============\n",
      "============== Pattern 169 ==============\n",
      "============== Pattern 170 ==============\n",
      "============== Pattern 171 ==============\n",
      "============== Pattern 172 ==============\n",
      "============== Pattern 173 ==============\n",
      "============== Pattern 174 ==============\n",
      "============== Pattern 175 ==============\n",
      "============== Pattern 176 ==============\n",
      "============== Pattern 177 ==============\n",
      "============== Pattern 178 ==============\n",
      "============== Pattern 179 ==============\n",
      "============== Pattern 180 ==============\n",
      "============== Pattern 181 ==============\n",
      "============== Pattern 182 ==============\n",
      "============== Pattern 183 ==============\n",
      "============== Pattern 184 ==============\n",
      "============== Pattern 185 ==============\n",
      "============== Pattern 186 ==============\n",
      "============== Pattern 187 ==============\n",
      "============== Pattern 188 ==============\n",
      "============== Pattern 189 ==============\n",
      "============== Pattern 190 ==============\n",
      "============== Pattern 191 ==============\n",
      "============== Pattern 192 ==============\n",
      "============== Pattern 193 ==============\n",
      "============== Pattern 194 ==============\n",
      "============== Pattern 195 ==============\n",
      "============== Pattern 196 ==============\n",
      "============== Pattern 197 ==============\n",
      "============== Pattern 198 ==============\n",
      "3069\n",
      "============== Pattern 199 ==============\n",
      "============== Pattern 200 ==============\n",
      "============== Pattern 201 ==============\n",
      "============== Pattern 202 ==============\n",
      "============== Pattern 203 ==============\n",
      "============== Pattern 204 ==============\n",
      "============== Pattern 205 ==============\n",
      "============== Pattern 206 ==============\n",
      "============== Pattern 207 ==============\n",
      "============== Pattern 208 ==============\n",
      "============== Pattern 209 ==============\n",
      "============== Pattern 210 ==============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 211 ==============\n",
      "============== Pattern 212 ==============\n",
      "============== Pattern 213 ==============\n",
      "============== Pattern 214 ==============\n",
      "============== Pattern 215 ==============\n",
      "============== Pattern 216 ==============\n",
      "============== Pattern 217 ==============\n",
      "============== Pattern 218 ==============\n",
      "============== Pattern 219 ==============\n",
      "============== Pattern 220 ==============\n",
      "============== Pattern 221 ==============\n",
      "============== Pattern 222 ==============\n",
      "============== Pattern 223 ==============\n",
      "============== Pattern 224 ==============\n",
      "============== Pattern 225 ==============\n",
      "============== Pattern 226 ==============\n",
      "============== Pattern 227 ==============\n",
      "============== Pattern 228 ==============\n",
      "============== Pattern 229 ==============\n",
      "============== Pattern 230 ==============\n",
      "============== Pattern 231 ==============\n",
      "============== Pattern 232 ==============\n",
      "Average comprehensibility: 83.96551724137932\n",
      "std comprehensibility: 13.367440522095908\n",
      "var comprehensibility: 178.6884661117717\n",
      "minimum comprehensibility: 30\n",
      "maximum comprehensibility: 98\n"
     ]
    }
   ],
   "source": [
    "signal_names = dataset.dataset.all_signals\n",
    "normalizers = torch.tensor([])\n",
    "attr_names = []\n",
    "for signal_name in signal_names:\n",
    "    attr_names += [f\"T{i}.{signal_name}\" for i in range(sampled.shape[-1])]\n",
    "    sensor_norm = torch.tensor([torch.tensor(dataset.dataset.sensor_maxs[signal_name]) for _ in range(sampled.shape[-1])])\n",
    "    normalizers = torch.cat([normalizers, sensor_norm])\n",
    "    \n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    for cond in conds:\n",
    "        cond.weights = cond.weights / normalizers\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
