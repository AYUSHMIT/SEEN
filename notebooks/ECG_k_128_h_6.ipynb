{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128\n",
    "tree_depth = 6\n",
    "batch_size = 512\n",
    "device = 'cpu'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.629314422607422 | KNN Loss: 5.94550085067749 | CLS Loss: 1.6838135719299316\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 6.246893882751465 | KNN Loss: 5.410148620605469 | CLS Loss: 0.8367450833320618\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 5.863901138305664 | KNN Loss: 5.224198341369629 | CLS Loss: 0.6397028565406799\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 5.8153977394104 | KNN Loss: 5.172204494476318 | CLS Loss: 0.6431933641433716\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 5.770508289337158 | KNN Loss: 5.207658290863037 | CLS Loss: 0.5628498792648315\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 5.6319355964660645 | KNN Loss: 5.1199951171875 | CLS Loss: 0.5119404792785645\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 5.606156826019287 | KNN Loss: 5.101445198059082 | CLS Loss: 0.5047116279602051\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 5.439274787902832 | KNN Loss: 5.02860164642334 | CLS Loss: 0.41067299246788025\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 5.412502765655518 | KNN Loss: 4.992825984954834 | CLS Loss: 0.41967689990997314\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 5.4178361892700195 | KNN Loss: 5.014838695526123 | CLS Loss: 0.4029977023601532\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 5.3911452293396 | KNN Loss: 5.007970809936523 | CLS Loss: 0.3831743896007538\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 5.435069561004639 | KNN Loss: 5.0570759773254395 | CLS Loss: 0.3779934048652649\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 5.4486212730407715 | KNN Loss: 5.016741752624512 | CLS Loss: 0.43187955021858215\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 5.297370433807373 | KNN Loss: 5.0077080726623535 | CLS Loss: 0.28966233134269714\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 5.448065280914307 | KNN Loss: 4.993860244750977 | CLS Loss: 0.4542049765586853\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 5.291629314422607 | KNN Loss: 4.972582817077637 | CLS Loss: 0.3190464377403259\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 5.291538238525391 | KNN Loss: 4.942795753479004 | CLS Loss: 0.3487425446510315\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 5.308398723602295 | KNN Loss: 4.97019624710083 | CLS Loss: 0.3382023870944977\n",
      "Epoch: 001, Loss: 5.6004, Train: 0.9086, Valid: 0.9089, Best: 0.9089\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 5.319389343261719 | KNN Loss: 4.993338584899902 | CLS Loss: 0.32605087757110596\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 5.24029016494751 | KNN Loss: 4.975978851318359 | CLS Loss: 0.2643115222454071\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 5.30033540725708 | KNN Loss: 4.999297142028809 | CLS Loss: 0.3010384738445282\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 5.2519073486328125 | KNN Loss: 4.981825351715088 | CLS Loss: 0.2700822353363037\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 5.219751358032227 | KNN Loss: 4.943045139312744 | CLS Loss: 0.27670618891716003\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 5.2284674644470215 | KNN Loss: 4.9481329917907715 | CLS Loss: 0.2803342938423157\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 5.307142734527588 | KNN Loss: 5.008267402648926 | CLS Loss: 0.2988751232624054\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 5.2461018562316895 | KNN Loss: 4.966877460479736 | CLS Loss: 0.2792242169380188\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 5.098645210266113 | KNN Loss: 4.913054466247559 | CLS Loss: 0.1855909526348114\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 5.257870674133301 | KNN Loss: 4.950981140136719 | CLS Loss: 0.30688947439193726\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 5.1023664474487305 | KNN Loss: 4.930932521820068 | CLS Loss: 0.1714337319135666\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 5.1139092445373535 | KNN Loss: 4.892019748687744 | CLS Loss: 0.22188930213451385\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 5.073039531707764 | KNN Loss: 4.90691614151001 | CLS Loss: 0.16612346470355988\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 5.060037612915039 | KNN Loss: 4.880424976348877 | CLS Loss: 0.17961283028125763\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 5.159516334533691 | KNN Loss: 4.891191005706787 | CLS Loss: 0.2683253288269043\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 5.071602821350098 | KNN Loss: 4.865852355957031 | CLS Loss: 0.20575052499771118\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 5.150633335113525 | KNN Loss: 4.90688943862915 | CLS Loss: 0.24374370276927948\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 5.12094783782959 | KNN Loss: 4.912939548492432 | CLS Loss: 0.20800839364528656\n",
      "Epoch: 002, Loss: 5.1800, Train: 0.9579, Valid: 0.9577, Best: 0.9577\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 5.125831604003906 | KNN Loss: 4.916943550109863 | CLS Loss: 0.20888786017894745\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 5.05506706237793 | KNN Loss: 4.889299392700195 | CLS Loss: 0.16576746106147766\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 5.054830551147461 | KNN Loss: 4.877464771270752 | CLS Loss: 0.1773659735918045\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 5.075644493103027 | KNN Loss: 4.898313999176025 | CLS Loss: 0.17733031511306763\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 5.0935540199279785 | KNN Loss: 4.910432815551758 | CLS Loss: 0.1831212192773819\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 5.0087151527404785 | KNN Loss: 4.85903263092041 | CLS Loss: 0.14968232810497284\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 5.038716793060303 | KNN Loss: 4.867237567901611 | CLS Loss: 0.17147919535636902\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 5.043726444244385 | KNN Loss: 4.868474960327148 | CLS Loss: 0.17525160312652588\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 4.976068019866943 | KNN Loss: 4.841333866119385 | CLS Loss: 0.13473433256149292\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 4.950151443481445 | KNN Loss: 4.842283248901367 | CLS Loss: 0.10786804556846619\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 5.049882411956787 | KNN Loss: 4.900733947753906 | CLS Loss: 0.1491485983133316\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 5.08500337600708 | KNN Loss: 4.916773796081543 | CLS Loss: 0.16822946071624756\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 5.031613826751709 | KNN Loss: 4.81339693069458 | CLS Loss: 0.21821710467338562\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 5.032135486602783 | KNN Loss: 4.873656749725342 | CLS Loss: 0.15847867727279663\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 5.0201640129089355 | KNN Loss: 4.873724460601807 | CLS Loss: 0.14643941819667816\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 5.033610820770264 | KNN Loss: 4.828193664550781 | CLS Loss: 0.20541709661483765\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 4.976644992828369 | KNN Loss: 4.847470283508301 | CLS Loss: 0.12917454540729523\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 5.116942405700684 | KNN Loss: 4.879043102264404 | CLS Loss: 0.23789933323860168\n",
      "Epoch: 003, Loss: 5.0458, Train: 0.9656, Valid: 0.9634, Best: 0.9634\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 4.9542012214660645 | KNN Loss: 4.841769218444824 | CLS Loss: 0.11243197321891785\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 5.01666259765625 | KNN Loss: 4.862705230712891 | CLS Loss: 0.1539575308561325\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 4.949807643890381 | KNN Loss: 4.809370994567871 | CLS Loss: 0.14043648540973663\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 5.097414493560791 | KNN Loss: 4.881554126739502 | CLS Loss: 0.21586036682128906\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 5.0375566482543945 | KNN Loss: 4.898980140686035 | CLS Loss: 0.1385764628648758\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 4.961668014526367 | KNN Loss: 4.82831335067749 | CLS Loss: 0.13335458934307098\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 5.041530609130859 | KNN Loss: 4.880289554595947 | CLS Loss: 0.16124123334884644\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 4.990079402923584 | KNN Loss: 4.836967468261719 | CLS Loss: 0.15311174094676971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 5.045559406280518 | KNN Loss: 4.834207057952881 | CLS Loss: 0.21135224401950836\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 4.956061840057373 | KNN Loss: 4.874513149261475 | CLS Loss: 0.08154855668544769\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 5.0474443435668945 | KNN Loss: 4.875492095947266 | CLS Loss: 0.17195230722427368\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 4.977890968322754 | KNN Loss: 4.8427324295043945 | CLS Loss: 0.13515834510326385\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 5.003618240356445 | KNN Loss: 4.8549323081970215 | CLS Loss: 0.14868596196174622\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 4.912004470825195 | KNN Loss: 4.81768798828125 | CLS Loss: 0.09431671351194382\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 4.937765598297119 | KNN Loss: 4.827059268951416 | CLS Loss: 0.11070647090673447\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 4.955239772796631 | KNN Loss: 4.8446946144104 | CLS Loss: 0.11054526269435883\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 4.920965194702148 | KNN Loss: 4.835570335388184 | CLS Loss: 0.08539484441280365\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 5.016929626464844 | KNN Loss: 4.890570640563965 | CLS Loss: 0.1263587921857834\n",
      "Epoch: 004, Loss: 4.9930, Train: 0.9678, Valid: 0.9657, Best: 0.9657\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 4.9213690757751465 | KNN Loss: 4.807292461395264 | CLS Loss: 0.11407681554555893\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 4.976309299468994 | KNN Loss: 4.84520959854126 | CLS Loss: 0.1310998797416687\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 4.991133213043213 | KNN Loss: 4.891664028167725 | CLS Loss: 0.09946904331445694\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 4.945891380310059 | KNN Loss: 4.864361763000488 | CLS Loss: 0.08152975142002106\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 4.887507438659668 | KNN Loss: 4.788697242736816 | CLS Loss: 0.09881006926298141\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 4.987021446228027 | KNN Loss: 4.87666130065918 | CLS Loss: 0.11036022752523422\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 4.966904163360596 | KNN Loss: 4.847507476806641 | CLS Loss: 0.11939675360918045\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 4.923103332519531 | KNN Loss: 4.8407883644104 | CLS Loss: 0.0823148712515831\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 4.939408779144287 | KNN Loss: 4.84294319152832 | CLS Loss: 0.09646576642990112\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 4.95066499710083 | KNN Loss: 4.867179870605469 | CLS Loss: 0.08348509669303894\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 4.914105415344238 | KNN Loss: 4.82527494430542 | CLS Loss: 0.08883035182952881\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 5.038845062255859 | KNN Loss: 4.899705410003662 | CLS Loss: 0.139139786362648\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 4.942286491394043 | KNN Loss: 4.84089994430542 | CLS Loss: 0.101386658847332\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 4.940647602081299 | KNN Loss: 4.819406032562256 | CLS Loss: 0.12124158442020416\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 4.927120685577393 | KNN Loss: 4.812291622161865 | CLS Loss: 0.11482925713062286\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 4.902420520782471 | KNN Loss: 4.807835578918457 | CLS Loss: 0.09458515048027039\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 5.020750999450684 | KNN Loss: 4.855885028839111 | CLS Loss: 0.1648659110069275\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 5.010168552398682 | KNN Loss: 4.861717224121094 | CLS Loss: 0.1484512835741043\n",
      "Epoch: 005, Loss: 4.9506, Train: 0.9715, Valid: 0.9697, Best: 0.9697\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 5.015469074249268 | KNN Loss: 4.8860650062561035 | CLS Loss: 0.1294039636850357\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 4.944126129150391 | KNN Loss: 4.830431938171387 | CLS Loss: 0.11369428783655167\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 4.907194137573242 | KNN Loss: 4.825001239776611 | CLS Loss: 0.08219294995069504\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 4.901834011077881 | KNN Loss: 4.808937072753906 | CLS Loss: 0.09289702028036118\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 4.872158527374268 | KNN Loss: 4.794185161590576 | CLS Loss: 0.07797350734472275\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 4.909108638763428 | KNN Loss: 4.797783851623535 | CLS Loss: 0.11132478713989258\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 4.903109073638916 | KNN Loss: 4.805797576904297 | CLS Loss: 0.09731146693229675\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 4.927709102630615 | KNN Loss: 4.8213911056518555 | CLS Loss: 0.1063181683421135\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 4.9022674560546875 | KNN Loss: 4.78363037109375 | CLS Loss: 0.11863700300455093\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 4.909139156341553 | KNN Loss: 4.826469898223877 | CLS Loss: 0.08266902714967728\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 4.8505377769470215 | KNN Loss: 4.779670715332031 | CLS Loss: 0.07086703926324844\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 4.918553829193115 | KNN Loss: 4.813803195953369 | CLS Loss: 0.10475076735019684\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 4.877941131591797 | KNN Loss: 4.800896644592285 | CLS Loss: 0.07704466581344604\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 4.908690929412842 | KNN Loss: 4.81222677230835 | CLS Loss: 0.09646429121494293\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 4.928848743438721 | KNN Loss: 4.830524444580078 | CLS Loss: 0.09832416474819183\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 4.947346210479736 | KNN Loss: 4.813357353210449 | CLS Loss: 0.13398872315883636\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 4.872115612030029 | KNN Loss: 4.784905910491943 | CLS Loss: 0.0872097983956337\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 4.82771635055542 | KNN Loss: 4.744279384613037 | CLS Loss: 0.0834370106458664\n",
      "Epoch: 006, Loss: 4.9193, Train: 0.9759, Valid: 0.9738, Best: 0.9738\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 4.857956409454346 | KNN Loss: 4.779013633728027 | CLS Loss: 0.07894283533096313\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 4.898959636688232 | KNN Loss: 4.802143573760986 | CLS Loss: 0.0968162789940834\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 4.857379913330078 | KNN Loss: 4.765987873077393 | CLS Loss: 0.09139201790094376\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 4.869844913482666 | KNN Loss: 4.790251731872559 | CLS Loss: 0.07959338277578354\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 4.919206619262695 | KNN Loss: 4.816334247589111 | CLS Loss: 0.10287252068519592\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 4.8810648918151855 | KNN Loss: 4.7983479499816895 | CLS Loss: 0.08271685242652893\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 4.92367696762085 | KNN Loss: 4.849050045013428 | CLS Loss: 0.07462672144174576\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 4.909948348999023 | KNN Loss: 4.815988540649414 | CLS Loss: 0.0939597636461258\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 4.969336032867432 | KNN Loss: 4.848562717437744 | CLS Loss: 0.12077343463897705\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 4.862857341766357 | KNN Loss: 4.800480365753174 | CLS Loss: 0.062377072870731354\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 4.84921407699585 | KNN Loss: 4.7955546379089355 | CLS Loss: 0.053659383207559586\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 4.9083075523376465 | KNN Loss: 4.789050579071045 | CLS Loss: 0.11925707012414932\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 4.832962989807129 | KNN Loss: 4.75649881362915 | CLS Loss: 0.07646409422159195\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 4.916199207305908 | KNN Loss: 4.841648578643799 | CLS Loss: 0.07455085963010788\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 4.81607723236084 | KNN Loss: 4.7580671310424805 | CLS Loss: 0.05801001191139221\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 4.880349159240723 | KNN Loss: 4.796853065490723 | CLS Loss: 0.08349592983722687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 4.912887096405029 | KNN Loss: 4.825107097625732 | CLS Loss: 0.08777984231710434\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 4.956603527069092 | KNN Loss: 4.823631286621094 | CLS Loss: 0.13297216594219208\n",
      "Epoch: 007, Loss: 4.8936, Train: 0.9796, Valid: 0.9783, Best: 0.9783\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 4.85853910446167 | KNN Loss: 4.749813556671143 | CLS Loss: 0.10872567445039749\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 4.895758152008057 | KNN Loss: 4.828134059906006 | CLS Loss: 0.06762416660785675\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 4.900043487548828 | KNN Loss: 4.7993669509887695 | CLS Loss: 0.10067657381296158\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 4.841984748840332 | KNN Loss: 4.771867752075195 | CLS Loss: 0.07011718302965164\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 4.883410453796387 | KNN Loss: 4.786993503570557 | CLS Loss: 0.0964171290397644\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 4.883818626403809 | KNN Loss: 4.795519828796387 | CLS Loss: 0.08829885721206665\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 4.948189735412598 | KNN Loss: 4.826269149780273 | CLS Loss: 0.12192058563232422\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 4.969264030456543 | KNN Loss: 4.844404697418213 | CLS Loss: 0.12485937774181366\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 4.87546443939209 | KNN Loss: 4.785953044891357 | CLS Loss: 0.08951128274202347\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 4.863953590393066 | KNN Loss: 4.806310653686523 | CLS Loss: 0.05764304846525192\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 4.846693992614746 | KNN Loss: 4.7862749099731445 | CLS Loss: 0.060419097542762756\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 4.8447160720825195 | KNN Loss: 4.811870574951172 | CLS Loss: 0.03284568712115288\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 4.8615570068359375 | KNN Loss: 4.787764549255371 | CLS Loss: 0.07379256188869476\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 4.87040376663208 | KNN Loss: 4.77781343460083 | CLS Loss: 0.09259019047021866\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 4.92091178894043 | KNN Loss: 4.820995330810547 | CLS Loss: 0.09991664439439774\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 4.839451789855957 | KNN Loss: 4.784286022186279 | CLS Loss: 0.05516590550541878\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 4.865453243255615 | KNN Loss: 4.7601776123046875 | CLS Loss: 0.10527553409337997\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 4.907019138336182 | KNN Loss: 4.835225582122803 | CLS Loss: 0.0717935711145401\n",
      "Epoch: 008, Loss: 4.8754, Train: 0.9797, Valid: 0.9773, Best: 0.9783\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 4.8142781257629395 | KNN Loss: 4.772585391998291 | CLS Loss: 0.04169280454516411\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 4.857897758483887 | KNN Loss: 4.783017635345459 | CLS Loss: 0.07488035410642624\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 4.826894760131836 | KNN Loss: 4.773725509643555 | CLS Loss: 0.05316922068595886\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 4.862711429595947 | KNN Loss: 4.793100357055664 | CLS Loss: 0.0696110650897026\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 4.901723861694336 | KNN Loss: 4.810294151306152 | CLS Loss: 0.09142988920211792\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 4.847662448883057 | KNN Loss: 4.795560359954834 | CLS Loss: 0.052102185785770416\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 4.903878688812256 | KNN Loss: 4.826019287109375 | CLS Loss: 0.07785950601100922\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 4.858307361602783 | KNN Loss: 4.768996715545654 | CLS Loss: 0.08931057900190353\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 4.857387065887451 | KNN Loss: 4.774349689483643 | CLS Loss: 0.08303724229335785\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 4.837210178375244 | KNN Loss: 4.788570880889893 | CLS Loss: 0.04863928258419037\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 4.882222652435303 | KNN Loss: 4.79337215423584 | CLS Loss: 0.08885060250759125\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 4.843438625335693 | KNN Loss: 4.76515531539917 | CLS Loss: 0.07828336209058762\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 4.86410665512085 | KNN Loss: 4.758472919464111 | CLS Loss: 0.10563381016254425\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 4.831634521484375 | KNN Loss: 4.767742156982422 | CLS Loss: 0.06389232724905014\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 4.893765449523926 | KNN Loss: 4.7801361083984375 | CLS Loss: 0.11362910270690918\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 4.865454196929932 | KNN Loss: 4.81299352645874 | CLS Loss: 0.05246087163686752\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 4.871038913726807 | KNN Loss: 4.805044174194336 | CLS Loss: 0.0659945160150528\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 4.814441204071045 | KNN Loss: 4.764125347137451 | CLS Loss: 0.05031586438417435\n",
      "Epoch: 009, Loss: 4.8615, Train: 0.9818, Valid: 0.9791, Best: 0.9791\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 4.879937648773193 | KNN Loss: 4.805219650268555 | CLS Loss: 0.0747181847691536\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 4.833066463470459 | KNN Loss: 4.7482428550720215 | CLS Loss: 0.0848236158490181\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 4.753746509552002 | KNN Loss: 4.71309232711792 | CLS Loss: 0.040654271841049194\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 4.815179347991943 | KNN Loss: 4.780160903930664 | CLS Loss: 0.03501836583018303\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 4.804629325866699 | KNN Loss: 4.769776821136475 | CLS Loss: 0.03485257178544998\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 4.8633294105529785 | KNN Loss: 4.797451019287109 | CLS Loss: 0.06587818264961243\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 4.771927356719971 | KNN Loss: 4.736255168914795 | CLS Loss: 0.035672370344400406\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 4.844718933105469 | KNN Loss: 4.777390956878662 | CLS Loss: 0.06732780486345291\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 4.840750694274902 | KNN Loss: 4.7910261154174805 | CLS Loss: 0.0497247613966465\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 4.852245330810547 | KNN Loss: 4.765790939331055 | CLS Loss: 0.08645453304052353\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 4.785193920135498 | KNN Loss: 4.706356525421143 | CLS Loss: 0.07883740961551666\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 4.789334774017334 | KNN Loss: 4.732974052429199 | CLS Loss: 0.05636073648929596\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 4.838817596435547 | KNN Loss: 4.7864789962768555 | CLS Loss: 0.05233859643340111\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 4.857821941375732 | KNN Loss: 4.758319854736328 | CLS Loss: 0.09950228035449982\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 4.864524841308594 | KNN Loss: 4.792755603790283 | CLS Loss: 0.07176927477121353\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 4.825020790100098 | KNN Loss: 4.75498104095459 | CLS Loss: 0.07003965228796005\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 4.916471481323242 | KNN Loss: 4.823418140411377 | CLS Loss: 0.0930534303188324\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 4.8800835609436035 | KNN Loss: 4.805221080780029 | CLS Loss: 0.0748622789978981\n",
      "Epoch: 010, Loss: 4.8381, Train: 0.9816, Valid: 0.9788, Best: 0.9791\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 4.919018268585205 | KNN Loss: 4.840901851654053 | CLS Loss: 0.07811630517244339\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 4.781033039093018 | KNN Loss: 4.743111610412598 | CLS Loss: 0.03792119771242142\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 4.8284125328063965 | KNN Loss: 4.768526077270508 | CLS Loss: 0.05988646298646927\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 4.836605548858643 | KNN Loss: 4.778067111968994 | CLS Loss: 0.05853832885622978\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 4.809924602508545 | KNN Loss: 4.739004611968994 | CLS Loss: 0.07092002779245377\n",
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 4.7893571853637695 | KNN Loss: 4.76022481918335 | CLS Loss: 0.0291324183344841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 4.8051252365112305 | KNN Loss: 4.732942581176758 | CLS Loss: 0.07218284159898758\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 4.853011608123779 | KNN Loss: 4.76618766784668 | CLS Loss: 0.0868237093091011\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 4.826859474182129 | KNN Loss: 4.7362589836120605 | CLS Loss: 0.09060072153806686\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 4.8144049644470215 | KNN Loss: 4.770278453826904 | CLS Loss: 0.04412638023495674\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 4.824174880981445 | KNN Loss: 4.756758213043213 | CLS Loss: 0.06741679459810257\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 4.837057590484619 | KNN Loss: 4.7804694175720215 | CLS Loss: 0.05658822879195213\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 4.781062126159668 | KNN Loss: 4.74584436416626 | CLS Loss: 0.03521760553121567\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 4.897092342376709 | KNN Loss: 4.798375606536865 | CLS Loss: 0.09871672838926315\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 4.833234786987305 | KNN Loss: 4.7670063972473145 | CLS Loss: 0.06622815877199173\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 4.857958793640137 | KNN Loss: 4.7797980308532715 | CLS Loss: 0.07816094160079956\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 4.797548770904541 | KNN Loss: 4.746778964996338 | CLS Loss: 0.050769779831171036\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 4.855457305908203 | KNN Loss: 4.796524524688721 | CLS Loss: 0.058933012187480927\n",
      "Epoch: 011, Loss: 4.8270, Train: 0.9846, Valid: 0.9815, Best: 0.9815\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 4.82726526260376 | KNN Loss: 4.769904613494873 | CLS Loss: 0.05736057087779045\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 4.883529186248779 | KNN Loss: 4.808938026428223 | CLS Loss: 0.07459121942520142\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 4.813282489776611 | KNN Loss: 4.752715110778809 | CLS Loss: 0.06056714430451393\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 4.846187114715576 | KNN Loss: 4.759379863739014 | CLS Loss: 0.08680727332830429\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 4.839606761932373 | KNN Loss: 4.796147346496582 | CLS Loss: 0.043459389358758926\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 4.86560583114624 | KNN Loss: 4.78856897354126 | CLS Loss: 0.07703684270381927\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 4.878828525543213 | KNN Loss: 4.781494617462158 | CLS Loss: 0.09733393788337708\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 4.775373458862305 | KNN Loss: 4.72735595703125 | CLS Loss: 0.048017337918281555\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 4.875923156738281 | KNN Loss: 4.786550045013428 | CLS Loss: 0.08937320858240128\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 4.791165828704834 | KNN Loss: 4.737257480621338 | CLS Loss: 0.05390851944684982\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 4.821791648864746 | KNN Loss: 4.7504401206970215 | CLS Loss: 0.07135128974914551\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 4.86022424697876 | KNN Loss: 4.758795261383057 | CLS Loss: 0.10142897069454193\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 4.8219780921936035 | KNN Loss: 4.765316486358643 | CLS Loss: 0.05666153132915497\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 4.791201591491699 | KNN Loss: 4.737882614135742 | CLS Loss: 0.053319040685892105\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 4.832738399505615 | KNN Loss: 4.771878242492676 | CLS Loss: 0.06086036190390587\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 4.905198097229004 | KNN Loss: 4.774531841278076 | CLS Loss: 0.13066616654396057\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 4.791324138641357 | KNN Loss: 4.725639820098877 | CLS Loss: 0.06568417698144913\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 4.811702251434326 | KNN Loss: 4.743286609649658 | CLS Loss: 0.06841570883989334\n",
      "Epoch: 012, Loss: 4.8240, Train: 0.9846, Valid: 0.9806, Best: 0.9815\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 4.832947731018066 | KNN Loss: 4.765463829040527 | CLS Loss: 0.06748374551534653\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 4.8376336097717285 | KNN Loss: 4.7830681800842285 | CLS Loss: 0.05456555634737015\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 4.863135814666748 | KNN Loss: 4.764153957366943 | CLS Loss: 0.09898165613412857\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 4.818722248077393 | KNN Loss: 4.745739459991455 | CLS Loss: 0.07298268377780914\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 4.797791004180908 | KNN Loss: 4.759576320648193 | CLS Loss: 0.0382147915661335\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 4.7826151847839355 | KNN Loss: 4.73530912399292 | CLS Loss: 0.04730600118637085\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 4.798348426818848 | KNN Loss: 4.730197429656982 | CLS Loss: 0.06815113127231598\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 4.83313512802124 | KNN Loss: 4.754002571105957 | CLS Loss: 0.07913253456354141\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 4.846502780914307 | KNN Loss: 4.776941776275635 | CLS Loss: 0.0695609375834465\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 4.807487487792969 | KNN Loss: 4.732751369476318 | CLS Loss: 0.07473604381084442\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 4.796108245849609 | KNN Loss: 4.74687385559082 | CLS Loss: 0.04923449084162712\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 4.829368591308594 | KNN Loss: 4.758162975311279 | CLS Loss: 0.07120557129383087\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 4.823278903961182 | KNN Loss: 4.721658706665039 | CLS Loss: 0.1016203835606575\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 4.826941967010498 | KNN Loss: 4.764171123504639 | CLS Loss: 0.06277074664831161\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 4.948367595672607 | KNN Loss: 4.861212253570557 | CLS Loss: 0.08715548366308212\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 4.775471210479736 | KNN Loss: 4.735184669494629 | CLS Loss: 0.040286704897880554\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 4.776487350463867 | KNN Loss: 4.745236396789551 | CLS Loss: 0.03125110641121864\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 4.824635028839111 | KNN Loss: 4.738401889801025 | CLS Loss: 0.08623336255550385\n",
      "Epoch: 013, Loss: 4.8174, Train: 0.9850, Valid: 0.9815, Best: 0.9815\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 4.804445266723633 | KNN Loss: 4.743957996368408 | CLS Loss: 0.060487329959869385\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 4.817899703979492 | KNN Loss: 4.759713172912598 | CLS Loss: 0.05818676948547363\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 4.775571823120117 | KNN Loss: 4.7095046043396 | CLS Loss: 0.06606732308864594\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 4.839728832244873 | KNN Loss: 4.78352689743042 | CLS Loss: 0.05620202422142029\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 4.821590900421143 | KNN Loss: 4.724322319030762 | CLS Loss: 0.09726843982934952\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 4.7467193603515625 | KNN Loss: 4.72035551071167 | CLS Loss: 0.026363898068666458\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 4.862565040588379 | KNN Loss: 4.761589050292969 | CLS Loss: 0.1009761393070221\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 4.8097004890441895 | KNN Loss: 4.757736682891846 | CLS Loss: 0.05196380987763405\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 4.760408878326416 | KNN Loss: 4.726153373718262 | CLS Loss: 0.03425569459795952\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 4.819945335388184 | KNN Loss: 4.797110080718994 | CLS Loss: 0.022835126146674156\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 4.7988362312316895 | KNN Loss: 4.7603888511657715 | CLS Loss: 0.03844723850488663\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 4.799056053161621 | KNN Loss: 4.72402811050415 | CLS Loss: 0.07502789795398712\n",
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 4.811009883880615 | KNN Loss: 4.755782604217529 | CLS Loss: 0.055227432399988174\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 4.793247699737549 | KNN Loss: 4.7275190353393555 | CLS Loss: 0.06572844833135605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 4.756664752960205 | KNN Loss: 4.704980850219727 | CLS Loss: 0.051684118807315826\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 4.789742946624756 | KNN Loss: 4.739541053771973 | CLS Loss: 0.05020182952284813\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 4.834897994995117 | KNN Loss: 4.767545700073242 | CLS Loss: 0.06735212355852127\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 4.801946640014648 | KNN Loss: 4.755081653594971 | CLS Loss: 0.046865154057741165\n",
      "Epoch: 014, Loss: 4.8062, Train: 0.9858, Valid: 0.9823, Best: 0.9823\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 4.761838436126709 | KNN Loss: 4.723233699798584 | CLS Loss: 0.038604702800512314\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 4.817720890045166 | KNN Loss: 4.738092422485352 | CLS Loss: 0.07962839305400848\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 4.823766231536865 | KNN Loss: 4.777785301208496 | CLS Loss: 0.045981090515851974\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 4.814037322998047 | KNN Loss: 4.7761921882629395 | CLS Loss: 0.03784498944878578\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 4.77556848526001 | KNN Loss: 4.7253313064575195 | CLS Loss: 0.050237368792295456\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 4.762969970703125 | KNN Loss: 4.705376148223877 | CLS Loss: 0.05759388953447342\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 4.788782596588135 | KNN Loss: 4.7510247230529785 | CLS Loss: 0.03775770589709282\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 4.885432720184326 | KNN Loss: 4.814675807952881 | CLS Loss: 0.07075712829828262\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 4.782171726226807 | KNN Loss: 4.740638256072998 | CLS Loss: 0.04153357818722725\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 4.794656276702881 | KNN Loss: 4.732418060302734 | CLS Loss: 0.06223803758621216\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 4.829712867736816 | KNN Loss: 4.779034614562988 | CLS Loss: 0.05067841336131096\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 4.740074157714844 | KNN Loss: 4.709295272827148 | CLS Loss: 0.030779080465435982\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 4.81381893157959 | KNN Loss: 4.730938911437988 | CLS Loss: 0.08287990093231201\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 4.832615852355957 | KNN Loss: 4.79240608215332 | CLS Loss: 0.04020997881889343\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 4.798360824584961 | KNN Loss: 4.746827125549316 | CLS Loss: 0.0515337809920311\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 4.783996105194092 | KNN Loss: 4.726937770843506 | CLS Loss: 0.05705828219652176\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 4.727666854858398 | KNN Loss: 4.692636489868164 | CLS Loss: 0.03503018617630005\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 4.807671546936035 | KNN Loss: 4.745227813720703 | CLS Loss: 0.062443770468235016\n",
      "Epoch: 015, Loss: 4.7976, Train: 0.9865, Valid: 0.9825, Best: 0.9825\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 4.791133880615234 | KNN Loss: 4.757120132446289 | CLS Loss: 0.034013718366622925\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 4.834148406982422 | KNN Loss: 4.767168045043945 | CLS Loss: 0.06698037683963776\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 4.78850793838501 | KNN Loss: 4.751105785369873 | CLS Loss: 0.03740215301513672\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 4.761491298675537 | KNN Loss: 4.7287702560424805 | CLS Loss: 0.032720837742090225\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 4.791104316711426 | KNN Loss: 4.748340129852295 | CLS Loss: 0.042764101177453995\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 4.7427568435668945 | KNN Loss: 4.722331523895264 | CLS Loss: 0.020425375550985336\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 4.742071151733398 | KNN Loss: 4.695353984832764 | CLS Loss: 0.04671706259250641\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 4.775574684143066 | KNN Loss: 4.712194442749023 | CLS Loss: 0.0633804053068161\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 4.77130651473999 | KNN Loss: 4.721591949462891 | CLS Loss: 0.04971450939774513\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 4.82184362411499 | KNN Loss: 4.77469539642334 | CLS Loss: 0.047148462384939194\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 4.741696357727051 | KNN Loss: 4.704443454742432 | CLS Loss: 0.03725307434797287\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 4.810169219970703 | KNN Loss: 4.741849899291992 | CLS Loss: 0.06831923127174377\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 4.707176685333252 | KNN Loss: 4.691281318664551 | CLS Loss: 0.015895236283540726\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 4.752020359039307 | KNN Loss: 4.723908424377441 | CLS Loss: 0.028112100437283516\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 4.762916564941406 | KNN Loss: 4.729737758636475 | CLS Loss: 0.03317876160144806\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 4.793212890625 | KNN Loss: 4.750857353210449 | CLS Loss: 0.04235538840293884\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 4.761683464050293 | KNN Loss: 4.730933666229248 | CLS Loss: 0.030749840661883354\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 4.813838958740234 | KNN Loss: 4.736222267150879 | CLS Loss: 0.07761658728122711\n",
      "Epoch: 016, Loss: 4.7994, Train: 0.9872, Valid: 0.9823, Best: 0.9825\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 4.81968879699707 | KNN Loss: 4.744123935699463 | CLS Loss: 0.07556507736444473\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 4.851848125457764 | KNN Loss: 4.7668046951293945 | CLS Loss: 0.08504339307546616\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 4.723247051239014 | KNN Loss: 4.674450874328613 | CLS Loss: 0.0487961545586586\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 4.806665897369385 | KNN Loss: 4.747708797454834 | CLS Loss: 0.05895699933171272\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 4.7532477378845215 | KNN Loss: 4.71106481552124 | CLS Loss: 0.0421830452978611\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 4.780477523803711 | KNN Loss: 4.739752769470215 | CLS Loss: 0.040724821388721466\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 4.8151350021362305 | KNN Loss: 4.756504058837891 | CLS Loss: 0.05863112583756447\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 4.819953441619873 | KNN Loss: 4.766689777374268 | CLS Loss: 0.05326377972960472\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 4.780197620391846 | KNN Loss: 4.743624687194824 | CLS Loss: 0.03657316789031029\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 4.786839962005615 | KNN Loss: 4.729482650756836 | CLS Loss: 0.05735722929239273\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 4.784811019897461 | KNN Loss: 4.725332260131836 | CLS Loss: 0.059478774666786194\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 4.769223213195801 | KNN Loss: 4.722939968109131 | CLS Loss: 0.046283334493637085\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 4.812005043029785 | KNN Loss: 4.745072364807129 | CLS Loss: 0.06693282723426819\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 4.844333171844482 | KNN Loss: 4.7953925132751465 | CLS Loss: 0.04894080385565758\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 4.8349175453186035 | KNN Loss: 4.784024238586426 | CLS Loss: 0.0508933961391449\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 4.775567531585693 | KNN Loss: 4.742602348327637 | CLS Loss: 0.032965291291475296\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 4.831153869628906 | KNN Loss: 4.7895965576171875 | CLS Loss: 0.04155723378062248\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 4.845042705535889 | KNN Loss: 4.7718634605407715 | CLS Loss: 0.07317911088466644\n",
      "Epoch: 017, Loss: 4.7941, Train: 0.9864, Valid: 0.9813, Best: 0.9825\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 4.865283489227295 | KNN Loss: 4.799172878265381 | CLS Loss: 0.06611081212759018\n",
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 4.798605442047119 | KNN Loss: 4.724496841430664 | CLS Loss: 0.0741085559129715\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 4.744255065917969 | KNN Loss: 4.703307628631592 | CLS Loss: 0.040947362780570984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 4.791929721832275 | KNN Loss: 4.718076229095459 | CLS Loss: 0.07385341823101044\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 4.797919750213623 | KNN Loss: 4.743964672088623 | CLS Loss: 0.05395513027906418\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 4.834443092346191 | KNN Loss: 4.772032737731934 | CLS Loss: 0.06241016462445259\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 4.888416767120361 | KNN Loss: 4.829061508178711 | CLS Loss: 0.059355124831199646\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 4.80781364440918 | KNN Loss: 4.748607635498047 | CLS Loss: 0.059205882251262665\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 4.81538200378418 | KNN Loss: 4.757635116577148 | CLS Loss: 0.05774672329425812\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 4.850193977355957 | KNN Loss: 4.7681565284729 | CLS Loss: 0.0820375308394432\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 4.762050151824951 | KNN Loss: 4.727203369140625 | CLS Loss: 0.03484661504626274\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 4.8234477043151855 | KNN Loss: 4.763311386108398 | CLS Loss: 0.060136280953884125\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 4.77095365524292 | KNN Loss: 4.738224983215332 | CLS Loss: 0.0327286496758461\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 4.827277183532715 | KNN Loss: 4.769136905670166 | CLS Loss: 0.05814018473029137\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 4.799459457397461 | KNN Loss: 4.761875152587891 | CLS Loss: 0.03758421912789345\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 4.7930989265441895 | KNN Loss: 4.761799335479736 | CLS Loss: 0.03129952400922775\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 4.796036720275879 | KNN Loss: 4.762789249420166 | CLS Loss: 0.03324735164642334\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 4.762022495269775 | KNN Loss: 4.7285685539245605 | CLS Loss: 0.03345393389463425\n",
      "Epoch: 018, Loss: 4.7969, Train: 0.9861, Valid: 0.9817, Best: 0.9825\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 4.773627281188965 | KNN Loss: 4.731024265289307 | CLS Loss: 0.04260312020778656\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 4.77617073059082 | KNN Loss: 4.73786735534668 | CLS Loss: 0.038303155452013016\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 4.745469093322754 | KNN Loss: 4.722426891326904 | CLS Loss: 0.023042233660817146\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 4.758236408233643 | KNN Loss: 4.710342884063721 | CLS Loss: 0.0478934608399868\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 4.862758636474609 | KNN Loss: 4.835907459259033 | CLS Loss: 0.026851141825318336\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 4.8317365646362305 | KNN Loss: 4.758382797241211 | CLS Loss: 0.07335367053747177\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 4.797693729400635 | KNN Loss: 4.756080150604248 | CLS Loss: 0.04161354526877403\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 4.797506332397461 | KNN Loss: 4.735311985015869 | CLS Loss: 0.062194500118494034\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 4.81536865234375 | KNN Loss: 4.7609357833862305 | CLS Loss: 0.05443273484706879\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 4.757819652557373 | KNN Loss: 4.723429203033447 | CLS Loss: 0.03439030796289444\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 4.817789077758789 | KNN Loss: 4.7848286628723145 | CLS Loss: 0.03296025097370148\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 4.781580448150635 | KNN Loss: 4.726774215698242 | CLS Loss: 0.054806359112262726\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 4.858658790588379 | KNN Loss: 4.790445327758789 | CLS Loss: 0.06821347773075104\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 4.824013710021973 | KNN Loss: 4.792133808135986 | CLS Loss: 0.03187984228134155\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 4.862911701202393 | KNN Loss: 4.82113790512085 | CLS Loss: 0.04177385941147804\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 4.750949859619141 | KNN Loss: 4.7174296379089355 | CLS Loss: 0.03352024033665657\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 4.772975921630859 | KNN Loss: 4.744428634643555 | CLS Loss: 0.028547082096338272\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 4.796215534210205 | KNN Loss: 4.747364044189453 | CLS Loss: 0.048851292580366135\n",
      "Epoch: 019, Loss: 4.7941, Train: 0.9870, Valid: 0.9822, Best: 0.9825\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 4.791509628295898 | KNN Loss: 4.7320475578308105 | CLS Loss: 0.05946224182844162\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 4.750438213348389 | KNN Loss: 4.70611047744751 | CLS Loss: 0.04432760179042816\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 4.865958213806152 | KNN Loss: 4.820186614990234 | CLS Loss: 0.04577159509062767\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 4.751053333282471 | KNN Loss: 4.708617687225342 | CLS Loss: 0.04243563860654831\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 4.813841819763184 | KNN Loss: 4.7704081535339355 | CLS Loss: 0.04343363642692566\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 4.7677788734436035 | KNN Loss: 4.713644504547119 | CLS Loss: 0.05413426458835602\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 4.739202976226807 | KNN Loss: 4.686922073364258 | CLS Loss: 0.05228088051080704\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 4.731054306030273 | KNN Loss: 4.713042259216309 | CLS Loss: 0.018012063577771187\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 4.743183135986328 | KNN Loss: 4.705691814422607 | CLS Loss: 0.037491101771593094\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 4.786916732788086 | KNN Loss: 4.750665664672852 | CLS Loss: 0.03625109791755676\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 4.851938247680664 | KNN Loss: 4.795623779296875 | CLS Loss: 0.05631444603204727\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 4.789078712463379 | KNN Loss: 4.743113994598389 | CLS Loss: 0.04596463963389397\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 4.820995330810547 | KNN Loss: 4.7631354331970215 | CLS Loss: 0.057859983295202255\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 4.78073263168335 | KNN Loss: 4.722173690795898 | CLS Loss: 0.05855916813015938\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 4.7777323722839355 | KNN Loss: 4.72908878326416 | CLS Loss: 0.04864363744854927\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 4.773714542388916 | KNN Loss: 4.732264041900635 | CLS Loss: 0.041450370103120804\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 4.712311267852783 | KNN Loss: 4.686329364776611 | CLS Loss: 0.025981847196817398\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 4.769658088684082 | KNN Loss: 4.700739860534668 | CLS Loss: 0.06891807168722153\n",
      "Epoch: 020, Loss: 4.7868, Train: 0.9873, Valid: 0.9832, Best: 0.9832\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 4.843719005584717 | KNN Loss: 4.798883438110352 | CLS Loss: 0.04483547806739807\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 4.728805065155029 | KNN Loss: 4.688078880310059 | CLS Loss: 0.04072639346122742\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 4.775964260101318 | KNN Loss: 4.737987518310547 | CLS Loss: 0.037976570427417755\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 4.75447416305542 | KNN Loss: 4.726193428039551 | CLS Loss: 0.028280850499868393\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 4.8492021560668945 | KNN Loss: 4.7980146408081055 | CLS Loss: 0.05118747428059578\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 4.74562931060791 | KNN Loss: 4.710167407989502 | CLS Loss: 0.035462066531181335\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 4.7578229904174805 | KNN Loss: 4.726407527923584 | CLS Loss: 0.03141526132822037\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 4.742224216461182 | KNN Loss: 4.695326328277588 | CLS Loss: 0.04689791426062584\n",
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 4.725712776184082 | KNN Loss: 4.689728260040283 | CLS Loss: 0.03598439320921898\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 4.791140556335449 | KNN Loss: 4.771140098571777 | CLS Loss: 0.0200006403028965\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 4.879373073577881 | KNN Loss: 4.790060520172119 | CLS Loss: 0.08931248635053635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 4.7503743171691895 | KNN Loss: 4.728378772735596 | CLS Loss: 0.02199532277882099\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 4.761358261108398 | KNN Loss: 4.707172393798828 | CLS Loss: 0.054185718297958374\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 4.7785186767578125 | KNN Loss: 4.711872577667236 | CLS Loss: 0.0666460320353508\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 4.8240156173706055 | KNN Loss: 4.780041694641113 | CLS Loss: 0.04397384822368622\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 4.765025615692139 | KNN Loss: 4.719274044036865 | CLS Loss: 0.04575154557824135\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 4.8462042808532715 | KNN Loss: 4.790517330169678 | CLS Loss: 0.05568686127662659\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 4.716973304748535 | KNN Loss: 4.686045169830322 | CLS Loss: 0.03092792071402073\n",
      "Epoch: 021, Loss: 4.7774, Train: 0.9884, Valid: 0.9837, Best: 0.9837\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 4.755509376525879 | KNN Loss: 4.707764148712158 | CLS Loss: 0.04774538800120354\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 4.795149326324463 | KNN Loss: 4.7689433097839355 | CLS Loss: 0.02620607241988182\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 4.793329238891602 | KNN Loss: 4.742372035980225 | CLS Loss: 0.05095720663666725\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 4.814685821533203 | KNN Loss: 4.774590492248535 | CLS Loss: 0.040095265954732895\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 4.789951324462891 | KNN Loss: 4.727688789367676 | CLS Loss: 0.062262583523988724\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 4.846548080444336 | KNN Loss: 4.779880046844482 | CLS Loss: 0.06666781008243561\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 4.774303436279297 | KNN Loss: 4.745571136474609 | CLS Loss: 0.028732120990753174\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 4.810982704162598 | KNN Loss: 4.750144004821777 | CLS Loss: 0.0608387216925621\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 4.727509021759033 | KNN Loss: 4.6971755027771 | CLS Loss: 0.030333301052451134\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 4.7784504890441895 | KNN Loss: 4.73283052444458 | CLS Loss: 0.04562007263302803\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 4.825699329376221 | KNN Loss: 4.778918743133545 | CLS Loss: 0.04678066074848175\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 4.757806301116943 | KNN Loss: 4.717912197113037 | CLS Loss: 0.03989418223500252\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 4.752145767211914 | KNN Loss: 4.726291656494141 | CLS Loss: 0.025854140520095825\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 4.771362781524658 | KNN Loss: 4.725009918212891 | CLS Loss: 0.046352967619895935\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 4.791877269744873 | KNN Loss: 4.73250675201416 | CLS Loss: 0.059370432049036026\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 4.814671993255615 | KNN Loss: 4.772428512573242 | CLS Loss: 0.04224328696727753\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 4.7581095695495605 | KNN Loss: 4.705392360687256 | CLS Loss: 0.05271712318062782\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 4.824872970581055 | KNN Loss: 4.752298831939697 | CLS Loss: 0.07257425785064697\n",
      "Epoch: 022, Loss: 4.7779, Train: 0.9886, Valid: 0.9831, Best: 0.9837\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 4.785094738006592 | KNN Loss: 4.730165958404541 | CLS Loss: 0.054928626865148544\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 4.789947986602783 | KNN Loss: 4.752890110015869 | CLS Loss: 0.037057988345623016\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 4.763331413269043 | KNN Loss: 4.736608505249023 | CLS Loss: 0.02672279253602028\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 4.744025230407715 | KNN Loss: 4.717206001281738 | CLS Loss: 0.026819149032235146\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 4.7808122634887695 | KNN Loss: 4.740370750427246 | CLS Loss: 0.04044128209352493\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 4.7513041496276855 | KNN Loss: 4.695250988006592 | CLS Loss: 0.05605296045541763\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 4.862107753753662 | KNN Loss: 4.810100078582764 | CLS Loss: 0.05200767144560814\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 4.75858211517334 | KNN Loss: 4.7216339111328125 | CLS Loss: 0.03694840520620346\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 4.800928115844727 | KNN Loss: 4.761725902557373 | CLS Loss: 0.039202142506837845\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 4.819933891296387 | KNN Loss: 4.770042896270752 | CLS Loss: 0.04989105463027954\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 4.764561176300049 | KNN Loss: 4.740460395812988 | CLS Loss: 0.024100985378026962\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 4.767467021942139 | KNN Loss: 4.723715305328369 | CLS Loss: 0.043751489371061325\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 4.802862167358398 | KNN Loss: 4.754849433898926 | CLS Loss: 0.04801257699728012\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 4.7268500328063965 | KNN Loss: 4.6799187660217285 | CLS Loss: 0.04693147912621498\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 4.738602161407471 | KNN Loss: 4.7041239738464355 | CLS Loss: 0.034478332847356796\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 4.779106616973877 | KNN Loss: 4.741903781890869 | CLS Loss: 0.037202734500169754\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 4.812350273132324 | KNN Loss: 4.7635297775268555 | CLS Loss: 0.048820313066244125\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 4.776710033416748 | KNN Loss: 4.730442047119141 | CLS Loss: 0.046268194913864136\n",
      "Epoch: 023, Loss: 4.7770, Train: 0.9874, Valid: 0.9829, Best: 0.9837\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 4.749892711639404 | KNN Loss: 4.724301338195801 | CLS Loss: 0.025591451674699783\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 4.790717601776123 | KNN Loss: 4.736240863800049 | CLS Loss: 0.05447687581181526\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 4.776993274688721 | KNN Loss: 4.736536979675293 | CLS Loss: 0.04045631363987923\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 4.799948215484619 | KNN Loss: 4.764537811279297 | CLS Loss: 0.03541063889861107\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 4.794087886810303 | KNN Loss: 4.74989128112793 | CLS Loss: 0.044196728616952896\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 4.832977294921875 | KNN Loss: 4.792191505432129 | CLS Loss: 0.04078562930226326\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 4.806046009063721 | KNN Loss: 4.75244140625 | CLS Loss: 0.05360462889075279\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 4.815045356750488 | KNN Loss: 4.762757778167725 | CLS Loss: 0.05228770896792412\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 4.7753987312316895 | KNN Loss: 4.733473777770996 | CLS Loss: 0.041924864053726196\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 4.759815692901611 | KNN Loss: 4.740656852722168 | CLS Loss: 0.019158877432346344\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 4.767617702484131 | KNN Loss: 4.74417781829834 | CLS Loss: 0.023439669981598854\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 4.803462028503418 | KNN Loss: 4.771485328674316 | CLS Loss: 0.03197680413722992\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 4.755352020263672 | KNN Loss: 4.728941917419434 | CLS Loss: 0.026409875601530075\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 4.773315906524658 | KNN Loss: 4.750818729400635 | CLS Loss: 0.022497273981571198\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 4.80351448059082 | KNN Loss: 4.740606307983398 | CLS Loss: 0.06290797889232635\n",
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 4.745203495025635 | KNN Loss: 4.70989465713501 | CLS Loss: 0.0353088453412056\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 4.785478115081787 | KNN Loss: 4.727816104888916 | CLS Loss: 0.057661980390548706\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 4.800478458404541 | KNN Loss: 4.765984535217285 | CLS Loss: 0.03449409455060959\n",
      "Epoch: 024, Loss: 4.7858, Train: 0.9899, Valid: 0.9849, Best: 0.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 4.755165100097656 | KNN Loss: 4.738037586212158 | CLS Loss: 0.017127374187111855\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 4.724353313446045 | KNN Loss: 4.699821472167969 | CLS Loss: 0.024531763046979904\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 4.791072368621826 | KNN Loss: 4.752983570098877 | CLS Loss: 0.03808900713920593\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 4.869054794311523 | KNN Loss: 4.810556411743164 | CLS Loss: 0.0584983229637146\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 4.77292013168335 | KNN Loss: 4.741631031036377 | CLS Loss: 0.03128919005393982\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 4.759739875793457 | KNN Loss: 4.718317985534668 | CLS Loss: 0.04142165929079056\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 4.727336406707764 | KNN Loss: 4.711234092712402 | CLS Loss: 0.016102243214845657\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 4.849032878875732 | KNN Loss: 4.793157577514648 | CLS Loss: 0.05587538704276085\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 4.807681083679199 | KNN Loss: 4.757944583892822 | CLS Loss: 0.04973640665411949\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 4.7645063400268555 | KNN Loss: 4.719707489013672 | CLS Loss: 0.044798869639635086\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 4.7945637702941895 | KNN Loss: 4.748938083648682 | CLS Loss: 0.04562581330537796\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 4.738936424255371 | KNN Loss: 4.715112686157227 | CLS Loss: 0.02382376231253147\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 4.862038612365723 | KNN Loss: 4.837978363037109 | CLS Loss: 0.02406003698706627\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 4.8571648597717285 | KNN Loss: 4.752209663391113 | CLS Loss: 0.10495533794164658\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 4.918580055236816 | KNN Loss: 4.886351108551025 | CLS Loss: 0.032228726893663406\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 4.76720666885376 | KNN Loss: 4.737804889678955 | CLS Loss: 0.029401980340480804\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 4.8029656410217285 | KNN Loss: 4.779481410980225 | CLS Loss: 0.0234840027987957\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 4.852485656738281 | KNN Loss: 4.7698445320129395 | CLS Loss: 0.08264102041721344\n",
      "Epoch: 025, Loss: 4.7848, Train: 0.9894, Valid: 0.9835, Best: 0.9849\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 4.752856254577637 | KNN Loss: 4.705418109893799 | CLS Loss: 0.047438036650419235\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 4.74772834777832 | KNN Loss: 4.729454517364502 | CLS Loss: 0.018273862078785896\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 4.754134654998779 | KNN Loss: 4.726566314697266 | CLS Loss: 0.02756856381893158\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 4.808982849121094 | KNN Loss: 4.788979530334473 | CLS Loss: 0.020003458485007286\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 4.760764122009277 | KNN Loss: 4.741675853729248 | CLS Loss: 0.01908835954964161\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 4.767179012298584 | KNN Loss: 4.736329555511475 | CLS Loss: 0.03084958717226982\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 4.737536907196045 | KNN Loss: 4.715544700622559 | CLS Loss: 0.021992020308971405\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 4.782811641693115 | KNN Loss: 4.759019374847412 | CLS Loss: 0.023792263120412827\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 4.781613826751709 | KNN Loss: 4.752383708953857 | CLS Loss: 0.02922993153333664\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 4.776927471160889 | KNN Loss: 4.757929801940918 | CLS Loss: 0.01899772323668003\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 4.802414894104004 | KNN Loss: 4.7648444175720215 | CLS Loss: 0.03757048398256302\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 4.755184173583984 | KNN Loss: 4.732857704162598 | CLS Loss: 0.022326262667775154\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 4.763497829437256 | KNN Loss: 4.725653171539307 | CLS Loss: 0.03784449025988579\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 4.819638729095459 | KNN Loss: 4.780580043792725 | CLS Loss: 0.039058879017829895\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 4.772678375244141 | KNN Loss: 4.725671768188477 | CLS Loss: 0.04700649157166481\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 4.825877666473389 | KNN Loss: 4.778607368469238 | CLS Loss: 0.04727018624544144\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 4.818552017211914 | KNN Loss: 4.775561809539795 | CLS Loss: 0.04299003258347511\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 4.760839462280273 | KNN Loss: 4.700767517089844 | CLS Loss: 0.060071736574172974\n",
      "Epoch: 026, Loss: 4.7825, Train: 0.9903, Valid: 0.9846, Best: 0.9849\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 4.759860992431641 | KNN Loss: 4.747956275939941 | CLS Loss: 0.011904803104698658\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 4.791844367980957 | KNN Loss: 4.747372150421143 | CLS Loss: 0.04447207227349281\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 4.772439956665039 | KNN Loss: 4.733650207519531 | CLS Loss: 0.03878974914550781\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 4.765970706939697 | KNN Loss: 4.730435848236084 | CLS Loss: 0.03553507477045059\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 4.731070041656494 | KNN Loss: 4.668386936187744 | CLS Loss: 0.06268300861120224\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 4.803536415100098 | KNN Loss: 4.754284381866455 | CLS Loss: 0.0492519810795784\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 4.714763164520264 | KNN Loss: 4.693817615509033 | CLS Loss: 0.02094569429755211\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 4.75590181350708 | KNN Loss: 4.7250895500183105 | CLS Loss: 0.03081246092915535\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 4.7578935623168945 | KNN Loss: 4.745782852172852 | CLS Loss: 0.012110678479075432\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 4.759820938110352 | KNN Loss: 4.716144561767578 | CLS Loss: 0.04367644712328911\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 4.823767185211182 | KNN Loss: 4.762810230255127 | CLS Loss: 0.06095690652728081\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 4.745894432067871 | KNN Loss: 4.728854179382324 | CLS Loss: 0.017040345817804337\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 4.711319923400879 | KNN Loss: 4.69429349899292 | CLS Loss: 0.017026614397764206\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 4.762280464172363 | KNN Loss: 4.735024452209473 | CLS Loss: 0.027255920693278313\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 4.723590850830078 | KNN Loss: 4.708146572113037 | CLS Loss: 0.015444310382008553\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 4.866170406341553 | KNN Loss: 4.829718112945557 | CLS Loss: 0.036452289670705795\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 4.732438087463379 | KNN Loss: 4.7151336669921875 | CLS Loss: 0.017304224893450737\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 4.7652974128723145 | KNN Loss: 4.728154182434082 | CLS Loss: 0.03714308887720108\n",
      "Epoch: 027, Loss: 4.7703, Train: 0.9890, Valid: 0.9838, Best: 0.9849\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 4.757948398590088 | KNN Loss: 4.702454566955566 | CLS Loss: 0.05549390986561775\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 4.8433074951171875 | KNN Loss: 4.758354187011719 | CLS Loss: 0.08495322614908218\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 4.781277656555176 | KNN Loss: 4.753460884094238 | CLS Loss: 0.02781682275235653\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 4.740390300750732 | KNN Loss: 4.725391864776611 | CLS Loss: 0.01499861292541027\n",
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 4.731756687164307 | KNN Loss: 4.70669412612915 | CLS Loss: 0.025062454864382744\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 4.726140975952148 | KNN Loss: 4.691679954528809 | CLS Loss: 0.03446095064282417\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 4.760202884674072 | KNN Loss: 4.7428717613220215 | CLS Loss: 0.017331061884760857\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 4.757901668548584 | KNN Loss: 4.742427825927734 | CLS Loss: 0.01547394972294569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 4.730710506439209 | KNN Loss: 4.704972743988037 | CLS Loss: 0.025737665593624115\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 4.779216289520264 | KNN Loss: 4.721531867980957 | CLS Loss: 0.05768420174717903\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 4.7538347244262695 | KNN Loss: 4.7370758056640625 | CLS Loss: 0.01675872877240181\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 4.785388469696045 | KNN Loss: 4.743839740753174 | CLS Loss: 0.04154874011874199\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 4.747068405151367 | KNN Loss: 4.722784042358398 | CLS Loss: 0.02428451180458069\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 4.732659816741943 | KNN Loss: 4.702388286590576 | CLS Loss: 0.03027172014117241\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 4.778486251831055 | KNN Loss: 4.72112512588501 | CLS Loss: 0.05736112967133522\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 4.752243518829346 | KNN Loss: 4.707546234130859 | CLS Loss: 0.04469715431332588\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 4.793841361999512 | KNN Loss: 4.756338596343994 | CLS Loss: 0.037502776831388474\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 4.752539157867432 | KNN Loss: 4.719935417175293 | CLS Loss: 0.03260382264852524\n",
      "Epoch: 028, Loss: 4.7692, Train: 0.9903, Valid: 0.9846, Best: 0.9849\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 4.7113471031188965 | KNN Loss: 4.692869186401367 | CLS Loss: 0.018477998673915863\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 4.750055313110352 | KNN Loss: 4.698726654052734 | CLS Loss: 0.05132852867245674\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 4.825128078460693 | KNN Loss: 4.766529560089111 | CLS Loss: 0.05859842151403427\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 4.752616882324219 | KNN Loss: 4.703758239746094 | CLS Loss: 0.0488588809967041\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 4.786679267883301 | KNN Loss: 4.741518020629883 | CLS Loss: 0.04516136273741722\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 4.76387882232666 | KNN Loss: 4.72686243057251 | CLS Loss: 0.037016499787569046\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 4.763247966766357 | KNN Loss: 4.743534088134766 | CLS Loss: 0.01971379481256008\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 4.760908603668213 | KNN Loss: 4.72540283203125 | CLS Loss: 0.03550587221980095\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 4.8045501708984375 | KNN Loss: 4.711342811584473 | CLS Loss: 0.09320741891860962\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 4.714247226715088 | KNN Loss: 4.698816299438477 | CLS Loss: 0.01543090958148241\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 4.761227607727051 | KNN Loss: 4.742136001586914 | CLS Loss: 0.019091742113232613\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 4.744680404663086 | KNN Loss: 4.710824966430664 | CLS Loss: 0.03385554626584053\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 4.790463924407959 | KNN Loss: 4.7279253005981445 | CLS Loss: 0.06253847479820251\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 4.77996301651001 | KNN Loss: 4.743378639221191 | CLS Loss: 0.0365845263004303\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 4.775554656982422 | KNN Loss: 4.724478244781494 | CLS Loss: 0.05107664689421654\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 4.784952640533447 | KNN Loss: 4.758023738861084 | CLS Loss: 0.026929089799523354\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 4.778863430023193 | KNN Loss: 4.753918647766113 | CLS Loss: 0.02494477480649948\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 4.757828235626221 | KNN Loss: 4.740734100341797 | CLS Loss: 0.017094120383262634\n",
      "Epoch: 029, Loss: 4.7714, Train: 0.9901, Valid: 0.9838, Best: 0.9849\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 4.780681133270264 | KNN Loss: 4.727746963500977 | CLS Loss: 0.05293438583612442\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 4.76795768737793 | KNN Loss: 4.744109153747559 | CLS Loss: 0.023848438635468483\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 4.788590908050537 | KNN Loss: 4.75153923034668 | CLS Loss: 0.037051722407341\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 4.7371697425842285 | KNN Loss: 4.714229106903076 | CLS Loss: 0.022940758615732193\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 4.833202838897705 | KNN Loss: 4.770038604736328 | CLS Loss: 0.06316428631544113\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 4.743650436401367 | KNN Loss: 4.705220699310303 | CLS Loss: 0.03842950984835625\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 4.758069038391113 | KNN Loss: 4.731480121612549 | CLS Loss: 0.026588696986436844\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 4.719587326049805 | KNN Loss: 4.707481384277344 | CLS Loss: 0.012105833739042282\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 4.724033355712891 | KNN Loss: 4.703307151794434 | CLS Loss: 0.02072630450129509\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 4.816990852355957 | KNN Loss: 4.780172824859619 | CLS Loss: 0.03681797906756401\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 4.7387824058532715 | KNN Loss: 4.7120680809021 | CLS Loss: 0.026714136824011803\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 4.745578765869141 | KNN Loss: 4.72786808013916 | CLS Loss: 0.017710711807012558\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 4.782620906829834 | KNN Loss: 4.738370418548584 | CLS Loss: 0.044250279664993286\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 4.753905773162842 | KNN Loss: 4.737802505493164 | CLS Loss: 0.01610320433974266\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 4.816904544830322 | KNN Loss: 4.773097991943359 | CLS Loss: 0.04380655661225319\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 4.831082820892334 | KNN Loss: 4.773383617401123 | CLS Loss: 0.05769919231534004\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 4.753422260284424 | KNN Loss: 4.714860439300537 | CLS Loss: 0.03856173902750015\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 4.72042989730835 | KNN Loss: 4.695704460144043 | CLS Loss: 0.024725230410695076\n",
      "Epoch: 030, Loss: 4.7703, Train: 0.9916, Valid: 0.9853, Best: 0.9853\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 4.785839080810547 | KNN Loss: 4.757604598999023 | CLS Loss: 0.028234565630555153\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 4.731914043426514 | KNN Loss: 4.704043865203857 | CLS Loss: 0.027870355173945427\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 4.775568008422852 | KNN Loss: 4.740950107574463 | CLS Loss: 0.034618012607097626\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 4.754101276397705 | KNN Loss: 4.717658519744873 | CLS Loss: 0.03644270449876785\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 4.831820011138916 | KNN Loss: 4.79812479019165 | CLS Loss: 0.03369543328881264\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 4.769816875457764 | KNN Loss: 4.712462902069092 | CLS Loss: 0.05735386162996292\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 4.845356464385986 | KNN Loss: 4.780491828918457 | CLS Loss: 0.06486470252275467\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 4.797085285186768 | KNN Loss: 4.735047340393066 | CLS Loss: 0.0620378702878952\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 4.7492852210998535 | KNN Loss: 4.7166242599487305 | CLS Loss: 0.032660964876413345\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 4.751183032989502 | KNN Loss: 4.722084999084473 | CLS Loss: 0.02909787930548191\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 4.804693222045898 | KNN Loss: 4.7330546379089355 | CLS Loss: 0.07163844257593155\n",
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 4.748754978179932 | KNN Loss: 4.730217456817627 | CLS Loss: 0.018537314608693123\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 4.779417037963867 | KNN Loss: 4.749817371368408 | CLS Loss: 0.02959977276623249\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 4.8165740966796875 | KNN Loss: 4.757327556610107 | CLS Loss: 0.05924655497074127\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 4.81398344039917 | KNN Loss: 4.754835605621338 | CLS Loss: 0.05914793163537979\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 4.742939472198486 | KNN Loss: 4.712226390838623 | CLS Loss: 0.030712956562638283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 4.840951442718506 | KNN Loss: 4.79369592666626 | CLS Loss: 0.047255393117666245\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 4.743808269500732 | KNN Loss: 4.709822177886963 | CLS Loss: 0.03398594260215759\n",
      "Epoch: 031, Loss: 4.7682, Train: 0.9895, Valid: 0.9825, Best: 0.9853\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 4.721872806549072 | KNN Loss: 4.705934524536133 | CLS Loss: 0.01593817211687565\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 4.720330715179443 | KNN Loss: 4.706740379333496 | CLS Loss: 0.01359035074710846\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 4.738834381103516 | KNN Loss: 4.711851596832275 | CLS Loss: 0.026982568204402924\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 4.750956058502197 | KNN Loss: 4.713137149810791 | CLS Loss: 0.03781897947192192\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 4.785808563232422 | KNN Loss: 4.730553150177002 | CLS Loss: 0.05525543913245201\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 4.751039028167725 | KNN Loss: 4.717110633850098 | CLS Loss: 0.0339282751083374\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 4.7511210441589355 | KNN Loss: 4.7136335372924805 | CLS Loss: 0.03748757019639015\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 4.748400688171387 | KNN Loss: 4.731344223022461 | CLS Loss: 0.01705624908208847\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 4.753543853759766 | KNN Loss: 4.707339286804199 | CLS Loss: 0.0462043471634388\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 4.738778591156006 | KNN Loss: 4.707402229309082 | CLS Loss: 0.031376246362924576\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 4.760173797607422 | KNN Loss: 4.726666450500488 | CLS Loss: 0.03350750729441643\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 4.759576320648193 | KNN Loss: 4.704853534698486 | CLS Loss: 0.05472268536686897\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 4.766115188598633 | KNN Loss: 4.7098541259765625 | CLS Loss: 0.056260883808135986\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 4.750402450561523 | KNN Loss: 4.6963300704956055 | CLS Loss: 0.054072294384241104\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 4.75877046585083 | KNN Loss: 4.739253520965576 | CLS Loss: 0.01951718144118786\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 4.771724224090576 | KNN Loss: 4.74391508102417 | CLS Loss: 0.02780926413834095\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 4.732207298278809 | KNN Loss: 4.71025276184082 | CLS Loss: 0.021954605355858803\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 4.752556324005127 | KNN Loss: 4.7209625244140625 | CLS Loss: 0.031593918800354004\n",
      "Epoch: 032, Loss: 4.7607, Train: 0.9913, Valid: 0.9857, Best: 0.9857\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 4.7008161544799805 | KNN Loss: 4.678795337677002 | CLS Loss: 0.02202092669904232\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 4.839630126953125 | KNN Loss: 4.792227268218994 | CLS Loss: 0.047402847558259964\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 4.724753379821777 | KNN Loss: 4.707408428192139 | CLS Loss: 0.01734505407512188\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 4.840008735656738 | KNN Loss: 4.7664313316345215 | CLS Loss: 0.07357744872570038\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 4.720885753631592 | KNN Loss: 4.6925835609436035 | CLS Loss: 0.02830231562256813\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 4.75427770614624 | KNN Loss: 4.724729061126709 | CLS Loss: 0.02954852022230625\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 4.722941875457764 | KNN Loss: 4.705321788787842 | CLS Loss: 0.01761988177895546\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 4.752076148986816 | KNN Loss: 4.724605560302734 | CLS Loss: 0.027470551431179047\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 4.749596118927002 | KNN Loss: 4.7192463874816895 | CLS Loss: 0.030349913984537125\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 4.805532455444336 | KNN Loss: 4.752150058746338 | CLS Loss: 0.05338217690587044\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 4.710951328277588 | KNN Loss: 4.681916236877441 | CLS Loss: 0.02903527393937111\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 4.723461151123047 | KNN Loss: 4.707791328430176 | CLS Loss: 0.01566978543996811\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 4.755279541015625 | KNN Loss: 4.731429100036621 | CLS Loss: 0.02385031245648861\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 4.809226036071777 | KNN Loss: 4.776770114898682 | CLS Loss: 0.032455943524837494\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 4.721715450286865 | KNN Loss: 4.707670211791992 | CLS Loss: 0.014045420102775097\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 4.775055408477783 | KNN Loss: 4.753872394561768 | CLS Loss: 0.021183038130402565\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 4.756619930267334 | KNN Loss: 4.698380947113037 | CLS Loss: 0.05823918804526329\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 4.695874214172363 | KNN Loss: 4.671322822570801 | CLS Loss: 0.02455132268369198\n",
      "Epoch: 033, Loss: 4.7547, Train: 0.9924, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 4.722227096557617 | KNN Loss: 4.698521614074707 | CLS Loss: 0.02370569482445717\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 4.739955902099609 | KNN Loss: 4.701427459716797 | CLS Loss: 0.03852861747145653\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 4.780365467071533 | KNN Loss: 4.760897636413574 | CLS Loss: 0.019467832520604134\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 4.729428291320801 | KNN Loss: 4.700753211975098 | CLS Loss: 0.028675181791186333\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 4.766611099243164 | KNN Loss: 4.735660076141357 | CLS Loss: 0.030951064079999924\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 4.809360980987549 | KNN Loss: 4.7637481689453125 | CLS Loss: 0.045612793415784836\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 4.739156246185303 | KNN Loss: 4.714345932006836 | CLS Loss: 0.024810414761304855\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 4.706777572631836 | KNN Loss: 4.675974369049072 | CLS Loss: 0.030803056433796883\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 4.722275257110596 | KNN Loss: 4.713210105895996 | CLS Loss: 0.00906532071530819\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 4.746906757354736 | KNN Loss: 4.692038536071777 | CLS Loss: 0.05486798658967018\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 4.759615421295166 | KNN Loss: 4.727982044219971 | CLS Loss: 0.031633175909519196\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 4.771410942077637 | KNN Loss: 4.7248077392578125 | CLS Loss: 0.04660334065556526\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 4.738589286804199 | KNN Loss: 4.719533920288086 | CLS Loss: 0.01905524730682373\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 4.779995918273926 | KNN Loss: 4.728056907653809 | CLS Loss: 0.05193880572915077\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 4.735345363616943 | KNN Loss: 4.712893486022949 | CLS Loss: 0.022451935335993767\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 4.8087849617004395 | KNN Loss: 4.751640796661377 | CLS Loss: 0.05714404210448265\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 4.8201398849487305 | KNN Loss: 4.800179958343506 | CLS Loss: 0.01996004953980446\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 4.817798614501953 | KNN Loss: 4.777525424957275 | CLS Loss: 0.040273357182741165\n",
      "Epoch: 034, Loss: 4.7515, Train: 0.9893, Valid: 0.9843, Best: 0.9867\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 4.760284900665283 | KNN Loss: 4.7200188636779785 | CLS Loss: 0.040266022086143494\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 4.759838581085205 | KNN Loss: 4.717294692993164 | CLS Loss: 0.042544055730104446\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 4.737427711486816 | KNN Loss: 4.704623699188232 | CLS Loss: 0.03280424699187279\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 4.814281463623047 | KNN Loss: 4.721312522888184 | CLS Loss: 0.09296915680170059\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 4.727662563323975 | KNN Loss: 4.703939437866211 | CLS Loss: 0.02372334897518158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 4.700842380523682 | KNN Loss: 4.680301666259766 | CLS Loss: 0.02054055780172348\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 4.737159729003906 | KNN Loss: 4.709205627441406 | CLS Loss: 0.02795402705669403\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 4.711860656738281 | KNN Loss: 4.683170795440674 | CLS Loss: 0.028689643368124962\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 4.7458038330078125 | KNN Loss: 4.719736576080322 | CLS Loss: 0.026067135855555534\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 4.756103038787842 | KNN Loss: 4.717801094055176 | CLS Loss: 0.03830195218324661\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 4.7588791847229 | KNN Loss: 4.689006328582764 | CLS Loss: 0.06987293064594269\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 4.735707759857178 | KNN Loss: 4.706620216369629 | CLS Loss: 0.029087338596582413\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 4.830999851226807 | KNN Loss: 4.750068664550781 | CLS Loss: 0.08093099296092987\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 4.737681865692139 | KNN Loss: 4.711771011352539 | CLS Loss: 0.025910740718245506\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 4.814063549041748 | KNN Loss: 4.763948917388916 | CLS Loss: 0.05011468008160591\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 4.7620439529418945 | KNN Loss: 4.728655815124512 | CLS Loss: 0.03338824212551117\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 4.7407450675964355 | KNN Loss: 4.713365077972412 | CLS Loss: 0.027380019426345825\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 4.806093215942383 | KNN Loss: 4.789924621582031 | CLS Loss: 0.016168510541319847\n",
      "Epoch: 035, Loss: 4.7531, Train: 0.9914, Valid: 0.9857, Best: 0.9867\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 4.721315383911133 | KNN Loss: 4.711705684661865 | CLS Loss: 0.009609545581042767\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 4.7234015464782715 | KNN Loss: 4.707455635070801 | CLS Loss: 0.015946010127663612\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 4.739333152770996 | KNN Loss: 4.723623275756836 | CLS Loss: 0.015709733590483665\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 4.803077220916748 | KNN Loss: 4.756387233734131 | CLS Loss: 0.04668987914919853\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 4.74400520324707 | KNN Loss: 4.71289587020874 | CLS Loss: 0.031109387055039406\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 4.745830059051514 | KNN Loss: 4.73351526260376 | CLS Loss: 0.012314899824559689\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 4.735875606536865 | KNN Loss: 4.723418235778809 | CLS Loss: 0.012457323260605335\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 4.744272708892822 | KNN Loss: 4.726449489593506 | CLS Loss: 0.017823275178670883\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 4.8004608154296875 | KNN Loss: 4.77642822265625 | CLS Loss: 0.024032682180404663\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 4.71433687210083 | KNN Loss: 4.680941104888916 | CLS Loss: 0.033395811915397644\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 4.744663238525391 | KNN Loss: 4.719554424285889 | CLS Loss: 0.02510857582092285\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 4.7632832527160645 | KNN Loss: 4.7136664390563965 | CLS Loss: 0.049616679549217224\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 4.787947177886963 | KNN Loss: 4.7533674240112305 | CLS Loss: 0.034579966217279434\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 4.788180828094482 | KNN Loss: 4.755814552307129 | CLS Loss: 0.03236639127135277\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 4.706606388092041 | KNN Loss: 4.65999698638916 | CLS Loss: 0.046609196811914444\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 4.726377010345459 | KNN Loss: 4.691956996917725 | CLS Loss: 0.03442007675766945\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 4.755241870880127 | KNN Loss: 4.683312892913818 | CLS Loss: 0.07192885875701904\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 4.733835697174072 | KNN Loss: 4.7022881507873535 | CLS Loss: 0.031547661870718\n",
      "Epoch: 036, Loss: 4.7575, Train: 0.9926, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 4.709944248199463 | KNN Loss: 4.6928019523620605 | CLS Loss: 0.01714244857430458\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 4.737994194030762 | KNN Loss: 4.711813449859619 | CLS Loss: 0.026180850341916084\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 4.67156457901001 | KNN Loss: 4.655426502227783 | CLS Loss: 0.016138125211000443\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 4.772436618804932 | KNN Loss: 4.731250286102295 | CLS Loss: 0.04118620976805687\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 4.724448204040527 | KNN Loss: 4.699357986450195 | CLS Loss: 0.025090139359235764\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 4.716276168823242 | KNN Loss: 4.697316646575928 | CLS Loss: 0.01895955018699169\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 4.750192642211914 | KNN Loss: 4.7185282707214355 | CLS Loss: 0.031664397567510605\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 4.789454460144043 | KNN Loss: 4.748458385467529 | CLS Loss: 0.04099629446864128\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 4.740668773651123 | KNN Loss: 4.725672721862793 | CLS Loss: 0.014996269717812538\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 4.742434978485107 | KNN Loss: 4.71804666519165 | CLS Loss: 0.024388166144490242\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 4.749959945678711 | KNN Loss: 4.71241569519043 | CLS Loss: 0.03754441812634468\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 4.746081352233887 | KNN Loss: 4.705935001373291 | CLS Loss: 0.04014616459608078\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 4.7452592849731445 | KNN Loss: 4.700826168060303 | CLS Loss: 0.044433169066905975\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 4.740302562713623 | KNN Loss: 4.693026542663574 | CLS Loss: 0.047276027500629425\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 4.815896511077881 | KNN Loss: 4.752618789672852 | CLS Loss: 0.06327793747186661\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 4.767068862915039 | KNN Loss: 4.737386226654053 | CLS Loss: 0.0296828243881464\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 4.756833076477051 | KNN Loss: 4.711480140686035 | CLS Loss: 0.04535289853811264\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 4.738504409790039 | KNN Loss: 4.693211555480957 | CLS Loss: 0.0452926941215992\n",
      "Epoch: 037, Loss: 4.7446, Train: 0.9907, Valid: 0.9833, Best: 0.9867\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 4.69650936126709 | KNN Loss: 4.678818225860596 | CLS Loss: 0.017690910026431084\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 4.816657066345215 | KNN Loss: 4.788207530975342 | CLS Loss: 0.028449608013033867\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 4.718055248260498 | KNN Loss: 4.707696914672852 | CLS Loss: 0.010358470492064953\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 4.791599273681641 | KNN Loss: 4.772444248199463 | CLS Loss: 0.01915525272488594\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 4.718634605407715 | KNN Loss: 4.708779811859131 | CLS Loss: 0.009855018928647041\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 4.777681827545166 | KNN Loss: 4.7668657302856445 | CLS Loss: 0.010816062800586224\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 4.674324035644531 | KNN Loss: 4.664133548736572 | CLS Loss: 0.01019064150750637\n",
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 4.733409881591797 | KNN Loss: 4.696029186248779 | CLS Loss: 0.037380561232566833\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 4.7022552490234375 | KNN Loss: 4.690567493438721 | CLS Loss: 0.011687520891427994\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 4.821727752685547 | KNN Loss: 4.779397487640381 | CLS Loss: 0.042330287396907806\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 4.746328830718994 | KNN Loss: 4.729547023773193 | CLS Loss: 0.01678185537457466\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 4.767889022827148 | KNN Loss: 4.754177093505859 | CLS Loss: 0.013711903244256973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 4.713037967681885 | KNN Loss: 4.689632892608643 | CLS Loss: 0.023405276238918304\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 4.751391887664795 | KNN Loss: 4.716283798217773 | CLS Loss: 0.03510820120573044\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 4.694932460784912 | KNN Loss: 4.67671537399292 | CLS Loss: 0.018217025324702263\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 4.746928691864014 | KNN Loss: 4.712491035461426 | CLS Loss: 0.034437861293554306\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 4.736726760864258 | KNN Loss: 4.712124347686768 | CLS Loss: 0.02460247464478016\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 4.77501106262207 | KNN Loss: 4.7244062423706055 | CLS Loss: 0.050604984164237976\n",
      "Epoch: 038, Loss: 4.7470, Train: 0.9926, Valid: 0.9859, Best: 0.9867\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 4.799773693084717 | KNN Loss: 4.779982089996338 | CLS Loss: 0.019791459664702415\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 4.738837718963623 | KNN Loss: 4.6862897872924805 | CLS Loss: 0.05254810303449631\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 4.756690502166748 | KNN Loss: 4.735815048217773 | CLS Loss: 0.020875418558716774\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 4.752580165863037 | KNN Loss: 4.741298675537109 | CLS Loss: 0.011281592771410942\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 4.741652488708496 | KNN Loss: 4.727827072143555 | CLS Loss: 0.013825243338942528\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 4.757612705230713 | KNN Loss: 4.744636535644531 | CLS Loss: 0.012976151891052723\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 4.761058807373047 | KNN Loss: 4.745538711547852 | CLS Loss: 0.01552030723541975\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 4.764683723449707 | KNN Loss: 4.741345405578613 | CLS Loss: 0.02333815023303032\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 4.763615608215332 | KNN Loss: 4.740863800048828 | CLS Loss: 0.02275202050805092\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 4.7220258712768555 | KNN Loss: 4.682246685028076 | CLS Loss: 0.03977910429239273\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 4.769439697265625 | KNN Loss: 4.727096080780029 | CLS Loss: 0.04234357178211212\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 4.72139835357666 | KNN Loss: 4.704340934753418 | CLS Loss: 0.01705743744969368\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 4.6776580810546875 | KNN Loss: 4.657708168029785 | CLS Loss: 0.01994977705180645\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 4.6992340087890625 | KNN Loss: 4.6798624992370605 | CLS Loss: 0.019371701404452324\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 4.7289042472839355 | KNN Loss: 4.682782173156738 | CLS Loss: 0.04612213745713234\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 4.704100608825684 | KNN Loss: 4.68897819519043 | CLS Loss: 0.015122261829674244\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 4.797544002532959 | KNN Loss: 4.743685722351074 | CLS Loss: 0.05385832488536835\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 4.751809120178223 | KNN Loss: 4.712772369384766 | CLS Loss: 0.039036720991134644\n",
      "Epoch: 039, Loss: 4.7443, Train: 0.9919, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 4.763040542602539 | KNN Loss: 4.728716850280762 | CLS Loss: 0.034323472529649734\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 4.755451202392578 | KNN Loss: 4.729835510253906 | CLS Loss: 0.025615649297833443\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 4.80647087097168 | KNN Loss: 4.745335578918457 | CLS Loss: 0.061135124415159225\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 4.7442827224731445 | KNN Loss: 4.7081499099731445 | CLS Loss: 0.036132585257291794\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 4.698427677154541 | KNN Loss: 4.689480304718018 | CLS Loss: 0.008947154507040977\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 4.720817565917969 | KNN Loss: 4.702225685119629 | CLS Loss: 0.01859188638627529\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 4.749459266662598 | KNN Loss: 4.706754207611084 | CLS Loss: 0.042704857885837555\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 4.791529655456543 | KNN Loss: 4.766101360321045 | CLS Loss: 0.02542838640511036\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 4.853095531463623 | KNN Loss: 4.815909385681152 | CLS Loss: 0.03718610480427742\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 4.767688751220703 | KNN Loss: 4.70475959777832 | CLS Loss: 0.06292925029993057\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 4.723038196563721 | KNN Loss: 4.694382667541504 | CLS Loss: 0.02865535393357277\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 4.787493705749512 | KNN Loss: 4.742702960968018 | CLS Loss: 0.044790901243686676\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 4.742377758026123 | KNN Loss: 4.715132713317871 | CLS Loss: 0.027245262637734413\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 4.745048522949219 | KNN Loss: 4.7169671058654785 | CLS Loss: 0.028081528842449188\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 4.7311553955078125 | KNN Loss: 4.7117533683776855 | CLS Loss: 0.019402053207159042\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 4.788837909698486 | KNN Loss: 4.728227615356445 | CLS Loss: 0.060610514134168625\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 4.690335750579834 | KNN Loss: 4.678438186645508 | CLS Loss: 0.011897683143615723\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 4.698810577392578 | KNN Loss: 4.684749126434326 | CLS Loss: 0.014061635360121727\n",
      "Epoch: 040, Loss: 4.7523, Train: 0.9936, Valid: 0.9866, Best: 0.9867\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 4.816495895385742 | KNN Loss: 4.775348663330078 | CLS Loss: 0.04114733263850212\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 4.819350242614746 | KNN Loss: 4.7863006591796875 | CLS Loss: 0.03304964303970337\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 4.738858699798584 | KNN Loss: 4.699764251708984 | CLS Loss: 0.03909454494714737\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 4.744373321533203 | KNN Loss: 4.697750091552734 | CLS Loss: 0.046623345464468\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 4.7277326583862305 | KNN Loss: 4.712700366973877 | CLS Loss: 0.015032474882900715\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 4.700389862060547 | KNN Loss: 4.667981147766113 | CLS Loss: 0.03240884467959404\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 4.87047815322876 | KNN Loss: 4.851749897003174 | CLS Loss: 0.018728338181972504\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 4.740447044372559 | KNN Loss: 4.705711364746094 | CLS Loss: 0.034735508263111115\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 4.737469673156738 | KNN Loss: 4.716047763824463 | CLS Loss: 0.021421855315566063\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 4.76547908782959 | KNN Loss: 4.7292304039001465 | CLS Loss: 0.0362485870718956\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 4.793598175048828 | KNN Loss: 4.759761333465576 | CLS Loss: 0.03383660316467285\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 4.727015018463135 | KNN Loss: 4.7068681716918945 | CLS Loss: 0.0201468076556921\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 4.69991397857666 | KNN Loss: 4.685001373291016 | CLS Loss: 0.014912757091224194\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 4.751241683959961 | KNN Loss: 4.718572616577148 | CLS Loss: 0.03266900032758713\n",
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 4.733550071716309 | KNN Loss: 4.724221706390381 | CLS Loss: 0.009328372776508331\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 4.723091125488281 | KNN Loss: 4.695346832275391 | CLS Loss: 0.02774450182914734\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 4.708445072174072 | KNN Loss: 4.676393032073975 | CLS Loss: 0.0320519357919693\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 4.748176574707031 | KNN Loss: 4.727071762084961 | CLS Loss: 0.02110496535897255\n",
      "Epoch: 041, Loss: 4.7452, Train: 0.9925, Valid: 0.9858, Best: 0.9867\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 4.7489752769470215 | KNN Loss: 4.717462062835693 | CLS Loss: 0.03151317685842514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 4.7694091796875 | KNN Loss: 4.7399725914001465 | CLS Loss: 0.02943648211658001\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 4.7939910888671875 | KNN Loss: 4.761270523071289 | CLS Loss: 0.03272048756480217\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 4.7398552894592285 | KNN Loss: 4.7179951667785645 | CLS Loss: 0.021860260516405106\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 4.777414798736572 | KNN Loss: 4.743305206298828 | CLS Loss: 0.03410957753658295\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 4.741176605224609 | KNN Loss: 4.699720859527588 | CLS Loss: 0.04145575314760208\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 4.72554349899292 | KNN Loss: 4.714349746704102 | CLS Loss: 0.01119384914636612\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 4.761524200439453 | KNN Loss: 4.734308242797852 | CLS Loss: 0.027216162532567978\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 4.751012325286865 | KNN Loss: 4.724146842956543 | CLS Loss: 0.026865607127547264\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 4.776650905609131 | KNN Loss: 4.750917911529541 | CLS Loss: 0.025733105838298798\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 4.761189937591553 | KNN Loss: 4.729462146759033 | CLS Loss: 0.031728003174066544\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 4.7203826904296875 | KNN Loss: 4.698122501373291 | CLS Loss: 0.022260235622525215\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 4.748823642730713 | KNN Loss: 4.7187581062316895 | CLS Loss: 0.030065299943089485\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 4.8446526527404785 | KNN Loss: 4.792273044586182 | CLS Loss: 0.05237974971532822\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 4.724611282348633 | KNN Loss: 4.698714256286621 | CLS Loss: 0.0258971955627203\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 4.752319812774658 | KNN Loss: 4.7182793617248535 | CLS Loss: 0.03404056653380394\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 4.729959964752197 | KNN Loss: 4.71545934677124 | CLS Loss: 0.014500437304377556\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 4.745242595672607 | KNN Loss: 4.686964988708496 | CLS Loss: 0.058277677744627\n",
      "Epoch: 042, Loss: 4.7512, Train: 0.9916, Valid: 0.9846, Best: 0.9867\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 4.738157749176025 | KNN Loss: 4.714737892150879 | CLS Loss: 0.023419858887791634\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 4.741006851196289 | KNN Loss: 4.714555263519287 | CLS Loss: 0.02645178884267807\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 4.720179557800293 | KNN Loss: 4.6920390129089355 | CLS Loss: 0.028140584006905556\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 4.677806854248047 | KNN Loss: 4.661920070648193 | CLS Loss: 0.015886982902884483\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 4.797456741333008 | KNN Loss: 4.774541854858398 | CLS Loss: 0.022914892062544823\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 4.685452938079834 | KNN Loss: 4.680261135101318 | CLS Loss: 0.005191875621676445\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 4.703044414520264 | KNN Loss: 4.682020664215088 | CLS Loss: 0.02102372795343399\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 4.736025333404541 | KNN Loss: 4.704880714416504 | CLS Loss: 0.031144658103585243\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 4.820252418518066 | KNN Loss: 4.790833950042725 | CLS Loss: 0.029418619349598885\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 4.737363338470459 | KNN Loss: 4.711134433746338 | CLS Loss: 0.026228753849864006\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 4.7875075340271 | KNN Loss: 4.746720790863037 | CLS Loss: 0.04078663885593414\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 4.7389068603515625 | KNN Loss: 4.699540138244629 | CLS Loss: 0.0393667072057724\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 4.796229362487793 | KNN Loss: 4.76689338684082 | CLS Loss: 0.02933582477271557\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 4.706083297729492 | KNN Loss: 4.691997528076172 | CLS Loss: 0.01408553309738636\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 4.753340244293213 | KNN Loss: 4.729203224182129 | CLS Loss: 0.024136846885085106\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 4.738316059112549 | KNN Loss: 4.713997840881348 | CLS Loss: 0.024318333715200424\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 4.7255072593688965 | KNN Loss: 4.694249153137207 | CLS Loss: 0.031258247792720795\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 4.825520992279053 | KNN Loss: 4.805845260620117 | CLS Loss: 0.0196758471429348\n",
      "Epoch: 043, Loss: 4.7394, Train: 0.9908, Valid: 0.9837, Best: 0.9867\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 4.696964263916016 | KNN Loss: 4.676679611206055 | CLS Loss: 0.020284492522478104\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 4.780097961425781 | KNN Loss: 4.727957248687744 | CLS Loss: 0.05214056745171547\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 4.742915153503418 | KNN Loss: 4.7101826667785645 | CLS Loss: 0.03273263946175575\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 4.740855693817139 | KNN Loss: 4.714084148406982 | CLS Loss: 0.02677144855260849\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 4.784066677093506 | KNN Loss: 4.769886016845703 | CLS Loss: 0.014180871658027172\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 4.861885070800781 | KNN Loss: 4.829708576202393 | CLS Loss: 0.032176580280065536\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 4.707146167755127 | KNN Loss: 4.690206527709961 | CLS Loss: 0.016939634457230568\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 4.786218643188477 | KNN Loss: 4.7361016273498535 | CLS Loss: 0.05011685565114021\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 4.733616352081299 | KNN Loss: 4.699885368347168 | CLS Loss: 0.03373078629374504\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 4.769984722137451 | KNN Loss: 4.749738693237305 | CLS Loss: 0.020245829597115517\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 4.816531181335449 | KNN Loss: 4.778264045715332 | CLS Loss: 0.03826713562011719\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 4.774970054626465 | KNN Loss: 4.750924587249756 | CLS Loss: 0.024045320227742195\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 4.725180625915527 | KNN Loss: 4.710906982421875 | CLS Loss: 0.014273563399910927\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 4.698141574859619 | KNN Loss: 4.686380863189697 | CLS Loss: 0.011760810390114784\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 4.778919696807861 | KNN Loss: 4.750293254852295 | CLS Loss: 0.028626224026083946\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 4.729987144470215 | KNN Loss: 4.710811138153076 | CLS Loss: 0.019176045432686806\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 4.744150161743164 | KNN Loss: 4.720029830932617 | CLS Loss: 0.02412034198641777\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 4.7868523597717285 | KNN Loss: 4.755804538726807 | CLS Loss: 0.031047744676470757\n",
      "Epoch: 044, Loss: 4.7449, Train: 0.9928, Valid: 0.9861, Best: 0.9867\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 4.73794412612915 | KNN Loss: 4.713421821594238 | CLS Loss: 0.02452215552330017\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 4.687953948974609 | KNN Loss: 4.674338340759277 | CLS Loss: 0.013615514151751995\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 4.761998176574707 | KNN Loss: 4.714252471923828 | CLS Loss: 0.04774583503603935\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 4.813689708709717 | KNN Loss: 4.772232532501221 | CLS Loss: 0.04145735502243042\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 4.807949066162109 | KNN Loss: 4.780088901519775 | CLS Loss: 0.027860401198267937\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 4.736930847167969 | KNN Loss: 4.71253776550293 | CLS Loss: 0.02439323626458645\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 4.76234245300293 | KNN Loss: 4.716372966766357 | CLS Loss: 0.045969486236572266\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 4.7074294090271 | KNN Loss: 4.677417278289795 | CLS Loss: 0.03001195751130581\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 4.733388900756836 | KNN Loss: 4.698356628417969 | CLS Loss: 0.03503209352493286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 4.71081018447876 | KNN Loss: 4.675663471221924 | CLS Loss: 0.035146936774253845\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 4.6789398193359375 | KNN Loss: 4.656825542449951 | CLS Loss: 0.022114157676696777\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 4.75437068939209 | KNN Loss: 4.711879730224609 | CLS Loss: 0.042490795254707336\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 4.693910121917725 | KNN Loss: 4.659311771392822 | CLS Loss: 0.034598369151353836\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 4.746001243591309 | KNN Loss: 4.6951422691345215 | CLS Loss: 0.05085901916027069\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 4.746581077575684 | KNN Loss: 4.719237804412842 | CLS Loss: 0.027343420311808586\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 4.788656711578369 | KNN Loss: 4.731900215148926 | CLS Loss: 0.05675647035241127\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 4.721305847167969 | KNN Loss: 4.700737953186035 | CLS Loss: 0.020567940548062325\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 4.790247917175293 | KNN Loss: 4.748317241668701 | CLS Loss: 0.04193057864904404\n",
      "Epoch: 045, Loss: 4.7386, Train: 0.9936, Valid: 0.9863, Best: 0.9867\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 4.717104911804199 | KNN Loss: 4.706617832183838 | CLS Loss: 0.010487097315490246\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 4.730050086975098 | KNN Loss: 4.708120822906494 | CLS Loss: 0.02192944847047329\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 4.713730812072754 | KNN Loss: 4.685704231262207 | CLS Loss: 0.028026537969708443\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 4.702364921569824 | KNN Loss: 4.689013481140137 | CLS Loss: 0.013351292349398136\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 4.80708122253418 | KNN Loss: 4.772276878356934 | CLS Loss: 0.03480416536331177\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 4.857758045196533 | KNN Loss: 4.832250595092773 | CLS Loss: 0.025507386773824692\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 4.7607035636901855 | KNN Loss: 4.758125305175781 | CLS Loss: 0.0025780831929296255\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 4.791407585144043 | KNN Loss: 4.749730110168457 | CLS Loss: 0.04167729616165161\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 4.7929463386535645 | KNN Loss: 4.755631923675537 | CLS Loss: 0.03731418773531914\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 4.716857433319092 | KNN Loss: 4.694181442260742 | CLS Loss: 0.022675760090351105\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 4.696717739105225 | KNN Loss: 4.684343338012695 | CLS Loss: 0.01237436756491661\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 4.711595058441162 | KNN Loss: 4.700312614440918 | CLS Loss: 0.011282367631793022\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 4.766570568084717 | KNN Loss: 4.730781078338623 | CLS Loss: 0.03578929975628853\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 4.802361488342285 | KNN Loss: 4.784066677093506 | CLS Loss: 0.01829475723206997\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 4.719262599945068 | KNN Loss: 4.7004218101501465 | CLS Loss: 0.01884082891047001\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 4.8248724937438965 | KNN Loss: 4.762209415435791 | CLS Loss: 0.06266306340694427\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 4.710613250732422 | KNN Loss: 4.686033248901367 | CLS Loss: 0.024580132216215134\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 4.745640754699707 | KNN Loss: 4.7344183921813965 | CLS Loss: 0.011222419328987598\n",
      "Epoch: 046, Loss: 4.7372, Train: 0.9933, Valid: 0.9855, Best: 0.9867\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 4.705221652984619 | KNN Loss: 4.679410457611084 | CLS Loss: 0.0258113332092762\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 4.748215198516846 | KNN Loss: 4.725978374481201 | CLS Loss: 0.022236637771129608\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 4.773707389831543 | KNN Loss: 4.741481781005859 | CLS Loss: 0.03222550079226494\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 4.790730953216553 | KNN Loss: 4.738720893859863 | CLS Loss: 0.05201004818081856\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 4.717543601989746 | KNN Loss: 4.6938347816467285 | CLS Loss: 0.02370884083211422\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 4.829456329345703 | KNN Loss: 4.791620254516602 | CLS Loss: 0.0378362238407135\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 4.865546703338623 | KNN Loss: 4.8230509757995605 | CLS Loss: 0.042495641857385635\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 4.745748996734619 | KNN Loss: 4.70640230178833 | CLS Loss: 0.039346516132354736\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 4.7069783210754395 | KNN Loss: 4.70226526260376 | CLS Loss: 0.004712941125035286\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 4.7303643226623535 | KNN Loss: 4.694273471832275 | CLS Loss: 0.036090679466724396\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 4.736961364746094 | KNN Loss: 4.718970775604248 | CLS Loss: 0.01799062080681324\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 4.740637302398682 | KNN Loss: 4.70107364654541 | CLS Loss: 0.03956349194049835\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 4.711781024932861 | KNN Loss: 4.696789741516113 | CLS Loss: 0.014991292729973793\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 4.718156337738037 | KNN Loss: 4.690802097320557 | CLS Loss: 0.02735407091677189\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 4.770829677581787 | KNN Loss: 4.742140769958496 | CLS Loss: 0.02868887037038803\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 4.778447151184082 | KNN Loss: 4.743053913116455 | CLS Loss: 0.03539314493536949\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 4.707566261291504 | KNN Loss: 4.689142227172852 | CLS Loss: 0.018424004316329956\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 4.737550258636475 | KNN Loss: 4.689573764801025 | CLS Loss: 0.04797670990228653\n",
      "Epoch: 047, Loss: 4.7456, Train: 0.9935, Valid: 0.9865, Best: 0.9867\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 4.762048721313477 | KNN Loss: 4.7440290451049805 | CLS Loss: 0.018019530922174454\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 4.699926376342773 | KNN Loss: 4.692939281463623 | CLS Loss: 0.006987190339714289\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 4.73724889755249 | KNN Loss: 4.714348793029785 | CLS Loss: 0.02289990521967411\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 4.734233379364014 | KNN Loss: 4.6800408363342285 | CLS Loss: 0.0541926734149456\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 4.740565776824951 | KNN Loss: 4.7203521728515625 | CLS Loss: 0.02021363005042076\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 4.778177738189697 | KNN Loss: 4.739241600036621 | CLS Loss: 0.03893632814288139\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 4.709646701812744 | KNN Loss: 4.6883864402771 | CLS Loss: 0.021260440349578857\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 4.718855381011963 | KNN Loss: 4.706327438354492 | CLS Loss: 0.012528168968856335\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 4.707752704620361 | KNN Loss: 4.701019763946533 | CLS Loss: 0.006733025424182415\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 4.704471111297607 | KNN Loss: 4.691603660583496 | CLS Loss: 0.012867671437561512\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 4.738478660583496 | KNN Loss: 4.691535472869873 | CLS Loss: 0.046943001449108124\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 4.780816078186035 | KNN Loss: 4.754079341888428 | CLS Loss: 0.026736745610833168\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 4.7397236824035645 | KNN Loss: 4.716846942901611 | CLS Loss: 0.022876517847180367\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 4.75386381149292 | KNN Loss: 4.724509239196777 | CLS Loss: 0.029354708269238472\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 4.762268543243408 | KNN Loss: 4.735571384429932 | CLS Loss: 0.026697255671024323\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 4.798233509063721 | KNN Loss: 4.76120662689209 | CLS Loss: 0.037026677280664444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 4.759403228759766 | KNN Loss: 4.7245988845825195 | CLS Loss: 0.03480418026447296\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 4.73067569732666 | KNN Loss: 4.710829257965088 | CLS Loss: 0.019846387207508087\n",
      "Epoch: 048, Loss: 4.7346, Train: 0.9928, Valid: 0.9859, Best: 0.9867\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 4.797367572784424 | KNN Loss: 4.741666316986084 | CLS Loss: 0.0557011179625988\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 4.736055850982666 | KNN Loss: 4.71439266204834 | CLS Loss: 0.021662971004843712\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 4.74731969833374 | KNN Loss: 4.733874320983887 | CLS Loss: 0.013445189222693443\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 4.721357345581055 | KNN Loss: 4.709593296051025 | CLS Loss: 0.011764280498027802\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 4.727178573608398 | KNN Loss: 4.701723575592041 | CLS Loss: 0.025454789400100708\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 4.8407883644104 | KNN Loss: 4.797967433929443 | CLS Loss: 0.04282113537192345\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 4.75508975982666 | KNN Loss: 4.70380163192749 | CLS Loss: 0.05128819867968559\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 4.734677791595459 | KNN Loss: 4.693177223205566 | CLS Loss: 0.04150036722421646\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 4.688915252685547 | KNN Loss: 4.6730146408081055 | CLS Loss: 0.015900535508990288\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 4.723042964935303 | KNN Loss: 4.697855472564697 | CLS Loss: 0.02518736757338047\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 4.707818031311035 | KNN Loss: 4.6875200271606445 | CLS Loss: 0.020297784358263016\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 4.737664222717285 | KNN Loss: 4.687707901000977 | CLS Loss: 0.0499565489590168\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 4.682632923126221 | KNN Loss: 4.64943790435791 | CLS Loss: 0.03319484740495682\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 4.734997272491455 | KNN Loss: 4.71113920211792 | CLS Loss: 0.023857837542891502\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 4.770733833312988 | KNN Loss: 4.721983909606934 | CLS Loss: 0.048750139772892\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 4.712846279144287 | KNN Loss: 4.703192710876465 | CLS Loss: 0.00965355709195137\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 4.723693370819092 | KNN Loss: 4.6953349113464355 | CLS Loss: 0.028358619660139084\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 4.74817419052124 | KNN Loss: 4.725293159484863 | CLS Loss: 0.022881081327795982\n",
      "Epoch: 049, Loss: 4.7449, Train: 0.9922, Valid: 0.9843, Best: 0.9867\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 4.720889091491699 | KNN Loss: 4.683671474456787 | CLS Loss: 0.037217773497104645\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 4.744227886199951 | KNN Loss: 4.713895797729492 | CLS Loss: 0.030332284048199654\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 4.733603000640869 | KNN Loss: 4.701054096221924 | CLS Loss: 0.03254913538694382\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 4.740961074829102 | KNN Loss: 4.701870441436768 | CLS Loss: 0.039090439677238464\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 4.727738380432129 | KNN Loss: 4.709131240844727 | CLS Loss: 0.018606912344694138\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 4.682104110717773 | KNN Loss: 4.668379306793213 | CLS Loss: 0.013724950142204762\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 4.689446926116943 | KNN Loss: 4.680107116699219 | CLS Loss: 0.009339993819594383\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 4.7262444496154785 | KNN Loss: 4.712794303894043 | CLS Loss: 0.013450167141854763\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 4.709346771240234 | KNN Loss: 4.685772895812988 | CLS Loss: 0.023573877289891243\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 4.719247817993164 | KNN Loss: 4.691397666931152 | CLS Loss: 0.027850328013300896\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 4.7158098220825195 | KNN Loss: 4.704869270324707 | CLS Loss: 0.01094054989516735\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 4.766829967498779 | KNN Loss: 4.741766929626465 | CLS Loss: 0.025063257664442062\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 4.713305473327637 | KNN Loss: 4.693500995635986 | CLS Loss: 0.01980430632829666\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 4.724064826965332 | KNN Loss: 4.705652713775635 | CLS Loss: 0.018412312492728233\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 4.706287384033203 | KNN Loss: 4.698058128356934 | CLS Loss: 0.008229262195527554\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 4.6760711669921875 | KNN Loss: 4.666423320770264 | CLS Loss: 0.009648076258599758\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 4.722148418426514 | KNN Loss: 4.687550067901611 | CLS Loss: 0.03459835797548294\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 4.841832160949707 | KNN Loss: 4.8144049644470215 | CLS Loss: 0.02742735482752323\n",
      "Epoch: 050, Loss: 4.7374, Train: 0.9926, Valid: 0.9866, Best: 0.9867\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 4.7346510887146 | KNN Loss: 4.719356060028076 | CLS Loss: 0.015295066870748997\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 4.70538854598999 | KNN Loss: 4.695018768310547 | CLS Loss: 0.010369827970862389\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 4.731358051300049 | KNN Loss: 4.700908660888672 | CLS Loss: 0.030449556186795235\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 4.738186359405518 | KNN Loss: 4.690792560577393 | CLS Loss: 0.04739363119006157\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 4.712358474731445 | KNN Loss: 4.6830549240112305 | CLS Loss: 0.029303686693310738\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 4.727991580963135 | KNN Loss: 4.683687210083008 | CLS Loss: 0.044304464012384415\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 4.824591636657715 | KNN Loss: 4.767322540283203 | CLS Loss: 0.05726933106780052\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 4.712979316711426 | KNN Loss: 4.684622764587402 | CLS Loss: 0.028356321156024933\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 4.781252384185791 | KNN Loss: 4.746070861816406 | CLS Loss: 0.0351816862821579\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 4.7695393562316895 | KNN Loss: 4.745330810546875 | CLS Loss: 0.02420840971171856\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 4.7567524909973145 | KNN Loss: 4.7137603759765625 | CLS Loss: 0.04299195110797882\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 4.7148942947387695 | KNN Loss: 4.69804048538208 | CLS Loss: 0.016853787004947662\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 4.7053961753845215 | KNN Loss: 4.688500881195068 | CLS Loss: 0.016895301640033722\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 4.821662902832031 | KNN Loss: 4.761155128479004 | CLS Loss: 0.06050761044025421\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 4.7584614753723145 | KNN Loss: 4.749385356903076 | CLS Loss: 0.009076160378754139\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 4.745556354522705 | KNN Loss: 4.716811180114746 | CLS Loss: 0.028744978830218315\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 4.690470218658447 | KNN Loss: 4.669861316680908 | CLS Loss: 0.02060876041650772\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 4.7219953536987305 | KNN Loss: 4.698283672332764 | CLS Loss: 0.02371167577803135\n",
      "Epoch: 051, Loss: 4.7451, Train: 0.9921, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 4.773525238037109 | KNN Loss: 4.746399402618408 | CLS Loss: 0.02712593600153923\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 4.804196834564209 | KNN Loss: 4.780511856079102 | CLS Loss: 0.02368520386517048\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 4.705633640289307 | KNN Loss: 4.685884475708008 | CLS Loss: 0.01974908635020256\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 4.699953556060791 | KNN Loss: 4.687516212463379 | CLS Loss: 0.012437192723155022\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 4.796695232391357 | KNN Loss: 4.770347595214844 | CLS Loss: 0.026347680017352104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 4.663251876831055 | KNN Loss: 4.649634838104248 | CLS Loss: 0.01361693162471056\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 4.717588424682617 | KNN Loss: 4.658873558044434 | CLS Loss: 0.05871477350592613\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 4.707067489624023 | KNN Loss: 4.6723713874816895 | CLS Loss: 0.03469623997807503\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 4.768733501434326 | KNN Loss: 4.719743251800537 | CLS Loss: 0.04899027198553085\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 4.7491326332092285 | KNN Loss: 4.731719493865967 | CLS Loss: 0.017413312569260597\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 4.737704753875732 | KNN Loss: 4.721890926361084 | CLS Loss: 0.015813684090971947\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 4.7184672355651855 | KNN Loss: 4.700959205627441 | CLS Loss: 0.01750796101987362\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 4.67574405670166 | KNN Loss: 4.661022663116455 | CLS Loss: 0.014721319079399109\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 4.723784446716309 | KNN Loss: 4.691324234008789 | CLS Loss: 0.032460443675518036\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 4.784268856048584 | KNN Loss: 4.747992038726807 | CLS Loss: 0.03627697750926018\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 4.733475208282471 | KNN Loss: 4.717743396759033 | CLS Loss: 0.01573200337588787\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 4.758073806762695 | KNN Loss: 4.741936683654785 | CLS Loss: 0.016137083992362022\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 4.726547718048096 | KNN Loss: 4.702642917633057 | CLS Loss: 0.0239049531519413\n",
      "Epoch: 052, Loss: 4.7459, Train: 0.9920, Valid: 0.9851, Best: 0.9867\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 4.703641414642334 | KNN Loss: 4.686480522155762 | CLS Loss: 0.01716066338121891\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 4.708401203155518 | KNN Loss: 4.691537857055664 | CLS Loss: 0.016863426193594933\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 4.702995300292969 | KNN Loss: 4.679191589355469 | CLS Loss: 0.02380376309156418\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 4.828420162200928 | KNN Loss: 4.811028003692627 | CLS Loss: 0.017392249777913094\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 4.74031925201416 | KNN Loss: 4.702702522277832 | CLS Loss: 0.03761656954884529\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 4.748835563659668 | KNN Loss: 4.714285373687744 | CLS Loss: 0.03455004841089249\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 4.774771690368652 | KNN Loss: 4.7526750564575195 | CLS Loss: 0.02209683693945408\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 4.720657825469971 | KNN Loss: 4.68060827255249 | CLS Loss: 0.0400497131049633\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 4.812411308288574 | KNN Loss: 4.770400524139404 | CLS Loss: 0.04201069474220276\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 4.703810691833496 | KNN Loss: 4.685790538787842 | CLS Loss: 0.01802029088139534\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 4.725652694702148 | KNN Loss: 4.695032119750977 | CLS Loss: 0.03062048926949501\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 4.73498010635376 | KNN Loss: 4.715260028839111 | CLS Loss: 0.019719889387488365\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 4.713545322418213 | KNN Loss: 4.699242115020752 | CLS Loss: 0.014303036965429783\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 4.719265937805176 | KNN Loss: 4.700263023376465 | CLS Loss: 0.01900295913219452\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 4.717344284057617 | KNN Loss: 4.684656620025635 | CLS Loss: 0.03268751502037048\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 4.698799133300781 | KNN Loss: 4.68784236907959 | CLS Loss: 0.010956770740449429\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 4.71866512298584 | KNN Loss: 4.705743789672852 | CLS Loss: 0.012921293266117573\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 4.709296226501465 | KNN Loss: 4.675026893615723 | CLS Loss: 0.03426937758922577\n",
      "Epoch: 053, Loss: 4.7363, Train: 0.9939, Valid: 0.9858, Best: 0.9867\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 4.734331130981445 | KNN Loss: 4.697467803955078 | CLS Loss: 0.03686333820223808\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 4.685176372528076 | KNN Loss: 4.668665409088135 | CLS Loss: 0.016510743647813797\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 4.728262901306152 | KNN Loss: 4.699624061584473 | CLS Loss: 0.028638936579227448\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 4.727527141571045 | KNN Loss: 4.714537620544434 | CLS Loss: 0.012989685870707035\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 4.675496578216553 | KNN Loss: 4.668924808502197 | CLS Loss: 0.006571848876774311\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 4.76731538772583 | KNN Loss: 4.727076530456543 | CLS Loss: 0.04023903235793114\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 4.715621471405029 | KNN Loss: 4.678776264190674 | CLS Loss: 0.036845169961452484\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 4.705175876617432 | KNN Loss: 4.695512294769287 | CLS Loss: 0.009663352742791176\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 4.788837432861328 | KNN Loss: 4.741177558898926 | CLS Loss: 0.047659777104854584\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 4.7798919677734375 | KNN Loss: 4.7183732986450195 | CLS Loss: 0.06151852011680603\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 4.770706653594971 | KNN Loss: 4.698104381561279 | CLS Loss: 0.0726023018360138\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 4.720157146453857 | KNN Loss: 4.70308256149292 | CLS Loss: 0.017074482515454292\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 4.798865795135498 | KNN Loss: 4.755692481994629 | CLS Loss: 0.043173253536224365\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 4.712098121643066 | KNN Loss: 4.681959629058838 | CLS Loss: 0.030138347297906876\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 4.763264179229736 | KNN Loss: 4.740723133087158 | CLS Loss: 0.0225408673286438\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 4.726988792419434 | KNN Loss: 4.697116851806641 | CLS Loss: 0.029871763661503792\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 4.761420726776123 | KNN Loss: 4.6984028816223145 | CLS Loss: 0.06301773339509964\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 4.719926834106445 | KNN Loss: 4.698907375335693 | CLS Loss: 0.021019602194428444\n",
      "Epoch: 054, Loss: 4.7335, Train: 0.9944, Valid: 0.9857, Best: 0.9867\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 4.703830718994141 | KNN Loss: 4.688626766204834 | CLS Loss: 0.015203920193016529\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 4.746769905090332 | KNN Loss: 4.7198896408081055 | CLS Loss: 0.02688034623861313\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 4.699974060058594 | KNN Loss: 4.692193031311035 | CLS Loss: 0.007781238295137882\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 4.801004886627197 | KNN Loss: 4.778292179107666 | CLS Loss: 0.022712651640176773\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 4.7343010902404785 | KNN Loss: 4.707783222198486 | CLS Loss: 0.02651803009212017\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 4.690728664398193 | KNN Loss: 4.684689521789551 | CLS Loss: 0.006039266008883715\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 4.68322229385376 | KNN Loss: 4.657857894897461 | CLS Loss: 0.025364167988300323\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 4.776952743530273 | KNN Loss: 4.7631964683532715 | CLS Loss: 0.013756155036389828\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 4.7112250328063965 | KNN Loss: 4.685632705688477 | CLS Loss: 0.02559252269566059\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 4.741699695587158 | KNN Loss: 4.7117204666137695 | CLS Loss: 0.029979098588228226\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 4.701320171356201 | KNN Loss: 4.673323154449463 | CLS Loss: 0.027997050434350967\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 4.782383918762207 | KNN Loss: 4.756663799285889 | CLS Loss: 0.02572028897702694\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 4.702363967895508 | KNN Loss: 4.691127300262451 | CLS Loss: 0.011236695572733879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 4.784759044647217 | KNN Loss: 4.745648384094238 | CLS Loss: 0.03911081328988075\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 4.7013325691223145 | KNN Loss: 4.689765453338623 | CLS Loss: 0.011566933244466782\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 4.717602252960205 | KNN Loss: 4.695037841796875 | CLS Loss: 0.02256433293223381\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 4.724377632141113 | KNN Loss: 4.694237232208252 | CLS Loss: 0.030140286311507225\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 4.778329372406006 | KNN Loss: 4.714925289154053 | CLS Loss: 0.06340423226356506\n",
      "Epoch: 055, Loss: 4.7325, Train: 0.9941, Valid: 0.9864, Best: 0.9867\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 4.685586452484131 | KNN Loss: 4.66071081161499 | CLS Loss: 0.02487550675868988\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 4.751164436340332 | KNN Loss: 4.712457180023193 | CLS Loss: 0.0387071892619133\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 4.723970890045166 | KNN Loss: 4.7017903327941895 | CLS Loss: 0.02218048647046089\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 4.835465908050537 | KNN Loss: 4.8044281005859375 | CLS Loss: 0.03103771060705185\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 4.743617057800293 | KNN Loss: 4.693680763244629 | CLS Loss: 0.049936141818761826\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 4.769153118133545 | KNN Loss: 4.724620342254639 | CLS Loss: 0.0445328950881958\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 4.6902174949646 | KNN Loss: 4.6818976402282715 | CLS Loss: 0.008319858461618423\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 4.713418960571289 | KNN Loss: 4.6761603355407715 | CLS Loss: 0.037258733063936234\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 4.753140926361084 | KNN Loss: 4.7296648025512695 | CLS Loss: 0.02347608469426632\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 4.722890853881836 | KNN Loss: 4.710651397705078 | CLS Loss: 0.012239391915500164\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 4.715892314910889 | KNN Loss: 4.703911781311035 | CLS Loss: 0.011980656534433365\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 4.705201148986816 | KNN Loss: 4.698381423950195 | CLS Loss: 0.006819537840783596\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 4.71522855758667 | KNN Loss: 4.6763482093811035 | CLS Loss: 0.038880303502082825\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 4.706762313842773 | KNN Loss: 4.686066150665283 | CLS Loss: 0.020696178078651428\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 4.830101490020752 | KNN Loss: 4.7758026123046875 | CLS Loss: 0.05429880693554878\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 4.749041557312012 | KNN Loss: 4.737392425537109 | CLS Loss: 0.011649188585579395\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 4.781435012817383 | KNN Loss: 4.764256000518799 | CLS Loss: 0.017179038375616074\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 4.7104997634887695 | KNN Loss: 4.676408767700195 | CLS Loss: 0.03409101814031601\n",
      "Epoch: 056, Loss: 4.7468, Train: 0.9933, Valid: 0.9850, Best: 0.9867\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 4.732423305511475 | KNN Loss: 4.715398788452148 | CLS Loss: 0.017024453729391098\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 4.673508167266846 | KNN Loss: 4.658595561981201 | CLS Loss: 0.014912518672645092\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 4.78178596496582 | KNN Loss: 4.7424516677856445 | CLS Loss: 0.03933423385024071\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 4.6838555335998535 | KNN Loss: 4.674283504486084 | CLS Loss: 0.009572229348123074\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 4.7891621589660645 | KNN Loss: 4.754698753356934 | CLS Loss: 0.03446335345506668\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 4.730257511138916 | KNN Loss: 4.705051422119141 | CLS Loss: 0.025206053629517555\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 4.8635454177856445 | KNN Loss: 4.796274662017822 | CLS Loss: 0.06727074086666107\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 4.750555038452148 | KNN Loss: 4.716919898986816 | CLS Loss: 0.03363536298274994\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 4.757316589355469 | KNN Loss: 4.730626106262207 | CLS Loss: 0.026690255850553513\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 4.7431769371032715 | KNN Loss: 4.719088077545166 | CLS Loss: 0.024088919162750244\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 4.7237372398376465 | KNN Loss: 4.702507972717285 | CLS Loss: 0.02122930809855461\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 4.7482829093933105 | KNN Loss: 4.711495399475098 | CLS Loss: 0.03678765520453453\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 4.725210666656494 | KNN Loss: 4.703403472900391 | CLS Loss: 0.021807102486491203\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 4.693583011627197 | KNN Loss: 4.673810005187988 | CLS Loss: 0.01977287232875824\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 4.6913275718688965 | KNN Loss: 4.685412406921387 | CLS Loss: 0.005915235262364149\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 4.694998741149902 | KNN Loss: 4.65455436706543 | CLS Loss: 0.040444258600473404\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 4.720242023468018 | KNN Loss: 4.710634231567383 | CLS Loss: 0.009607723914086819\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 4.729698657989502 | KNN Loss: 4.692189693450928 | CLS Loss: 0.03750911355018616\n",
      "Epoch: 057, Loss: 4.7379, Train: 0.9939, Valid: 0.9863, Best: 0.9867\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 4.708819389343262 | KNN Loss: 4.697934150695801 | CLS Loss: 0.01088508777320385\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 4.70048189163208 | KNN Loss: 4.670021057128906 | CLS Loss: 0.030460821464657784\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 4.777719020843506 | KNN Loss: 4.75740909576416 | CLS Loss: 0.020309796556830406\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 4.709282398223877 | KNN Loss: 4.691137790679932 | CLS Loss: 0.01814439333975315\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 4.713564872741699 | KNN Loss: 4.692363262176514 | CLS Loss: 0.021201375871896744\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 4.7979278564453125 | KNN Loss: 4.7785868644714355 | CLS Loss: 0.019340990111231804\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 4.795536041259766 | KNN Loss: 4.73756217956543 | CLS Loss: 0.057973697781562805\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 4.7001423835754395 | KNN Loss: 4.687523365020752 | CLS Loss: 0.012618803419172764\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 4.813148498535156 | KNN Loss: 4.764121055603027 | CLS Loss: 0.049027662724256516\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 4.7456183433532715 | KNN Loss: 4.737595558166504 | CLS Loss: 0.008022855035960674\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 4.7115702629089355 | KNN Loss: 4.6948041915893555 | CLS Loss: 0.01676601730287075\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 4.69149923324585 | KNN Loss: 4.670616626739502 | CLS Loss: 0.020882470533251762\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 4.676191806793213 | KNN Loss: 4.6518354415893555 | CLS Loss: 0.024356573820114136\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 4.759041786193848 | KNN Loss: 4.733845233917236 | CLS Loss: 0.025196615606546402\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 4.723779201507568 | KNN Loss: 4.689325332641602 | CLS Loss: 0.03445364534854889\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 4.763204097747803 | KNN Loss: 4.7313032150268555 | CLS Loss: 0.031900811940431595\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 4.736360549926758 | KNN Loss: 4.704194068908691 | CLS Loss: 0.0321662612259388\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 4.68463134765625 | KNN Loss: 4.675677299499512 | CLS Loss: 0.008953988552093506\n",
      "Epoch: 058, Loss: 4.7315, Train: 0.9941, Valid: 0.9866, Best: 0.9867\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 4.717977523803711 | KNN Loss: 4.69977331161499 | CLS Loss: 0.018204206600785255\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 4.695375919342041 | KNN Loss: 4.687328815460205 | CLS Loss: 0.008047153241932392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 4.706699848175049 | KNN Loss: 4.698912143707275 | CLS Loss: 0.007787507027387619\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 4.676464557647705 | KNN Loss: 4.656978130340576 | CLS Loss: 0.019486529752612114\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 4.7313761711120605 | KNN Loss: 4.700752258300781 | CLS Loss: 0.03062368556857109\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 4.67796516418457 | KNN Loss: 4.662048816680908 | CLS Loss: 0.015916133299469948\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 4.711739540100098 | KNN Loss: 4.691953659057617 | CLS Loss: 0.019785994663834572\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 4.7136969566345215 | KNN Loss: 4.684292316436768 | CLS Loss: 0.02940448187291622\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 4.717371463775635 | KNN Loss: 4.69194221496582 | CLS Loss: 0.025429442524909973\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 4.692537307739258 | KNN Loss: 4.674537181854248 | CLS Loss: 0.01800008863210678\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 4.713102340698242 | KNN Loss: 4.703886985778809 | CLS Loss: 0.009215396828949451\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 4.723896026611328 | KNN Loss: 4.698114395141602 | CLS Loss: 0.025781573727726936\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 4.715505123138428 | KNN Loss: 4.690688610076904 | CLS Loss: 0.02481670491397381\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 4.680246829986572 | KNN Loss: 4.665419101715088 | CLS Loss: 0.014827776700258255\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 4.734618663787842 | KNN Loss: 4.713818550109863 | CLS Loss: 0.020800020545721054\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 4.839813709259033 | KNN Loss: 4.796756744384766 | CLS Loss: 0.043056804686784744\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 4.80168342590332 | KNN Loss: 4.772619724273682 | CLS Loss: 0.029063912108540535\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 4.787357330322266 | KNN Loss: 4.739190101623535 | CLS Loss: 0.04816723242402077\n",
      "Epoch: 059, Loss: 4.7326, Train: 0.9929, Valid: 0.9851, Best: 0.9867\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 4.809696197509766 | KNN Loss: 4.792236804962158 | CLS Loss: 0.0174593273550272\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 4.66694450378418 | KNN Loss: 4.65495491027832 | CLS Loss: 0.011989541351795197\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 4.737298011779785 | KNN Loss: 4.7307024002075195 | CLS Loss: 0.0065955775789916515\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 4.716813087463379 | KNN Loss: 4.695874214172363 | CLS Loss: 0.020938724279403687\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 4.759709358215332 | KNN Loss: 4.748964309692383 | CLS Loss: 0.010745085775852203\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 4.8322529792785645 | KNN Loss: 4.796686172485352 | CLS Loss: 0.03556674346327782\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 4.71387243270874 | KNN Loss: 4.6836371421813965 | CLS Loss: 0.030235426500439644\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 4.761475086212158 | KNN Loss: 4.719274044036865 | CLS Loss: 0.04220081865787506\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 4.69818639755249 | KNN Loss: 4.678710460662842 | CLS Loss: 0.019475877285003662\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 4.748136043548584 | KNN Loss: 4.725276947021484 | CLS Loss: 0.022858964279294014\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 4.67822265625 | KNN Loss: 4.671497821807861 | CLS Loss: 0.006724846549332142\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 4.719902992248535 | KNN Loss: 4.69621467590332 | CLS Loss: 0.02368824928998947\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 4.724666118621826 | KNN Loss: 4.6975603103637695 | CLS Loss: 0.02710578218102455\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 4.770186424255371 | KNN Loss: 4.756294250488281 | CLS Loss: 0.01389240100979805\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 4.6828179359436035 | KNN Loss: 4.661224365234375 | CLS Loss: 0.021593471989035606\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 4.695461273193359 | KNN Loss: 4.68166446685791 | CLS Loss: 0.013796784915030003\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 4.75595760345459 | KNN Loss: 4.726665496826172 | CLS Loss: 0.02929229848086834\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 4.8043694496154785 | KNN Loss: 4.779057025909424 | CLS Loss: 0.025312645360827446\n",
      "Epoch: 060, Loss: 4.7290, Train: 0.9923, Valid: 0.9849, Best: 0.9867\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 4.698022365570068 | KNN Loss: 4.689734935760498 | CLS Loss: 0.00828731432557106\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 4.729458332061768 | KNN Loss: 4.70129919052124 | CLS Loss: 0.02815910428762436\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 4.768103122711182 | KNN Loss: 4.728118419647217 | CLS Loss: 0.03998483344912529\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 4.689801216125488 | KNN Loss: 4.664517879486084 | CLS Loss: 0.02528326027095318\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 4.757317543029785 | KNN Loss: 4.730709075927734 | CLS Loss: 0.026608338579535484\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 4.720252990722656 | KNN Loss: 4.697166442871094 | CLS Loss: 0.023086518049240112\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 4.766603469848633 | KNN Loss: 4.757964134216309 | CLS Loss: 0.008639408275485039\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 4.784811496734619 | KNN Loss: 4.77425479888916 | CLS Loss: 0.010556698776781559\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 4.705080986022949 | KNN Loss: 4.686018466949463 | CLS Loss: 0.019062520936131477\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 4.7582106590271 | KNN Loss: 4.745240211486816 | CLS Loss: 0.012970485724508762\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 4.699124813079834 | KNN Loss: 4.6930084228515625 | CLS Loss: 0.006116469856351614\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 4.73190975189209 | KNN Loss: 4.71209192276001 | CLS Loss: 0.0198177732527256\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 4.810209274291992 | KNN Loss: 4.783293724060059 | CLS Loss: 0.026915408670902252\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 4.70973014831543 | KNN Loss: 4.690242290496826 | CLS Loss: 0.019487710669636726\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 4.681379318237305 | KNN Loss: 4.662912845611572 | CLS Loss: 0.018466291949152946\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 4.686741828918457 | KNN Loss: 4.66350793838501 | CLS Loss: 0.023233963176608086\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 4.713985443115234 | KNN Loss: 4.686244010925293 | CLS Loss: 0.027741316705942154\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 4.761834621429443 | KNN Loss: 4.74041748046875 | CLS Loss: 0.02141694165766239\n",
      "Epoch: 061, Loss: 4.7320, Train: 0.9940, Valid: 0.9863, Best: 0.9867\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 4.901464939117432 | KNN Loss: 4.8557515144348145 | CLS Loss: 0.0457133986055851\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 4.744107246398926 | KNN Loss: 4.706200122833252 | CLS Loss: 0.037907056510448456\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 4.692207336425781 | KNN Loss: 4.656949520111084 | CLS Loss: 0.03525763005018234\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 4.77626371383667 | KNN Loss: 4.717687606811523 | CLS Loss: 0.05857590585947037\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 4.773469924926758 | KNN Loss: 4.75290584564209 | CLS Loss: 0.020564153790473938\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 4.722102642059326 | KNN Loss: 4.68839168548584 | CLS Loss: 0.033711157739162445\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 4.768159866333008 | KNN Loss: 4.757655620574951 | CLS Loss: 0.010504336096346378\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 4.7548089027404785 | KNN Loss: 4.727967739105225 | CLS Loss: 0.02684125117957592\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 4.744735240936279 | KNN Loss: 4.714380741119385 | CLS Loss: 0.030354449525475502\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 4.738430976867676 | KNN Loss: 4.734691619873047 | CLS Loss: 0.0037394033279269934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 4.652350902557373 | KNN Loss: 4.6443305015563965 | CLS Loss: 0.008020630106329918\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 4.700518608093262 | KNN Loss: 4.686192035675049 | CLS Loss: 0.014326769858598709\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 4.693160057067871 | KNN Loss: 4.69080924987793 | CLS Loss: 0.002350822789594531\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 4.712261199951172 | KNN Loss: 4.684502601623535 | CLS Loss: 0.02775839902460575\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 4.844231605529785 | KNN Loss: 4.797901153564453 | CLS Loss: 0.046330563724040985\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 4.764029026031494 | KNN Loss: 4.737517833709717 | CLS Loss: 0.026511378586292267\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 4.782322883605957 | KNN Loss: 4.753468036651611 | CLS Loss: 0.028855066746473312\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 4.7098798751831055 | KNN Loss: 4.689962863922119 | CLS Loss: 0.019917136058211327\n",
      "Epoch: 062, Loss: 4.7257, Train: 0.9948, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 4.666022300720215 | KNN Loss: 4.657215595245361 | CLS Loss: 0.00880669616162777\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 4.7422871589660645 | KNN Loss: 4.711059093475342 | CLS Loss: 0.03122817538678646\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 4.68768835067749 | KNN Loss: 4.66894006729126 | CLS Loss: 0.018748408183455467\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 4.691705226898193 | KNN Loss: 4.672380447387695 | CLS Loss: 0.01932482048869133\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 4.746745586395264 | KNN Loss: 4.728946685791016 | CLS Loss: 0.01779869757592678\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 4.755379676818848 | KNN Loss: 4.733028888702393 | CLS Loss: 0.022350864484906197\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 4.78440523147583 | KNN Loss: 4.754187107086182 | CLS Loss: 0.030218057334423065\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 4.746455192565918 | KNN Loss: 4.72437858581543 | CLS Loss: 0.022076502442359924\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 4.7378058433532715 | KNN Loss: 4.707395076751709 | CLS Loss: 0.030410556122660637\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 4.707705974578857 | KNN Loss: 4.695318222045898 | CLS Loss: 0.012387562543153763\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 4.671163558959961 | KNN Loss: 4.664209365844727 | CLS Loss: 0.006954235024750233\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 4.730088233947754 | KNN Loss: 4.707795143127441 | CLS Loss: 0.022292951121926308\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 4.764407634735107 | KNN Loss: 4.751317977905273 | CLS Loss: 0.013089550659060478\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 4.705211639404297 | KNN Loss: 4.671064376831055 | CLS Loss: 0.034147098660469055\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 4.673318386077881 | KNN Loss: 4.65976619720459 | CLS Loss: 0.013551989570260048\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 4.776302814483643 | KNN Loss: 4.744454383850098 | CLS Loss: 0.03184865415096283\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 4.69840669631958 | KNN Loss: 4.681210994720459 | CLS Loss: 0.01719580590724945\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 4.697754859924316 | KNN Loss: 4.674272537231445 | CLS Loss: 0.02348245307803154\n",
      "Epoch: 063, Loss: 4.7328, Train: 0.9937, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 4.78400182723999 | KNN Loss: 4.739682197570801 | CLS Loss: 0.04431947320699692\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 4.741669178009033 | KNN Loss: 4.70463752746582 | CLS Loss: 0.03703181445598602\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 4.7243218421936035 | KNN Loss: 4.696996688842773 | CLS Loss: 0.027325382456183434\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 4.705377578735352 | KNN Loss: 4.693342685699463 | CLS Loss: 0.012034943327307701\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 4.68133544921875 | KNN Loss: 4.676657199859619 | CLS Loss: 0.0046781315468251705\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 4.678369998931885 | KNN Loss: 4.642423629760742 | CLS Loss: 0.03594633936882019\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 4.657768726348877 | KNN Loss: 4.645593643188477 | CLS Loss: 0.012174999341368675\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 4.754414081573486 | KNN Loss: 4.7193450927734375 | CLS Loss: 0.03506884351372719\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 4.73079776763916 | KNN Loss: 4.685187816619873 | CLS Loss: 0.045610155910253525\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 4.697118282318115 | KNN Loss: 4.674180030822754 | CLS Loss: 0.022938132286071777\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 4.796019077301025 | KNN Loss: 4.78415584564209 | CLS Loss: 0.011863195337355137\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 4.6910014152526855 | KNN Loss: 4.682260990142822 | CLS Loss: 0.008740207180380821\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 4.844958305358887 | KNN Loss: 4.834558486938477 | CLS Loss: 0.010399878956377506\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 4.74483585357666 | KNN Loss: 4.722743511199951 | CLS Loss: 0.022092485800385475\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 4.70817232131958 | KNN Loss: 4.661736488342285 | CLS Loss: 0.04643585532903671\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 4.739899635314941 | KNN Loss: 4.729959487915039 | CLS Loss: 0.009940197691321373\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 4.768024444580078 | KNN Loss: 4.741778373718262 | CLS Loss: 0.026246238499879837\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 4.741758823394775 | KNN Loss: 4.7049126625061035 | CLS Loss: 0.036846283823251724\n",
      "Epoch: 064, Loss: 4.7404, Train: 0.9941, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 4.706714153289795 | KNN Loss: 4.669763088226318 | CLS Loss: 0.03695106506347656\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 4.778218746185303 | KNN Loss: 4.766454696655273 | CLS Loss: 0.01176400575786829\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 4.672175884246826 | KNN Loss: 4.663553237915039 | CLS Loss: 0.008622470311820507\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 4.713260173797607 | KNN Loss: 4.706961631774902 | CLS Loss: 0.006298654712736607\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 4.7603559494018555 | KNN Loss: 4.733646392822266 | CLS Loss: 0.026709357276558876\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 4.733460903167725 | KNN Loss: 4.683450698852539 | CLS Loss: 0.050009969621896744\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 4.6614909172058105 | KNN Loss: 4.642350196838379 | CLS Loss: 0.019140778109431267\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 4.658469200134277 | KNN Loss: 4.642213821411133 | CLS Loss: 0.01625516079366207\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 4.725257873535156 | KNN Loss: 4.71006441116333 | CLS Loss: 0.015193420462310314\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 4.713233470916748 | KNN Loss: 4.686892986297607 | CLS Loss: 0.02634054608643055\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 4.679293632507324 | KNN Loss: 4.666637897491455 | CLS Loss: 0.012655781581997871\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 4.685157775878906 | KNN Loss: 4.650200366973877 | CLS Loss: 0.03495746850967407\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 4.76237678527832 | KNN Loss: 4.7457275390625 | CLS Loss: 0.016649318858981133\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 4.699838638305664 | KNN Loss: 4.661990165710449 | CLS Loss: 0.03784838318824768\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 4.742580890655518 | KNN Loss: 4.7141265869140625 | CLS Loss: 0.0284543726593256\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 4.799369812011719 | KNN Loss: 4.769826412200928 | CLS Loss: 0.029543422162532806\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 4.70250940322876 | KNN Loss: 4.671950340270996 | CLS Loss: 0.030559124425053596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 4.695548057556152 | KNN Loss: 4.674094200134277 | CLS Loss: 0.02145376242697239\n",
      "Epoch: 065, Loss: 4.7259, Train: 0.9950, Valid: 0.9865, Best: 0.9867\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 4.687714099884033 | KNN Loss: 4.66969633102417 | CLS Loss: 0.018017776310443878\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 4.797497749328613 | KNN Loss: 4.770165920257568 | CLS Loss: 0.027331799268722534\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 4.690598011016846 | KNN Loss: 4.671249866485596 | CLS Loss: 0.01934833452105522\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 4.665422439575195 | KNN Loss: 4.658097743988037 | CLS Loss: 0.007324494421482086\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 4.6960673332214355 | KNN Loss: 4.686069965362549 | CLS Loss: 0.009997517801821232\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 4.771283149719238 | KNN Loss: 4.7330827713012695 | CLS Loss: 0.03820024058222771\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 4.7334818840026855 | KNN Loss: 4.687142848968506 | CLS Loss: 0.046338941901922226\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 4.749942302703857 | KNN Loss: 4.714456558227539 | CLS Loss: 0.035485923290252686\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 4.69883918762207 | KNN Loss: 4.670100212097168 | CLS Loss: 0.02873917669057846\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 4.726724147796631 | KNN Loss: 4.703654766082764 | CLS Loss: 0.023069575428962708\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 4.736714839935303 | KNN Loss: 4.701254367828369 | CLS Loss: 0.03546055406332016\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 4.779611110687256 | KNN Loss: 4.728534698486328 | CLS Loss: 0.05107632279396057\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 4.703942775726318 | KNN Loss: 4.68804407119751 | CLS Loss: 0.015898525714874268\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 4.732935428619385 | KNN Loss: 4.706905841827393 | CLS Loss: 0.02602940984070301\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 4.752558708190918 | KNN Loss: 4.724900722503662 | CLS Loss: 0.027658214792609215\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 4.702854156494141 | KNN Loss: 4.663861274719238 | CLS Loss: 0.03899310156702995\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 4.6898603439331055 | KNN Loss: 4.6806135177612305 | CLS Loss: 0.009247047826647758\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 4.787662029266357 | KNN Loss: 4.771853923797607 | CLS Loss: 0.01580807752907276\n",
      "Epoch: 066, Loss: 4.7328, Train: 0.9941, Valid: 0.9856, Best: 0.9867\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 4.704670429229736 | KNN Loss: 4.691842555999756 | CLS Loss: 0.01282801665365696\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 4.711902141571045 | KNN Loss: 4.695671081542969 | CLS Loss: 0.01623087003827095\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 4.758929252624512 | KNN Loss: 4.745948791503906 | CLS Loss: 0.012980298139154911\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 4.7608160972595215 | KNN Loss: 4.705273151397705 | CLS Loss: 0.05554287135601044\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 4.717981815338135 | KNN Loss: 4.678488254547119 | CLS Loss: 0.039493776857852936\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 4.774502754211426 | KNN Loss: 4.7427215576171875 | CLS Loss: 0.03178117424249649\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 4.686563968658447 | KNN Loss: 4.660444259643555 | CLS Loss: 0.026119694113731384\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 4.719125747680664 | KNN Loss: 4.684512615203857 | CLS Loss: 0.034612931311130524\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 4.738556861877441 | KNN Loss: 4.713396072387695 | CLS Loss: 0.025161022320389748\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 4.737564563751221 | KNN Loss: 4.702691555023193 | CLS Loss: 0.034872811287641525\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 4.817277908325195 | KNN Loss: 4.771046161651611 | CLS Loss: 0.046231698244810104\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 4.7828049659729 | KNN Loss: 4.717605113983154 | CLS Loss: 0.0651998445391655\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 4.735315322875977 | KNN Loss: 4.698946475982666 | CLS Loss: 0.03636908158659935\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 4.690466403961182 | KNN Loss: 4.65561580657959 | CLS Loss: 0.0348505973815918\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 4.696170806884766 | KNN Loss: 4.676323413848877 | CLS Loss: 0.019847292453050613\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 4.703998565673828 | KNN Loss: 4.6857380867004395 | CLS Loss: 0.018260493874549866\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 4.731901168823242 | KNN Loss: 4.702629566192627 | CLS Loss: 0.029271692037582397\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 4.661216735839844 | KNN Loss: 4.64436674118042 | CLS Loss: 0.01684996671974659\n",
      "Epoch: 067, Loss: 4.7318, Train: 0.9954, Valid: 0.9868, Best: 0.9868\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 4.729060649871826 | KNN Loss: 4.715715408325195 | CLS Loss: 0.013345283456146717\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 4.712745666503906 | KNN Loss: 4.684274673461914 | CLS Loss: 0.028470875695347786\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 4.7786173820495605 | KNN Loss: 4.7681145668029785 | CLS Loss: 0.01050291396677494\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 4.720559597015381 | KNN Loss: 4.702335357666016 | CLS Loss: 0.018224036321043968\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 4.7076029777526855 | KNN Loss: 4.695511341094971 | CLS Loss: 0.012091757729649544\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 4.709077835083008 | KNN Loss: 4.686863899230957 | CLS Loss: 0.022213881835341454\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 4.739633083343506 | KNN Loss: 4.703309059143066 | CLS Loss: 0.036324020475149155\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 4.7361860275268555 | KNN Loss: 4.707965850830078 | CLS Loss: 0.028220124542713165\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 4.65141487121582 | KNN Loss: 4.62844705581665 | CLS Loss: 0.022967804223299026\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 4.704787254333496 | KNN Loss: 4.696152687072754 | CLS Loss: 0.008634504862129688\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 4.706680774688721 | KNN Loss: 4.67600154876709 | CLS Loss: 0.030679138377308846\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 4.721890926361084 | KNN Loss: 4.7009596824646 | CLS Loss: 0.02093118615448475\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 4.689012050628662 | KNN Loss: 4.675701141357422 | CLS Loss: 0.013310720212757587\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 4.681116104125977 | KNN Loss: 4.6625189781188965 | CLS Loss: 0.018597165122628212\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 4.804993629455566 | KNN Loss: 4.759806156158447 | CLS Loss: 0.04518764093518257\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 4.703441143035889 | KNN Loss: 4.698028087615967 | CLS Loss: 0.005413198843598366\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 4.6851887702941895 | KNN Loss: 4.659056663513184 | CLS Loss: 0.026132013648748398\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 4.694116592407227 | KNN Loss: 4.674772262573242 | CLS Loss: 0.01934429258108139\n",
      "Epoch: 068, Loss: 4.7255, Train: 0.9915, Valid: 0.9820, Best: 0.9868\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 4.7213544845581055 | KNN Loss: 4.697695255279541 | CLS Loss: 0.023659219965338707\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 4.6773200035095215 | KNN Loss: 4.641800403594971 | CLS Loss: 0.03551970794796944\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 4.705488681793213 | KNN Loss: 4.690480709075928 | CLS Loss: 0.015008095651865005\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 4.684992790222168 | KNN Loss: 4.679971218109131 | CLS Loss: 0.005021553486585617\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 4.717926025390625 | KNN Loss: 4.7046098709106445 | CLS Loss: 0.013316103257238865\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 4.790093898773193 | KNN Loss: 4.781234264373779 | CLS Loss: 0.008859483525156975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 4.684815883636475 | KNN Loss: 4.65388298034668 | CLS Loss: 0.030932817608118057\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 4.78237771987915 | KNN Loss: 4.7424421310424805 | CLS Loss: 0.039935722947120667\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 4.728329658508301 | KNN Loss: 4.705081939697266 | CLS Loss: 0.023247847333550453\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 4.690245628356934 | KNN Loss: 4.670650482177734 | CLS Loss: 0.019595179706811905\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 4.715877532958984 | KNN Loss: 4.700520038604736 | CLS Loss: 0.015357361175119877\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 4.7068352699279785 | KNN Loss: 4.674800395965576 | CLS Loss: 0.03203496336936951\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 4.6674041748046875 | KNN Loss: 4.643582820892334 | CLS Loss: 0.023821575567126274\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 4.791815280914307 | KNN Loss: 4.75942325592041 | CLS Loss: 0.03239179030060768\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 4.712889671325684 | KNN Loss: 4.693075180053711 | CLS Loss: 0.019814517349004745\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 4.741270542144775 | KNN Loss: 4.730376720428467 | CLS Loss: 0.010893972590565681\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 4.767238616943359 | KNN Loss: 4.732107162475586 | CLS Loss: 0.035131536424160004\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 4.729145526885986 | KNN Loss: 4.693582534790039 | CLS Loss: 0.03556296229362488\n",
      "Epoch: 069, Loss: 4.7224, Train: 0.9949, Valid: 0.9854, Best: 0.9868\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 4.7345147132873535 | KNN Loss: 4.725170135498047 | CLS Loss: 0.009344649501144886\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 4.747153282165527 | KNN Loss: 4.708158493041992 | CLS Loss: 0.03899490833282471\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 4.805449962615967 | KNN Loss: 4.782631874084473 | CLS Loss: 0.02281787432730198\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 4.804774284362793 | KNN Loss: 4.785233020782471 | CLS Loss: 0.019541125744581223\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 4.707028865814209 | KNN Loss: 4.693110942840576 | CLS Loss: 0.013918050564825535\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 4.7051544189453125 | KNN Loss: 4.6750922203063965 | CLS Loss: 0.03006240725517273\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 4.746981620788574 | KNN Loss: 4.727743625640869 | CLS Loss: 0.019237885251641273\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 4.716222286224365 | KNN Loss: 4.702849388122559 | CLS Loss: 0.013373074121773243\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 4.7547101974487305 | KNN Loss: 4.732958793640137 | CLS Loss: 0.02175132744014263\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 4.719654560089111 | KNN Loss: 4.687124729156494 | CLS Loss: 0.032529812306165695\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 4.868491172790527 | KNN Loss: 4.80756139755249 | CLS Loss: 0.060929760336875916\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 4.752021789550781 | KNN Loss: 4.7060627937316895 | CLS Loss: 0.04595878720283508\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 4.727938175201416 | KNN Loss: 4.71640682220459 | CLS Loss: 0.011531439609825611\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 4.676122188568115 | KNN Loss: 4.666353702545166 | CLS Loss: 0.009768697433173656\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 4.717102527618408 | KNN Loss: 4.694428443908691 | CLS Loss: 0.0226739551872015\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 4.6715569496154785 | KNN Loss: 4.652519702911377 | CLS Loss: 0.019037121906876564\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 4.69223690032959 | KNN Loss: 4.6698689460754395 | CLS Loss: 0.022368168458342552\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 4.715450286865234 | KNN Loss: 4.680380821228027 | CLS Loss: 0.03506961464881897\n",
      "Epoch: 070, Loss: 4.7240, Train: 0.9951, Valid: 0.9866, Best: 0.9868\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 4.7494001388549805 | KNN Loss: 4.742431640625 | CLS Loss: 0.006968281231820583\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 4.749536514282227 | KNN Loss: 4.7331929206848145 | CLS Loss: 0.016343455761671066\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 4.65293550491333 | KNN Loss: 4.647716522216797 | CLS Loss: 0.00521891750395298\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 4.707042217254639 | KNN Loss: 4.688792705535889 | CLS Loss: 0.018249675631523132\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 4.735462188720703 | KNN Loss: 4.70369815826416 | CLS Loss: 0.03176411613821983\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 4.700467586517334 | KNN Loss: 4.683133125305176 | CLS Loss: 0.017334453761577606\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 4.69262170791626 | KNN Loss: 4.669124126434326 | CLS Loss: 0.023497605696320534\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 4.742887496948242 | KNN Loss: 4.723639488220215 | CLS Loss: 0.019248217344284058\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 4.717706680297852 | KNN Loss: 4.6806864738464355 | CLS Loss: 0.03702034056186676\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 4.68892765045166 | KNN Loss: 4.672167778015137 | CLS Loss: 0.016759904101490974\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 4.682822227478027 | KNN Loss: 4.654492378234863 | CLS Loss: 0.028330083936452866\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 4.7395405769348145 | KNN Loss: 4.714273929595947 | CLS Loss: 0.025266794487833977\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 4.729330062866211 | KNN Loss: 4.692965507507324 | CLS Loss: 0.03636457026004791\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 4.773754119873047 | KNN Loss: 4.747082233428955 | CLS Loss: 0.026672087609767914\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 4.680194854736328 | KNN Loss: 4.667636394500732 | CLS Loss: 0.012558409944176674\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 4.7425150871276855 | KNN Loss: 4.717493534088135 | CLS Loss: 0.025021355599164963\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 4.671792507171631 | KNN Loss: 4.645933628082275 | CLS Loss: 0.025858785957098007\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 4.687666416168213 | KNN Loss: 4.665991306304932 | CLS Loss: 0.02167521044611931\n",
      "Epoch: 071, Loss: 4.7186, Train: 0.9947, Valid: 0.9870, Best: 0.9870\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 4.686765670776367 | KNN Loss: 4.657650947570801 | CLS Loss: 0.02911471016705036\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 4.6813154220581055 | KNN Loss: 4.668803691864014 | CLS Loss: 0.01251152902841568\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 4.708524227142334 | KNN Loss: 4.672953128814697 | CLS Loss: 0.03557101637125015\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 4.671861171722412 | KNN Loss: 4.660507678985596 | CLS Loss: 0.011353332549333572\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 4.731818675994873 | KNN Loss: 4.709760665893555 | CLS Loss: 0.022057926282286644\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 4.684213638305664 | KNN Loss: 4.671695709228516 | CLS Loss: 0.012517903931438923\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 4.784460067749023 | KNN Loss: 4.730756759643555 | CLS Loss: 0.05370326340198517\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 4.729917049407959 | KNN Loss: 4.715517520904541 | CLS Loss: 0.014399457722902298\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 4.658932685852051 | KNN Loss: 4.649028778076172 | CLS Loss: 0.009903689846396446\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 4.705058574676514 | KNN Loss: 4.69881010055542 | CLS Loss: 0.006248650141060352\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 4.692789077758789 | KNN Loss: 4.67454719543457 | CLS Loss: 0.018241915851831436\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 4.789486885070801 | KNN Loss: 4.766870498657227 | CLS Loss: 0.022616339847445488\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 4.840023994445801 | KNN Loss: 4.821568489074707 | CLS Loss: 0.01845572143793106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 4.696310043334961 | KNN Loss: 4.674035549163818 | CLS Loss: 0.02227451279759407\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 4.690064430236816 | KNN Loss: 4.660336494445801 | CLS Loss: 0.029728049412369728\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 4.71966552734375 | KNN Loss: 4.708710670471191 | CLS Loss: 0.01095469668507576\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 4.832865238189697 | KNN Loss: 4.779080867767334 | CLS Loss: 0.05378442257642746\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 4.688311576843262 | KNN Loss: 4.677219390869141 | CLS Loss: 0.01109207421541214\n",
      "Epoch: 072, Loss: 4.7303, Train: 0.9933, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 4.676386833190918 | KNN Loss: 4.666842937469482 | CLS Loss: 0.009543945081532001\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 4.650279998779297 | KNN Loss: 4.643248558044434 | CLS Loss: 0.007031308487057686\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 4.733076572418213 | KNN Loss: 4.718669891357422 | CLS Loss: 0.01440674439072609\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 4.7193756103515625 | KNN Loss: 4.703611850738525 | CLS Loss: 0.015763819217681885\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 4.725809574127197 | KNN Loss: 4.692600250244141 | CLS Loss: 0.03320950269699097\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 4.663355350494385 | KNN Loss: 4.649374008178711 | CLS Loss: 0.013981364667415619\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 4.711392879486084 | KNN Loss: 4.687010288238525 | CLS Loss: 0.0243828222155571\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 4.735160827636719 | KNN Loss: 4.690457344055176 | CLS Loss: 0.04470337554812431\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 4.848544120788574 | KNN Loss: 4.843928813934326 | CLS Loss: 0.004615358542650938\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 4.756499767303467 | KNN Loss: 4.713579177856445 | CLS Loss: 0.0429205447435379\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 4.771730422973633 | KNN Loss: 4.740962982177734 | CLS Loss: 0.03076763078570366\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 4.704324245452881 | KNN Loss: 4.670636177062988 | CLS Loss: 0.033688005059957504\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 4.736133575439453 | KNN Loss: 4.711906909942627 | CLS Loss: 0.024226805195212364\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 4.692051410675049 | KNN Loss: 4.664456844329834 | CLS Loss: 0.027594609186053276\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 4.723402976989746 | KNN Loss: 4.708785533905029 | CLS Loss: 0.014617531560361385\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 4.702621936798096 | KNN Loss: 4.690581321716309 | CLS Loss: 0.012040471658110619\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 4.7119622230529785 | KNN Loss: 4.699036598205566 | CLS Loss: 0.012925775721669197\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 4.686462879180908 | KNN Loss: 4.671396732330322 | CLS Loss: 0.015066198073327541\n",
      "Epoch: 073, Loss: 4.7170, Train: 0.9953, Valid: 0.9870, Best: 0.9870\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 4.685855388641357 | KNN Loss: 4.677219390869141 | CLS Loss: 0.008635998703539371\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 4.66754674911499 | KNN Loss: 4.647969722747803 | CLS Loss: 0.01957697421312332\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 4.745569705963135 | KNN Loss: 4.7234673500061035 | CLS Loss: 0.022102149203419685\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 4.682977676391602 | KNN Loss: 4.666680812835693 | CLS Loss: 0.0162969958037138\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 4.703367710113525 | KNN Loss: 4.663886547088623 | CLS Loss: 0.03948134183883667\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 4.690567970275879 | KNN Loss: 4.674319267272949 | CLS Loss: 0.01624888926744461\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 4.751067638397217 | KNN Loss: 4.729289531707764 | CLS Loss: 0.02177814021706581\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 4.662253379821777 | KNN Loss: 4.655201435089111 | CLS Loss: 0.007051710970699787\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 4.695298671722412 | KNN Loss: 4.690202236175537 | CLS Loss: 0.005096601787954569\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 4.698527812957764 | KNN Loss: 4.69020414352417 | CLS Loss: 0.00832343939691782\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 4.696290969848633 | KNN Loss: 4.682629108428955 | CLS Loss: 0.013661680743098259\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 4.751347064971924 | KNN Loss: 4.728297710418701 | CLS Loss: 0.02304924838244915\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 4.771493911743164 | KNN Loss: 4.754049301147461 | CLS Loss: 0.017444394528865814\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 4.663747310638428 | KNN Loss: 4.654968738555908 | CLS Loss: 0.008778782561421394\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 4.746272563934326 | KNN Loss: 4.7331342697143555 | CLS Loss: 0.013138256035745144\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 4.65247106552124 | KNN Loss: 4.64280366897583 | CLS Loss: 0.009667464531958103\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 4.728037357330322 | KNN Loss: 4.708812236785889 | CLS Loss: 0.019225098192691803\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 4.805309772491455 | KNN Loss: 4.778702259063721 | CLS Loss: 0.026607733219861984\n",
      "Epoch: 074, Loss: 4.7144, Train: 0.9920, Valid: 0.9824, Best: 0.9870\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 4.703305244445801 | KNN Loss: 4.670940399169922 | CLS Loss: 0.03236465901136398\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 4.698340892791748 | KNN Loss: 4.675045490264893 | CLS Loss: 0.023295605555176735\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 4.719449520111084 | KNN Loss: 4.672959327697754 | CLS Loss: 0.046490419656038284\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 4.670582294464111 | KNN Loss: 4.650888919830322 | CLS Loss: 0.01969331130385399\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 4.683036804199219 | KNN Loss: 4.6713690757751465 | CLS Loss: 0.011667613871395588\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 4.70444393157959 | KNN Loss: 4.679189682006836 | CLS Loss: 0.025254040956497192\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 4.714983940124512 | KNN Loss: 4.688103675842285 | CLS Loss: 0.026880115270614624\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 4.8159027099609375 | KNN Loss: 4.801973342895508 | CLS Loss: 0.013929599896073341\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 4.673518180847168 | KNN Loss: 4.666990756988525 | CLS Loss: 0.006527486722916365\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 4.702998161315918 | KNN Loss: 4.671591758728027 | CLS Loss: 0.031406521797180176\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 4.72651481628418 | KNN Loss: 4.698410987854004 | CLS Loss: 0.02810387872159481\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 4.670827388763428 | KNN Loss: 4.659073352813721 | CLS Loss: 0.011754060164093971\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 4.743230819702148 | KNN Loss: 4.690496921539307 | CLS Loss: 0.052733853459358215\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 4.684135437011719 | KNN Loss: 4.647323131561279 | CLS Loss: 0.036812443286180496\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 4.727433204650879 | KNN Loss: 4.716357707977295 | CLS Loss: 0.011075697839260101\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 4.711159706115723 | KNN Loss: 4.691686630249023 | CLS Loss: 0.019473077729344368\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 4.805520534515381 | KNN Loss: 4.7821455001831055 | CLS Loss: 0.023374896496534348\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 4.725149631500244 | KNN Loss: 4.703557014465332 | CLS Loss: 0.021592674776911736\n",
      "Epoch: 075, Loss: 4.7319, Train: 0.9939, Valid: 0.9853, Best: 0.9870\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 4.738640785217285 | KNN Loss: 4.720832347869873 | CLS Loss: 0.01780821569263935\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 4.698622703552246 | KNN Loss: 4.685615062713623 | CLS Loss: 0.013007618486881256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 4.688770294189453 | KNN Loss: 4.668248176574707 | CLS Loss: 0.02052224613726139\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 4.696654319763184 | KNN Loss: 4.667148113250732 | CLS Loss: 0.029506415128707886\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 4.690762519836426 | KNN Loss: 4.67844295501709 | CLS Loss: 0.012319492176175117\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 4.739765167236328 | KNN Loss: 4.727096080780029 | CLS Loss: 0.012669023126363754\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 4.729842185974121 | KNN Loss: 4.674856662750244 | CLS Loss: 0.05498557910323143\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 4.720070838928223 | KNN Loss: 4.707390785217285 | CLS Loss: 0.012680169194936752\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 4.736769676208496 | KNN Loss: 4.720137119293213 | CLS Loss: 0.016632476821541786\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 4.712795734405518 | KNN Loss: 4.692928314208984 | CLS Loss: 0.019867394119501114\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 4.734102249145508 | KNN Loss: 4.704484462738037 | CLS Loss: 0.029617948457598686\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 4.706608772277832 | KNN Loss: 4.661076545715332 | CLS Loss: 0.04553205519914627\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 4.718599319458008 | KNN Loss: 4.708912372589111 | CLS Loss: 0.009687097743153572\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 4.726699352264404 | KNN Loss: 4.700466156005859 | CLS Loss: 0.026233207434415817\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 4.719361305236816 | KNN Loss: 4.69631814956665 | CLS Loss: 0.023043321445584297\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 4.714498043060303 | KNN Loss: 4.688161849975586 | CLS Loss: 0.026336129754781723\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 4.72158670425415 | KNN Loss: 4.7165045738220215 | CLS Loss: 0.005081953480839729\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 4.764233589172363 | KNN Loss: 4.71379280090332 | CLS Loss: 0.05044065788388252\n",
      "Epoch: 076, Loss: 4.7183, Train: 0.9952, Valid: 0.9866, Best: 0.9870\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 4.6889495849609375 | KNN Loss: 4.677821636199951 | CLS Loss: 0.011127847246825695\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 4.677169322967529 | KNN Loss: 4.663141250610352 | CLS Loss: 0.014027966186404228\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 4.680849075317383 | KNN Loss: 4.67216157913208 | CLS Loss: 0.008687656372785568\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 4.74216890335083 | KNN Loss: 4.72208833694458 | CLS Loss: 0.020080430433154106\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 4.6927008628845215 | KNN Loss: 4.667247295379639 | CLS Loss: 0.02545357123017311\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 4.759661674499512 | KNN Loss: 4.71627950668335 | CLS Loss: 0.04338228702545166\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 4.66610860824585 | KNN Loss: 4.654941082000732 | CLS Loss: 0.01116773672401905\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 4.649342060089111 | KNN Loss: 4.6457648277282715 | CLS Loss: 0.003577012801542878\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 4.735761642456055 | KNN Loss: 4.6934661865234375 | CLS Loss: 0.04229538515210152\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 4.6961588859558105 | KNN Loss: 4.676697731018066 | CLS Loss: 0.019461140036582947\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 4.722745418548584 | KNN Loss: 4.680984020233154 | CLS Loss: 0.041761208325624466\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 4.7770233154296875 | KNN Loss: 4.740704536437988 | CLS Loss: 0.03631899133324623\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 4.7472758293151855 | KNN Loss: 4.725375175476074 | CLS Loss: 0.021900467574596405\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 4.671359062194824 | KNN Loss: 4.660257339477539 | CLS Loss: 0.011101571843028069\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 4.812939643859863 | KNN Loss: 4.791984558105469 | CLS Loss: 0.02095494419336319\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 4.794471263885498 | KNN Loss: 4.734241962432861 | CLS Loss: 0.06022949144244194\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 4.711342811584473 | KNN Loss: 4.674577236175537 | CLS Loss: 0.03676559031009674\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 4.696629047393799 | KNN Loss: 4.68568754196167 | CLS Loss: 0.010941436514258385\n",
      "Epoch: 077, Loss: 4.7315, Train: 0.9923, Valid: 0.9849, Best: 0.9870\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 4.7364912033081055 | KNN Loss: 4.687633037567139 | CLS Loss: 0.04885825142264366\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 4.714666843414307 | KNN Loss: 4.685624599456787 | CLS Loss: 0.0290420800447464\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 4.74706506729126 | KNN Loss: 4.726589202880859 | CLS Loss: 0.020476054400205612\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 4.771637439727783 | KNN Loss: 4.738945007324219 | CLS Loss: 0.032692424952983856\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 4.716707229614258 | KNN Loss: 4.701297283172607 | CLS Loss: 0.015409956686198711\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 4.700076103210449 | KNN Loss: 4.678956985473633 | CLS Loss: 0.021119100973010063\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 4.799498558044434 | KNN Loss: 4.7843098640441895 | CLS Loss: 0.015188919380307198\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 4.729547023773193 | KNN Loss: 4.692558288574219 | CLS Loss: 0.036988914012908936\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 4.686130046844482 | KNN Loss: 4.678637981414795 | CLS Loss: 0.007492219563573599\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 4.674929141998291 | KNN Loss: 4.663965225219727 | CLS Loss: 0.010963854379951954\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 4.696284294128418 | KNN Loss: 4.6852593421936035 | CLS Loss: 0.01102514285594225\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 4.74985933303833 | KNN Loss: 4.690155029296875 | CLS Loss: 0.05970422923564911\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 4.71417236328125 | KNN Loss: 4.699040412902832 | CLS Loss: 0.015132112428545952\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 4.72875452041626 | KNN Loss: 4.697657108306885 | CLS Loss: 0.03109741397202015\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 4.693200588226318 | KNN Loss: 4.684850215911865 | CLS Loss: 0.008350363001227379\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 4.712625980377197 | KNN Loss: 4.665591716766357 | CLS Loss: 0.047034382820129395\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 4.757635593414307 | KNN Loss: 4.741124153137207 | CLS Loss: 0.016511619091033936\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 4.755539417266846 | KNN Loss: 4.731662273406982 | CLS Loss: 0.023876957595348358\n",
      "Epoch: 078, Loss: 4.7180, Train: 0.9950, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 4.68314790725708 | KNN Loss: 4.677443027496338 | CLS Loss: 0.005704689305275679\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 4.776202201843262 | KNN Loss: 4.7629008293151855 | CLS Loss: 0.01330140233039856\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 4.699650287628174 | KNN Loss: 4.692607879638672 | CLS Loss: 0.0070425462909042835\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 4.760996341705322 | KNN Loss: 4.728214740753174 | CLS Loss: 0.032781634479761124\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 4.728753566741943 | KNN Loss: 4.708362579345703 | CLS Loss: 0.02039097435772419\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 4.7306809425354 | KNN Loss: 4.707457542419434 | CLS Loss: 0.023223483934998512\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 4.758670330047607 | KNN Loss: 4.722517490386963 | CLS Loss: 0.03615294396877289\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 4.668504238128662 | KNN Loss: 4.641254425048828 | CLS Loss: 0.027249790728092194\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 4.706059455871582 | KNN Loss: 4.702026844024658 | CLS Loss: 0.004032618831843138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 4.749201774597168 | KNN Loss: 4.71890926361084 | CLS Loss: 0.03029240481555462\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 4.674299716949463 | KNN Loss: 4.666773796081543 | CLS Loss: 0.00752576207742095\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 4.729270935058594 | KNN Loss: 4.701777458190918 | CLS Loss: 0.027493465691804886\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 4.7278151512146 | KNN Loss: 4.6826558113098145 | CLS Loss: 0.04515913128852844\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 4.664077281951904 | KNN Loss: 4.647403240203857 | CLS Loss: 0.016674185171723366\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 4.693663597106934 | KNN Loss: 4.684532642364502 | CLS Loss: 0.009130863472819328\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 4.692898750305176 | KNN Loss: 4.676730632781982 | CLS Loss: 0.016168085858225822\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 4.729942321777344 | KNN Loss: 4.717080116271973 | CLS Loss: 0.012862232513725758\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 4.731503486633301 | KNN Loss: 4.71286153793335 | CLS Loss: 0.018642183393239975\n",
      "Epoch: 079, Loss: 4.7187, Train: 0.9943, Valid: 0.9859, Best: 0.9870\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 4.664286136627197 | KNN Loss: 4.655846118927002 | CLS Loss: 0.008440183475613594\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 4.7050628662109375 | KNN Loss: 4.689617156982422 | CLS Loss: 0.01544557511806488\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 4.703919887542725 | KNN Loss: 4.674006938934326 | CLS Loss: 0.02991279773414135\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 4.768081188201904 | KNN Loss: 4.759019374847412 | CLS Loss: 0.00906204991042614\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 4.70516300201416 | KNN Loss: 4.677994251251221 | CLS Loss: 0.027168555185198784\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 4.720490455627441 | KNN Loss: 4.6799702644348145 | CLS Loss: 0.04052016884088516\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 4.735357761383057 | KNN Loss: 4.72601842880249 | CLS Loss: 0.009339487180113792\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 4.695245265960693 | KNN Loss: 4.6788835525512695 | CLS Loss: 0.01636151410639286\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 4.669938087463379 | KNN Loss: 4.651646137237549 | CLS Loss: 0.01829197071492672\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 4.708479404449463 | KNN Loss: 4.690308570861816 | CLS Loss: 0.018171068280935287\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 4.70758581161499 | KNN Loss: 4.663928985595703 | CLS Loss: 0.04365680366754532\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 4.710416316986084 | KNN Loss: 4.664520263671875 | CLS Loss: 0.04589585214853287\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 4.713590621948242 | KNN Loss: 4.686850547790527 | CLS Loss: 0.02674001082777977\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 4.6935930252075195 | KNN Loss: 4.673079013824463 | CLS Loss: 0.020513778552412987\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 4.684385776519775 | KNN Loss: 4.659797191619873 | CLS Loss: 0.02458835579454899\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 4.721034526824951 | KNN Loss: 4.702071189880371 | CLS Loss: 0.0189631637185812\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 4.661571979522705 | KNN Loss: 4.652675151824951 | CLS Loss: 0.0088967215269804\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 4.685549736022949 | KNN Loss: 4.670276165008545 | CLS Loss: 0.015273393131792545\n",
      "Epoch: 080, Loss: 4.7166, Train: 0.9932, Valid: 0.9844, Best: 0.9870\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 4.723536491394043 | KNN Loss: 4.7080159187316895 | CLS Loss: 0.015520470216870308\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 4.700754165649414 | KNN Loss: 4.688202381134033 | CLS Loss: 0.012551696039736271\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 4.766048431396484 | KNN Loss: 4.759671688079834 | CLS Loss: 0.006376712117344141\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 4.6982550621032715 | KNN Loss: 4.672031879425049 | CLS Loss: 0.02622322365641594\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 4.721303462982178 | KNN Loss: 4.697208881378174 | CLS Loss: 0.02409464307129383\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 4.747269630432129 | KNN Loss: 4.734521389007568 | CLS Loss: 0.01274810079485178\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 4.730949401855469 | KNN Loss: 4.721661567687988 | CLS Loss: 0.00928778201341629\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 4.78349494934082 | KNN Loss: 4.7519612312316895 | CLS Loss: 0.03153355419635773\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 4.695257663726807 | KNN Loss: 4.677780628204346 | CLS Loss: 0.017476940527558327\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 4.668318748474121 | KNN Loss: 4.643674850463867 | CLS Loss: 0.024643879383802414\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 4.723109722137451 | KNN Loss: 4.709797382354736 | CLS Loss: 0.013312354683876038\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 4.6810760498046875 | KNN Loss: 4.671024799346924 | CLS Loss: 0.010051272809505463\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 4.6810994148254395 | KNN Loss: 4.676728248596191 | CLS Loss: 0.004371303599327803\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 4.707115173339844 | KNN Loss: 4.693092346191406 | CLS Loss: 0.014023063704371452\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 4.683032512664795 | KNN Loss: 4.668891429901123 | CLS Loss: 0.014141203835606575\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 4.706019878387451 | KNN Loss: 4.687398433685303 | CLS Loss: 0.018621589988470078\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 4.697979927062988 | KNN Loss: 4.679609298706055 | CLS Loss: 0.01837044022977352\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 4.687196731567383 | KNN Loss: 4.680554389953613 | CLS Loss: 0.006642424967139959\n",
      "Epoch: 081, Loss: 4.7118, Train: 0.9961, Valid: 0.9868, Best: 0.9870\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 4.705253601074219 | KNN Loss: 4.683703422546387 | CLS Loss: 0.021550334990024567\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 4.7449750900268555 | KNN Loss: 4.736572265625 | CLS Loss: 0.008403006941080093\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 4.817747116088867 | KNN Loss: 4.783685684204102 | CLS Loss: 0.03406137600541115\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 4.768215656280518 | KNN Loss: 4.735259532928467 | CLS Loss: 0.03295605629682541\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 4.732522010803223 | KNN Loss: 4.702585697174072 | CLS Loss: 0.029936186969280243\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 4.715531349182129 | KNN Loss: 4.705445289611816 | CLS Loss: 0.010086248628795147\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 4.775899887084961 | KNN Loss: 4.738577365875244 | CLS Loss: 0.03732241317629814\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 4.734370708465576 | KNN Loss: 4.689232349395752 | CLS Loss: 0.045138269662857056\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 4.738320827484131 | KNN Loss: 4.712152481079102 | CLS Loss: 0.026168562471866608\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 4.764156818389893 | KNN Loss: 4.728578090667725 | CLS Loss: 0.03557881340384483\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 4.694794654846191 | KNN Loss: 4.679965972900391 | CLS Loss: 0.014828533865511417\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 4.716552734375 | KNN Loss: 4.7067179679870605 | CLS Loss: 0.009834595024585724\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 4.742092132568359 | KNN Loss: 4.739409446716309 | CLS Loss: 0.0026824951637536287\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 4.681408882141113 | KNN Loss: 4.662395477294922 | CLS Loss: 0.019013455137610435\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 4.786191940307617 | KNN Loss: 4.769131183624268 | CLS Loss: 0.017060713842511177\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 4.692413330078125 | KNN Loss: 4.6766133308410645 | CLS Loss: 0.015799978747963905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 4.694540023803711 | KNN Loss: 4.6625590324401855 | CLS Loss: 0.03198079764842987\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 4.677211284637451 | KNN Loss: 4.643377780914307 | CLS Loss: 0.03383341059088707\n",
      "Epoch: 082, Loss: 4.7175, Train: 0.9944, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 4.676074981689453 | KNN Loss: 4.665339469909668 | CLS Loss: 0.010735508985817432\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 4.698059558868408 | KNN Loss: 4.6681389808654785 | CLS Loss: 0.029920395463705063\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 4.665213108062744 | KNN Loss: 4.6573405265808105 | CLS Loss: 0.007872720248997211\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 4.653903007507324 | KNN Loss: 4.6487250328063965 | CLS Loss: 0.005178028251975775\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 4.6849517822265625 | KNN Loss: 4.680814266204834 | CLS Loss: 0.00413739075884223\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 4.7409257888793945 | KNN Loss: 4.696162223815918 | CLS Loss: 0.04476356506347656\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 4.709688663482666 | KNN Loss: 4.67760705947876 | CLS Loss: 0.032081425189971924\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 4.713789463043213 | KNN Loss: 4.698931694030762 | CLS Loss: 0.01485784724354744\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 4.6603875160217285 | KNN Loss: 4.652566432952881 | CLS Loss: 0.007821249775588512\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 4.700793743133545 | KNN Loss: 4.680731773376465 | CLS Loss: 0.0200620386749506\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 4.704971790313721 | KNN Loss: 4.685478687286377 | CLS Loss: 0.01949288882315159\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 4.7944841384887695 | KNN Loss: 4.781164169311523 | CLS Loss: 0.013319763354957104\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 4.6741156578063965 | KNN Loss: 4.653952598571777 | CLS Loss: 0.020163001492619514\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 4.729959964752197 | KNN Loss: 4.678053379058838 | CLS Loss: 0.05190655589103699\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 4.827098369598389 | KNN Loss: 4.802944660186768 | CLS Loss: 0.024153629317879677\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 4.7688188552856445 | KNN Loss: 4.731834411621094 | CLS Loss: 0.036984652280807495\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 4.688750743865967 | KNN Loss: 4.6825714111328125 | CLS Loss: 0.006179296877235174\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 4.763299942016602 | KNN Loss: 4.734218597412109 | CLS Loss: 0.02908121794462204\n",
      "Epoch: 083, Loss: 4.7196, Train: 0.9895, Valid: 0.9842, Best: 0.9872\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 4.728442192077637 | KNN Loss: 4.716823577880859 | CLS Loss: 0.011618620716035366\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 4.707695007324219 | KNN Loss: 4.684508800506592 | CLS Loss: 0.023186298087239265\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 4.822959899902344 | KNN Loss: 4.803597927093506 | CLS Loss: 0.019362112507224083\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 4.849735736846924 | KNN Loss: 4.811115264892578 | CLS Loss: 0.03862033039331436\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 4.807713508605957 | KNN Loss: 4.780628204345703 | CLS Loss: 0.027085283771157265\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 4.850281238555908 | KNN Loss: 4.8142523765563965 | CLS Loss: 0.03602892532944679\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 4.92194938659668 | KNN Loss: 4.850445747375488 | CLS Loss: 0.07150356471538544\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 4.7717413902282715 | KNN Loss: 4.722567558288574 | CLS Loss: 0.04917363077402115\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 4.718148231506348 | KNN Loss: 4.701665878295898 | CLS Loss: 0.016482116654515266\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 4.812905788421631 | KNN Loss: 4.787734031677246 | CLS Loss: 0.025171848013997078\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 4.719388484954834 | KNN Loss: 4.6803107261657715 | CLS Loss: 0.03907780349254608\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 4.7473225593566895 | KNN Loss: 4.717091083526611 | CLS Loss: 0.030231652781367302\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 4.785682678222656 | KNN Loss: 4.726508617401123 | CLS Loss: 0.0591740645468235\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 4.80088472366333 | KNN Loss: 4.7684326171875 | CLS Loss: 0.03245189040899277\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 4.714752674102783 | KNN Loss: 4.687660217285156 | CLS Loss: 0.02709236927330494\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 4.7495832443237305 | KNN Loss: 4.7197442054748535 | CLS Loss: 0.02983926609158516\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 4.775223731994629 | KNN Loss: 4.756256103515625 | CLS Loss: 0.018967604264616966\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 4.715967178344727 | KNN Loss: 4.706384658813477 | CLS Loss: 0.00958237610757351\n",
      "Epoch: 084, Loss: 4.7665, Train: 0.9929, Valid: 0.9851, Best: 0.9872\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 4.702311038970947 | KNN Loss: 4.684718608856201 | CLS Loss: 0.01759237051010132\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 4.699926376342773 | KNN Loss: 4.689472198486328 | CLS Loss: 0.010454319417476654\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 4.718107223510742 | KNN Loss: 4.6963701248168945 | CLS Loss: 0.021737264469265938\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 4.807156562805176 | KNN Loss: 4.7892866134643555 | CLS Loss: 0.01786995679140091\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 4.6820197105407715 | KNN Loss: 4.661433219909668 | CLS Loss: 0.02058625966310501\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 4.644130706787109 | KNN Loss: 4.631124973297119 | CLS Loss: 0.013005625456571579\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 4.699204921722412 | KNN Loss: 4.681414604187012 | CLS Loss: 0.017790377140045166\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 4.759951114654541 | KNN Loss: 4.752791404724121 | CLS Loss: 0.007159759756177664\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 4.66420316696167 | KNN Loss: 4.6518449783325195 | CLS Loss: 0.012358206324279308\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 4.731869697570801 | KNN Loss: 4.718791484832764 | CLS Loss: 0.013078277930617332\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 4.674282073974609 | KNN Loss: 4.664446830749512 | CLS Loss: 0.009835105389356613\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 4.652082920074463 | KNN Loss: 4.6322550773620605 | CLS Loss: 0.01982799544930458\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 4.673164367675781 | KNN Loss: 4.644435405731201 | CLS Loss: 0.028728779405355453\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 4.716360092163086 | KNN Loss: 4.712379455566406 | CLS Loss: 0.003980493173003197\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 4.682061672210693 | KNN Loss: 4.674266815185547 | CLS Loss: 0.007795050740242004\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 4.736029624938965 | KNN Loss: 4.7055768966674805 | CLS Loss: 0.030452702194452286\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 4.753284931182861 | KNN Loss: 4.720162391662598 | CLS Loss: 0.03312245011329651\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 4.691488742828369 | KNN Loss: 4.6773200035095215 | CLS Loss: 0.014168697409331799\n",
      "Epoch: 085, Loss: 4.7155, Train: 0.9945, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 4.748220920562744 | KNN Loss: 4.713778018951416 | CLS Loss: 0.03444276005029678\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 4.760192394256592 | KNN Loss: 4.755478382110596 | CLS Loss: 0.004713988862931728\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 4.6923136711120605 | KNN Loss: 4.671676158905029 | CLS Loss: 0.02063761278986931\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 4.749799728393555 | KNN Loss: 4.715566635131836 | CLS Loss: 0.03423288092017174\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 4.670304298400879 | KNN Loss: 4.641470432281494 | CLS Loss: 0.028834065422415733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 4.665544033050537 | KNN Loss: 4.661722660064697 | CLS Loss: 0.0038213187362998724\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 4.6744303703308105 | KNN Loss: 4.663593292236328 | CLS Loss: 0.01083712000399828\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 4.649409770965576 | KNN Loss: 4.638027191162109 | CLS Loss: 0.011382469907402992\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 4.736215591430664 | KNN Loss: 4.73093318939209 | CLS Loss: 0.005282334052026272\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 4.667987823486328 | KNN Loss: 4.641734600067139 | CLS Loss: 0.02625301666557789\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 4.731301307678223 | KNN Loss: 4.70539665222168 | CLS Loss: 0.025904793292284012\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 4.7266340255737305 | KNN Loss: 4.708229064941406 | CLS Loss: 0.018404977396130562\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 4.7539567947387695 | KNN Loss: 4.697652339935303 | CLS Loss: 0.056304480880498886\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 4.689952373504639 | KNN Loss: 4.6740922927856445 | CLS Loss: 0.01586017943918705\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 4.6942548751831055 | KNN Loss: 4.6721367835998535 | CLS Loss: 0.022118285298347473\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 4.709649085998535 | KNN Loss: 4.693155765533447 | CLS Loss: 0.016493089497089386\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 4.725441932678223 | KNN Loss: 4.713373184204102 | CLS Loss: 0.012068902142345905\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 4.672011852264404 | KNN Loss: 4.660610198974609 | CLS Loss: 0.011401859112083912\n",
      "Epoch: 086, Loss: 4.7116, Train: 0.9952, Valid: 0.9865, Best: 0.9872\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 4.710530757904053 | KNN Loss: 4.679431915283203 | CLS Loss: 0.031098833307623863\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 4.680397987365723 | KNN Loss: 4.6711931228637695 | CLS Loss: 0.00920465774834156\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 4.674623012542725 | KNN Loss: 4.645503044128418 | CLS Loss: 0.029120201244950294\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 4.788120746612549 | KNN Loss: 4.775348663330078 | CLS Loss: 0.012772051617503166\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 4.712066173553467 | KNN Loss: 4.708058834075928 | CLS Loss: 0.004007201176136732\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 4.696147441864014 | KNN Loss: 4.68142032623291 | CLS Loss: 0.014726962894201279\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 4.709726333618164 | KNN Loss: 4.692297458648682 | CLS Loss: 0.017428869381546974\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 4.666414737701416 | KNN Loss: 4.654750347137451 | CLS Loss: 0.011664162389934063\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 4.684638023376465 | KNN Loss: 4.665734767913818 | CLS Loss: 0.018903393298387527\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 4.685170650482178 | KNN Loss: 4.676276683807373 | CLS Loss: 0.008893923833966255\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 4.719747066497803 | KNN Loss: 4.712230682373047 | CLS Loss: 0.007516307756304741\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 4.65510892868042 | KNN Loss: 4.644033908843994 | CLS Loss: 0.011075211688876152\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 4.792835235595703 | KNN Loss: 4.778534412384033 | CLS Loss: 0.014300670474767685\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 4.718497276306152 | KNN Loss: 4.688220500946045 | CLS Loss: 0.030276892706751823\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 4.679427146911621 | KNN Loss: 4.662822723388672 | CLS Loss: 0.016604620963335037\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 4.737155437469482 | KNN Loss: 4.718552112579346 | CLS Loss: 0.018603088334202766\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 4.68276834487915 | KNN Loss: 4.677001476287842 | CLS Loss: 0.005766719114035368\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 4.739503383636475 | KNN Loss: 4.728225231170654 | CLS Loss: 0.011278058402240276\n",
      "Epoch: 087, Loss: 4.7143, Train: 0.9946, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 4.825351715087891 | KNN Loss: 4.803410053253174 | CLS Loss: 0.021941443905234337\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 4.66949462890625 | KNN Loss: 4.656910419464111 | CLS Loss: 0.012584089301526546\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 4.71344518661499 | KNN Loss: 4.682909965515137 | CLS Loss: 0.030535224825143814\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 4.771653175354004 | KNN Loss: 4.756624698638916 | CLS Loss: 0.015028468333184719\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 4.684333801269531 | KNN Loss: 4.675905227661133 | CLS Loss: 0.008428700268268585\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 4.772091865539551 | KNN Loss: 4.760124206542969 | CLS Loss: 0.011967622675001621\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 4.6845221519470215 | KNN Loss: 4.668239116668701 | CLS Loss: 0.016283050179481506\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 4.769776821136475 | KNN Loss: 4.751801013946533 | CLS Loss: 0.017975779250264168\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 4.794191837310791 | KNN Loss: 4.779623985290527 | CLS Loss: 0.014567871578037739\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 4.7304182052612305 | KNN Loss: 4.7093610763549805 | CLS Loss: 0.02105702832341194\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 4.714088439941406 | KNN Loss: 4.702803611755371 | CLS Loss: 0.0112848412245512\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 4.728283882141113 | KNN Loss: 4.71789026260376 | CLS Loss: 0.010393799282610416\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 4.760953426361084 | KNN Loss: 4.72116231918335 | CLS Loss: 0.03979114443063736\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 4.771362781524658 | KNN Loss: 4.761302947998047 | CLS Loss: 0.010059828869998455\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 4.724637985229492 | KNN Loss: 4.708583354949951 | CLS Loss: 0.016054760664701462\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 4.688159465789795 | KNN Loss: 4.658442974090576 | CLS Loss: 0.02971627376973629\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 4.720118045806885 | KNN Loss: 4.707106113433838 | CLS Loss: 0.013012036681175232\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 4.67654275894165 | KNN Loss: 4.653849124908447 | CLS Loss: 0.022693736478686333\n",
      "Epoch: 088, Loss: 4.7178, Train: 0.9940, Valid: 0.9858, Best: 0.9872\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 4.712252140045166 | KNN Loss: 4.669529438018799 | CLS Loss: 0.04272263124585152\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 4.708718776702881 | KNN Loss: 4.704307556152344 | CLS Loss: 0.004411320202052593\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 4.687117576599121 | KNN Loss: 4.6531500816345215 | CLS Loss: 0.033967386931180954\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 4.701787948608398 | KNN Loss: 4.696562767028809 | CLS Loss: 0.005225402303040028\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 4.724300861358643 | KNN Loss: 4.6954426765441895 | CLS Loss: 0.028858104720711708\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 4.728658199310303 | KNN Loss: 4.693567752838135 | CLS Loss: 0.035090506076812744\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 4.681367874145508 | KNN Loss: 4.67575740814209 | CLS Loss: 0.00561048649251461\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 4.682102203369141 | KNN Loss: 4.675477981567383 | CLS Loss: 0.0066240704618394375\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 4.776843547821045 | KNN Loss: 4.759871482849121 | CLS Loss: 0.016971977427601814\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 4.715032577514648 | KNN Loss: 4.687326908111572 | CLS Loss: 0.027705883607268333\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 4.7124738693237305 | KNN Loss: 4.684751033782959 | CLS Loss: 0.02772272750735283\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 4.689871788024902 | KNN Loss: 4.672908782958984 | CLS Loss: 0.016963209956884384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 4.710534572601318 | KNN Loss: 4.706701755523682 | CLS Loss: 0.0038326869253069162\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 4.721573352813721 | KNN Loss: 4.687057971954346 | CLS Loss: 0.034515202045440674\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 4.664742946624756 | KNN Loss: 4.656628608703613 | CLS Loss: 0.008114155381917953\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 4.746030330657959 | KNN Loss: 4.723965167999268 | CLS Loss: 0.022065024822950363\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 4.761634826660156 | KNN Loss: 4.739597320556641 | CLS Loss: 0.022037314251065254\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 4.790550708770752 | KNN Loss: 4.7768659591674805 | CLS Loss: 0.01368456706404686\n",
      "Epoch: 089, Loss: 4.7135, Train: 0.9946, Valid: 0.9858, Best: 0.9872\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 4.6970906257629395 | KNN Loss: 4.680536270141602 | CLS Loss: 0.01655414327979088\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 4.732559680938721 | KNN Loss: 4.711486339569092 | CLS Loss: 0.02107349969446659\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 4.6981120109558105 | KNN Loss: 4.6785759925842285 | CLS Loss: 0.019535992294549942\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 4.766907691955566 | KNN Loss: 4.732113838195801 | CLS Loss: 0.034794047474861145\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 4.787062168121338 | KNN Loss: 4.754345417022705 | CLS Loss: 0.03271687030792236\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 4.671843528747559 | KNN Loss: 4.655691623687744 | CLS Loss: 0.016151780262589455\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 4.752857208251953 | KNN Loss: 4.741788387298584 | CLS Loss: 0.011068707332015038\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 4.714690685272217 | KNN Loss: 4.708859920501709 | CLS Loss: 0.005830526817589998\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 4.755420207977295 | KNN Loss: 4.746965408325195 | CLS Loss: 0.008454586379230022\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 4.726047515869141 | KNN Loss: 4.695423126220703 | CLS Loss: 0.03062451258301735\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 4.670034885406494 | KNN Loss: 4.64612340927124 | CLS Loss: 0.02391165681183338\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 4.674698829650879 | KNN Loss: 4.663692951202393 | CLS Loss: 0.011005707085132599\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 4.686959743499756 | KNN Loss: 4.651668071746826 | CLS Loss: 0.03529145196080208\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 4.682382106781006 | KNN Loss: 4.661060333251953 | CLS Loss: 0.0213218554854393\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 4.731094837188721 | KNN Loss: 4.717833042144775 | CLS Loss: 0.01326197199523449\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 4.680112361907959 | KNN Loss: 4.673877239227295 | CLS Loss: 0.0062349834479391575\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 4.704293251037598 | KNN Loss: 4.688430309295654 | CLS Loss: 0.015862787142395973\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 4.791564464569092 | KNN Loss: 4.7735915184021 | CLS Loss: 0.01797308772802353\n",
      "Epoch: 090, Loss: 4.7148, Train: 0.9951, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 4.661396026611328 | KNN Loss: 4.651492118835449 | CLS Loss: 0.00990397110581398\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 4.7598557472229 | KNN Loss: 4.738912582397461 | CLS Loss: 0.020943190902471542\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 4.7402729988098145 | KNN Loss: 4.702913761138916 | CLS Loss: 0.03735927492380142\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 4.712788105010986 | KNN Loss: 4.693321228027344 | CLS Loss: 0.01946686953306198\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 4.715240001678467 | KNN Loss: 4.696932315826416 | CLS Loss: 0.01830778643488884\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 4.691072463989258 | KNN Loss: 4.675229549407959 | CLS Loss: 0.015842804685235023\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 4.803637981414795 | KNN Loss: 4.794632434844971 | CLS Loss: 0.00900565180927515\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 4.702388286590576 | KNN Loss: 4.690971374511719 | CLS Loss: 0.011416815221309662\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 4.834410667419434 | KNN Loss: 4.800137042999268 | CLS Loss: 0.03427343815565109\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 4.7118611335754395 | KNN Loss: 4.681168079376221 | CLS Loss: 0.030693048611283302\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 4.737029075622559 | KNN Loss: 4.714682102203369 | CLS Loss: 0.02234719693660736\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 4.694206237792969 | KNN Loss: 4.6903791427612305 | CLS Loss: 0.0038269832730293274\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 4.733074188232422 | KNN Loss: 4.710242748260498 | CLS Loss: 0.022831235080957413\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 4.7204670906066895 | KNN Loss: 4.688002586364746 | CLS Loss: 0.032464537769556046\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 4.697632312774658 | KNN Loss: 4.6838059425354 | CLS Loss: 0.013826508074998856\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 4.68738317489624 | KNN Loss: 4.666092872619629 | CLS Loss: 0.021290436387062073\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 4.6843366622924805 | KNN Loss: 4.667369842529297 | CLS Loss: 0.01696685515344143\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 4.721029281616211 | KNN Loss: 4.707447528839111 | CLS Loss: 0.013581912033259869\n",
      "Epoch: 091, Loss: 4.7171, Train: 0.9963, Valid: 0.9875, Best: 0.9875\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 4.7198896408081055 | KNN Loss: 4.687553405761719 | CLS Loss: 0.03233626112341881\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 4.644966125488281 | KNN Loss: 4.638047695159912 | CLS Loss: 0.006918652448803186\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 4.747284412384033 | KNN Loss: 4.7385149002075195 | CLS Loss: 0.00876963697373867\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 4.766232013702393 | KNN Loss: 4.745893955230713 | CLS Loss: 0.020337853580713272\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 4.692377090454102 | KNN Loss: 4.683061599731445 | CLS Loss: 0.009315282106399536\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 4.700862884521484 | KNN Loss: 4.682177543640137 | CLS Loss: 0.018685542047023773\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 4.671765327453613 | KNN Loss: 4.658824443817139 | CLS Loss: 0.012941110879182816\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 4.795018672943115 | KNN Loss: 4.789616107940674 | CLS Loss: 0.005402475595474243\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 4.753978729248047 | KNN Loss: 4.735941410064697 | CLS Loss: 0.018037334084510803\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 4.70136022567749 | KNN Loss: 4.691466331481934 | CLS Loss: 0.009893854148685932\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 4.774791717529297 | KNN Loss: 4.7628302574157715 | CLS Loss: 0.011961441487073898\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 4.690823554992676 | KNN Loss: 4.686548709869385 | CLS Loss: 0.004274872597306967\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 4.701084613800049 | KNN Loss: 4.664131164550781 | CLS Loss: 0.03695349767804146\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 4.72999382019043 | KNN Loss: 4.724760055541992 | CLS Loss: 0.0052335564978420734\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 4.832383155822754 | KNN Loss: 4.8082756996154785 | CLS Loss: 0.02410738915205002\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 4.687285900115967 | KNN Loss: 4.671152114868164 | CLS Loss: 0.016133587807416916\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 4.68247127532959 | KNN Loss: 4.674389362335205 | CLS Loss: 0.008082086220383644\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 4.739336013793945 | KNN Loss: 4.705546855926514 | CLS Loss: 0.03378915414214134\n",
      "Epoch: 092, Loss: 4.7231, Train: 0.9955, Valid: 0.9864, Best: 0.9875\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 4.776016712188721 | KNN Loss: 4.736460208892822 | CLS Loss: 0.039556581526994705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 4.691937446594238 | KNN Loss: 4.677088737487793 | CLS Loss: 0.01484874077141285\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 4.669137001037598 | KNN Loss: 4.64680290222168 | CLS Loss: 0.022334007546305656\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 4.840211868286133 | KNN Loss: 4.810022354125977 | CLS Loss: 0.03018931858241558\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 4.7588887214660645 | KNN Loss: 4.724839687347412 | CLS Loss: 0.03404882550239563\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 4.670864105224609 | KNN Loss: 4.652909278869629 | CLS Loss: 0.017954975366592407\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 4.672861099243164 | KNN Loss: 4.663883686065674 | CLS Loss: 0.008977356366813183\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 4.652175426483154 | KNN Loss: 4.64774751663208 | CLS Loss: 0.004427762236446142\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 4.735976696014404 | KNN Loss: 4.718782424926758 | CLS Loss: 0.01719450019299984\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 4.711058616638184 | KNN Loss: 4.686598300933838 | CLS Loss: 0.02446022257208824\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 4.701569080352783 | KNN Loss: 4.670734405517578 | CLS Loss: 0.030834577977657318\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 4.674201011657715 | KNN Loss: 4.667444705963135 | CLS Loss: 0.006756083574146032\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 4.684673309326172 | KNN Loss: 4.673703193664551 | CLS Loss: 0.010969900526106358\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 4.71621561050415 | KNN Loss: 4.691037178039551 | CLS Loss: 0.025178248062729836\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 4.7056121826171875 | KNN Loss: 4.682199954986572 | CLS Loss: 0.02341211587190628\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 4.668354511260986 | KNN Loss: 4.6632981300354 | CLS Loss: 0.005056530702859163\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 4.679224014282227 | KNN Loss: 4.674759387969971 | CLS Loss: 0.004464851692318916\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 4.694668292999268 | KNN Loss: 4.6685919761657715 | CLS Loss: 0.026076316833496094\n",
      "Epoch: 093, Loss: 4.7117, Train: 0.9948, Valid: 0.9866, Best: 0.9875\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 4.736819267272949 | KNN Loss: 4.715693950653076 | CLS Loss: 0.02112519182264805\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 4.741335391998291 | KNN Loss: 4.714201927185059 | CLS Loss: 0.02713358961045742\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 4.888000011444092 | KNN Loss: 4.848923683166504 | CLS Loss: 0.03907611221075058\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 4.707029342651367 | KNN Loss: 4.686926364898682 | CLS Loss: 0.02010318823158741\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 4.696258544921875 | KNN Loss: 4.678158283233643 | CLS Loss: 0.018100429326295853\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 4.81532096862793 | KNN Loss: 4.800899028778076 | CLS Loss: 0.014421925880014896\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 4.7140069007873535 | KNN Loss: 4.697772979736328 | CLS Loss: 0.016233809292316437\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 4.723873138427734 | KNN Loss: 4.696788311004639 | CLS Loss: 0.027085019275546074\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 4.738610744476318 | KNN Loss: 4.721234321594238 | CLS Loss: 0.01737629994750023\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 4.764177322387695 | KNN Loss: 4.753726482391357 | CLS Loss: 0.010450868867337704\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 4.724826812744141 | KNN Loss: 4.705208778381348 | CLS Loss: 0.019618220627307892\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 4.786502361297607 | KNN Loss: 4.764281749725342 | CLS Loss: 0.022220518440008163\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 4.693270206451416 | KNN Loss: 4.6819167137146 | CLS Loss: 0.011353448033332825\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 4.690145492553711 | KNN Loss: 4.6770524978637695 | CLS Loss: 0.01309285033494234\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 4.767309188842773 | KNN Loss: 4.744334697723389 | CLS Loss: 0.022974273189902306\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 4.6676177978515625 | KNN Loss: 4.6642537117004395 | CLS Loss: 0.0033641967456787825\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 4.757603645324707 | KNN Loss: 4.738690376281738 | CLS Loss: 0.018913188949227333\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 4.712642669677734 | KNN Loss: 4.685869216918945 | CLS Loss: 0.026773665100336075\n",
      "Epoch: 094, Loss: 4.7158, Train: 0.9950, Valid: 0.9866, Best: 0.9875\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 4.697227478027344 | KNN Loss: 4.666618347167969 | CLS Loss: 0.03060893528163433\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 4.660400390625 | KNN Loss: 4.6518940925598145 | CLS Loss: 0.008506117388606071\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 4.668123245239258 | KNN Loss: 4.663008213043213 | CLS Loss: 0.005114973988384008\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 4.716858863830566 | KNN Loss: 4.702953815460205 | CLS Loss: 0.013905085623264313\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 4.78778600692749 | KNN Loss: 4.781300067901611 | CLS Loss: 0.006486175116151571\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 4.719088554382324 | KNN Loss: 4.708320140838623 | CLS Loss: 0.010768533684313297\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 4.789429664611816 | KNN Loss: 4.760087013244629 | CLS Loss: 0.02934264950454235\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 4.71551513671875 | KNN Loss: 4.695038795471191 | CLS Loss: 0.020476223900914192\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 4.81504487991333 | KNN Loss: 4.785506725311279 | CLS Loss: 0.029538093134760857\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 4.769962787628174 | KNN Loss: 4.710626125335693 | CLS Loss: 0.059336453676223755\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 4.716747283935547 | KNN Loss: 4.705521583557129 | CLS Loss: 0.011225607246160507\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 4.716694355010986 | KNN Loss: 4.701439380645752 | CLS Loss: 0.015255178324878216\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 4.666400909423828 | KNN Loss: 4.639157295227051 | CLS Loss: 0.027243653312325478\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 4.676148891448975 | KNN Loss: 4.651060581207275 | CLS Loss: 0.02508821152150631\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 4.714494228363037 | KNN Loss: 4.703258037567139 | CLS Loss: 0.011236079037189484\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 4.681572437286377 | KNN Loss: 4.673864841461182 | CLS Loss: 0.007707715965807438\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 4.736512660980225 | KNN Loss: 4.728329181671143 | CLS Loss: 0.008183394558727741\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 4.704487323760986 | KNN Loss: 4.695655345916748 | CLS Loss: 0.008832000195980072\n",
      "Epoch: 095, Loss: 4.7087, Train: 0.9944, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 4.728044033050537 | KNN Loss: 4.697775363922119 | CLS Loss: 0.030268659815192223\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 4.683422088623047 | KNN Loss: 4.67827844619751 | CLS Loss: 0.005143445450812578\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 4.751276969909668 | KNN Loss: 4.745960235595703 | CLS Loss: 0.005316729191690683\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 4.716304302215576 | KNN Loss: 4.688241481781006 | CLS Loss: 0.028062589466571808\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 4.65562629699707 | KNN Loss: 4.647943496704102 | CLS Loss: 0.00768285384401679\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 4.81846284866333 | KNN Loss: 4.775780200958252 | CLS Loss: 0.04268276318907738\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 4.660086154937744 | KNN Loss: 4.642439365386963 | CLS Loss: 0.017646852880716324\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 4.8005146980285645 | KNN Loss: 4.786073207855225 | CLS Loss: 0.014441529288887978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 4.7123565673828125 | KNN Loss: 4.669720649719238 | CLS Loss: 0.042636122554540634\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 4.744257926940918 | KNN Loss: 4.701762676239014 | CLS Loss: 0.042495302855968475\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 4.743129253387451 | KNN Loss: 4.708944797515869 | CLS Loss: 0.03418467566370964\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 4.729891300201416 | KNN Loss: 4.713491439819336 | CLS Loss: 0.016399793326854706\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 4.69455623626709 | KNN Loss: 4.666153430938721 | CLS Loss: 0.02840261161327362\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 4.66073751449585 | KNN Loss: 4.648351669311523 | CLS Loss: 0.012385695241391659\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 4.741384506225586 | KNN Loss: 4.713133335113525 | CLS Loss: 0.028251243755221367\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 4.713798522949219 | KNN Loss: 4.699870586395264 | CLS Loss: 0.013927854597568512\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 4.7237043380737305 | KNN Loss: 4.706379413604736 | CLS Loss: 0.01732487604022026\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 4.678997039794922 | KNN Loss: 4.672793388366699 | CLS Loss: 0.006203618831932545\n",
      "Epoch: 096, Loss: 4.7154, Train: 0.9958, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 4.670707702636719 | KNN Loss: 4.650659561157227 | CLS Loss: 0.02004835195839405\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 4.665720462799072 | KNN Loss: 4.657629489898682 | CLS Loss: 0.008090795949101448\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 4.677264213562012 | KNN Loss: 4.668956279754639 | CLS Loss: 0.008307728916406631\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 4.691812038421631 | KNN Loss: 4.671319484710693 | CLS Loss: 0.020492400974035263\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 4.831668853759766 | KNN Loss: 4.794357776641846 | CLS Loss: 0.03731130436062813\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 4.695934295654297 | KNN Loss: 4.68590784072876 | CLS Loss: 0.010026630014181137\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 4.688085079193115 | KNN Loss: 4.668722629547119 | CLS Loss: 0.019362401217222214\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 4.7196550369262695 | KNN Loss: 4.706661224365234 | CLS Loss: 0.012993715703487396\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 4.709280967712402 | KNN Loss: 4.694660663604736 | CLS Loss: 0.014620413072407246\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 4.700357913970947 | KNN Loss: 4.693663597106934 | CLS Loss: 0.006694150157272816\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 4.740853309631348 | KNN Loss: 4.696579933166504 | CLS Loss: 0.04427345097064972\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 4.7435808181762695 | KNN Loss: 4.705315113067627 | CLS Loss: 0.038265764713287354\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 4.67152214050293 | KNN Loss: 4.669964790344238 | CLS Loss: 0.0015572123229503632\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 4.741950035095215 | KNN Loss: 4.7325310707092285 | CLS Loss: 0.009419201873242855\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 4.723753929138184 | KNN Loss: 4.695133209228516 | CLS Loss: 0.028620639815926552\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 4.679668426513672 | KNN Loss: 4.663815021514893 | CLS Loss: 0.015853211283683777\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 4.679924964904785 | KNN Loss: 4.655837535858154 | CLS Loss: 0.024087537080049515\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 4.794716835021973 | KNN Loss: 4.7605085372924805 | CLS Loss: 0.03420807048678398\n",
      "Epoch: 097, Loss: 4.7123, Train: 0.9946, Valid: 0.9852, Best: 0.9875\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 4.759174346923828 | KNN Loss: 4.751873970031738 | CLS Loss: 0.007300153374671936\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 4.663797855377197 | KNN Loss: 4.654408931732178 | CLS Loss: 0.009389091283082962\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 4.707406997680664 | KNN Loss: 4.6668925285339355 | CLS Loss: 0.040514372289180756\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 4.732667922973633 | KNN Loss: 4.67081356048584 | CLS Loss: 0.061854392290115356\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 4.733003616333008 | KNN Loss: 4.703902721405029 | CLS Loss: 0.029101090505719185\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 4.692309379577637 | KNN Loss: 4.6612067222595215 | CLS Loss: 0.031102675944566727\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 4.695585250854492 | KNN Loss: 4.682963848114014 | CLS Loss: 0.012621338479220867\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 4.691508769989014 | KNN Loss: 4.677316665649414 | CLS Loss: 0.014192230999469757\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 4.694080829620361 | KNN Loss: 4.681617259979248 | CLS Loss: 0.012463545426726341\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 4.802740097045898 | KNN Loss: 4.763714790344238 | CLS Loss: 0.03902517631649971\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 4.742030620574951 | KNN Loss: 4.734807014465332 | CLS Loss: 0.007223624270409346\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 4.681121826171875 | KNN Loss: 4.664221286773682 | CLS Loss: 0.016900671645998955\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 4.777493953704834 | KNN Loss: 4.770755290985107 | CLS Loss: 0.0067389002069830894\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 4.694624900817871 | KNN Loss: 4.678737163543701 | CLS Loss: 0.015887875109910965\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 4.733792781829834 | KNN Loss: 4.708366870880127 | CLS Loss: 0.02542594075202942\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 4.688542366027832 | KNN Loss: 4.667618751525879 | CLS Loss: 0.020923836156725883\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 4.767580032348633 | KNN Loss: 4.749956130981445 | CLS Loss: 0.01762380078434944\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 4.768882751464844 | KNN Loss: 4.766469955444336 | CLS Loss: 0.0024126959033310413\n",
      "Epoch: 098, Loss: 4.7155, Train: 0.9953, Valid: 0.9855, Best: 0.9875\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 4.6715474128723145 | KNN Loss: 4.666151523590088 | CLS Loss: 0.00539605924859643\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 4.676600456237793 | KNN Loss: 4.644777774810791 | CLS Loss: 0.031822677701711655\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 4.718006134033203 | KNN Loss: 4.696628093719482 | CLS Loss: 0.021377909928560257\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 4.6683173179626465 | KNN Loss: 4.660760879516602 | CLS Loss: 0.0075562866404652596\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 4.834320068359375 | KNN Loss: 4.813955783843994 | CLS Loss: 0.020364098250865936\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 4.692797660827637 | KNN Loss: 4.6800312995910645 | CLS Loss: 0.01276630349457264\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 4.858453750610352 | KNN Loss: 4.7978901863098145 | CLS Loss: 0.0605635903775692\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 4.719476699829102 | KNN Loss: 4.708127975463867 | CLS Loss: 0.011348691768944263\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 4.67806339263916 | KNN Loss: 4.666261196136475 | CLS Loss: 0.011802022345364094\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 4.6511759757995605 | KNN Loss: 4.638904571533203 | CLS Loss: 0.012271497398614883\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 4.701043605804443 | KNN Loss: 4.670568943023682 | CLS Loss: 0.030474577099084854\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 4.703787326812744 | KNN Loss: 4.684823036193848 | CLS Loss: 0.018964342772960663\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 4.661570072174072 | KNN Loss: 4.65834379196167 | CLS Loss: 0.0032265176996588707\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 4.774753093719482 | KNN Loss: 4.748331069946289 | CLS Loss: 0.026422077789902687\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 4.623925685882568 | KNN Loss: 4.6154046058654785 | CLS Loss: 0.008521252311766148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 4.685487270355225 | KNN Loss: 4.668654441833496 | CLS Loss: 0.016832629218697548\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 4.662221908569336 | KNN Loss: 4.657052040100098 | CLS Loss: 0.005169677548110485\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 4.832718849182129 | KNN Loss: 4.808174133300781 | CLS Loss: 0.02454492822289467\n",
      "Epoch: 099, Loss: 4.7115, Train: 0.9949, Valid: 0.9858, Best: 0.9875\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 4.812679767608643 | KNN Loss: 4.8079423904418945 | CLS Loss: 0.004737257957458496\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 4.801422119140625 | KNN Loss: 4.781116008758545 | CLS Loss: 0.020306140184402466\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 4.685364246368408 | KNN Loss: 4.6790995597839355 | CLS Loss: 0.0062647550366818905\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 4.678440093994141 | KNN Loss: 4.655169486999512 | CLS Loss: 0.02327064424753189\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 4.690634250640869 | KNN Loss: 4.672154426574707 | CLS Loss: 0.01847962662577629\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 4.735737323760986 | KNN Loss: 4.691978931427002 | CLS Loss: 0.04375838860869408\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 4.7020649909973145 | KNN Loss: 4.675069332122803 | CLS Loss: 0.026995431631803513\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 4.690267562866211 | KNN Loss: 4.677520275115967 | CLS Loss: 0.012747147120535374\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 4.799806594848633 | KNN Loss: 4.76275634765625 | CLS Loss: 0.03705007955431938\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 4.666509628295898 | KNN Loss: 4.661048889160156 | CLS Loss: 0.005460541229695082\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 4.670454502105713 | KNN Loss: 4.666234016418457 | CLS Loss: 0.004220654256641865\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 4.723237991333008 | KNN Loss: 4.690803527832031 | CLS Loss: 0.032434407621622086\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 4.770875453948975 | KNN Loss: 4.765446186065674 | CLS Loss: 0.005429461598396301\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 4.699036121368408 | KNN Loss: 4.675810813903809 | CLS Loss: 0.02322547882795334\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 4.6505279541015625 | KNN Loss: 4.641264915466309 | CLS Loss: 0.009263228625059128\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 4.716995716094971 | KNN Loss: 4.705540657043457 | CLS Loss: 0.011454891413450241\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 4.684742450714111 | KNN Loss: 4.671301364898682 | CLS Loss: 0.013440852984786034\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 4.7310709953308105 | KNN Loss: 4.710537433624268 | CLS Loss: 0.020533578470349312\n",
      "Epoch: 100, Loss: 4.7130, Train: 0.9919, Valid: 0.9829, Best: 0.9875\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 4.726313591003418 | KNN Loss: 4.6814141273498535 | CLS Loss: 0.04489966109395027\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 4.751673221588135 | KNN Loss: 4.724852085113525 | CLS Loss: 0.02682110294699669\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 4.746753215789795 | KNN Loss: 4.727707862854004 | CLS Loss: 0.019045328721404076\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 4.685456275939941 | KNN Loss: 4.66887092590332 | CLS Loss: 0.016585441306233406\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 4.694343090057373 | KNN Loss: 4.677051067352295 | CLS Loss: 0.017292138189077377\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 4.706696033477783 | KNN Loss: 4.6477742195129395 | CLS Loss: 0.05892198160290718\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 4.7010040283203125 | KNN Loss: 4.6971893310546875 | CLS Loss: 0.003814568044617772\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 4.687595367431641 | KNN Loss: 4.6689910888671875 | CLS Loss: 0.018604492768645287\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 4.720220565795898 | KNN Loss: 4.692479610443115 | CLS Loss: 0.027741050347685814\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 4.690637588500977 | KNN Loss: 4.6554765701293945 | CLS Loss: 0.03516124561429024\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 4.784640312194824 | KNN Loss: 4.768153190612793 | CLS Loss: 0.016487210988998413\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 4.702945709228516 | KNN Loss: 4.684756278991699 | CLS Loss: 0.018189651891589165\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 4.752645969390869 | KNN Loss: 4.721810817718506 | CLS Loss: 0.030834972858428955\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 4.735666751861572 | KNN Loss: 4.694653511047363 | CLS Loss: 0.04101300984621048\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 4.734653472900391 | KNN Loss: 4.715723037719727 | CLS Loss: 0.01893063634634018\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 4.745135307312012 | KNN Loss: 4.720683574676514 | CLS Loss: 0.024451887235045433\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 4.68880033493042 | KNN Loss: 4.67461633682251 | CLS Loss: 0.014183971099555492\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 4.715970516204834 | KNN Loss: 4.680154800415039 | CLS Loss: 0.03581589087843895\n",
      "Epoch: 101, Loss: 4.7255, Train: 0.9933, Valid: 0.9847, Best: 0.9875\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 4.71926736831665 | KNN Loss: 4.707103729248047 | CLS Loss: 0.012163694016635418\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 4.757272243499756 | KNN Loss: 4.739090442657471 | CLS Loss: 0.018181631341576576\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 4.712776184082031 | KNN Loss: 4.700565338134766 | CLS Loss: 0.012210717424750328\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 4.724277019500732 | KNN Loss: 4.693058013916016 | CLS Loss: 0.031219180673360825\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 4.676109790802002 | KNN Loss: 4.65019416809082 | CLS Loss: 0.02591584622859955\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 4.686171531677246 | KNN Loss: 4.6682634353637695 | CLS Loss: 0.017908213660120964\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 4.712203025817871 | KNN Loss: 4.696655750274658 | CLS Loss: 0.015547282062470913\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 4.932332992553711 | KNN Loss: 4.879734992980957 | CLS Loss: 0.05259821563959122\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 4.744701862335205 | KNN Loss: 4.737398624420166 | CLS Loss: 0.007303458638489246\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 4.699496269226074 | KNN Loss: 4.680416584014893 | CLS Loss: 0.019079918041825294\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 4.648860454559326 | KNN Loss: 4.633039951324463 | CLS Loss: 0.015820292755961418\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 4.715969085693359 | KNN Loss: 4.686300754547119 | CLS Loss: 0.0296684131026268\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 4.766176700592041 | KNN Loss: 4.745251655578613 | CLS Loss: 0.020924948155879974\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 4.737449645996094 | KNN Loss: 4.687712669372559 | CLS Loss: 0.049736831337213516\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 4.718486309051514 | KNN Loss: 4.681818962097168 | CLS Loss: 0.036667343229055405\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 4.683364391326904 | KNN Loss: 4.673418045043945 | CLS Loss: 0.009946326725184917\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 4.741067886352539 | KNN Loss: 4.702310085296631 | CLS Loss: 0.03875800222158432\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 4.706829071044922 | KNN Loss: 4.669736385345459 | CLS Loss: 0.037092626094818115\n",
      "Epoch: 102, Loss: 4.7272, Train: 0.9945, Valid: 0.9860, Best: 0.9875\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 4.704039573669434 | KNN Loss: 4.693273067474365 | CLS Loss: 0.010766597464680672\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 4.6630635261535645 | KNN Loss: 4.6574554443359375 | CLS Loss: 0.005608001723885536\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 4.729933261871338 | KNN Loss: 4.671483039855957 | CLS Loss: 0.05845044180750847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 4.692645072937012 | KNN Loss: 4.679912567138672 | CLS Loss: 0.01273231953382492\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 4.82916259765625 | KNN Loss: 4.769058704376221 | CLS Loss: 0.06010374054312706\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 4.667762756347656 | KNN Loss: 4.663081169128418 | CLS Loss: 0.004681488964706659\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 4.683344841003418 | KNN Loss: 4.674220561981201 | CLS Loss: 0.00912412442266941\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 4.748209476470947 | KNN Loss: 4.734986305236816 | CLS Loss: 0.013223184272646904\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 4.668698310852051 | KNN Loss: 4.646714687347412 | CLS Loss: 0.02198338508605957\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 4.70866584777832 | KNN Loss: 4.679040431976318 | CLS Loss: 0.02962525002658367\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 4.72878360748291 | KNN Loss: 4.720092296600342 | CLS Loss: 0.0086911516264081\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 4.716330528259277 | KNN Loss: 4.698462963104248 | CLS Loss: 0.01786758564412594\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 4.7316765785217285 | KNN Loss: 4.686960697174072 | CLS Loss: 0.044715866446495056\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 4.709279537200928 | KNN Loss: 4.688167572021484 | CLS Loss: 0.021111788228154182\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 4.6657538414001465 | KNN Loss: 4.655123710632324 | CLS Loss: 0.010630190372467041\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 4.722434043884277 | KNN Loss: 4.7117486000061035 | CLS Loss: 0.010685303248465061\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 4.677640438079834 | KNN Loss: 4.676044940948486 | CLS Loss: 0.001595479086972773\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 4.751659870147705 | KNN Loss: 4.725961685180664 | CLS Loss: 0.025698166340589523\n",
      "Epoch: 103, Loss: 4.7210, Train: 0.9950, Valid: 0.9859, Best: 0.9875\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 4.708404541015625 | KNN Loss: 4.689779281616211 | CLS Loss: 0.018625274300575256\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 4.752804756164551 | KNN Loss: 4.7257304191589355 | CLS Loss: 0.027074381709098816\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 4.668271064758301 | KNN Loss: 4.653054714202881 | CLS Loss: 0.015216449275612831\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 4.697967052459717 | KNN Loss: 4.6883368492126465 | CLS Loss: 0.00963023491203785\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 4.729766845703125 | KNN Loss: 4.713438034057617 | CLS Loss: 0.016328677535057068\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 4.699252605438232 | KNN Loss: 4.679433822631836 | CLS Loss: 0.019818762317299843\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 4.732564449310303 | KNN Loss: 4.700354099273682 | CLS Loss: 0.032210420817136765\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 4.653237819671631 | KNN Loss: 4.6482744216918945 | CLS Loss: 0.004963431041687727\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 4.742254257202148 | KNN Loss: 4.720602512359619 | CLS Loss: 0.02165152318775654\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 4.669848442077637 | KNN Loss: 4.657188415527344 | CLS Loss: 0.012660158798098564\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 4.739912509918213 | KNN Loss: 4.724796772003174 | CLS Loss: 0.015115770511329174\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 4.735652923583984 | KNN Loss: 4.730293273925781 | CLS Loss: 0.005359881557524204\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 4.708317279815674 | KNN Loss: 4.696537971496582 | CLS Loss: 0.011779398657381535\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 4.667202949523926 | KNN Loss: 4.635911464691162 | CLS Loss: 0.03129146248102188\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 4.8099894523620605 | KNN Loss: 4.793610095977783 | CLS Loss: 0.016379131004214287\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 4.736496448516846 | KNN Loss: 4.722898483276367 | CLS Loss: 0.013598178513348103\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 4.700262069702148 | KNN Loss: 4.690184593200684 | CLS Loss: 0.0100774010643363\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 4.6624226570129395 | KNN Loss: 4.636544704437256 | CLS Loss: 0.025877948850393295\n",
      "Epoch: 104, Loss: 4.7118, Train: 0.9952, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 4.717706680297852 | KNN Loss: 4.697658061981201 | CLS Loss: 0.020048515871167183\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 4.697935104370117 | KNN Loss: 4.675572395324707 | CLS Loss: 0.022362809628248215\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 4.667285919189453 | KNN Loss: 4.640693664550781 | CLS Loss: 0.02659231424331665\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 4.667319297790527 | KNN Loss: 4.654600620269775 | CLS Loss: 0.012718464247882366\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 4.786342620849609 | KNN Loss: 4.778480052947998 | CLS Loss: 0.007862611673772335\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 4.664318561553955 | KNN Loss: 4.646819114685059 | CLS Loss: 0.01749933511018753\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 4.725650310516357 | KNN Loss: 4.713374137878418 | CLS Loss: 0.01227598823606968\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 4.6847615242004395 | KNN Loss: 4.677899360656738 | CLS Loss: 0.006862063426524401\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 4.726487159729004 | KNN Loss: 4.697755336761475 | CLS Loss: 0.02873171865940094\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 4.7655792236328125 | KNN Loss: 4.7314372062683105 | CLS Loss: 0.034141991287469864\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
