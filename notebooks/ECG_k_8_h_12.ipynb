{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "tree_depth = 12\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'/mnt/qnap/ekosman/mitbih_train.csv'\n",
    "test_data_path = r'/mnt/qnap/ekosman/mitbih_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.476043224334717 | KNN Loss: 5.769813060760498 | CLS Loss: 1.7062300443649292\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 4.464776992797852 | KNN Loss: 3.2373194694519043 | CLS Loss: 1.2274576425552368\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 3.391493320465088 | KNN Loss: 2.6543593406677246 | CLS Loss: 0.7371340990066528\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 3.1886754035949707 | KNN Loss: 2.561807632446289 | CLS Loss: 0.6268676519393921\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 3.188472032546997 | KNN Loss: 2.5338451862335205 | CLS Loss: 0.6546267867088318\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 3.1445138454437256 | KNN Loss: 2.6530253887176514 | CLS Loss: 0.49148836731910706\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 3.0928361415863037 | KNN Loss: 2.5160574913024902 | CLS Loss: 0.5767786502838135\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 2.983839511871338 | KNN Loss: 2.5216012001037598 | CLS Loss: 0.46223822236061096\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 2.950084924697876 | KNN Loss: 2.5605385303497314 | CLS Loss: 0.38954633474349976\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 2.9554808139801025 | KNN Loss: 2.541261672973633 | CLS Loss: 0.41421908140182495\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 2.9758121967315674 | KNN Loss: 2.5998260974884033 | CLS Loss: 0.37598615884780884\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 2.926525115966797 | KNN Loss: 2.5560224056243896 | CLS Loss: 0.37050265073776245\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 3.0317940711975098 | KNN Loss: 2.6711277961730957 | CLS Loss: 0.3606663942337036\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 2.884044885635376 | KNN Loss: 2.5728766918182373 | CLS Loss: 0.3111681640148163\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 2.8688902854919434 | KNN Loss: 2.5427424907684326 | CLS Loss: 0.3261478543281555\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 2.8552534580230713 | KNN Loss: 2.598280906677246 | CLS Loss: 0.2569725811481476\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 2.872304677963257 | KNN Loss: 2.53619647026062 | CLS Loss: 0.33610811829566956\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 2.8630101680755615 | KNN Loss: 2.5484485626220703 | CLS Loss: 0.3145615756511688\n",
      "Epoch: 001, Loss: 3.2385, Train: 0.9140, Valid: 0.9124, Best: 0.9124\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 2.8854546546936035 | KNN Loss: 2.536599636077881 | CLS Loss: 0.3488548994064331\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 2.861021041870117 | KNN Loss: 2.5946953296661377 | CLS Loss: 0.2663256824016571\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 2.828500747680664 | KNN Loss: 2.563798189163208 | CLS Loss: 0.2647026777267456\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 2.8121747970581055 | KNN Loss: 2.5197372436523438 | CLS Loss: 0.29243749380111694\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 2.7767457962036133 | KNN Loss: 2.5414977073669434 | CLS Loss: 0.23524807393550873\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 2.8383522033691406 | KNN Loss: 2.4754717350006104 | CLS Loss: 0.3628803491592407\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 2.8193490505218506 | KNN Loss: 2.5411031246185303 | CLS Loss: 0.27824586629867554\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 2.773535966873169 | KNN Loss: 2.492037534713745 | CLS Loss: 0.28149843215942383\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 2.7340757846832275 | KNN Loss: 2.4847137928009033 | CLS Loss: 0.2493620663881302\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 2.7385799884796143 | KNN Loss: 2.5286529064178467 | CLS Loss: 0.2099270224571228\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 2.7840943336486816 | KNN Loss: 2.538475751876831 | CLS Loss: 0.24561864137649536\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 2.777263641357422 | KNN Loss: 2.5549042224884033 | CLS Loss: 0.22235949337482452\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 2.7693116664886475 | KNN Loss: 2.551708936691284 | CLS Loss: 0.21760264039039612\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 2.718682289123535 | KNN Loss: 2.532341718673706 | CLS Loss: 0.18634051084518433\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 2.740718126296997 | KNN Loss: 2.51741361618042 | CLS Loss: 0.22330448031425476\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 2.734602451324463 | KNN Loss: 2.522688627243042 | CLS Loss: 0.21191394329071045\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 2.6845993995666504 | KNN Loss: 2.4851200580596924 | CLS Loss: 0.19947922229766846\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 2.7161989212036133 | KNN Loss: 2.5268192291259766 | CLS Loss: 0.1893797069787979\n",
      "Epoch: 002, Loss: 2.7834, Train: 0.9489, Valid: 0.9484, Best: 0.9484\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 2.711677074432373 | KNN Loss: 2.4969682693481445 | CLS Loss: 0.21470873057842255\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 2.762335777282715 | KNN Loss: 2.535550832748413 | CLS Loss: 0.22678492963314056\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 2.6461033821105957 | KNN Loss: 2.4812581539154053 | CLS Loss: 0.164845272898674\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 2.719341278076172 | KNN Loss: 2.53554368019104 | CLS Loss: 0.18379762768745422\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 2.7279586791992188 | KNN Loss: 2.539106607437134 | CLS Loss: 0.18885205686092377\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 2.733372688293457 | KNN Loss: 2.5739762783050537 | CLS Loss: 0.15939652919769287\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 2.7046496868133545 | KNN Loss: 2.5121171474456787 | CLS Loss: 0.19253258407115936\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 2.7203891277313232 | KNN Loss: 2.5345988273620605 | CLS Loss: 0.18579019606113434\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 2.7090539932250977 | KNN Loss: 2.518810987472534 | CLS Loss: 0.19024299085140228\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 2.6628551483154297 | KNN Loss: 2.5134215354919434 | CLS Loss: 0.14943350851535797\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 2.6944360733032227 | KNN Loss: 2.516629934310913 | CLS Loss: 0.17780625820159912\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 2.6395602226257324 | KNN Loss: 2.503199338912964 | CLS Loss: 0.13636082410812378\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 2.6843228340148926 | KNN Loss: 2.5047035217285156 | CLS Loss: 0.17961935698986053\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 2.645597219467163 | KNN Loss: 2.5459651947021484 | CLS Loss: 0.09963198006153107\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 2.648275136947632 | KNN Loss: 2.504916191101074 | CLS Loss: 0.1433590203523636\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 2.711002826690674 | KNN Loss: 2.523475170135498 | CLS Loss: 0.18752773106098175\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 2.635545015335083 | KNN Loss: 2.478473663330078 | CLS Loss: 0.15707141160964966\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 2.666795253753662 | KNN Loss: 2.5349647998809814 | CLS Loss: 0.13183048367500305\n",
      "Epoch: 003, Loss: 2.6850, Train: 0.9620, Valid: 0.9593, Best: 0.9593\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 2.6575846672058105 | KNN Loss: 2.514390230178833 | CLS Loss: 0.1431945264339447\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 2.6199839115142822 | KNN Loss: 2.447805643081665 | CLS Loss: 0.17217816412448883\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 2.623642921447754 | KNN Loss: 2.4486727714538574 | CLS Loss: 0.17497006058692932\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 2.6326022148132324 | KNN Loss: 2.504483222961426 | CLS Loss: 0.12811894714832306\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 2.6600465774536133 | KNN Loss: 2.5135812759399414 | CLS Loss: 0.14646539092063904\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 2.6172034740448 | KNN Loss: 2.447211265563965 | CLS Loss: 0.1699921041727066\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 2.5681233406066895 | KNN Loss: 2.482804536819458 | CLS Loss: 0.08531871438026428\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 2.6874043941497803 | KNN Loss: 2.5041861534118652 | CLS Loss: 0.18321821093559265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 2.598839044570923 | KNN Loss: 2.4779484272003174 | CLS Loss: 0.12089067697525024\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 2.6051814556121826 | KNN Loss: 2.512763023376465 | CLS Loss: 0.09241849184036255\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 2.6455912590026855 | KNN Loss: 2.53206729888916 | CLS Loss: 0.11352407932281494\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 2.606755018234253 | KNN Loss: 2.515778064727783 | CLS Loss: 0.09097685664892197\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 2.613258123397827 | KNN Loss: 2.504054546356201 | CLS Loss: 0.10920365154743195\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 2.590320587158203 | KNN Loss: 2.4629762172698975 | CLS Loss: 0.1273442655801773\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 2.6003620624542236 | KNN Loss: 2.474505662918091 | CLS Loss: 0.1258564591407776\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 2.6393747329711914 | KNN Loss: 2.500462293624878 | CLS Loss: 0.13891255855560303\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 2.6382555961608887 | KNN Loss: 2.497544288635254 | CLS Loss: 0.14071141183376312\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 2.627772331237793 | KNN Loss: 2.5075953006744385 | CLS Loss: 0.12017706036567688\n",
      "Epoch: 004, Loss: 2.6305, Train: 0.9675, Valid: 0.9649, Best: 0.9649\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 2.616076946258545 | KNN Loss: 2.480158805847168 | CLS Loss: 0.13591809570789337\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 2.5869572162628174 | KNN Loss: 2.4624061584472656 | CLS Loss: 0.12455100566148758\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 2.587080478668213 | KNN Loss: 2.466371774673462 | CLS Loss: 0.12070880085229874\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 2.584071636199951 | KNN Loss: 2.480855941772461 | CLS Loss: 0.10321564227342606\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 2.62484073638916 | KNN Loss: 2.471813440322876 | CLS Loss: 0.15302734076976776\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 2.602473020553589 | KNN Loss: 2.5146484375 | CLS Loss: 0.08782458305358887\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 2.595005750656128 | KNN Loss: 2.4860949516296387 | CLS Loss: 0.10891072452068329\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 2.6120729446411133 | KNN Loss: 2.4818379878997803 | CLS Loss: 0.13023492693901062\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 2.522602081298828 | KNN Loss: 2.455014228820801 | CLS Loss: 0.06758780777454376\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 2.5942108631134033 | KNN Loss: 2.448108196258545 | CLS Loss: 0.14610262215137482\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 2.609578847885132 | KNN Loss: 2.460953712463379 | CLS Loss: 0.14862513542175293\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 2.60182523727417 | KNN Loss: 2.503513813018799 | CLS Loss: 0.09831144660711288\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 2.6315131187438965 | KNN Loss: 2.507467746734619 | CLS Loss: 0.12404527515172958\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 2.53460693359375 | KNN Loss: 2.487189769744873 | CLS Loss: 0.04741712659597397\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 2.560100793838501 | KNN Loss: 2.4557344913482666 | CLS Loss: 0.10436628758907318\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 2.58683443069458 | KNN Loss: 2.4628961086273193 | CLS Loss: 0.12393844127655029\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 2.5976810455322266 | KNN Loss: 2.4461829662323 | CLS Loss: 0.15149816870689392\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 2.6012909412384033 | KNN Loss: 2.4983460903167725 | CLS Loss: 0.10294496268033981\n",
      "Epoch: 005, Loss: 2.5981, Train: 0.9718, Valid: 0.9690, Best: 0.9690\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 2.6041829586029053 | KNN Loss: 2.4891324043273926 | CLS Loss: 0.11505066603422165\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 2.614464044570923 | KNN Loss: 2.446066379547119 | CLS Loss: 0.16839773952960968\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 2.5960898399353027 | KNN Loss: 2.502218008041382 | CLS Loss: 0.09387180209159851\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 2.5951294898986816 | KNN Loss: 2.450572967529297 | CLS Loss: 0.14455659687519073\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 2.5571601390838623 | KNN Loss: 2.467493772506714 | CLS Loss: 0.08966641873121262\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 2.561309337615967 | KNN Loss: 2.441340446472168 | CLS Loss: 0.11996880918741226\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 2.5804686546325684 | KNN Loss: 2.4660208225250244 | CLS Loss: 0.1144479289650917\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 2.5445170402526855 | KNN Loss: 2.4571735858917236 | CLS Loss: 0.08734343945980072\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 2.5958070755004883 | KNN Loss: 2.485004425048828 | CLS Loss: 0.11080264300107956\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 2.5418941974639893 | KNN Loss: 2.464970588684082 | CLS Loss: 0.07692360877990723\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 2.6567556858062744 | KNN Loss: 2.5011115074157715 | CLS Loss: 0.15564408898353577\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 2.5682525634765625 | KNN Loss: 2.4843690395355225 | CLS Loss: 0.08388344198465347\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 2.5686562061309814 | KNN Loss: 2.476531744003296 | CLS Loss: 0.09212454408407211\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 2.588144063949585 | KNN Loss: 2.4892961978912354 | CLS Loss: 0.09884775429964066\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 2.6193158626556396 | KNN Loss: 2.4922144412994385 | CLS Loss: 0.12710131704807281\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 2.541008472442627 | KNN Loss: 2.465014696121216 | CLS Loss: 0.07599381357431412\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 2.596909999847412 | KNN Loss: 2.476750612258911 | CLS Loss: 0.12015940994024277\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 2.5625905990600586 | KNN Loss: 2.4579551219940186 | CLS Loss: 0.10463551431894302\n",
      "Epoch: 006, Loss: 2.5718, Train: 0.9743, Valid: 0.9715, Best: 0.9715\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 2.551377534866333 | KNN Loss: 2.4336977005004883 | CLS Loss: 0.11767978966236115\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 2.5565900802612305 | KNN Loss: 2.4360408782958984 | CLS Loss: 0.1205492839217186\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 2.5548624992370605 | KNN Loss: 2.4835660457611084 | CLS Loss: 0.07129643112421036\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 2.563157081604004 | KNN Loss: 2.465376138687134 | CLS Loss: 0.09778101742267609\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 2.538766622543335 | KNN Loss: 2.444490671157837 | CLS Loss: 0.09427588433027267\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 2.5771822929382324 | KNN Loss: 2.474689483642578 | CLS Loss: 0.10249276459217072\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 2.5788817405700684 | KNN Loss: 2.4627580642700195 | CLS Loss: 0.11612360924482346\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 2.5671660900115967 | KNN Loss: 2.4574248790740967 | CLS Loss: 0.10974130034446716\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 2.563739776611328 | KNN Loss: 2.4774117469787598 | CLS Loss: 0.0863279327750206\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 2.5934503078460693 | KNN Loss: 2.46700382232666 | CLS Loss: 0.1264464259147644\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 2.544236898422241 | KNN Loss: 2.4528608322143555 | CLS Loss: 0.09137608110904694\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 2.5757086277008057 | KNN Loss: 2.488253593444824 | CLS Loss: 0.08745501190423965\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 2.5466020107269287 | KNN Loss: 2.4855337142944336 | CLS Loss: 0.06106828898191452\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 2.5490012168884277 | KNN Loss: 2.481776475906372 | CLS Loss: 0.06722482293844223\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 2.5208961963653564 | KNN Loss: 2.463618755340576 | CLS Loss: 0.057277463376522064\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 2.5476033687591553 | KNN Loss: 2.471266508102417 | CLS Loss: 0.07633688300848007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 2.5393362045288086 | KNN Loss: 2.4390337467193604 | CLS Loss: 0.10030245035886765\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 2.56878662109375 | KNN Loss: 2.441195011138916 | CLS Loss: 0.12759165465831757\n",
      "Epoch: 007, Loss: 2.5576, Train: 0.9771, Valid: 0.9739, Best: 0.9739\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 2.5666160583496094 | KNN Loss: 2.468266725540161 | CLS Loss: 0.09834936261177063\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 2.557650327682495 | KNN Loss: 2.459782123565674 | CLS Loss: 0.09786819666624069\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 2.5491745471954346 | KNN Loss: 2.4246954917907715 | CLS Loss: 0.12447910010814667\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 2.5385468006134033 | KNN Loss: 2.462998867034912 | CLS Loss: 0.07554784417152405\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 2.5647027492523193 | KNN Loss: 2.4557669162750244 | CLS Loss: 0.10893575102090836\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 2.541818857192993 | KNN Loss: 2.432434320449829 | CLS Loss: 0.10938458889722824\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 2.607985496520996 | KNN Loss: 2.4892380237579346 | CLS Loss: 0.11874744296073914\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 2.5226314067840576 | KNN Loss: 2.4254753589630127 | CLS Loss: 0.09715597331523895\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 2.57826566696167 | KNN Loss: 2.4828929901123047 | CLS Loss: 0.09537257999181747\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 2.575244665145874 | KNN Loss: 2.4658119678497314 | CLS Loss: 0.10943260043859482\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 2.504300117492676 | KNN Loss: 2.447787284851074 | CLS Loss: 0.05651292949914932\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 2.5253007411956787 | KNN Loss: 2.426440477371216 | CLS Loss: 0.0988602340221405\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 2.5590689182281494 | KNN Loss: 2.4693567752838135 | CLS Loss: 0.08971220999956131\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 2.522563934326172 | KNN Loss: 2.4552853107452393 | CLS Loss: 0.06727852672338486\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 2.4989631175994873 | KNN Loss: 2.4292047023773193 | CLS Loss: 0.06975840032100677\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 2.530803680419922 | KNN Loss: 2.4593889713287354 | CLS Loss: 0.07141470164060593\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 2.5399675369262695 | KNN Loss: 2.4477241039276123 | CLS Loss: 0.09224337339401245\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 2.5501275062561035 | KNN Loss: 2.4695587158203125 | CLS Loss: 0.08056876808404922\n",
      "Epoch: 008, Loss: 2.5419, Train: 0.9754, Valid: 0.9732, Best: 0.9739\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 2.5323660373687744 | KNN Loss: 2.435990333557129 | CLS Loss: 0.09637574106454849\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 2.5339016914367676 | KNN Loss: 2.4626359939575195 | CLS Loss: 0.07126573473215103\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 2.533930778503418 | KNN Loss: 2.468829870223999 | CLS Loss: 0.06510087847709656\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 2.5193300247192383 | KNN Loss: 2.4221103191375732 | CLS Loss: 0.09721961617469788\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 2.513766288757324 | KNN Loss: 2.4532201290130615 | CLS Loss: 0.06054622307419777\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 2.530540943145752 | KNN Loss: 2.442333221435547 | CLS Loss: 0.0882076621055603\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 2.5357935428619385 | KNN Loss: 2.426616907119751 | CLS Loss: 0.1091766431927681\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 2.5109848976135254 | KNN Loss: 2.4519736766815186 | CLS Loss: 0.05901133269071579\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 2.5021965503692627 | KNN Loss: 2.426325559616089 | CLS Loss: 0.07587088644504547\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 2.5255372524261475 | KNN Loss: 2.4481279850006104 | CLS Loss: 0.07740931212902069\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 2.546983480453491 | KNN Loss: 2.4430038928985596 | CLS Loss: 0.10397955030202866\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 2.5700764656066895 | KNN Loss: 2.4325315952301025 | CLS Loss: 0.13754498958587646\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 2.5575110912323 | KNN Loss: 2.442949056625366 | CLS Loss: 0.11456210166215897\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 2.5438668727874756 | KNN Loss: 2.4647271633148193 | CLS Loss: 0.07913974672555923\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 2.532167911529541 | KNN Loss: 2.4323463439941406 | CLS Loss: 0.09982147067785263\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 2.5482068061828613 | KNN Loss: 2.452751398086548 | CLS Loss: 0.09545552730560303\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 2.5137317180633545 | KNN Loss: 2.4215197563171387 | CLS Loss: 0.09221198409795761\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 2.5261967182159424 | KNN Loss: 2.417813301086426 | CLS Loss: 0.10838338732719421\n",
      "Epoch: 009, Loss: 2.5308, Train: 0.9776, Valid: 0.9741, Best: 0.9741\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 2.5204689502716064 | KNN Loss: 2.4099881649017334 | CLS Loss: 0.11048079282045364\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 2.480430841445923 | KNN Loss: 2.434601306915283 | CLS Loss: 0.04582947865128517\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 2.496837854385376 | KNN Loss: 2.459683895111084 | CLS Loss: 0.03715392202138901\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 2.4970180988311768 | KNN Loss: 2.4452710151672363 | CLS Loss: 0.05174718052148819\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 2.51808762550354 | KNN Loss: 2.453972101211548 | CLS Loss: 0.06411544978618622\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 2.539017915725708 | KNN Loss: 2.4537291526794434 | CLS Loss: 0.08528876304626465\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 2.544924020767212 | KNN Loss: 2.4832823276519775 | CLS Loss: 0.06164178624749184\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 2.5245003700256348 | KNN Loss: 2.447552442550659 | CLS Loss: 0.07694787532091141\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 2.502060890197754 | KNN Loss: 2.444053888320923 | CLS Loss: 0.058006975799798965\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 2.5258584022521973 | KNN Loss: 2.489274740219116 | CLS Loss: 0.03658361732959747\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 2.5554778575897217 | KNN Loss: 2.48433518409729 | CLS Loss: 0.07114265114068985\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 2.5106818675994873 | KNN Loss: 2.418985366821289 | CLS Loss: 0.09169656783342361\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 2.511373519897461 | KNN Loss: 2.421518325805664 | CLS Loss: 0.0898551493883133\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 2.518707752227783 | KNN Loss: 2.4335668087005615 | CLS Loss: 0.08514104783535004\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 2.4993765354156494 | KNN Loss: 2.4439330101013184 | CLS Loss: 0.0554434098303318\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 2.5135908126831055 | KNN Loss: 2.4266927242279053 | CLS Loss: 0.08689818531274796\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 2.5519375801086426 | KNN Loss: 2.4635510444641113 | CLS Loss: 0.08838656544685364\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 2.494943141937256 | KNN Loss: 2.4445550441741943 | CLS Loss: 0.05038809776306152\n",
      "Epoch: 010, Loss: 2.5235, Train: 0.9797, Valid: 0.9768, Best: 0.9768\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 2.488483428955078 | KNN Loss: 2.417619228363037 | CLS Loss: 0.07086428999900818\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 2.496201515197754 | KNN Loss: 2.4429686069488525 | CLS Loss: 0.05323290824890137\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 2.5160372257232666 | KNN Loss: 2.424105405807495 | CLS Loss: 0.09193174540996552\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 2.523496389389038 | KNN Loss: 2.461524486541748 | CLS Loss: 0.06197180971503258\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 2.508463144302368 | KNN Loss: 2.417027235031128 | CLS Loss: 0.091436006128788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 2.4872567653656006 | KNN Loss: 2.4295566082000732 | CLS Loss: 0.05770007520914078\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 2.546365261077881 | KNN Loss: 2.4590630531311035 | CLS Loss: 0.0873023197054863\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 2.5020530223846436 | KNN Loss: 2.4328184127807617 | CLS Loss: 0.0692346841096878\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 2.5381650924682617 | KNN Loss: 2.461623191833496 | CLS Loss: 0.07654178887605667\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 2.5211596488952637 | KNN Loss: 2.43990159034729 | CLS Loss: 0.08125804364681244\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 2.533362627029419 | KNN Loss: 2.455315589904785 | CLS Loss: 0.07804711163043976\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 2.4923484325408936 | KNN Loss: 2.420955181121826 | CLS Loss: 0.07139333337545395\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 2.4960505962371826 | KNN Loss: 2.4238147735595703 | CLS Loss: 0.0722358226776123\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 2.4935388565063477 | KNN Loss: 2.444183826446533 | CLS Loss: 0.04935501515865326\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 2.5105834007263184 | KNN Loss: 2.4521732330322266 | CLS Loss: 0.058410052210092545\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 2.534867286682129 | KNN Loss: 2.4530837535858154 | CLS Loss: 0.08178342133760452\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 2.49627423286438 | KNN Loss: 2.4515631198883057 | CLS Loss: 0.04471118375658989\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 2.4851315021514893 | KNN Loss: 2.408266305923462 | CLS Loss: 0.07686527073383331\n",
      "Epoch: 011, Loss: 2.5079, Train: 0.9816, Valid: 0.9787, Best: 0.9787\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 2.4891645908355713 | KNN Loss: 2.4374351501464844 | CLS Loss: 0.05172951519489288\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 2.5061798095703125 | KNN Loss: 2.4292638301849365 | CLS Loss: 0.07691602408885956\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 2.4796295166015625 | KNN Loss: 2.3973581790924072 | CLS Loss: 0.08227124810218811\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 2.4982481002807617 | KNN Loss: 2.4462757110595703 | CLS Loss: 0.05197235569357872\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 2.499009609222412 | KNN Loss: 2.4053821563720703 | CLS Loss: 0.09362742304801941\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 2.4999523162841797 | KNN Loss: 2.443216323852539 | CLS Loss: 0.05673610046505928\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 2.4924404621124268 | KNN Loss: 2.442932367324829 | CLS Loss: 0.049508143216371536\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 2.5369908809661865 | KNN Loss: 2.488205671310425 | CLS Loss: 0.04878512769937515\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 2.5006582736968994 | KNN Loss: 2.4149696826934814 | CLS Loss: 0.08568857610225677\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 2.5108718872070312 | KNN Loss: 2.4420769214630127 | CLS Loss: 0.06879498809576035\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 2.492661237716675 | KNN Loss: 2.440497398376465 | CLS Loss: 0.05216379836201668\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 2.5152814388275146 | KNN Loss: 2.465031623840332 | CLS Loss: 0.05024971067905426\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 2.514547348022461 | KNN Loss: 2.435393810272217 | CLS Loss: 0.07915350049734116\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 2.495499849319458 | KNN Loss: 2.4361767768859863 | CLS Loss: 0.059323184192180634\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 2.496217727661133 | KNN Loss: 2.434243679046631 | CLS Loss: 0.06197407841682434\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 2.4863436222076416 | KNN Loss: 2.4068870544433594 | CLS Loss: 0.0794566422700882\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 2.593825101852417 | KNN Loss: 2.4790971279144287 | CLS Loss: 0.1147279217839241\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 2.493061065673828 | KNN Loss: 2.4140431880950928 | CLS Loss: 0.0790179893374443\n",
      "Epoch: 012, Loss: 2.5049, Train: 0.9831, Valid: 0.9798, Best: 0.9798\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 2.519881248474121 | KNN Loss: 2.4622879028320312 | CLS Loss: 0.05759332701563835\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 2.4374308586120605 | KNN Loss: 2.386594295501709 | CLS Loss: 0.05083664879202843\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 2.495011806488037 | KNN Loss: 2.4130990505218506 | CLS Loss: 0.08191265165805817\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 2.515953302383423 | KNN Loss: 2.415151596069336 | CLS Loss: 0.10080176591873169\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 2.5039284229278564 | KNN Loss: 2.456716299057007 | CLS Loss: 0.04721209034323692\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 2.500819444656372 | KNN Loss: 2.4279351234436035 | CLS Loss: 0.07288441807031631\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 2.53767991065979 | KNN Loss: 2.4455726146698 | CLS Loss: 0.09210727363824844\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 2.481604814529419 | KNN Loss: 2.452136278152466 | CLS Loss: 0.029468435794115067\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 2.468203544616699 | KNN Loss: 2.4179701805114746 | CLS Loss: 0.050233352929353714\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 2.4998881816864014 | KNN Loss: 2.4089207649230957 | CLS Loss: 0.09096743166446686\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 2.472287893295288 | KNN Loss: 2.4147586822509766 | CLS Loss: 0.05752922222018242\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 2.471343994140625 | KNN Loss: 2.398353338241577 | CLS Loss: 0.0729905366897583\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 2.5497360229492188 | KNN Loss: 2.4504902362823486 | CLS Loss: 0.09924585372209549\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 2.534618377685547 | KNN Loss: 2.41739821434021 | CLS Loss: 0.11722014844417572\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 2.4649691581726074 | KNN Loss: 2.4018869400024414 | CLS Loss: 0.06308232247829437\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 2.532338857650757 | KNN Loss: 2.4428257942199707 | CLS Loss: 0.08951296657323837\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 2.524949073791504 | KNN Loss: 2.4683761596679688 | CLS Loss: 0.0565728098154068\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 2.514763355255127 | KNN Loss: 2.3897314071655273 | CLS Loss: 0.12503188848495483\n",
      "Epoch: 013, Loss: 2.4990, Train: 0.9796, Valid: 0.9760, Best: 0.9798\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 2.4908218383789062 | KNN Loss: 2.414423704147339 | CLS Loss: 0.07639823853969574\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 2.4920578002929688 | KNN Loss: 2.4549126625061035 | CLS Loss: 0.03714507445693016\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 2.5155715942382812 | KNN Loss: 2.442606210708618 | CLS Loss: 0.07296537607908249\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 2.500945806503296 | KNN Loss: 2.4155678749084473 | CLS Loss: 0.08537793904542923\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 2.5084638595581055 | KNN Loss: 2.465223550796509 | CLS Loss: 0.043240368366241455\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 2.5168378353118896 | KNN Loss: 2.447800874710083 | CLS Loss: 0.06903693079948425\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 2.4759974479675293 | KNN Loss: 2.403961658477783 | CLS Loss: 0.07203588634729385\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 2.5094358921051025 | KNN Loss: 2.41487455368042 | CLS Loss: 0.09456139802932739\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 2.5247292518615723 | KNN Loss: 2.4646615982055664 | CLS Loss: 0.06006753444671631\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 2.459740400314331 | KNN Loss: 2.433340311050415 | CLS Loss: 0.026400122791528702\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 2.4765825271606445 | KNN Loss: 2.4166157245635986 | CLS Loss: 0.05996689945459366\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 2.5146706104278564 | KNN Loss: 2.4546988010406494 | CLS Loss: 0.059971921145915985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 2.499396562576294 | KNN Loss: 2.453481435775757 | CLS Loss: 0.04591507464647293\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 2.462001323699951 | KNN Loss: 2.413766384124756 | CLS Loss: 0.04823485016822815\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 2.498473882675171 | KNN Loss: 2.407113552093506 | CLS Loss: 0.09136022627353668\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 2.4779276847839355 | KNN Loss: 2.412907123565674 | CLS Loss: 0.06502047181129456\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 2.4980461597442627 | KNN Loss: 2.4089159965515137 | CLS Loss: 0.08913024514913559\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 2.499948263168335 | KNN Loss: 2.43463397026062 | CLS Loss: 0.06531422585248947\n",
      "Epoch: 014, Loss: 2.4911, Train: 0.9813, Valid: 0.9778, Best: 0.9798\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 2.5111746788024902 | KNN Loss: 2.3962152004241943 | CLS Loss: 0.11495952308177948\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 2.500000238418579 | KNN Loss: 2.415426731109619 | CLS Loss: 0.08457351475954056\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 2.5560171604156494 | KNN Loss: 2.3968465328216553 | CLS Loss: 0.15917062759399414\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 2.496236562728882 | KNN Loss: 2.4458186626434326 | CLS Loss: 0.05041787773370743\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 2.442964792251587 | KNN Loss: 2.417135715484619 | CLS Loss: 0.025829177349805832\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 2.456451416015625 | KNN Loss: 2.4162025451660156 | CLS Loss: 0.040248751640319824\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 2.4613869190216064 | KNN Loss: 2.4081478118896484 | CLS Loss: 0.05323901027441025\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 2.456247091293335 | KNN Loss: 2.3938190937042236 | CLS Loss: 0.06242801621556282\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 2.438528537750244 | KNN Loss: 2.3996434211730957 | CLS Loss: 0.038885001093149185\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 2.5080325603485107 | KNN Loss: 2.449338436126709 | CLS Loss: 0.058694127947092056\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 2.4899210929870605 | KNN Loss: 2.429309844970703 | CLS Loss: 0.06061132624745369\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 2.45099139213562 | KNN Loss: 2.413480520248413 | CLS Loss: 0.03751085698604584\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 2.484046220779419 | KNN Loss: 2.416943311691284 | CLS Loss: 0.06710284948348999\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 2.436338424682617 | KNN Loss: 2.398212194442749 | CLS Loss: 0.03812619671225548\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 2.5437448024749756 | KNN Loss: 2.48630952835083 | CLS Loss: 0.057435259222984314\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 2.501897096633911 | KNN Loss: 2.411576747894287 | CLS Loss: 0.09032034128904343\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 2.477660894393921 | KNN Loss: 2.4423654079437256 | CLS Loss: 0.035295408219099045\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 2.483048915863037 | KNN Loss: 2.423715114593506 | CLS Loss: 0.05933390557765961\n",
      "Epoch: 015, Loss: 2.4874, Train: 0.9825, Valid: 0.9779, Best: 0.9798\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 2.4992928504943848 | KNN Loss: 2.44346022605896 | CLS Loss: 0.05583253130316734\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 2.482881546020508 | KNN Loss: 2.405383825302124 | CLS Loss: 0.07749773561954498\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 2.525052309036255 | KNN Loss: 2.4437055587768555 | CLS Loss: 0.08134671300649643\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 2.4362056255340576 | KNN Loss: 2.3930859565734863 | CLS Loss: 0.043119605630636215\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 2.49354887008667 | KNN Loss: 2.4406464099884033 | CLS Loss: 0.05290236324071884\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 2.4942452907562256 | KNN Loss: 2.3926637172698975 | CLS Loss: 0.1015816181898117\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 2.466423511505127 | KNN Loss: 2.4245545864105225 | CLS Loss: 0.04186883568763733\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 2.4560186862945557 | KNN Loss: 2.4089536666870117 | CLS Loss: 0.04706490412354469\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 2.4591431617736816 | KNN Loss: 2.4206783771514893 | CLS Loss: 0.03846489265561104\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 2.512606382369995 | KNN Loss: 2.4594852924346924 | CLS Loss: 0.05312103033065796\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 2.4617044925689697 | KNN Loss: 2.419175863265991 | CLS Loss: 0.042528554797172546\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 2.5259463787078857 | KNN Loss: 2.436302900314331 | CLS Loss: 0.08964350819587708\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 2.4588522911071777 | KNN Loss: 2.4107398986816406 | CLS Loss: 0.048112403601408005\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 2.4921321868896484 | KNN Loss: 2.3753042221069336 | CLS Loss: 0.11682797223329544\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 2.485438823699951 | KNN Loss: 2.4289376735687256 | CLS Loss: 0.05650108680129051\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 2.4478886127471924 | KNN Loss: 2.408453941345215 | CLS Loss: 0.039434704929590225\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 2.4690768718719482 | KNN Loss: 2.4247488975524902 | CLS Loss: 0.04432803392410278\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 2.4885573387145996 | KNN Loss: 2.4247028827667236 | CLS Loss: 0.06385441869497299\n",
      "Epoch: 016, Loss: 2.4809, Train: 0.9827, Valid: 0.9787, Best: 0.9798\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 2.4392614364624023 | KNN Loss: 2.3901894092559814 | CLS Loss: 0.04907204583287239\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 2.487757444381714 | KNN Loss: 2.440856695175171 | CLS Loss: 0.046900779008865356\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 2.5235462188720703 | KNN Loss: 2.4870424270629883 | CLS Loss: 0.03650378808379173\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 2.4837303161621094 | KNN Loss: 2.420701265335083 | CLS Loss: 0.06302906572818756\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 2.5038022994995117 | KNN Loss: 2.4335334300994873 | CLS Loss: 0.07026885449886322\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 2.4629242420196533 | KNN Loss: 2.3905630111694336 | CLS Loss: 0.07236112654209137\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 2.5029633045196533 | KNN Loss: 2.41855525970459 | CLS Loss: 0.08440793305635452\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 2.496544361114502 | KNN Loss: 2.430107831954956 | CLS Loss: 0.06643655151128769\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 2.4844930171966553 | KNN Loss: 2.4030630588531494 | CLS Loss: 0.08142989128828049\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 2.4508206844329834 | KNN Loss: 2.4100682735443115 | CLS Loss: 0.04075233265757561\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 2.4467527866363525 | KNN Loss: 2.3863046169281006 | CLS Loss: 0.06044821813702583\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 2.4424517154693604 | KNN Loss: 2.3973562717437744 | CLS Loss: 0.04509545862674713\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 2.489569664001465 | KNN Loss: 2.4512436389923096 | CLS Loss: 0.03832591697573662\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 2.470261812210083 | KNN Loss: 2.402235269546509 | CLS Loss: 0.06802663207054138\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 2.49721622467041 | KNN Loss: 2.4325902462005615 | CLS Loss: 0.06462599337100983\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 2.476447820663452 | KNN Loss: 2.4340107440948486 | CLS Loss: 0.04243696108460426\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 2.4698596000671387 | KNN Loss: 2.4180402755737305 | CLS Loss: 0.05181923136115074\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 2.4801297187805176 | KNN Loss: 2.4103150367736816 | CLS Loss: 0.0698147863149643\n",
      "Epoch: 017, Loss: 2.4785, Train: 0.9854, Valid: 0.9816, Best: 0.9816\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 2.470895528793335 | KNN Loss: 2.424809455871582 | CLS Loss: 0.04608609527349472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 2.476365327835083 | KNN Loss: 2.4304699897766113 | CLS Loss: 0.04589524492621422\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 2.512005567550659 | KNN Loss: 2.453900098800659 | CLS Loss: 0.058105386793613434\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 2.462614059448242 | KNN Loss: 2.4157018661499023 | CLS Loss: 0.04691208153963089\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 2.44916033744812 | KNN Loss: 2.4168167114257812 | CLS Loss: 0.03234367445111275\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 2.4674506187438965 | KNN Loss: 2.431638479232788 | CLS Loss: 0.035812027752399445\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 2.498500108718872 | KNN Loss: 2.440647840499878 | CLS Loss: 0.05785217508673668\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 2.4817447662353516 | KNN Loss: 2.411778688430786 | CLS Loss: 0.06996599584817886\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 2.5137434005737305 | KNN Loss: 2.4466099739074707 | CLS Loss: 0.06713340431451797\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 2.4876627922058105 | KNN Loss: 2.4349205493927 | CLS Loss: 0.052742332220077515\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 2.459191083908081 | KNN Loss: 2.404494285583496 | CLS Loss: 0.054696813225746155\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 2.497065305709839 | KNN Loss: 2.4463703632354736 | CLS Loss: 0.050694871693849564\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 2.4844274520874023 | KNN Loss: 2.4331893920898438 | CLS Loss: 0.05123814567923546\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 2.4754695892333984 | KNN Loss: 2.399244546890259 | CLS Loss: 0.07622501999139786\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 2.4656589031219482 | KNN Loss: 2.4210660457611084 | CLS Loss: 0.04459274560213089\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 2.4537148475646973 | KNN Loss: 2.411522150039673 | CLS Loss: 0.042192794382572174\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 2.458878517150879 | KNN Loss: 2.3949337005615234 | CLS Loss: 0.06394471973180771\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 2.48581600189209 | KNN Loss: 2.4321062564849854 | CLS Loss: 0.05370970070362091\n",
      "Epoch: 018, Loss: 2.4733, Train: 0.9855, Valid: 0.9809, Best: 0.9816\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 2.512035369873047 | KNN Loss: 2.4315855503082275 | CLS Loss: 0.08044987171888351\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 2.446315050125122 | KNN Loss: 2.4060986042022705 | CLS Loss: 0.040216416120529175\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 2.5151164531707764 | KNN Loss: 2.4809460639953613 | CLS Loss: 0.03417039290070534\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 2.448896884918213 | KNN Loss: 2.395012378692627 | CLS Loss: 0.05388444662094116\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 2.474640130996704 | KNN Loss: 2.431089162826538 | CLS Loss: 0.04355085641145706\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 2.487272024154663 | KNN Loss: 2.440382719039917 | CLS Loss: 0.04688926786184311\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 2.489945650100708 | KNN Loss: 2.4040141105651855 | CLS Loss: 0.08593149483203888\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 2.4417715072631836 | KNN Loss: 2.3996405601501465 | CLS Loss: 0.0421309694647789\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 2.475703716278076 | KNN Loss: 2.3890187740325928 | CLS Loss: 0.08668504655361176\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 2.436148166656494 | KNN Loss: 2.3949685096740723 | CLS Loss: 0.04117956385016441\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 2.456143379211426 | KNN Loss: 2.4019768238067627 | CLS Loss: 0.054166439920663834\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 2.4890239238739014 | KNN Loss: 2.4490184783935547 | CLS Loss: 0.04000554978847504\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 2.458667039871216 | KNN Loss: 2.373328447341919 | CLS Loss: 0.0853385180234909\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 2.464054584503174 | KNN Loss: 2.422708749771118 | CLS Loss: 0.041345831006765366\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 2.4722440242767334 | KNN Loss: 2.4217329025268555 | CLS Loss: 0.05051112174987793\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 2.4413235187530518 | KNN Loss: 2.4115536212921143 | CLS Loss: 0.02976987138390541\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 2.4761292934417725 | KNN Loss: 2.4215095043182373 | CLS Loss: 0.054619740694761276\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 2.5122642517089844 | KNN Loss: 2.4453914165496826 | CLS Loss: 0.06687293946743011\n",
      "Epoch: 019, Loss: 2.4682, Train: 0.9857, Valid: 0.9815, Best: 0.9816\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 2.4314606189727783 | KNN Loss: 2.407750368118286 | CLS Loss: 0.023710239678621292\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 2.4522831439971924 | KNN Loss: 2.419769287109375 | CLS Loss: 0.03251390531659126\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 2.5159969329833984 | KNN Loss: 2.415900945663452 | CLS Loss: 0.10009600967168808\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 2.457575559616089 | KNN Loss: 2.415476083755493 | CLS Loss: 0.04209941253066063\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 2.4474692344665527 | KNN Loss: 2.408461093902588 | CLS Loss: 0.03900812566280365\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 2.4677507877349854 | KNN Loss: 2.437282085418701 | CLS Loss: 0.03046879731118679\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 2.4723715782165527 | KNN Loss: 2.4045658111572266 | CLS Loss: 0.06780566275119781\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 2.5269510746002197 | KNN Loss: 2.438167095184326 | CLS Loss: 0.08878394216299057\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 2.447770118713379 | KNN Loss: 2.3891220092773438 | CLS Loss: 0.05864804610610008\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 2.48111629486084 | KNN Loss: 2.4091811180114746 | CLS Loss: 0.07193523645401001\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 2.4996020793914795 | KNN Loss: 2.445709705352783 | CLS Loss: 0.05389239266514778\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 2.477386713027954 | KNN Loss: 2.436166286468506 | CLS Loss: 0.0412205271422863\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 2.4604058265686035 | KNN Loss: 2.393091917037964 | CLS Loss: 0.06731384992599487\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 2.448025703430176 | KNN Loss: 2.392244338989258 | CLS Loss: 0.055781375616788864\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 2.4798338413238525 | KNN Loss: 2.4342408180236816 | CLS Loss: 0.04559297859668732\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 2.4476654529571533 | KNN Loss: 2.415071725845337 | CLS Loss: 0.03259376063942909\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 2.4302518367767334 | KNN Loss: 2.3927056789398193 | CLS Loss: 0.037546273320913315\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 2.4634501934051514 | KNN Loss: 2.393662929534912 | CLS Loss: 0.06978718936443329\n",
      "Epoch: 020, Loss: 2.4704, Train: 0.9855, Valid: 0.9804, Best: 0.9816\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 2.4977688789367676 | KNN Loss: 2.4419164657592773 | CLS Loss: 0.05585233122110367\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 2.4928083419799805 | KNN Loss: 2.455759048461914 | CLS Loss: 0.037049248814582825\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 2.436163902282715 | KNN Loss: 2.4122085571289062 | CLS Loss: 0.023955274373292923\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 2.4565324783325195 | KNN Loss: 2.4261422157287598 | CLS Loss: 0.030390247702598572\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 2.5146918296813965 | KNN Loss: 2.414523124694824 | CLS Loss: 0.10016870498657227\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 2.5163938999176025 | KNN Loss: 2.4753758907318115 | CLS Loss: 0.041018057614564896\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 2.424553871154785 | KNN Loss: 2.373110294342041 | CLS Loss: 0.05144364759325981\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 2.4596567153930664 | KNN Loss: 2.419924020767212 | CLS Loss: 0.03973270580172539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 2.473090648651123 | KNN Loss: 2.429137706756592 | CLS Loss: 0.043952930718660355\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 2.4419784545898438 | KNN Loss: 2.399592399597168 | CLS Loss: 0.04238595440983772\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 2.447232961654663 | KNN Loss: 2.397538900375366 | CLS Loss: 0.0496939979493618\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 2.482562303543091 | KNN Loss: 2.449773073196411 | CLS Loss: 0.032789330929517746\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 2.5182583332061768 | KNN Loss: 2.4657480716705322 | CLS Loss: 0.05251025781035423\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 2.493154287338257 | KNN Loss: 2.429997205734253 | CLS Loss: 0.06315703690052032\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 2.4538466930389404 | KNN Loss: 2.415354013442993 | CLS Loss: 0.0384925976395607\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 2.510446310043335 | KNN Loss: 2.42501163482666 | CLS Loss: 0.08543459326028824\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 2.49420428276062 | KNN Loss: 2.4330031871795654 | CLS Loss: 0.061201080679893494\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 2.521435260772705 | KNN Loss: 2.445720672607422 | CLS Loss: 0.07571452111005783\n",
      "Epoch: 021, Loss: 2.4655, Train: 0.9840, Valid: 0.9792, Best: 0.9816\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 2.472350835800171 | KNN Loss: 2.410438060760498 | CLS Loss: 0.06191274896264076\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 2.4554049968719482 | KNN Loss: 2.4371843338012695 | CLS Loss: 0.018220670521259308\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 2.4292349815368652 | KNN Loss: 2.392094612121582 | CLS Loss: 0.037140462547540665\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 2.4545140266418457 | KNN Loss: 2.4134602546691895 | CLS Loss: 0.04105371981859207\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 2.4900381565093994 | KNN Loss: 2.4351718425750732 | CLS Loss: 0.054866328835487366\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 2.49743390083313 | KNN Loss: 2.45986270904541 | CLS Loss: 0.03757118061184883\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 2.487417697906494 | KNN Loss: 2.4292964935302734 | CLS Loss: 0.05812116339802742\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 2.4595186710357666 | KNN Loss: 2.419218063354492 | CLS Loss: 0.04030068963766098\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 2.4644997119903564 | KNN Loss: 2.4180877208709717 | CLS Loss: 0.04641205444931984\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 2.523967742919922 | KNN Loss: 2.424989938735962 | CLS Loss: 0.09897769242525101\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 2.451941967010498 | KNN Loss: 2.426682949066162 | CLS Loss: 0.025259004905819893\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 2.444960117340088 | KNN Loss: 2.3937923908233643 | CLS Loss: 0.05116765573620796\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 2.437520742416382 | KNN Loss: 2.3994388580322266 | CLS Loss: 0.03808188438415527\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 2.4674782752990723 | KNN Loss: 2.4157795906066895 | CLS Loss: 0.0516987107694149\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 2.463095188140869 | KNN Loss: 2.38755464553833 | CLS Loss: 0.07554066181182861\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 2.454357147216797 | KNN Loss: 2.4100747108459473 | CLS Loss: 0.044282447546720505\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 2.4753599166870117 | KNN Loss: 2.407515048980713 | CLS Loss: 0.06784480065107346\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 2.444349765777588 | KNN Loss: 2.391451358795166 | CLS Loss: 0.05289840325713158\n",
      "Epoch: 022, Loss: 2.4644, Train: 0.9861, Valid: 0.9815, Best: 0.9816\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 2.4825308322906494 | KNN Loss: 2.414203643798828 | CLS Loss: 0.06832711398601532\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 2.4400904178619385 | KNN Loss: 2.390214204788208 | CLS Loss: 0.0498761422932148\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 2.4931704998016357 | KNN Loss: 2.4253880977630615 | CLS Loss: 0.06778240948915482\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 2.437225818634033 | KNN Loss: 2.3903913497924805 | CLS Loss: 0.04683440178632736\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 2.468221664428711 | KNN Loss: 2.4127109050750732 | CLS Loss: 0.05551072955131531\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 2.412914276123047 | KNN Loss: 2.396852731704712 | CLS Loss: 0.016061611473560333\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 2.429365396499634 | KNN Loss: 2.4082658290863037 | CLS Loss: 0.021099451929330826\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 2.5015392303466797 | KNN Loss: 2.4510393142700195 | CLS Loss: 0.0504998117685318\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 2.4777932167053223 | KNN Loss: 2.4384303092956543 | CLS Loss: 0.039362844079732895\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 2.48937726020813 | KNN Loss: 2.433134078979492 | CLS Loss: 0.056243255734443665\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 2.4439406394958496 | KNN Loss: 2.3944835662841797 | CLS Loss: 0.04945710673928261\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 2.4688968658447266 | KNN Loss: 2.4106357097625732 | CLS Loss: 0.058261070400476456\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 2.484942674636841 | KNN Loss: 2.432088851928711 | CLS Loss: 0.05285392701625824\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 2.4724369049072266 | KNN Loss: 2.437760829925537 | CLS Loss: 0.03467599302530289\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 2.4448728561401367 | KNN Loss: 2.3986763954162598 | CLS Loss: 0.04619656503200531\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 2.4499471187591553 | KNN Loss: 2.4017391204833984 | CLS Loss: 0.04820806533098221\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 2.4428868293762207 | KNN Loss: 2.393479347229004 | CLS Loss: 0.04940760135650635\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 2.4274611473083496 | KNN Loss: 2.377251625061035 | CLS Loss: 0.05020947381854057\n",
      "Epoch: 023, Loss: 2.4625, Train: 0.9867, Valid: 0.9819, Best: 0.9819\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 2.4437572956085205 | KNN Loss: 2.4087891578674316 | CLS Loss: 0.03496810793876648\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 2.462432384490967 | KNN Loss: 2.4255599975585938 | CLS Loss: 0.03687233105301857\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 2.4734692573547363 | KNN Loss: 2.433422088623047 | CLS Loss: 0.04004723206162453\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 2.445556163787842 | KNN Loss: 2.3993136882781982 | CLS Loss: 0.046242568641901016\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 2.4376487731933594 | KNN Loss: 2.40372371673584 | CLS Loss: 0.03392505273222923\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 2.5027599334716797 | KNN Loss: 2.439852237701416 | CLS Loss: 0.06290777027606964\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 2.4593136310577393 | KNN Loss: 2.4267375469207764 | CLS Loss: 0.03257598727941513\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 2.4551119804382324 | KNN Loss: 2.4279346466064453 | CLS Loss: 0.027177248150110245\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 2.4582974910736084 | KNN Loss: 2.41999888420105 | CLS Loss: 0.038298651576042175\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 2.4747989177703857 | KNN Loss: 2.444857120513916 | CLS Loss: 0.029941778630018234\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 2.4286391735076904 | KNN Loss: 2.3703768253326416 | CLS Loss: 0.058262281119823456\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 2.451308012008667 | KNN Loss: 2.395496368408203 | CLS Loss: 0.055811576545238495\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 2.4615352153778076 | KNN Loss: 2.428133010864258 | CLS Loss: 0.03340223431587219\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 2.462890625 | KNN Loss: 2.4006330966949463 | CLS Loss: 0.062257517129182816\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 2.454810857772827 | KNN Loss: 2.3802056312561035 | CLS Loss: 0.07460527122020721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 2.478961706161499 | KNN Loss: 2.426452398300171 | CLS Loss: 0.052509281784296036\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 2.461373805999756 | KNN Loss: 2.3844196796417236 | CLS Loss: 0.07695411145687103\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 2.4501399993896484 | KNN Loss: 2.420170783996582 | CLS Loss: 0.02996929921209812\n",
      "Epoch: 024, Loss: 2.4611, Train: 0.9874, Valid: 0.9823, Best: 0.9823\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 2.465010166168213 | KNN Loss: 2.4102790355682373 | CLS Loss: 0.05473123490810394\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 2.429643392562866 | KNN Loss: 2.407382011413574 | CLS Loss: 0.022261325269937515\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 2.4425854682922363 | KNN Loss: 2.4156391620635986 | CLS Loss: 0.026946209371089935\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 2.461549997329712 | KNN Loss: 2.4253170490264893 | CLS Loss: 0.036232877522706985\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 2.423970937728882 | KNN Loss: 2.3771116733551025 | CLS Loss: 0.04685923457145691\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 2.5315794944763184 | KNN Loss: 2.4330568313598633 | CLS Loss: 0.09852271527051926\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 2.478238344192505 | KNN Loss: 2.439302444458008 | CLS Loss: 0.03893586993217468\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 2.431978225708008 | KNN Loss: 2.3816022872924805 | CLS Loss: 0.05037584528326988\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 2.4496512413024902 | KNN Loss: 2.4221622943878174 | CLS Loss: 0.02748901955783367\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 2.4548420906066895 | KNN Loss: 2.4162487983703613 | CLS Loss: 0.03859325870871544\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 2.4866392612457275 | KNN Loss: 2.4323313236236572 | CLS Loss: 0.05430794507265091\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 2.432795524597168 | KNN Loss: 2.408698797225952 | CLS Loss: 0.024096829816699028\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 2.4518203735351562 | KNN Loss: 2.4168808460235596 | CLS Loss: 0.03493943437933922\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 2.45745587348938 | KNN Loss: 2.3886072635650635 | CLS Loss: 0.06884854286909103\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 2.456812858581543 | KNN Loss: 2.410113573074341 | CLS Loss: 0.04669928550720215\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 2.5001325607299805 | KNN Loss: 2.435567855834961 | CLS Loss: 0.0645647719502449\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 2.507071018218994 | KNN Loss: 2.455164909362793 | CLS Loss: 0.051906127482652664\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 2.4497358798980713 | KNN Loss: 2.3812782764434814 | CLS Loss: 0.06845764815807343\n",
      "Epoch: 025, Loss: 2.4556, Train: 0.9875, Valid: 0.9827, Best: 0.9827\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 2.44206166267395 | KNN Loss: 2.4085495471954346 | CLS Loss: 0.03351211920380592\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 2.425440788269043 | KNN Loss: 2.39035701751709 | CLS Loss: 0.0350838266313076\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 2.41182017326355 | KNN Loss: 2.36494779586792 | CLS Loss: 0.04687228053808212\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 2.455522060394287 | KNN Loss: 2.4055378437042236 | CLS Loss: 0.049984160810709\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 2.476567506790161 | KNN Loss: 2.4282073974609375 | CLS Loss: 0.04836008697748184\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 2.4679346084594727 | KNN Loss: 2.4281744956970215 | CLS Loss: 0.03976019099354744\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 2.438903570175171 | KNN Loss: 2.402726411819458 | CLS Loss: 0.03617718443274498\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 2.441879987716675 | KNN Loss: 2.415024995803833 | CLS Loss: 0.02685493789613247\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 2.468541383743286 | KNN Loss: 2.4284121990203857 | CLS Loss: 0.0401291660964489\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 2.4472618103027344 | KNN Loss: 2.413565158843994 | CLS Loss: 0.03369675576686859\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 2.4603545665740967 | KNN Loss: 2.4029226303100586 | CLS Loss: 0.05743204802274704\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 2.4590516090393066 | KNN Loss: 2.4105944633483887 | CLS Loss: 0.048457056283950806\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 2.4970526695251465 | KNN Loss: 2.4529361724853516 | CLS Loss: 0.0441165491938591\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 2.456035852432251 | KNN Loss: 2.4084348678588867 | CLS Loss: 0.047600872814655304\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 2.4368927478790283 | KNN Loss: 2.3821799755096436 | CLS Loss: 0.05471283942461014\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 2.4202158451080322 | KNN Loss: 2.3957300186157227 | CLS Loss: 0.024485720321536064\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 2.4131360054016113 | KNN Loss: 2.3748526573181152 | CLS Loss: 0.038283396512269974\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 2.47890567779541 | KNN Loss: 2.414109468460083 | CLS Loss: 0.06479620188474655\n",
      "Epoch: 026, Loss: 2.4538, Train: 0.9878, Valid: 0.9830, Best: 0.9830\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 2.4337594509124756 | KNN Loss: 2.3976082801818848 | CLS Loss: 0.036151133477687836\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 2.4414186477661133 | KNN Loss: 2.406900405883789 | CLS Loss: 0.034518249332904816\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 2.442828893661499 | KNN Loss: 2.393714666366577 | CLS Loss: 0.04911432042717934\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 2.472820281982422 | KNN Loss: 2.4259440898895264 | CLS Loss: 0.046876147389411926\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 2.452909231185913 | KNN Loss: 2.404845714569092 | CLS Loss: 0.04806342348456383\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 2.427417516708374 | KNN Loss: 2.3988542556762695 | CLS Loss: 0.028563296422362328\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 2.401628017425537 | KNN Loss: 2.3880856037139893 | CLS Loss: 0.013542504981160164\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 2.4642436504364014 | KNN Loss: 2.4048962593078613 | CLS Loss: 0.05934731662273407\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 2.497654676437378 | KNN Loss: 2.4473531246185303 | CLS Loss: 0.050301507115364075\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 2.474599838256836 | KNN Loss: 2.453584671020508 | CLS Loss: 0.021015211939811707\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 2.456252336502075 | KNN Loss: 2.3938417434692383 | CLS Loss: 0.06241068243980408\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 2.4656949043273926 | KNN Loss: 2.430187702178955 | CLS Loss: 0.03550725802779198\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 2.4584803581237793 | KNN Loss: 2.433894395828247 | CLS Loss: 0.024585990235209465\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 2.427976608276367 | KNN Loss: 2.4129374027252197 | CLS Loss: 0.015039319172501564\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 2.4457449913024902 | KNN Loss: 2.412954330444336 | CLS Loss: 0.032790590077638626\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 2.4387500286102295 | KNN Loss: 2.396174430847168 | CLS Loss: 0.04257548227906227\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 2.416328191757202 | KNN Loss: 2.376645565032959 | CLS Loss: 0.039682526141405106\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 2.4522321224212646 | KNN Loss: 2.41428542137146 | CLS Loss: 0.037946611642837524\n",
      "Epoch: 027, Loss: 2.4543, Train: 0.9872, Valid: 0.9831, Best: 0.9831\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 2.435892105102539 | KNN Loss: 2.3947372436523438 | CLS Loss: 0.04115490987896919\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 2.4815709590911865 | KNN Loss: 2.424868583679199 | CLS Loss: 0.05670227110385895\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 2.4521920680999756 | KNN Loss: 2.3978703022003174 | CLS Loss: 0.05432165786623955\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 2.419938325881958 | KNN Loss: 2.370387315750122 | CLS Loss: 0.04955098405480385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 2.4560916423797607 | KNN Loss: 2.4172110557556152 | CLS Loss: 0.038880616426467896\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 2.4351308345794678 | KNN Loss: 2.397585391998291 | CLS Loss: 0.037545353174209595\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 2.459334135055542 | KNN Loss: 2.4448766708374023 | CLS Loss: 0.014457393437623978\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 2.422696590423584 | KNN Loss: 2.3990533351898193 | CLS Loss: 0.023643314838409424\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 2.4593446254730225 | KNN Loss: 2.4292666912078857 | CLS Loss: 0.03007788211107254\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 2.4258744716644287 | KNN Loss: 2.400040626525879 | CLS Loss: 0.025833861902356148\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 2.42549729347229 | KNN Loss: 2.3973891735076904 | CLS Loss: 0.02810804173350334\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 2.434732437133789 | KNN Loss: 2.376387596130371 | CLS Loss: 0.05834494158625603\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 2.45737886428833 | KNN Loss: 2.436283826828003 | CLS Loss: 0.02109495736658573\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 2.4445319175720215 | KNN Loss: 2.4077374935150146 | CLS Loss: 0.03679453954100609\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 2.4692349433898926 | KNN Loss: 2.4442813396453857 | CLS Loss: 0.024953553453087807\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 2.4388442039489746 | KNN Loss: 2.391874074935913 | CLS Loss: 0.04697014391422272\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 2.4945571422576904 | KNN Loss: 2.4500391483306885 | CLS Loss: 0.044518034905195236\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 2.4590470790863037 | KNN Loss: 2.4142401218414307 | CLS Loss: 0.04480692371726036\n",
      "Epoch: 028, Loss: 2.4537, Train: 0.9877, Valid: 0.9830, Best: 0.9831\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 2.4223995208740234 | KNN Loss: 2.3813846111297607 | CLS Loss: 0.04101485759019852\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 2.420837640762329 | KNN Loss: 2.391721248626709 | CLS Loss: 0.029116380959749222\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 2.3991212844848633 | KNN Loss: 2.3767988681793213 | CLS Loss: 0.02232236973941326\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 2.4193570613861084 | KNN Loss: 2.394404649734497 | CLS Loss: 0.02495245821774006\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 2.4566080570220947 | KNN Loss: 2.414522409439087 | CLS Loss: 0.04208572581410408\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 2.4459521770477295 | KNN Loss: 2.3915700912475586 | CLS Loss: 0.054382141679525375\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 2.4438116550445557 | KNN Loss: 2.36842942237854 | CLS Loss: 0.07538217306137085\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 2.4355785846710205 | KNN Loss: 2.3887903690338135 | CLS Loss: 0.046788234263658524\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 2.435511350631714 | KNN Loss: 2.3764829635620117 | CLS Loss: 0.059028301388025284\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 2.4420554637908936 | KNN Loss: 2.388248920440674 | CLS Loss: 0.053806502372026443\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 2.4717648029327393 | KNN Loss: 2.4361538887023926 | CLS Loss: 0.03561099246144295\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 2.4803428649902344 | KNN Loss: 2.4343039989471436 | CLS Loss: 0.046038784086704254\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 2.4392948150634766 | KNN Loss: 2.3995208740234375 | CLS Loss: 0.039773933589458466\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 2.4379568099975586 | KNN Loss: 2.4116408824920654 | CLS Loss: 0.02631581947207451\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 2.4770078659057617 | KNN Loss: 2.4286763668060303 | CLS Loss: 0.048331499099731445\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 2.447798013687134 | KNN Loss: 2.3969247341156006 | CLS Loss: 0.05087337642908096\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 2.4528095722198486 | KNN Loss: 2.4105329513549805 | CLS Loss: 0.04227656498551369\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 2.411590814590454 | KNN Loss: 2.398171901702881 | CLS Loss: 0.013418847694993019\n",
      "Epoch: 029, Loss: 2.4481, Train: 0.9894, Valid: 0.9846, Best: 0.9846\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 2.459641695022583 | KNN Loss: 2.4005706310272217 | CLS Loss: 0.05907096341252327\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 2.4800612926483154 | KNN Loss: 2.429776906967163 | CLS Loss: 0.050284452736377716\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 2.431468963623047 | KNN Loss: 2.392953872680664 | CLS Loss: 0.0385151207447052\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 2.434966802597046 | KNN Loss: 2.3734936714172363 | CLS Loss: 0.061473067849874496\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 2.4663984775543213 | KNN Loss: 2.4235785007476807 | CLS Loss: 0.042820047587156296\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 2.446258068084717 | KNN Loss: 2.3888192176818848 | CLS Loss: 0.05743890628218651\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 2.4337499141693115 | KNN Loss: 2.4067769050598145 | CLS Loss: 0.02697291597723961\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 2.437209367752075 | KNN Loss: 2.4108643531799316 | CLS Loss: 0.026344986632466316\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 2.44381046295166 | KNN Loss: 2.3982996940612793 | CLS Loss: 0.04551086947321892\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 2.4443509578704834 | KNN Loss: 2.3996315002441406 | CLS Loss: 0.044719498604536057\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 2.4596426486968994 | KNN Loss: 2.4420299530029297 | CLS Loss: 0.017612779513001442\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 2.4127206802368164 | KNN Loss: 2.373431444168091 | CLS Loss: 0.03928915038704872\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 2.4289345741271973 | KNN Loss: 2.3751094341278076 | CLS Loss: 0.05382517725229263\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 2.477837562561035 | KNN Loss: 2.447880506515503 | CLS Loss: 0.029957158491015434\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 2.511698007583618 | KNN Loss: 2.4542977809906006 | CLS Loss: 0.057400114834308624\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 2.443807601928711 | KNN Loss: 2.3871638774871826 | CLS Loss: 0.05664375051856041\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 2.4571571350097656 | KNN Loss: 2.3878817558288574 | CLS Loss: 0.06927526742219925\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 2.4215738773345947 | KNN Loss: 2.3820834159851074 | CLS Loss: 0.03949040547013283\n",
      "Epoch: 030, Loss: 2.4471, Train: 0.9878, Valid: 0.9832, Best: 0.9846\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 2.4531259536743164 | KNN Loss: 2.4180049896240234 | CLS Loss: 0.03512096777558327\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 2.491645336151123 | KNN Loss: 2.4189631938934326 | CLS Loss: 0.07268204540014267\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 2.4417879581451416 | KNN Loss: 2.426908254623413 | CLS Loss: 0.014879683963954449\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 2.4090521335601807 | KNN Loss: 2.3860795497894287 | CLS Loss: 0.022972673177719116\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 2.4773383140563965 | KNN Loss: 2.420372247695923 | CLS Loss: 0.05696599557995796\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 2.4255404472351074 | KNN Loss: 2.390625238418579 | CLS Loss: 0.03491511940956116\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 2.4562277793884277 | KNN Loss: 2.422227382659912 | CLS Loss: 0.03400048613548279\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 2.418227195739746 | KNN Loss: 2.3832764625549316 | CLS Loss: 0.03495066985487938\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 2.4881088733673096 | KNN Loss: 2.4345598220825195 | CLS Loss: 0.05354897677898407\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 2.4117300510406494 | KNN Loss: 2.4043545722961426 | CLS Loss: 0.007375492248684168\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 2.456355094909668 | KNN Loss: 2.403000593185425 | CLS Loss: 0.053354423493146896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 2.423253059387207 | KNN Loss: 2.394390344619751 | CLS Loss: 0.028862737119197845\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 2.497260093688965 | KNN Loss: 2.406461000442505 | CLS Loss: 0.09079910814762115\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 2.4309191703796387 | KNN Loss: 2.37016224861145 | CLS Loss: 0.060756832361221313\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 2.460653305053711 | KNN Loss: 2.4172117710113525 | CLS Loss: 0.043441418558359146\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 2.429929256439209 | KNN Loss: 2.407388925552368 | CLS Loss: 0.02254021354019642\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 2.445472240447998 | KNN Loss: 2.373246669769287 | CLS Loss: 0.07222560793161392\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 2.4646317958831787 | KNN Loss: 2.4043023586273193 | CLS Loss: 0.06032932177186012\n",
      "Epoch: 031, Loss: 2.4467, Train: 0.9901, Valid: 0.9848, Best: 0.9848\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 2.395787000656128 | KNN Loss: 2.3736701011657715 | CLS Loss: 0.022116871550679207\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 2.4673945903778076 | KNN Loss: 2.4170982837677 | CLS Loss: 0.05029631778597832\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 2.40067195892334 | KNN Loss: 2.3680779933929443 | CLS Loss: 0.032593984156847\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 2.458390474319458 | KNN Loss: 2.4032676219940186 | CLS Loss: 0.055122777819633484\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 2.4489009380340576 | KNN Loss: 2.395726442337036 | CLS Loss: 0.05317457765340805\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 2.41107177734375 | KNN Loss: 2.401282787322998 | CLS Loss: 0.009788880124688148\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 2.434375762939453 | KNN Loss: 2.3932511806488037 | CLS Loss: 0.0411246195435524\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 2.426870584487915 | KNN Loss: 2.390437602996826 | CLS Loss: 0.03643307834863663\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 2.477022409439087 | KNN Loss: 2.4204070568084717 | CLS Loss: 0.05661532282829285\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 2.4743776321411133 | KNN Loss: 2.4373769760131836 | CLS Loss: 0.037000562995672226\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 2.416179895401001 | KNN Loss: 2.3743574619293213 | CLS Loss: 0.041822489351034164\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 2.437567710876465 | KNN Loss: 2.3939626216888428 | CLS Loss: 0.0436050221323967\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 2.408651351928711 | KNN Loss: 2.3723654747009277 | CLS Loss: 0.03628598153591156\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 2.434204578399658 | KNN Loss: 2.398695468902588 | CLS Loss: 0.03550919517874718\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 2.4567952156066895 | KNN Loss: 2.4235754013061523 | CLS Loss: 0.033219799399375916\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 2.4198429584503174 | KNN Loss: 2.378092050552368 | CLS Loss: 0.04175093024969101\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 2.412747621536255 | KNN Loss: 2.364969491958618 | CLS Loss: 0.04777805134654045\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 2.488919734954834 | KNN Loss: 2.43660831451416 | CLS Loss: 0.052311331033706665\n",
      "Epoch: 032, Loss: 2.4436, Train: 0.9895, Valid: 0.9842, Best: 0.9848\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 2.4619574546813965 | KNN Loss: 2.3939285278320312 | CLS Loss: 0.06802895665168762\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 2.431698799133301 | KNN Loss: 2.417562961578369 | CLS Loss: 0.01413572859019041\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 2.4654102325439453 | KNN Loss: 2.4361698627471924 | CLS Loss: 0.029240485280752182\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 2.4307057857513428 | KNN Loss: 2.3915598392486572 | CLS Loss: 0.039145901799201965\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 2.4260988235473633 | KNN Loss: 2.381474256515503 | CLS Loss: 0.04462456330657005\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 2.4587697982788086 | KNN Loss: 2.4096364974975586 | CLS Loss: 0.04913320764899254\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 2.4517600536346436 | KNN Loss: 2.4244930744171143 | CLS Loss: 0.027266982942819595\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 2.433382034301758 | KNN Loss: 2.410832405090332 | CLS Loss: 0.02254970371723175\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 2.445768117904663 | KNN Loss: 2.414032220840454 | CLS Loss: 0.03173579275608063\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 2.4605584144592285 | KNN Loss: 2.407256603240967 | CLS Loss: 0.05330183357000351\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 2.428182601928711 | KNN Loss: 2.3994321823120117 | CLS Loss: 0.02875037118792534\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 2.437023162841797 | KNN Loss: 2.4109389781951904 | CLS Loss: 0.026084184646606445\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 2.407993793487549 | KNN Loss: 2.3422625064849854 | CLS Loss: 0.06573119014501572\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 2.4228456020355225 | KNN Loss: 2.3820033073425293 | CLS Loss: 0.040842361748218536\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 2.4324378967285156 | KNN Loss: 2.386488437652588 | CLS Loss: 0.045949481427669525\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 2.4304358959198 | KNN Loss: 2.4015450477600098 | CLS Loss: 0.02889081835746765\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 2.4228763580322266 | KNN Loss: 2.402172803878784 | CLS Loss: 0.020703548565506935\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 2.422525644302368 | KNN Loss: 2.4040563106536865 | CLS Loss: 0.018469350412487984\n",
      "Epoch: 033, Loss: 2.4446, Train: 0.9884, Valid: 0.9836, Best: 0.9848\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 2.4093453884124756 | KNN Loss: 2.3653955459594727 | CLS Loss: 0.043949808925390244\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 2.420431137084961 | KNN Loss: 2.3749208450317383 | CLS Loss: 0.04551026597619057\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 2.4359593391418457 | KNN Loss: 2.4218294620513916 | CLS Loss: 0.014129828661680222\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 2.433025598526001 | KNN Loss: 2.4174418449401855 | CLS Loss: 0.015583831816911697\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 2.4376485347747803 | KNN Loss: 2.396533727645874 | CLS Loss: 0.04111476615071297\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 2.434556722640991 | KNN Loss: 2.3981032371520996 | CLS Loss: 0.03645339608192444\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 2.46598219871521 | KNN Loss: 2.4037532806396484 | CLS Loss: 0.06222889944911003\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 2.4706990718841553 | KNN Loss: 2.4392826557159424 | CLS Loss: 0.031416524201631546\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 2.428415298461914 | KNN Loss: 2.4130489826202393 | CLS Loss: 0.015366348437964916\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 2.448575496673584 | KNN Loss: 2.4092977046966553 | CLS Loss: 0.039277855306863785\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 2.40981388092041 | KNN Loss: 2.3861560821533203 | CLS Loss: 0.023657822981476784\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 2.453859567642212 | KNN Loss: 2.405169725418091 | CLS Loss: 0.04868994280695915\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 2.4510555267333984 | KNN Loss: 2.4067201614379883 | CLS Loss: 0.04433540999889374\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 2.4375481605529785 | KNN Loss: 2.3974757194519043 | CLS Loss: 0.0400724932551384\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 2.427036762237549 | KNN Loss: 2.386416435241699 | CLS Loss: 0.040620315819978714\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 2.4315061569213867 | KNN Loss: 2.4180543422698975 | CLS Loss: 0.013451873324811459\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 2.44006085395813 | KNN Loss: 2.404001235961914 | CLS Loss: 0.036059603095054626\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 2.4621529579162598 | KNN Loss: 2.4202780723571777 | CLS Loss: 0.04187489300966263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 2.4372, Train: 0.9896, Valid: 0.9838, Best: 0.9848\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 2.4702939987182617 | KNN Loss: 2.4292545318603516 | CLS Loss: 0.041039370000362396\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 2.401801824569702 | KNN Loss: 2.362006187438965 | CLS Loss: 0.03979559242725372\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 2.4323740005493164 | KNN Loss: 2.4127323627471924 | CLS Loss: 0.019641710445284843\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 2.4204773902893066 | KNN Loss: 2.3849031925201416 | CLS Loss: 0.03557419404387474\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 2.4500319957733154 | KNN Loss: 2.421945333480835 | CLS Loss: 0.028086746111512184\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 2.4397902488708496 | KNN Loss: 2.413207769393921 | CLS Loss: 0.02658259868621826\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 2.465892791748047 | KNN Loss: 2.4149134159088135 | CLS Loss: 0.0509793795645237\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 2.4229938983917236 | KNN Loss: 2.3937079906463623 | CLS Loss: 0.029285941272974014\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 2.4048497676849365 | KNN Loss: 2.3698556423187256 | CLS Loss: 0.034994110465049744\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 2.4971234798431396 | KNN Loss: 2.47152042388916 | CLS Loss: 0.025602947920560837\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 2.4687092304229736 | KNN Loss: 2.426100015640259 | CLS Loss: 0.04260922223329544\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 2.434408664703369 | KNN Loss: 2.4045588970184326 | CLS Loss: 0.029849695041775703\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 2.461212635040283 | KNN Loss: 2.438610553741455 | CLS Loss: 0.022602170705795288\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 2.4444637298583984 | KNN Loss: 2.390758752822876 | CLS Loss: 0.05370504781603813\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 2.4359219074249268 | KNN Loss: 2.4145665168762207 | CLS Loss: 0.021355275064706802\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 2.4307210445404053 | KNN Loss: 2.3915281295776367 | CLS Loss: 0.039192985743284225\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 2.4398114681243896 | KNN Loss: 2.4135003089904785 | CLS Loss: 0.02631123550236225\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 2.4704391956329346 | KNN Loss: 2.430280923843384 | CLS Loss: 0.04015832021832466\n",
      "Epoch: 035, Loss: 2.4421, Train: 0.9902, Valid: 0.9849, Best: 0.9849\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 2.435040235519409 | KNN Loss: 2.416317939758301 | CLS Loss: 0.018722252920269966\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 2.4343082904815674 | KNN Loss: 2.4120688438415527 | CLS Loss: 0.02223934419453144\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 2.4139926433563232 | KNN Loss: 2.394970655441284 | CLS Loss: 0.019021879881620407\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 2.4775240421295166 | KNN Loss: 2.4374661445617676 | CLS Loss: 0.04005791246891022\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 2.439889669418335 | KNN Loss: 2.4077179431915283 | CLS Loss: 0.03217161446809769\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 2.4911811351776123 | KNN Loss: 2.4383764266967773 | CLS Loss: 0.052804820239543915\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 2.446643829345703 | KNN Loss: 2.4307219982147217 | CLS Loss: 0.015921805053949356\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 2.4356558322906494 | KNN Loss: 2.402930736541748 | CLS Loss: 0.032725028693675995\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 2.4777462482452393 | KNN Loss: 2.4224894046783447 | CLS Loss: 0.055256858468055725\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 2.413944959640503 | KNN Loss: 2.3675036430358887 | CLS Loss: 0.046441223472356796\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 2.4634757041931152 | KNN Loss: 2.4375851154327393 | CLS Loss: 0.02589067630469799\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 2.4409215450286865 | KNN Loss: 2.392645835876465 | CLS Loss: 0.04827573522925377\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 2.424799680709839 | KNN Loss: 2.3944573402404785 | CLS Loss: 0.03034231811761856\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 2.4572653770446777 | KNN Loss: 2.4017534255981445 | CLS Loss: 0.05551190301775932\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 2.466773271560669 | KNN Loss: 2.436023712158203 | CLS Loss: 0.030749497935175896\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 2.422238826751709 | KNN Loss: 2.3642516136169434 | CLS Loss: 0.057987116277217865\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 2.43696665763855 | KNN Loss: 2.4089460372924805 | CLS Loss: 0.02802070789039135\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 2.4359915256500244 | KNN Loss: 2.4270691871643066 | CLS Loss: 0.008922453969717026\n",
      "Epoch: 036, Loss: 2.4386, Train: 0.9902, Valid: 0.9843, Best: 0.9849\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 2.4628875255584717 | KNN Loss: 2.4069664478302 | CLS Loss: 0.05592111870646477\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 2.486593723297119 | KNN Loss: 2.443847417831421 | CLS Loss: 0.04274621605873108\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 2.453502893447876 | KNN Loss: 2.401395082473755 | CLS Loss: 0.052107878029346466\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 2.442556142807007 | KNN Loss: 2.3833940029144287 | CLS Loss: 0.059162162244319916\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 2.4716155529022217 | KNN Loss: 2.4086997509002686 | CLS Loss: 0.06291572004556656\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 2.4621520042419434 | KNN Loss: 2.4271528720855713 | CLS Loss: 0.03499908000230789\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 2.414107084274292 | KNN Loss: 2.389793634414673 | CLS Loss: 0.02431337907910347\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 2.4285385608673096 | KNN Loss: 2.4049489498138428 | CLS Loss: 0.02358964830636978\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 2.424083948135376 | KNN Loss: 2.3986690044403076 | CLS Loss: 0.025415031239390373\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 2.439920425415039 | KNN Loss: 2.4065372943878174 | CLS Loss: 0.03338306024670601\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 2.4349584579467773 | KNN Loss: 2.4206652641296387 | CLS Loss: 0.014293300919234753\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 2.3911197185516357 | KNN Loss: 2.363992691040039 | CLS Loss: 0.027126962319016457\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 2.4450950622558594 | KNN Loss: 2.4032912254333496 | CLS Loss: 0.04180392995476723\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 2.376431703567505 | KNN Loss: 2.357095241546631 | CLS Loss: 0.019336499273777008\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 2.449740171432495 | KNN Loss: 2.392059564590454 | CLS Loss: 0.05768055096268654\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 2.4576313495635986 | KNN Loss: 2.4163784980773926 | CLS Loss: 0.041252944618463516\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 2.4433579444885254 | KNN Loss: 2.418975591659546 | CLS Loss: 0.02438243478536606\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 2.439155340194702 | KNN Loss: 2.401857614517212 | CLS Loss: 0.03729776293039322\n",
      "Epoch: 037, Loss: 2.4412, Train: 0.9899, Valid: 0.9845, Best: 0.9849\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 2.419246196746826 | KNN Loss: 2.3849165439605713 | CLS Loss: 0.03432971611618996\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 2.460777997970581 | KNN Loss: 2.4284379482269287 | CLS Loss: 0.03234002739191055\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 2.4690163135528564 | KNN Loss: 2.441225051879883 | CLS Loss: 0.027791205793619156\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 2.4244232177734375 | KNN Loss: 2.3975462913513184 | CLS Loss: 0.02687700465321541\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 2.4786038398742676 | KNN Loss: 2.4277281761169434 | CLS Loss: 0.050875645130872726\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 2.4611077308654785 | KNN Loss: 2.433051109313965 | CLS Loss: 0.028056534007191658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 2.4443163871765137 | KNN Loss: 2.4109508991241455 | CLS Loss: 0.033365555107593536\n",
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 2.515061616897583 | KNN Loss: 2.447596311569214 | CLS Loss: 0.0674654170870781\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 2.4252536296844482 | KNN Loss: 2.406633138656616 | CLS Loss: 0.018620382994413376\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 2.437495708465576 | KNN Loss: 2.399496555328369 | CLS Loss: 0.03799916431307793\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 2.448355197906494 | KNN Loss: 2.4140427112579346 | CLS Loss: 0.0343124084174633\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 2.428218126296997 | KNN Loss: 2.4171054363250732 | CLS Loss: 0.011112766340374947\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 2.460858106613159 | KNN Loss: 2.4175121784210205 | CLS Loss: 0.043345846235752106\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 2.4029033184051514 | KNN Loss: 2.3835721015930176 | CLS Loss: 0.019331173971295357\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 2.386389970779419 | KNN Loss: 2.3667688369750977 | CLS Loss: 0.01962115429341793\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 2.4151391983032227 | KNN Loss: 2.379920721054077 | CLS Loss: 0.035218555480241776\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 2.459721088409424 | KNN Loss: 2.4078164100646973 | CLS Loss: 0.051904693245887756\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 2.425873041152954 | KNN Loss: 2.3755598068237305 | CLS Loss: 0.050313230603933334\n",
      "Epoch: 038, Loss: 2.4406, Train: 0.9909, Valid: 0.9848, Best: 0.9849\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 2.4302635192871094 | KNN Loss: 2.417574882507324 | CLS Loss: 0.01268857717514038\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 2.4238507747650146 | KNN Loss: 2.3767294883728027 | CLS Loss: 0.04712122306227684\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 2.4429891109466553 | KNN Loss: 2.3969264030456543 | CLS Loss: 0.0460626482963562\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 2.4560775756835938 | KNN Loss: 2.4090089797973633 | CLS Loss: 0.0470685139298439\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 2.467700958251953 | KNN Loss: 2.3987998962402344 | CLS Loss: 0.06890111416578293\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 2.4694981575012207 | KNN Loss: 2.402651309967041 | CLS Loss: 0.06684694439172745\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 2.4569296836853027 | KNN Loss: 2.4230034351348877 | CLS Loss: 0.03392622247338295\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 2.4353621006011963 | KNN Loss: 2.380307912826538 | CLS Loss: 0.05505428835749626\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 2.4318981170654297 | KNN Loss: 2.424781322479248 | CLS Loss: 0.007116813212633133\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 2.4237895011901855 | KNN Loss: 2.394029140472412 | CLS Loss: 0.02976042591035366\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 2.4570047855377197 | KNN Loss: 2.421746015548706 | CLS Loss: 0.03525873273611069\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 2.4426376819610596 | KNN Loss: 2.4043989181518555 | CLS Loss: 0.038238707929849625\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 2.433636426925659 | KNN Loss: 2.3826849460601807 | CLS Loss: 0.050951406359672546\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 2.4636001586914062 | KNN Loss: 2.4075870513916016 | CLS Loss: 0.05601312220096588\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 2.4511642456054688 | KNN Loss: 2.4171431064605713 | CLS Loss: 0.03402121737599373\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 2.4114670753479004 | KNN Loss: 2.399487257003784 | CLS Loss: 0.011979793198406696\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 2.462174415588379 | KNN Loss: 2.4234237670898438 | CLS Loss: 0.0387505404651165\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 2.470229148864746 | KNN Loss: 2.4332449436187744 | CLS Loss: 0.03698422387242317\n",
      "Epoch: 039, Loss: 2.4375, Train: 0.9903, Valid: 0.9829, Best: 0.9849\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 2.4444382190704346 | KNN Loss: 2.411773443222046 | CLS Loss: 0.0326647013425827\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 2.4657111167907715 | KNN Loss: 2.406700372695923 | CLS Loss: 0.05901065468788147\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 2.390352487564087 | KNN Loss: 2.3751907348632812 | CLS Loss: 0.015161724761128426\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 2.401761054992676 | KNN Loss: 2.368499994277954 | CLS Loss: 0.03326105698943138\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 2.450634717941284 | KNN Loss: 2.399672031402588 | CLS Loss: 0.05096259340643883\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 2.4018421173095703 | KNN Loss: 2.3790364265441895 | CLS Loss: 0.022805731743574142\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 2.445402145385742 | KNN Loss: 2.387512683868408 | CLS Loss: 0.05788954347372055\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 2.4135384559631348 | KNN Loss: 2.3961665630340576 | CLS Loss: 0.017371825873851776\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 2.458604574203491 | KNN Loss: 2.4110515117645264 | CLS Loss: 0.04755310341715813\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 2.441272497177124 | KNN Loss: 2.420154333114624 | CLS Loss: 0.021118076518177986\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 2.4353950023651123 | KNN Loss: 2.3972082138061523 | CLS Loss: 0.03818677365779877\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 2.4576823711395264 | KNN Loss: 2.4071755409240723 | CLS Loss: 0.05050674080848694\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 2.4944443702697754 | KNN Loss: 2.43638014793396 | CLS Loss: 0.058064233511686325\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 2.4221012592315674 | KNN Loss: 2.3957762718200684 | CLS Loss: 0.026325101032853127\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 2.420738458633423 | KNN Loss: 2.378533363342285 | CLS Loss: 0.04220518097281456\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 2.4656665325164795 | KNN Loss: 2.4221622943878174 | CLS Loss: 0.04350420460104942\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 2.4386775493621826 | KNN Loss: 2.398942232131958 | CLS Loss: 0.03973532095551491\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 2.4358606338500977 | KNN Loss: 2.3907079696655273 | CLS Loss: 0.04515273496508598\n",
      "Epoch: 040, Loss: 2.4327, Train: 0.9917, Valid: 0.9855, Best: 0.9855\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 2.4472899436950684 | KNN Loss: 2.404677629470825 | CLS Loss: 0.042612239718437195\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 2.413496971130371 | KNN Loss: 2.3978490829467773 | CLS Loss: 0.015647852793335915\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 2.438476800918579 | KNN Loss: 2.404466390609741 | CLS Loss: 0.034010399132966995\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 2.433699131011963 | KNN Loss: 2.4140024185180664 | CLS Loss: 0.019696732982993126\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 2.411146640777588 | KNN Loss: 2.394014835357666 | CLS Loss: 0.01713184267282486\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 2.4197771549224854 | KNN Loss: 2.3971664905548096 | CLS Loss: 0.022610632702708244\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 2.432720422744751 | KNN Loss: 2.4045729637145996 | CLS Loss: 0.02814757078886032\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 2.4298081398010254 | KNN Loss: 2.412313461303711 | CLS Loss: 0.017494559288024902\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 2.456376075744629 | KNN Loss: 2.406221866607666 | CLS Loss: 0.05015420541167259\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 2.4534473419189453 | KNN Loss: 2.389963150024414 | CLS Loss: 0.06348428130149841\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 2.4368724822998047 | KNN Loss: 2.4099087715148926 | CLS Loss: 0.026963744312524796\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 2.4611752033233643 | KNN Loss: 2.437993049621582 | CLS Loss: 0.023182163015007973\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 2.463043689727783 | KNN Loss: 2.4285271167755127 | CLS Loss: 0.034516580402851105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 2.45642352104187 | KNN Loss: 2.4265215396881104 | CLS Loss: 0.029901890084147453\n",
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 2.4397263526916504 | KNN Loss: 2.381004571914673 | CLS Loss: 0.05872169882059097\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 2.4666736125946045 | KNN Loss: 2.4100866317749023 | CLS Loss: 0.056587085127830505\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 2.4598941802978516 | KNN Loss: 2.4122819900512695 | CLS Loss: 0.04761224985122681\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 2.4564359188079834 | KNN Loss: 2.379107713699341 | CLS Loss: 0.07732813060283661\n",
      "Epoch: 041, Loss: 2.4353, Train: 0.9909, Valid: 0.9844, Best: 0.9855\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 2.4529037475585938 | KNN Loss: 2.4050447940826416 | CLS Loss: 0.04785895720124245\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 2.444174289703369 | KNN Loss: 2.4141197204589844 | CLS Loss: 0.030054498463869095\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 2.404237985610962 | KNN Loss: 2.3646411895751953 | CLS Loss: 0.03959676995873451\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 2.424860954284668 | KNN Loss: 2.400876760482788 | CLS Loss: 0.023984244093298912\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 2.4169015884399414 | KNN Loss: 2.4039857387542725 | CLS Loss: 0.01291586086153984\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 2.4432899951934814 | KNN Loss: 2.3774476051330566 | CLS Loss: 0.06584238260984421\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 2.4219155311584473 | KNN Loss: 2.4029855728149414 | CLS Loss: 0.018929840996861458\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 2.398165464401245 | KNN Loss: 2.35686993598938 | CLS Loss: 0.041295576840639114\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 2.392301321029663 | KNN Loss: 2.3782968521118164 | CLS Loss: 0.014004351571202278\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 2.4488775730133057 | KNN Loss: 2.4148905277252197 | CLS Loss: 0.03398701548576355\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 2.455049991607666 | KNN Loss: 2.4336137771606445 | CLS Loss: 0.021436220034956932\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 2.4057278633117676 | KNN Loss: 2.3651480674743652 | CLS Loss: 0.040579892694950104\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 2.4296391010284424 | KNN Loss: 2.412482976913452 | CLS Loss: 0.017156220972537994\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 2.467947483062744 | KNN Loss: 2.4437196254730225 | CLS Loss: 0.02422780729830265\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 2.4430713653564453 | KNN Loss: 2.411822557449341 | CLS Loss: 0.031248748302459717\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 2.4530105590820312 | KNN Loss: 2.419172525405884 | CLS Loss: 0.033837977796792984\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 2.4573864936828613 | KNN Loss: 2.4149534702301025 | CLS Loss: 0.04243297874927521\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 2.4100124835968018 | KNN Loss: 2.3926889896392822 | CLS Loss: 0.017323428764939308\n",
      "Epoch: 042, Loss: 2.4328, Train: 0.9907, Valid: 0.9841, Best: 0.9855\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 2.414301633834839 | KNN Loss: 2.3944578170776367 | CLS Loss: 0.019843772053718567\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 2.4319820404052734 | KNN Loss: 2.41062331199646 | CLS Loss: 0.021358700469136238\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 2.4438230991363525 | KNN Loss: 2.4227020740509033 | CLS Loss: 0.02112114243209362\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 2.4326796531677246 | KNN Loss: 2.420154571533203 | CLS Loss: 0.012524982914328575\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 2.4487192630767822 | KNN Loss: 2.4101333618164062 | CLS Loss: 0.03858589008450508\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 2.423828363418579 | KNN Loss: 2.376201629638672 | CLS Loss: 0.04762681946158409\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 2.426715612411499 | KNN Loss: 2.3780205249786377 | CLS Loss: 0.048695046454668045\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 2.45344877243042 | KNN Loss: 2.422567844390869 | CLS Loss: 0.030880851671099663\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 2.442641496658325 | KNN Loss: 2.400949001312256 | CLS Loss: 0.04169241338968277\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 2.4280736446380615 | KNN Loss: 2.409627676010132 | CLS Loss: 0.01844589225947857\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 2.4356210231781006 | KNN Loss: 2.382586717605591 | CLS Loss: 0.05303427204489708\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 2.45544171333313 | KNN Loss: 2.4129388332366943 | CLS Loss: 0.042502887547016144\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 2.4456493854522705 | KNN Loss: 2.4300425052642822 | CLS Loss: 0.015606771223247051\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 2.4115920066833496 | KNN Loss: 2.393122911453247 | CLS Loss: 0.01846904121339321\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 2.466083288192749 | KNN Loss: 2.419896364212036 | CLS Loss: 0.04618699848651886\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 2.441624402999878 | KNN Loss: 2.4049124717712402 | CLS Loss: 0.036711957305669785\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 2.4219627380371094 | KNN Loss: 2.375824213027954 | CLS Loss: 0.046138618141412735\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 2.4128010272979736 | KNN Loss: 2.3833155632019043 | CLS Loss: 0.029485564678907394\n",
      "Epoch: 043, Loss: 2.4289, Train: 0.9919, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 2.3946149349212646 | KNN Loss: 2.378966808319092 | CLS Loss: 0.015648221597075462\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 2.421025037765503 | KNN Loss: 2.395526647567749 | CLS Loss: 0.02549845725297928\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 2.406775951385498 | KNN Loss: 2.375335454940796 | CLS Loss: 0.03144058212637901\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 2.4493463039398193 | KNN Loss: 2.4277548789978027 | CLS Loss: 0.021591434255242348\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 2.4329488277435303 | KNN Loss: 2.405276298522949 | CLS Loss: 0.027672506868839264\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 2.4249651432037354 | KNN Loss: 2.3674492835998535 | CLS Loss: 0.05751591548323631\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 2.4703147411346436 | KNN Loss: 2.440703868865967 | CLS Loss: 0.02961088716983795\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 2.4270951747894287 | KNN Loss: 2.401498794555664 | CLS Loss: 0.025596337392926216\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 2.4251935482025146 | KNN Loss: 2.387232542037964 | CLS Loss: 0.03796090930700302\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 2.4182448387145996 | KNN Loss: 2.4035401344299316 | CLS Loss: 0.014704731293022633\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 2.422513961791992 | KNN Loss: 2.3903536796569824 | CLS Loss: 0.03216021507978439\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 2.4224138259887695 | KNN Loss: 2.3792762756347656 | CLS Loss: 0.043137647211551666\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 2.4318182468414307 | KNN Loss: 2.400651216506958 | CLS Loss: 0.031167026609182358\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 2.378256320953369 | KNN Loss: 2.3529412746429443 | CLS Loss: 0.02531508356332779\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 2.4026601314544678 | KNN Loss: 2.3844399452209473 | CLS Loss: 0.01822025328874588\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 2.4151370525360107 | KNN Loss: 2.3638362884521484 | CLS Loss: 0.05130083113908768\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 2.4314491748809814 | KNN Loss: 2.383493423461914 | CLS Loss: 0.047955822199583054\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 2.430244207382202 | KNN Loss: 2.412642002105713 | CLS Loss: 0.017602266743779182\n",
      "Epoch: 044, Loss: 2.4284, Train: 0.9922, Valid: 0.9852, Best: 0.9860\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 2.371856689453125 | KNN Loss: 2.3549492359161377 | CLS Loss: 0.016907429322600365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 2.4254403114318848 | KNN Loss: 2.409135341644287 | CLS Loss: 0.01630507968366146\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 2.4383227825164795 | KNN Loss: 2.3875625133514404 | CLS Loss: 0.050760384649038315\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 2.406935214996338 | KNN Loss: 2.3941409587860107 | CLS Loss: 0.01279417984187603\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 2.4219818115234375 | KNN Loss: 2.4021973609924316 | CLS Loss: 0.01978437229990959\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 2.4444479942321777 | KNN Loss: 2.414515733718872 | CLS Loss: 0.029932230710983276\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 2.427824020385742 | KNN Loss: 2.397669553756714 | CLS Loss: 0.030154500156641006\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 2.4205048084259033 | KNN Loss: 2.3979949951171875 | CLS Loss: 0.02250991202890873\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 2.462672710418701 | KNN Loss: 2.4277729988098145 | CLS Loss: 0.034899644553661346\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 2.417501926422119 | KNN Loss: 2.38818621635437 | CLS Loss: 0.029315602034330368\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 2.451415538787842 | KNN Loss: 2.4350879192352295 | CLS Loss: 0.016327708959579468\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 2.4289724826812744 | KNN Loss: 2.4230778217315674 | CLS Loss: 0.005894768517464399\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 2.4120736122131348 | KNN Loss: 2.384093761444092 | CLS Loss: 0.027979938313364983\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 2.4661543369293213 | KNN Loss: 2.436201810836792 | CLS Loss: 0.029952475801110268\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 2.3773574829101562 | KNN Loss: 2.369457721710205 | CLS Loss: 0.007899793796241283\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 2.4419405460357666 | KNN Loss: 2.411207675933838 | CLS Loss: 0.03073291853070259\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 2.435238838195801 | KNN Loss: 2.3837807178497314 | CLS Loss: 0.05145817622542381\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 2.4339582920074463 | KNN Loss: 2.3773272037506104 | CLS Loss: 0.056631047278642654\n",
      "Epoch: 045, Loss: 2.4308, Train: 0.9918, Valid: 0.9842, Best: 0.9860\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 2.4059643745422363 | KNN Loss: 2.367290496826172 | CLS Loss: 0.03867388516664505\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 2.435981035232544 | KNN Loss: 2.4202020168304443 | CLS Loss: 0.015779072418808937\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 2.401682138442993 | KNN Loss: 2.382141351699829 | CLS Loss: 0.019540783017873764\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 2.4030258655548096 | KNN Loss: 2.352346420288086 | CLS Loss: 0.050679538398981094\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 2.438063144683838 | KNN Loss: 2.410127878189087 | CLS Loss: 0.02793533354997635\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 2.4133973121643066 | KNN Loss: 2.407195568084717 | CLS Loss: 0.006201729644089937\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 2.4297842979431152 | KNN Loss: 2.399975538253784 | CLS Loss: 0.029808705672621727\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 2.4085581302642822 | KNN Loss: 2.3877689838409424 | CLS Loss: 0.020789170637726784\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 2.483124017715454 | KNN Loss: 2.405941963195801 | CLS Loss: 0.07718212902545929\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 2.4517414569854736 | KNN Loss: 2.411921977996826 | CLS Loss: 0.03981946408748627\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 2.4429407119750977 | KNN Loss: 2.4118754863739014 | CLS Loss: 0.031065264716744423\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 2.419316053390503 | KNN Loss: 2.4051010608673096 | CLS Loss: 0.014215044677257538\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 2.3934669494628906 | KNN Loss: 2.378957986831665 | CLS Loss: 0.014509003609418869\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 2.4229421615600586 | KNN Loss: 2.3803465366363525 | CLS Loss: 0.04259553551673889\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 2.43254017829895 | KNN Loss: 2.39005970954895 | CLS Loss: 0.04248056560754776\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 2.4406237602233887 | KNN Loss: 2.412517547607422 | CLS Loss: 0.028106186538934708\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 2.422135829925537 | KNN Loss: 2.3889472484588623 | CLS Loss: 0.03318865969777107\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 2.425227642059326 | KNN Loss: 2.4019458293914795 | CLS Loss: 0.023281889036297798\n",
      "Epoch: 046, Loss: 2.4283, Train: 0.9925, Valid: 0.9859, Best: 0.9860\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 2.4494645595550537 | KNN Loss: 2.4317383766174316 | CLS Loss: 0.017726292833685875\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 2.440046787261963 | KNN Loss: 2.4201927185058594 | CLS Loss: 0.01985403150320053\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 2.4585886001586914 | KNN Loss: 2.4154715538024902 | CLS Loss: 0.043116942048072815\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 2.4520232677459717 | KNN Loss: 2.4269039630889893 | CLS Loss: 0.02511921338737011\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 2.4370925426483154 | KNN Loss: 2.404299736022949 | CLS Loss: 0.03279275447130203\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 2.4385626316070557 | KNN Loss: 2.4075446128845215 | CLS Loss: 0.031018024310469627\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 2.405726432800293 | KNN Loss: 2.3714444637298584 | CLS Loss: 0.034281883388757706\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 2.4153549671173096 | KNN Loss: 2.387989044189453 | CLS Loss: 0.02736598066985607\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 2.397923231124878 | KNN Loss: 2.3408310413360596 | CLS Loss: 0.057092081755399704\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 2.4088146686553955 | KNN Loss: 2.399121046066284 | CLS Loss: 0.009693573229014874\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 2.4355854988098145 | KNN Loss: 2.400256633758545 | CLS Loss: 0.03532886505126953\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 2.402547597885132 | KNN Loss: 2.375194787979126 | CLS Loss: 0.02735270746052265\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 2.4739949703216553 | KNN Loss: 2.4639759063720703 | CLS Loss: 0.010019115172326565\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 2.4203572273254395 | KNN Loss: 2.383288621902466 | CLS Loss: 0.037068694829940796\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 2.4210619926452637 | KNN Loss: 2.387911319732666 | CLS Loss: 0.03315063938498497\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 2.4172871112823486 | KNN Loss: 2.379352569580078 | CLS Loss: 0.037934500724077225\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 2.4113807678222656 | KNN Loss: 2.374523162841797 | CLS Loss: 0.03685770928859711\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 2.4269661903381348 | KNN Loss: 2.397601842880249 | CLS Loss: 0.02936433255672455\n",
      "Epoch: 047, Loss: 2.4267, Train: 0.9908, Valid: 0.9838, Best: 0.9860\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 2.444479465484619 | KNN Loss: 2.4074811935424805 | CLS Loss: 0.036998387426137924\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 2.4476587772369385 | KNN Loss: 2.412971258163452 | CLS Loss: 0.034687407314777374\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 2.440605640411377 | KNN Loss: 2.401336908340454 | CLS Loss: 0.039268676191568375\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 2.4129698276519775 | KNN Loss: 2.403080701828003 | CLS Loss: 0.009889086708426476\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 2.457850217819214 | KNN Loss: 2.417973279953003 | CLS Loss: 0.039876848459243774\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 2.406414031982422 | KNN Loss: 2.3770861625671387 | CLS Loss: 0.029327820986509323\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 2.4399542808532715 | KNN Loss: 2.410670518875122 | CLS Loss: 0.029283840209245682\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 2.454890727996826 | KNN Loss: 2.422079563140869 | CLS Loss: 0.03281121701002121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 2.403923988342285 | KNN Loss: 2.3744709491729736 | CLS Loss: 0.029453100636601448\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 2.3851051330566406 | KNN Loss: 2.36529803276062 | CLS Loss: 0.01980709843337536\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 2.438324451446533 | KNN Loss: 2.4056169986724854 | CLS Loss: 0.03270747512578964\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 2.403348445892334 | KNN Loss: 2.386944532394409 | CLS Loss: 0.01640380546450615\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 2.488034963607788 | KNN Loss: 2.4501867294311523 | CLS Loss: 0.03784829378128052\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 2.4452977180480957 | KNN Loss: 2.4301037788391113 | CLS Loss: 0.015193942002952099\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 2.430123805999756 | KNN Loss: 2.391632080078125 | CLS Loss: 0.03849177062511444\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 2.435600757598877 | KNN Loss: 2.408054828643799 | CLS Loss: 0.027546025812625885\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 2.4489448070526123 | KNN Loss: 2.404404640197754 | CLS Loss: 0.0445401556789875\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 2.436743974685669 | KNN Loss: 2.4212381839752197 | CLS Loss: 0.015505746006965637\n",
      "Epoch: 048, Loss: 2.4258, Train: 0.9924, Valid: 0.9852, Best: 0.9860\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 2.409403085708618 | KNN Loss: 2.378880023956299 | CLS Loss: 0.03052300587296486\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 2.450171947479248 | KNN Loss: 2.4239237308502197 | CLS Loss: 0.026248116046190262\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 2.4595792293548584 | KNN Loss: 2.4087796211242676 | CLS Loss: 0.05079958960413933\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 2.3860719203948975 | KNN Loss: 2.3628194332122803 | CLS Loss: 0.023252518847584724\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 2.423328161239624 | KNN Loss: 2.407651662826538 | CLS Loss: 0.015676595270633698\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 2.403456449508667 | KNN Loss: 2.385802745819092 | CLS Loss: 0.01765376888215542\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 2.4387762546539307 | KNN Loss: 2.4040160179138184 | CLS Loss: 0.03476031497120857\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 2.418623208999634 | KNN Loss: 2.3929641246795654 | CLS Loss: 0.02565908059477806\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 2.4446861743927 | KNN Loss: 2.411081314086914 | CLS Loss: 0.03360495716333389\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 2.4229226112365723 | KNN Loss: 2.376413583755493 | CLS Loss: 0.046509116888046265\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 2.4611966609954834 | KNN Loss: 2.449338674545288 | CLS Loss: 0.011857914738357067\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 2.45817232131958 | KNN Loss: 2.419355869293213 | CLS Loss: 0.03881647810339928\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 2.435877561569214 | KNN Loss: 2.402475118637085 | CLS Loss: 0.03340240195393562\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 2.4386844635009766 | KNN Loss: 2.417210817337036 | CLS Loss: 0.02147364430129528\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 2.4321322441101074 | KNN Loss: 2.414367198944092 | CLS Loss: 0.01776495762169361\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 2.4479150772094727 | KNN Loss: 2.423201322555542 | CLS Loss: 0.02471384033560753\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 2.4322926998138428 | KNN Loss: 2.404087543487549 | CLS Loss: 0.028205079957842827\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 2.4531350135803223 | KNN Loss: 2.422450065612793 | CLS Loss: 0.030684927478432655\n",
      "Epoch: 049, Loss: 2.4251, Train: 0.9928, Valid: 0.9855, Best: 0.9860\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 2.3923919200897217 | KNN Loss: 2.364497661590576 | CLS Loss: 0.027894319966435432\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 2.419682025909424 | KNN Loss: 2.3847672939300537 | CLS Loss: 0.034914687275886536\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 2.443430185317993 | KNN Loss: 2.4118125438690186 | CLS Loss: 0.031617697328329086\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 2.432774782180786 | KNN Loss: 2.387312412261963 | CLS Loss: 0.04546235129237175\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 2.3694653511047363 | KNN Loss: 2.355689764022827 | CLS Loss: 0.013775501400232315\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 2.469435930252075 | KNN Loss: 2.4374494552612305 | CLS Loss: 0.03198637068271637\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 2.4305508136749268 | KNN Loss: 2.392259359359741 | CLS Loss: 0.038291532546281815\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 2.4360039234161377 | KNN Loss: 2.3914027214050293 | CLS Loss: 0.0446011908352375\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 2.416536808013916 | KNN Loss: 2.3627429008483887 | CLS Loss: 0.053793858736753464\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 2.423973560333252 | KNN Loss: 2.411252737045288 | CLS Loss: 0.012720865197479725\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 2.4594030380249023 | KNN Loss: 2.4202773571014404 | CLS Loss: 0.03912579268217087\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 2.421480655670166 | KNN Loss: 2.406109571456909 | CLS Loss: 0.01537102647125721\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 2.456845760345459 | KNN Loss: 2.4276340007781982 | CLS Loss: 0.02921186573803425\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 2.41042423248291 | KNN Loss: 2.386162281036377 | CLS Loss: 0.02426205947995186\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 2.430161952972412 | KNN Loss: 2.4058570861816406 | CLS Loss: 0.024304907768964767\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 2.3819992542266846 | KNN Loss: 2.3624343872070312 | CLS Loss: 0.01956481859087944\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 2.4002106189727783 | KNN Loss: 2.3673644065856934 | CLS Loss: 0.03284630551934242\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 2.4110379219055176 | KNN Loss: 2.395871877670288 | CLS Loss: 0.01516601350158453\n",
      "Epoch: 050, Loss: 2.4216, Train: 0.9916, Valid: 0.9852, Best: 0.9860\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 2.3971502780914307 | KNN Loss: 2.379507303237915 | CLS Loss: 0.01764301210641861\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 2.4278063774108887 | KNN Loss: 2.405747175216675 | CLS Loss: 0.022059131413698196\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 2.383526563644409 | KNN Loss: 2.360377311706543 | CLS Loss: 0.023149173706769943\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 2.403613805770874 | KNN Loss: 2.38364577293396 | CLS Loss: 0.019967960193753242\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 2.4056286811828613 | KNN Loss: 2.3725035190582275 | CLS Loss: 0.033125195652246475\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 2.401824712753296 | KNN Loss: 2.3789072036743164 | CLS Loss: 0.02291746810078621\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 2.415940284729004 | KNN Loss: 2.40000057220459 | CLS Loss: 0.015939759090542793\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 2.4658398628234863 | KNN Loss: 2.4366936683654785 | CLS Loss: 0.029146140441298485\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 2.4151861667633057 | KNN Loss: 2.401109218597412 | CLS Loss: 0.014076901599764824\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 2.394847869873047 | KNN Loss: 2.383145332336426 | CLS Loss: 0.011702525429427624\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 2.382605791091919 | KNN Loss: 2.374772071838379 | CLS Loss: 0.007833728566765785\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 2.4071218967437744 | KNN Loss: 2.396118640899658 | CLS Loss: 0.011003246530890465\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 2.4418892860412598 | KNN Loss: 2.4121975898742676 | CLS Loss: 0.02969173528254032\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 2.4196102619171143 | KNN Loss: 2.3992667198181152 | CLS Loss: 0.02034345455467701\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 2.4055368900299072 | KNN Loss: 2.3738274574279785 | CLS Loss: 0.031709522008895874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 2.385340452194214 | KNN Loss: 2.359915018081665 | CLS Loss: 0.025425374507904053\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 2.4093568325042725 | KNN Loss: 2.39463472366333 | CLS Loss: 0.014722065068781376\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 2.4576432704925537 | KNN Loss: 2.4137659072875977 | CLS Loss: 0.04387732595205307\n",
      "Epoch: 051, Loss: 2.4225, Train: 0.9937, Valid: 0.9859, Best: 0.9860\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 2.416010618209839 | KNN Loss: 2.3905551433563232 | CLS Loss: 0.025455553084611893\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 2.4474287033081055 | KNN Loss: 2.3864963054656982 | CLS Loss: 0.06093234196305275\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 2.411317825317383 | KNN Loss: 2.393038034439087 | CLS Loss: 0.018279794603586197\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 2.4189419746398926 | KNN Loss: 2.4055140018463135 | CLS Loss: 0.01342797465622425\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 2.4048092365264893 | KNN Loss: 2.3913791179656982 | CLS Loss: 0.013430137187242508\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 2.4130170345306396 | KNN Loss: 2.391735792160034 | CLS Loss: 0.021281246095895767\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 2.431886672973633 | KNN Loss: 2.4090442657470703 | CLS Loss: 0.022842440754175186\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 2.431861639022827 | KNN Loss: 2.421931266784668 | CLS Loss: 0.009930395521223545\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 2.419227123260498 | KNN Loss: 2.360532283782959 | CLS Loss: 0.05869491398334503\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 2.4444780349731445 | KNN Loss: 2.390035629272461 | CLS Loss: 0.05444240942597389\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 2.444046974182129 | KNN Loss: 2.390855312347412 | CLS Loss: 0.05319170653820038\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 2.3967647552490234 | KNN Loss: 2.385692834854126 | CLS Loss: 0.011071917600929737\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 2.440279960632324 | KNN Loss: 2.426445245742798 | CLS Loss: 0.013834799639880657\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 2.4071059226989746 | KNN Loss: 2.391725778579712 | CLS Loss: 0.015380039811134338\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 2.4431650638580322 | KNN Loss: 2.3913917541503906 | CLS Loss: 0.05177325755357742\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 2.425870418548584 | KNN Loss: 2.404184341430664 | CLS Loss: 0.021685991436243057\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 2.4071507453918457 | KNN Loss: 2.394740581512451 | CLS Loss: 0.012410086579620838\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 2.4874353408813477 | KNN Loss: 2.4258532524108887 | CLS Loss: 0.06158218905329704\n",
      "Epoch: 052, Loss: 2.4234, Train: 0.9913, Valid: 0.9848, Best: 0.9860\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 2.462881326675415 | KNN Loss: 2.4177916049957275 | CLS Loss: 0.045089829713106155\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 2.4578988552093506 | KNN Loss: 2.4245197772979736 | CLS Loss: 0.03337918594479561\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 2.4119017124176025 | KNN Loss: 2.3976333141326904 | CLS Loss: 0.014268404804170132\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 2.417387008666992 | KNN Loss: 2.3975682258605957 | CLS Loss: 0.019818715751171112\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 2.419908285140991 | KNN Loss: 2.3844947814941406 | CLS Loss: 0.03541341796517372\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 2.494163990020752 | KNN Loss: 2.4532058238983154 | CLS Loss: 0.04095809906721115\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 2.4275622367858887 | KNN Loss: 2.4063382148742676 | CLS Loss: 0.021224012598395348\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 2.394930124282837 | KNN Loss: 2.379146099090576 | CLS Loss: 0.015784000977873802\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 2.4165868759155273 | KNN Loss: 2.406576156616211 | CLS Loss: 0.010010793805122375\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 2.4353208541870117 | KNN Loss: 2.4141340255737305 | CLS Loss: 0.02118690125644207\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 2.369448661804199 | KNN Loss: 2.363600015640259 | CLS Loss: 0.005848763510584831\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 2.421661376953125 | KNN Loss: 2.388043165206909 | CLS Loss: 0.03361830115318298\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 2.4194116592407227 | KNN Loss: 2.394605875015259 | CLS Loss: 0.024805741384625435\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 2.431544780731201 | KNN Loss: 2.413189172744751 | CLS Loss: 0.018355654552578926\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 2.428100347518921 | KNN Loss: 2.3993968963623047 | CLS Loss: 0.028703337535262108\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 2.394540548324585 | KNN Loss: 2.377927541732788 | CLS Loss: 0.016613014042377472\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 2.4102425575256348 | KNN Loss: 2.383239507675171 | CLS Loss: 0.027003077790141106\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 2.427210569381714 | KNN Loss: 2.3972532749176025 | CLS Loss: 0.02995738573372364\n",
      "Epoch: 053, Loss: 2.4194, Train: 0.9914, Valid: 0.9842, Best: 0.9860\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 2.4166834354400635 | KNN Loss: 2.394545793533325 | CLS Loss: 0.022137658670544624\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 2.3790040016174316 | KNN Loss: 2.3681418895721436 | CLS Loss: 0.010862056165933609\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 2.417017698287964 | KNN Loss: 2.386406183242798 | CLS Loss: 0.030611490830779076\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 2.400416135787964 | KNN Loss: 2.369004726409912 | CLS Loss: 0.03141145035624504\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 2.4152169227600098 | KNN Loss: 2.389395236968994 | CLS Loss: 0.025821685791015625\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 2.4569432735443115 | KNN Loss: 2.440258264541626 | CLS Loss: 0.0166851244866848\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 2.4431121349334717 | KNN Loss: 2.419349431991577 | CLS Loss: 0.023762686178088188\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 2.4511795043945312 | KNN Loss: 2.4179396629333496 | CLS Loss: 0.03323991969227791\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 2.4085261821746826 | KNN Loss: 2.390242576599121 | CLS Loss: 0.01828363910317421\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 2.4346795082092285 | KNN Loss: 2.4158432483673096 | CLS Loss: 0.018836142495274544\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 2.4725749492645264 | KNN Loss: 2.4401285648345947 | CLS Loss: 0.03244645148515701\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 2.4313247203826904 | KNN Loss: 2.3981008529663086 | CLS Loss: 0.03322387859225273\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 2.4509429931640625 | KNN Loss: 2.4009759426116943 | CLS Loss: 0.04996709153056145\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 2.3925838470458984 | KNN Loss: 2.3628320693969727 | CLS Loss: 0.02975188009440899\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 2.432389497756958 | KNN Loss: 2.3880319595336914 | CLS Loss: 0.04435761272907257\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 2.4060118198394775 | KNN Loss: 2.3987483978271484 | CLS Loss: 0.007263525389134884\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 2.409153699874878 | KNN Loss: 2.3834967613220215 | CLS Loss: 0.02565699629485607\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 2.421952486038208 | KNN Loss: 2.3909640312194824 | CLS Loss: 0.030988503247499466\n",
      "Epoch: 054, Loss: 2.4216, Train: 0.9939, Valid: 0.9863, Best: 0.9863\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 2.393233060836792 | KNN Loss: 2.3629074096679688 | CLS Loss: 0.030325638130307198\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 2.4514238834381104 | KNN Loss: 2.419677495956421 | CLS Loss: 0.03174629434943199\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 2.431373357772827 | KNN Loss: 2.414517641067505 | CLS Loss: 0.01685583032667637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 2.424492359161377 | KNN Loss: 2.3797924518585205 | CLS Loss: 0.044699911028146744\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 2.436307907104492 | KNN Loss: 2.3976376056671143 | CLS Loss: 0.03867029771208763\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 2.4385111331939697 | KNN Loss: 2.4099462032318115 | CLS Loss: 0.028564922511577606\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 2.4468417167663574 | KNN Loss: 2.4197678565979004 | CLS Loss: 0.027073752135038376\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 2.4102749824523926 | KNN Loss: 2.388718366622925 | CLS Loss: 0.02155664749443531\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 2.425039052963257 | KNN Loss: 2.4102883338928223 | CLS Loss: 0.014750654809176922\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 2.4437363147735596 | KNN Loss: 2.4171199798583984 | CLS Loss: 0.026616238057613373\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 2.4503867626190186 | KNN Loss: 2.4042468070983887 | CLS Loss: 0.04613989591598511\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 2.3833837509155273 | KNN Loss: 2.3726017475128174 | CLS Loss: 0.010781965218484402\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 2.3789656162261963 | KNN Loss: 2.3379979133605957 | CLS Loss: 0.04096777364611626\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 2.446253538131714 | KNN Loss: 2.433535575866699 | CLS Loss: 0.012718024663627148\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 2.3768417835235596 | KNN Loss: 2.3642120361328125 | CLS Loss: 0.012629701755940914\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 2.4208736419677734 | KNN Loss: 2.390018939971924 | CLS Loss: 0.030854802578687668\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 2.4067256450653076 | KNN Loss: 2.3760406970977783 | CLS Loss: 0.030684858560562134\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 2.4032225608825684 | KNN Loss: 2.3917996883392334 | CLS Loss: 0.011422867886722088\n",
      "Epoch: 055, Loss: 2.4257, Train: 0.9935, Valid: 0.9864, Best: 0.9864\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 2.401318311691284 | KNN Loss: 2.3982467651367188 | CLS Loss: 0.0030714375898241997\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 2.4226183891296387 | KNN Loss: 2.385474681854248 | CLS Loss: 0.037143733352422714\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 2.4187541007995605 | KNN Loss: 2.398899793624878 | CLS Loss: 0.019854409620165825\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 2.403766632080078 | KNN Loss: 2.3825435638427734 | CLS Loss: 0.021222976967692375\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 2.4360249042510986 | KNN Loss: 2.413857936859131 | CLS Loss: 0.02216704562306404\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 2.3695032596588135 | KNN Loss: 2.351893424987793 | CLS Loss: 0.017609847709536552\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 2.432800531387329 | KNN Loss: 2.408102512359619 | CLS Loss: 0.024697931483387947\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 2.43612003326416 | KNN Loss: 2.414273500442505 | CLS Loss: 0.021846434101462364\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 2.400127649307251 | KNN Loss: 2.3774096965789795 | CLS Loss: 0.022718051448464394\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 2.369442939758301 | KNN Loss: 2.35728120803833 | CLS Loss: 0.012161723338067532\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 2.4462594985961914 | KNN Loss: 2.43148136138916 | CLS Loss: 0.014778110198676586\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 2.4559192657470703 | KNN Loss: 2.418003559112549 | CLS Loss: 0.037915706634521484\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 2.415170669555664 | KNN Loss: 2.4018101692199707 | CLS Loss: 0.013360438868403435\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 2.4115729331970215 | KNN Loss: 2.39666748046875 | CLS Loss: 0.014905378222465515\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 2.44207501411438 | KNN Loss: 2.4087672233581543 | CLS Loss: 0.03330772742629051\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 2.4377501010894775 | KNN Loss: 2.421109437942505 | CLS Loss: 0.016640679910779\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 2.43259334564209 | KNN Loss: 2.4178006649017334 | CLS Loss: 0.014792770147323608\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 2.4137821197509766 | KNN Loss: 2.3902947902679443 | CLS Loss: 0.023487411439418793\n",
      "Epoch: 056, Loss: 2.4189, Train: 0.9925, Valid: 0.9846, Best: 0.9864\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 2.432896375656128 | KNN Loss: 2.4164106845855713 | CLS Loss: 0.016485661268234253\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 2.412449359893799 | KNN Loss: 2.401364326477051 | CLS Loss: 0.01108495518565178\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 2.4078428745269775 | KNN Loss: 2.380934476852417 | CLS Loss: 0.026908457279205322\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 2.4488372802734375 | KNN Loss: 2.4260733127593994 | CLS Loss: 0.022763943299651146\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 2.4040839672088623 | KNN Loss: 2.392550230026245 | CLS Loss: 0.011533618904650211\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 2.4315874576568604 | KNN Loss: 2.3947863578796387 | CLS Loss: 0.036801110953092575\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 2.4112472534179688 | KNN Loss: 2.392214298248291 | CLS Loss: 0.019032945856451988\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 2.4535651206970215 | KNN Loss: 2.4352781772613525 | CLS Loss: 0.018286971375346184\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 2.3775198459625244 | KNN Loss: 2.3736636638641357 | CLS Loss: 0.003856251249089837\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 2.4570136070251465 | KNN Loss: 2.426254987716675 | CLS Loss: 0.03075852058827877\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 2.436976909637451 | KNN Loss: 2.4155588150024414 | CLS Loss: 0.021418213844299316\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 2.4563050270080566 | KNN Loss: 2.4107720851898193 | CLS Loss: 0.045533016324043274\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 2.4243850708007812 | KNN Loss: 2.382805585861206 | CLS Loss: 0.04157959297299385\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 2.38926100730896 | KNN Loss: 2.3498401641845703 | CLS Loss: 0.039420899003744125\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 2.4104132652282715 | KNN Loss: 2.394744634628296 | CLS Loss: 0.01566867157816887\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 2.42638897895813 | KNN Loss: 2.399306297302246 | CLS Loss: 0.02708260528743267\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 2.4208292961120605 | KNN Loss: 2.389000654220581 | CLS Loss: 0.031828537583351135\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 2.4443094730377197 | KNN Loss: 2.4084293842315674 | CLS Loss: 0.03588007763028145\n",
      "Epoch: 057, Loss: 2.4165, Train: 0.9931, Valid: 0.9864, Best: 0.9864\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 2.449223518371582 | KNN Loss: 2.4123594760894775 | CLS Loss: 0.036864131689071655\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 2.431713342666626 | KNN Loss: 2.410200834274292 | CLS Loss: 0.021512525156140327\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 2.411799669265747 | KNN Loss: 2.368170976638794 | CLS Loss: 0.04362872987985611\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 2.4279661178588867 | KNN Loss: 2.415895462036133 | CLS Loss: 0.01207070704549551\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 2.4224588871002197 | KNN Loss: 2.4094290733337402 | CLS Loss: 0.013029771856963634\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 2.4089670181274414 | KNN Loss: 2.377592086791992 | CLS Loss: 0.03137494623661041\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 2.4371514320373535 | KNN Loss: 2.402863025665283 | CLS Loss: 0.034288328140974045\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 2.43508243560791 | KNN Loss: 2.4107143878936768 | CLS Loss: 0.024368155747652054\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 2.430640935897827 | KNN Loss: 2.4131555557250977 | CLS Loss: 0.017485352233052254\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 2.4086341857910156 | KNN Loss: 2.38006329536438 | CLS Loss: 0.028570855036377907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 2.443161964416504 | KNN Loss: 2.4257256984710693 | CLS Loss: 0.017436208203434944\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 2.4094314575195312 | KNN Loss: 2.37402606010437 | CLS Loss: 0.035405367612838745\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 2.4204819202423096 | KNN Loss: 2.3981552124023438 | CLS Loss: 0.02232675813138485\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 2.433419942855835 | KNN Loss: 2.3967061042785645 | CLS Loss: 0.03671391308307648\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 2.393270969390869 | KNN Loss: 2.379490852355957 | CLS Loss: 0.013780014589428902\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 2.4027881622314453 | KNN Loss: 2.393852710723877 | CLS Loss: 0.008935380727052689\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 2.462623357772827 | KNN Loss: 2.447075366973877 | CLS Loss: 0.015547892078757286\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 2.43915057182312 | KNN Loss: 2.403683662414551 | CLS Loss: 0.03546702116727829\n",
      "Epoch: 058, Loss: 2.4226, Train: 0.9937, Valid: 0.9860, Best: 0.9864\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 2.4030447006225586 | KNN Loss: 2.394174575805664 | CLS Loss: 0.008870238438248634\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 2.4333548545837402 | KNN Loss: 2.411726236343384 | CLS Loss: 0.021628722548484802\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 2.3952138423919678 | KNN Loss: 2.376448631286621 | CLS Loss: 0.01876530982553959\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 2.3933160305023193 | KNN Loss: 2.3805975914001465 | CLS Loss: 0.012718557380139828\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 2.414344072341919 | KNN Loss: 2.395892381668091 | CLS Loss: 0.018451601266860962\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 2.414034128189087 | KNN Loss: 2.405794620513916 | CLS Loss: 0.008239543996751308\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 2.4026801586151123 | KNN Loss: 2.3768956661224365 | CLS Loss: 0.025784414261579514\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 2.388068914413452 | KNN Loss: 2.36592435836792 | CLS Loss: 0.02214464172720909\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 2.370199680328369 | KNN Loss: 2.3530585765838623 | CLS Loss: 0.017141206189990044\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 2.4332737922668457 | KNN Loss: 2.403796672821045 | CLS Loss: 0.029477067291736603\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 2.3961050510406494 | KNN Loss: 2.3666553497314453 | CLS Loss: 0.029449619352817535\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 2.4293978214263916 | KNN Loss: 2.3944294452667236 | CLS Loss: 0.03496840223670006\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 2.458402156829834 | KNN Loss: 2.4375221729278564 | CLS Loss: 0.020879941061139107\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 2.3936750888824463 | KNN Loss: 2.3580400943756104 | CLS Loss: 0.03563510999083519\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 2.418564796447754 | KNN Loss: 2.395704507827759 | CLS Loss: 0.022860193625092506\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 2.4091601371765137 | KNN Loss: 2.364539861679077 | CLS Loss: 0.044620245695114136\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 2.4520695209503174 | KNN Loss: 2.423541784286499 | CLS Loss: 0.02852773852646351\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 2.413879632949829 | KNN Loss: 2.398036003112793 | CLS Loss: 0.015843674540519714\n",
      "Epoch: 059, Loss: 2.4163, Train: 0.9939, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 2.410597562789917 | KNN Loss: 2.3942384719848633 | CLS Loss: 0.016359062865376472\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 2.423650026321411 | KNN Loss: 2.3787708282470703 | CLS Loss: 0.04487930238246918\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 2.435204029083252 | KNN Loss: 2.4097228050231934 | CLS Loss: 0.025481248274445534\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 2.3625102043151855 | KNN Loss: 2.34847092628479 | CLS Loss: 0.014039319939911366\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 2.389540433883667 | KNN Loss: 2.3646445274353027 | CLS Loss: 0.024895910173654556\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 2.410672903060913 | KNN Loss: 2.389300584793091 | CLS Loss: 0.021372264251112938\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 2.4625964164733887 | KNN Loss: 2.4333176612854004 | CLS Loss: 0.029278745874762535\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 2.4053823947906494 | KNN Loss: 2.3826873302459717 | CLS Loss: 0.022695010527968407\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 2.382380723953247 | KNN Loss: 2.3600008487701416 | CLS Loss: 0.022379809990525246\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 2.458261251449585 | KNN Loss: 2.421823024749756 | CLS Loss: 0.0364382229745388\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 2.4524145126342773 | KNN Loss: 2.428415060043335 | CLS Loss: 0.023999569937586784\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 2.4037728309631348 | KNN Loss: 2.373183250427246 | CLS Loss: 0.030589591711759567\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 2.4132256507873535 | KNN Loss: 2.3979811668395996 | CLS Loss: 0.01524440385401249\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 2.393021821975708 | KNN Loss: 2.3866028785705566 | CLS Loss: 0.006419049575924873\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 2.429276704788208 | KNN Loss: 2.411590576171875 | CLS Loss: 0.017686136066913605\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 2.3851609230041504 | KNN Loss: 2.372481346130371 | CLS Loss: 0.012679469771683216\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 2.3967249393463135 | KNN Loss: 2.3663926124572754 | CLS Loss: 0.030332259833812714\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 2.418391227722168 | KNN Loss: 2.398608922958374 | CLS Loss: 0.01978232152760029\n",
      "Epoch: 060, Loss: 2.4143, Train: 0.9938, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 2.4043166637420654 | KNN Loss: 2.379396915435791 | CLS Loss: 0.024919778108596802\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 2.3936192989349365 | KNN Loss: 2.387749195098877 | CLS Loss: 0.005870029330253601\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 2.3899800777435303 | KNN Loss: 2.3838729858398438 | CLS Loss: 0.006107207853347063\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 2.385664463043213 | KNN Loss: 2.3803417682647705 | CLS Loss: 0.005322649143636227\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 2.4228336811065674 | KNN Loss: 2.4053356647491455 | CLS Loss: 0.017498020082712173\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 2.466374635696411 | KNN Loss: 2.4441652297973633 | CLS Loss: 0.022209294140338898\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 2.3915581703186035 | KNN Loss: 2.386857748031616 | CLS Loss: 0.004700399469584227\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 2.4072628021240234 | KNN Loss: 2.397381544113159 | CLS Loss: 0.009881161153316498\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 2.4639408588409424 | KNN Loss: 2.4229772090911865 | CLS Loss: 0.04096364974975586\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 2.4857900142669678 | KNN Loss: 2.4450864791870117 | CLS Loss: 0.040703482925891876\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 2.3788416385650635 | KNN Loss: 2.3472704887390137 | CLS Loss: 0.031571198254823685\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 2.3974835872650146 | KNN Loss: 2.3878889083862305 | CLS Loss: 0.009594560600817204\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 2.396869659423828 | KNN Loss: 2.3870415687561035 | CLS Loss: 0.009828190319240093\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 2.3895328044891357 | KNN Loss: 2.3690896034240723 | CLS Loss: 0.020443206652998924\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 2.450059652328491 | KNN Loss: 2.431349039077759 | CLS Loss: 0.01871059648692608\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 2.414170742034912 | KNN Loss: 2.386336326599121 | CLS Loss: 0.02783431112766266\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 2.4239630699157715 | KNN Loss: 2.4063055515289307 | CLS Loss: 0.017657499760389328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 2.4484915733337402 | KNN Loss: 2.433476448059082 | CLS Loss: 0.015015038661658764\n",
      "Epoch: 061, Loss: 2.4163, Train: 0.9938, Valid: 0.9863, Best: 0.9866\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 2.3923816680908203 | KNN Loss: 2.380629062652588 | CLS Loss: 0.011752615682780743\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 2.400252342224121 | KNN Loss: 2.3560538291931152 | CLS Loss: 0.04419856145977974\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 2.4265213012695312 | KNN Loss: 2.4142675399780273 | CLS Loss: 0.012253833934664726\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 2.3598058223724365 | KNN Loss: 2.348642110824585 | CLS Loss: 0.011163600720465183\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 2.3771982192993164 | KNN Loss: 2.3567731380462646 | CLS Loss: 0.020425181835889816\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 2.4069948196411133 | KNN Loss: 2.3843259811401367 | CLS Loss: 0.022668899968266487\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 2.410475730895996 | KNN Loss: 2.3981072902679443 | CLS Loss: 0.012368516065180302\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 2.4496777057647705 | KNN Loss: 2.407470226287842 | CLS Loss: 0.042207375168800354\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 2.422794818878174 | KNN Loss: 2.406602621078491 | CLS Loss: 0.01619209535419941\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 2.4174513816833496 | KNN Loss: 2.3870277404785156 | CLS Loss: 0.030423689633607864\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 2.4158453941345215 | KNN Loss: 2.3912270069122314 | CLS Loss: 0.024618497118353844\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 2.4059946537017822 | KNN Loss: 2.3912224769592285 | CLS Loss: 0.014772173017263412\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 2.4361536502838135 | KNN Loss: 2.3978216648101807 | CLS Loss: 0.0383320078253746\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 2.423497438430786 | KNN Loss: 2.3839316368103027 | CLS Loss: 0.039565861225128174\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 2.3769454956054688 | KNN Loss: 2.359468460083008 | CLS Loss: 0.017476964741945267\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 2.4140169620513916 | KNN Loss: 2.3941152095794678 | CLS Loss: 0.019901851192116737\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 2.431629180908203 | KNN Loss: 2.396726608276367 | CLS Loss: 0.03490246832370758\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 2.390530824661255 | KNN Loss: 2.3670036792755127 | CLS Loss: 0.02352725900709629\n",
      "Epoch: 062, Loss: 2.4134, Train: 0.9941, Valid: 0.9855, Best: 0.9866\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 2.410893201828003 | KNN Loss: 2.3958652019500732 | CLS Loss: 0.01502800639718771\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 2.425583839416504 | KNN Loss: 2.407343864440918 | CLS Loss: 0.01823999173939228\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 2.4534270763397217 | KNN Loss: 2.4177584648132324 | CLS Loss: 0.03566872328519821\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 2.427948236465454 | KNN Loss: 2.401066541671753 | CLS Loss: 0.026881765574216843\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 2.4213836193084717 | KNN Loss: 2.398310422897339 | CLS Loss: 0.02307317592203617\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 2.4218902587890625 | KNN Loss: 2.3998119831085205 | CLS Loss: 0.02207837626338005\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 2.384882926940918 | KNN Loss: 2.3746066093444824 | CLS Loss: 0.01027633436024189\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 2.3854422569274902 | KNN Loss: 2.367098093032837 | CLS Loss: 0.0183442123234272\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 2.408634662628174 | KNN Loss: 2.3907241821289062 | CLS Loss: 0.0179105494171381\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 2.398475408554077 | KNN Loss: 2.3838181495666504 | CLS Loss: 0.01465725339949131\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 2.398930788040161 | KNN Loss: 2.3818533420562744 | CLS Loss: 0.017077403143048286\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 2.4238922595977783 | KNN Loss: 2.389408826828003 | CLS Loss: 0.034483347088098526\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 2.443976640701294 | KNN Loss: 2.4298572540283203 | CLS Loss: 0.014119395986199379\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 2.4266228675842285 | KNN Loss: 2.4128661155700684 | CLS Loss: 0.013756650499999523\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 2.4010708332061768 | KNN Loss: 2.3938992023468018 | CLS Loss: 0.007171529810875654\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 2.431868314743042 | KNN Loss: 2.396247386932373 | CLS Loss: 0.03562101349234581\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 2.4342892169952393 | KNN Loss: 2.4204471111297607 | CLS Loss: 0.013842201791703701\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 2.4502079486846924 | KNN Loss: 2.424114227294922 | CLS Loss: 0.0260937437415123\n",
      "Epoch: 063, Loss: 2.4134, Train: 0.9949, Valid: 0.9870, Best: 0.9870\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 2.4608616828918457 | KNN Loss: 2.4257402420043945 | CLS Loss: 0.035121362656354904\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 2.432502508163452 | KNN Loss: 2.4186153411865234 | CLS Loss: 0.013887202367186546\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 2.4150073528289795 | KNN Loss: 2.4041576385498047 | CLS Loss: 0.01084981020539999\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 2.4640467166900635 | KNN Loss: 2.435598611831665 | CLS Loss: 0.028448063880205154\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 2.365412950515747 | KNN Loss: 2.3618555068969727 | CLS Loss: 0.003557539312168956\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 2.420804023742676 | KNN Loss: 2.4054951667785645 | CLS Loss: 0.01530891191214323\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 2.4276366233825684 | KNN Loss: 2.405569314956665 | CLS Loss: 0.022067241370677948\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 2.4220480918884277 | KNN Loss: 2.4020609855651855 | CLS Loss: 0.01998719945549965\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 2.469559669494629 | KNN Loss: 2.407494068145752 | CLS Loss: 0.06206550821661949\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 2.426483631134033 | KNN Loss: 2.3999345302581787 | CLS Loss: 0.026549160480499268\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 2.403040885925293 | KNN Loss: 2.376494884490967 | CLS Loss: 0.026546087116003036\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 2.393357276916504 | KNN Loss: 2.383502244949341 | CLS Loss: 0.009855137206614017\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 2.370769739151001 | KNN Loss: 2.3571712970733643 | CLS Loss: 0.01359850075095892\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 2.436602830886841 | KNN Loss: 2.4133410453796387 | CLS Loss: 0.023261800408363342\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 2.4213385581970215 | KNN Loss: 2.403188467025757 | CLS Loss: 0.018150152638554573\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 2.3836634159088135 | KNN Loss: 2.366905689239502 | CLS Loss: 0.016757838428020477\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 2.4414944648742676 | KNN Loss: 2.4118809700012207 | CLS Loss: 0.029613539576530457\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 2.4261317253112793 | KNN Loss: 2.4107658863067627 | CLS Loss: 0.015365740284323692\n",
      "Epoch: 064, Loss: 2.4126, Train: 0.9923, Valid: 0.9854, Best: 0.9870\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 2.4073920249938965 | KNN Loss: 2.391798496246338 | CLS Loss: 0.015593464486300945\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 2.4281718730926514 | KNN Loss: 2.3919355869293213 | CLS Loss: 0.0362362265586853\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 2.4041638374328613 | KNN Loss: 2.390425682067871 | CLS Loss: 0.013738172128796577\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 2.385484457015991 | KNN Loss: 2.3668744564056396 | CLS Loss: 0.018610069528222084\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 2.388953924179077 | KNN Loss: 2.368105888366699 | CLS Loss: 0.020847972482442856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 2.408505916595459 | KNN Loss: 2.362030506134033 | CLS Loss: 0.04647543653845787\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 2.4002785682678223 | KNN Loss: 2.382356643676758 | CLS Loss: 0.01792190782725811\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 2.4258835315704346 | KNN Loss: 2.3888189792633057 | CLS Loss: 0.037064582109451294\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 2.410062074661255 | KNN Loss: 2.382854700088501 | CLS Loss: 0.027207354083657265\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 2.401031970977783 | KNN Loss: 2.3783507347106934 | CLS Loss: 0.022681163623929024\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 2.3490424156188965 | KNN Loss: 2.331092119216919 | CLS Loss: 0.017950186505913734\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 2.4045069217681885 | KNN Loss: 2.3863487243652344 | CLS Loss: 0.018158189952373505\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 2.3989577293395996 | KNN Loss: 2.379758596420288 | CLS Loss: 0.01919918693602085\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 2.382913589477539 | KNN Loss: 2.368680477142334 | CLS Loss: 0.014233071357011795\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 2.4093892574310303 | KNN Loss: 2.3917667865753174 | CLS Loss: 0.017622381448745728\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 2.417360544204712 | KNN Loss: 2.40393328666687 | CLS Loss: 0.013427245430648327\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 2.406322479248047 | KNN Loss: 2.4020354747772217 | CLS Loss: 0.004286901094019413\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 2.4188151359558105 | KNN Loss: 2.395324230194092 | CLS Loss: 0.023490965366363525\n",
      "Epoch: 065, Loss: 2.4128, Train: 0.9939, Valid: 0.9847, Best: 0.9870\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 2.419674873352051 | KNN Loss: 2.389813184738159 | CLS Loss: 0.02986171655356884\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 2.3848142623901367 | KNN Loss: 2.3706629276275635 | CLS Loss: 0.014151310548186302\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 2.3979153633117676 | KNN Loss: 2.375427722930908 | CLS Loss: 0.022487584501504898\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 2.4183297157287598 | KNN Loss: 2.408010482788086 | CLS Loss: 0.010319136083126068\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 2.4361443519592285 | KNN Loss: 2.4146814346313477 | CLS Loss: 0.021462956443428993\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 2.4355180263519287 | KNN Loss: 2.4027998447418213 | CLS Loss: 0.032718148082494736\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 2.4368996620178223 | KNN Loss: 2.4049532413482666 | CLS Loss: 0.031946346163749695\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 2.4716203212738037 | KNN Loss: 2.4534668922424316 | CLS Loss: 0.01815336011350155\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 2.459880828857422 | KNN Loss: 2.4256067276000977 | CLS Loss: 0.03427417576313019\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 2.391914129257202 | KNN Loss: 2.375058889389038 | CLS Loss: 0.016855251044034958\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 2.4100465774536133 | KNN Loss: 2.3990845680236816 | CLS Loss: 0.010961939580738544\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 2.4196178913116455 | KNN Loss: 2.393887519836426 | CLS Loss: 0.025730295106768608\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 2.402575731277466 | KNN Loss: 2.3916072845458984 | CLS Loss: 0.010968401096761227\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 2.4188740253448486 | KNN Loss: 2.3876237869262695 | CLS Loss: 0.0312502421438694\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 2.4360952377319336 | KNN Loss: 2.3893966674804688 | CLS Loss: 0.0466986820101738\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 2.400970935821533 | KNN Loss: 2.3814709186553955 | CLS Loss: 0.019499899819493294\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 2.396744966506958 | KNN Loss: 2.3778817653656006 | CLS Loss: 0.018863121047616005\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 2.3667407035827637 | KNN Loss: 2.3584299087524414 | CLS Loss: 0.008310836739838123\n",
      "Epoch: 066, Loss: 2.4139, Train: 0.9947, Valid: 0.9859, Best: 0.9870\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 2.3753857612609863 | KNN Loss: 2.368363380432129 | CLS Loss: 0.007022412959486246\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 2.403606653213501 | KNN Loss: 2.386251449584961 | CLS Loss: 0.017355170100927353\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 2.3922905921936035 | KNN Loss: 2.3605690002441406 | CLS Loss: 0.031721699982881546\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 2.403062105178833 | KNN Loss: 2.3874497413635254 | CLS Loss: 0.015612427145242691\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 2.406348466873169 | KNN Loss: 2.390759229660034 | CLS Loss: 0.01558913104236126\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 2.4081904888153076 | KNN Loss: 2.36932635307312 | CLS Loss: 0.038864221423864365\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 2.4163804054260254 | KNN Loss: 2.409822940826416 | CLS Loss: 0.006557501386851072\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 2.4457037448883057 | KNN Loss: 2.3881304264068604 | CLS Loss: 0.05757336691021919\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 2.3792738914489746 | KNN Loss: 2.362508773803711 | CLS Loss: 0.01676519587635994\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 2.383013963699341 | KNN Loss: 2.360666513442993 | CLS Loss: 0.02234749123454094\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 2.3979251384735107 | KNN Loss: 2.375138282775879 | CLS Loss: 0.02278689108788967\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 2.435634136199951 | KNN Loss: 2.392859935760498 | CLS Loss: 0.04277410730719566\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 2.3924217224121094 | KNN Loss: 2.3692612648010254 | CLS Loss: 0.02316048927605152\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 2.408527374267578 | KNN Loss: 2.3746650218963623 | CLS Loss: 0.033862292766571045\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 2.4191794395446777 | KNN Loss: 2.406282663345337 | CLS Loss: 0.012896847911179066\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 2.4102084636688232 | KNN Loss: 2.368260622024536 | CLS Loss: 0.04194780811667442\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 2.407447338104248 | KNN Loss: 2.382272243499756 | CLS Loss: 0.025175129994750023\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 2.4045002460479736 | KNN Loss: 2.376913070678711 | CLS Loss: 0.027587128803133965\n",
      "Epoch: 067, Loss: 2.4095, Train: 0.9951, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 2.399538040161133 | KNN Loss: 2.3912312984466553 | CLS Loss: 0.008306827396154404\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 2.3911924362182617 | KNN Loss: 2.373460054397583 | CLS Loss: 0.01773238368332386\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 2.434199810028076 | KNN Loss: 2.4158411026000977 | CLS Loss: 0.018358655273914337\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 2.4590706825256348 | KNN Loss: 2.415376663208008 | CLS Loss: 0.04369400069117546\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 2.4176652431488037 | KNN Loss: 2.3706889152526855 | CLS Loss: 0.04697643965482712\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 2.4127252101898193 | KNN Loss: 2.4028687477111816 | CLS Loss: 0.009856488555669785\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 2.3821165561676025 | KNN Loss: 2.3681411743164062 | CLS Loss: 0.013975411653518677\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 2.4147768020629883 | KNN Loss: 2.3864808082580566 | CLS Loss: 0.028295956552028656\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 2.4190943241119385 | KNN Loss: 2.4020769596099854 | CLS Loss: 0.017017383128404617\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 2.423393726348877 | KNN Loss: 2.396721839904785 | CLS Loss: 0.02667193114757538\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 2.4211621284484863 | KNN Loss: 2.4124295711517334 | CLS Loss: 0.008732497692108154\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 2.4190902709960938 | KNN Loss: 2.3823845386505127 | CLS Loss: 0.03670564666390419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 2.4230194091796875 | KNN Loss: 2.394366502761841 | CLS Loss: 0.028652790933847427\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 2.404181957244873 | KNN Loss: 2.3799145221710205 | CLS Loss: 0.024267427623271942\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 2.4208555221557617 | KNN Loss: 2.409362316131592 | CLS Loss: 0.011493168771266937\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 2.4084174633026123 | KNN Loss: 2.3685362339019775 | CLS Loss: 0.0398811511695385\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 2.4145121574401855 | KNN Loss: 2.4092984199523926 | CLS Loss: 0.005213804543018341\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 2.346195697784424 | KNN Loss: 2.3315963745117188 | CLS Loss: 0.014599375426769257\n",
      "Epoch: 068, Loss: 2.4145, Train: 0.9946, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 2.4166018962860107 | KNN Loss: 2.390693187713623 | CLS Loss: 0.025908783078193665\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 2.438632011413574 | KNN Loss: 2.4058837890625 | CLS Loss: 0.03274814039468765\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 2.3909504413604736 | KNN Loss: 2.3760106563568115 | CLS Loss: 0.014939901418983936\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 2.3972089290618896 | KNN Loss: 2.368360757827759 | CLS Loss: 0.02884816750884056\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 2.400665760040283 | KNN Loss: 2.3728270530700684 | CLS Loss: 0.02783859334886074\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 2.483898878097534 | KNN Loss: 2.4642770290374756 | CLS Loss: 0.019621847197413445\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 2.383526086807251 | KNN Loss: 2.378340005874634 | CLS Loss: 0.005186194088310003\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 2.3859682083129883 | KNN Loss: 2.3732779026031494 | CLS Loss: 0.012690262869000435\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 2.4095678329467773 | KNN Loss: 2.380481719970703 | CLS Loss: 0.029086023569107056\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 2.4489328861236572 | KNN Loss: 2.421496868133545 | CLS Loss: 0.02743607759475708\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 2.3841919898986816 | KNN Loss: 2.373655080795288 | CLS Loss: 0.01053701527416706\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 2.420877695083618 | KNN Loss: 2.4048337936401367 | CLS Loss: 0.016043880954384804\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 2.3787989616394043 | KNN Loss: 2.3714280128479004 | CLS Loss: 0.00737084960564971\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 2.40214467048645 | KNN Loss: 2.3867173194885254 | CLS Loss: 0.015427261590957642\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 2.4117648601531982 | KNN Loss: 2.3965160846710205 | CLS Loss: 0.015248780138790607\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 2.415452480316162 | KNN Loss: 2.4069440364837646 | CLS Loss: 0.008508424274623394\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 2.4799768924713135 | KNN Loss: 2.465479850769043 | CLS Loss: 0.014496932737529278\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 2.4424421787261963 | KNN Loss: 2.427934408187866 | CLS Loss: 0.014507805928587914\n",
      "Epoch: 069, Loss: 2.4156, Train: 0.9952, Valid: 0.9867, Best: 0.9870\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 2.385329008102417 | KNN Loss: 2.3561527729034424 | CLS Loss: 0.029176194220781326\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 2.404719829559326 | KNN Loss: 2.380949020385742 | CLS Loss: 0.02377086877822876\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 2.4192118644714355 | KNN Loss: 2.403383255004883 | CLS Loss: 0.015828557312488556\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 2.4386487007141113 | KNN Loss: 2.3867971897125244 | CLS Loss: 0.05185161158442497\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 2.3895275592803955 | KNN Loss: 2.373033285140991 | CLS Loss: 0.016494276002049446\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 2.4404067993164062 | KNN Loss: 2.4323959350585938 | CLS Loss: 0.00801096297800541\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 2.4110591411590576 | KNN Loss: 2.3959028720855713 | CLS Loss: 0.015156262554228306\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 2.4132325649261475 | KNN Loss: 2.4015848636627197 | CLS Loss: 0.011647684499621391\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 2.431748151779175 | KNN Loss: 2.423654556274414 | CLS Loss: 0.008093712851405144\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 2.4149932861328125 | KNN Loss: 2.3907546997070312 | CLS Loss: 0.02423860691487789\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 2.3892016410827637 | KNN Loss: 2.366837501525879 | CLS Loss: 0.022364074364304543\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 2.448140859603882 | KNN Loss: 2.4319801330566406 | CLS Loss: 0.016160832718014717\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 2.361582040786743 | KNN Loss: 2.3482446670532227 | CLS Loss: 0.013337473385035992\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 2.4218106269836426 | KNN Loss: 2.3820645809173584 | CLS Loss: 0.03974601998925209\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 2.447758436203003 | KNN Loss: 2.4049417972564697 | CLS Loss: 0.04281659796833992\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 2.447829246520996 | KNN Loss: 2.3984034061431885 | CLS Loss: 0.049425799399614334\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 2.431694507598877 | KNN Loss: 2.4065728187561035 | CLS Loss: 0.02512180432677269\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 2.3904170989990234 | KNN Loss: 2.3769521713256836 | CLS Loss: 0.013464890420436859\n",
      "Epoch: 070, Loss: 2.4134, Train: 0.9948, Valid: 0.9867, Best: 0.9870\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 2.4029884338378906 | KNN Loss: 2.384087562561035 | CLS Loss: 0.018900945782661438\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 2.4327099323272705 | KNN Loss: 2.4162838459014893 | CLS Loss: 0.016426149755716324\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 2.4064676761627197 | KNN Loss: 2.396052360534668 | CLS Loss: 0.010415272787213326\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 2.4097557067871094 | KNN Loss: 2.3839271068573 | CLS Loss: 0.025828665122389793\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 2.392507314682007 | KNN Loss: 2.3774349689483643 | CLS Loss: 0.015072330832481384\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 2.4264986515045166 | KNN Loss: 2.4058265686035156 | CLS Loss: 0.020671993494033813\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 2.392070770263672 | KNN Loss: 2.3686816692352295 | CLS Loss: 0.02338920347392559\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 2.397613525390625 | KNN Loss: 2.3853509426116943 | CLS Loss: 0.01226264052093029\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 2.4278531074523926 | KNN Loss: 2.388349771499634 | CLS Loss: 0.03950342535972595\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 2.43259334564209 | KNN Loss: 2.404081344604492 | CLS Loss: 0.028511883690953255\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 2.4104819297790527 | KNN Loss: 2.3720414638519287 | CLS Loss: 0.038440555334091187\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 2.3834526538848877 | KNN Loss: 2.371762990951538 | CLS Loss: 0.011689715087413788\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 2.40547513961792 | KNN Loss: 2.381197452545166 | CLS Loss: 0.02427765540778637\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 2.408628463745117 | KNN Loss: 2.3923306465148926 | CLS Loss: 0.01629793643951416\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 2.399322986602783 | KNN Loss: 2.36715030670166 | CLS Loss: 0.03217264637351036\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 2.414137125015259 | KNN Loss: 2.4043080806732178 | CLS Loss: 0.009828931652009487\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 2.4040284156799316 | KNN Loss: 2.3867135047912598 | CLS Loss: 0.017314907163381577\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 2.4527406692504883 | KNN Loss: 2.423640727996826 | CLS Loss: 0.029099924489855766\n",
      "Epoch: 071, Loss: 2.4133, Train: 0.9933, Valid: 0.9849, Best: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 2.368018865585327 | KNN Loss: 2.355069875717163 | CLS Loss: 0.012949004769325256\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 2.3890514373779297 | KNN Loss: 2.3738434314727783 | CLS Loss: 0.015208037570118904\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 2.387073278427124 | KNN Loss: 2.3728458881378174 | CLS Loss: 0.014227384701371193\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 2.3678743839263916 | KNN Loss: 2.3587167263031006 | CLS Loss: 0.009157653898000717\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 2.4119327068328857 | KNN Loss: 2.4028570652008057 | CLS Loss: 0.009075754322111607\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 2.39367938041687 | KNN Loss: 2.3858113288879395 | CLS Loss: 0.007867933250963688\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 2.423067569732666 | KNN Loss: 2.40354061126709 | CLS Loss: 0.019527047872543335\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 2.423534393310547 | KNN Loss: 2.392904758453369 | CLS Loss: 0.03062959760427475\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 2.428248167037964 | KNN Loss: 2.4127018451690674 | CLS Loss: 0.015546340495347977\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 2.450822591781616 | KNN Loss: 2.4292850494384766 | CLS Loss: 0.021537601947784424\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 2.3718340396881104 | KNN Loss: 2.364199638366699 | CLS Loss: 0.007634396199136972\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 2.440218448638916 | KNN Loss: 2.416450262069702 | CLS Loss: 0.0237681046128273\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 2.3718645572662354 | KNN Loss: 2.348370313644409 | CLS Loss: 0.023494157940149307\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 2.37627911567688 | KNN Loss: 2.3491032123565674 | CLS Loss: 0.027175968512892723\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 2.425800323486328 | KNN Loss: 2.4149668216705322 | CLS Loss: 0.010833533480763435\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 2.385737180709839 | KNN Loss: 2.3632445335388184 | CLS Loss: 0.022492559626698494\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 2.378389596939087 | KNN Loss: 2.363818407058716 | CLS Loss: 0.014571208506822586\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 2.4176716804504395 | KNN Loss: 2.399676561355591 | CLS Loss: 0.017995018512010574\n",
      "Epoch: 072, Loss: 2.4138, Train: 0.9950, Valid: 0.9866, Best: 0.9870\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 2.388843059539795 | KNN Loss: 2.381018877029419 | CLS Loss: 0.007824070751667023\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 2.3880040645599365 | KNN Loss: 2.375823974609375 | CLS Loss: 0.012180062010884285\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 2.408947229385376 | KNN Loss: 2.3941473960876465 | CLS Loss: 0.014799808152019978\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 2.443932294845581 | KNN Loss: 2.4405171871185303 | CLS Loss: 0.003415157785639167\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 2.4450430870056152 | KNN Loss: 2.4301393032073975 | CLS Loss: 0.014903740957379341\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 2.3937697410583496 | KNN Loss: 2.3833959102630615 | CLS Loss: 0.010373876430094242\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 2.4164416790008545 | KNN Loss: 2.396519184112549 | CLS Loss: 0.019922388717532158\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 2.4156229496002197 | KNN Loss: 2.392665147781372 | CLS Loss: 0.022957876324653625\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 2.3996059894561768 | KNN Loss: 2.384958267211914 | CLS Loss: 0.014647696167230606\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 2.4176342487335205 | KNN Loss: 2.4035146236419678 | CLS Loss: 0.014119644649326801\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 2.390414237976074 | KNN Loss: 2.3815817832946777 | CLS Loss: 0.008832519873976707\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 2.440532684326172 | KNN Loss: 2.4290127754211426 | CLS Loss: 0.011519862338900566\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 2.406122922897339 | KNN Loss: 2.3885862827301025 | CLS Loss: 0.017536645755171776\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 2.4028334617614746 | KNN Loss: 2.3843441009521484 | CLS Loss: 0.018489263951778412\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 2.4386491775512695 | KNN Loss: 2.423377275466919 | CLS Loss: 0.015271922573447227\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 2.444425582885742 | KNN Loss: 2.4307327270507812 | CLS Loss: 0.013692871667444706\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 2.373950481414795 | KNN Loss: 2.367079496383667 | CLS Loss: 0.006871006451547146\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 2.4045345783233643 | KNN Loss: 2.387293815612793 | CLS Loss: 0.017240816727280617\n",
      "Epoch: 073, Loss: 2.4114, Train: 0.9948, Valid: 0.9862, Best: 0.9870\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 2.420487880706787 | KNN Loss: 2.3991904258728027 | CLS Loss: 0.02129734307527542\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 2.4497859477996826 | KNN Loss: 2.438966989517212 | CLS Loss: 0.010818892158567905\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 2.4290597438812256 | KNN Loss: 2.414200782775879 | CLS Loss: 0.014858980663120747\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 2.422821521759033 | KNN Loss: 2.3850197792053223 | CLS Loss: 0.03780169039964676\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 2.393362522125244 | KNN Loss: 2.38045334815979 | CLS Loss: 0.012909164652228355\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 2.3891875743865967 | KNN Loss: 2.378479242324829 | CLS Loss: 0.010708299465477467\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 2.3948264122009277 | KNN Loss: 2.373706102371216 | CLS Loss: 0.02112039364874363\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 2.4376091957092285 | KNN Loss: 2.3870277404785156 | CLS Loss: 0.050581421703100204\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 2.384385824203491 | KNN Loss: 2.3759422302246094 | CLS Loss: 0.008443569764494896\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 2.408271074295044 | KNN Loss: 2.3797099590301514 | CLS Loss: 0.02856115996837616\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 2.420069456100464 | KNN Loss: 2.4047293663024902 | CLS Loss: 0.015340163372457027\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 2.4252192974090576 | KNN Loss: 2.4206929206848145 | CLS Loss: 0.004526482429355383\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 2.3965165615081787 | KNN Loss: 2.373711109161377 | CLS Loss: 0.022805489599704742\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 2.4126086235046387 | KNN Loss: 2.3996269702911377 | CLS Loss: 0.012981625273823738\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 2.4336841106414795 | KNN Loss: 2.417358636856079 | CLS Loss: 0.016325363889336586\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 2.43088960647583 | KNN Loss: 2.404527425765991 | CLS Loss: 0.026362089440226555\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 2.40907883644104 | KNN Loss: 2.390139579772949 | CLS Loss: 0.018939178436994553\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 2.4592788219451904 | KNN Loss: 2.432245969772339 | CLS Loss: 0.027032939717173576\n",
      "Epoch: 074, Loss: 2.4125, Train: 0.9951, Valid: 0.9857, Best: 0.9870\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 2.41032338142395 | KNN Loss: 2.399674654006958 | CLS Loss: 0.010648807510733604\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 2.459643602371216 | KNN Loss: 2.443810224533081 | CLS Loss: 0.015833333134651184\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 2.4132039546966553 | KNN Loss: 2.3987340927124023 | CLS Loss: 0.014469927176833153\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 2.3879213333129883 | KNN Loss: 2.3753418922424316 | CLS Loss: 0.012579369358718395\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 2.4314944744110107 | KNN Loss: 2.408123016357422 | CLS Loss: 0.023371467366814613\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 2.3910939693450928 | KNN Loss: 2.379072427749634 | CLS Loss: 0.01202149037271738\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 2.405539035797119 | KNN Loss: 2.385281801223755 | CLS Loss: 0.02025715447962284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 2.4620580673217773 | KNN Loss: 2.449739456176758 | CLS Loss: 0.012318691238760948\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 2.387554168701172 | KNN Loss: 2.379441738128662 | CLS Loss: 0.008112340234220028\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 2.411417245864868 | KNN Loss: 2.3929836750030518 | CLS Loss: 0.018433624878525734\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 2.4166247844696045 | KNN Loss: 2.403425693511963 | CLS Loss: 0.013199173845350742\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 2.420776128768921 | KNN Loss: 2.395629644393921 | CLS Loss: 0.02514658309519291\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 2.4043240547180176 | KNN Loss: 2.3859939575195312 | CLS Loss: 0.01833019219338894\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 2.447852373123169 | KNN Loss: 2.4210171699523926 | CLS Loss: 0.026835277676582336\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 2.4298691749572754 | KNN Loss: 2.3971850872039795 | CLS Loss: 0.03268399089574814\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 2.452881336212158 | KNN Loss: 2.429593563079834 | CLS Loss: 0.023287774994969368\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 2.4272124767303467 | KNN Loss: 2.4109787940979004 | CLS Loss: 0.016233764588832855\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 2.4177112579345703 | KNN Loss: 2.392965793609619 | CLS Loss: 0.024745527654886246\n",
      "Epoch: 075, Loss: 2.4133, Train: 0.9953, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 2.3960673809051514 | KNN Loss: 2.3721251487731934 | CLS Loss: 0.023942220956087112\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 2.3712637424468994 | KNN Loss: 2.354857921600342 | CLS Loss: 0.01640593819320202\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 2.4022552967071533 | KNN Loss: 2.3758583068847656 | CLS Loss: 0.0263970997184515\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 2.3867666721343994 | KNN Loss: 2.3750598430633545 | CLS Loss: 0.011706908233463764\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 2.419009208679199 | KNN Loss: 2.404489517211914 | CLS Loss: 0.014519795775413513\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 2.4150612354278564 | KNN Loss: 2.407345771789551 | CLS Loss: 0.007715464569628239\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 2.3863236904144287 | KNN Loss: 2.3620073795318604 | CLS Loss: 0.024316243827342987\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 2.417616367340088 | KNN Loss: 2.397386074066162 | CLS Loss: 0.020230315625667572\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 2.409550905227661 | KNN Loss: 2.3807835578918457 | CLS Loss: 0.0287674181163311\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 2.4006195068359375 | KNN Loss: 2.344785213470459 | CLS Loss: 0.05583436042070389\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 2.3744957447052 | KNN Loss: 2.3646302223205566 | CLS Loss: 0.00986554753035307\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 2.4182794094085693 | KNN Loss: 2.3827731609344482 | CLS Loss: 0.0355062335729599\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 2.417261838912964 | KNN Loss: 2.3960320949554443 | CLS Loss: 0.021229682490229607\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 2.435014009475708 | KNN Loss: 2.415194272994995 | CLS Loss: 0.019819805398583412\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 2.4127464294433594 | KNN Loss: 2.3743674755096436 | CLS Loss: 0.03837892785668373\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 2.4536569118499756 | KNN Loss: 2.42246150970459 | CLS Loss: 0.03119535744190216\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 2.418722152709961 | KNN Loss: 2.4004878997802734 | CLS Loss: 0.018234174698591232\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 2.4745407104492188 | KNN Loss: 2.422377109527588 | CLS Loss: 0.052163515239953995\n",
      "Epoch: 076, Loss: 2.4107, Train: 0.9945, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 2.3662359714508057 | KNN Loss: 2.3527591228485107 | CLS Loss: 0.013476946391165257\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 2.388859748840332 | KNN Loss: 2.3691306114196777 | CLS Loss: 0.019729185849428177\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 2.411642074584961 | KNN Loss: 2.4060959815979004 | CLS Loss: 0.005545978434383869\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 2.3820159435272217 | KNN Loss: 2.3619422912597656 | CLS Loss: 0.02007373422384262\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 2.449753761291504 | KNN Loss: 2.433746099472046 | CLS Loss: 0.016007734462618828\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 2.4204037189483643 | KNN Loss: 2.3971478939056396 | CLS Loss: 0.02325591817498207\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 2.4745755195617676 | KNN Loss: 2.42061710357666 | CLS Loss: 0.0539584718644619\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 2.4058165550231934 | KNN Loss: 2.401496410369873 | CLS Loss: 0.004320244770497084\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 2.41660475730896 | KNN Loss: 2.4015495777130127 | CLS Loss: 0.015055115334689617\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 2.417588710784912 | KNN Loss: 2.402386426925659 | CLS Loss: 0.015202298760414124\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 2.366859197616577 | KNN Loss: 2.35408878326416 | CLS Loss: 0.012770389206707478\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 2.402665615081787 | KNN Loss: 2.391770601272583 | CLS Loss: 0.010895115323364735\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 2.4005095958709717 | KNN Loss: 2.3760876655578613 | CLS Loss: 0.024421855807304382\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 2.388031482696533 | KNN Loss: 2.374234199523926 | CLS Loss: 0.013797369785606861\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 2.4183709621429443 | KNN Loss: 2.4142916202545166 | CLS Loss: 0.00407929765060544\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 2.41015625 | KNN Loss: 2.399165153503418 | CLS Loss: 0.010991092771291733\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 2.4332573413848877 | KNN Loss: 2.393022060394287 | CLS Loss: 0.04023531451821327\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 2.3797261714935303 | KNN Loss: 2.3703527450561523 | CLS Loss: 0.009373486042022705\n",
      "Epoch: 077, Loss: 2.4126, Train: 0.9947, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 2.3861443996429443 | KNN Loss: 2.3698437213897705 | CLS Loss: 0.016300655901432037\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 2.4077038764953613 | KNN Loss: 2.3961451053619385 | CLS Loss: 0.011558677069842815\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 2.371241569519043 | KNN Loss: 2.3619654178619385 | CLS Loss: 0.009276113472878933\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 2.392526865005493 | KNN Loss: 2.3829550743103027 | CLS Loss: 0.0095718614757061\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 2.4418296813964844 | KNN Loss: 2.421142578125 | CLS Loss: 0.020687101408839226\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 2.407320499420166 | KNN Loss: 2.3872811794281006 | CLS Loss: 0.020039401948451996\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 2.3759982585906982 | KNN Loss: 2.36480712890625 | CLS Loss: 0.011191056109964848\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 2.3939461708068848 | KNN Loss: 2.3812410831451416 | CLS Loss: 0.012705189175903797\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 2.4156033992767334 | KNN Loss: 2.399811267852783 | CLS Loss: 0.01579222083091736\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 2.4053032398223877 | KNN Loss: 2.3846352100372314 | CLS Loss: 0.020667968317866325\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 2.4014766216278076 | KNN Loss: 2.3926467895507812 | CLS Loss: 0.008829724974930286\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 2.3934545516967773 | KNN Loss: 2.379801034927368 | CLS Loss: 0.013653572648763657\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 2.3835227489471436 | KNN Loss: 2.3651185035705566 | CLS Loss: 0.018404202535748482\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 2.4406282901763916 | KNN Loss: 2.424034357070923 | CLS Loss: 0.01659395545721054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 2.3851075172424316 | KNN Loss: 2.3683154582977295 | CLS Loss: 0.016792094334959984\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 2.3794193267822266 | KNN Loss: 2.3760485649108887 | CLS Loss: 0.003370713908225298\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 2.4055888652801514 | KNN Loss: 2.4018564224243164 | CLS Loss: 0.0037324409931898117\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 2.376258134841919 | KNN Loss: 2.35781192779541 | CLS Loss: 0.018446089699864388\n",
      "Epoch: 078, Loss: 2.4069, Train: 0.9954, Valid: 0.9861, Best: 0.9870\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 2.3918685913085938 | KNN Loss: 2.376077890396118 | CLS Loss: 0.015790794044733047\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 2.381571054458618 | KNN Loss: 2.3624930381774902 | CLS Loss: 0.019078057259321213\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 2.37876296043396 | KNN Loss: 2.374074935913086 | CLS Loss: 0.004688005894422531\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 2.427130699157715 | KNN Loss: 2.4209420680999756 | CLS Loss: 0.006188674364238977\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 2.3663599491119385 | KNN Loss: 2.3516225814819336 | CLS Loss: 0.014737265184521675\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 2.4478113651275635 | KNN Loss: 2.4333691596984863 | CLS Loss: 0.01444225199520588\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 2.399733781814575 | KNN Loss: 2.3746273517608643 | CLS Loss: 0.025106316432356834\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 2.3900091648101807 | KNN Loss: 2.3807551860809326 | CLS Loss: 0.009254044853150845\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 2.4559528827667236 | KNN Loss: 2.4337127208709717 | CLS Loss: 0.022240202873945236\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 2.3861234188079834 | KNN Loss: 2.3631412982940674 | CLS Loss: 0.022982100024819374\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 2.387662649154663 | KNN Loss: 2.3631045818328857 | CLS Loss: 0.02455812133848667\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 2.4291110038757324 | KNN Loss: 2.408020257949829 | CLS Loss: 0.021090785041451454\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 2.4012811183929443 | KNN Loss: 2.37789249420166 | CLS Loss: 0.023388538509607315\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 2.373565196990967 | KNN Loss: 2.3616344928741455 | CLS Loss: 0.011930732056498528\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 2.4145047664642334 | KNN Loss: 2.388195514678955 | CLS Loss: 0.026309218257665634\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 2.4336838722229004 | KNN Loss: 2.4112322330474854 | CLS Loss: 0.022451672703027725\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 2.3851938247680664 | KNN Loss: 2.3551692962646484 | CLS Loss: 0.03002457320690155\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 2.4027647972106934 | KNN Loss: 2.369507074356079 | CLS Loss: 0.033257801085710526\n",
      "Epoch: 079, Loss: 2.4056, Train: 0.9948, Valid: 0.9857, Best: 0.9870\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 2.4027798175811768 | KNN Loss: 2.380225896835327 | CLS Loss: 0.022553825750947\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 2.4293270111083984 | KNN Loss: 2.4031105041503906 | CLS Loss: 0.026216503232717514\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 2.418793201446533 | KNN Loss: 2.3789899349212646 | CLS Loss: 0.03980317711830139\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 2.3945183753967285 | KNN Loss: 2.350938081741333 | CLS Loss: 0.04358036071062088\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 2.4036996364593506 | KNN Loss: 2.380873918533325 | CLS Loss: 0.022825801745057106\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 2.4081504344940186 | KNN Loss: 2.382905960083008 | CLS Loss: 0.025244565680623055\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 2.438123941421509 | KNN Loss: 2.4335806369781494 | CLS Loss: 0.00454340036958456\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 2.4034605026245117 | KNN Loss: 2.386380434036255 | CLS Loss: 0.017080157995224\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 2.401284694671631 | KNN Loss: 2.3962042331695557 | CLS Loss: 0.005080351606011391\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 2.4186742305755615 | KNN Loss: 2.41001296043396 | CLS Loss: 0.008661281317472458\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 2.387410879135132 | KNN Loss: 2.367921829223633 | CLS Loss: 0.019489074125885963\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 2.4475035667419434 | KNN Loss: 2.4414193630218506 | CLS Loss: 0.006084153428673744\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 2.4474759101867676 | KNN Loss: 2.407621383666992 | CLS Loss: 0.03985464572906494\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 2.3874571323394775 | KNN Loss: 2.3709170818328857 | CLS Loss: 0.016540061682462692\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 2.362306594848633 | KNN Loss: 2.350111246109009 | CLS Loss: 0.012195331044495106\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 2.4292211532592773 | KNN Loss: 2.4032726287841797 | CLS Loss: 0.02594859153032303\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 2.4323418140411377 | KNN Loss: 2.427999496459961 | CLS Loss: 0.004342339932918549\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 2.4104726314544678 | KNN Loss: 2.399289846420288 | CLS Loss: 0.011182881891727448\n",
      "Epoch: 080, Loss: 2.4126, Train: 0.9957, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 2.4191396236419678 | KNN Loss: 2.4035427570343018 | CLS Loss: 0.015596832148730755\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 2.3889923095703125 | KNN Loss: 2.3715665340423584 | CLS Loss: 0.017425736412405968\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 2.3637146949768066 | KNN Loss: 2.34845232963562 | CLS Loss: 0.015262356959283352\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 2.430346727371216 | KNN Loss: 2.4136955738067627 | CLS Loss: 0.01665126346051693\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 2.475790023803711 | KNN Loss: 2.4357759952545166 | CLS Loss: 0.04001403599977493\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 2.430508852005005 | KNN Loss: 2.427086591720581 | CLS Loss: 0.003422365989536047\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 2.4503443241119385 | KNN Loss: 2.4133591651916504 | CLS Loss: 0.03698515146970749\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 2.384927272796631 | KNN Loss: 2.366076707839966 | CLS Loss: 0.01885046996176243\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 2.4222865104675293 | KNN Loss: 2.3980748653411865 | CLS Loss: 0.024211641401052475\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 2.3952527046203613 | KNN Loss: 2.3882522583007812 | CLS Loss: 0.007000343408435583\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 2.417557716369629 | KNN Loss: 2.3954520225524902 | CLS Loss: 0.02210562862455845\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 2.400193214416504 | KNN Loss: 2.3889033794403076 | CLS Loss: 0.011289720423519611\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 2.421377658843994 | KNN Loss: 2.399233102798462 | CLS Loss: 0.02214464358985424\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 2.4597702026367188 | KNN Loss: 2.431797981262207 | CLS Loss: 0.027972282841801643\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 2.4451169967651367 | KNN Loss: 2.4264233112335205 | CLS Loss: 0.01869378052651882\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 2.450366497039795 | KNN Loss: 2.4388482570648193 | CLS Loss: 0.011518255807459354\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 2.3919074535369873 | KNN Loss: 2.3760311603546143 | CLS Loss: 0.015876242890954018\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 2.43701434135437 | KNN Loss: 2.403853416442871 | CLS Loss: 0.03316088765859604\n",
      "Epoch: 081, Loss: 2.4187, Train: 0.9946, Valid: 0.9857, Best: 0.9870\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 2.4370152950286865 | KNN Loss: 2.417523145675659 | CLS Loss: 0.019492262974381447\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 2.4681549072265625 | KNN Loss: 2.42569637298584 | CLS Loss: 0.042458564043045044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 2.4049623012542725 | KNN Loss: 2.392625093460083 | CLS Loss: 0.012337195686995983\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 2.4060940742492676 | KNN Loss: 2.38356876373291 | CLS Loss: 0.02252526767551899\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 2.3783302307128906 | KNN Loss: 2.3739070892333984 | CLS Loss: 0.004423215985298157\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 2.4224019050598145 | KNN Loss: 2.4096133708953857 | CLS Loss: 0.012788445688784122\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 2.44667387008667 | KNN Loss: 2.419440507888794 | CLS Loss: 0.02723325788974762\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 2.431288242340088 | KNN Loss: 2.420243501663208 | CLS Loss: 0.011044629849493504\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 2.3953049182891846 | KNN Loss: 2.387882947921753 | CLS Loss: 0.007421907968819141\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 2.4151647090911865 | KNN Loss: 2.400254964828491 | CLS Loss: 0.014909744262695312\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 2.402757406234741 | KNN Loss: 2.395273208618164 | CLS Loss: 0.007484137080609798\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 2.407332420349121 | KNN Loss: 2.3936452865600586 | CLS Loss: 0.013687077909708023\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 2.446331262588501 | KNN Loss: 2.436755895614624 | CLS Loss: 0.00957540050148964\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 2.3945770263671875 | KNN Loss: 2.38175892829895 | CLS Loss: 0.012818138115108013\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 2.412780284881592 | KNN Loss: 2.3986666202545166 | CLS Loss: 0.014113610610365868\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 2.433246374130249 | KNN Loss: 2.3945701122283936 | CLS Loss: 0.038676321506500244\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 2.4059829711914062 | KNN Loss: 2.388808012008667 | CLS Loss: 0.01717494986951351\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 2.362975597381592 | KNN Loss: 2.3295483589172363 | CLS Loss: 0.03342728316783905\n",
      "Epoch: 082, Loss: 2.4183, Train: 0.9954, Valid: 0.9857, Best: 0.9870\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 2.424724578857422 | KNN Loss: 2.412997007369995 | CLS Loss: 0.011727482080459595\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 2.407853841781616 | KNN Loss: 2.3693063259124756 | CLS Loss: 0.03854750096797943\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 2.4204888343811035 | KNN Loss: 2.3999080657958984 | CLS Loss: 0.020580744370818138\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 2.3971176147460938 | KNN Loss: 2.3923628330230713 | CLS Loss: 0.004754680674523115\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 2.4438235759735107 | KNN Loss: 2.41544246673584 | CLS Loss: 0.028381215408444405\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 2.4749956130981445 | KNN Loss: 2.4715707302093506 | CLS Loss: 0.0034247739240527153\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 2.4475131034851074 | KNN Loss: 2.431464195251465 | CLS Loss: 0.016048826277256012\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 2.401594400405884 | KNN Loss: 2.3775041103363037 | CLS Loss: 0.0240903552621603\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 2.438969850540161 | KNN Loss: 2.42362380027771 | CLS Loss: 0.015346131287515163\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 2.4024555683135986 | KNN Loss: 2.387924909591675 | CLS Loss: 0.014530709013342857\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 2.3760976791381836 | KNN Loss: 2.347816228866577 | CLS Loss: 0.028281500563025475\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 2.4263312816619873 | KNN Loss: 2.3937466144561768 | CLS Loss: 0.032584551721811295\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 2.4264280796051025 | KNN Loss: 2.4137473106384277 | CLS Loss: 0.012680675834417343\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 2.411954641342163 | KNN Loss: 2.3895087242126465 | CLS Loss: 0.022445956245064735\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 2.4019224643707275 | KNN Loss: 2.389782190322876 | CLS Loss: 0.01214023120701313\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 2.4320547580718994 | KNN Loss: 2.418968677520752 | CLS Loss: 0.01308599766343832\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 2.415471076965332 | KNN Loss: 2.392218589782715 | CLS Loss: 0.02325248345732689\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 2.394564628601074 | KNN Loss: 2.3895230293273926 | CLS Loss: 0.005041702650487423\n",
      "Epoch: 083, Loss: 2.4182, Train: 0.9959, Valid: 0.9866, Best: 0.9870\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 2.3873350620269775 | KNN Loss: 2.3768701553344727 | CLS Loss: 0.01046498492360115\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 2.4096174240112305 | KNN Loss: 2.4018263816833496 | CLS Loss: 0.007791058160364628\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 2.412111759185791 | KNN Loss: 2.4049925804138184 | CLS Loss: 0.007119280751794577\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 2.420185089111328 | KNN Loss: 2.4147279262542725 | CLS Loss: 0.005457207560539246\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 2.387619972229004 | KNN Loss: 2.3666610717773438 | CLS Loss: 0.020958833396434784\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 2.3938777446746826 | KNN Loss: 2.3840537071228027 | CLS Loss: 0.009824073873460293\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 2.3726677894592285 | KNN Loss: 2.3431482315063477 | CLS Loss: 0.02951965294778347\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 2.39945387840271 | KNN Loss: 2.3914148807525635 | CLS Loss: 0.008039027452468872\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 2.4053456783294678 | KNN Loss: 2.3879787921905518 | CLS Loss: 0.017366958782076836\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 2.4629156589508057 | KNN Loss: 2.4188990592956543 | CLS Loss: 0.04401664063334465\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 2.4346656799316406 | KNN Loss: 2.4074654579162598 | CLS Loss: 0.027200210839509964\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 2.4329028129577637 | KNN Loss: 2.4278507232666016 | CLS Loss: 0.0050520156510174274\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 2.3871374130249023 | KNN Loss: 2.3759779930114746 | CLS Loss: 0.011159487999975681\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 2.455235481262207 | KNN Loss: 2.4339396953582764 | CLS Loss: 0.0212956964969635\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 2.4320647716522217 | KNN Loss: 2.3947229385375977 | CLS Loss: 0.03734182193875313\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 2.4068620204925537 | KNN Loss: 2.3880248069763184 | CLS Loss: 0.01883717067539692\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 2.4489688873291016 | KNN Loss: 2.403487205505371 | CLS Loss: 0.04548180103302002\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 2.425065517425537 | KNN Loss: 2.38240122795105 | CLS Loss: 0.042664382606744766\n",
      "Epoch: 084, Loss: 2.4144, Train: 0.9951, Valid: 0.9862, Best: 0.9870\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 2.441401243209839 | KNN Loss: 2.4171881675720215 | CLS Loss: 0.024213191121816635\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 2.386986494064331 | KNN Loss: 2.371863603591919 | CLS Loss: 0.015122978016734123\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 2.462536096572876 | KNN Loss: 2.4381039142608643 | CLS Loss: 0.0244322270154953\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 2.3976364135742188 | KNN Loss: 2.3907203674316406 | CLS Loss: 0.006915979087352753\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 2.4227001667022705 | KNN Loss: 2.414158821105957 | CLS Loss: 0.008541364222764969\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 2.442382574081421 | KNN Loss: 2.4216105937957764 | CLS Loss: 0.02077200450003147\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 2.4069910049438477 | KNN Loss: 2.3760645389556885 | CLS Loss: 0.030926480889320374\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 2.4236979484558105 | KNN Loss: 2.4013047218322754 | CLS Loss: 0.02239316888153553\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 2.431213617324829 | KNN Loss: 2.4120900630950928 | CLS Loss: 0.01912347599864006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 2.436995029449463 | KNN Loss: 2.4124646186828613 | CLS Loss: 0.024530477821826935\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 2.4446861743927 | KNN Loss: 2.437509775161743 | CLS Loss: 0.007176365703344345\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 2.398958444595337 | KNN Loss: 2.388225555419922 | CLS Loss: 0.010732815600931644\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 2.4128384590148926 | KNN Loss: 2.390338897705078 | CLS Loss: 0.022499555721879005\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 2.438443183898926 | KNN Loss: 2.421572685241699 | CLS Loss: 0.016870535910129547\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 2.4197299480438232 | KNN Loss: 2.406599283218384 | CLS Loss: 0.013130630366504192\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 2.376617193222046 | KNN Loss: 2.3699934482574463 | CLS Loss: 0.006623793859034777\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 2.4485151767730713 | KNN Loss: 2.421963691711426 | CLS Loss: 0.026551425457000732\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 2.4149444103240967 | KNN Loss: 2.3941915035247803 | CLS Loss: 0.02075297199189663\n",
      "Epoch: 085, Loss: 2.4156, Train: 0.9954, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 2.398071050643921 | KNN Loss: 2.393181085586548 | CLS Loss: 0.0048898919485509396\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 2.4162957668304443 | KNN Loss: 2.3918933868408203 | CLS Loss: 0.02440243773162365\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 2.420752763748169 | KNN Loss: 2.41792368888855 | CLS Loss: 0.0028289901092648506\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 2.3904430866241455 | KNN Loss: 2.3690192699432373 | CLS Loss: 0.021423833444714546\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 2.4396536350250244 | KNN Loss: 2.399505138397217 | CLS Loss: 0.04014841839671135\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 2.4453389644622803 | KNN Loss: 2.4393515586853027 | CLS Loss: 0.005987309850752354\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 2.4449172019958496 | KNN Loss: 2.4278860092163086 | CLS Loss: 0.01703115738928318\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 2.4489095211029053 | KNN Loss: 2.4412484169006348 | CLS Loss: 0.007661005947738886\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 2.428830862045288 | KNN Loss: 2.417372226715088 | CLS Loss: 0.011458554305136204\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 2.435030221939087 | KNN Loss: 2.428880453109741 | CLS Loss: 0.006149655673652887\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 2.4406352043151855 | KNN Loss: 2.4141011238098145 | CLS Loss: 0.026534127071499825\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 2.4390695095062256 | KNN Loss: 2.410257577896118 | CLS Loss: 0.028811831027269363\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 2.447258234024048 | KNN Loss: 2.4182422161102295 | CLS Loss: 0.029016094282269478\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 2.4169886112213135 | KNN Loss: 2.3835108280181885 | CLS Loss: 0.03347782418131828\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 2.4583866596221924 | KNN Loss: 2.4486265182495117 | CLS Loss: 0.009760103188455105\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 2.4276888370513916 | KNN Loss: 2.4231948852539062 | CLS Loss: 0.004493847023695707\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 2.4192986488342285 | KNN Loss: 2.3997321128845215 | CLS Loss: 0.01956649124622345\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 2.413661241531372 | KNN Loss: 2.4045119285583496 | CLS Loss: 0.009149298071861267\n",
      "Epoch: 086, Loss: 2.4174, Train: 0.9956, Valid: 0.9854, Best: 0.9870\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 2.4365475177764893 | KNN Loss: 2.431243419647217 | CLS Loss: 0.0053041367791593075\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 2.4260456562042236 | KNN Loss: 2.4130892753601074 | CLS Loss: 0.012956488877534866\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 2.405508279800415 | KNN Loss: 2.385521411895752 | CLS Loss: 0.019986873492598534\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 2.4446635246276855 | KNN Loss: 2.414896249771118 | CLS Loss: 0.029767286032438278\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 2.4403438568115234 | KNN Loss: 2.4036316871643066 | CLS Loss: 0.03671221807599068\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 2.4224979877471924 | KNN Loss: 2.404954671859741 | CLS Loss: 0.017543267458677292\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 2.417343854904175 | KNN Loss: 2.413752794265747 | CLS Loss: 0.003591163782402873\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 2.398092269897461 | KNN Loss: 2.3900458812713623 | CLS Loss: 0.00804649293422699\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 2.450568199157715 | KNN Loss: 2.422786235809326 | CLS Loss: 0.027781952172517776\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 2.3765997886657715 | KNN Loss: 2.3561835289001465 | CLS Loss: 0.02041628584265709\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 2.4542665481567383 | KNN Loss: 2.413020610809326 | CLS Loss: 0.04124602675437927\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 2.4447762966156006 | KNN Loss: 2.425621271133423 | CLS Loss: 0.019154975190758705\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 2.419860601425171 | KNN Loss: 2.4084737300872803 | CLS Loss: 0.011386822909116745\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 2.436053991317749 | KNN Loss: 2.397573947906494 | CLS Loss: 0.03848009184002876\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 2.411975383758545 | KNN Loss: 2.3795862197875977 | CLS Loss: 0.032389093190431595\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 2.4574012756347656 | KNN Loss: 2.440098524093628 | CLS Loss: 0.0173027366399765\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 2.3905088901519775 | KNN Loss: 2.385058879852295 | CLS Loss: 0.005449953489005566\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 2.400106191635132 | KNN Loss: 2.3816661834716797 | CLS Loss: 0.01844003051519394\n",
      "Epoch: 087, Loss: 2.4176, Train: 0.9956, Valid: 0.9855, Best: 0.9870\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 2.4433631896972656 | KNN Loss: 2.429938554763794 | CLS Loss: 0.013424611650407314\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 2.410097122192383 | KNN Loss: 2.39473295211792 | CLS Loss: 0.015364082530140877\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 2.40899395942688 | KNN Loss: 2.40537166595459 | CLS Loss: 0.0036222529597580433\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 2.3986589908599854 | KNN Loss: 2.3832414150238037 | CLS Loss: 0.015417555347084999\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 2.4167633056640625 | KNN Loss: 2.4067418575286865 | CLS Loss: 0.010021544061601162\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 2.418684959411621 | KNN Loss: 2.3933751583099365 | CLS Loss: 0.02530978061258793\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 2.4220564365386963 | KNN Loss: 2.4077091217041016 | CLS Loss: 0.014347377233207226\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 2.38643217086792 | KNN Loss: 2.3764660358428955 | CLS Loss: 0.009966020472347736\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 2.4334256649017334 | KNN Loss: 2.4182474613189697 | CLS Loss: 0.015178150497376919\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 2.393198013305664 | KNN Loss: 2.3668434619903564 | CLS Loss: 0.026354605332016945\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 2.370828628540039 | KNN Loss: 2.362243413925171 | CLS Loss: 0.008585331961512566\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 2.402177095413208 | KNN Loss: 2.3691606521606445 | CLS Loss: 0.03301655128598213\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 2.374283790588379 | KNN Loss: 2.3708560466766357 | CLS Loss: 0.0034276582300662994\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 2.4034953117370605 | KNN Loss: 2.3777823448181152 | CLS Loss: 0.02571306936442852\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 2.4263625144958496 | KNN Loss: 2.399857521057129 | CLS Loss: 0.026505092158913612\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 2.401160478591919 | KNN Loss: 2.389883279800415 | CLS Loss: 0.011277291923761368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 2.421468496322632 | KNN Loss: 2.4140453338623047 | CLS Loss: 0.0074231442995369434\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 2.4335970878601074 | KNN Loss: 2.4257922172546387 | CLS Loss: 0.007804783992469311\n",
      "Epoch: 088, Loss: 2.4173, Train: 0.9963, Valid: 0.9864, Best: 0.9870\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 2.402679920196533 | KNN Loss: 2.3951048851013184 | CLS Loss: 0.007575063034892082\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 2.406231641769409 | KNN Loss: 2.399745464324951 | CLS Loss: 0.006486090831458569\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 2.4038681983947754 | KNN Loss: 2.387392044067383 | CLS Loss: 0.016476167365908623\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 2.42533802986145 | KNN Loss: 2.4097063541412354 | CLS Loss: 0.015631593763828278\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 2.4160501956939697 | KNN Loss: 2.401535987854004 | CLS Loss: 0.014514271169900894\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 2.421355962753296 | KNN Loss: 2.410357713699341 | CLS Loss: 0.010998180136084557\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 2.4013025760650635 | KNN Loss: 2.381182909011841 | CLS Loss: 0.020119644701480865\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 2.3816399574279785 | KNN Loss: 2.3759162425994873 | CLS Loss: 0.005723609123378992\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 2.40616774559021 | KNN Loss: 2.3985698223114014 | CLS Loss: 0.007597815245389938\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 2.443535566329956 | KNN Loss: 2.425461530685425 | CLS Loss: 0.018074041232466698\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 2.4139881134033203 | KNN Loss: 2.3968493938446045 | CLS Loss: 0.017138682305812836\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 2.4536564350128174 | KNN Loss: 2.4256486892700195 | CLS Loss: 0.028007833287119865\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 2.4201786518096924 | KNN Loss: 2.397141218185425 | CLS Loss: 0.023037351667881012\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 2.429847002029419 | KNN Loss: 2.420024871826172 | CLS Loss: 0.00982215628027916\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 2.4168479442596436 | KNN Loss: 2.4137394428253174 | CLS Loss: 0.0031084781512618065\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 2.392775058746338 | KNN Loss: 2.377903938293457 | CLS Loss: 0.014871216379106045\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 2.4233591556549072 | KNN Loss: 2.405837059020996 | CLS Loss: 0.017522096633911133\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 2.434248208999634 | KNN Loss: 2.3946945667266846 | CLS Loss: 0.039553530514240265\n",
      "Epoch: 089, Loss: 2.4188, Train: 0.9945, Valid: 0.9841, Best: 0.9870\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 2.391681671142578 | KNN Loss: 2.3735671043395996 | CLS Loss: 0.018114475533366203\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 2.411968231201172 | KNN Loss: 2.4048075675964355 | CLS Loss: 0.007160755340009928\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 2.460752010345459 | KNN Loss: 2.4216063022613525 | CLS Loss: 0.03914562985301018\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 2.433000326156616 | KNN Loss: 2.4232137203216553 | CLS Loss: 0.009786716662347317\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 2.4300951957702637 | KNN Loss: 2.415221691131592 | CLS Loss: 0.014873535372316837\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 2.4227705001831055 | KNN Loss: 2.3978617191314697 | CLS Loss: 0.02490878663957119\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 2.406919002532959 | KNN Loss: 2.3980906009674072 | CLS Loss: 0.008828295394778252\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 2.4017462730407715 | KNN Loss: 2.388371467590332 | CLS Loss: 0.013374748639762402\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 2.391294479370117 | KNN Loss: 2.3663084506988525 | CLS Loss: 0.02498599886894226\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 2.4105193614959717 | KNN Loss: 2.406503677368164 | CLS Loss: 0.004015704151242971\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 2.406473398208618 | KNN Loss: 2.398047685623169 | CLS Loss: 0.008425640873610973\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 2.4104416370391846 | KNN Loss: 2.4022343158721924 | CLS Loss: 0.008207423612475395\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 2.4020626544952393 | KNN Loss: 2.398589849472046 | CLS Loss: 0.003472716547548771\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 2.406216621398926 | KNN Loss: 2.384263038635254 | CLS Loss: 0.021953526884317398\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 2.4583468437194824 | KNN Loss: 2.4157159328460693 | CLS Loss: 0.04263085126876831\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 2.448410987854004 | KNN Loss: 2.4240803718566895 | CLS Loss: 0.02433052472770214\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 2.428851366043091 | KNN Loss: 2.4004735946655273 | CLS Loss: 0.028377685695886612\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 2.4082415103912354 | KNN Loss: 2.395576000213623 | CLS Loss: 0.012665459886193275\n",
      "Epoch: 090, Loss: 2.4182, Train: 0.9961, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 2.3861281871795654 | KNN Loss: 2.3794474601745605 | CLS Loss: 0.006680807564407587\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 2.39693546295166 | KNN Loss: 2.3946032524108887 | CLS Loss: 0.0023322661872953176\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 2.4231066703796387 | KNN Loss: 2.4179952144622803 | CLS Loss: 0.005111538805067539\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 2.3998403549194336 | KNN Loss: 2.394679307937622 | CLS Loss: 0.005160950589925051\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 2.4365382194519043 | KNN Loss: 2.4206347465515137 | CLS Loss: 0.015903357416391373\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 2.42517352104187 | KNN Loss: 2.421806812286377 | CLS Loss: 0.003366687335073948\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 2.3854258060455322 | KNN Loss: 2.377351999282837 | CLS Loss: 0.008073749952018261\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 2.416361093521118 | KNN Loss: 2.39060115814209 | CLS Loss: 0.025760047137737274\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 2.390856981277466 | KNN Loss: 2.3874170780181885 | CLS Loss: 0.0034399377182126045\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 2.4075872898101807 | KNN Loss: 2.3791821002960205 | CLS Loss: 0.028405291959643364\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 2.3917887210845947 | KNN Loss: 2.3847625255584717 | CLS Loss: 0.0070262448862195015\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 2.4320147037506104 | KNN Loss: 2.4140312671661377 | CLS Loss: 0.017983369529247284\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 2.4317784309387207 | KNN Loss: 2.4049928188323975 | CLS Loss: 0.02678562141954899\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 2.4125099182128906 | KNN Loss: 2.4056320190429688 | CLS Loss: 0.00687794853001833\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 2.406623363494873 | KNN Loss: 2.3988773822784424 | CLS Loss: 0.007746036630123854\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 2.4285385608673096 | KNN Loss: 2.423712968826294 | CLS Loss: 0.0048255170695483685\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 2.406759738922119 | KNN Loss: 2.400556802749634 | CLS Loss: 0.006203019060194492\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 2.411111354827881 | KNN Loss: 2.385308027267456 | CLS Loss: 0.025803402066230774\n",
      "Epoch: 091, Loss: 2.4125, Train: 0.9953, Valid: 0.9849, Best: 0.9870\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 2.424135684967041 | KNN Loss: 2.4143447875976562 | CLS Loss: 0.009790973737835884\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 2.4421558380126953 | KNN Loss: 2.4225106239318848 | CLS Loss: 0.019645322114229202\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 2.4426400661468506 | KNN Loss: 2.418705940246582 | CLS Loss: 0.023934127762913704\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 2.4081337451934814 | KNN Loss: 2.3955249786376953 | CLS Loss: 0.012608831748366356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 2.4651124477386475 | KNN Loss: 2.4454314708709717 | CLS Loss: 0.019681042060256004\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 2.406785488128662 | KNN Loss: 2.3961617946624756 | CLS Loss: 0.01062364038079977\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 2.4199676513671875 | KNN Loss: 2.4152958393096924 | CLS Loss: 0.004671864211559296\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 2.4186787605285645 | KNN Loss: 2.4108617305755615 | CLS Loss: 0.00781709048897028\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 2.460679054260254 | KNN Loss: 2.4170899391174316 | CLS Loss: 0.043589036911726\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 2.406858444213867 | KNN Loss: 2.3903110027313232 | CLS Loss: 0.01654748059809208\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 2.3963940143585205 | KNN Loss: 2.3835110664367676 | CLS Loss: 0.012882894836366177\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 2.4486448764801025 | KNN Loss: 2.434680938720703 | CLS Loss: 0.01396402157843113\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 2.408496379852295 | KNN Loss: 2.3981704711914062 | CLS Loss: 0.01032581552863121\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 2.412203073501587 | KNN Loss: 2.3879549503326416 | CLS Loss: 0.024248238652944565\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 2.437519073486328 | KNN Loss: 2.416255235671997 | CLS Loss: 0.021263733506202698\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 2.401033878326416 | KNN Loss: 2.383415699005127 | CLS Loss: 0.017618298530578613\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 2.396907091140747 | KNN Loss: 2.38531494140625 | CLS Loss: 0.011592131108045578\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 2.4525058269500732 | KNN Loss: 2.4302361011505127 | CLS Loss: 0.02226961776614189\n",
      "Epoch: 092, Loss: 2.4188, Train: 0.9956, Valid: 0.9852, Best: 0.9870\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 2.4202685356140137 | KNN Loss: 2.4132699966430664 | CLS Loss: 0.006998625583946705\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 2.405930519104004 | KNN Loss: 2.392686128616333 | CLS Loss: 0.013244413770735264\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 2.4147093296051025 | KNN Loss: 2.399564266204834 | CLS Loss: 0.015145041048526764\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 2.4160056114196777 | KNN Loss: 2.39190936088562 | CLS Loss: 0.02409636601805687\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 2.428023099899292 | KNN Loss: 2.4131052494049072 | CLS Loss: 0.01491784118115902\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 2.4649553298950195 | KNN Loss: 2.4522881507873535 | CLS Loss: 0.012667244300246239\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 2.4117913246154785 | KNN Loss: 2.3883752822875977 | CLS Loss: 0.023416096344590187\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 2.4448277950286865 | KNN Loss: 2.426532506942749 | CLS Loss: 0.018295394256711006\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 2.433319330215454 | KNN Loss: 2.4269330501556396 | CLS Loss: 0.006386168301105499\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 2.4333229064941406 | KNN Loss: 2.4291229248046875 | CLS Loss: 0.004199972376227379\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 2.4023492336273193 | KNN Loss: 2.3898584842681885 | CLS Loss: 0.012490862049162388\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 2.4154624938964844 | KNN Loss: 2.3969993591308594 | CLS Loss: 0.01846318691968918\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 2.392218589782715 | KNN Loss: 2.371351718902588 | CLS Loss: 0.020866872742772102\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 2.406769275665283 | KNN Loss: 2.3952646255493164 | CLS Loss: 0.011504583060741425\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 2.3914356231689453 | KNN Loss: 2.384955406188965 | CLS Loss: 0.006480250973254442\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 2.4422595500946045 | KNN Loss: 2.4252734184265137 | CLS Loss: 0.016986101865768433\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 2.451385498046875 | KNN Loss: 2.4403650760650635 | CLS Loss: 0.011020319536328316\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 2.41823673248291 | KNN Loss: 2.408684253692627 | CLS Loss: 0.009552404284477234\n",
      "Epoch: 093, Loss: 2.4192, Train: 0.9961, Valid: 0.9861, Best: 0.9870\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 2.397007942199707 | KNN Loss: 2.3823251724243164 | CLS Loss: 0.014682712033390999\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 2.4060802459716797 | KNN Loss: 2.404345750808716 | CLS Loss: 0.0017344135558232665\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 2.373997926712036 | KNN Loss: 2.365593910217285 | CLS Loss: 0.00840400904417038\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 2.396522045135498 | KNN Loss: 2.3762996196746826 | CLS Loss: 0.0202223788946867\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 2.3971054553985596 | KNN Loss: 2.3926842212677 | CLS Loss: 0.004421178251504898\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 2.371690273284912 | KNN Loss: 2.3469347953796387 | CLS Loss: 0.02475557290017605\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 2.394454002380371 | KNN Loss: 2.3772799968719482 | CLS Loss: 0.01717403531074524\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 2.407569169998169 | KNN Loss: 2.386399745941162 | CLS Loss: 0.021169530227780342\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 2.380295515060425 | KNN Loss: 2.372004508972168 | CLS Loss: 0.008290939033031464\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 2.444810152053833 | KNN Loss: 2.4344546794891357 | CLS Loss: 0.010355476289987564\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 2.396601438522339 | KNN Loss: 2.385286331176758 | CLS Loss: 0.01131500955671072\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 2.470576286315918 | KNN Loss: 2.416084051132202 | CLS Loss: 0.054492149502038956\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 2.4851179122924805 | KNN Loss: 2.4804177284240723 | CLS Loss: 0.0047002010978758335\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 2.4188318252563477 | KNN Loss: 2.400315046310425 | CLS Loss: 0.018516797572374344\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 2.3908321857452393 | KNN Loss: 2.3823325634002686 | CLS Loss: 0.00849963165819645\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 2.3765017986297607 | KNN Loss: 2.3626019954681396 | CLS Loss: 0.013899789191782475\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 2.4413628578186035 | KNN Loss: 2.413731813430786 | CLS Loss: 0.027631038799881935\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 2.432447910308838 | KNN Loss: 2.420825719833374 | CLS Loss: 0.011622260324656963\n",
      "Epoch: 094, Loss: 2.4160, Train: 0.9956, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 2.408932685852051 | KNN Loss: 2.379094123840332 | CLS Loss: 0.02983861044049263\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 2.4297258853912354 | KNN Loss: 2.4068315029144287 | CLS Loss: 0.022894300520420074\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 2.408576726913452 | KNN Loss: 2.3894824981689453 | CLS Loss: 0.019094251096248627\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 2.442243814468384 | KNN Loss: 2.4183571338653564 | CLS Loss: 0.02388661541044712\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 2.3883354663848877 | KNN Loss: 2.3804028034210205 | CLS Loss: 0.007932621985673904\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 2.4358184337615967 | KNN Loss: 2.4117231369018555 | CLS Loss: 0.024095358327031136\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 2.453498601913452 | KNN Loss: 2.4294116497039795 | CLS Loss: 0.024086885154247284\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 2.4061179161071777 | KNN Loss: 2.3998818397521973 | CLS Loss: 0.006236027926206589\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 2.4363417625427246 | KNN Loss: 2.4263367652893066 | CLS Loss: 0.01000501774251461\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 2.407085418701172 | KNN Loss: 2.38828444480896 | CLS Loss: 0.018801068887114525\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 2.4199841022491455 | KNN Loss: 2.3883938789367676 | CLS Loss: 0.03159020468592644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 2.4156079292297363 | KNN Loss: 2.4104323387145996 | CLS Loss: 0.005175556987524033\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 2.4309065341949463 | KNN Loss: 2.4187920093536377 | CLS Loss: 0.012114496901631355\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 2.443948745727539 | KNN Loss: 2.440953016281128 | CLS Loss: 0.00299580255523324\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 2.420226573944092 | KNN Loss: 2.41505765914917 | CLS Loss: 0.005168868228793144\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 2.4071362018585205 | KNN Loss: 2.383702039718628 | CLS Loss: 0.023434164002537727\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 2.406251907348633 | KNN Loss: 2.397050619125366 | CLS Loss: 0.009201178327202797\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 2.431401491165161 | KNN Loss: 2.4119269847869873 | CLS Loss: 0.01947452500462532\n",
      "Epoch: 095, Loss: 2.4185, Train: 0.9960, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 2.44217586517334 | KNN Loss: 2.4376003742218018 | CLS Loss: 0.004575579892843962\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 2.4209742546081543 | KNN Loss: 2.4047727584838867 | CLS Loss: 0.016201471909880638\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 2.416379690170288 | KNN Loss: 2.3931334018707275 | CLS Loss: 0.023246312513947487\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 2.3942015171051025 | KNN Loss: 2.375441789627075 | CLS Loss: 0.018759679049253464\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 2.4013707637786865 | KNN Loss: 2.3970158100128174 | CLS Loss: 0.004354961682111025\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 2.4346301555633545 | KNN Loss: 2.430828332901001 | CLS Loss: 0.0038019148632884026\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 2.4211184978485107 | KNN Loss: 2.416271686553955 | CLS Loss: 0.004846764262765646\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 2.410421371459961 | KNN Loss: 2.3969528675079346 | CLS Loss: 0.01346841175109148\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 2.4565746784210205 | KNN Loss: 2.4478776454925537 | CLS Loss: 0.008696945384144783\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 2.4454572200775146 | KNN Loss: 2.392493963241577 | CLS Loss: 0.05296328663825989\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 2.427180528640747 | KNN Loss: 2.398681640625 | CLS Loss: 0.028498873114585876\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 2.3843634128570557 | KNN Loss: 2.3484444618225098 | CLS Loss: 0.035918936133384705\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 2.3775124549865723 | KNN Loss: 2.3688337802886963 | CLS Loss: 0.008678555488586426\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 2.4374802112579346 | KNN Loss: 2.435530424118042 | CLS Loss: 0.0019497065804898739\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 2.4097647666931152 | KNN Loss: 2.3917407989501953 | CLS Loss: 0.01802397519350052\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 2.423368453979492 | KNN Loss: 2.408221483230591 | CLS Loss: 0.015146941877901554\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 2.375682830810547 | KNN Loss: 2.351980209350586 | CLS Loss: 0.02370251901447773\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 2.4305763244628906 | KNN Loss: 2.4146103858947754 | CLS Loss: 0.015965977683663368\n",
      "Epoch: 096, Loss: 2.4162, Train: 0.9955, Valid: 0.9850, Best: 0.9870\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 2.427992820739746 | KNN Loss: 2.4150145053863525 | CLS Loss: 0.012978333979845047\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 2.446892499923706 | KNN Loss: 2.4202027320861816 | CLS Loss: 0.026689860969781876\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 2.4078478813171387 | KNN Loss: 2.370842695236206 | CLS Loss: 0.037005215883255005\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 2.395540714263916 | KNN Loss: 2.378481149673462 | CLS Loss: 0.017059603706002235\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 2.3905255794525146 | KNN Loss: 2.388916492462158 | CLS Loss: 0.0016090563731268048\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 2.3851044178009033 | KNN Loss: 2.356602430343628 | CLS Loss: 0.028501885011792183\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 2.409329891204834 | KNN Loss: 2.399829864501953 | CLS Loss: 0.009499951265752316\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 2.4579646587371826 | KNN Loss: 2.4438631534576416 | CLS Loss: 0.014101590029895306\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 2.382498264312744 | KNN Loss: 2.3759026527404785 | CLS Loss: 0.006595602259039879\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 2.4314520359039307 | KNN Loss: 2.4169111251831055 | CLS Loss: 0.014540880918502808\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 2.475236177444458 | KNN Loss: 2.466655731201172 | CLS Loss: 0.008580503985285759\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 2.4180617332458496 | KNN Loss: 2.3983800411224365 | CLS Loss: 0.019681785255670547\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 2.4541122913360596 | KNN Loss: 2.439265012741089 | CLS Loss: 0.014847160317003727\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 2.4225454330444336 | KNN Loss: 2.4067158699035645 | CLS Loss: 0.015829667448997498\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 2.4253599643707275 | KNN Loss: 2.410802125930786 | CLS Loss: 0.01455780677497387\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 2.409226417541504 | KNN Loss: 2.3954873085021973 | CLS Loss: 0.013739209622144699\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 2.4193665981292725 | KNN Loss: 2.3999390602111816 | CLS Loss: 0.019427591934800148\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 2.4354259967803955 | KNN Loss: 2.4098753929138184 | CLS Loss: 0.025550521910190582\n",
      "Epoch: 097, Loss: 2.4158, Train: 0.9957, Valid: 0.9862, Best: 0.9870\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 2.4428861141204834 | KNN Loss: 2.4125285148620605 | CLS Loss: 0.030357660725712776\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 2.4016590118408203 | KNN Loss: 2.394777297973633 | CLS Loss: 0.006881651468575001\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 2.399822235107422 | KNN Loss: 2.39162278175354 | CLS Loss: 0.008199416100978851\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 2.4230682849884033 | KNN Loss: 2.3880791664123535 | CLS Loss: 0.03498907387256622\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 2.4036710262298584 | KNN Loss: 2.3864269256591797 | CLS Loss: 0.017244141548871994\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 2.391800880432129 | KNN Loss: 2.3758506774902344 | CLS Loss: 0.015950104221701622\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 2.406980514526367 | KNN Loss: 2.3933804035186768 | CLS Loss: 0.013600151054561138\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 2.4353723526000977 | KNN Loss: 2.4114620685577393 | CLS Loss: 0.02391028217971325\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 2.398176670074463 | KNN Loss: 2.389146566390991 | CLS Loss: 0.009030221961438656\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 2.466888427734375 | KNN Loss: 2.441964626312256 | CLS Loss: 0.024923887103796005\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 2.453319549560547 | KNN Loss: 2.4251790046691895 | CLS Loss: 0.02814050205051899\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 2.457657814025879 | KNN Loss: 2.441317081451416 | CLS Loss: 0.016340838745236397\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 2.4034132957458496 | KNN Loss: 2.384639024734497 | CLS Loss: 0.018774274736642838\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 2.409038543701172 | KNN Loss: 2.4000797271728516 | CLS Loss: 0.008958782069385052\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 2.4466378688812256 | KNN Loss: 2.416477680206299 | CLS Loss: 0.030160104855895042\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 2.4090793132781982 | KNN Loss: 2.3869736194610596 | CLS Loss: 0.02210560441017151\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 2.4295520782470703 | KNN Loss: 2.4134738445281982 | CLS Loss: 0.016078216955065727\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 2.403787136077881 | KNN Loss: 2.388991117477417 | CLS Loss: 0.014796039089560509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 098, Loss: 2.4173, Train: 0.9951, Valid: 0.9849, Best: 0.9870\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 2.4523048400878906 | KNN Loss: 2.4183411598205566 | CLS Loss: 0.03396376967430115\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 2.4421989917755127 | KNN Loss: 2.4221854209899902 | CLS Loss: 0.02001352794468403\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 2.442675828933716 | KNN Loss: 2.4247429370880127 | CLS Loss: 0.017932849004864693\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 2.3987739086151123 | KNN Loss: 2.3848423957824707 | CLS Loss: 0.01393153890967369\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 2.4056754112243652 | KNN Loss: 2.372952938079834 | CLS Loss: 0.0327225923538208\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 2.457200050354004 | KNN Loss: 2.4324018955230713 | CLS Loss: 0.02479827031493187\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 2.397240161895752 | KNN Loss: 2.374983549118042 | CLS Loss: 0.0222565196454525\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 2.4231700897216797 | KNN Loss: 2.4114041328430176 | CLS Loss: 0.011765971779823303\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 2.4022281169891357 | KNN Loss: 2.3903398513793945 | CLS Loss: 0.01188825536519289\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 2.412456750869751 | KNN Loss: 2.3992934226989746 | CLS Loss: 0.013163262978196144\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 2.3759400844573975 | KNN Loss: 2.365060329437256 | CLS Loss: 0.010879738256335258\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 2.392853021621704 | KNN Loss: 2.388087749481201 | CLS Loss: 0.004765327554196119\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 2.445375919342041 | KNN Loss: 2.4253909587860107 | CLS Loss: 0.019985076040029526\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 2.408642292022705 | KNN Loss: 2.3838531970977783 | CLS Loss: 0.024789202958345413\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 2.401768684387207 | KNN Loss: 2.3843882083892822 | CLS Loss: 0.0173804871737957\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 2.3603203296661377 | KNN Loss: 2.350228786468506 | CLS Loss: 0.010091611184179783\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 2.476633310317993 | KNN Loss: 2.420135736465454 | CLS Loss: 0.05649767443537712\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 2.4374332427978516 | KNN Loss: 2.41978120803833 | CLS Loss: 0.01765194907784462\n",
      "Epoch: 099, Loss: 2.4151, Train: 0.9963, Valid: 0.9856, Best: 0.9870\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 2.379453182220459 | KNN Loss: 2.376248359680176 | CLS Loss: 0.003204918000847101\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 2.427997589111328 | KNN Loss: 2.4149672985076904 | CLS Loss: 0.013030333444476128\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 2.4297847747802734 | KNN Loss: 2.409210205078125 | CLS Loss: 0.02057461068034172\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 2.3935234546661377 | KNN Loss: 2.375716209411621 | CLS Loss: 0.017807355150580406\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 2.404320478439331 | KNN Loss: 2.3916029930114746 | CLS Loss: 0.012717471458017826\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 2.4039783477783203 | KNN Loss: 2.376831293106079 | CLS Loss: 0.027147172018885612\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 2.4240214824676514 | KNN Loss: 2.4142472743988037 | CLS Loss: 0.009774158708751202\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 2.428907871246338 | KNN Loss: 2.4047906398773193 | CLS Loss: 0.02411724627017975\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 2.397240400314331 | KNN Loss: 2.3898355960845947 | CLS Loss: 0.0074049183167517185\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 2.4029924869537354 | KNN Loss: 2.3916585445404053 | CLS Loss: 0.011333977803587914\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 2.3849992752075195 | KNN Loss: 2.372889757156372 | CLS Loss: 0.012109463103115559\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 2.4319491386413574 | KNN Loss: 2.4194891452789307 | CLS Loss: 0.01245992910116911\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 2.407991886138916 | KNN Loss: 2.3854854106903076 | CLS Loss: 0.022506466135382652\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 2.4233736991882324 | KNN Loss: 2.4103329181671143 | CLS Loss: 0.013040878809988499\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 2.454253673553467 | KNN Loss: 2.4361813068389893 | CLS Loss: 0.01807236485183239\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 2.4006006717681885 | KNN Loss: 2.382023572921753 | CLS Loss: 0.018577130511403084\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 2.3988752365112305 | KNN Loss: 2.376781463623047 | CLS Loss: 0.022093825042247772\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 2.3838207721710205 | KNN Loss: 2.3723742961883545 | CLS Loss: 0.01144658587872982\n",
      "Epoch: 100, Loss: 2.4151, Train: 0.9968, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 2.4502530097961426 | KNN Loss: 2.4267380237579346 | CLS Loss: 0.023515086621046066\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 2.424669027328491 | KNN Loss: 2.3959431648254395 | CLS Loss: 0.028725940734148026\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 2.3904364109039307 | KNN Loss: 2.3653881549835205 | CLS Loss: 0.025048192590475082\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 2.4078221321105957 | KNN Loss: 2.387244462966919 | CLS Loss: 0.020577730610966682\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 2.4100964069366455 | KNN Loss: 2.397221565246582 | CLS Loss: 0.012874885462224483\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 2.3867268562316895 | KNN Loss: 2.361206531524658 | CLS Loss: 0.025520427152514458\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 2.4414167404174805 | KNN Loss: 2.428838014602661 | CLS Loss: 0.012578653171658516\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 2.390941619873047 | KNN Loss: 2.3792450428009033 | CLS Loss: 0.01169666275382042\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 2.4084465503692627 | KNN Loss: 2.4001893997192383 | CLS Loss: 0.008257118985056877\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 2.4158825874328613 | KNN Loss: 2.3936405181884766 | CLS Loss: 0.022242143750190735\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 2.4337191581726074 | KNN Loss: 2.4244892597198486 | CLS Loss: 0.009229951538145542\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 2.4310081005096436 | KNN Loss: 2.4177281856536865 | CLS Loss: 0.013279943726956844\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 2.407282590866089 | KNN Loss: 2.362185001373291 | CLS Loss: 0.045097582042217255\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 2.409820556640625 | KNN Loss: 2.404296875 | CLS Loss: 0.005523721221834421\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 2.4200425148010254 | KNN Loss: 2.4126548767089844 | CLS Loss: 0.00738769955933094\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 2.422136068344116 | KNN Loss: 2.4006659984588623 | CLS Loss: 0.021470170468091965\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 2.3814432621002197 | KNN Loss: 2.372443675994873 | CLS Loss: 0.008999654091894627\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 2.451031446456909 | KNN Loss: 2.4418766498565674 | CLS Loss: 0.00915482547134161\n",
      "Epoch: 101, Loss: 2.4139, Train: 0.9966, Valid: 0.9870, Best: 0.9870\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 2.39076828956604 | KNN Loss: 2.3841452598571777 | CLS Loss: 0.006622954271733761\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 2.3987324237823486 | KNN Loss: 2.3809194564819336 | CLS Loss: 0.01781286671757698\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 2.4477291107177734 | KNN Loss: 2.4257681369781494 | CLS Loss: 0.021960871294140816\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 2.4195516109466553 | KNN Loss: 2.391751289367676 | CLS Loss: 0.02780037559568882\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 2.4039547443389893 | KNN Loss: 2.3950648307800293 | CLS Loss: 0.008889991790056229\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 2.493183135986328 | KNN Loss: 2.4847099781036377 | CLS Loss: 0.008473161607980728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 2.3852458000183105 | KNN Loss: 2.376171112060547 | CLS Loss: 0.009074619971215725\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 2.4600932598114014 | KNN Loss: 2.4394562244415283 | CLS Loss: 0.020637130364775658\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 2.41862154006958 | KNN Loss: 2.404925584793091 | CLS Loss: 0.013695919886231422\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 2.3987865447998047 | KNN Loss: 2.3953492641448975 | CLS Loss: 0.0034373211674392223\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 2.42932391166687 | KNN Loss: 2.4042611122131348 | CLS Loss: 0.02506287582218647\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 2.4069204330444336 | KNN Loss: 2.3977105617523193 | CLS Loss: 0.009209905751049519\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 2.434507369995117 | KNN Loss: 2.4197723865509033 | CLS Loss: 0.014734945259988308\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 2.4093708992004395 | KNN Loss: 2.401564359664917 | CLS Loss: 0.007806586101651192\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 2.4309396743774414 | KNN Loss: 2.4213969707489014 | CLS Loss: 0.00954260304570198\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 2.420217752456665 | KNN Loss: 2.3900504112243652 | CLS Loss: 0.030167317017912865\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 2.450397491455078 | KNN Loss: 2.4062654972076416 | CLS Loss: 0.04413202404975891\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 2.3902580738067627 | KNN Loss: 2.3778882026672363 | CLS Loss: 0.012369895353913307\n",
      "Epoch: 102, Loss: 2.4154, Train: 0.9954, Valid: 0.9856, Best: 0.9870\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 2.428502321243286 | KNN Loss: 2.409813165664673 | CLS Loss: 0.018689075484871864\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 2.4025838375091553 | KNN Loss: 2.4002716541290283 | CLS Loss: 0.002312254160642624\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 2.402879476547241 | KNN Loss: 2.3814666271209717 | CLS Loss: 0.021412964910268784\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 2.4026002883911133 | KNN Loss: 2.3975203037261963 | CLS Loss: 0.005079950671643019\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 2.423887014389038 | KNN Loss: 2.395159959793091 | CLS Loss: 0.028727004304528236\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 2.416926145553589 | KNN Loss: 2.401244640350342 | CLS Loss: 0.015681592747569084\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 2.400006055831909 | KNN Loss: 2.394339084625244 | CLS Loss: 0.005666879937052727\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 2.4350881576538086 | KNN Loss: 2.426682472229004 | CLS Loss: 0.00840560533106327\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 2.4271788597106934 | KNN Loss: 2.3997304439544678 | CLS Loss: 0.027448441833257675\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 2.4304299354553223 | KNN Loss: 2.4140877723693848 | CLS Loss: 0.016342055052518845\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 2.4418768882751465 | KNN Loss: 2.4165961742401123 | CLS Loss: 0.025280635803937912\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 2.4014785289764404 | KNN Loss: 2.3902933597564697 | CLS Loss: 0.011185201816260815\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 2.408872365951538 | KNN Loss: 2.3996973037719727 | CLS Loss: 0.00917502585798502\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 2.4099674224853516 | KNN Loss: 2.3938846588134766 | CLS Loss: 0.016082806512713432\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 2.4664926528930664 | KNN Loss: 2.4458775520324707 | CLS Loss: 0.020615028217434883\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 2.409255027770996 | KNN Loss: 2.3988919258117676 | CLS Loss: 0.010363059118390083\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 2.4591681957244873 | KNN Loss: 2.4466392993927 | CLS Loss: 0.012528837658464909\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 2.4163994789123535 | KNN Loss: 2.3982181549072266 | CLS Loss: 0.018181249499320984\n",
      "Epoch: 103, Loss: 2.4171, Train: 0.9962, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 2.393082618713379 | KNN Loss: 2.3799290657043457 | CLS Loss: 0.013153517618775368\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 2.4017553329467773 | KNN Loss: 2.3926002979278564 | CLS Loss: 0.009154989384114742\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 2.4094817638397217 | KNN Loss: 2.4052743911743164 | CLS Loss: 0.004207269288599491\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 2.444340229034424 | KNN Loss: 2.42893648147583 | CLS Loss: 0.01540376152843237\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 2.4578146934509277 | KNN Loss: 2.4463982582092285 | CLS Loss: 0.011416331864893436\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 2.4207875728607178 | KNN Loss: 2.3970730304718018 | CLS Loss: 0.023714503273367882\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 2.4454236030578613 | KNN Loss: 2.4220025539398193 | CLS Loss: 0.02342108264565468\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 2.390061378479004 | KNN Loss: 2.385009527206421 | CLS Loss: 0.005051843356341124\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 2.3706703186035156 | KNN Loss: 2.364635705947876 | CLS Loss: 0.006034600082784891\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 2.418868064880371 | KNN Loss: 2.4006638526916504 | CLS Loss: 0.018204208463430405\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 2.4295172691345215 | KNN Loss: 2.4053804874420166 | CLS Loss: 0.02413669042289257\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 2.4214532375335693 | KNN Loss: 2.403937578201294 | CLS Loss: 0.017515601590275764\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 2.4152028560638428 | KNN Loss: 2.409562587738037 | CLS Loss: 0.0056401644833385944\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 2.4189915657043457 | KNN Loss: 2.407025098800659 | CLS Loss: 0.011966397054493427\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 2.4088969230651855 | KNN Loss: 2.3982889652252197 | CLS Loss: 0.010607974603772163\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 2.419454336166382 | KNN Loss: 2.4000213146209717 | CLS Loss: 0.019433047622442245\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 2.42645525932312 | KNN Loss: 2.4198241233825684 | CLS Loss: 0.006631156895309687\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 2.4083197116851807 | KNN Loss: 2.402200222015381 | CLS Loss: 0.006119483150541782\n",
      "Epoch: 104, Loss: 2.4143, Train: 0.9961, Valid: 0.9856, Best: 0.9870\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 2.4153895378112793 | KNN Loss: 2.4009969234466553 | CLS Loss: 0.014392714016139507\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 2.410770893096924 | KNN Loss: 2.4065916538238525 | CLS Loss: 0.004179201554507017\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 2.3967440128326416 | KNN Loss: 2.3813583850860596 | CLS Loss: 0.015385637059807777\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 2.4072391986846924 | KNN Loss: 2.4031331539154053 | CLS Loss: 0.004106159787625074\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 2.430143356323242 | KNN Loss: 2.418013095855713 | CLS Loss: 0.01213030144572258\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 2.4064550399780273 | KNN Loss: 2.3844990730285645 | CLS Loss: 0.021956004202365875\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 2.4101030826568604 | KNN Loss: 2.3699967861175537 | CLS Loss: 0.04010622948408127\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 2.4115548133850098 | KNN Loss: 2.3912510871887207 | CLS Loss: 0.020303694531321526\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 2.439333200454712 | KNN Loss: 2.4182138442993164 | CLS Loss: 0.021119313314557076\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 2.403404951095581 | KNN Loss: 2.3984375 | CLS Loss: 0.004967509303241968\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 2.4354605674743652 | KNN Loss: 2.4104321002960205 | CLS Loss: 0.025028428062796593\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 2.4025228023529053 | KNN Loss: 2.393139123916626 | CLS Loss: 0.009383791126310825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 2.4168472290039062 | KNN Loss: 2.413574695587158 | CLS Loss: 0.0032726323697715998\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 2.425452709197998 | KNN Loss: 2.415271282196045 | CLS Loss: 0.010181366465985775\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 2.412182092666626 | KNN Loss: 2.383709192276001 | CLS Loss: 0.02847299911081791\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 2.4597644805908203 | KNN Loss: 2.446932077407837 | CLS Loss: 0.012832383625209332\n",
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 2.4042937755584717 | KNN Loss: 2.395169258117676 | CLS Loss: 0.009124553762376308\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 2.4052982330322266 | KNN Loss: 2.4007411003112793 | CLS Loss: 0.004557175096124411\n",
      "Epoch: 105, Loss: 2.4173, Train: 0.9962, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 2.393795967102051 | KNN Loss: 2.3769400119781494 | CLS Loss: 0.016855992376804352\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 2.4166483879089355 | KNN Loss: 2.3959546089172363 | CLS Loss: 0.020693663507699966\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 2.4080188274383545 | KNN Loss: 2.3990514278411865 | CLS Loss: 0.008967427536845207\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 2.415032386779785 | KNN Loss: 2.411794424057007 | CLS Loss: 0.003237947355955839\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 2.454324722290039 | KNN Loss: 2.403374671936035 | CLS Loss: 0.05094998702406883\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 2.416541576385498 | KNN Loss: 2.387835741043091 | CLS Loss: 0.02870582602918148\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 2.364955186843872 | KNN Loss: 2.3621225357055664 | CLS Loss: 0.0028327698819339275\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 2.3980069160461426 | KNN Loss: 2.3929736614227295 | CLS Loss: 0.005033154506236315\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 2.388078212738037 | KNN Loss: 2.3823134899139404 | CLS Loss: 0.005764788016676903\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 2.4375596046447754 | KNN Loss: 2.4339828491210938 | CLS Loss: 0.003576855408027768\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 2.425147533416748 | KNN Loss: 2.4097416400909424 | CLS Loss: 0.015405864454805851\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 2.421617031097412 | KNN Loss: 2.4072425365448 | CLS Loss: 0.014374453574419022\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 2.4179816246032715 | KNN Loss: 2.413616180419922 | CLS Loss: 0.004365396685898304\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 2.3960466384887695 | KNN Loss: 2.388887405395508 | CLS Loss: 0.007159245200455189\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 2.3839805126190186 | KNN Loss: 2.381392478942871 | CLS Loss: 0.0025879815220832825\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 2.4156367778778076 | KNN Loss: 2.388521909713745 | CLS Loss: 0.02711482159793377\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 2.480245351791382 | KNN Loss: 2.4289329051971436 | CLS Loss: 0.05131238326430321\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 2.4244680404663086 | KNN Loss: 2.4188923835754395 | CLS Loss: 0.005575584247708321\n",
      "Epoch: 106, Loss: 2.4126, Train: 0.9962, Valid: 0.9862, Best: 0.9870\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 2.38563871383667 | KNN Loss: 2.382072687149048 | CLS Loss: 0.0035659775603562593\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 2.4213757514953613 | KNN Loss: 2.415186643600464 | CLS Loss: 0.0061891651712358\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 2.4006803035736084 | KNN Loss: 2.379195213317871 | CLS Loss: 0.021485166624188423\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 2.444483757019043 | KNN Loss: 2.4146525859832764 | CLS Loss: 0.029831094667315483\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 2.4074995517730713 | KNN Loss: 2.397254228591919 | CLS Loss: 0.010245355777442455\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 2.4013171195983887 | KNN Loss: 2.3936731815338135 | CLS Loss: 0.007643834687769413\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 2.411674976348877 | KNN Loss: 2.397935152053833 | CLS Loss: 0.013739746063947678\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 2.388345241546631 | KNN Loss: 2.3669519424438477 | CLS Loss: 0.021393371745944023\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 2.4204514026641846 | KNN Loss: 2.4186103343963623 | CLS Loss: 0.001841146731749177\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 2.4435572624206543 | KNN Loss: 2.425872325897217 | CLS Loss: 0.017684856429696083\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 2.3862948417663574 | KNN Loss: 2.3803770542144775 | CLS Loss: 0.005917778238654137\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 2.414900064468384 | KNN Loss: 2.3938369750976562 | CLS Loss: 0.021063189953565598\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 2.4075379371643066 | KNN Loss: 2.3989615440368652 | CLS Loss: 0.008576353080570698\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 2.4236927032470703 | KNN Loss: 2.405093193054199 | CLS Loss: 0.018599458038806915\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 2.398591995239258 | KNN Loss: 2.3829710483551025 | CLS Loss: 0.015620863996446133\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 2.4275383949279785 | KNN Loss: 2.426140546798706 | CLS Loss: 0.0013979190262034535\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 2.407823085784912 | KNN Loss: 2.4039418697357178 | CLS Loss: 0.003881166921928525\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 2.4248716831207275 | KNN Loss: 2.417811632156372 | CLS Loss: 0.0070601338520646095\n",
      "Epoch: 107, Loss: 2.4145, Train: 0.9964, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 2.442845106124878 | KNN Loss: 2.4353764057159424 | CLS Loss: 0.007468814495950937\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 2.410750150680542 | KNN Loss: 2.398446798324585 | CLS Loss: 0.012303426861763\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 2.4080259799957275 | KNN Loss: 2.387416362762451 | CLS Loss: 0.02060973271727562\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 2.4118294715881348 | KNN Loss: 2.3982431888580322 | CLS Loss: 0.013586306944489479\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 2.3825814723968506 | KNN Loss: 2.374258279800415 | CLS Loss: 0.008323147892951965\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 2.431403160095215 | KNN Loss: 2.413206100463867 | CLS Loss: 0.018197176977992058\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 2.3875322341918945 | KNN Loss: 2.3830418586730957 | CLS Loss: 0.00449047377333045\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 2.3905446529388428 | KNN Loss: 2.3872733116149902 | CLS Loss: 0.003271332010626793\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 2.3893933296203613 | KNN Loss: 2.381617546081543 | CLS Loss: 0.007775689009577036\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 2.4070537090301514 | KNN Loss: 2.398287773132324 | CLS Loss: 0.008766045793890953\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 2.397663116455078 | KNN Loss: 2.3799211978912354 | CLS Loss: 0.01774180866777897\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 2.3952713012695312 | KNN Loss: 2.38486909866333 | CLS Loss: 0.010402320884168148\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 2.379732131958008 | KNN Loss: 2.368462085723877 | CLS Loss: 0.011270115152001381\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 2.4176321029663086 | KNN Loss: 2.4152328968048096 | CLS Loss: 0.0023992215283215046\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 2.4120755195617676 | KNN Loss: 2.398239850997925 | CLS Loss: 0.013835696503520012\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 2.40743088722229 | KNN Loss: 2.3978824615478516 | CLS Loss: 0.009548415429890156\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 2.4289801120758057 | KNN Loss: 2.4080138206481934 | CLS Loss: 0.02096618339419365\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 2.42895245552063 | KNN Loss: 2.4095325469970703 | CLS Loss: 0.019419817253947258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Loss: 2.4169, Train: 0.9967, Valid: 0.9866, Best: 0.9870\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 2.417480945587158 | KNN Loss: 2.3990001678466797 | CLS Loss: 0.018480826169252396\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 2.3961849212646484 | KNN Loss: 2.3906407356262207 | CLS Loss: 0.005544242914766073\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 2.3604087829589844 | KNN Loss: 2.3551676273345947 | CLS Loss: 0.005241159815341234\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 2.4372761249542236 | KNN Loss: 2.4272913932800293 | CLS Loss: 0.00998464785516262\n",
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 2.4340336322784424 | KNN Loss: 2.4157543182373047 | CLS Loss: 0.01827928237617016\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 2.4266507625579834 | KNN Loss: 2.415034055709839 | CLS Loss: 0.011616635136306286\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 2.4249379634857178 | KNN Loss: 2.421326160430908 | CLS Loss: 0.003611853811889887\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 2.4292445182800293 | KNN Loss: 2.4186599254608154 | CLS Loss: 0.010584475472569466\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 2.4440765380859375 | KNN Loss: 2.422210693359375 | CLS Loss: 0.021865788847208023\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 2.445894718170166 | KNN Loss: 2.42724609375 | CLS Loss: 0.018648570403456688\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 2.4157750606536865 | KNN Loss: 2.402017116546631 | CLS Loss: 0.013757866807281971\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 2.429469347000122 | KNN Loss: 2.4015376567840576 | CLS Loss: 0.027931619435548782\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 2.412429094314575 | KNN Loss: 2.3815205097198486 | CLS Loss: 0.030908605083823204\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 2.4282965660095215 | KNN Loss: 2.4191622734069824 | CLS Loss: 0.009134315885603428\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 2.3665781021118164 | KNN Loss: 2.349977970123291 | CLS Loss: 0.0166001133620739\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 2.4274439811706543 | KNN Loss: 2.411264419555664 | CLS Loss: 0.016179539263248444\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 2.437901020050049 | KNN Loss: 2.401176691055298 | CLS Loss: 0.03672422468662262\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 2.4334986209869385 | KNN Loss: 2.4031007289886475 | CLS Loss: 0.03039793111383915\n",
      "Epoch: 109, Loss: 2.4136, Train: 0.9952, Valid: 0.9854, Best: 0.9870\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 2.4348742961883545 | KNN Loss: 2.421093463897705 | CLS Loss: 0.013780834153294563\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 2.4185259342193604 | KNN Loss: 2.412311315536499 | CLS Loss: 0.006214527878910303\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 2.4030773639678955 | KNN Loss: 2.3980445861816406 | CLS Loss: 0.005032788030803204\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 2.371647357940674 | KNN Loss: 2.3650267124176025 | CLS Loss: 0.006620642263442278\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 2.4016454219818115 | KNN Loss: 2.3945255279541016 | CLS Loss: 0.007119783200323582\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 2.4021801948547363 | KNN Loss: 2.3831217288970947 | CLS Loss: 0.019058365374803543\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 2.4479100704193115 | KNN Loss: 2.440959930419922 | CLS Loss: 0.006950038019567728\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 2.5004968643188477 | KNN Loss: 2.46439790725708 | CLS Loss: 0.03609893098473549\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 2.4009265899658203 | KNN Loss: 2.3875539302825928 | CLS Loss: 0.01337263360619545\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 2.4141173362731934 | KNN Loss: 2.3866117000579834 | CLS Loss: 0.027505608275532722\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 2.4187121391296387 | KNN Loss: 2.4144155979156494 | CLS Loss: 0.004296464845538139\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 2.3834197521209717 | KNN Loss: 2.379222869873047 | CLS Loss: 0.004196798894554377\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 2.4455795288085938 | KNN Loss: 2.4235358238220215 | CLS Loss: 0.022043650969862938\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 2.428342819213867 | KNN Loss: 2.4192473888397217 | CLS Loss: 0.00909541267901659\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 2.4193215370178223 | KNN Loss: 2.3918628692626953 | CLS Loss: 0.02745859883725643\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 2.4019277095794678 | KNN Loss: 2.3895628452301025 | CLS Loss: 0.012364867143332958\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 2.398022413253784 | KNN Loss: 2.390310525894165 | CLS Loss: 0.007711820304393768\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 2.4215471744537354 | KNN Loss: 2.4192795753479004 | CLS Loss: 0.0022675697691738605\n",
      "Epoch: 110, Loss: 2.4170, Train: 0.9966, Valid: 0.9867, Best: 0.9870\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 2.3949666023254395 | KNN Loss: 2.382380485534668 | CLS Loss: 0.012586038559675217\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 2.433640956878662 | KNN Loss: 2.4318647384643555 | CLS Loss: 0.0017761243507266045\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 2.4157228469848633 | KNN Loss: 2.39949107170105 | CLS Loss: 0.0162318367511034\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 2.4047491550445557 | KNN Loss: 2.385880947113037 | CLS Loss: 0.0188680998980999\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 2.3852829933166504 | KNN Loss: 2.368910074234009 | CLS Loss: 0.016372909769415855\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 2.4017581939697266 | KNN Loss: 2.3813111782073975 | CLS Loss: 0.020446987822651863\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 2.40336012840271 | KNN Loss: 2.3865315914154053 | CLS Loss: 0.016828643158078194\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 2.43462872505188 | KNN Loss: 2.413644552230835 | CLS Loss: 0.02098410204052925\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 2.4254167079925537 | KNN Loss: 2.397465944290161 | CLS Loss: 0.027950730174779892\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 2.436976909637451 | KNN Loss: 2.416172742843628 | CLS Loss: 0.020804280415177345\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 2.4099719524383545 | KNN Loss: 2.400315284729004 | CLS Loss: 0.009656761772930622\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 2.404130220413208 | KNN Loss: 2.3631770610809326 | CLS Loss: 0.040953051298856735\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 2.4523110389709473 | KNN Loss: 2.428096294403076 | CLS Loss: 0.024214651435613632\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 2.3858628273010254 | KNN Loss: 2.3757269382476807 | CLS Loss: 0.010135817341506481\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 2.3908674716949463 | KNN Loss: 2.3730764389038086 | CLS Loss: 0.017790919169783592\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 2.464374542236328 | KNN Loss: 2.4567782878875732 | CLS Loss: 0.00759635865688324\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 2.445174217224121 | KNN Loss: 2.42061185836792 | CLS Loss: 0.024562465026974678\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 2.4097118377685547 | KNN Loss: 2.3922817707061768 | CLS Loss: 0.017430024221539497\n",
      "Epoch: 111, Loss: 2.4160, Train: 0.9953, Valid: 0.9843, Best: 0.9870\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 2.448077917098999 | KNN Loss: 2.4302539825439453 | CLS Loss: 0.01782398298382759\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 2.4406332969665527 | KNN Loss: 2.43668270111084 | CLS Loss: 0.0039505488239228725\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 2.403116464614868 | KNN Loss: 2.3840746879577637 | CLS Loss: 0.01904166489839554\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 2.394444227218628 | KNN Loss: 2.383798360824585 | CLS Loss: 0.010645902715623379\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 2.4157588481903076 | KNN Loss: 2.4018685817718506 | CLS Loss: 0.013890364207327366\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 2.4188458919525146 | KNN Loss: 2.3891959190368652 | CLS Loss: 0.029650066047906876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 2.4094011783599854 | KNN Loss: 2.406369686126709 | CLS Loss: 0.0030314791947603226\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 2.398012399673462 | KNN Loss: 2.3939149379730225 | CLS Loss: 0.004097490571439266\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 2.429311990737915 | KNN Loss: 2.414421796798706 | CLS Loss: 0.01489012036472559\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 2.4133269786834717 | KNN Loss: 2.407501459121704 | CLS Loss: 0.0058255321346223354\n",
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 2.3620738983154297 | KNN Loss: 2.3573949337005615 | CLS Loss: 0.004678880330175161\n",
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 2.3816614151000977 | KNN Loss: 2.3783910274505615 | CLS Loss: 0.0032704814802855253\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 2.4178731441497803 | KNN Loss: 2.4011666774749756 | CLS Loss: 0.016706442460417747\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 2.3879244327545166 | KNN Loss: 2.383666753768921 | CLS Loss: 0.004257565829902887\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 2.382366180419922 | KNN Loss: 2.372112274169922 | CLS Loss: 0.010253828950226307\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 2.414285182952881 | KNN Loss: 2.380908250808716 | CLS Loss: 0.0333770215511322\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 2.395751953125 | KNN Loss: 2.385777473449707 | CLS Loss: 0.009974493645131588\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 2.4057629108428955 | KNN Loss: 2.402427911758423 | CLS Loss: 0.0033350628800690174\n",
      "Epoch: 112, Loss: 2.4121, Train: 0.9968, Valid: 0.9867, Best: 0.9870\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 2.3885767459869385 | KNN Loss: 2.3868355751037598 | CLS Loss: 0.0017410723958164454\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 2.383544445037842 | KNN Loss: 2.3719449043273926 | CLS Loss: 0.011599475517868996\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 2.3877623081207275 | KNN Loss: 2.380056858062744 | CLS Loss: 0.0077054756693542\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 2.381126880645752 | KNN Loss: 2.367063283920288 | CLS Loss: 0.014063546434044838\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 2.3927650451660156 | KNN Loss: 2.379148006439209 | CLS Loss: 0.013616934418678284\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 2.413126230239868 | KNN Loss: 2.4073867797851562 | CLS Loss: 0.005739469081163406\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 2.3985238075256348 | KNN Loss: 2.3947768211364746 | CLS Loss: 0.003746938891708851\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 2.4408183097839355 | KNN Loss: 2.436983108520508 | CLS Loss: 0.003835221054032445\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 2.414250373840332 | KNN Loss: 2.4001500606536865 | CLS Loss: 0.01410042867064476\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 2.3995048999786377 | KNN Loss: 2.387047529220581 | CLS Loss: 0.012457355856895447\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 2.434684991836548 | KNN Loss: 2.4176859855651855 | CLS Loss: 0.01699904538691044\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 2.421391487121582 | KNN Loss: 2.390167236328125 | CLS Loss: 0.03122420236468315\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 2.4231088161468506 | KNN Loss: 2.4200751781463623 | CLS Loss: 0.0030336861964315176\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 2.40360689163208 | KNN Loss: 2.3730785846710205 | CLS Loss: 0.03052825853228569\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 2.4046921730041504 | KNN Loss: 2.3964691162109375 | CLS Loss: 0.008223095908761024\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 2.397181749343872 | KNN Loss: 2.3879642486572266 | CLS Loss: 0.009217409417033195\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 2.4270408153533936 | KNN Loss: 2.421368360519409 | CLS Loss: 0.005672338418662548\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 2.429037570953369 | KNN Loss: 2.42297625541687 | CLS Loss: 0.0060612210072577\n",
      "Epoch: 113, Loss: 2.4127, Train: 0.9954, Valid: 0.9846, Best: 0.9870\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 2.4320688247680664 | KNN Loss: 2.39115309715271 | CLS Loss: 0.04091581702232361\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 2.421649694442749 | KNN Loss: 2.3918042182922363 | CLS Loss: 0.029845431447029114\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 2.3929672241210938 | KNN Loss: 2.381476402282715 | CLS Loss: 0.011490777134895325\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 2.4601922035217285 | KNN Loss: 2.448561429977417 | CLS Loss: 0.011630753055214882\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 2.379732131958008 | KNN Loss: 2.372668743133545 | CLS Loss: 0.007063412573188543\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 2.427906036376953 | KNN Loss: 2.397564649581909 | CLS Loss: 0.03034139983355999\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 2.40313982963562 | KNN Loss: 2.400216817855835 | CLS Loss: 0.0029230602085590363\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 2.404163360595703 | KNN Loss: 2.3988747596740723 | CLS Loss: 0.005288506392389536\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 2.3911776542663574 | KNN Loss: 2.3885369300842285 | CLS Loss: 0.002640723716467619\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 2.3851685523986816 | KNN Loss: 2.3837149143218994 | CLS Loss: 0.0014536440139636397\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 2.430339813232422 | KNN Loss: 2.425063133239746 | CLS Loss: 0.005276632960885763\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 2.4152162075042725 | KNN Loss: 2.3995721340179443 | CLS Loss: 0.015644142404198647\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 2.4356300830841064 | KNN Loss: 2.4048168659210205 | CLS Loss: 0.030813144519925117\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 2.3781003952026367 | KNN Loss: 2.3721561431884766 | CLS Loss: 0.005944260396063328\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 2.4000139236450195 | KNN Loss: 2.386117935180664 | CLS Loss: 0.013896062970161438\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 2.4439504146575928 | KNN Loss: 2.420968770980835 | CLS Loss: 0.022981682792305946\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 2.426345109939575 | KNN Loss: 2.4163918495178223 | CLS Loss: 0.009953365661203861\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 2.4096269607543945 | KNN Loss: 2.4040732383728027 | CLS Loss: 0.005553819704800844\n",
      "Epoch: 114, Loss: 2.4128, Train: 0.9953, Valid: 0.9849, Best: 0.9870\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 2.41987943649292 | KNN Loss: 2.4059841632843018 | CLS Loss: 0.013895292766392231\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 2.4246950149536133 | KNN Loss: 2.396022081375122 | CLS Loss: 0.028672877699136734\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 2.411926031112671 | KNN Loss: 2.406020164489746 | CLS Loss: 0.0059059252962470055\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 2.4165375232696533 | KNN Loss: 2.40779185295105 | CLS Loss: 0.008745613507926464\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 2.4360907077789307 | KNN Loss: 2.423973321914673 | CLS Loss: 0.012117313221096992\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 2.4367313385009766 | KNN Loss: 2.3992316722869873 | CLS Loss: 0.037499576807022095\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 2.4233791828155518 | KNN Loss: 2.402606248855591 | CLS Loss: 0.02077298052608967\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 2.403400421142578 | KNN Loss: 2.3889758586883545 | CLS Loss: 0.014424450695514679\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 2.3956332206726074 | KNN Loss: 2.3944644927978516 | CLS Loss: 0.0011688151862472296\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 2.420884132385254 | KNN Loss: 2.4072484970092773 | CLS Loss: 0.013635745272040367\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 2.451535940170288 | KNN Loss: 2.4311892986297607 | CLS Loss: 0.020346667617559433\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 2.4093339443206787 | KNN Loss: 2.389211654663086 | CLS Loss: 0.02012229897081852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 2.4208109378814697 | KNN Loss: 2.4130618572235107 | CLS Loss: 0.007749016396701336\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 2.4110419750213623 | KNN Loss: 2.405611991882324 | CLS Loss: 0.0054300385527312756\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 2.4018967151641846 | KNN Loss: 2.3929219245910645 | CLS Loss: 0.008974701166152954\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 2.371898651123047 | KNN Loss: 2.368736505508423 | CLS Loss: 0.0031620431691408157\n",
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 2.4303157329559326 | KNN Loss: 2.4179165363311768 | CLS Loss: 0.012399178929626942\n",
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 2.430546522140503 | KNN Loss: 2.425171375274658 | CLS Loss: 0.005375260021537542\n",
      "Epoch: 115, Loss: 2.4175, Train: 0.9955, Valid: 0.9848, Best: 0.9870\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 2.410747528076172 | KNN Loss: 2.391237735748291 | CLS Loss: 0.01950974389910698\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 2.4199681282043457 | KNN Loss: 2.4133400917053223 | CLS Loss: 0.0066280062310397625\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 2.414499044418335 | KNN Loss: 2.407191276550293 | CLS Loss: 0.007307864259928465\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 2.408087730407715 | KNN Loss: 2.4034483432769775 | CLS Loss: 0.004639461636543274\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 2.3634681701660156 | KNN Loss: 2.356368064880371 | CLS Loss: 0.007100199814885855\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 2.4130992889404297 | KNN Loss: 2.4049770832061768 | CLS Loss: 0.008122110739350319\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 2.365269422531128 | KNN Loss: 2.3623225688934326 | CLS Loss: 0.0029468885622918606\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 2.375903606414795 | KNN Loss: 2.374241590499878 | CLS Loss: 0.0016619438538327813\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 2.417506694793701 | KNN Loss: 2.4136993885040283 | CLS Loss: 0.003807194298133254\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 2.419734001159668 | KNN Loss: 2.394382953643799 | CLS Loss: 0.025351081043481827\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 2.4151508808135986 | KNN Loss: 2.411052703857422 | CLS Loss: 0.004098113626241684\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 2.4453160762786865 | KNN Loss: 2.4298956394195557 | CLS Loss: 0.015420490875840187\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 2.4327940940856934 | KNN Loss: 2.4251651763916016 | CLS Loss: 0.007629035972058773\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 2.3838818073272705 | KNN Loss: 2.376893997192383 | CLS Loss: 0.006987909786403179\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 2.4511489868164062 | KNN Loss: 2.4379403591156006 | CLS Loss: 0.013208682648837566\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 2.457624673843384 | KNN Loss: 2.4403209686279297 | CLS Loss: 0.017303595319390297\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 2.3983402252197266 | KNN Loss: 2.395653247833252 | CLS Loss: 0.002686914522200823\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 2.3927512168884277 | KNN Loss: 2.389249086380005 | CLS Loss: 0.0035020187497138977\n",
      "Epoch: 116, Loss: 2.4113, Train: 0.9963, Valid: 0.9857, Best: 0.9870\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 2.428096294403076 | KNN Loss: 2.403268814086914 | CLS Loss: 0.02482740767300129\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 2.388873815536499 | KNN Loss: 2.376904010772705 | CLS Loss: 0.011969882063567638\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 2.378349542617798 | KNN Loss: 2.367464780807495 | CLS Loss: 0.010884699411690235\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 2.3803203105926514 | KNN Loss: 2.3658628463745117 | CLS Loss: 0.014457509852945805\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 2.4364237785339355 | KNN Loss: 2.432527780532837 | CLS Loss: 0.0038958946242928505\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 2.422213315963745 | KNN Loss: 2.404362201690674 | CLS Loss: 0.01785111054778099\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 2.4439640045166016 | KNN Loss: 2.4329376220703125 | CLS Loss: 0.011026476509869099\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 2.404317855834961 | KNN Loss: 2.3849120140075684 | CLS Loss: 0.0194059070199728\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 2.3986620903015137 | KNN Loss: 2.38853120803833 | CLS Loss: 0.010130822658538818\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 2.4424893856048584 | KNN Loss: 2.43510103225708 | CLS Loss: 0.007388395722955465\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 2.4054901599884033 | KNN Loss: 2.384120225906372 | CLS Loss: 0.021370036527514458\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 2.3856148719787598 | KNN Loss: 2.3643407821655273 | CLS Loss: 0.021274061873555183\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 2.4414193630218506 | KNN Loss: 2.4328389167785645 | CLS Loss: 0.008580402471125126\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 2.3928728103637695 | KNN Loss: 2.382230758666992 | CLS Loss: 0.01064208708703518\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 2.418536424636841 | KNN Loss: 2.407174587249756 | CLS Loss: 0.011361840181052685\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 2.3849573135375977 | KNN Loss: 2.3803093433380127 | CLS Loss: 0.004647985566407442\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 2.433600664138794 | KNN Loss: 2.424546480178833 | CLS Loss: 0.009054135531187057\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 2.41576886177063 | KNN Loss: 2.405257225036621 | CLS Loss: 0.010511735454201698\n",
      "Epoch: 117, Loss: 2.4085, Train: 0.9963, Valid: 0.9863, Best: 0.9870\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 2.379734992980957 | KNN Loss: 2.3782029151916504 | CLS Loss: 0.0015321121318265796\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 2.4221949577331543 | KNN Loss: 2.4074113368988037 | CLS Loss: 0.01478351280093193\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 2.406046152114868 | KNN Loss: 2.386245012283325 | CLS Loss: 0.01980111002922058\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 2.409316062927246 | KNN Loss: 2.4043102264404297 | CLS Loss: 0.005005824379622936\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 2.389850616455078 | KNN Loss: 2.376840829849243 | CLS Loss: 0.01300977636128664\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 2.459007501602173 | KNN Loss: 2.430006504058838 | CLS Loss: 0.029000908136367798\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 2.4254493713378906 | KNN Loss: 2.4050745964050293 | CLS Loss: 0.020374741405248642\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 2.4280591011047363 | KNN Loss: 2.404815196990967 | CLS Loss: 0.023243926465511322\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 2.412163734436035 | KNN Loss: 2.396864175796509 | CLS Loss: 0.01529950276017189\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 2.4095587730407715 | KNN Loss: 2.400651216506958 | CLS Loss: 0.008907480165362358\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 2.3706066608428955 | KNN Loss: 2.365051031112671 | CLS Loss: 0.005555545911192894\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 2.402688503265381 | KNN Loss: 2.396582841873169 | CLS Loss: 0.006105557084083557\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 2.4065775871276855 | KNN Loss: 2.390979528427124 | CLS Loss: 0.015598101541399956\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 2.429412603378296 | KNN Loss: 2.426377058029175 | CLS Loss: 0.003035650821402669\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 2.460663080215454 | KNN Loss: 2.4516544342041016 | CLS Loss: 0.009008627384901047\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 2.4369325637817383 | KNN Loss: 2.4078710079193115 | CLS Loss: 0.02906154841184616\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 2.404406785964966 | KNN Loss: 2.3964335918426514 | CLS Loss: 0.007973152212798595\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 2.4036612510681152 | KNN Loss: 2.3925960063934326 | CLS Loss: 0.011065256781876087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118, Loss: 2.4116, Train: 0.9953, Valid: 0.9844, Best: 0.9870\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 2.4362974166870117 | KNN Loss: 2.4298620223999023 | CLS Loss: 0.006435394752770662\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 2.4023447036743164 | KNN Loss: 2.390296459197998 | CLS Loss: 0.01204831525683403\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 2.404844284057617 | KNN Loss: 2.3731110095977783 | CLS Loss: 0.03173327073454857\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 2.4085395336151123 | KNN Loss: 2.3965132236480713 | CLS Loss: 0.012026423588395119\n",
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 2.4360713958740234 | KNN Loss: 2.4265594482421875 | CLS Loss: 0.009512060321867466\n",
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 2.4272701740264893 | KNN Loss: 2.4199352264404297 | CLS Loss: 0.0073348358273506165\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 2.427964210510254 | KNN Loss: 2.4036123752593994 | CLS Loss: 0.024351801723241806\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 2.4072611331939697 | KNN Loss: 2.400256633758545 | CLS Loss: 0.007004581391811371\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 2.463125467300415 | KNN Loss: 2.443458080291748 | CLS Loss: 0.019667498767375946\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 2.388946056365967 | KNN Loss: 2.3685803413391113 | CLS Loss: 0.0203656367957592\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 2.391510009765625 | KNN Loss: 2.3681459426879883 | CLS Loss: 0.023364007472991943\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 2.362290143966675 | KNN Loss: 2.3588249683380127 | CLS Loss: 0.003465218935161829\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 2.377224922180176 | KNN Loss: 2.3658201694488525 | CLS Loss: 0.011404693126678467\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 2.423607110977173 | KNN Loss: 2.4140830039978027 | CLS Loss: 0.009524201042950153\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 2.4296207427978516 | KNN Loss: 2.394036293029785 | CLS Loss: 0.03558444604277611\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 2.4322433471679688 | KNN Loss: 2.4244887828826904 | CLS Loss: 0.007754480466246605\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 2.427410840988159 | KNN Loss: 2.387186288833618 | CLS Loss: 0.040224578231573105\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 2.394850492477417 | KNN Loss: 2.390906572341919 | CLS Loss: 0.003943941555917263\n",
      "Epoch: 119, Loss: 2.4129, Train: 0.9970, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 2.3870697021484375 | KNN Loss: 2.3754897117614746 | CLS Loss: 0.011580054648220539\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 2.3804900646209717 | KNN Loss: 2.3745572566986084 | CLS Loss: 0.0059327976778149605\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 2.4095821380615234 | KNN Loss: 2.4040894508361816 | CLS Loss: 0.0054925838485360146\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 2.4334959983825684 | KNN Loss: 2.432544231414795 | CLS Loss: 0.0009517533471807837\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 2.379204750061035 | KNN Loss: 2.3703482151031494 | CLS Loss: 0.008856425993144512\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 2.4054627418518066 | KNN Loss: 2.3898255825042725 | CLS Loss: 0.015637189149856567\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 2.4333994388580322 | KNN Loss: 2.420449733734131 | CLS Loss: 0.01294968742877245\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 2.3755481243133545 | KNN Loss: 2.3655877113342285 | CLS Loss: 0.009960426948964596\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 2.391387462615967 | KNN Loss: 2.380873680114746 | CLS Loss: 0.010513846762478352\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 2.4224131107330322 | KNN Loss: 2.417546033859253 | CLS Loss: 0.004867027048021555\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 2.425161838531494 | KNN Loss: 2.4232337474823 | CLS Loss: 0.0019280558917671442\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 2.4202957153320312 | KNN Loss: 2.41558575630188 | CLS Loss: 0.004709894768893719\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 2.377502918243408 | KNN Loss: 2.3742690086364746 | CLS Loss: 0.0032338311430066824\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 2.4238121509552 | KNN Loss: 2.414111614227295 | CLS Loss: 0.009700621478259563\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 2.435833215713501 | KNN Loss: 2.425166606903076 | CLS Loss: 0.010666689835488796\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 2.421329975128174 | KNN Loss: 2.414043426513672 | CLS Loss: 0.007286621257662773\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 2.383084774017334 | KNN Loss: 2.3688907623291016 | CLS Loss: 0.01419389620423317\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 2.380185842514038 | KNN Loss: 2.3629231452941895 | CLS Loss: 0.017262673005461693\n",
      "Epoch: 120, Loss: 2.4111, Train: 0.9958, Valid: 0.9849, Best: 0.9870\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 2.3808305263519287 | KNN Loss: 2.3703911304473877 | CLS Loss: 0.010439429432153702\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 2.4455020427703857 | KNN Loss: 2.4253015518188477 | CLS Loss: 0.02020048163831234\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 2.4518675804138184 | KNN Loss: 2.443046808242798 | CLS Loss: 0.008820652961730957\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 2.427576780319214 | KNN Loss: 2.4101436138153076 | CLS Loss: 0.017433226108551025\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 2.4427638053894043 | KNN Loss: 2.4093635082244873 | CLS Loss: 0.033400196582078934\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 2.4366376399993896 | KNN Loss: 2.433814764022827 | CLS Loss: 0.002822868525981903\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 2.407822608947754 | KNN Loss: 2.40551495552063 | CLS Loss: 0.002307555405423045\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 2.4079596996307373 | KNN Loss: 2.403597116470337 | CLS Loss: 0.004362474195659161\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 2.4017903804779053 | KNN Loss: 2.3992974758148193 | CLS Loss: 0.002492987783625722\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 2.404465675354004 | KNN Loss: 2.397233486175537 | CLS Loss: 0.0072321584448218346\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 2.4375946521759033 | KNN Loss: 2.4201295375823975 | CLS Loss: 0.01746513321995735\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 2.398373603820801 | KNN Loss: 2.3869638442993164 | CLS Loss: 0.011409803293645382\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 2.431428909301758 | KNN Loss: 2.421999216079712 | CLS Loss: 0.009429601021111012\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 2.428466320037842 | KNN Loss: 2.413982391357422 | CLS Loss: 0.014484001323580742\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 2.4057233333587646 | KNN Loss: 2.3914568424224854 | CLS Loss: 0.014266571961343288\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 2.3844943046569824 | KNN Loss: 2.3663909435272217 | CLS Loss: 0.018103431910276413\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 2.4288036823272705 | KNN Loss: 2.4113759994506836 | CLS Loss: 0.017427634447813034\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 2.4680590629577637 | KNN Loss: 2.463864803314209 | CLS Loss: 0.004194345325231552\n",
      "Epoch: 121, Loss: 2.4167, Train: 0.9956, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 2.4596471786499023 | KNN Loss: 2.4285902976989746 | CLS Loss: 0.0310568418353796\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 2.42020320892334 | KNN Loss: 2.384857177734375 | CLS Loss: 0.03534594923257828\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 2.4282333850860596 | KNN Loss: 2.424982786178589 | CLS Loss: 0.0032506571151316166\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 2.451629638671875 | KNN Loss: 2.4322643280029297 | CLS Loss: 0.019365400075912476\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 2.3833909034729004 | KNN Loss: 2.3773529529571533 | CLS Loss: 0.006037927232682705\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 2.420126438140869 | KNN Loss: 2.412929058074951 | CLS Loss: 0.007197410333901644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 2.3907456398010254 | KNN Loss: 2.3761260509490967 | CLS Loss: 0.014619573950767517\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 2.437025785446167 | KNN Loss: 2.430744171142578 | CLS Loss: 0.006281713955104351\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 2.413574695587158 | KNN Loss: 2.402433395385742 | CLS Loss: 0.011141324415802956\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 2.4266183376312256 | KNN Loss: 2.4154694080352783 | CLS Loss: 0.011148910038173199\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 2.4263272285461426 | KNN Loss: 2.403916835784912 | CLS Loss: 0.022410370409488678\n",
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 2.412644624710083 | KNN Loss: 2.4009196758270264 | CLS Loss: 0.011724921874701977\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 2.437598705291748 | KNN Loss: 2.4150497913360596 | CLS Loss: 0.022548945620656013\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 2.3856568336486816 | KNN Loss: 2.3670971393585205 | CLS Loss: 0.018559670075774193\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 2.4005420207977295 | KNN Loss: 2.389962673187256 | CLS Loss: 0.010579337365925312\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 2.4398488998413086 | KNN Loss: 2.4260153770446777 | CLS Loss: 0.0138334259390831\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 2.395627737045288 | KNN Loss: 2.388059139251709 | CLS Loss: 0.007568565662950277\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 2.406463146209717 | KNN Loss: 2.3980395793914795 | CLS Loss: 0.00842367485165596\n",
      "Epoch: 122, Loss: 2.4128, Train: 0.9971, Valid: 0.9865, Best: 0.9870\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 2.4260401725769043 | KNN Loss: 2.40505313873291 | CLS Loss: 0.020987076684832573\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 2.3663856983184814 | KNN Loss: 2.362011432647705 | CLS Loss: 0.004374346695840359\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 2.4389700889587402 | KNN Loss: 2.4355390071868896 | CLS Loss: 0.003431181889027357\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 2.438410997390747 | KNN Loss: 2.4333994388580322 | CLS Loss: 0.005011543165892363\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 2.4345459938049316 | KNN Loss: 2.42419695854187 | CLS Loss: 0.010349053889513016\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 2.4137232303619385 | KNN Loss: 2.4026010036468506 | CLS Loss: 0.011122127994894981\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 2.4356625080108643 | KNN Loss: 2.414093494415283 | CLS Loss: 0.02156897448003292\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 2.3919453620910645 | KNN Loss: 2.3809237480163574 | CLS Loss: 0.011021710932254791\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 2.3856687545776367 | KNN Loss: 2.3790063858032227 | CLS Loss: 0.006662287749350071\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 2.3989641666412354 | KNN Loss: 2.3852341175079346 | CLS Loss: 0.013730061240494251\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 2.4162955284118652 | KNN Loss: 2.385441303253174 | CLS Loss: 0.0308542437851429\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 2.4136011600494385 | KNN Loss: 2.4094033241271973 | CLS Loss: 0.004197810310870409\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 2.4004008769989014 | KNN Loss: 2.3871853351593018 | CLS Loss: 0.013215500861406326\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 2.4131062030792236 | KNN Loss: 2.39676570892334 | CLS Loss: 0.016340579837560654\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 2.420243978500366 | KNN Loss: 2.40364933013916 | CLS Loss: 0.016594668850302696\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 2.398974895477295 | KNN Loss: 2.3870158195495605 | CLS Loss: 0.011959177441895008\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 2.412226676940918 | KNN Loss: 2.3989665508270264 | CLS Loss: 0.01326022855937481\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 2.4416558742523193 | KNN Loss: 2.417267084121704 | CLS Loss: 0.024388864636421204\n",
      "Epoch: 123, Loss: 2.4088, Train: 0.9968, Valid: 0.9862, Best: 0.9870\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 2.4424448013305664 | KNN Loss: 2.429731607437134 | CLS Loss: 0.012713246047496796\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 2.4508349895477295 | KNN Loss: 2.4122273921966553 | CLS Loss: 0.038607675582170486\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 2.4209156036376953 | KNN Loss: 2.4076225757598877 | CLS Loss: 0.01329296175390482\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 2.3983757495880127 | KNN Loss: 2.3814661502838135 | CLS Loss: 0.016909675672650337\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 2.3775992393493652 | KNN Loss: 2.3746631145477295 | CLS Loss: 0.0029360540211200714\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 2.4047725200653076 | KNN Loss: 2.394361972808838 | CLS Loss: 0.010410538874566555\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 2.4593169689178467 | KNN Loss: 2.4128646850585938 | CLS Loss: 0.046452317386865616\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 2.4030239582061768 | KNN Loss: 2.392538547515869 | CLS Loss: 0.010485470294952393\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 2.427457094192505 | KNN Loss: 2.4256458282470703 | CLS Loss: 0.0018113239202648401\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 2.427694320678711 | KNN Loss: 2.414564609527588 | CLS Loss: 0.013129751197993755\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 2.4061005115509033 | KNN Loss: 2.388584613800049 | CLS Loss: 0.017515799030661583\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 2.4161107540130615 | KNN Loss: 2.400012969970703 | CLS Loss: 0.016097893938422203\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 2.4123144149780273 | KNN Loss: 2.3878512382507324 | CLS Loss: 0.024463212117552757\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 2.4072136878967285 | KNN Loss: 2.398149013519287 | CLS Loss: 0.00906459242105484\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 2.424849510192871 | KNN Loss: 2.4116907119750977 | CLS Loss: 0.01315887738019228\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 2.4227960109710693 | KNN Loss: 2.4177398681640625 | CLS Loss: 0.005056130699813366\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 2.431844472885132 | KNN Loss: 2.4125993251800537 | CLS Loss: 0.019245119765400887\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 2.414821147918701 | KNN Loss: 2.391879081726074 | CLS Loss: 0.022942163050174713\n",
      "Epoch: 124, Loss: 2.4153, Train: 0.9967, Valid: 0.9859, Best: 0.9870\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 2.4321725368499756 | KNN Loss: 2.420830011367798 | CLS Loss: 0.011342604644596577\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 2.400650978088379 | KNN Loss: 2.3931920528411865 | CLS Loss: 0.007459007203578949\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 2.4142801761627197 | KNN Loss: 2.3976457118988037 | CLS Loss: 0.016634540632367134\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 2.377772092819214 | KNN Loss: 2.3741767406463623 | CLS Loss: 0.00359546672552824\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 2.378124237060547 | KNN Loss: 2.369831085205078 | CLS Loss: 0.008293146267533302\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 2.4223592281341553 | KNN Loss: 2.3929216861724854 | CLS Loss: 0.02943761833012104\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 2.4311611652374268 | KNN Loss: 2.4154741764068604 | CLS Loss: 0.015686973929405212\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 2.383661985397339 | KNN Loss: 2.3788905143737793 | CLS Loss: 0.004771476145833731\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 2.384800910949707 | KNN Loss: 2.375164747238159 | CLS Loss: 0.009636194445192814\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 2.419142246246338 | KNN Loss: 2.415945053100586 | CLS Loss: 0.003197111189365387\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 2.4358627796173096 | KNN Loss: 2.431274175643921 | CLS Loss: 0.004588712006807327\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 2.410334587097168 | KNN Loss: 2.4007599353790283 | CLS Loss: 0.009574598632752895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 2.439101457595825 | KNN Loss: 2.420600652694702 | CLS Loss: 0.01850087381899357\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 2.418489694595337 | KNN Loss: 2.4145569801330566 | CLS Loss: 0.003932792693376541\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 2.4175102710723877 | KNN Loss: 2.405975580215454 | CLS Loss: 0.011534666642546654\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 2.4131479263305664 | KNN Loss: 2.3925201892852783 | CLS Loss: 0.020627837628126144\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 2.379848003387451 | KNN Loss: 2.3683745861053467 | CLS Loss: 0.011473424732685089\n",
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 2.4358131885528564 | KNN Loss: 2.4272522926330566 | CLS Loss: 0.008560797199606895\n",
      "Epoch: 125, Loss: 2.4151, Train: 0.9967, Valid: 0.9867, Best: 0.9870\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 2.408902406692505 | KNN Loss: 2.3954036235809326 | CLS Loss: 0.013498751446604729\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 2.406517267227173 | KNN Loss: 2.392256498336792 | CLS Loss: 0.014260655269026756\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 2.3926243782043457 | KNN Loss: 2.3835620880126953 | CLS Loss: 0.009062211029231548\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 2.4457385540008545 | KNN Loss: 2.428945779800415 | CLS Loss: 0.016792813315987587\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 2.4140727519989014 | KNN Loss: 2.412013292312622 | CLS Loss: 0.002059368183836341\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 2.4104323387145996 | KNN Loss: 2.4013450145721436 | CLS Loss: 0.009087258018553257\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 2.3951172828674316 | KNN Loss: 2.3823392391204834 | CLS Loss: 0.012777993455529213\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 2.431142807006836 | KNN Loss: 2.3931002616882324 | CLS Loss: 0.03804261237382889\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 2.4285025596618652 | KNN Loss: 2.4215428829193115 | CLS Loss: 0.0069597442634403706\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 2.4408934116363525 | KNN Loss: 2.4257254600524902 | CLS Loss: 0.015168000012636185\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 2.4277849197387695 | KNN Loss: 2.4035584926605225 | CLS Loss: 0.024226363748311996\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 2.4157333374023438 | KNN Loss: 2.4034934043884277 | CLS Loss: 0.012239960953593254\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 2.4249887466430664 | KNN Loss: 2.413756847381592 | CLS Loss: 0.011231907643377781\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 2.4364356994628906 | KNN Loss: 2.423543930053711 | CLS Loss: 0.012891821563243866\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 2.414984941482544 | KNN Loss: 2.403564214706421 | CLS Loss: 0.011420837603509426\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 2.3989715576171875 | KNN Loss: 2.395703077316284 | CLS Loss: 0.003268586937338114\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 2.4254918098449707 | KNN Loss: 2.416980743408203 | CLS Loss: 0.008511072024703026\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 2.398797035217285 | KNN Loss: 2.38411808013916 | CLS Loss: 0.014678984880447388\n",
      "Epoch: 126, Loss: 2.4147, Train: 0.9968, Valid: 0.9858, Best: 0.9870\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 2.429100751876831 | KNN Loss: 2.424166440963745 | CLS Loss: 0.004934229422360659\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 2.4041473865509033 | KNN Loss: 2.3904240131378174 | CLS Loss: 0.013723485171794891\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 2.3972768783569336 | KNN Loss: 2.3851239681243896 | CLS Loss: 0.012152954936027527\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 2.413938283920288 | KNN Loss: 2.401341676712036 | CLS Loss: 0.01259662676602602\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 2.4084513187408447 | KNN Loss: 2.3871312141418457 | CLS Loss: 0.02132015861570835\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 2.4096662998199463 | KNN Loss: 2.404991388320923 | CLS Loss: 0.0046748146414756775\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 2.4302518367767334 | KNN Loss: 2.4184770584106445 | CLS Loss: 0.011774847283959389\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 2.4126715660095215 | KNN Loss: 2.406376600265503 | CLS Loss: 0.00629491126164794\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 2.4304139614105225 | KNN Loss: 2.424241304397583 | CLS Loss: 0.006172722205519676\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 2.389374017715454 | KNN Loss: 2.3719608783721924 | CLS Loss: 0.017413217574357986\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 2.4316341876983643 | KNN Loss: 2.3987438678741455 | CLS Loss: 0.03289026394486427\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 2.4287023544311523 | KNN Loss: 2.4086976051330566 | CLS Loss: 0.020004769787192345\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 2.3789615631103516 | KNN Loss: 2.3705906867980957 | CLS Loss: 0.008370775729417801\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 2.4287469387054443 | KNN Loss: 2.4091413021087646 | CLS Loss: 0.01960558444261551\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 2.4524245262145996 | KNN Loss: 2.4464378356933594 | CLS Loss: 0.005986692849546671\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 2.3942837715148926 | KNN Loss: 2.386406660079956 | CLS Loss: 0.007877052761614323\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 2.384676218032837 | KNN Loss: 2.379751443862915 | CLS Loss: 0.004924663342535496\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 2.473588466644287 | KNN Loss: 2.4710521697998047 | CLS Loss: 0.0025362970773130655\n",
      "Epoch: 127, Loss: 2.4135, Train: 0.9962, Valid: 0.9862, Best: 0.9870\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 2.417125701904297 | KNN Loss: 2.4052720069885254 | CLS Loss: 0.011853809468448162\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 2.4025704860687256 | KNN Loss: 2.3910021781921387 | CLS Loss: 0.011568283662199974\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 2.4059042930603027 | KNN Loss: 2.403491258621216 | CLS Loss: 0.002412983914837241\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 2.4154458045959473 | KNN Loss: 2.392695188522339 | CLS Loss: 0.02275051549077034\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 2.4359629154205322 | KNN Loss: 2.413212537765503 | CLS Loss: 0.02275042049586773\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 2.434762716293335 | KNN Loss: 2.4182498455047607 | CLS Loss: 0.016512922942638397\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 2.461995840072632 | KNN Loss: 2.4483072757720947 | CLS Loss: 0.01368858851492405\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 2.3822078704833984 | KNN Loss: 2.3608760833740234 | CLS Loss: 0.02133180946111679\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 2.4197232723236084 | KNN Loss: 2.410961866378784 | CLS Loss: 0.008761516772210598\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 2.4416871070861816 | KNN Loss: 2.4342572689056396 | CLS Loss: 0.00742976414039731\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 2.413695812225342 | KNN Loss: 2.387354612350464 | CLS Loss: 0.02634110115468502\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 2.4272348880767822 | KNN Loss: 2.423076629638672 | CLS Loss: 0.0041581494733691216\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 2.390434980392456 | KNN Loss: 2.3722567558288574 | CLS Loss: 0.018178226426243782\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 2.406043767929077 | KNN Loss: 2.387338876724243 | CLS Loss: 0.018704939633607864\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 2.422808885574341 | KNN Loss: 2.4094619750976562 | CLS Loss: 0.013346966356039047\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 2.410874366760254 | KNN Loss: 2.4030611515045166 | CLS Loss: 0.007813201285898685\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 2.412684679031372 | KNN Loss: 2.4010043144226074 | CLS Loss: 0.011680369265377522\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 2.383011817932129 | KNN Loss: 2.3776614665985107 | CLS Loss: 0.00535042816773057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, Loss: 2.4163, Train: 0.9957, Valid: 0.9852, Best: 0.9870\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 2.390692949295044 | KNN Loss: 2.3826498985290527 | CLS Loss: 0.008043126203119755\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 2.411470890045166 | KNN Loss: 2.3970823287963867 | CLS Loss: 0.014388534240424633\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 2.442150354385376 | KNN Loss: 2.4227421283721924 | CLS Loss: 0.019408326596021652\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 2.4101297855377197 | KNN Loss: 2.396545886993408 | CLS Loss: 0.013583862222731113\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 2.435899019241333 | KNN Loss: 2.4035658836364746 | CLS Loss: 0.03233322873711586\n",
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 2.466184377670288 | KNN Loss: 2.4581122398376465 | CLS Loss: 0.008072148077189922\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 2.3869035243988037 | KNN Loss: 2.3843331336975098 | CLS Loss: 0.002570290584117174\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 2.417233467102051 | KNN Loss: 2.407301902770996 | CLS Loss: 0.009931516833603382\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 2.404698133468628 | KNN Loss: 2.3990535736083984 | CLS Loss: 0.00564455846324563\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 2.4082260131835938 | KNN Loss: 2.3995866775512695 | CLS Loss: 0.008639288134872913\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 2.4317586421966553 | KNN Loss: 2.4216067790985107 | CLS Loss: 0.010151864029467106\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 2.4434025287628174 | KNN Loss: 2.440532922744751 | CLS Loss: 0.002869535004720092\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 2.42404842376709 | KNN Loss: 2.420116424560547 | CLS Loss: 0.003932100720703602\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 2.4207639694213867 | KNN Loss: 2.4129505157470703 | CLS Loss: 0.00781347043812275\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 2.42695689201355 | KNN Loss: 2.424344062805176 | CLS Loss: 0.0026127814780920744\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 2.421647071838379 | KNN Loss: 2.4147651195526123 | CLS Loss: 0.006881901994347572\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 2.427966356277466 | KNN Loss: 2.4143128395080566 | CLS Loss: 0.013653425499796867\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 2.4283061027526855 | KNN Loss: 2.4169790744781494 | CLS Loss: 0.011327018029987812\n",
      "Epoch: 129, Loss: 2.4120, Train: 0.9972, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 2.446812391281128 | KNN Loss: 2.4403584003448486 | CLS Loss: 0.0064540947787463665\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 2.396637201309204 | KNN Loss: 2.3941075801849365 | CLS Loss: 0.002529645338654518\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 2.4294886589050293 | KNN Loss: 2.4113149642944336 | CLS Loss: 0.018173616379499435\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 2.4392895698547363 | KNN Loss: 2.424997091293335 | CLS Loss: 0.014292534440755844\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 2.440742015838623 | KNN Loss: 2.433779001235962 | CLS Loss: 0.006962988525629044\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 2.399732828140259 | KNN Loss: 2.3938515186309814 | CLS Loss: 0.00588132394477725\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 2.3933684825897217 | KNN Loss: 2.387193202972412 | CLS Loss: 0.006175280082970858\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 2.4192073345184326 | KNN Loss: 2.415571689605713 | CLS Loss: 0.0036357513163238764\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 2.4334769248962402 | KNN Loss: 2.432657480239868 | CLS Loss: 0.0008195354021154344\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 2.3853371143341064 | KNN Loss: 2.3843917846679688 | CLS Loss: 0.00094539241399616\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 2.4144678115844727 | KNN Loss: 2.409071445465088 | CLS Loss: 0.0053964462131261826\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 2.435760736465454 | KNN Loss: 2.415529251098633 | CLS Loss: 0.020231585949659348\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 2.4374914169311523 | KNN Loss: 2.43571400642395 | CLS Loss: 0.0017774690641090274\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 2.3869729042053223 | KNN Loss: 2.3782029151916504 | CLS Loss: 0.008770028129220009\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 2.408581256866455 | KNN Loss: 2.387618064880371 | CLS Loss: 0.02096322551369667\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 2.4139065742492676 | KNN Loss: 2.3943421840667725 | CLS Loss: 0.019564487040042877\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 2.4138660430908203 | KNN Loss: 2.4028303623199463 | CLS Loss: 0.011035689152777195\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 2.409243106842041 | KNN Loss: 2.3955302238464355 | CLS Loss: 0.013712959364056587\n",
      "Epoch: 130, Loss: 2.4112, Train: 0.9972, Valid: 0.9855, Best: 0.9872\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 2.417794942855835 | KNN Loss: 2.4066457748413086 | CLS Loss: 0.011149070225656033\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 2.447822093963623 | KNN Loss: 2.41349458694458 | CLS Loss: 0.03432760387659073\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 2.364563226699829 | KNN Loss: 2.3593311309814453 | CLS Loss: 0.005232025869190693\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 2.4089748859405518 | KNN Loss: 2.401134967803955 | CLS Loss: 0.007840011268854141\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 2.379408836364746 | KNN Loss: 2.3758938312530518 | CLS Loss: 0.0035150209441781044\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 2.4073891639709473 | KNN Loss: 2.3959622383117676 | CLS Loss: 0.011426984332501888\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 2.3983237743377686 | KNN Loss: 2.3946948051452637 | CLS Loss: 0.003629016224294901\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 2.412973403930664 | KNN Loss: 2.409224033355713 | CLS Loss: 0.0037494080606848\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 2.4189064502716064 | KNN Loss: 2.398860454559326 | CLS Loss: 0.020045896992087364\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 2.3652288913726807 | KNN Loss: 2.3432910442352295 | CLS Loss: 0.021937860175967216\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 2.387042999267578 | KNN Loss: 2.376171827316284 | CLS Loss: 0.010871061123907566\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 2.40800142288208 | KNN Loss: 2.4038119316101074 | CLS Loss: 0.004189387429505587\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 2.3815910816192627 | KNN Loss: 2.369222402572632 | CLS Loss: 0.012368733063340187\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 2.3717033863067627 | KNN Loss: 2.3625059127807617 | CLS Loss: 0.009197506122291088\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 2.4372353553771973 | KNN Loss: 2.418097496032715 | CLS Loss: 0.01913795992732048\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 2.415067434310913 | KNN Loss: 2.405337333679199 | CLS Loss: 0.009730201214551926\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 2.4172797203063965 | KNN Loss: 2.4073879718780518 | CLS Loss: 0.009891705587506294\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 2.414438247680664 | KNN Loss: 2.4103288650512695 | CLS Loss: 0.004109405446797609\n",
      "Epoch: 131, Loss: 2.4105, Train: 0.9962, Valid: 0.9866, Best: 0.9872\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 2.396655797958374 | KNN Loss: 2.362032175064087 | CLS Loss: 0.03462373465299606\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 2.397623062133789 | KNN Loss: 2.385181188583374 | CLS Loss: 0.012441959232091904\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 2.3841617107391357 | KNN Loss: 2.3786072731018066 | CLS Loss: 0.005554439499974251\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 2.4014275074005127 | KNN Loss: 2.3906283378601074 | CLS Loss: 0.010799129493534565\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 2.4018008708953857 | KNN Loss: 2.397765874862671 | CLS Loss: 0.004034970421344042\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 2.3954575061798096 | KNN Loss: 2.3873488903045654 | CLS Loss: 0.008108594454824924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 2.423673629760742 | KNN Loss: 2.4195034503936768 | CLS Loss: 0.004170069005340338\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 2.458491802215576 | KNN Loss: 2.447695255279541 | CLS Loss: 0.010796554386615753\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 2.4014525413513184 | KNN Loss: 2.387829542160034 | CLS Loss: 0.013622942380607128\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 2.434735059738159 | KNN Loss: 2.4321162700653076 | CLS Loss: 0.0026187968906015158\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 2.407010316848755 | KNN Loss: 2.403341054916382 | CLS Loss: 0.0036691795103251934\n",
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 2.394099712371826 | KNN Loss: 2.3781158924102783 | CLS Loss: 0.01598382368683815\n",
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 2.395442247390747 | KNN Loss: 2.386655569076538 | CLS Loss: 0.00878671370446682\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 2.4117226600646973 | KNN Loss: 2.4007692337036133 | CLS Loss: 0.010953419841825962\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 2.4270522594451904 | KNN Loss: 2.401111125946045 | CLS Loss: 0.025941070169210434\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 2.3891074657440186 | KNN Loss: 2.383845090866089 | CLS Loss: 0.005262274760752916\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 2.407304525375366 | KNN Loss: 2.4011716842651367 | CLS Loss: 0.006132849026471376\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 2.4308009147644043 | KNN Loss: 2.404829740524292 | CLS Loss: 0.02597123384475708\n",
      "Epoch: 132, Loss: 2.4127, Train: 0.9966, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 2.4090867042541504 | KNN Loss: 2.3844079971313477 | CLS Loss: 0.024678673595190048\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 2.449125051498413 | KNN Loss: 2.4411702156066895 | CLS Loss: 0.007954941131174564\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 2.407571792602539 | KNN Loss: 2.3935115337371826 | CLS Loss: 0.014060325920581818\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 2.4156291484832764 | KNN Loss: 2.4061005115509033 | CLS Loss: 0.009528531692922115\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 2.403609037399292 | KNN Loss: 2.393869400024414 | CLS Loss: 0.009739535860717297\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 2.3845410346984863 | KNN Loss: 2.3771328926086426 | CLS Loss: 0.00740808853879571\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 2.4168734550476074 | KNN Loss: 2.409362316131592 | CLS Loss: 0.007511093746870756\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 2.424816131591797 | KNN Loss: 2.4095089435577393 | CLS Loss: 0.015307151712477207\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 2.4405388832092285 | KNN Loss: 2.40533709526062 | CLS Loss: 0.03520190715789795\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 2.4024856090545654 | KNN Loss: 2.3856351375579834 | CLS Loss: 0.016850415617227554\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 2.410846471786499 | KNN Loss: 2.393740177154541 | CLS Loss: 0.017106343060731888\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 2.4605419635772705 | KNN Loss: 2.4483752250671387 | CLS Loss: 0.01216672919690609\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 2.4452319145202637 | KNN Loss: 2.428534984588623 | CLS Loss: 0.016697004437446594\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 2.3723697662353516 | KNN Loss: 2.357351064682007 | CLS Loss: 0.015018759295344353\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 2.3966009616851807 | KNN Loss: 2.3914551734924316 | CLS Loss: 0.005145791452378035\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 2.377354860305786 | KNN Loss: 2.372925281524658 | CLS Loss: 0.004429499618709087\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 2.4535720348358154 | KNN Loss: 2.4408116340637207 | CLS Loss: 0.012760396115481853\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 2.4200398921966553 | KNN Loss: 2.3926849365234375 | CLS Loss: 0.02735486440360546\n",
      "Epoch: 133, Loss: 2.4120, Train: 0.9973, Valid: 0.9868, Best: 0.9872\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 2.368845224380493 | KNN Loss: 2.3648931980133057 | CLS Loss: 0.00395192950963974\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 2.381098985671997 | KNN Loss: 2.378143072128296 | CLS Loss: 0.002955986885353923\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 2.4032344818115234 | KNN Loss: 2.401427745819092 | CLS Loss: 0.00180661934427917\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 2.413619041442871 | KNN Loss: 2.406738042831421 | CLS Loss: 0.006880924571305513\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 2.358476400375366 | KNN Loss: 2.352391242980957 | CLS Loss: 0.006085256114602089\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 2.4039254188537598 | KNN Loss: 2.401580810546875 | CLS Loss: 0.0023447228595614433\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 2.4112155437469482 | KNN Loss: 2.404747486114502 | CLS Loss: 0.006467973813414574\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 2.375577449798584 | KNN Loss: 2.3731985092163086 | CLS Loss: 0.002378827193751931\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 2.429182291030884 | KNN Loss: 2.4134931564331055 | CLS Loss: 0.015689043328166008\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 2.4482030868530273 | KNN Loss: 2.4377193450927734 | CLS Loss: 0.010483642108738422\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 2.3959927558898926 | KNN Loss: 2.3825366497039795 | CLS Loss: 0.013456217013299465\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 2.388582706451416 | KNN Loss: 2.3765029907226562 | CLS Loss: 0.012079811654984951\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 2.377869129180908 | KNN Loss: 2.3667094707489014 | CLS Loss: 0.011159679852426052\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 2.427375316619873 | KNN Loss: 2.4218404293060303 | CLS Loss: 0.005534859839826822\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 2.418567657470703 | KNN Loss: 2.412658214569092 | CLS Loss: 0.005909367464482784\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 2.414795398712158 | KNN Loss: 2.395360231399536 | CLS Loss: 0.01943524181842804\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 2.414867639541626 | KNN Loss: 2.4057440757751465 | CLS Loss: 0.009123574011027813\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 2.4076390266418457 | KNN Loss: 2.405001163482666 | CLS Loss: 0.0026379015762358904\n",
      "Epoch: 134, Loss: 2.4093, Train: 0.9963, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 2.388937473297119 | KNN Loss: 2.3879261016845703 | CLS Loss: 0.0010113497264683247\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 2.3725500106811523 | KNN Loss: 2.3667914867401123 | CLS Loss: 0.0057586319744586945\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 2.424367666244507 | KNN Loss: 2.4046630859375 | CLS Loss: 0.019704656675457954\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 2.411163091659546 | KNN Loss: 2.388763427734375 | CLS Loss: 0.02239968813955784\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 2.4114513397216797 | KNN Loss: 2.4059841632843018 | CLS Loss: 0.005467273760586977\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 2.404379367828369 | KNN Loss: 2.3959028720855713 | CLS Loss: 0.00847651157528162\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 2.436602830886841 | KNN Loss: 2.4062845706939697 | CLS Loss: 0.03031834214925766\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 2.4301297664642334 | KNN Loss: 2.413849353790283 | CLS Loss: 0.016280418261885643\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 2.4327738285064697 | KNN Loss: 2.4086501598358154 | CLS Loss: 0.02412361279129982\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 2.4307186603546143 | KNN Loss: 2.3948936462402344 | CLS Loss: 0.035825058817863464\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 2.4262144565582275 | KNN Loss: 2.4212520122528076 | CLS Loss: 0.004962512291967869\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 2.4211411476135254 | KNN Loss: 2.415966033935547 | CLS Loss: 0.005175027064979076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 2.3926191329956055 | KNN Loss: 2.377835273742676 | CLS Loss: 0.014783822931349277\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 2.403862953186035 | KNN Loss: 2.379260301589966 | CLS Loss: 0.024602683261036873\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 2.440702199935913 | KNN Loss: 2.419074296951294 | CLS Loss: 0.021627986803650856\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 2.458510637283325 | KNN Loss: 2.432723045349121 | CLS Loss: 0.02578757517039776\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 2.4666924476623535 | KNN Loss: 2.462677240371704 | CLS Loss: 0.0040151989087462425\n",
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 2.419105052947998 | KNN Loss: 2.4024643898010254 | CLS Loss: 0.016640733927488327\n",
      "Epoch: 135, Loss: 2.4131, Train: 0.9967, Valid: 0.9858, Best: 0.9872\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 2.4257922172546387 | KNN Loss: 2.421905279159546 | CLS Loss: 0.0038869958370923996\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 2.4201889038085938 | KNN Loss: 2.416980743408203 | CLS Loss: 0.0032081017270684242\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 2.3930647373199463 | KNN Loss: 2.3866946697235107 | CLS Loss: 0.006370058748871088\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 2.430387496948242 | KNN Loss: 2.4102160930633545 | CLS Loss: 0.020171521231532097\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 2.396789312362671 | KNN Loss: 2.393606185913086 | CLS Loss: 0.0031830414664000273\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 2.434227466583252 | KNN Loss: 2.421989917755127 | CLS Loss: 0.012237641029059887\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 2.440747022628784 | KNN Loss: 2.4309003353118896 | CLS Loss: 0.00984680000692606\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 2.3749237060546875 | KNN Loss: 2.3674142360687256 | CLS Loss: 0.007509542629122734\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 2.3969008922576904 | KNN Loss: 2.3807034492492676 | CLS Loss: 0.01619754731655121\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 2.425490617752075 | KNN Loss: 2.4144175052642822 | CLS Loss: 0.011073002591729164\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 2.430298328399658 | KNN Loss: 2.427081823348999 | CLS Loss: 0.003216387936845422\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 2.4102087020874023 | KNN Loss: 2.3861796855926514 | CLS Loss: 0.024029074236750603\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 2.38173246383667 | KNN Loss: 2.3721606731414795 | CLS Loss: 0.009571874514222145\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 2.419280767440796 | KNN Loss: 2.4039576053619385 | CLS Loss: 0.01532319188117981\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 2.403186798095703 | KNN Loss: 2.3883392810821533 | CLS Loss: 0.014847527258098125\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 2.372236490249634 | KNN Loss: 2.360957384109497 | CLS Loss: 0.011279002763330936\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 2.4057555198669434 | KNN Loss: 2.3627145290374756 | CLS Loss: 0.04304104298353195\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 2.4098384380340576 | KNN Loss: 2.3991146087646484 | CLS Loss: 0.010723932646214962\n",
      "Epoch: 136, Loss: 2.4136, Train: 0.9971, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 2.419565439224243 | KNN Loss: 2.398000717163086 | CLS Loss: 0.021564660593867302\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 2.4137604236602783 | KNN Loss: 2.406090021133423 | CLS Loss: 0.0076703825034201145\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 2.417891502380371 | KNN Loss: 2.3959827423095703 | CLS Loss: 0.021908879280090332\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 2.420001268386841 | KNN Loss: 2.408548593521118 | CLS Loss: 0.011452754028141499\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 2.4347140789031982 | KNN Loss: 2.4074175357818604 | CLS Loss: 0.027296539396047592\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 2.4179623126983643 | KNN Loss: 2.4156558513641357 | CLS Loss: 0.002306533744558692\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 2.4056169986724854 | KNN Loss: 2.395132303237915 | CLS Loss: 0.01048473734408617\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 2.4150683879852295 | KNN Loss: 2.39388370513916 | CLS Loss: 0.021184701472520828\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 2.424870252609253 | KNN Loss: 2.4018001556396484 | CLS Loss: 0.02307017333805561\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 2.4327280521392822 | KNN Loss: 2.410299062728882 | CLS Loss: 0.022428881376981735\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 2.4532010555267334 | KNN Loss: 2.4388227462768555 | CLS Loss: 0.014378320425748825\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 2.4114253520965576 | KNN Loss: 2.4069430828094482 | CLS Loss: 0.0044823396019637585\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 2.442523717880249 | KNN Loss: 2.4349260330200195 | CLS Loss: 0.007597717922180891\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 2.395181179046631 | KNN Loss: 2.3910586833953857 | CLS Loss: 0.004122491925954819\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 2.4260215759277344 | KNN Loss: 2.417445182800293 | CLS Loss: 0.00857628881931305\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 2.404639482498169 | KNN Loss: 2.393979549407959 | CLS Loss: 0.010659881867468357\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 2.4186999797821045 | KNN Loss: 2.4031050205230713 | CLS Loss: 0.015595076605677605\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 2.410236120223999 | KNN Loss: 2.3996644020080566 | CLS Loss: 0.010571601800620556\n",
      "Epoch: 137, Loss: 2.4086, Train: 0.9973, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 2.3975436687469482 | KNN Loss: 2.38555908203125 | CLS Loss: 0.01198460441082716\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 2.3983356952667236 | KNN Loss: 2.3952410221099854 | CLS Loss: 0.0030946172773838043\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 2.402416706085205 | KNN Loss: 2.396684408187866 | CLS Loss: 0.0057322243228554726\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 2.4052648544311523 | KNN Loss: 2.398242235183716 | CLS Loss: 0.007022688165307045\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 2.4298532009124756 | KNN Loss: 2.4232890605926514 | CLS Loss: 0.006564176641404629\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 2.425509452819824 | KNN Loss: 2.39792537689209 | CLS Loss: 0.027584033086895943\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 2.4341509342193604 | KNN Loss: 2.424020290374756 | CLS Loss: 0.01013070810586214\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 2.42146372795105 | KNN Loss: 2.4058868885040283 | CLS Loss: 0.015576746314764023\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 2.3597183227539062 | KNN Loss: 2.3414182662963867 | CLS Loss: 0.01829994097352028\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 2.429781675338745 | KNN Loss: 2.412975788116455 | CLS Loss: 0.01680583506822586\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 2.407545328140259 | KNN Loss: 2.395024061203003 | CLS Loss: 0.012521225959062576\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 2.4007067680358887 | KNN Loss: 2.389850616455078 | CLS Loss: 0.010856211185455322\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 2.4052603244781494 | KNN Loss: 2.3962793350219727 | CLS Loss: 0.008981051854789257\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 2.3818397521972656 | KNN Loss: 2.37766432762146 | CLS Loss: 0.004175496753305197\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 2.40427565574646 | KNN Loss: 2.4031407833099365 | CLS Loss: 0.001134835765697062\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 2.425628423690796 | KNN Loss: 2.421496868133545 | CLS Loss: 0.004131518304347992\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 2.4023563861846924 | KNN Loss: 2.384269952774048 | CLS Loss: 0.018086550757288933\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 2.4287655353546143 | KNN Loss: 2.4078080654144287 | CLS Loss: 0.020957520231604576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138, Loss: 2.4070, Train: 0.9966, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 2.4293875694274902 | KNN Loss: 2.419623613357544 | CLS Loss: 0.00976401474326849\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 2.404351234436035 | KNN Loss: 2.399686574935913 | CLS Loss: 0.004664599895477295\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 2.4004955291748047 | KNN Loss: 2.381991386413574 | CLS Loss: 0.01850416511297226\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 2.419252872467041 | KNN Loss: 2.404296636581421 | CLS Loss: 0.014956243336200714\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 2.4266433715820312 | KNN Loss: 2.4201161861419678 | CLS Loss: 0.00652730418369174\n",
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 2.417839527130127 | KNN Loss: 2.406299114227295 | CLS Loss: 0.01154048927128315\n",
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 2.4182417392730713 | KNN Loss: 2.398493766784668 | CLS Loss: 0.01974790170788765\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 2.4049782752990723 | KNN Loss: 2.3992834091186523 | CLS Loss: 0.005694831721484661\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 2.4162614345550537 | KNN Loss: 2.4133341312408447 | CLS Loss: 0.002927301451563835\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 2.3988466262817383 | KNN Loss: 2.3805065155029297 | CLS Loss: 0.018340162932872772\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 2.4334769248962402 | KNN Loss: 2.4277172088623047 | CLS Loss: 0.005759669002145529\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 2.3969130516052246 | KNN Loss: 2.388679265975952 | CLS Loss: 0.008233818225562572\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 2.4193367958068848 | KNN Loss: 2.4172654151916504 | CLS Loss: 0.0020714830607175827\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 2.4521169662475586 | KNN Loss: 2.433016538619995 | CLS Loss: 0.019100356847047806\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 2.419265031814575 | KNN Loss: 2.402637481689453 | CLS Loss: 0.016627445816993713\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 2.402493476867676 | KNN Loss: 2.3897929191589355 | CLS Loss: 0.012700553983449936\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 2.415863513946533 | KNN Loss: 2.374603033065796 | CLS Loss: 0.04126038774847984\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 2.4451119899749756 | KNN Loss: 2.4337234497070312 | CLS Loss: 0.011388441547751427\n",
      "Epoch: 139, Loss: 2.4128, Train: 0.9963, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 2.435136556625366 | KNN Loss: 2.428361415863037 | CLS Loss: 0.006775130517780781\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 2.3795807361602783 | KNN Loss: 2.370157241821289 | CLS Loss: 0.009423593990504742\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 2.415480613708496 | KNN Loss: 2.412590980529785 | CLS Loss: 0.0028895591385662556\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 2.442070484161377 | KNN Loss: 2.434279680252075 | CLS Loss: 0.0077907489612698555\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 2.3836889266967773 | KNN Loss: 2.3792266845703125 | CLS Loss: 0.004462304059416056\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 2.456662178039551 | KNN Loss: 2.4384682178497314 | CLS Loss: 0.018194042146205902\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 2.4329841136932373 | KNN Loss: 2.4202442169189453 | CLS Loss: 0.012739858590066433\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 2.4199185371398926 | KNN Loss: 2.3808231353759766 | CLS Loss: 0.03909536823630333\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 2.4051477909088135 | KNN Loss: 2.3928916454315186 | CLS Loss: 0.01225622370839119\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 2.434298276901245 | KNN Loss: 2.424673080444336 | CLS Loss: 0.009625114500522614\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 2.388141632080078 | KNN Loss: 2.3737616539001465 | CLS Loss: 0.014379964210093021\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 2.3790504932403564 | KNN Loss: 2.3676106929779053 | CLS Loss: 0.011439774185419083\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 2.444182872772217 | KNN Loss: 2.4326112270355225 | CLS Loss: 0.011571559123694897\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 2.4257161617279053 | KNN Loss: 2.411099433898926 | CLS Loss: 0.014616640284657478\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 2.3903558254241943 | KNN Loss: 2.3728489875793457 | CLS Loss: 0.017506925389170647\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 2.3948166370391846 | KNN Loss: 2.3854541778564453 | CLS Loss: 0.009362449869513512\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 2.3980846405029297 | KNN Loss: 2.39327073097229 | CLS Loss: 0.004814020358026028\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 2.37198805809021 | KNN Loss: 2.361367702484131 | CLS Loss: 0.010620295070111752\n",
      "Epoch: 140, Loss: 2.4099, Train: 0.9976, Valid: 0.9861, Best: 0.9872\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 2.464822769165039 | KNN Loss: 2.4606616497039795 | CLS Loss: 0.004161004908382893\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 2.3993656635284424 | KNN Loss: 2.3932363986968994 | CLS Loss: 0.006129296030849218\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 2.427875280380249 | KNN Loss: 2.4092977046966553 | CLS Loss: 0.018577545881271362\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 2.404398202896118 | KNN Loss: 2.3983824253082275 | CLS Loss: 0.006015818566083908\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 2.404024839401245 | KNN Loss: 2.399954080581665 | CLS Loss: 0.004070799797773361\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 2.4449880123138428 | KNN Loss: 2.4288623332977295 | CLS Loss: 0.01612558774650097\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 2.36377215385437 | KNN Loss: 2.3604965209960938 | CLS Loss: 0.003275603987276554\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 2.4037351608276367 | KNN Loss: 2.401095390319824 | CLS Loss: 0.0026396731846034527\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 2.3966124057769775 | KNN Loss: 2.396059513092041 | CLS Loss: 0.0005527999601326883\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 2.3702876567840576 | KNN Loss: 2.3559048175811768 | CLS Loss: 0.014382796362042427\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 2.410248279571533 | KNN Loss: 2.394582986831665 | CLS Loss: 0.015665214508771896\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 2.4276747703552246 | KNN Loss: 2.3997719287872314 | CLS Loss: 0.027902960777282715\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 2.404447317123413 | KNN Loss: 2.3950443267822266 | CLS Loss: 0.009402981959283352\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 2.37542462348938 | KNN Loss: 2.3740265369415283 | CLS Loss: 0.0013980166986584663\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 2.4066147804260254 | KNN Loss: 2.402125120162964 | CLS Loss: 0.004489609971642494\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 2.408097267150879 | KNN Loss: 2.393803358078003 | CLS Loss: 0.014293795451521873\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 2.408604860305786 | KNN Loss: 2.397597312927246 | CLS Loss: 0.011007633060216904\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 2.4073798656463623 | KNN Loss: 2.4019322395324707 | CLS Loss: 0.005447717849165201\n",
      "Epoch: 141, Loss: 2.4104, Train: 0.9979, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 2.383727788925171 | KNN Loss: 2.382863998413086 | CLS Loss: 0.0008639079751446843\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 2.372563600540161 | KNN Loss: 2.3675103187561035 | CLS Loss: 0.005053327884525061\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 2.387417793273926 | KNN Loss: 2.3773984909057617 | CLS Loss: 0.010019301436841488\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 2.4309871196746826 | KNN Loss: 2.4233267307281494 | CLS Loss: 0.007660468574613333\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 2.406722068786621 | KNN Loss: 2.399658679962158 | CLS Loss: 0.007063407450914383\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 2.400275945663452 | KNN Loss: 2.390291690826416 | CLS Loss: 0.00998422596603632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 2.396801710128784 | KNN Loss: 2.3930184841156006 | CLS Loss: 0.003783267457038164\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 2.417140483856201 | KNN Loss: 2.3986928462982178 | CLS Loss: 0.018447542563080788\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 2.4030094146728516 | KNN Loss: 2.3969268798828125 | CLS Loss: 0.006082584615796804\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 2.426377296447754 | KNN Loss: 2.4216182231903076 | CLS Loss: 0.00475896243005991\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 2.39205002784729 | KNN Loss: 2.385650634765625 | CLS Loss: 0.006399284582585096\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 2.3765580654144287 | KNN Loss: 2.3732762336730957 | CLS Loss: 0.0032818240579217672\n",
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 2.426480770111084 | KNN Loss: 2.422492027282715 | CLS Loss: 0.0039887810125947\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 2.4028639793395996 | KNN Loss: 2.3936784267425537 | CLS Loss: 0.009185637347400188\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 2.3752827644348145 | KNN Loss: 2.361237049102783 | CLS Loss: 0.01404571533203125\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 2.4156837463378906 | KNN Loss: 2.3964686393737793 | CLS Loss: 0.019215131178498268\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 2.4064126014709473 | KNN Loss: 2.392932653427124 | CLS Loss: 0.013479895889759064\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 2.3457863330841064 | KNN Loss: 2.343942642211914 | CLS Loss: 0.001843648380599916\n",
      "Epoch: 142, Loss: 2.4092, Train: 0.9969, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 2.4150230884552 | KNN Loss: 2.4144513607025146 | CLS Loss: 0.0005716460873372853\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 2.4470176696777344 | KNN Loss: 2.44160795211792 | CLS Loss: 0.005409772042185068\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 2.4223978519439697 | KNN Loss: 2.4067764282226562 | CLS Loss: 0.01562134176492691\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 2.427686929702759 | KNN Loss: 2.4218251705169678 | CLS Loss: 0.005861690733581781\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 2.3879544734954834 | KNN Loss: 2.380341053009033 | CLS Loss: 0.007613534107804298\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 2.4041032791137695 | KNN Loss: 2.3973758220672607 | CLS Loss: 0.006727428641170263\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 2.4151058197021484 | KNN Loss: 2.4070467948913574 | CLS Loss: 0.008058927953243256\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 2.390448808670044 | KNN Loss: 2.36936616897583 | CLS Loss: 0.021082527935504913\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 2.369245767593384 | KNN Loss: 2.359142541885376 | CLS Loss: 0.010103199630975723\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 2.3922319412231445 | KNN Loss: 2.371000289916992 | CLS Loss: 0.02123171277344227\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 2.4093334674835205 | KNN Loss: 2.402186632156372 | CLS Loss: 0.007146742660552263\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 2.4227256774902344 | KNN Loss: 2.4173879623413086 | CLS Loss: 0.005337637849152088\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 2.4137115478515625 | KNN Loss: 2.4004318714141846 | CLS Loss: 0.013279635459184647\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 2.3960750102996826 | KNN Loss: 2.388983964920044 | CLS Loss: 0.007090938277542591\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 2.4531149864196777 | KNN Loss: 2.4492149353027344 | CLS Loss: 0.003899982664734125\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 2.3878490924835205 | KNN Loss: 2.3869571685791016 | CLS Loss: 0.0008918878738768399\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 2.409712314605713 | KNN Loss: 2.3914427757263184 | CLS Loss: 0.018269557505846024\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 2.4060654640197754 | KNN Loss: 2.403536558151245 | CLS Loss: 0.002528854412958026\n",
      "Epoch: 143, Loss: 2.4100, Train: 0.9979, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 2.387430191040039 | KNN Loss: 2.3844311237335205 | CLS Loss: 0.0029990756884217262\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 2.3778598308563232 | KNN Loss: 2.372722864151001 | CLS Loss: 0.005137009546160698\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 2.4029738903045654 | KNN Loss: 2.401869297027588 | CLS Loss: 0.0011047114385291934\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 2.391190767288208 | KNN Loss: 2.373800039291382 | CLS Loss: 0.017390798777341843\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 2.394224166870117 | KNN Loss: 2.3880672454833984 | CLS Loss: 0.0061569735407829285\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 2.4032511711120605 | KNN Loss: 2.39730167388916 | CLS Loss: 0.005949525162577629\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 2.427028179168701 | KNN Loss: 2.424081802368164 | CLS Loss: 0.0029464138206094503\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 2.3701298236846924 | KNN Loss: 2.360689163208008 | CLS Loss: 0.00944070890545845\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 2.407186508178711 | KNN Loss: 2.4045658111572266 | CLS Loss: 0.0026207270566374063\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 2.421586036682129 | KNN Loss: 2.3982908725738525 | CLS Loss: 0.023295113816857338\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 2.41178035736084 | KNN Loss: 2.3857192993164062 | CLS Loss: 0.02606111764907837\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 2.4360196590423584 | KNN Loss: 2.433002471923828 | CLS Loss: 0.0030172266997396946\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 2.4275553226470947 | KNN Loss: 2.4230880737304688 | CLS Loss: 0.004467147868126631\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 2.425487995147705 | KNN Loss: 2.4227216243743896 | CLS Loss: 0.002766265533864498\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 2.38511323928833 | KNN Loss: 2.3812460899353027 | CLS Loss: 0.0038670937065035105\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 2.4180002212524414 | KNN Loss: 2.402390956878662 | CLS Loss: 0.015609167516231537\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 2.4031589031219482 | KNN Loss: 2.3894569873809814 | CLS Loss: 0.01370182540267706\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 2.4023373126983643 | KNN Loss: 2.387275218963623 | CLS Loss: 0.01506220642477274\n",
      "Epoch: 144, Loss: 2.4101, Train: 0.9977, Valid: 0.9861, Best: 0.9872\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 2.3765194416046143 | KNN Loss: 2.3728179931640625 | CLS Loss: 0.0037013976834714413\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 2.453606605529785 | KNN Loss: 2.4462475776672363 | CLS Loss: 0.007358910981565714\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 2.4018824100494385 | KNN Loss: 2.4003541469573975 | CLS Loss: 0.0015283017419278622\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 2.4102978706359863 | KNN Loss: 2.4065709114074707 | CLS Loss: 0.0037269366439431906\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 2.4173686504364014 | KNN Loss: 2.412961006164551 | CLS Loss: 0.004407636821269989\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 2.3846757411956787 | KNN Loss: 2.380056381225586 | CLS Loss: 0.0046194614842534065\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 2.4426827430725098 | KNN Loss: 2.427133798599243 | CLS Loss: 0.015548843890428543\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 2.4199154376983643 | KNN Loss: 2.415133476257324 | CLS Loss: 0.00478191627189517\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 2.404449939727783 | KNN Loss: 2.4012112617492676 | CLS Loss: 0.0032386339735239744\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 2.3682708740234375 | KNN Loss: 2.356659173965454 | CLS Loss: 0.011611618101596832\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 2.3752055168151855 | KNN Loss: 2.362138032913208 | CLS Loss: 0.013067511841654778\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 2.372469663619995 | KNN Loss: 2.3665688037872314 | CLS Loss: 0.005900876130908728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 2.4133758544921875 | KNN Loss: 2.394998550415039 | CLS Loss: 0.018377244472503662\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 2.3793256282806396 | KNN Loss: 2.3762621879577637 | CLS Loss: 0.0030634193681180477\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 2.4180376529693604 | KNN Loss: 2.3935165405273438 | CLS Loss: 0.024521199986338615\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 2.4487240314483643 | KNN Loss: 2.4326465129852295 | CLS Loss: 0.016077591106295586\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 2.4032468795776367 | KNN Loss: 2.3990578651428223 | CLS Loss: 0.004189037252217531\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 2.367698907852173 | KNN Loss: 2.361074686050415 | CLS Loss: 0.006624209228903055\n",
      "Epoch: 145, Loss: 2.4067, Train: 0.9978, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 2.421119213104248 | KNN Loss: 2.4184162616729736 | CLS Loss: 0.002702998463064432\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 2.4055511951446533 | KNN Loss: 2.3857054710388184 | CLS Loss: 0.01984565332531929\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 2.4468002319335938 | KNN Loss: 2.436228036880493 | CLS Loss: 0.010572277009487152\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 2.4451427459716797 | KNN Loss: 2.435858964920044 | CLS Loss: 0.009283664636313915\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 2.425724506378174 | KNN Loss: 2.420728921890259 | CLS Loss: 0.004995477851480246\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 2.3999221324920654 | KNN Loss: 2.3931047916412354 | CLS Loss: 0.006817278917878866\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 2.4232187271118164 | KNN Loss: 2.4106199741363525 | CLS Loss: 0.012598645873367786\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 2.4175288677215576 | KNN Loss: 2.410778045654297 | CLS Loss: 0.006750916596502066\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 2.3766839504241943 | KNN Loss: 2.3645222187042236 | CLS Loss: 0.01216165628284216\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 2.426778793334961 | KNN Loss: 2.403087854385376 | CLS Loss: 0.023691043257713318\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 2.4039385318756104 | KNN Loss: 2.3952505588531494 | CLS Loss: 0.008687871508300304\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 2.3826944828033447 | KNN Loss: 2.373417615890503 | CLS Loss: 0.009276903234422207\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 2.432624101638794 | KNN Loss: 2.4216256141662598 | CLS Loss: 0.01099838875234127\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 2.382552146911621 | KNN Loss: 2.3768324851989746 | CLS Loss: 0.005719569977372885\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 2.3748667240142822 | KNN Loss: 2.3709874153137207 | CLS Loss: 0.003879386465996504\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 2.410240411758423 | KNN Loss: 2.400289535522461 | CLS Loss: 0.00995080266147852\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 2.413992404937744 | KNN Loss: 2.412250518798828 | CLS Loss: 0.0017418696079403162\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 2.3490350246429443 | KNN Loss: 2.3400802612304688 | CLS Loss: 0.008954823948442936\n",
      "Epoch: 146, Loss: 2.4082, Train: 0.9975, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 2.378725051879883 | KNN Loss: 2.375448226928711 | CLS Loss: 0.00327689410187304\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 2.451523780822754 | KNN Loss: 2.4487199783325195 | CLS Loss: 0.0028038411401212215\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 2.4215962886810303 | KNN Loss: 2.4126198291778564 | CLS Loss: 0.00897647999227047\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 2.435214042663574 | KNN Loss: 2.429455518722534 | CLS Loss: 0.005758458282798529\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 2.4157540798187256 | KNN Loss: 2.4028480052948 | CLS Loss: 0.012906108051538467\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 2.3909268379211426 | KNN Loss: 2.3798930644989014 | CLS Loss: 0.011033755727112293\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 2.3882179260253906 | KNN Loss: 2.3755054473876953 | CLS Loss: 0.012712361291050911\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 2.441643476486206 | KNN Loss: 2.4191946983337402 | CLS Loss: 0.02244887687265873\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 2.3745617866516113 | KNN Loss: 2.367043972015381 | CLS Loss: 0.007517751771956682\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 2.4020423889160156 | KNN Loss: 2.3875744342803955 | CLS Loss: 0.014467868022620678\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 2.4001410007476807 | KNN Loss: 2.3879170417785645 | CLS Loss: 0.012223982252180576\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 2.4014298915863037 | KNN Loss: 2.3860342502593994 | CLS Loss: 0.01539561152458191\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 2.382700204849243 | KNN Loss: 2.3612115383148193 | CLS Loss: 0.02148859016597271\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 2.406782865524292 | KNN Loss: 2.3909871578216553 | CLS Loss: 0.015795685350894928\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 2.4279863834381104 | KNN Loss: 2.395594835281372 | CLS Loss: 0.032391663640737534\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 2.4204373359680176 | KNN Loss: 2.4127514362335205 | CLS Loss: 0.007685922551900148\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 2.4062485694885254 | KNN Loss: 2.397081136703491 | CLS Loss: 0.009167417883872986\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 2.391239881515503 | KNN Loss: 2.378133535385132 | CLS Loss: 0.013106356374919415\n",
      "Epoch: 147, Loss: 2.4103, Train: 0.9968, Valid: 0.9854, Best: 0.9872\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 2.4106664657592773 | KNN Loss: 2.408085584640503 | CLS Loss: 0.002580906730145216\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 2.418142795562744 | KNN Loss: 2.413928747177124 | CLS Loss: 0.0042139459401369095\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 2.45393705368042 | KNN Loss: 2.4411251544952393 | CLS Loss: 0.012811988592147827\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 2.4209911823272705 | KNN Loss: 2.416217088699341 | CLS Loss: 0.004774068016558886\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 2.4135541915893555 | KNN Loss: 2.4011170864105225 | CLS Loss: 0.012437095865607262\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 2.4257760047912598 | KNN Loss: 2.4245967864990234 | CLS Loss: 0.0011792998993769288\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 2.4041619300842285 | KNN Loss: 2.403158664703369 | CLS Loss: 0.0010032225400209427\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 2.3765523433685303 | KNN Loss: 2.374652862548828 | CLS Loss: 0.0018993893172591925\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 2.407405138015747 | KNN Loss: 2.38395619392395 | CLS Loss: 0.023449011147022247\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 2.404714822769165 | KNN Loss: 2.3998303413391113 | CLS Loss: 0.004884498659521341\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 2.391253709793091 | KNN Loss: 2.3817975521087646 | CLS Loss: 0.009456053376197815\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 2.4012064933776855 | KNN Loss: 2.3977534770965576 | CLS Loss: 0.0034530682023614645\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 2.396097421646118 | KNN Loss: 2.3694870471954346 | CLS Loss: 0.026610415428876877\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 2.383716344833374 | KNN Loss: 2.375558376312256 | CLS Loss: 0.00815789494663477\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 2.3967037200927734 | KNN Loss: 2.386143207550049 | CLS Loss: 0.010560547932982445\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 2.403252124786377 | KNN Loss: 2.384533166885376 | CLS Loss: 0.018718987703323364\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 2.4019806385040283 | KNN Loss: 2.401228666305542 | CLS Loss: 0.0007520051440224051\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 2.4098260402679443 | KNN Loss: 2.4064605236053467 | CLS Loss: 0.003365428652614355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148, Loss: 2.4070, Train: 0.9959, Valid: 0.9845, Best: 0.9872\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 2.444162130355835 | KNN Loss: 2.409745693206787 | CLS Loss: 0.03441649675369263\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 2.417348861694336 | KNN Loss: 2.412590503692627 | CLS Loss: 0.004758280701935291\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 2.4143965244293213 | KNN Loss: 2.393092393875122 | CLS Loss: 0.021304160356521606\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 2.4054372310638428 | KNN Loss: 2.3918607234954834 | CLS Loss: 0.01357639953494072\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 2.4007883071899414 | KNN Loss: 2.3769075870513916 | CLS Loss: 0.023880617693066597\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 2.392603874206543 | KNN Loss: 2.390293836593628 | CLS Loss: 0.0023101160768419504\n",
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 2.440016746520996 | KNN Loss: 2.433034658432007 | CLS Loss: 0.006982048507779837\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 2.39243483543396 | KNN Loss: 2.389784097671509 | CLS Loss: 0.0026507617440074682\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 2.394956111907959 | KNN Loss: 2.3847737312316895 | CLS Loss: 0.010182437486946583\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 2.3804473876953125 | KNN Loss: 2.379086971282959 | CLS Loss: 0.0013603346887975931\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 2.391510009765625 | KNN Loss: 2.3863227367401123 | CLS Loss: 0.005187257193028927\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 2.381537914276123 | KNN Loss: 2.3706741333007812 | CLS Loss: 0.010863743722438812\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 2.37758731842041 | KNN Loss: 2.367192268371582 | CLS Loss: 0.01039509940892458\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 2.4394547939300537 | KNN Loss: 2.408484697341919 | CLS Loss: 0.030970122665166855\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 2.4009785652160645 | KNN Loss: 2.389338254928589 | CLS Loss: 0.011640251614153385\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 2.411069393157959 | KNN Loss: 2.4077508449554443 | CLS Loss: 0.0033184722997248173\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 2.427764415740967 | KNN Loss: 2.412182092666626 | CLS Loss: 0.015582417137920856\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 2.4016199111938477 | KNN Loss: 2.382275104522705 | CLS Loss: 0.01934480294585228\n",
      "Epoch: 149, Loss: 2.4095, Train: 0.9967, Valid: 0.9849, Best: 0.9872\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 2.4214975833892822 | KNN Loss: 2.4174253940582275 | CLS Loss: 0.004072289913892746\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 2.3958096504211426 | KNN Loss: 2.393869161605835 | CLS Loss: 0.00194053933955729\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 2.3731637001037598 | KNN Loss: 2.371042490005493 | CLS Loss: 0.002121296478435397\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 2.381042718887329 | KNN Loss: 2.3642489910125732 | CLS Loss: 0.01679382286965847\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 2.406527519226074 | KNN Loss: 2.4031903743743896 | CLS Loss: 0.0033371394965797663\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 2.4065284729003906 | KNN Loss: 2.3766028881073 | CLS Loss: 0.029925569891929626\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 2.413766384124756 | KNN Loss: 2.4090027809143066 | CLS Loss: 0.0047635301016271114\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 2.3997271060943604 | KNN Loss: 2.388374090194702 | CLS Loss: 0.011353123001754284\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 2.389807939529419 | KNN Loss: 2.3832759857177734 | CLS Loss: 0.006531863939017057\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 2.4343738555908203 | KNN Loss: 2.4318699836730957 | CLS Loss: 0.0025038542225956917\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 2.4041802883148193 | KNN Loss: 2.4031083583831787 | CLS Loss: 0.0010720484424382448\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 2.4245352745056152 | KNN Loss: 2.404277801513672 | CLS Loss: 0.020257582888007164\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 2.4259798526763916 | KNN Loss: 2.4201395511627197 | CLS Loss: 0.005840313620865345\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 2.4385125637054443 | KNN Loss: 2.421704053878784 | CLS Loss: 0.016808591783046722\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 2.4144957065582275 | KNN Loss: 2.401338577270508 | CLS Loss: 0.013157070614397526\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 2.3928656578063965 | KNN Loss: 2.391080617904663 | CLS Loss: 0.0017850568983703852\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 2.4202606678009033 | KNN Loss: 2.405940055847168 | CLS Loss: 0.01432052068412304\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 2.4221951961517334 | KNN Loss: 2.421207904815674 | CLS Loss: 0.000987282837741077\n",
      "Epoch: 150, Loss: 2.4066, Train: 0.9974, Valid: 0.9856, Best: 0.9872\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 2.384112596511841 | KNN Loss: 2.380486011505127 | CLS Loss: 0.0036265444941818714\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 2.3921163082122803 | KNN Loss: 2.3876025676727295 | CLS Loss: 0.004513676278293133\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 2.4096357822418213 | KNN Loss: 2.4060680866241455 | CLS Loss: 0.003567697247490287\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 2.3791067600250244 | KNN Loss: 2.375570058822632 | CLS Loss: 0.003536625998094678\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 2.430058717727661 | KNN Loss: 2.4203081130981445 | CLS Loss: 0.009750659577548504\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 2.4057295322418213 | KNN Loss: 2.394225597381592 | CLS Loss: 0.011504020541906357\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 2.388040065765381 | KNN Loss: 2.379258155822754 | CLS Loss: 0.00878190714865923\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 2.393893241882324 | KNN Loss: 2.3900864124298096 | CLS Loss: 0.0038069412112236023\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 2.378629446029663 | KNN Loss: 2.3695507049560547 | CLS Loss: 0.009078627452254295\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 2.3848071098327637 | KNN Loss: 2.3803327083587646 | CLS Loss: 0.004474424757063389\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 2.445441722869873 | KNN Loss: 2.4140939712524414 | CLS Loss: 0.03134779632091522\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 2.4125821590423584 | KNN Loss: 2.401256799697876 | CLS Loss: 0.011325258761644363\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 2.4012112617492676 | KNN Loss: 2.397125482559204 | CLS Loss: 0.0040857852436602116\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 2.4014320373535156 | KNN Loss: 2.3995625972747803 | CLS Loss: 0.001869440427981317\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 2.3917930126190186 | KNN Loss: 2.3818488121032715 | CLS Loss: 0.00994431134313345\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 2.4477975368499756 | KNN Loss: 2.425095319747925 | CLS Loss: 0.022702274844050407\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 2.443319320678711 | KNN Loss: 2.432420015335083 | CLS Loss: 0.010899189859628677\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 2.4150197505950928 | KNN Loss: 2.4054460525512695 | CLS Loss: 0.009573791176080704\n",
      "Epoch: 151, Loss: 2.4054, Train: 0.9958, Valid: 0.9853, Best: 0.9872\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 2.3898842334747314 | KNN Loss: 2.3846116065979004 | CLS Loss: 0.005272539798170328\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 2.3933985233306885 | KNN Loss: 2.372277021408081 | CLS Loss: 0.0211214330047369\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 2.3789710998535156 | KNN Loss: 2.3558783531188965 | CLS Loss: 0.023092690855264664\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 2.448197364807129 | KNN Loss: 2.438692808151245 | CLS Loss: 0.009504597634077072\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 2.3713042736053467 | KNN Loss: 2.3650851249694824 | CLS Loss: 0.006219095084816217\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 2.4330337047576904 | KNN Loss: 2.4208984375 | CLS Loss: 0.012135189026594162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 2.4184517860412598 | KNN Loss: 2.413170337677002 | CLS Loss: 0.005281556863337755\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 2.412416696548462 | KNN Loss: 2.408963203430176 | CLS Loss: 0.0034534367732703686\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 2.3978819847106934 | KNN Loss: 2.396674394607544 | CLS Loss: 0.0012075315462425351\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 2.370090961456299 | KNN Loss: 2.363598585128784 | CLS Loss: 0.006492315791547298\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 2.4271326065063477 | KNN Loss: 2.4233052730560303 | CLS Loss: 0.003827235661447048\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 2.467238426208496 | KNN Loss: 2.4562411308288574 | CLS Loss: 0.010997183620929718\n",
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 2.3843889236450195 | KNN Loss: 2.3700692653656006 | CLS Loss: 0.01431970950216055\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 2.385526180267334 | KNN Loss: 2.3735830783843994 | CLS Loss: 0.01194320060312748\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 2.4223647117614746 | KNN Loss: 2.408132791519165 | CLS Loss: 0.01423185970634222\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 2.4018352031707764 | KNN Loss: 2.3979976177215576 | CLS Loss: 0.003837496740743518\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 2.4049019813537598 | KNN Loss: 2.3864128589630127 | CLS Loss: 0.018489211797714233\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 2.4401426315307617 | KNN Loss: 2.4300427436828613 | CLS Loss: 0.010099925100803375\n",
      "Epoch: 152, Loss: 2.4088, Train: 0.9972, Valid: 0.9856, Best: 0.9872\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 2.3966095447540283 | KNN Loss: 2.3933565616607666 | CLS Loss: 0.0032529649324715137\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 2.4389264583587646 | KNN Loss: 2.424138069152832 | CLS Loss: 0.014788304455578327\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 2.406353235244751 | KNN Loss: 2.3976645469665527 | CLS Loss: 0.00868861936032772\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 2.4087607860565186 | KNN Loss: 2.390058994293213 | CLS Loss: 0.018701765686273575\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 2.4171664714813232 | KNN Loss: 2.402998924255371 | CLS Loss: 0.014167551882565022\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 2.4157001972198486 | KNN Loss: 2.409428119659424 | CLS Loss: 0.0062721590511500835\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 2.3890435695648193 | KNN Loss: 2.3797266483306885 | CLS Loss: 0.009316820651292801\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 2.418785333633423 | KNN Loss: 2.416896343231201 | CLS Loss: 0.0018889391794800758\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 2.435455083847046 | KNN Loss: 2.410792112350464 | CLS Loss: 0.02466297149658203\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 2.3947227001190186 | KNN Loss: 2.3909873962402344 | CLS Loss: 0.003735265461727977\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 2.394184112548828 | KNN Loss: 2.389608144760132 | CLS Loss: 0.004576000850647688\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 2.4091906547546387 | KNN Loss: 2.3986477851867676 | CLS Loss: 0.010542981326580048\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 2.4252820014953613 | KNN Loss: 2.4134604930877686 | CLS Loss: 0.011821569874882698\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 2.3760201930999756 | KNN Loss: 2.3666486740112305 | CLS Loss: 0.009371618740260601\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 2.403931140899658 | KNN Loss: 2.3978166580200195 | CLS Loss: 0.006114553660154343\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 2.3704640865325928 | KNN Loss: 2.3694772720336914 | CLS Loss: 0.0009867482585832477\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 2.419792890548706 | KNN Loss: 2.3979415893554688 | CLS Loss: 0.021851398050785065\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 2.3869848251342773 | KNN Loss: 2.366875648498535 | CLS Loss: 0.020109225064516068\n",
      "Epoch: 153, Loss: 2.4099, Train: 0.9949, Valid: 0.9849, Best: 0.9872\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 2.4222936630249023 | KNN Loss: 2.402796983718872 | CLS Loss: 0.01949659176170826\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 2.387012481689453 | KNN Loss: 2.374319076538086 | CLS Loss: 0.012693398632109165\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 2.431211471557617 | KNN Loss: 2.422966480255127 | CLS Loss: 0.00824499037116766\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 2.4047346115112305 | KNN Loss: 2.398878574371338 | CLS Loss: 0.005856112111359835\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 2.381906270980835 | KNN Loss: 2.3742446899414062 | CLS Loss: 0.007661491632461548\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 2.4108152389526367 | KNN Loss: 2.406757116317749 | CLS Loss: 0.004058046266436577\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 2.3980371952056885 | KNN Loss: 2.392230987548828 | CLS Loss: 0.005806097760796547\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 2.3864424228668213 | KNN Loss: 2.3834986686706543 | CLS Loss: 0.002943819621577859\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 2.390998125076294 | KNN Loss: 2.362691640853882 | CLS Loss: 0.028306569904088974\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 2.4105629920959473 | KNN Loss: 2.408888816833496 | CLS Loss: 0.001674058148637414\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 2.422151565551758 | KNN Loss: 2.4104111194610596 | CLS Loss: 0.011740511283278465\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 2.4003331661224365 | KNN Loss: 2.3984885215759277 | CLS Loss: 0.0018446124158799648\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 2.396381139755249 | KNN Loss: 2.388714075088501 | CLS Loss: 0.00766704510897398\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 2.4693384170532227 | KNN Loss: 2.4528541564941406 | CLS Loss: 0.016484158113598824\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 2.418142557144165 | KNN Loss: 2.4092023372650146 | CLS Loss: 0.008940119296312332\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 2.38425874710083 | KNN Loss: 2.377898931503296 | CLS Loss: 0.006359799765050411\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 2.423398017883301 | KNN Loss: 2.420597553253174 | CLS Loss: 0.0028003614861518145\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 2.390129804611206 | KNN Loss: 2.3844451904296875 | CLS Loss: 0.005684620700776577\n",
      "Epoch: 154, Loss: 2.4077, Train: 0.9974, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 2.38789963722229 | KNN Loss: 2.381516218185425 | CLS Loss: 0.006383476313203573\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 2.409128189086914 | KNN Loss: 2.40523624420166 | CLS Loss: 0.0038919684011489153\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 2.399632215499878 | KNN Loss: 2.3961973190307617 | CLS Loss: 0.003435010090470314\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 2.409008502960205 | KNN Loss: 2.4059553146362305 | CLS Loss: 0.0030532272066920996\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 2.414259672164917 | KNN Loss: 2.4072062969207764 | CLS Loss: 0.007053465116769075\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 2.4068288803100586 | KNN Loss: 2.3946940898895264 | CLS Loss: 0.01213483139872551\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 2.3997271060943604 | KNN Loss: 2.3885767459869385 | CLS Loss: 0.011150272563099861\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 2.425597906112671 | KNN Loss: 2.415780782699585 | CLS Loss: 0.009817101992666721\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 2.4313442707061768 | KNN Loss: 2.42960786819458 | CLS Loss: 0.0017364064697176218\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 2.4131665229797363 | KNN Loss: 2.390578508377075 | CLS Loss: 0.022587915882468224\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 2.411994218826294 | KNN Loss: 2.408801317214966 | CLS Loss: 0.0031929872930049896\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 2.402571201324463 | KNN Loss: 2.399477243423462 | CLS Loss: 0.003093849401921034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 2.434494733810425 | KNN Loss: 2.424710273742676 | CLS Loss: 0.009784398600459099\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 2.4036617279052734 | KNN Loss: 2.3947813510894775 | CLS Loss: 0.008880479261279106\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 2.4097115993499756 | KNN Loss: 2.4057745933532715 | CLS Loss: 0.003936906810849905\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 2.410839557647705 | KNN Loss: 2.4064414501190186 | CLS Loss: 0.00439799576997757\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 2.404160499572754 | KNN Loss: 2.3962314128875732 | CLS Loss: 0.00792916864156723\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 2.3837244510650635 | KNN Loss: 2.3737735748291016 | CLS Loss: 0.009950980544090271\n",
      "Epoch: 155, Loss: 2.4137, Train: 0.9970, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 2.4218616485595703 | KNN Loss: 2.4171524047851562 | CLS Loss: 0.004709149710834026\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 2.3734281063079834 | KNN Loss: 2.3702242374420166 | CLS Loss: 0.003203987842425704\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 2.4369425773620605 | KNN Loss: 2.4245893955230713 | CLS Loss: 0.012353169731795788\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 2.44680118560791 | KNN Loss: 2.4406473636627197 | CLS Loss: 0.0061538489535450935\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 2.455556631088257 | KNN Loss: 2.450021505355835 | CLS Loss: 0.005535012576729059\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 2.424532175064087 | KNN Loss: 2.4172186851501465 | CLS Loss: 0.007313531823456287\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 2.4264700412750244 | KNN Loss: 2.422039270401001 | CLS Loss: 0.004430803470313549\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 2.467726945877075 | KNN Loss: 2.4397668838500977 | CLS Loss: 0.02795998752117157\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 2.4057540893554688 | KNN Loss: 2.396268844604492 | CLS Loss: 0.009485357441008091\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 2.4493749141693115 | KNN Loss: 2.4401302337646484 | CLS Loss: 0.009244699962437153\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 2.414416551589966 | KNN Loss: 2.406364917755127 | CLS Loss: 0.008051586337387562\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 2.4226319789886475 | KNN Loss: 2.4111812114715576 | CLS Loss: 0.01145083922892809\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 2.446507215499878 | KNN Loss: 2.4355554580688477 | CLS Loss: 0.010951640084385872\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 2.3981659412384033 | KNN Loss: 2.3948612213134766 | CLS Loss: 0.0033047550823539495\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 2.4408257007598877 | KNN Loss: 2.4220173358917236 | CLS Loss: 0.01880832016468048\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 2.4007933139801025 | KNN Loss: 2.3842358589172363 | CLS Loss: 0.016557564958930016\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 2.3827521800994873 | KNN Loss: 2.381085157394409 | CLS Loss: 0.0016669797478243709\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 2.407460927963257 | KNN Loss: 2.399749755859375 | CLS Loss: 0.007711081765592098\n",
      "Epoch: 156, Loss: 2.4203, Train: 0.9966, Valid: 0.9854, Best: 0.9872\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 2.4312689304351807 | KNN Loss: 2.430105686187744 | CLS Loss: 0.0011632851092144847\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 2.428345203399658 | KNN Loss: 2.4247448444366455 | CLS Loss: 0.0036003950517624617\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 2.4249215126037598 | KNN Loss: 2.40812611579895 | CLS Loss: 0.016795502975583076\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 2.4231343269348145 | KNN Loss: 2.4168245792388916 | CLS Loss: 0.0063098641112446785\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 2.4367642402648926 | KNN Loss: 2.421619176864624 | CLS Loss: 0.015144946053624153\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 2.4213979244232178 | KNN Loss: 2.4143147468566895 | CLS Loss: 0.007083207368850708\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 2.426647663116455 | KNN Loss: 2.4043428897857666 | CLS Loss: 0.022304844111204147\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 2.4077415466308594 | KNN Loss: 2.4061129093170166 | CLS Loss: 0.0016285270685330033\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 2.4210336208343506 | KNN Loss: 2.4181711673736572 | CLS Loss: 0.002862389199435711\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 2.4223058223724365 | KNN Loss: 2.416118621826172 | CLS Loss: 0.006187101360410452\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 2.4230756759643555 | KNN Loss: 2.4080538749694824 | CLS Loss: 0.01502181775867939\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 2.402804136276245 | KNN Loss: 2.3973517417907715 | CLS Loss: 0.005452292505651712\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 2.4230434894561768 | KNN Loss: 2.418823003768921 | CLS Loss: 0.00422038184478879\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 2.399416923522949 | KNN Loss: 2.382127285003662 | CLS Loss: 0.0172895360738039\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 2.4049110412597656 | KNN Loss: 2.401982307434082 | CLS Loss: 0.002928738249465823\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 2.446742534637451 | KNN Loss: 2.4423646926879883 | CLS Loss: 0.0043778009712696075\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 2.3890037536621094 | KNN Loss: 2.3835091590881348 | CLS Loss: 0.005494588986039162\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 2.4131972789764404 | KNN Loss: 2.40541672706604 | CLS Loss: 0.00778044993057847\n",
      "Epoch: 157, Loss: 2.4174, Train: 0.9979, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 2.397108554840088 | KNN Loss: 2.386770725250244 | CLS Loss: 0.01033789198845625\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 2.467723846435547 | KNN Loss: 2.453294277191162 | CLS Loss: 0.014429496601223946\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 2.431187629699707 | KNN Loss: 2.418231725692749 | CLS Loss: 0.012955914251506329\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 2.4115095138549805 | KNN Loss: 2.398303985595703 | CLS Loss: 0.013205474242568016\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 2.4188404083251953 | KNN Loss: 2.4105710983276367 | CLS Loss: 0.008269223384559155\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 2.409097909927368 | KNN Loss: 2.4047412872314453 | CLS Loss: 0.004356677643954754\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 2.408470630645752 | KNN Loss: 2.391756296157837 | CLS Loss: 0.016714395955204964\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 2.435277223587036 | KNN Loss: 2.416588544845581 | CLS Loss: 0.01868877187371254\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 2.428257465362549 | KNN Loss: 2.4259068965911865 | CLS Loss: 0.0023505555000156164\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 2.4105913639068604 | KNN Loss: 2.405100107192993 | CLS Loss: 0.005491368472576141\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 2.3911190032958984 | KNN Loss: 2.3811285495758057 | CLS Loss: 0.009990419261157513\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 2.412907838821411 | KNN Loss: 2.4089481830596924 | CLS Loss: 0.003959554713219404\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 2.418879270553589 | KNN Loss: 2.415773868560791 | CLS Loss: 0.0031054229475557804\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 2.44095778465271 | KNN Loss: 2.4211604595184326 | CLS Loss: 0.019797304645180702\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 2.424870014190674 | KNN Loss: 2.4214327335357666 | CLS Loss: 0.0034372699446976185\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 2.4131736755371094 | KNN Loss: 2.401761054992676 | CLS Loss: 0.011412539519369602\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 2.4088973999023438 | KNN Loss: 2.403273344039917 | CLS Loss: 0.005624160170555115\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 2.415393590927124 | KNN Loss: 2.4047508239746094 | CLS Loss: 0.010642703622579575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 158, Loss: 2.4192, Train: 0.9964, Valid: 0.9853, Best: 0.9872\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 2.443228006362915 | KNN Loss: 2.433905839920044 | CLS Loss: 0.00932206679135561\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 2.43428897857666 | KNN Loss: 2.4239776134490967 | CLS Loss: 0.010311344638466835\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 2.4657115936279297 | KNN Loss: 2.456658363342285 | CLS Loss: 0.009053127840161324\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 2.4090301990509033 | KNN Loss: 2.4027915000915527 | CLS Loss: 0.006238613277673721\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 2.4046480655670166 | KNN Loss: 2.396949052810669 | CLS Loss: 0.007698944304138422\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 2.384688377380371 | KNN Loss: 2.3804023265838623 | CLS Loss: 0.004286156967282295\n",
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 2.404247522354126 | KNN Loss: 2.395864963531494 | CLS Loss: 0.008382528088986874\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 2.437911033630371 | KNN Loss: 2.433582067489624 | CLS Loss: 0.004328953567892313\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 2.4166259765625 | KNN Loss: 2.4100635051727295 | CLS Loss: 0.006562554277479649\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 2.38848614692688 | KNN Loss: 2.3834388256073 | CLS Loss: 0.005047205835580826\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 2.4036967754364014 | KNN Loss: 2.3743433952331543 | CLS Loss: 0.029353484511375427\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 2.4235146045684814 | KNN Loss: 2.393885850906372 | CLS Loss: 0.029628649353981018\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 2.4179909229278564 | KNN Loss: 2.396481990814209 | CLS Loss: 0.021509019657969475\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 2.4029159545898438 | KNN Loss: 2.3999202251434326 | CLS Loss: 0.002995843766257167\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 2.410827159881592 | KNN Loss: 2.4074058532714844 | CLS Loss: 0.0034212141763418913\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 2.4285407066345215 | KNN Loss: 2.4143848419189453 | CLS Loss: 0.014155978336930275\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 2.440680503845215 | KNN Loss: 2.437664747238159 | CLS Loss: 0.003015663707628846\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 2.404691219329834 | KNN Loss: 2.4029202461242676 | CLS Loss: 0.0017710115062072873\n",
      "Epoch: 159, Loss: 2.4197, Train: 0.9973, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 2.4113032817840576 | KNN Loss: 2.408381700515747 | CLS Loss: 0.0029214692767709494\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 2.398036479949951 | KNN Loss: 2.395296573638916 | CLS Loss: 0.0027399584650993347\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 2.4299862384796143 | KNN Loss: 2.4234862327575684 | CLS Loss: 0.00650005741044879\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 2.44326114654541 | KNN Loss: 2.44270396232605 | CLS Loss: 0.0005571531364694238\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 2.4218051433563232 | KNN Loss: 2.41190242767334 | CLS Loss: 0.009902706369757652\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 2.423393964767456 | KNN Loss: 2.421581983566284 | CLS Loss: 0.0018119711894541979\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 2.392439842224121 | KNN Loss: 2.3846755027770996 | CLS Loss: 0.007764370646327734\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 2.4058945178985596 | KNN Loss: 2.4048633575439453 | CLS Loss: 0.001031099003739655\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 2.4095733165740967 | KNN Loss: 2.402974843978882 | CLS Loss: 0.006598406005650759\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 2.4225640296936035 | KNN Loss: 2.420131206512451 | CLS Loss: 0.002432827604934573\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 2.423248767852783 | KNN Loss: 2.414247751235962 | CLS Loss: 0.009001022204756737\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 2.464808702468872 | KNN Loss: 2.4304065704345703 | CLS Loss: 0.034402232617139816\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 2.416548252105713 | KNN Loss: 2.4078409671783447 | CLS Loss: 0.008707369677722454\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 2.438870668411255 | KNN Loss: 2.4373199939727783 | CLS Loss: 0.0015507654752582312\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 2.400953769683838 | KNN Loss: 2.3955817222595215 | CLS Loss: 0.0053720311261713505\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 2.4427030086517334 | KNN Loss: 2.4206793308258057 | CLS Loss: 0.022023765370249748\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 2.4476914405822754 | KNN Loss: 2.443833827972412 | CLS Loss: 0.003857614006847143\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 2.4292948246002197 | KNN Loss: 2.4210119247436523 | CLS Loss: 0.008282874710857868\n",
      "Epoch: 160, Loss: 2.4208, Train: 0.9956, Valid: 0.9852, Best: 0.9872\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 2.41900634765625 | KNN Loss: 2.4123647212982178 | CLS Loss: 0.006641638930886984\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 2.4342901706695557 | KNN Loss: 2.4194231033325195 | CLS Loss: 0.014866954647004604\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 2.437565803527832 | KNN Loss: 2.4180238246917725 | CLS Loss: 0.019542068243026733\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 2.387955904006958 | KNN Loss: 2.3726165294647217 | CLS Loss: 0.015339268371462822\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 2.433480978012085 | KNN Loss: 2.4325408935546875 | CLS Loss: 0.0009400967974215746\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 2.4114460945129395 | KNN Loss: 2.4105148315429688 | CLS Loss: 0.0009313326445408165\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 2.401979684829712 | KNN Loss: 2.382385730743408 | CLS Loss: 0.01959390379488468\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 2.427985906600952 | KNN Loss: 2.4263150691986084 | CLS Loss: 0.0016709016636013985\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 2.417142868041992 | KNN Loss: 2.404067039489746 | CLS Loss: 0.0130757512524724\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 2.4156932830810547 | KNN Loss: 2.4035744667053223 | CLS Loss: 0.012118772603571415\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 2.370234489440918 | KNN Loss: 2.368659019470215 | CLS Loss: 0.0015754582127556205\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 2.4004178047180176 | KNN Loss: 2.3947970867156982 | CLS Loss: 0.0056206523440778255\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 2.3989176750183105 | KNN Loss: 2.3840177059173584 | CLS Loss: 0.014900026842951775\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 2.4047088623046875 | KNN Loss: 2.391406774520874 | CLS Loss: 0.013301997445523739\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 2.406930446624756 | KNN Loss: 2.4018166065216064 | CLS Loss: 0.005113914143294096\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 2.4055423736572266 | KNN Loss: 2.3937103748321533 | CLS Loss: 0.011832104995846748\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 2.3922078609466553 | KNN Loss: 2.3879082202911377 | CLS Loss: 0.004299522377550602\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 2.4174201488494873 | KNN Loss: 2.3991079330444336 | CLS Loss: 0.018312271684408188\n",
      "Epoch: 161, Loss: 2.4172, Train: 0.9978, Valid: 0.9868, Best: 0.9872\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 2.38140606880188 | KNN Loss: 2.367722272872925 | CLS Loss: 0.01368370559066534\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 2.4489309787750244 | KNN Loss: 2.4312846660614014 | CLS Loss: 0.017646227031946182\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 2.413788318634033 | KNN Loss: 2.403928756713867 | CLS Loss: 0.009859534911811352\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 2.3857221603393555 | KNN Loss: 2.3829822540283203 | CLS Loss: 0.0027398334350436926\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 2.419612407684326 | KNN Loss: 2.418400526046753 | CLS Loss: 0.0012119768653064966\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 2.4510719776153564 | KNN Loss: 2.446157932281494 | CLS Loss: 0.004914123099297285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 2.4197309017181396 | KNN Loss: 2.4131736755371094 | CLS Loss: 0.006557187996804714\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 2.409358501434326 | KNN Loss: 2.40689754486084 | CLS Loss: 0.0024608904495835304\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 2.3979856967926025 | KNN Loss: 2.391758680343628 | CLS Loss: 0.006227103527635336\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 2.4295308589935303 | KNN Loss: 2.4244730472564697 | CLS Loss: 0.005057752598077059\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 2.3954851627349854 | KNN Loss: 2.3830649852752686 | CLS Loss: 0.012420210056006908\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 2.4105212688446045 | KNN Loss: 2.400390863418579 | CLS Loss: 0.010130386799573898\n",
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 2.4687814712524414 | KNN Loss: 2.457796335220337 | CLS Loss: 0.01098511554300785\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 2.454808473587036 | KNN Loss: 2.4466195106506348 | CLS Loss: 0.008188966661691666\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 2.410831928253174 | KNN Loss: 2.4013421535491943 | CLS Loss: 0.00948982685804367\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 2.368631601333618 | KNN Loss: 2.366856098175049 | CLS Loss: 0.00177544925827533\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 2.439714193344116 | KNN Loss: 2.419506549835205 | CLS Loss: 0.020207535475492477\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 2.4571022987365723 | KNN Loss: 2.438897132873535 | CLS Loss: 0.018205109983682632\n",
      "Epoch: 162, Loss: 2.4197, Train: 0.9974, Valid: 0.9868, Best: 0.9872\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 2.386234998703003 | KNN Loss: 2.3837978839874268 | CLS Loss: 0.0024370462633669376\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 2.4030449390411377 | KNN Loss: 2.4013724327087402 | CLS Loss: 0.0016725948080420494\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 2.3917953968048096 | KNN Loss: 2.390211343765259 | CLS Loss: 0.0015840638661757112\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 2.4184443950653076 | KNN Loss: 2.3970441818237305 | CLS Loss: 0.02140018343925476\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 2.382354736328125 | KNN Loss: 2.3789634704589844 | CLS Loss: 0.0033912179060280323\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 2.4440815448760986 | KNN Loss: 2.4287707805633545 | CLS Loss: 0.015310692600905895\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 2.3987314701080322 | KNN Loss: 2.3921008110046387 | CLS Loss: 0.006630596239119768\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 2.4227359294891357 | KNN Loss: 2.413057804107666 | CLS Loss: 0.009678073227405548\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 2.401724100112915 | KNN Loss: 2.3939685821533203 | CLS Loss: 0.0077554695308208466\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 2.394343614578247 | KNN Loss: 2.3924050331115723 | CLS Loss: 0.001938521396368742\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 2.4002771377563477 | KNN Loss: 2.39862060546875 | CLS Loss: 0.0016564641846343875\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 2.402911901473999 | KNN Loss: 2.3790693283081055 | CLS Loss: 0.023842623457312584\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 2.4159011840820312 | KNN Loss: 2.409708023071289 | CLS Loss: 0.00619326950982213\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 2.4114749431610107 | KNN Loss: 2.408459186553955 | CLS Loss: 0.0030158155132085085\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 2.4342234134674072 | KNN Loss: 2.42500901222229 | CLS Loss: 0.009214472025632858\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 2.427839517593384 | KNN Loss: 2.4080514907836914 | CLS Loss: 0.019788067787885666\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 2.410259246826172 | KNN Loss: 2.377138376235962 | CLS Loss: 0.033120810985565186\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 2.422511339187622 | KNN Loss: 2.4145922660827637 | CLS Loss: 0.007918980903923512\n",
      "Epoch: 163, Loss: 2.4140, Train: 0.9976, Valid: 0.9860, Best: 0.9872\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 2.3911516666412354 | KNN Loss: 2.3561317920684814 | CLS Loss: 0.03501987084746361\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 2.417034149169922 | KNN Loss: 2.4020121097564697 | CLS Loss: 0.015021955594420433\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 2.4253504276275635 | KNN Loss: 2.417570114135742 | CLS Loss: 0.007780410349369049\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 2.454620838165283 | KNN Loss: 2.4450297355651855 | CLS Loss: 0.009591118432581425\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 2.4291086196899414 | KNN Loss: 2.4140243530273438 | CLS Loss: 0.015084262937307358\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 2.4427566528320312 | KNN Loss: 2.4395792484283447 | CLS Loss: 0.003177351551130414\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 2.381652593612671 | KNN Loss: 2.3766379356384277 | CLS Loss: 0.005014562048017979\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 2.392307996749878 | KNN Loss: 2.374784231185913 | CLS Loss: 0.017523815855383873\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 2.4077308177948 | KNN Loss: 2.4051315784454346 | CLS Loss: 0.002599128056317568\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 2.4639618396759033 | KNN Loss: 2.451437473297119 | CLS Loss: 0.01252426952123642\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 2.4352803230285645 | KNN Loss: 2.394360303878784 | CLS Loss: 0.040920108556747437\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 2.398672103881836 | KNN Loss: 2.382373332977295 | CLS Loss: 0.016298750415444374\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 2.3933751583099365 | KNN Loss: 2.3901865482330322 | CLS Loss: 0.0031885781791061163\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 2.429206609725952 | KNN Loss: 2.426940441131592 | CLS Loss: 0.002266202587634325\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 2.398580312728882 | KNN Loss: 2.3955342769622803 | CLS Loss: 0.003045927733182907\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 2.388218641281128 | KNN Loss: 2.381335973739624 | CLS Loss: 0.006882746238261461\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 2.4475979804992676 | KNN Loss: 2.426358699798584 | CLS Loss: 0.021239181980490685\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 2.4373300075531006 | KNN Loss: 2.434816837310791 | CLS Loss: 0.002513081068173051\n",
      "Epoch: 164, Loss: 2.4150, Train: 0.9970, Valid: 0.9854, Best: 0.9872\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 2.4047467708587646 | KNN Loss: 2.398885726928711 | CLS Loss: 0.005861016921699047\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 2.4076523780822754 | KNN Loss: 2.4055428504943848 | CLS Loss: 0.0021096058189868927\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 2.440768241882324 | KNN Loss: 2.439420223236084 | CLS Loss: 0.001347926678135991\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 2.40358829498291 | KNN Loss: 2.4003379344940186 | CLS Loss: 0.003250251291319728\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 2.4084243774414062 | KNN Loss: 2.399834394454956 | CLS Loss: 0.008589916862547398\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 2.4233009815216064 | KNN Loss: 2.406404495239258 | CLS Loss: 0.016896549612283707\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 2.434343099594116 | KNN Loss: 2.4253249168395996 | CLS Loss: 0.00901809148490429\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 2.4458258152008057 | KNN Loss: 2.4287619590759277 | CLS Loss: 0.017063776031136513\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 2.405684471130371 | KNN Loss: 2.3950161933898926 | CLS Loss: 0.010668282397091389\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 2.399890184402466 | KNN Loss: 2.39611554145813 | CLS Loss: 0.003774545853957534\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 2.469270706176758 | KNN Loss: 2.4471919536590576 | CLS Loss: 0.022078663110733032\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 2.3901302814483643 | KNN Loss: 2.3827004432678223 | CLS Loss: 0.007429950404912233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 2.418165445327759 | KNN Loss: 2.40348744392395 | CLS Loss: 0.01467798464000225\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 2.435713529586792 | KNN Loss: 2.4294190406799316 | CLS Loss: 0.006294600665569305\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 2.4189960956573486 | KNN Loss: 2.414642095565796 | CLS Loss: 0.004354076460003853\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 2.4105513095855713 | KNN Loss: 2.4028000831604004 | CLS Loss: 0.007751145865768194\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 2.416099786758423 | KNN Loss: 2.411648988723755 | CLS Loss: 0.004450783133506775\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 2.437040090560913 | KNN Loss: 2.4231956005096436 | CLS Loss: 0.013844595290720463\n",
      "Epoch: 165, Loss: 2.4162, Train: 0.9978, Valid: 0.9871, Best: 0.9872\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 2.389057159423828 | KNN Loss: 2.383793592453003 | CLS Loss: 0.0052634538151323795\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 2.391594409942627 | KNN Loss: 2.3870272636413574 | CLS Loss: 0.004567181225866079\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 2.4245598316192627 | KNN Loss: 2.42385196685791 | CLS Loss: 0.0007078290218487382\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 2.440481185913086 | KNN Loss: 2.437608003616333 | CLS Loss: 0.0028732430655509233\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 2.3960635662078857 | KNN Loss: 2.393268346786499 | CLS Loss: 0.0027951474767178297\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 2.4146230220794678 | KNN Loss: 2.4023349285125732 | CLS Loss: 0.012288207188248634\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 2.410839319229126 | KNN Loss: 2.4049806594848633 | CLS Loss: 0.005858541466295719\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 2.3881683349609375 | KNN Loss: 2.3865842819213867 | CLS Loss: 0.0015839380212128162\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 2.4099647998809814 | KNN Loss: 2.4087142944335938 | CLS Loss: 0.0012504211626946926\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 2.4288253784179688 | KNN Loss: 2.421546697616577 | CLS Loss: 0.007278667762875557\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 2.4298646450042725 | KNN Loss: 2.4281742572784424 | CLS Loss: 0.0016903328942134976\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 2.4149887561798096 | KNN Loss: 2.3909480571746826 | CLS Loss: 0.024040671065449715\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 2.4159226417541504 | KNN Loss: 2.393423080444336 | CLS Loss: 0.02249954268336296\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 2.4374654293060303 | KNN Loss: 2.4332377910614014 | CLS Loss: 0.004227575846016407\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 2.4020674228668213 | KNN Loss: 2.389312505722046 | CLS Loss: 0.012754987925291061\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 2.401029109954834 | KNN Loss: 2.3920180797576904 | CLS Loss: 0.00901113823056221\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 2.4025654792785645 | KNN Loss: 2.3971424102783203 | CLS Loss: 0.005422964226454496\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 2.4295246601104736 | KNN Loss: 2.417692184448242 | CLS Loss: 0.011832471005618572\n",
      "Epoch: 166, Loss: 2.4162, Train: 0.9976, Valid: 0.9865, Best: 0.9872\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 2.417832612991333 | KNN Loss: 2.4113264083862305 | CLS Loss: 0.006506249774247408\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 2.4017112255096436 | KNN Loss: 2.3909785747528076 | CLS Loss: 0.010732663795351982\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 2.4535412788391113 | KNN Loss: 2.434680700302124 | CLS Loss: 0.018860653042793274\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 2.4513421058654785 | KNN Loss: 2.440253973007202 | CLS Loss: 0.011088208295404911\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 2.447568893432617 | KNN Loss: 2.4433698654174805 | CLS Loss: 0.0041990443132817745\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 2.397103786468506 | KNN Loss: 2.3952252864837646 | CLS Loss: 0.0018784361891448498\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 2.428986072540283 | KNN Loss: 2.41727614402771 | CLS Loss: 0.011709834448993206\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 2.4414162635803223 | KNN Loss: 2.4385344982147217 | CLS Loss: 0.0028816508129239082\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 2.394282341003418 | KNN Loss: 2.3809335231781006 | CLS Loss: 0.013348892331123352\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 2.4399335384368896 | KNN Loss: 2.434067487716675 | CLS Loss: 0.005866144318133593\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 2.422309398651123 | KNN Loss: 2.4106523990631104 | CLS Loss: 0.01165706105530262\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 2.413529396057129 | KNN Loss: 2.4010324478149414 | CLS Loss: 0.012497040443122387\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 2.450244426727295 | KNN Loss: 2.428565740585327 | CLS Loss: 0.02167864516377449\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 2.43066668510437 | KNN Loss: 2.412245750427246 | CLS Loss: 0.018420863896608353\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 2.4335877895355225 | KNN Loss: 2.4240989685058594 | CLS Loss: 0.00948889460414648\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 2.4739410877227783 | KNN Loss: 2.438779830932617 | CLS Loss: 0.03516121953725815\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 2.3907551765441895 | KNN Loss: 2.3863277435302734 | CLS Loss: 0.004427524283528328\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 2.444566011428833 | KNN Loss: 2.42856502532959 | CLS Loss: 0.016000915318727493\n",
      "Epoch: 167, Loss: 2.4184, Train: 0.9970, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 2.417792558670044 | KNN Loss: 2.412686824798584 | CLS Loss: 0.005105629563331604\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 2.417557716369629 | KNN Loss: 2.412907123565674 | CLS Loss: 0.0046506114304065704\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 2.4518399238586426 | KNN Loss: 2.4478695392608643 | CLS Loss: 0.0039703273214399815\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 2.4322142601013184 | KNN Loss: 2.422018051147461 | CLS Loss: 0.010196183808147907\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 2.419654369354248 | KNN Loss: 2.417344331741333 | CLS Loss: 0.002309937961399555\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 2.3952178955078125 | KNN Loss: 2.3802080154418945 | CLS Loss: 0.015009810216724873\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 2.439260721206665 | KNN Loss: 2.43049955368042 | CLS Loss: 0.0087612085044384\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 2.468538999557495 | KNN Loss: 2.4405200481414795 | CLS Loss: 0.028018951416015625\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 2.43699312210083 | KNN Loss: 2.4288651943206787 | CLS Loss: 0.008127816952764988\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 2.387267827987671 | KNN Loss: 2.385873317718506 | CLS Loss: 0.001394613878801465\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 2.431441307067871 | KNN Loss: 2.413207530975342 | CLS Loss: 0.018233658745884895\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 2.4431281089782715 | KNN Loss: 2.4133591651916504 | CLS Loss: 0.0297690536826849\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 2.4232025146484375 | KNN Loss: 2.4130916595458984 | CLS Loss: 0.010110811330378056\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 2.4177303314208984 | KNN Loss: 2.4083058834075928 | CLS Loss: 0.00942444521933794\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 2.445431709289551 | KNN Loss: 2.4294495582580566 | CLS Loss: 0.015982244163751602\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 2.403869152069092 | KNN Loss: 2.389397621154785 | CLS Loss: 0.014471534639596939\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 2.417429208755493 | KNN Loss: 2.4115090370178223 | CLS Loss: 0.005920275580137968\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 2.4223225116729736 | KNN Loss: 2.3853583335876465 | CLS Loss: 0.036964159458875656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 168, Loss: 2.4199, Train: 0.9970, Valid: 0.9852, Best: 0.9872\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 2.3933002948760986 | KNN Loss: 2.3888840675354004 | CLS Loss: 0.004416283685714006\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 2.4267635345458984 | KNN Loss: 2.4117419719696045 | CLS Loss: 0.015021542087197304\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 2.4258947372436523 | KNN Loss: 2.4238414764404297 | CLS Loss: 0.0020533695351332426\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 2.395958662033081 | KNN Loss: 2.3925158977508545 | CLS Loss: 0.0034427656792104244\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 2.4156854152679443 | KNN Loss: 2.413133382797241 | CLS Loss: 0.0025520557537674904\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 2.3704793453216553 | KNN Loss: 2.366595506668091 | CLS Loss: 0.003883955767378211\n",
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 2.4039924144744873 | KNN Loss: 2.402238368988037 | CLS Loss: 0.001753952936269343\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 2.4098615646362305 | KNN Loss: 2.4024205207824707 | CLS Loss: 0.007440991699695587\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 2.41180419921875 | KNN Loss: 2.4088125228881836 | CLS Loss: 0.0029916188213974237\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 2.413456678390503 | KNN Loss: 2.400909662246704 | CLS Loss: 0.012546923011541367\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 2.423419237136841 | KNN Loss: 2.4117071628570557 | CLS Loss: 0.011711967177689075\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 2.4200053215026855 | KNN Loss: 2.3957228660583496 | CLS Loss: 0.02428237907588482\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 2.4011313915252686 | KNN Loss: 2.398376226425171 | CLS Loss: 0.0027551325038075447\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 2.409252643585205 | KNN Loss: 2.397188901901245 | CLS Loss: 0.012063775211572647\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 2.4540882110595703 | KNN Loss: 2.435575246810913 | CLS Loss: 0.018513068556785583\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 2.4247870445251465 | KNN Loss: 2.417213201522827 | CLS Loss: 0.0075737782754004\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 2.4181020259857178 | KNN Loss: 2.415043592453003 | CLS Loss: 0.0030583376064896584\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 2.3914685249328613 | KNN Loss: 2.3871707916259766 | CLS Loss: 0.004297693260014057\n",
      "Epoch: 169, Loss: 2.4135, Train: 0.9970, Valid: 0.9850, Best: 0.9872\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 2.4176268577575684 | KNN Loss: 2.409719228744507 | CLS Loss: 0.007907730527222157\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 2.3983447551727295 | KNN Loss: 2.3944778442382812 | CLS Loss: 0.0038669039495289326\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 2.4044229984283447 | KNN Loss: 2.402432441711426 | CLS Loss: 0.001990577671676874\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 2.418598175048828 | KNN Loss: 2.4127607345581055 | CLS Loss: 0.005837420467287302\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 2.4316563606262207 | KNN Loss: 2.4205162525177 | CLS Loss: 0.011140111833810806\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 2.4322710037231445 | KNN Loss: 2.4204978942871094 | CLS Loss: 0.01177302747964859\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 2.401088237762451 | KNN Loss: 2.393766403198242 | CLS Loss: 0.007321903947740793\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 2.4186208248138428 | KNN Loss: 2.399174213409424 | CLS Loss: 0.019446631893515587\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 2.408432960510254 | KNN Loss: 2.4039108753204346 | CLS Loss: 0.0045220935717225075\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 2.3972532749176025 | KNN Loss: 2.3896191120147705 | CLS Loss: 0.007634228095412254\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 2.418076276779175 | KNN Loss: 2.411526918411255 | CLS Loss: 0.006549364887177944\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 2.413719415664673 | KNN Loss: 2.393517255783081 | CLS Loss: 0.020202070474624634\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 2.453465700149536 | KNN Loss: 2.432274580001831 | CLS Loss: 0.021191205829381943\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 2.4159061908721924 | KNN Loss: 2.4061625003814697 | CLS Loss: 0.009743587113916874\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 2.459364175796509 | KNN Loss: 2.442554473876953 | CLS Loss: 0.016809586435556412\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 2.4188852310180664 | KNN Loss: 2.4099481105804443 | CLS Loss: 0.008937226608395576\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 2.4183461666107178 | KNN Loss: 2.403557300567627 | CLS Loss: 0.014788869768381119\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 2.443284034729004 | KNN Loss: 2.4297056198120117 | CLS Loss: 0.013578503392636776\n",
      "Epoch: 170, Loss: 2.4171, Train: 0.9962, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 2.418710708618164 | KNN Loss: 2.4155020713806152 | CLS Loss: 0.0032086537685245275\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 2.482616662979126 | KNN Loss: 2.455984354019165 | CLS Loss: 0.026632338762283325\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 2.4338107109069824 | KNN Loss: 2.4080355167388916 | CLS Loss: 0.02577514387667179\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 2.4124088287353516 | KNN Loss: 2.405200481414795 | CLS Loss: 0.007208247669041157\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 2.4323298931121826 | KNN Loss: 2.4208812713623047 | CLS Loss: 0.011448648758232594\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 2.41876220703125 | KNN Loss: 2.401279926300049 | CLS Loss: 0.017482275143265724\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 2.4457411766052246 | KNN Loss: 2.4405517578125 | CLS Loss: 0.005189451389014721\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 2.3934764862060547 | KNN Loss: 2.3904764652252197 | CLS Loss: 0.003000133903697133\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 2.4262211322784424 | KNN Loss: 2.420175552368164 | CLS Loss: 0.006045538932085037\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 2.3969359397888184 | KNN Loss: 2.3891706466674805 | CLS Loss: 0.007765278685837984\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 2.433847427368164 | KNN Loss: 2.412384510040283 | CLS Loss: 0.02146282233297825\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 2.3929457664489746 | KNN Loss: 2.3780829906463623 | CLS Loss: 0.014862710610032082\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 2.40615177154541 | KNN Loss: 2.3980534076690674 | CLS Loss: 0.008098269812762737\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 2.377775192260742 | KNN Loss: 2.376918315887451 | CLS Loss: 0.0008568960474804044\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 2.4025962352752686 | KNN Loss: 2.3976078033447266 | CLS Loss: 0.004988477099686861\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 2.44225811958313 | KNN Loss: 2.4380338191986084 | CLS Loss: 0.004224378615617752\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 2.3859832286834717 | KNN Loss: 2.3844363689422607 | CLS Loss: 0.001546878949739039\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 2.4124884605407715 | KNN Loss: 2.3978517055511475 | CLS Loss: 0.01463676430284977\n",
      "Epoch: 171, Loss: 2.4183, Train: 0.9972, Valid: 0.9871, Best: 0.9872\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 2.425551414489746 | KNN Loss: 2.4223244190216064 | CLS Loss: 0.0032270271331071854\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 2.4288506507873535 | KNN Loss: 2.42230224609375 | CLS Loss: 0.0065482910722494125\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 2.44830060005188 | KNN Loss: 2.4368457794189453 | CLS Loss: 0.011454812251031399\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 2.437781572341919 | KNN Loss: 2.426121711730957 | CLS Loss: 0.011659855954349041\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 2.450758695602417 | KNN Loss: 2.427280902862549 | CLS Loss: 0.023477764800190926\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 2.412914276123047 | KNN Loss: 2.3896853923797607 | CLS Loss: 0.023228930309414864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 2.414000988006592 | KNN Loss: 2.395493268966675 | CLS Loss: 0.018507622182369232\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 2.392164945602417 | KNN Loss: 2.387985944747925 | CLS Loss: 0.004179018083959818\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 2.4149200916290283 | KNN Loss: 2.4134469032287598 | CLS Loss: 0.0014730974799022079\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 2.4165005683898926 | KNN Loss: 2.4132676124572754 | CLS Loss: 0.0032328381203114986\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 2.407639741897583 | KNN Loss: 2.4062561988830566 | CLS Loss: 0.0013834249693900347\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 2.4261586666107178 | KNN Loss: 2.415469169616699 | CLS Loss: 0.010689567774534225\n",
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 2.447883129119873 | KNN Loss: 2.4248173236846924 | CLS Loss: 0.02306571789085865\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 2.400278091430664 | KNN Loss: 2.3965513706207275 | CLS Loss: 0.0037266621366143227\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 2.398571014404297 | KNN Loss: 2.3967442512512207 | CLS Loss: 0.0018266495317220688\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 2.426175355911255 | KNN Loss: 2.416717052459717 | CLS Loss: 0.009458226151764393\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 2.4407753944396973 | KNN Loss: 2.428154468536377 | CLS Loss: 0.012621001340448856\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 2.378533363342285 | KNN Loss: 2.3768677711486816 | CLS Loss: 0.0016656036023050547\n",
      "Epoch: 172, Loss: 2.4183, Train: 0.9977, Valid: 0.9874, Best: 0.9874\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 2.4181172847747803 | KNN Loss: 2.401013135910034 | CLS Loss: 0.017104070633649826\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 2.4459171295166016 | KNN Loss: 2.4387307167053223 | CLS Loss: 0.007186480797827244\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 2.433004140853882 | KNN Loss: 2.4280829429626465 | CLS Loss: 0.004921204876154661\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 2.407217502593994 | KNN Loss: 2.3932785987854004 | CLS Loss: 0.013938876800239086\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 2.4070191383361816 | KNN Loss: 2.3978466987609863 | CLS Loss: 0.009172331541776657\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 2.409961700439453 | KNN Loss: 2.400912046432495 | CLS Loss: 0.009049593470990658\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 2.4015305042266846 | KNN Loss: 2.3885815143585205 | CLS Loss: 0.012949060648679733\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 2.4058585166931152 | KNN Loss: 2.3945882320404053 | CLS Loss: 0.011270211078226566\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 2.408505439758301 | KNN Loss: 2.4008278846740723 | CLS Loss: 0.007677552755922079\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 2.440438985824585 | KNN Loss: 2.429305076599121 | CLS Loss: 0.011133833788335323\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 2.4168155193328857 | KNN Loss: 2.413907051086426 | CLS Loss: 0.002908530179411173\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 2.3980703353881836 | KNN Loss: 2.3849799633026123 | CLS Loss: 0.013090458698570728\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 2.379565715789795 | KNN Loss: 2.374591827392578 | CLS Loss: 0.004973916336894035\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 2.4317307472229004 | KNN Loss: 2.4281744956970215 | CLS Loss: 0.0035561486147344112\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 2.3744287490844727 | KNN Loss: 2.3680050373077393 | CLS Loss: 0.0064236815087497234\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 2.40987229347229 | KNN Loss: 2.37872052192688 | CLS Loss: 0.031151851639151573\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 2.420358419418335 | KNN Loss: 2.3983705043792725 | CLS Loss: 0.021988002583384514\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 2.4386026859283447 | KNN Loss: 2.4232113361358643 | CLS Loss: 0.01539137028157711\n",
      "Epoch: 173, Loss: 2.4193, Train: 0.9973, Valid: 0.9861, Best: 0.9874\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 2.4401416778564453 | KNN Loss: 2.433535575866699 | CLS Loss: 0.006606215611100197\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 2.4276087284088135 | KNN Loss: 2.4119467735290527 | CLS Loss: 0.015662014484405518\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 2.4169154167175293 | KNN Loss: 2.4050121307373047 | CLS Loss: 0.011903186328709126\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 2.4782021045684814 | KNN Loss: 2.461331367492676 | CLS Loss: 0.016870848834514618\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 2.409081220626831 | KNN Loss: 2.404268980026245 | CLS Loss: 0.004812339786440134\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 2.438666582107544 | KNN Loss: 2.4344356060028076 | CLS Loss: 0.004231080412864685\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 2.390127658843994 | KNN Loss: 2.3643627166748047 | CLS Loss: 0.025764932855963707\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 2.4355554580688477 | KNN Loss: 2.4325382709503174 | CLS Loss: 0.003017276059836149\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 2.3969221115112305 | KNN Loss: 2.3880674839019775 | CLS Loss: 0.008854689076542854\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 2.4072763919830322 | KNN Loss: 2.3984017372131348 | CLS Loss: 0.00887462217360735\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 2.3848717212677 | KNN Loss: 2.383687973022461 | CLS Loss: 0.0011837902711704373\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 2.4352591037750244 | KNN Loss: 2.428544282913208 | CLS Loss: 0.006714818067848682\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 2.389504909515381 | KNN Loss: 2.387131929397583 | CLS Loss: 0.0023730965331196785\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 2.4056472778320312 | KNN Loss: 2.4008865356445312 | CLS Loss: 0.0047607868909835815\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 2.418766498565674 | KNN Loss: 2.4123713970184326 | CLS Loss: 0.0063950736075639725\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 2.4270267486572266 | KNN Loss: 2.4217512607574463 | CLS Loss: 0.005275378935039043\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 2.3949928283691406 | KNN Loss: 2.3867568969726562 | CLS Loss: 0.008235895074903965\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 2.413477659225464 | KNN Loss: 2.4091455936431885 | CLS Loss: 0.004332083277404308\n",
      "Epoch: 174, Loss: 2.4160, Train: 0.9971, Valid: 0.9866, Best: 0.9874\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 2.415400981903076 | KNN Loss: 2.411161184310913 | CLS Loss: 0.004239753820002079\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 2.4250082969665527 | KNN Loss: 2.4201290607452393 | CLS Loss: 0.004879162646830082\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 2.4545323848724365 | KNN Loss: 2.4484896659851074 | CLS Loss: 0.006042723078280687\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 2.402146577835083 | KNN Loss: 2.392540454864502 | CLS Loss: 0.00960605125874281\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 2.4160890579223633 | KNN Loss: 2.3984858989715576 | CLS Loss: 0.01760304532945156\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 2.402642250061035 | KNN Loss: 2.399533271789551 | CLS Loss: 0.003109005279839039\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 2.404953956604004 | KNN Loss: 2.389483690261841 | CLS Loss: 0.015470199286937714\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 2.3926961421966553 | KNN Loss: 2.387744188308716 | CLS Loss: 0.00495189568027854\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 2.4234654903411865 | KNN Loss: 2.421722888946533 | CLS Loss: 0.001742504769936204\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 2.4045212268829346 | KNN Loss: 2.397132158279419 | CLS Loss: 0.007389153819531202\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 2.440098524093628 | KNN Loss: 2.422656297683716 | CLS Loss: 0.01744217611849308\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 2.4697582721710205 | KNN Loss: 2.459810733795166 | CLS Loss: 0.009947637096047401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 2.4374735355377197 | KNN Loss: 2.4320428371429443 | CLS Loss: 0.005430754739791155\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 2.4023661613464355 | KNN Loss: 2.395905017852783 | CLS Loss: 0.006461227312684059\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 2.450218915939331 | KNN Loss: 2.400432586669922 | CLS Loss: 0.04978625848889351\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 2.3913938999176025 | KNN Loss: 2.3854787349700928 | CLS Loss: 0.005915118847042322\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 2.4014580249786377 | KNN Loss: 2.3997857570648193 | CLS Loss: 0.0016723406733945012\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 2.463972806930542 | KNN Loss: 2.435152292251587 | CLS Loss: 0.028820551931858063\n",
      "Epoch: 175, Loss: 2.4187, Train: 0.9957, Valid: 0.9840, Best: 0.9874\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 2.429286003112793 | KNN Loss: 2.4078259468078613 | CLS Loss: 0.021459970623254776\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 2.4202990531921387 | KNN Loss: 2.4148523807525635 | CLS Loss: 0.005446769762784243\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 2.3960988521575928 | KNN Loss: 2.3937339782714844 | CLS Loss: 0.002364950953051448\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 2.4298503398895264 | KNN Loss: 2.4259543418884277 | CLS Loss: 0.003896026173606515\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 2.433816909790039 | KNN Loss: 2.4221677780151367 | CLS Loss: 0.011649059131741524\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 2.4104158878326416 | KNN Loss: 2.4024558067321777 | CLS Loss: 0.00796003732830286\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 2.477874279022217 | KNN Loss: 2.4534833431243896 | CLS Loss: 0.024391038343310356\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 2.402103900909424 | KNN Loss: 2.382768392562866 | CLS Loss: 0.01933557167649269\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 2.441232204437256 | KNN Loss: 2.426431179046631 | CLS Loss: 0.01480106357485056\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 2.4436426162719727 | KNN Loss: 2.4233973026275635 | CLS Loss: 0.020245373249053955\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 2.4219532012939453 | KNN Loss: 2.417239189147949 | CLS Loss: 0.00471389340236783\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 2.431285858154297 | KNN Loss: 2.4039931297302246 | CLS Loss: 0.027292778715491295\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 2.436401844024658 | KNN Loss: 2.434243679046631 | CLS Loss: 0.0021582525223493576\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 2.406827926635742 | KNN Loss: 2.4033868312835693 | CLS Loss: 0.0034411908127367496\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 2.3917787075042725 | KNN Loss: 2.3830718994140625 | CLS Loss: 0.008706807158887386\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 2.403010606765747 | KNN Loss: 2.3937456607818604 | CLS Loss: 0.009265057742595673\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 2.4170238971710205 | KNN Loss: 2.4020464420318604 | CLS Loss: 0.014977539889514446\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 2.4347286224365234 | KNN Loss: 2.420030117034912 | CLS Loss: 0.014698565006256104\n",
      "Epoch: 176, Loss: 2.4177, Train: 0.9978, Valid: 0.9864, Best: 0.9874\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 2.447345018386841 | KNN Loss: 2.436316728591919 | CLS Loss: 0.011028262786567211\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 2.395604133605957 | KNN Loss: 2.3717262744903564 | CLS Loss: 0.02387782372534275\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 2.402320623397827 | KNN Loss: 2.395390510559082 | CLS Loss: 0.006930082105100155\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 2.3813135623931885 | KNN Loss: 2.3712408542633057 | CLS Loss: 0.010072666220366955\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 2.4526455402374268 | KNN Loss: 2.4341230392456055 | CLS Loss: 0.018522413447499275\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 2.3964385986328125 | KNN Loss: 2.392970085144043 | CLS Loss: 0.003468576353043318\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 2.4182488918304443 | KNN Loss: 2.414170980453491 | CLS Loss: 0.004077831748872995\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 2.3658835887908936 | KNN Loss: 2.3529040813446045 | CLS Loss: 0.012979520484805107\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 2.3808562755584717 | KNN Loss: 2.3799703121185303 | CLS Loss: 0.0008859167573973536\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 2.403733491897583 | KNN Loss: 2.4031105041503906 | CLS Loss: 0.0006229410646483302\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 2.3970072269439697 | KNN Loss: 2.39205002784729 | CLS Loss: 0.004957163240760565\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 2.4401040077209473 | KNN Loss: 2.423492193222046 | CLS Loss: 0.016611814498901367\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 2.4116811752319336 | KNN Loss: 2.409940481185913 | CLS Loss: 0.0017407332779839635\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 2.390913724899292 | KNN Loss: 2.38871169090271 | CLS Loss: 0.00220200652256608\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 2.406179428100586 | KNN Loss: 2.403029441833496 | CLS Loss: 0.003149984870105982\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 2.3773410320281982 | KNN Loss: 2.3668124675750732 | CLS Loss: 0.010528475977480412\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 2.410466432571411 | KNN Loss: 2.401449680328369 | CLS Loss: 0.00901686493307352\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 2.421190023422241 | KNN Loss: 2.398549795150757 | CLS Loss: 0.0226401649415493\n",
      "Epoch: 177, Loss: 2.4121, Train: 0.9969, Valid: 0.9857, Best: 0.9874\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 2.452272653579712 | KNN Loss: 2.4295918941497803 | CLS Loss: 0.022680852562189102\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 2.404787540435791 | KNN Loss: 2.4031810760498047 | CLS Loss: 0.0016064237570390105\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 2.440828800201416 | KNN Loss: 2.4376182556152344 | CLS Loss: 0.0032105331774801016\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 2.423419952392578 | KNN Loss: 2.4109318256378174 | CLS Loss: 0.012488193809986115\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 2.4202771186828613 | KNN Loss: 2.4175477027893066 | CLS Loss: 0.002729347674176097\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 2.4384994506835938 | KNN Loss: 2.4179093837738037 | CLS Loss: 0.020590156316757202\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 2.398280620574951 | KNN Loss: 2.3909506797790527 | CLS Loss: 0.007329944986850023\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 2.4128544330596924 | KNN Loss: 2.4114022254943848 | CLS Loss: 0.001452250755392015\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 2.4248220920562744 | KNN Loss: 2.4125874042510986 | CLS Loss: 0.012234674766659737\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 2.3821828365325928 | KNN Loss: 2.3760416507720947 | CLS Loss: 0.006141189020127058\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 2.39023494720459 | KNN Loss: 2.3841171264648438 | CLS Loss: 0.00611772108823061\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 2.4023003578186035 | KNN Loss: 2.399712085723877 | CLS Loss: 0.002588174771517515\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 2.3991026878356934 | KNN Loss: 2.3891329765319824 | CLS Loss: 0.009969787672162056\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 2.4052658081054688 | KNN Loss: 2.4015791416168213 | CLS Loss: 0.003686784766614437\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 2.4328551292419434 | KNN Loss: 2.4135260581970215 | CLS Loss: 0.019329126924276352\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 2.393103837966919 | KNN Loss: 2.3877577781677246 | CLS Loss: 0.005346013233065605\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 2.3881242275238037 | KNN Loss: 2.380676507949829 | CLS Loss: 0.007447600830346346\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 2.415065050125122 | KNN Loss: 2.4124701023101807 | CLS Loss: 0.0025949471164494753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 178, Loss: 2.4145, Train: 0.9978, Valid: 0.9858, Best: 0.9874\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 2.4150428771972656 | KNN Loss: 2.409811496734619 | CLS Loss: 0.005231310613453388\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 2.4563872814178467 | KNN Loss: 2.4371211528778076 | CLS Loss: 0.019266119226813316\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 2.3951241970062256 | KNN Loss: 2.3914458751678467 | CLS Loss: 0.0036782645620405674\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 2.3775322437286377 | KNN Loss: 2.3705897331237793 | CLS Loss: 0.0069425893016159534\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 2.4068145751953125 | KNN Loss: 2.391777276992798 | CLS Loss: 0.015037310309708118\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 2.3904595375061035 | KNN Loss: 2.372316598892212 | CLS Loss: 0.018142856657505035\n",
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 2.4148144721984863 | KNN Loss: 2.408608913421631 | CLS Loss: 0.006205475423485041\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 2.4423556327819824 | KNN Loss: 2.4373278617858887 | CLS Loss: 0.005027793347835541\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 2.430251359939575 | KNN Loss: 2.4234282970428467 | CLS Loss: 0.006823159288614988\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 2.4121346473693848 | KNN Loss: 2.386138916015625 | CLS Loss: 0.025995811447501183\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 2.386101722717285 | KNN Loss: 2.3721084594726562 | CLS Loss: 0.013993239030241966\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 2.386791229248047 | KNN Loss: 2.382631301879883 | CLS Loss: 0.004159943200647831\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 2.417456865310669 | KNN Loss: 2.4069042205810547 | CLS Loss: 0.010552658699452877\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 2.450122833251953 | KNN Loss: 2.4417364597320557 | CLS Loss: 0.008386262692511082\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 2.42529296875 | KNN Loss: 2.421889543533325 | CLS Loss: 0.0034035234712064266\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 2.4172141551971436 | KNN Loss: 2.3982720375061035 | CLS Loss: 0.01894213818013668\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 2.4142515659332275 | KNN Loss: 2.4010589122772217 | CLS Loss: 0.013192690908908844\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 2.404634714126587 | KNN Loss: 2.3992059230804443 | CLS Loss: 0.005428811069577932\n",
      "Epoch: 179, Loss: 2.4173, Train: 0.9969, Valid: 0.9860, Best: 0.9874\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 2.3678717613220215 | KNN Loss: 2.3639743328094482 | CLS Loss: 0.003897435963153839\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 2.4404075145721436 | KNN Loss: 2.436645030975342 | CLS Loss: 0.0037624735850840807\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 2.42246150970459 | KNN Loss: 2.417292833328247 | CLS Loss: 0.005168674513697624\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 2.4021408557891846 | KNN Loss: 2.3827452659606934 | CLS Loss: 0.01939563825726509\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 2.4455738067626953 | KNN Loss: 2.444150686264038 | CLS Loss: 0.001423144480213523\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 2.424990177154541 | KNN Loss: 2.4122700691223145 | CLS Loss: 0.01272006705403328\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 2.4040884971618652 | KNN Loss: 2.403136730194092 | CLS Loss: 0.0009516481659375131\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 2.4442765712738037 | KNN Loss: 2.4124183654785156 | CLS Loss: 0.0318581722676754\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 2.4167873859405518 | KNN Loss: 2.4028894901275635 | CLS Loss: 0.013898010365664959\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 2.392719268798828 | KNN Loss: 2.388242721557617 | CLS Loss: 0.004476491361856461\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 2.4170985221862793 | KNN Loss: 2.405041217803955 | CLS Loss: 0.01205737516283989\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 2.395815134048462 | KNN Loss: 2.3866915702819824 | CLS Loss: 0.009123613126575947\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 2.413796901702881 | KNN Loss: 2.4019999504089355 | CLS Loss: 0.011796899139881134\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 2.4370241165161133 | KNN Loss: 2.4052700996398926 | CLS Loss: 0.031753942370414734\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 2.410780906677246 | KNN Loss: 2.4076290130615234 | CLS Loss: 0.0031518342439085245\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 2.4068470001220703 | KNN Loss: 2.399557113647461 | CLS Loss: 0.007289939094334841\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 2.4545862674713135 | KNN Loss: 2.4406254291534424 | CLS Loss: 0.013960829004645348\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 2.433321952819824 | KNN Loss: 2.431224822998047 | CLS Loss: 0.002097013872116804\n",
      "Epoch: 180, Loss: 2.4157, Train: 0.9977, Valid: 0.9858, Best: 0.9874\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 2.440408945083618 | KNN Loss: 2.4202747344970703 | CLS Loss: 0.020134316757321358\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 2.4336531162261963 | KNN Loss: 2.4320616722106934 | CLS Loss: 0.0015913733514025807\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 2.4287917613983154 | KNN Loss: 2.407604932785034 | CLS Loss: 0.021186886355280876\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 2.391517162322998 | KNN Loss: 2.383378267288208 | CLS Loss: 0.008138944394886494\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 2.389991044998169 | KNN Loss: 2.3862462043762207 | CLS Loss: 0.003744944231584668\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 2.4109947681427 | KNN Loss: 2.4002151489257812 | CLS Loss: 0.010779610835015774\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 2.4298460483551025 | KNN Loss: 2.419508695602417 | CLS Loss: 0.010337281040847301\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 2.4329118728637695 | KNN Loss: 2.4286844730377197 | CLS Loss: 0.004227417055517435\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 2.3935530185699463 | KNN Loss: 2.3864405155181885 | CLS Loss: 0.007112396415323019\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 2.3895158767700195 | KNN Loss: 2.387974500656128 | CLS Loss: 0.0015413612127304077\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 2.4092273712158203 | KNN Loss: 2.376314878463745 | CLS Loss: 0.032912421971559525\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 2.419647455215454 | KNN Loss: 2.414271593093872 | CLS Loss: 0.0053759473375976086\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 2.397801160812378 | KNN Loss: 2.3750810623168945 | CLS Loss: 0.022720210254192352\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 2.4358174800872803 | KNN Loss: 2.4170820713043213 | CLS Loss: 0.018735310062766075\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 2.437708616256714 | KNN Loss: 2.4206607341766357 | CLS Loss: 0.017047902569174767\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 2.4168527126312256 | KNN Loss: 2.404482126235962 | CLS Loss: 0.012370677664875984\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 2.3988847732543945 | KNN Loss: 2.392848253250122 | CLS Loss: 0.006036554928869009\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 2.4330668449401855 | KNN Loss: 2.427612066268921 | CLS Loss: 0.005454809870570898\n",
      "Epoch: 181, Loss: 2.4164, Train: 0.9965, Valid: 0.9863, Best: 0.9874\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 2.4293062686920166 | KNN Loss: 2.4181792736053467 | CLS Loss: 0.011127046309411526\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 2.421535015106201 | KNN Loss: 2.417767286300659 | CLS Loss: 0.003767773974686861\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 2.4111814498901367 | KNN Loss: 2.4085588455200195 | CLS Loss: 0.002622658386826515\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 2.412670373916626 | KNN Loss: 2.409092903137207 | CLS Loss: 0.0035775871947407722\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 2.434300422668457 | KNN Loss: 2.4222731590270996 | CLS Loss: 0.012027314864099026\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 2.443291425704956 | KNN Loss: 2.4259798526763916 | CLS Loss: 0.01731155440211296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 2.4124467372894287 | KNN Loss: 2.411271333694458 | CLS Loss: 0.0011753460858017206\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 2.434814691543579 | KNN Loss: 2.4138009548187256 | CLS Loss: 0.02101362869143486\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 2.4243712425231934 | KNN Loss: 2.4127674102783203 | CLS Loss: 0.011603936553001404\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 2.4099419116973877 | KNN Loss: 2.404778480529785 | CLS Loss: 0.005163388792425394\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 2.404109477996826 | KNN Loss: 2.3904213905334473 | CLS Loss: 0.013687968254089355\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 2.388370990753174 | KNN Loss: 2.38631010055542 | CLS Loss: 0.002060906495898962\n",
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 2.380505323410034 | KNN Loss: 2.375601053237915 | CLS Loss: 0.004904215224087238\n",
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 2.4256198406219482 | KNN Loss: 2.4169816970825195 | CLS Loss: 0.008638119325041771\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 2.414069652557373 | KNN Loss: 2.402902364730835 | CLS Loss: 0.011167231015861034\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 2.4174766540527344 | KNN Loss: 2.4043097496032715 | CLS Loss: 0.013166811317205429\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 2.415060520172119 | KNN Loss: 2.404223918914795 | CLS Loss: 0.010836547240614891\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 2.3836448192596436 | KNN Loss: 2.37911057472229 | CLS Loss: 0.004534317646175623\n",
      "Epoch: 182, Loss: 2.4147, Train: 0.9974, Valid: 0.9866, Best: 0.9874\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 2.4352614879608154 | KNN Loss: 2.423274517059326 | CLS Loss: 0.011987007223069668\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 2.390165328979492 | KNN Loss: 2.387468099594116 | CLS Loss: 0.0026973169296979904\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 2.41593861579895 | KNN Loss: 2.413433790206909 | CLS Loss: 0.002504776231944561\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 2.4084417819976807 | KNN Loss: 2.4030163288116455 | CLS Loss: 0.0054253567941486835\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 2.4443576335906982 | KNN Loss: 2.41799259185791 | CLS Loss: 0.02636493183672428\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 2.4145779609680176 | KNN Loss: 2.407778024673462 | CLS Loss: 0.006800003349781036\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 2.397663116455078 | KNN Loss: 2.3881914615631104 | CLS Loss: 0.009471675381064415\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 2.4133594036102295 | KNN Loss: 2.408801317214966 | CLS Loss: 0.00455812131986022\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 2.444080352783203 | KNN Loss: 2.423021078109741 | CLS Loss: 0.021059246733784676\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 2.383476972579956 | KNN Loss: 2.369032621383667 | CLS Loss: 0.014444384723901749\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 2.451171875 | KNN Loss: 2.440685749053955 | CLS Loss: 0.010486011393368244\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 2.4007391929626465 | KNN Loss: 2.393770456314087 | CLS Loss: 0.0069687217473983765\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 2.4161901473999023 | KNN Loss: 2.406647205352783 | CLS Loss: 0.009542964398860931\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 2.415571689605713 | KNN Loss: 2.3925580978393555 | CLS Loss: 0.023013614118099213\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 2.4053280353546143 | KNN Loss: 2.393920421600342 | CLS Loss: 0.011407628655433655\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 2.42791748046875 | KNN Loss: 2.425109386444092 | CLS Loss: 0.0028080670163035393\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 2.3992300033569336 | KNN Loss: 2.396388292312622 | CLS Loss: 0.0028417163994163275\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 2.451594114303589 | KNN Loss: 2.449117422103882 | CLS Loss: 0.002476596040651202\n",
      "Epoch: 183, Loss: 2.4138, Train: 0.9971, Valid: 0.9863, Best: 0.9874\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 2.4494755268096924 | KNN Loss: 2.4208240509033203 | CLS Loss: 0.028651537373661995\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 2.4568307399749756 | KNN Loss: 2.4487416744232178 | CLS Loss: 0.008089170791208744\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 2.366269826889038 | KNN Loss: 2.364614248275757 | CLS Loss: 0.001655612955801189\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 2.432321071624756 | KNN Loss: 2.4116461277008057 | CLS Loss: 0.020674841478466988\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 2.3641726970672607 | KNN Loss: 2.359992742538452 | CLS Loss: 0.0041798739694058895\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 2.432042121887207 | KNN Loss: 2.4300711154937744 | CLS Loss: 0.0019709609914571047\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 2.396639823913574 | KNN Loss: 2.3899106979370117 | CLS Loss: 0.006729193963110447\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 2.4589624404907227 | KNN Loss: 2.4546384811401367 | CLS Loss: 0.0043238624930381775\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 2.4021735191345215 | KNN Loss: 2.3852739334106445 | CLS Loss: 0.016899559646844864\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 2.3795394897460938 | KNN Loss: 2.369112491607666 | CLS Loss: 0.010426893830299377\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 2.4249494075775146 | KNN Loss: 2.4019062519073486 | CLS Loss: 0.023043273016810417\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 2.4082255363464355 | KNN Loss: 2.406599283218384 | CLS Loss: 0.0016262256540358067\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 2.4320292472839355 | KNN Loss: 2.4301750659942627 | CLS Loss: 0.0018542776815593243\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 2.4270288944244385 | KNN Loss: 2.4223883152008057 | CLS Loss: 0.00464053638279438\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 2.466820001602173 | KNN Loss: 2.451364040374756 | CLS Loss: 0.015456045977771282\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 2.394460439682007 | KNN Loss: 2.3930933475494385 | CLS Loss: 0.0013671971391886473\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 2.4488837718963623 | KNN Loss: 2.434624671936035 | CLS Loss: 0.01425913441926241\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 2.3912954330444336 | KNN Loss: 2.388784170150757 | CLS Loss: 0.0025112011935561895\n",
      "Epoch: 184, Loss: 2.4137, Train: 0.9971, Valid: 0.9865, Best: 0.9874\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 2.444154739379883 | KNN Loss: 2.4325923919677734 | CLS Loss: 0.011562283150851727\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 2.411273241043091 | KNN Loss: 2.407696485519409 | CLS Loss: 0.003576803719624877\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 2.417076349258423 | KNN Loss: 2.3979976177215576 | CLS Loss: 0.01907864771783352\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 2.434814214706421 | KNN Loss: 2.4291648864746094 | CLS Loss: 0.005649219732731581\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 2.447061777114868 | KNN Loss: 2.444917678833008 | CLS Loss: 0.0021439928095787764\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 2.4560720920562744 | KNN Loss: 2.4484031200408936 | CLS Loss: 0.007668983191251755\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 2.399848699569702 | KNN Loss: 2.398740768432617 | CLS Loss: 0.00110783358104527\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 2.4152579307556152 | KNN Loss: 2.4144163131713867 | CLS Loss: 0.0008416133932769299\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 2.4161105155944824 | KNN Loss: 2.3927974700927734 | CLS Loss: 0.023312939330935478\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 2.403224468231201 | KNN Loss: 2.38034987449646 | CLS Loss: 0.0228746198117733\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 2.406674861907959 | KNN Loss: 2.403040647506714 | CLS Loss: 0.003634294029325247\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 2.3825623989105225 | KNN Loss: 2.377214193344116 | CLS Loss: 0.0053482954390347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 2.410003662109375 | KNN Loss: 2.4045491218566895 | CLS Loss: 0.005454644560813904\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 2.4125468730926514 | KNN Loss: 2.4065325260162354 | CLS Loss: 0.006014366168528795\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 2.4414896965026855 | KNN Loss: 2.4342782497406006 | CLS Loss: 0.007211505901068449\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 2.402709484100342 | KNN Loss: 2.4011120796203613 | CLS Loss: 0.0015975134447216988\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 2.429591417312622 | KNN Loss: 2.4050540924072266 | CLS Loss: 0.024537308141589165\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 2.407379150390625 | KNN Loss: 2.4010794162750244 | CLS Loss: 0.006299692206084728\n",
      "Epoch: 185, Loss: 2.4127, Train: 0.9964, Valid: 0.9852, Best: 0.9874\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 2.3946070671081543 | KNN Loss: 2.3843612670898438 | CLS Loss: 0.010245775803923607\n",
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 2.421269178390503 | KNN Loss: 2.419146776199341 | CLS Loss: 0.0021224466618150473\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 2.432368278503418 | KNN Loss: 2.4236981868743896 | CLS Loss: 0.008670066483318806\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 2.4205076694488525 | KNN Loss: 2.400195598602295 | CLS Loss: 0.020312096923589706\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 2.4550812244415283 | KNN Loss: 2.4471113681793213 | CLS Loss: 0.007969871163368225\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 2.377634048461914 | KNN Loss: 2.366885185241699 | CLS Loss: 0.010748866014182568\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 2.3844127655029297 | KNN Loss: 2.3820557594299316 | CLS Loss: 0.0023571194615215063\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 2.399691104888916 | KNN Loss: 2.3972105979919434 | CLS Loss: 0.002480536000803113\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 2.3919594287872314 | KNN Loss: 2.384949207305908 | CLS Loss: 0.007010259665548801\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 2.379338026046753 | KNN Loss: 2.3745651245117188 | CLS Loss: 0.0047729723155498505\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 2.3843677043914795 | KNN Loss: 2.3788764476776123 | CLS Loss: 0.005491368006914854\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 2.4049854278564453 | KNN Loss: 2.396721601486206 | CLS Loss: 0.008263797499239445\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 2.4001450538635254 | KNN Loss: 2.3911261558532715 | CLS Loss: 0.009018877521157265\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 2.436326265335083 | KNN Loss: 2.4161410331726074 | CLS Loss: 0.020185254514217377\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 2.416217565536499 | KNN Loss: 2.406339406967163 | CLS Loss: 0.009878152050077915\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 2.4169909954071045 | KNN Loss: 2.4117798805236816 | CLS Loss: 0.00521119125187397\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 2.4106483459472656 | KNN Loss: 2.399779796600342 | CLS Loss: 0.01086859405040741\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 2.409335136413574 | KNN Loss: 2.405836582183838 | CLS Loss: 0.00349849509075284\n",
      "Epoch: 186, Loss: 2.4134, Train: 0.9967, Valid: 0.9857, Best: 0.9874\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 2.4924707412719727 | KNN Loss: 2.4599227905273438 | CLS Loss: 0.03254786878824234\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 2.4135639667510986 | KNN Loss: 2.408838987350464 | CLS Loss: 0.004725066479295492\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 2.4005274772644043 | KNN Loss: 2.3956873416900635 | CLS Loss: 0.004840100649744272\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 2.4011216163635254 | KNN Loss: 2.3807778358459473 | CLS Loss: 0.020343834534287453\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 2.422741174697876 | KNN Loss: 2.4115970134735107 | CLS Loss: 0.01114416029304266\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 2.4391207695007324 | KNN Loss: 2.4260342121124268 | CLS Loss: 0.013086646795272827\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 2.4121861457824707 | KNN Loss: 2.4011025428771973 | CLS Loss: 0.01108370628207922\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 2.4353206157684326 | KNN Loss: 2.4130783081054688 | CLS Loss: 0.022242411971092224\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 2.421501874923706 | KNN Loss: 2.4186058044433594 | CLS Loss: 0.002896041376516223\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 2.437617778778076 | KNN Loss: 2.41851544380188 | CLS Loss: 0.019102249294519424\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 2.3992388248443604 | KNN Loss: 2.388702869415283 | CLS Loss: 0.01053594145923853\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 2.421038866043091 | KNN Loss: 2.415731906890869 | CLS Loss: 0.00530701270326972\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 2.4309492111206055 | KNN Loss: 2.430309295654297 | CLS Loss: 0.0006398269324563444\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 2.413257598876953 | KNN Loss: 2.399796724319458 | CLS Loss: 0.013460942544043064\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 2.3933660984039307 | KNN Loss: 2.3750572204589844 | CLS Loss: 0.018308980390429497\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 2.4323360919952393 | KNN Loss: 2.4254581928253174 | CLS Loss: 0.006877894513309002\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 2.418605089187622 | KNN Loss: 2.389204263687134 | CLS Loss: 0.02940082736313343\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 2.4482836723327637 | KNN Loss: 2.4317519664764404 | CLS Loss: 0.01653168722987175\n",
      "Epoch: 187, Loss: 2.4161, Train: 0.9974, Valid: 0.9870, Best: 0.9874\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 2.4321627616882324 | KNN Loss: 2.423593759536743 | CLS Loss: 0.008568921126425266\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 2.435938835144043 | KNN Loss: 2.4320945739746094 | CLS Loss: 0.003844195045530796\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 2.4127180576324463 | KNN Loss: 2.407909870147705 | CLS Loss: 0.004808258265256882\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 2.4461441040039062 | KNN Loss: 2.4265873432159424 | CLS Loss: 0.019556647166609764\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 2.4181835651397705 | KNN Loss: 2.415006160736084 | CLS Loss: 0.003177426988258958\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 2.4668142795562744 | KNN Loss: 2.4610583782196045 | CLS Loss: 0.005755947437137365\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 2.4339325428009033 | KNN Loss: 2.4202120304107666 | CLS Loss: 0.01372041366994381\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 2.4126086235046387 | KNN Loss: 2.398970603942871 | CLS Loss: 0.013637954369187355\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 2.426847457885742 | KNN Loss: 2.4217560291290283 | CLS Loss: 0.005091376602649689\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 2.4070889949798584 | KNN Loss: 2.4018545150756836 | CLS Loss: 0.005234460812062025\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 2.4095401763916016 | KNN Loss: 2.3902926445007324 | CLS Loss: 0.0192476287484169\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 2.440227508544922 | KNN Loss: 2.423619270324707 | CLS Loss: 0.016608333215117455\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 2.416425943374634 | KNN Loss: 2.40537166595459 | CLS Loss: 0.011054329574108124\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 2.425741195678711 | KNN Loss: 2.420552968978882 | CLS Loss: 0.005188269075006247\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 2.4248197078704834 | KNN Loss: 2.4069135189056396 | CLS Loss: 0.01790609396994114\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 2.4405200481414795 | KNN Loss: 2.4375576972961426 | CLS Loss: 0.002962255384773016\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 2.396976947784424 | KNN Loss: 2.3949618339538574 | CLS Loss: 0.0020151054486632347\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 2.444938898086548 | KNN Loss: 2.4355363845825195 | CLS Loss: 0.009402562864124775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 188, Loss: 2.4163, Train: 0.9968, Valid: 0.9856, Best: 0.9874\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 2.4022114276885986 | KNN Loss: 2.39015531539917 | CLS Loss: 0.01205622497946024\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 2.4021103382110596 | KNN Loss: 2.3974359035491943 | CLS Loss: 0.004674519412219524\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 2.4069371223449707 | KNN Loss: 2.3938426971435547 | CLS Loss: 0.013094501569867134\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 2.3911221027374268 | KNN Loss: 2.3857240676879883 | CLS Loss: 0.0053981030359864235\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 2.377262592315674 | KNN Loss: 2.370898723602295 | CLS Loss: 0.006363935302942991\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 2.475409984588623 | KNN Loss: 2.4523887634277344 | CLS Loss: 0.02302112616598606\n",
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 2.4302632808685303 | KNN Loss: 2.4257004261016846 | CLS Loss: 0.00456285011023283\n",
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 2.3958353996276855 | KNN Loss: 2.3856043815612793 | CLS Loss: 0.01023103203624487\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 2.4207115173339844 | KNN Loss: 2.4032506942749023 | CLS Loss: 0.0174607764929533\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 2.3848376274108887 | KNN Loss: 2.3828413486480713 | CLS Loss: 0.0019963074009865522\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 2.37724232673645 | KNN Loss: 2.3747639656066895 | CLS Loss: 0.002478282665833831\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 2.410099744796753 | KNN Loss: 2.3841190338134766 | CLS Loss: 0.025980792939662933\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 2.411642551422119 | KNN Loss: 2.405715227127075 | CLS Loss: 0.0059272972866892815\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 2.4344704151153564 | KNN Loss: 2.4206278324127197 | CLS Loss: 0.013842672109603882\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 2.4192721843719482 | KNN Loss: 2.4154052734375 | CLS Loss: 0.003867021994665265\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 2.422377109527588 | KNN Loss: 2.412698268890381 | CLS Loss: 0.009678862057626247\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 2.4493637084960938 | KNN Loss: 2.431504011154175 | CLS Loss: 0.017859812825918198\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 2.4504921436309814 | KNN Loss: 2.4439857006073 | CLS Loss: 0.0065065291710197926\n",
      "Epoch: 189, Loss: 2.4120, Train: 0.9970, Valid: 0.9864, Best: 0.9874\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 2.4323770999908447 | KNN Loss: 2.4197661876678467 | CLS Loss: 0.01261084247380495\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 2.42197847366333 | KNN Loss: 2.4177026748657227 | CLS Loss: 0.004275818821042776\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 2.4328694343566895 | KNN Loss: 2.432434320449829 | CLS Loss: 0.00043521521729417145\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 2.4080886840820312 | KNN Loss: 2.4057867527008057 | CLS Loss: 0.0023019742220640182\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 2.4170432090759277 | KNN Loss: 2.3968029022216797 | CLS Loss: 0.02024039439857006\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 2.396199941635132 | KNN Loss: 2.3933215141296387 | CLS Loss: 0.002878373023122549\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 2.4034228324890137 | KNN Loss: 2.39507794380188 | CLS Loss: 0.008344842121005058\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 2.445406913757324 | KNN Loss: 2.4396376609802246 | CLS Loss: 0.00576933054253459\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 2.3786187171936035 | KNN Loss: 2.361708402633667 | CLS Loss: 0.016910217702388763\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 2.4224929809570312 | KNN Loss: 2.413087844848633 | CLS Loss: 0.009405153803527355\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 2.4087255001068115 | KNN Loss: 2.3933262825012207 | CLS Loss: 0.015399197116494179\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 2.403423547744751 | KNN Loss: 2.398806571960449 | CLS Loss: 0.004616886842995882\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 2.4341320991516113 | KNN Loss: 2.4129905700683594 | CLS Loss: 0.02114148437976837\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 2.4576144218444824 | KNN Loss: 2.4491677284240723 | CLS Loss: 0.00844673253595829\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 2.4335391521453857 | KNN Loss: 2.417299270629883 | CLS Loss: 0.016239989548921585\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 2.3968570232391357 | KNN Loss: 2.386070966720581 | CLS Loss: 0.01078596618026495\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 2.41560697555542 | KNN Loss: 2.4094715118408203 | CLS Loss: 0.006135561037808657\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 2.408762216567993 | KNN Loss: 2.37724232673645 | CLS Loss: 0.031519971787929535\n",
      "Epoch: 190, Loss: 2.4149, Train: 0.9972, Valid: 0.9873, Best: 0.9874\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 2.4348108768463135 | KNN Loss: 2.4332194328308105 | CLS Loss: 0.001591542037203908\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 2.383821964263916 | KNN Loss: 2.374894618988037 | CLS Loss: 0.008927241899073124\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 2.4322667121887207 | KNN Loss: 2.4257569313049316 | CLS Loss: 0.006509802304208279\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 2.4168946743011475 | KNN Loss: 2.409290313720703 | CLS Loss: 0.007604427635669708\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 2.407557487487793 | KNN Loss: 2.4036202430725098 | CLS Loss: 0.0039373598992824554\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 2.3876869678497314 | KNN Loss: 2.3846006393432617 | CLS Loss: 0.0030863534193485975\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 2.372335433959961 | KNN Loss: 2.3629579544067383 | CLS Loss: 0.009377425536513329\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 2.457522392272949 | KNN Loss: 2.4387576580047607 | CLS Loss: 0.01876462996006012\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 2.4289605617523193 | KNN Loss: 2.4269754886627197 | CLS Loss: 0.0019851832184940577\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 2.3801863193511963 | KNN Loss: 2.3624186515808105 | CLS Loss: 0.017767703160643578\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 2.371412992477417 | KNN Loss: 2.360901117324829 | CLS Loss: 0.010511777363717556\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 2.4625244140625 | KNN Loss: 2.444307565689087 | CLS Loss: 0.01821676269173622\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 2.3958899974823 | KNN Loss: 2.394141912460327 | CLS Loss: 0.0017479673260822892\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 2.4819753170013428 | KNN Loss: 2.438769817352295 | CLS Loss: 0.04320550337433815\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 2.402092456817627 | KNN Loss: 2.3868257999420166 | CLS Loss: 0.015266623347997665\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 2.40246844291687 | KNN Loss: 2.3952972888946533 | CLS Loss: 0.007171048782765865\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 2.435847043991089 | KNN Loss: 2.427663803100586 | CLS Loss: 0.008183340542018414\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 2.4066860675811768 | KNN Loss: 2.3956542015075684 | CLS Loss: 0.011031800881028175\n",
      "Epoch: 191, Loss: 2.4147, Train: 0.9980, Valid: 0.9866, Best: 0.9874\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 2.437471866607666 | KNN Loss: 2.4346399307250977 | CLS Loss: 0.0028318208642303944\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 2.3997323513031006 | KNN Loss: 2.3954415321350098 | CLS Loss: 0.004290734883397818\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 2.3750908374786377 | KNN Loss: 2.3724663257598877 | CLS Loss: 0.002624545944854617\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 2.3975582122802734 | KNN Loss: 2.395543098449707 | CLS Loss: 0.0020151687785983086\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 2.415372133255005 | KNN Loss: 2.410783290863037 | CLS Loss: 0.00458888104185462\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 2.3922173976898193 | KNN Loss: 2.379948854446411 | CLS Loss: 0.012268577702343464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 2.445564031600952 | KNN Loss: 2.4437737464904785 | CLS Loss: 0.0017902180552482605\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 2.4203107357025146 | KNN Loss: 2.4160983562469482 | CLS Loss: 0.004212354775518179\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 2.4323344230651855 | KNN Loss: 2.4142065048217773 | CLS Loss: 0.01812788099050522\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 2.41702938079834 | KNN Loss: 2.4050469398498535 | CLS Loss: 0.01198238879442215\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 2.3841145038604736 | KNN Loss: 2.379514694213867 | CLS Loss: 0.004599805921316147\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 2.4017508029937744 | KNN Loss: 2.399730920791626 | CLS Loss: 0.0020198074635118246\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 2.4248809814453125 | KNN Loss: 2.407672643661499 | CLS Loss: 0.01720832660794258\n",
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 2.42305588722229 | KNN Loss: 2.4199140071868896 | CLS Loss: 0.00314183603040874\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 2.3786427974700928 | KNN Loss: 2.372498035430908 | CLS Loss: 0.006144647486507893\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 2.4543569087982178 | KNN Loss: 2.4515974521636963 | CLS Loss: 0.0027595688588917255\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 2.429898977279663 | KNN Loss: 2.409173011779785 | CLS Loss: 0.020726021379232407\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 2.4287097454071045 | KNN Loss: 2.3915963172912598 | CLS Loss: 0.037113435566425323\n",
      "Epoch: 192, Loss: 2.4137, Train: 0.9973, Valid: 0.9859, Best: 0.9874\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 2.4460692405700684 | KNN Loss: 2.4386372566223145 | CLS Loss: 0.007431891746819019\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 2.3941147327423096 | KNN Loss: 2.389723062515259 | CLS Loss: 0.004391773138195276\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 2.3932197093963623 | KNN Loss: 2.3916914463043213 | CLS Loss: 0.0015282008098438382\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 2.385563850402832 | KNN Loss: 2.3844118118286133 | CLS Loss: 0.0011521417181938887\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 2.3788065910339355 | KNN Loss: 2.373563528060913 | CLS Loss: 0.005243049934506416\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 2.397664785385132 | KNN Loss: 2.3818728923797607 | CLS Loss: 0.015791937708854675\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 2.3960628509521484 | KNN Loss: 2.3860723972320557 | CLS Loss: 0.009990391321480274\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 2.4029572010040283 | KNN Loss: 2.4019103050231934 | CLS Loss: 0.001046956516802311\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 2.3874270915985107 | KNN Loss: 2.383080005645752 | CLS Loss: 0.004347131587564945\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 2.404003620147705 | KNN Loss: 2.394102096557617 | CLS Loss: 0.009901580400764942\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 2.3978402614593506 | KNN Loss: 2.3801920413970947 | CLS Loss: 0.01764833740890026\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 2.439228057861328 | KNN Loss: 2.4365246295928955 | CLS Loss: 0.002703358419239521\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 2.4163825511932373 | KNN Loss: 2.4123740196228027 | CLS Loss: 0.004008416086435318\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 2.37460994720459 | KNN Loss: 2.3657705783843994 | CLS Loss: 0.008839420974254608\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 2.3915722370147705 | KNN Loss: 2.375288248062134 | CLS Loss: 0.016283946111798286\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 2.4141626358032227 | KNN Loss: 2.4073617458343506 | CLS Loss: 0.006800818722695112\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 2.3975651264190674 | KNN Loss: 2.383513927459717 | CLS Loss: 0.014051241800189018\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 2.413346290588379 | KNN Loss: 2.405139446258545 | CLS Loss: 0.008206754922866821\n",
      "Epoch: 193, Loss: 2.4120, Train: 0.9974, Valid: 0.9861, Best: 0.9874\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 2.466214179992676 | KNN Loss: 2.4488821029663086 | CLS Loss: 0.017332026734948158\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 2.383004665374756 | KNN Loss: 2.378997564315796 | CLS Loss: 0.004007106181234121\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 2.4327995777130127 | KNN Loss: 2.416475772857666 | CLS Loss: 0.01632387563586235\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 2.389981746673584 | KNN Loss: 2.3831870555877686 | CLS Loss: 0.006794734857976437\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 2.4235613346099854 | KNN Loss: 2.4194295406341553 | CLS Loss: 0.004131904803216457\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 2.4158730506896973 | KNN Loss: 2.41245436668396 | CLS Loss: 0.0034186532720923424\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 2.406073570251465 | KNN Loss: 2.380544424057007 | CLS Loss: 0.025529256090521812\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 2.398258924484253 | KNN Loss: 2.3957700729370117 | CLS Loss: 0.002488960511982441\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 2.425806760787964 | KNN Loss: 2.4129955768585205 | CLS Loss: 0.01281126867979765\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 2.406466007232666 | KNN Loss: 2.391258716583252 | CLS Loss: 0.015207210555672646\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 2.395808696746826 | KNN Loss: 2.3947479724884033 | CLS Loss: 0.0010606565047055483\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 2.407311201095581 | KNN Loss: 2.401125431060791 | CLS Loss: 0.006185748148709536\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 2.425353765487671 | KNN Loss: 2.399155378341675 | CLS Loss: 0.026198429986834526\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 2.4128024578094482 | KNN Loss: 2.4102392196655273 | CLS Loss: 0.0025632197503000498\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 2.4645864963531494 | KNN Loss: 2.4569404125213623 | CLS Loss: 0.007646022364497185\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 2.4248406887054443 | KNN Loss: 2.4209251403808594 | CLS Loss: 0.003915510606020689\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 2.397272825241089 | KNN Loss: 2.387907028198242 | CLS Loss: 0.009365754202008247\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 2.405867099761963 | KNN Loss: 2.4032256603240967 | CLS Loss: 0.0026413395535200834\n",
      "Epoch: 194, Loss: 2.4174, Train: 0.9971, Valid: 0.9870, Best: 0.9874\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 2.399878978729248 | KNN Loss: 2.3969972133636475 | CLS Loss: 0.002881735796108842\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 2.3831863403320312 | KNN Loss: 2.3808138370513916 | CLS Loss: 0.002372486749663949\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 2.4032442569732666 | KNN Loss: 2.390725612640381 | CLS Loss: 0.012518687173724174\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 2.4352190494537354 | KNN Loss: 2.4336559772491455 | CLS Loss: 0.0015631429851055145\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 2.398081064224243 | KNN Loss: 2.386003255844116 | CLS Loss: 0.012077784165740013\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 2.4069151878356934 | KNN Loss: 2.3955366611480713 | CLS Loss: 0.011378414928913116\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 2.4231598377227783 | KNN Loss: 2.4214062690734863 | CLS Loss: 0.0017535180086269975\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 2.400897979736328 | KNN Loss: 2.39186692237854 | CLS Loss: 0.009030955843627453\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 2.4015896320343018 | KNN Loss: 2.400676727294922 | CLS Loss: 0.0009129743557423353\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 2.4019792079925537 | KNN Loss: 2.3874244689941406 | CLS Loss: 0.014554711058735847\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 2.423475742340088 | KNN Loss: 2.413917064666748 | CLS Loss: 0.009558589197695255\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 2.3935599327087402 | KNN Loss: 2.3913750648498535 | CLS Loss: 0.002184923505410552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 2.3954384326934814 | KNN Loss: 2.3866419792175293 | CLS Loss: 0.00879654660820961\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 2.3906569480895996 | KNN Loss: 2.3863706588745117 | CLS Loss: 0.0042863208800554276\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 2.378544330596924 | KNN Loss: 2.371440887451172 | CLS Loss: 0.007103500887751579\n",
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 2.413036346435547 | KNN Loss: 2.37988018989563 | CLS Loss: 0.03315627574920654\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 2.413043975830078 | KNN Loss: 2.409041166305542 | CLS Loss: 0.004002727568149567\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 2.436136245727539 | KNN Loss: 2.4286253452301025 | CLS Loss: 0.007510796654969454\n",
      "Epoch: 195, Loss: 2.4133, Train: 0.9975, Valid: 0.9863, Best: 0.9874\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 2.405136823654175 | KNN Loss: 2.396449089050293 | CLS Loss: 0.008687762543559074\n",
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 2.422450065612793 | KNN Loss: 2.418450117111206 | CLS Loss: 0.00400003744289279\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 2.4437971115112305 | KNN Loss: 2.4278554916381836 | CLS Loss: 0.01594170741736889\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 2.427802801132202 | KNN Loss: 2.425870180130005 | CLS Loss: 0.0019327019108459353\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 2.4580318927764893 | KNN Loss: 2.4200284481048584 | CLS Loss: 0.0380033478140831\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 2.4251527786254883 | KNN Loss: 2.4136176109313965 | CLS Loss: 0.011535203084349632\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 2.4268715381622314 | KNN Loss: 2.4169278144836426 | CLS Loss: 0.009943796321749687\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 2.4470958709716797 | KNN Loss: 2.4278814792633057 | CLS Loss: 0.019214319065213203\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 2.4230124950408936 | KNN Loss: 2.4025766849517822 | CLS Loss: 0.020435839891433716\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 2.423739433288574 | KNN Loss: 2.4196786880493164 | CLS Loss: 0.0040608420968055725\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 2.4416847229003906 | KNN Loss: 2.433730125427246 | CLS Loss: 0.007954716682434082\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 2.440917730331421 | KNN Loss: 2.426044225692749 | CLS Loss: 0.01487359032034874\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 2.4371626377105713 | KNN Loss: 2.423840045928955 | CLS Loss: 0.013322599232196808\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 2.4664008617401123 | KNN Loss: 2.438812017440796 | CLS Loss: 0.02758895978331566\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 2.398374319076538 | KNN Loss: 2.3870441913604736 | CLS Loss: 0.011330080218613148\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 2.4337501525878906 | KNN Loss: 2.430237054824829 | CLS Loss: 0.0035130854230374098\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 2.4282608032226562 | KNN Loss: 2.416769027709961 | CLS Loss: 0.011491796001791954\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 2.4145638942718506 | KNN Loss: 2.399819850921631 | CLS Loss: 0.014744059182703495\n",
      "Epoch: 196, Loss: 2.4156, Train: 0.9970, Valid: 0.9860, Best: 0.9874\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 2.4130096435546875 | KNN Loss: 2.405623435974121 | CLS Loss: 0.0073861293494701385\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 2.4271090030670166 | KNN Loss: 2.4253547191619873 | CLS Loss: 0.0017543262802064419\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 2.4010231494903564 | KNN Loss: 2.3893697261810303 | CLS Loss: 0.01165343914180994\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 2.4147562980651855 | KNN Loss: 2.406210422515869 | CLS Loss: 0.008545924909412861\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 2.3950555324554443 | KNN Loss: 2.390504837036133 | CLS Loss: 0.004550774581730366\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 2.3856353759765625 | KNN Loss: 2.3631317615509033 | CLS Loss: 0.022503720596432686\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 2.3993146419525146 | KNN Loss: 2.3963844776153564 | CLS Loss: 0.0029301883187144995\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 2.4032976627349854 | KNN Loss: 2.3894360065460205 | CLS Loss: 0.013861768878996372\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 2.4217073917388916 | KNN Loss: 2.419809103012085 | CLS Loss: 0.001898189657367766\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 2.397904396057129 | KNN Loss: 2.3840014934539795 | CLS Loss: 0.013902985490858555\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 2.453667640686035 | KNN Loss: 2.442270278930664 | CLS Loss: 0.0113974092528224\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 2.4197146892547607 | KNN Loss: 2.4018211364746094 | CLS Loss: 0.0178935918956995\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 2.436816930770874 | KNN Loss: 2.417173385620117 | CLS Loss: 0.01964344084262848\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 2.3902347087860107 | KNN Loss: 2.387866497039795 | CLS Loss: 0.0023682028986513615\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 2.3864693641662598 | KNN Loss: 2.3850131034851074 | CLS Loss: 0.0014561774441972375\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 2.4125568866729736 | KNN Loss: 2.4112720489501953 | CLS Loss: 0.0012847577454522252\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 2.436000347137451 | KNN Loss: 2.426215171813965 | CLS Loss: 0.009785063564777374\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 2.408721685409546 | KNN Loss: 2.4032464027404785 | CLS Loss: 0.005475368816405535\n",
      "Epoch: 197, Loss: 2.4129, Train: 0.9972, Valid: 0.9859, Best: 0.9874\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 2.439857006072998 | KNN Loss: 2.4326536655426025 | CLS Loss: 0.007203247398138046\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 2.439692497253418 | KNN Loss: 2.430020570755005 | CLS Loss: 0.009672039188444614\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 2.3820197582244873 | KNN Loss: 2.377230644226074 | CLS Loss: 0.004789226688444614\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 2.411428451538086 | KNN Loss: 2.4047656059265137 | CLS Loss: 0.006662743631750345\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 2.410003423690796 | KNN Loss: 2.4071226119995117 | CLS Loss: 0.0028807129710912704\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 2.426007032394409 | KNN Loss: 2.4224870204925537 | CLS Loss: 0.0035199590492993593\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 2.4203922748565674 | KNN Loss: 2.4114105701446533 | CLS Loss: 0.008981667459011078\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 2.409163236618042 | KNN Loss: 2.3873696327209473 | CLS Loss: 0.021793542429804802\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 2.3871371746063232 | KNN Loss: 2.3823766708374023 | CLS Loss: 0.004760434851050377\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 2.3779451847076416 | KNN Loss: 2.372711181640625 | CLS Loss: 0.0052340067923069\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 2.4628047943115234 | KNN Loss: 2.455289602279663 | CLS Loss: 0.007515286095440388\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 2.3755123615264893 | KNN Loss: 2.3723952770233154 | CLS Loss: 0.0031172006856650114\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 2.4031271934509277 | KNN Loss: 2.400233745574951 | CLS Loss: 0.0028935519512742758\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 2.393109083175659 | KNN Loss: 2.3821516036987305 | CLS Loss: 0.01095736213028431\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 2.412336826324463 | KNN Loss: 2.4037840366363525 | CLS Loss: 0.008552808314561844\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 2.427371025085449 | KNN Loss: 2.423676013946533 | CLS Loss: 0.0036950530484318733\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 2.40535306930542 | KNN Loss: 2.3904201984405518 | CLS Loss: 0.014932895079255104\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 2.4142634868621826 | KNN Loss: 2.4024531841278076 | CLS Loss: 0.011810277588665485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198, Loss: 2.4146, Train: 0.9965, Valid: 0.9855, Best: 0.9874\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 2.458559513092041 | KNN Loss: 2.4451005458831787 | CLS Loss: 0.013458899222314358\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 2.393702745437622 | KNN Loss: 2.3843774795532227 | CLS Loss: 0.009325203485786915\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 2.411714792251587 | KNN Loss: 2.408041477203369 | CLS Loss: 0.0036733821034431458\n",
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 2.4443836212158203 | KNN Loss: 2.425159454345703 | CLS Loss: 0.01922428421676159\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 2.3968935012817383 | KNN Loss: 2.3940272331237793 | CLS Loss: 0.002866328228265047\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 2.4277451038360596 | KNN Loss: 2.412027359008789 | CLS Loss: 0.01571783795952797\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 2.4099137783050537 | KNN Loss: 2.4005932807922363 | CLS Loss: 0.009320582263171673\n",
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 2.4217920303344727 | KNN Loss: 2.411710739135742 | CLS Loss: 0.010081183165311813\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 2.3796286582946777 | KNN Loss: 2.37123966217041 | CLS Loss: 0.008389110676944256\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 2.4267044067382812 | KNN Loss: 2.4213740825653076 | CLS Loss: 0.005330256186425686\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 2.379427194595337 | KNN Loss: 2.3680365085601807 | CLS Loss: 0.011390695348381996\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 2.409759759902954 | KNN Loss: 2.4050424098968506 | CLS Loss: 0.0047173528000712395\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 2.4258689880371094 | KNN Loss: 2.4237306118011475 | CLS Loss: 0.002138487296178937\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 2.4093451499938965 | KNN Loss: 2.3940722942352295 | CLS Loss: 0.015272781252861023\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 2.433237075805664 | KNN Loss: 2.4293911457061768 | CLS Loss: 0.0038460195064544678\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 2.421816825866699 | KNN Loss: 2.408137321472168 | CLS Loss: 0.01367948018014431\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 2.4552276134490967 | KNN Loss: 2.434885263442993 | CLS Loss: 0.02034236490726471\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 2.439066171646118 | KNN Loss: 2.4312667846679688 | CLS Loss: 0.007799472659826279\n",
      "Epoch: 199, Loss: 2.4131, Train: 0.9965, Valid: 0.9853, Best: 0.9874\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 2.458714008331299 | KNN Loss: 2.443237543106079 | CLS Loss: 0.015476435422897339\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 2.4034814834594727 | KNN Loss: 2.390842914581299 | CLS Loss: 0.012638644315302372\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 2.393878221511841 | KNN Loss: 2.3886706829071045 | CLS Loss: 0.00520765595138073\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 2.3722450733184814 | KNN Loss: 2.3695900440216064 | CLS Loss: 0.0026550462935119867\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 2.4135169982910156 | KNN Loss: 2.4108662605285645 | CLS Loss: 0.002650691894814372\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 2.3935844898223877 | KNN Loss: 2.374696731567383 | CLS Loss: 0.018887648358941078\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 2.403209924697876 | KNN Loss: 2.3839356899261475 | CLS Loss: 0.019274193793535233\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 2.4017045497894287 | KNN Loss: 2.3971853256225586 | CLS Loss: 0.004519319627434015\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 2.378734588623047 | KNN Loss: 2.3641135692596436 | CLS Loss: 0.014621053822338581\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 2.3905677795410156 | KNN Loss: 2.387233018875122 | CLS Loss: 0.0033348307479172945\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 2.3767220973968506 | KNN Loss: 2.3684685230255127 | CLS Loss: 0.008253676816821098\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 2.466703414916992 | KNN Loss: 2.4518892765045166 | CLS Loss: 0.014814227819442749\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 2.435068368911743 | KNN Loss: 2.413602590560913 | CLS Loss: 0.021465713158249855\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 2.383655071258545 | KNN Loss: 2.371882915496826 | CLS Loss: 0.011772089637815952\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 2.3876819610595703 | KNN Loss: 2.362102746963501 | CLS Loss: 0.025579171255230904\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 2.389946699142456 | KNN Loss: 2.385956287384033 | CLS Loss: 0.0039903633296489716\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 2.4188175201416016 | KNN Loss: 2.4037158489227295 | CLS Loss: 0.015101723372936249\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 2.4168155193328857 | KNN Loss: 2.3994967937469482 | CLS Loss: 0.017318710684776306\n",
      "Epoch: 200, Loss: 2.4089, Train: 0.9975, Valid: 0.9856, Best: 0.9874\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9856, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcdabc7658848c8b568e03fcd8c2de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2af0d164a446219dc2a50e77eee26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7d814f2f594c34b3a83491f9c33974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=43.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6738f370cc14a5282f7b47ed2e4b6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bd3ea7b191c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdistances_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mmatshow\u001b[0;34m(A, fignum, **kwargs)\u001b[0m\n\u001b[1;32m   2299\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigaspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.775\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.775\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2301\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2302\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mmatshow\u001b[0;34m(self, Z, **kwargs)\u001b[0m\n\u001b[1;32m   7756\u001b[0m               \u001b[0;34m'aspect'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'equal'\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# (already the imshow default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7757\u001b[0m               **kwargs}\n\u001b[0;32m-> 7758\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         if (self._A.dtype != np.uint8 and\n",
      "\u001b[0;32m~/miniconda3/envs/rambo/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# If we have already made a copy, do the byteswap in place, else make a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.8591658672513819\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a0f5fb227840f392c30ffaea1107ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "layer 9: 0.0\n",
      "layer 10: 0.0\n",
      "Epoch: 00 | Batch: 000 / 037 | Total loss: 3.313 | Reg loss: 0.014 | Tree loss: 3.313 | Accuracy: 0.033203 | 7.816 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 037 | Total loss: 3.305 | Reg loss: 0.005 | Tree loss: 3.305 | Accuracy: 0.060547 | 5.372 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 037 | Total loss: 3.302 | Reg loss: 0.007 | Tree loss: 3.302 | Accuracy: 0.068359 | 5.325 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 037 | Total loss: 3.297 | Reg loss: 0.009 | Tree loss: 3.297 | Accuracy: 0.099609 | 5.282 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 037 | Total loss: 3.296 | Reg loss: 0.010 | Tree loss: 3.296 | Accuracy: 0.126953 | 5.271 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 037 | Total loss: 3.291 | Reg loss: 0.010 | Tree loss: 3.291 | Accuracy: 0.189453 | 5.269 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 037 | Total loss: 3.282 | Reg loss: 0.010 | Tree loss: 3.282 | Accuracy: 0.251953 | 5.267 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 037 | Total loss: 3.276 | Reg loss: 0.010 | Tree loss: 3.276 | Accuracy: 0.214844 | 5.256 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 037 | Total loss: 3.255 | Reg loss: 0.011 | Tree loss: 3.255 | Accuracy: 0.273438 | 5.252 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 037 | Total loss: 3.252 | Reg loss: 0.011 | Tree loss: 3.252 | Accuracy: 0.265625 | 5.255 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 037 | Total loss: 3.240 | Reg loss: 0.012 | Tree loss: 3.240 | Accuracy: 0.255859 | 5.262 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 037 | Total loss: 3.233 | Reg loss: 0.012 | Tree loss: 3.233 | Accuracy: 0.265625 | 5.256 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 037 | Total loss: 3.211 | Reg loss: 0.012 | Tree loss: 3.211 | Accuracy: 0.269531 | 5.269 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 037 | Total loss: 3.206 | Reg loss: 0.013 | Tree loss: 3.206 | Accuracy: 0.271484 | 5.262 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 037 | Total loss: 3.189 | Reg loss: 0.013 | Tree loss: 3.189 | Accuracy: 0.271484 | 5.27 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 037 | Total loss: 3.189 | Reg loss: 0.014 | Tree loss: 3.189 | Accuracy: 0.244141 | 5.26 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 037 | Total loss: 3.153 | Reg loss: 0.014 | Tree loss: 3.153 | Accuracy: 0.277344 | 5.26 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 037 | Total loss: 3.158 | Reg loss: 0.014 | Tree loss: 3.158 | Accuracy: 0.296875 | 5.259 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 037 | Total loss: 3.137 | Reg loss: 0.015 | Tree loss: 3.137 | Accuracy: 0.289062 | 5.258 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 037 | Total loss: 3.138 | Reg loss: 0.015 | Tree loss: 3.138 | Accuracy: 0.269531 | 5.261 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 20 | Batch: 000 / 037 | Total loss: 3.149 | Reg loss: 0.015 | Tree loss: 3.149 | Accuracy: 0.273438 | 5.26 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 037 | Total loss: 3.140 | Reg loss: 0.016 | Tree loss: 3.140 | Accuracy: 0.263672 | 5.257 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 037 | Total loss: 3.114 | Reg loss: 0.016 | Tree loss: 3.114 | Accuracy: 0.275391 | 5.25 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 23 | Batch: 000 / 037 | Total loss: 3.121 | Reg loss: 0.016 | Tree loss: 3.121 | Accuracy: 0.267578 | 5.245 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 037 | Total loss: 3.111 | Reg loss: 0.016 | Tree loss: 3.111 | Accuracy: 0.251953 | 5.242 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 037 | Total loss: 3.092 | Reg loss: 0.016 | Tree loss: 3.092 | Accuracy: 0.271484 | 5.238 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 037 | Total loss: 3.110 | Reg loss: 0.017 | Tree loss: 3.110 | Accuracy: 0.267578 | 5.233 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 037 | Total loss: 3.120 | Reg loss: 0.017 | Tree loss: 3.120 | Accuracy: 0.244141 | 5.231 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 037 | Total loss: 3.106 | Reg loss: 0.017 | Tree loss: 3.106 | Accuracy: 0.283203 | 5.227 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 037 | Total loss: 3.086 | Reg loss: 0.017 | Tree loss: 3.086 | Accuracy: 0.287109 | 5.224 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 037 | Total loss: 3.087 | Reg loss: 0.017 | Tree loss: 3.087 | Accuracy: 0.287109 | 5.222 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 037 | Total loss: 3.088 | Reg loss: 0.017 | Tree loss: 3.088 | Accuracy: 0.277344 | 5.222 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 037 | Total loss: 3.065 | Reg loss: 0.017 | Tree loss: 3.065 | Accuracy: 0.294922 | 5.226 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 037 | Total loss: 3.093 | Reg loss: 0.018 | Tree loss: 3.093 | Accuracy: 0.291016 | 5.227 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 037 | Total loss: 3.109 | Reg loss: 0.018 | Tree loss: 3.109 | Accuracy: 0.255859 | 5.227 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 35 | Batch: 000 / 037 | Total loss: 3.127 | Reg loss: 0.018 | Tree loss: 3.127 | Accuracy: 0.255859 | 5.227 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 037 | Total loss: 3.079 | Reg loss: 0.018 | Tree loss: 3.079 | Accuracy: 0.296875 | 5.226 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 037 | Total loss: 3.095 | Reg loss: 0.018 | Tree loss: 3.095 | Accuracy: 0.269531 | 5.226 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 037 | Total loss: 3.066 | Reg loss: 0.018 | Tree loss: 3.066 | Accuracy: 0.312500 | 5.224 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 037 | Total loss: 3.074 | Reg loss: 0.018 | Tree loss: 3.074 | Accuracy: 0.294922 | 5.222 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 40 | Batch: 000 / 037 | Total loss: 3.095 | Reg loss: 0.018 | Tree loss: 3.095 | Accuracy: 0.308594 | 5.223 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 037 | Total loss: 3.086 | Reg loss: 0.018 | Tree loss: 3.086 | Accuracy: 0.285156 | 5.224 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 037 | Total loss: 3.049 | Reg loss: 0.018 | Tree loss: 3.049 | Accuracy: 0.332031 | 5.222 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 037 | Total loss: 3.095 | Reg loss: 0.018 | Tree loss: 3.095 | Accuracy: 0.296875 | 5.222 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 037 | Total loss: 3.076 | Reg loss: 0.018 | Tree loss: 3.076 | Accuracy: 0.246094 | 5.222 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 037 | Total loss: 3.067 | Reg loss: 0.018 | Tree loss: 3.067 | Accuracy: 0.326172 | 5.221 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 46 | Batch: 000 / 037 | Total loss: 3.082 | Reg loss: 0.018 | Tree loss: 3.082 | Accuracy: 0.291016 | 5.221 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 037 | Total loss: 3.049 | Reg loss: 0.018 | Tree loss: 3.049 | Accuracy: 0.316406 | 5.219 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 037 | Total loss: 3.081 | Reg loss: 0.019 | Tree loss: 3.081 | Accuracy: 0.300781 | 5.216 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
