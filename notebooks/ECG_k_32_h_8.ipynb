{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 32\n",
    "tree_depth = 8\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.338754177093506 | KNN Loss: 5.834799289703369 | CLS Loss: 1.5039548873901367\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 5.342403888702393 | KNN Loss: 4.256844997406006 | CLS Loss: 1.0855587720870972\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 4.604902744293213 | KNN Loss: 3.9738428592681885 | CLS Loss: 0.6310598850250244\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 4.551351070404053 | KNN Loss: 3.9501264095306396 | CLS Loss: 0.6012245416641235\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 4.384238243103027 | KNN Loss: 3.87967848777771 | CLS Loss: 0.5045595765113831\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 4.387600898742676 | KNN Loss: 3.8757076263427734 | CLS Loss: 0.5118935108184814\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 4.261226177215576 | KNN Loss: 3.863406181335449 | CLS Loss: 0.3978199064731598\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.3324408531188965 | KNN Loss: 3.8777098655700684 | CLS Loss: 0.4547310471534729\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.26317834854126 | KNN Loss: 3.8836846351623535 | CLS Loss: 0.37949368357658386\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.328299522399902 | KNN Loss: 3.927549362182617 | CLS Loss: 0.40075039863586426\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.232325077056885 | KNN Loss: 3.847165584564209 | CLS Loss: 0.38515955209732056\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.172785758972168 | KNN Loss: 3.852198362350464 | CLS Loss: 0.32058751583099365\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.235875129699707 | KNN Loss: 3.892786741256714 | CLS Loss: 0.34308817982673645\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.186332702636719 | KNN Loss: 3.8265132904052734 | CLS Loss: 0.3598192036151886\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.13637113571167 | KNN Loss: 3.839452028274536 | CLS Loss: 0.2969188988208771\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.096521377563477 | KNN Loss: 3.82678484916687 | CLS Loss: 0.2697363495826721\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.102268695831299 | KNN Loss: 3.8138225078582764 | CLS Loss: 0.2884461283683777\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.102607250213623 | KNN Loss: 3.8001549243927 | CLS Loss: 0.3024521768093109\n",
      "Epoch: 001, Loss: 4.4291, Train: 0.9157, Valid: 0.9154, Best: 0.9154\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.149565696716309 | KNN Loss: 3.861731767654419 | CLS Loss: 0.2878340482711792\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.075207710266113 | KNN Loss: 3.770472764968872 | CLS Loss: 0.3047347366809845\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.089031219482422 | KNN Loss: 3.794865846633911 | CLS Loss: 0.29416561126708984\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 4.1081461906433105 | KNN Loss: 3.843944549560547 | CLS Loss: 0.26420146226882935\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 3.9954171180725098 | KNN Loss: 3.8052282333374023 | CLS Loss: 0.19018882513046265\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 3.957707643508911 | KNN Loss: 3.763381004333496 | CLS Loss: 0.19432662427425385\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 4.017575263977051 | KNN Loss: 3.8148012161254883 | CLS Loss: 0.20277416706085205\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 3.9853615760803223 | KNN Loss: 3.7453901767730713 | CLS Loss: 0.23997147381305695\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 4.017531394958496 | KNN Loss: 3.7844245433807373 | CLS Loss: 0.2331070601940155\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 3.9225895404815674 | KNN Loss: 3.7642910480499268 | CLS Loss: 0.15829859673976898\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 3.965515375137329 | KNN Loss: 3.7634947299957275 | CLS Loss: 0.2020205706357956\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 3.953749895095825 | KNN Loss: 3.7605226039886475 | CLS Loss: 0.1932273954153061\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 4.003399848937988 | KNN Loss: 3.766918897628784 | CLS Loss: 0.23648102581501007\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 3.9560253620147705 | KNN Loss: 3.7528252601623535 | CLS Loss: 0.20319999754428864\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 3.993661880493164 | KNN Loss: 3.756571054458618 | CLS Loss: 0.23709078133106232\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 3.914325475692749 | KNN Loss: 3.730703115463257 | CLS Loss: 0.18362241983413696\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 3.96087646484375 | KNN Loss: 3.7408297061920166 | CLS Loss: 0.2200467735528946\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 3.9481568336486816 | KNN Loss: 3.764399528503418 | CLS Loss: 0.18375718593597412\n",
      "Epoch: 002, Loss: 4.0036, Train: 0.9477, Valid: 0.9479, Best: 0.9479\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 3.93032169342041 | KNN Loss: 3.7287557125091553 | CLS Loss: 0.20156604051589966\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 3.8423097133636475 | KNN Loss: 3.7164103984832764 | CLS Loss: 0.1258992999792099\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 3.9419827461242676 | KNN Loss: 3.747560977935791 | CLS Loss: 0.19442181289196014\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 3.892958641052246 | KNN Loss: 3.7402546405792236 | CLS Loss: 0.1527038961648941\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 3.9270458221435547 | KNN Loss: 3.768986225128174 | CLS Loss: 0.15805959701538086\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 3.887299060821533 | KNN Loss: 3.7231390476226807 | CLS Loss: 0.16415990889072418\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 3.892925500869751 | KNN Loss: 3.769770622253418 | CLS Loss: 0.12315477430820465\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 3.9068009853363037 | KNN Loss: 3.7346606254577637 | CLS Loss: 0.17214037477970123\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 3.8789875507354736 | KNN Loss: 3.711744785308838 | CLS Loss: 0.16724270582199097\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 3.902172803878784 | KNN Loss: 3.751859188079834 | CLS Loss: 0.1503135710954666\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 3.832700252532959 | KNN Loss: 3.73861026763916 | CLS Loss: 0.09409000724554062\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 3.8924384117126465 | KNN Loss: 3.732203483581543 | CLS Loss: 0.16023504734039307\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 3.8959434032440186 | KNN Loss: 3.68461012840271 | CLS Loss: 0.21133318543434143\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 3.8893418312072754 | KNN Loss: 3.7479777336120605 | CLS Loss: 0.14136414229869843\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 3.922434091567993 | KNN Loss: 3.720393180847168 | CLS Loss: 0.20204098522663116\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 3.9292266368865967 | KNN Loss: 3.785828113555908 | CLS Loss: 0.14339859783649445\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 3.906259298324585 | KNN Loss: 3.7400307655334473 | CLS Loss: 0.16622863709926605\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 3.872553586959839 | KNN Loss: 3.7274510860443115 | CLS Loss: 0.14510256052017212\n",
      "Epoch: 003, Loss: 3.8992, Train: 0.9655, Valid: 0.9637, Best: 0.9637\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 3.8493309020996094 | KNN Loss: 3.679337501525879 | CLS Loss: 0.16999340057373047\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 3.853825569152832 | KNN Loss: 3.7035582065582275 | CLS Loss: 0.15026727318763733\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 3.870220899581909 | KNN Loss: 3.759558916091919 | CLS Loss: 0.11066202074289322\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 3.803834915161133 | KNN Loss: 3.647618055343628 | CLS Loss: 0.15621685981750488\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 4.032900810241699 | KNN Loss: 3.7298195362091064 | CLS Loss: 0.3030811846256256\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 3.8533151149749756 | KNN Loss: 3.723776340484619 | CLS Loss: 0.12953881919384003\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 3.8882598876953125 | KNN Loss: 3.740785598754883 | CLS Loss: 0.1474742740392685\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 3.8804666996002197 | KNN Loss: 3.725264072418213 | CLS Loss: 0.15520265698432922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 3.843834638595581 | KNN Loss: 3.724855661392212 | CLS Loss: 0.1189790666103363\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 3.889632225036621 | KNN Loss: 3.6959853172302246 | CLS Loss: 0.19364680349826813\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 3.847315549850464 | KNN Loss: 3.7167088985443115 | CLS Loss: 0.13060657680034637\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 3.943624496459961 | KNN Loss: 3.7300667762756348 | CLS Loss: 0.21355783939361572\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 3.8840489387512207 | KNN Loss: 3.7766077518463135 | CLS Loss: 0.1074412390589714\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 3.8714261054992676 | KNN Loss: 3.7358646392822266 | CLS Loss: 0.1355615109205246\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 3.9323315620422363 | KNN Loss: 3.7160022258758545 | CLS Loss: 0.21632935106754303\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 3.868086338043213 | KNN Loss: 3.770447015762329 | CLS Loss: 0.0976392924785614\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 3.8313639163970947 | KNN Loss: 3.7010483741760254 | CLS Loss: 0.1303156018257141\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 3.8506240844726562 | KNN Loss: 3.730786085128784 | CLS Loss: 0.11983790248632431\n",
      "Epoch: 004, Loss: 3.8610, Train: 0.9672, Valid: 0.9651, Best: 0.9651\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 3.8626723289489746 | KNN Loss: 3.7498362064361572 | CLS Loss: 0.11283621191978455\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 3.858107566833496 | KNN Loss: 3.685616970062256 | CLS Loss: 0.1724907010793686\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 3.84114670753479 | KNN Loss: 3.6848161220550537 | CLS Loss: 0.15633052587509155\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 3.791062355041504 | KNN Loss: 3.6874845027923584 | CLS Loss: 0.1035778820514679\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 3.8732635974884033 | KNN Loss: 3.7556393146514893 | CLS Loss: 0.11762428283691406\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 3.8627166748046875 | KNN Loss: 3.7431960105895996 | CLS Loss: 0.11952069401741028\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 3.8364994525909424 | KNN Loss: 3.7153637409210205 | CLS Loss: 0.12113570421934128\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 3.8201184272766113 | KNN Loss: 3.6942968368530273 | CLS Loss: 0.1258215308189392\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 3.8075547218322754 | KNN Loss: 3.708265781402588 | CLS Loss: 0.09928885102272034\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 3.8562886714935303 | KNN Loss: 3.7184221744537354 | CLS Loss: 0.13786639273166656\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 3.8538331985473633 | KNN Loss: 3.70945143699646 | CLS Loss: 0.14438170194625854\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 3.864259958267212 | KNN Loss: 3.7279551029205322 | CLS Loss: 0.1363048255443573\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 3.8704779148101807 | KNN Loss: 3.7233192920684814 | CLS Loss: 0.14715851843357086\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 3.857922077178955 | KNN Loss: 3.750805616378784 | CLS Loss: 0.10711649805307388\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 3.818631649017334 | KNN Loss: 3.7108311653137207 | CLS Loss: 0.1078004539012909\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 3.8559718132019043 | KNN Loss: 3.706350088119507 | CLS Loss: 0.1496216207742691\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 3.792085647583008 | KNN Loss: 3.710508346557617 | CLS Loss: 0.08157731592655182\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 3.8174495697021484 | KNN Loss: 3.759329319000244 | CLS Loss: 0.058120246976614\n",
      "Epoch: 005, Loss: 3.8391, Train: 0.9729, Valid: 0.9706, Best: 0.9706\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 3.8142874240875244 | KNN Loss: 3.723945140838623 | CLS Loss: 0.09034234285354614\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 3.8174386024475098 | KNN Loss: 3.668518304824829 | CLS Loss: 0.14892035722732544\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 3.829425096511841 | KNN Loss: 3.705703020095825 | CLS Loss: 0.1237221509218216\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 3.846607208251953 | KNN Loss: 3.7386844158172607 | CLS Loss: 0.10792289674282074\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 3.832864761352539 | KNN Loss: 3.717153549194336 | CLS Loss: 0.11571130156517029\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 3.8164052963256836 | KNN Loss: 3.7184386253356934 | CLS Loss: 0.09796671569347382\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 3.777923822402954 | KNN Loss: 3.696199417114258 | CLS Loss: 0.08172445744276047\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 3.8259572982788086 | KNN Loss: 3.713162899017334 | CLS Loss: 0.11279450356960297\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 3.800204038619995 | KNN Loss: 3.6995818614959717 | CLS Loss: 0.10062216967344284\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 3.8486838340759277 | KNN Loss: 3.746119499206543 | CLS Loss: 0.10256435722112656\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 3.7834627628326416 | KNN Loss: 3.717390775680542 | CLS Loss: 0.06607195734977722\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 3.7898166179656982 | KNN Loss: 3.6773815155029297 | CLS Loss: 0.11243506520986557\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 3.76990008354187 | KNN Loss: 3.7184927463531494 | CLS Loss: 0.051407359540462494\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 3.829930543899536 | KNN Loss: 3.7422680854797363 | CLS Loss: 0.08766245096921921\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 3.826084852218628 | KNN Loss: 3.7126433849334717 | CLS Loss: 0.11344154924154282\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 3.809854507446289 | KNN Loss: 3.7548375129699707 | CLS Loss: 0.05501696094870567\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 3.842557430267334 | KNN Loss: 3.696493148803711 | CLS Loss: 0.14606435596942902\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 3.7842698097229004 | KNN Loss: 3.706995964050293 | CLS Loss: 0.07727374136447906\n",
      "Epoch: 006, Loss: 3.8186, Train: 0.9765, Valid: 0.9737, Best: 0.9737\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 3.799485921859741 | KNN Loss: 3.7011308670043945 | CLS Loss: 0.09835502505302429\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 3.8006935119628906 | KNN Loss: 3.689114809036255 | CLS Loss: 0.11157865822315216\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 3.8323049545288086 | KNN Loss: 3.7364439964294434 | CLS Loss: 0.09586100280284882\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 3.8027985095977783 | KNN Loss: 3.6941328048706055 | CLS Loss: 0.10866567492485046\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 3.7938992977142334 | KNN Loss: 3.714862108230591 | CLS Loss: 0.07903715968132019\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 3.7777841091156006 | KNN Loss: 3.7017855644226074 | CLS Loss: 0.07599848508834839\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 3.774216651916504 | KNN Loss: 3.67757511138916 | CLS Loss: 0.09664156287908554\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 3.7944631576538086 | KNN Loss: 3.7064950466156006 | CLS Loss: 0.08796817064285278\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 3.9110560417175293 | KNN Loss: 3.7739782333374023 | CLS Loss: 0.1370776891708374\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 3.780111789703369 | KNN Loss: 3.6994287967681885 | CLS Loss: 0.0806829109787941\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 3.807286024093628 | KNN Loss: 3.7201597690582275 | CLS Loss: 0.08712618798017502\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 3.799522638320923 | KNN Loss: 3.7352216243743896 | CLS Loss: 0.064301036298275\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 3.7979483604431152 | KNN Loss: 3.7261226177215576 | CLS Loss: 0.07182569056749344\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 3.795553207397461 | KNN Loss: 3.7022411823272705 | CLS Loss: 0.09331203252077103\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 3.789621353149414 | KNN Loss: 3.698827028274536 | CLS Loss: 0.09079426527023315\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 3.774585247039795 | KNN Loss: 3.6960971355438232 | CLS Loss: 0.07848812639713287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 3.749708414077759 | KNN Loss: 3.7052414417266846 | CLS Loss: 0.04446694999933243\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 3.840590476989746 | KNN Loss: 3.7238759994506836 | CLS Loss: 0.11671452969312668\n",
      "Epoch: 007, Loss: 3.8055, Train: 0.9751, Valid: 0.9724, Best: 0.9737\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 3.7702958583831787 | KNN Loss: 3.7018682956695557 | CLS Loss: 0.0684276595711708\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 3.813961982727051 | KNN Loss: 3.7236132621765137 | CLS Loss: 0.09034878015518188\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 3.771840810775757 | KNN Loss: 3.6930980682373047 | CLS Loss: 0.07874263823032379\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 3.795667886734009 | KNN Loss: 3.6814167499542236 | CLS Loss: 0.11425109207630157\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 3.7971737384796143 | KNN Loss: 3.695945978164673 | CLS Loss: 0.10122781991958618\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 3.7805964946746826 | KNN Loss: 3.6957924365997314 | CLS Loss: 0.08480411022901535\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 3.765913963317871 | KNN Loss: 3.657498598098755 | CLS Loss: 0.10841534286737442\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 3.781704902648926 | KNN Loss: 3.6953234672546387 | CLS Loss: 0.08638134598731995\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 3.7553083896636963 | KNN Loss: 3.6884570121765137 | CLS Loss: 0.06685126572847366\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 3.7694168090820312 | KNN Loss: 3.6922192573547363 | CLS Loss: 0.0771975964307785\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 3.773716688156128 | KNN Loss: 3.7065792083740234 | CLS Loss: 0.06713742017745972\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 3.834221363067627 | KNN Loss: 3.661100387573242 | CLS Loss: 0.17312099039554596\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 3.804260015487671 | KNN Loss: 3.689023971557617 | CLS Loss: 0.11523598432540894\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 3.8546342849731445 | KNN Loss: 3.7568156719207764 | CLS Loss: 0.09781860560178757\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 3.785775661468506 | KNN Loss: 3.7075254917144775 | CLS Loss: 0.07825013995170593\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 3.7573606967926025 | KNN Loss: 3.6754815578460693 | CLS Loss: 0.08187907934188843\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 3.754688262939453 | KNN Loss: 3.6806280612945557 | CLS Loss: 0.0740601122379303\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 3.789407968521118 | KNN Loss: 3.6891837120056152 | CLS Loss: 0.1002243384718895\n",
      "Epoch: 008, Loss: 3.7850, Train: 0.9795, Valid: 0.9757, Best: 0.9757\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 3.737121343612671 | KNN Loss: 3.6504154205322266 | CLS Loss: 0.08670596033334732\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 3.8098645210266113 | KNN Loss: 3.7067043781280518 | CLS Loss: 0.10316018760204315\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 3.78830885887146 | KNN Loss: 3.682135581970215 | CLS Loss: 0.10617329925298691\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 3.7644848823547363 | KNN Loss: 3.6743757724761963 | CLS Loss: 0.09010908752679825\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 3.769788980484009 | KNN Loss: 3.660374164581299 | CLS Loss: 0.10941474139690399\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 3.7935500144958496 | KNN Loss: 3.673916816711426 | CLS Loss: 0.11963330209255219\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 3.7754929065704346 | KNN Loss: 3.709041118621826 | CLS Loss: 0.06645188480615616\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 3.774177312850952 | KNN Loss: 3.716268539428711 | CLS Loss: 0.05790876969695091\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 3.7488441467285156 | KNN Loss: 3.688915252685547 | CLS Loss: 0.05992889031767845\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 3.779003143310547 | KNN Loss: 3.711909770965576 | CLS Loss: 0.06709348410367966\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 3.7360661029815674 | KNN Loss: 3.675666093826294 | CLS Loss: 0.060400016605854034\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 3.832258701324463 | KNN Loss: 3.7181808948516846 | CLS Loss: 0.1140778437256813\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 3.7785568237304688 | KNN Loss: 3.672628164291382 | CLS Loss: 0.10592874139547348\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 3.80193829536438 | KNN Loss: 3.6654868125915527 | CLS Loss: 0.1364515721797943\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 3.779465913772583 | KNN Loss: 3.6926462650299072 | CLS Loss: 0.08681963384151459\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 3.7705202102661133 | KNN Loss: 3.6914455890655518 | CLS Loss: 0.07907472550868988\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 3.7364542484283447 | KNN Loss: 3.6812026500701904 | CLS Loss: 0.05525152012705803\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 3.8162832260131836 | KNN Loss: 3.6640625 | CLS Loss: 0.15222084522247314\n",
      "Epoch: 009, Loss: 3.7768, Train: 0.9792, Valid: 0.9768, Best: 0.9768\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 3.777630567550659 | KNN Loss: 3.687516212463379 | CLS Loss: 0.09011427313089371\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 3.78011417388916 | KNN Loss: 3.7156765460968018 | CLS Loss: 0.06443751603364944\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 3.8001174926757812 | KNN Loss: 3.698875665664673 | CLS Loss: 0.10124170780181885\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 3.739954710006714 | KNN Loss: 3.68638014793396 | CLS Loss: 0.053574491292238235\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 3.758668899536133 | KNN Loss: 3.685872793197632 | CLS Loss: 0.0727960467338562\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 3.773597240447998 | KNN Loss: 3.646348476409912 | CLS Loss: 0.12724876403808594\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 3.758532762527466 | KNN Loss: 3.683319091796875 | CLS Loss: 0.07521370053291321\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 3.771099328994751 | KNN Loss: 3.704099655151367 | CLS Loss: 0.06699966639280319\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 3.7345869541168213 | KNN Loss: 3.6628074645996094 | CLS Loss: 0.0717795118689537\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 3.768617868423462 | KNN Loss: 3.6687004566192627 | CLS Loss: 0.09991739690303802\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 3.7861082553863525 | KNN Loss: 3.6908605098724365 | CLS Loss: 0.0952477753162384\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 3.780423164367676 | KNN Loss: 3.6559510231018066 | CLS Loss: 0.12447226047515869\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 3.805281162261963 | KNN Loss: 3.7260866165161133 | CLS Loss: 0.0791945606470108\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 3.770033121109009 | KNN Loss: 3.6878015995025635 | CLS Loss: 0.08223161846399307\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 3.7536349296569824 | KNN Loss: 3.693247079849243 | CLS Loss: 0.0603877529501915\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 3.765732765197754 | KNN Loss: 3.7065582275390625 | CLS Loss: 0.05917461961507797\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 3.8084449768066406 | KNN Loss: 3.6880550384521484 | CLS Loss: 0.12038984894752502\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 3.738393783569336 | KNN Loss: 3.682727575302124 | CLS Loss: 0.055666275322437286\n",
      "Epoch: 010, Loss: 3.7651, Train: 0.9818, Valid: 0.9782, Best: 0.9782\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 3.7656643390655518 | KNN Loss: 3.6872308254241943 | CLS Loss: 0.07843346148729324\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 3.7452423572540283 | KNN Loss: 3.690274953842163 | CLS Loss: 0.05496745556592941\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 3.6863768100738525 | KNN Loss: 3.6433401107788086 | CLS Loss: 0.04303664341568947\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 3.7706496715545654 | KNN Loss: 3.705084800720215 | CLS Loss: 0.06556487828493118\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 3.7473320960998535 | KNN Loss: 3.6777589321136475 | CLS Loss: 0.06957320123910904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 3.7585644721984863 | KNN Loss: 3.6319265365600586 | CLS Loss: 0.1266380250453949\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 3.759752035140991 | KNN Loss: 3.68269419670105 | CLS Loss: 0.077057845890522\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 3.824002265930176 | KNN Loss: 3.7147364616394043 | CLS Loss: 0.1092657595872879\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 3.772289276123047 | KNN Loss: 3.680137872695923 | CLS Loss: 0.09215141087770462\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 3.7551050186157227 | KNN Loss: 3.672175168991089 | CLS Loss: 0.08292978256940842\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 3.7618613243103027 | KNN Loss: 3.681504249572754 | CLS Loss: 0.08035717159509659\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 3.759122848510742 | KNN Loss: 3.623027801513672 | CLS Loss: 0.13609500229358673\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 3.7889795303344727 | KNN Loss: 3.6959903240203857 | CLS Loss: 0.09298920631408691\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 3.7343387603759766 | KNN Loss: 3.645662784576416 | CLS Loss: 0.08867595344781876\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 3.783379077911377 | KNN Loss: 3.7040398120880127 | CLS Loss: 0.0793391615152359\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 3.7876052856445312 | KNN Loss: 3.7079646587371826 | CLS Loss: 0.07964064925909042\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 3.725642204284668 | KNN Loss: 3.661139726638794 | CLS Loss: 0.06450239568948746\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 3.741698741912842 | KNN Loss: 3.7035317420959473 | CLS Loss: 0.03816692903637886\n",
      "Epoch: 011, Loss: 3.7555, Train: 0.9826, Valid: 0.9783, Best: 0.9783\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 3.7721850872039795 | KNN Loss: 3.708632230758667 | CLS Loss: 0.06355278939008713\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 3.75216007232666 | KNN Loss: 3.698852777481079 | CLS Loss: 0.0533071793615818\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 3.7084147930145264 | KNN Loss: 3.619746446609497 | CLS Loss: 0.0886683538556099\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 3.772841453552246 | KNN Loss: 3.7132081985473633 | CLS Loss: 0.05963326245546341\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 3.7630555629730225 | KNN Loss: 3.680232286453247 | CLS Loss: 0.08282327651977539\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 3.7415778636932373 | KNN Loss: 3.692868709564209 | CLS Loss: 0.0487092062830925\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 3.749495267868042 | KNN Loss: 3.676790475845337 | CLS Loss: 0.07270469516515732\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 3.7621970176696777 | KNN Loss: 3.693392515182495 | CLS Loss: 0.0688045471906662\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 3.8174543380737305 | KNN Loss: 3.699090003967285 | CLS Loss: 0.11836422979831696\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 3.7646782398223877 | KNN Loss: 3.675419807434082 | CLS Loss: 0.08925841003656387\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 3.7176878452301025 | KNN Loss: 3.6424148082733154 | CLS Loss: 0.07527298480272293\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 3.708218574523926 | KNN Loss: 3.6415438652038574 | CLS Loss: 0.06667476892471313\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 3.78330135345459 | KNN Loss: 3.7154018878936768 | CLS Loss: 0.06789950281381607\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 3.7387609481811523 | KNN Loss: 3.6600916385650635 | CLS Loss: 0.07866919785737991\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 3.7339162826538086 | KNN Loss: 3.6723484992980957 | CLS Loss: 0.0615677684545517\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 3.747282028198242 | KNN Loss: 3.6941051483154297 | CLS Loss: 0.05317690223455429\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 3.7734758853912354 | KNN Loss: 3.710339307785034 | CLS Loss: 0.06313654780387878\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 3.8308300971984863 | KNN Loss: 3.728496789932251 | CLS Loss: 0.10233324021100998\n",
      "Epoch: 012, Loss: 3.7575, Train: 0.9834, Valid: 0.9788, Best: 0.9788\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 3.7616004943847656 | KNN Loss: 3.6839845180511475 | CLS Loss: 0.07761586457490921\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 3.7123167514801025 | KNN Loss: 3.675229549407959 | CLS Loss: 0.03708714246749878\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 3.7665205001831055 | KNN Loss: 3.713813304901123 | CLS Loss: 0.05270710214972496\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 3.741968870162964 | KNN Loss: 3.6859428882598877 | CLS Loss: 0.05602595955133438\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 3.730027437210083 | KNN Loss: 3.635573148727417 | CLS Loss: 0.09445429593324661\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 3.751309633255005 | KNN Loss: 3.6824915409088135 | CLS Loss: 0.06881808489561081\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 3.7007646560668945 | KNN Loss: 3.6516950130462646 | CLS Loss: 0.04906967654824257\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 3.712899923324585 | KNN Loss: 3.638209581375122 | CLS Loss: 0.07469037175178528\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 3.7370967864990234 | KNN Loss: 3.662182092666626 | CLS Loss: 0.0749145895242691\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 3.7289724349975586 | KNN Loss: 3.705857515335083 | CLS Loss: 0.02311486378312111\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 3.721224784851074 | KNN Loss: 3.6811513900756836 | CLS Loss: 0.04007338732481003\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 3.7918970584869385 | KNN Loss: 3.6945407390594482 | CLS Loss: 0.09735631942749023\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 3.7433178424835205 | KNN Loss: 3.702958345413208 | CLS Loss: 0.04035957157611847\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 3.786870241165161 | KNN Loss: 3.6710288524627686 | CLS Loss: 0.11584144085645676\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 3.698699712753296 | KNN Loss: 3.656097888946533 | CLS Loss: 0.0426018051803112\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 3.7409567832946777 | KNN Loss: 3.6695423126220703 | CLS Loss: 0.07141455262899399\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 3.740504264831543 | KNN Loss: 3.6931114196777344 | CLS Loss: 0.047392938286066055\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 3.74395751953125 | KNN Loss: 3.711907148361206 | CLS Loss: 0.03205043077468872\n",
      "Epoch: 013, Loss: 3.7493, Train: 0.9852, Valid: 0.9806, Best: 0.9806\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 3.7374207973480225 | KNN Loss: 3.663790225982666 | CLS Loss: 0.07363061606884003\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 3.780021905899048 | KNN Loss: 3.7159597873687744 | CLS Loss: 0.06406203657388687\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 3.7210233211517334 | KNN Loss: 3.6689560413360596 | CLS Loss: 0.05206738039851189\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 3.758932113647461 | KNN Loss: 3.668926477432251 | CLS Loss: 0.09000562876462936\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 3.775743007659912 | KNN Loss: 3.6837196350097656 | CLS Loss: 0.0920233279466629\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 3.726161479949951 | KNN Loss: 3.671079158782959 | CLS Loss: 0.05508236587047577\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 3.711780071258545 | KNN Loss: 3.664954900741577 | CLS Loss: 0.046825096011161804\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 3.7571299076080322 | KNN Loss: 3.710397720336914 | CLS Loss: 0.046732254326343536\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 3.758943796157837 | KNN Loss: 3.6866610050201416 | CLS Loss: 0.07228288054466248\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 3.7405989170074463 | KNN Loss: 3.680792808532715 | CLS Loss: 0.059806060045957565\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 3.719808578491211 | KNN Loss: 3.6636228561401367 | CLS Loss: 0.05618569999933243\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 3.748060703277588 | KNN Loss: 3.679197072982788 | CLS Loss: 0.06886367499828339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 3.753809690475464 | KNN Loss: 3.6689274311065674 | CLS Loss: 0.0848822072148323\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 3.7419090270996094 | KNN Loss: 3.6707661151885986 | CLS Loss: 0.07114293426275253\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 3.7657008171081543 | KNN Loss: 3.708181142807007 | CLS Loss: 0.05751967802643776\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 3.7609260082244873 | KNN Loss: 3.6992526054382324 | CLS Loss: 0.061673350632190704\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 3.7297489643096924 | KNN Loss: 3.6697888374328613 | CLS Loss: 0.059960171580314636\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 3.776679277420044 | KNN Loss: 3.7186031341552734 | CLS Loss: 0.058076124638319016\n",
      "Epoch: 014, Loss: 3.7413, Train: 0.9839, Valid: 0.9805, Best: 0.9806\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 3.7490642070770264 | KNN Loss: 3.6808879375457764 | CLS Loss: 0.06817632168531418\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 3.7347733974456787 | KNN Loss: 3.697275400161743 | CLS Loss: 0.03749788925051689\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 3.733839750289917 | KNN Loss: 3.704232931137085 | CLS Loss: 0.029606912285089493\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 3.7323391437530518 | KNN Loss: 3.6650776863098145 | CLS Loss: 0.06726135313510895\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 3.7391867637634277 | KNN Loss: 3.680243968963623 | CLS Loss: 0.058942727744579315\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 3.7005465030670166 | KNN Loss: 3.6593925952911377 | CLS Loss: 0.041153836995363235\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 3.755627155303955 | KNN Loss: 3.694298028945923 | CLS Loss: 0.06132921576499939\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 3.770878791809082 | KNN Loss: 3.6990861892700195 | CLS Loss: 0.07179252058267593\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 3.733990430831909 | KNN Loss: 3.6730966567993164 | CLS Loss: 0.06089385598897934\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 3.743037462234497 | KNN Loss: 3.6897811889648438 | CLS Loss: 0.053256236016750336\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 3.7452926635742188 | KNN Loss: 3.7016780376434326 | CLS Loss: 0.043614670634269714\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 3.71396541595459 | KNN Loss: 3.678239345550537 | CLS Loss: 0.03572618216276169\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 3.7434403896331787 | KNN Loss: 3.68087100982666 | CLS Loss: 0.06256947666406631\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 3.7869369983673096 | KNN Loss: 3.7141799926757812 | CLS Loss: 0.0727570503950119\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 3.723661422729492 | KNN Loss: 3.669691562652588 | CLS Loss: 0.05396995320916176\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 3.7282073497772217 | KNN Loss: 3.664771795272827 | CLS Loss: 0.0634356141090393\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 3.7089827060699463 | KNN Loss: 3.666938543319702 | CLS Loss: 0.04204414412379265\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 3.8117244243621826 | KNN Loss: 3.7328009605407715 | CLS Loss: 0.07892335951328278\n",
      "Epoch: 015, Loss: 3.7408, Train: 0.9840, Valid: 0.9802, Best: 0.9806\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 3.743168830871582 | KNN Loss: 3.672377586364746 | CLS Loss: 0.07079119235277176\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 3.756650447845459 | KNN Loss: 3.698554515838623 | CLS Loss: 0.0580960214138031\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 3.746397018432617 | KNN Loss: 3.6798527240753174 | CLS Loss: 0.06654426455497742\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 3.7768280506134033 | KNN Loss: 3.727888345718384 | CLS Loss: 0.048939645290374756\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 3.8167741298675537 | KNN Loss: 3.7432141304016113 | CLS Loss: 0.0735599622130394\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 3.749786376953125 | KNN Loss: 3.697962760925293 | CLS Loss: 0.051823507994413376\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 3.693810224533081 | KNN Loss: 3.6522610187530518 | CLS Loss: 0.04154931753873825\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 3.687689781188965 | KNN Loss: 3.6712658405303955 | CLS Loss: 0.016423869878053665\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 3.7054123878479004 | KNN Loss: 3.6659421920776367 | CLS Loss: 0.03947011008858681\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 3.7243103981018066 | KNN Loss: 3.6771485805511475 | CLS Loss: 0.04716188460588455\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 3.6956300735473633 | KNN Loss: 3.6531319618225098 | CLS Loss: 0.042498212307691574\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 3.751898765563965 | KNN Loss: 3.6512460708618164 | CLS Loss: 0.10065262019634247\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 3.751917600631714 | KNN Loss: 3.652470827102661 | CLS Loss: 0.09944675117731094\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 3.7268686294555664 | KNN Loss: 3.6617507934570312 | CLS Loss: 0.06511793285608292\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 3.6915135383605957 | KNN Loss: 3.659353256225586 | CLS Loss: 0.03216031938791275\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 3.7481820583343506 | KNN Loss: 3.7023730278015137 | CLS Loss: 0.04580896347761154\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 3.736450672149658 | KNN Loss: 3.6950018405914307 | CLS Loss: 0.04144873470067978\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 3.760439872741699 | KNN Loss: 3.701514959335327 | CLS Loss: 0.0589248389005661\n",
      "Epoch: 016, Loss: 3.7289, Train: 0.9847, Valid: 0.9809, Best: 0.9809\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 3.742091655731201 | KNN Loss: 3.7027487754821777 | CLS Loss: 0.03934277966618538\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 3.7429754734039307 | KNN Loss: 3.676473379135132 | CLS Loss: 0.06650210916996002\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 3.6998226642608643 | KNN Loss: 3.6581952571868896 | CLS Loss: 0.04162732884287834\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 3.7547125816345215 | KNN Loss: 3.696780204772949 | CLS Loss: 0.05793245509266853\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 3.7594733238220215 | KNN Loss: 3.6687216758728027 | CLS Loss: 0.09075172990560532\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 3.6981360912323 | KNN Loss: 3.6419811248779297 | CLS Loss: 0.05615507438778877\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 3.7580533027648926 | KNN Loss: 3.701051950454712 | CLS Loss: 0.05700135603547096\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 3.723813533782959 | KNN Loss: 3.6772267818450928 | CLS Loss: 0.046586692333221436\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 3.7164552211761475 | KNN Loss: 3.6380345821380615 | CLS Loss: 0.07842055708169937\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 3.714012622833252 | KNN Loss: 3.6377370357513428 | CLS Loss: 0.07627556473016739\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 3.7330198287963867 | KNN Loss: 3.69875431060791 | CLS Loss: 0.03426554054021835\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 3.746321439743042 | KNN Loss: 3.6642675399780273 | CLS Loss: 0.08205391466617584\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 3.7140610218048096 | KNN Loss: 3.6369717121124268 | CLS Loss: 0.0770893394947052\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 3.695627450942993 | KNN Loss: 3.640160322189331 | CLS Loss: 0.05546707287430763\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 3.7113354206085205 | KNN Loss: 3.6711583137512207 | CLS Loss: 0.040177106857299805\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 3.7742533683776855 | KNN Loss: 3.6932148933410645 | CLS Loss: 0.08103854954242706\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 3.736468553543091 | KNN Loss: 3.6895923614501953 | CLS Loss: 0.046876128762960434\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 3.701799154281616 | KNN Loss: 3.653703451156616 | CLS Loss: 0.04809568449854851\n",
      "Epoch: 017, Loss: 3.7277, Train: 0.9856, Valid: 0.9805, Best: 0.9809\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 3.720925807952881 | KNN Loss: 3.6867692470550537 | CLS Loss: 0.03415659815073013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 3.6982250213623047 | KNN Loss: 3.6511051654815674 | CLS Loss: 0.04711996018886566\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 3.7589612007141113 | KNN Loss: 3.6595091819763184 | CLS Loss: 0.09945190697908401\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 3.7329001426696777 | KNN Loss: 3.6983208656311035 | CLS Loss: 0.03457936644554138\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 3.7600438594818115 | KNN Loss: 3.6894490718841553 | CLS Loss: 0.07059486955404282\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 3.7165403366088867 | KNN Loss: 3.6628689765930176 | CLS Loss: 0.05367138236761093\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 3.7211008071899414 | KNN Loss: 3.6618824005126953 | CLS Loss: 0.05921830236911774\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 3.688033103942871 | KNN Loss: 3.6543681621551514 | CLS Loss: 0.03366489335894585\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 3.6989071369171143 | KNN Loss: 3.6421597003936768 | CLS Loss: 0.05674738809466362\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 3.7125792503356934 | KNN Loss: 3.6538190841674805 | CLS Loss: 0.05876028537750244\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 3.678213119506836 | KNN Loss: 3.6283345222473145 | CLS Loss: 0.04987861216068268\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 3.7308621406555176 | KNN Loss: 3.6766061782836914 | CLS Loss: 0.054256077855825424\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 3.6916494369506836 | KNN Loss: 3.6579554080963135 | CLS Loss: 0.03369399905204773\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 3.69923734664917 | KNN Loss: 3.6417124271392822 | CLS Loss: 0.05752485990524292\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 3.701678514480591 | KNN Loss: 3.628016710281372 | CLS Loss: 0.07366180419921875\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 3.7585575580596924 | KNN Loss: 3.7363903522491455 | CLS Loss: 0.022167125716805458\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 3.731356143951416 | KNN Loss: 3.6728034019470215 | CLS Loss: 0.058552831411361694\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 3.690925121307373 | KNN Loss: 3.6605947017669678 | CLS Loss: 0.030330387875437737\n",
      "Epoch: 018, Loss: 3.7180, Train: 0.9874, Valid: 0.9818, Best: 0.9818\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 3.7039990425109863 | KNN Loss: 3.662888526916504 | CLS Loss: 0.04111044481396675\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 3.7106432914733887 | KNN Loss: 3.62569260597229 | CLS Loss: 0.08495058864355087\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 3.756516695022583 | KNN Loss: 3.6623122692108154 | CLS Loss: 0.09420439600944519\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 3.7264561653137207 | KNN Loss: 3.6596429347991943 | CLS Loss: 0.06681313365697861\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 3.7162251472473145 | KNN Loss: 3.6545019149780273 | CLS Loss: 0.06172320991754532\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 3.6908514499664307 | KNN Loss: 3.6276214122772217 | CLS Loss: 0.06322994828224182\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 3.6718997955322266 | KNN Loss: 3.6512703895568848 | CLS Loss: 0.020629389211535454\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 3.689166307449341 | KNN Loss: 3.6623237133026123 | CLS Loss: 0.02684248611330986\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 3.721449851989746 | KNN Loss: 3.662184715270996 | CLS Loss: 0.059265051037073135\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 3.6805381774902344 | KNN Loss: 3.620633840560913 | CLS Loss: 0.059904277324676514\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 3.699281930923462 | KNN Loss: 3.6612741947174072 | CLS Loss: 0.03800763934850693\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 3.674696207046509 | KNN Loss: 3.649282693862915 | CLS Loss: 0.02541355788707733\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 3.7697083950042725 | KNN Loss: 3.694411039352417 | CLS Loss: 0.07529736310243607\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 3.7178144454956055 | KNN Loss: 3.6546521186828613 | CLS Loss: 0.06316221505403519\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 3.721423387527466 | KNN Loss: 3.6604959964752197 | CLS Loss: 0.06092742830514908\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 3.6751203536987305 | KNN Loss: 3.62705659866333 | CLS Loss: 0.048063673079013824\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 3.742609977722168 | KNN Loss: 3.704515218734741 | CLS Loss: 0.038094714283943176\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 3.682795286178589 | KNN Loss: 3.635038375854492 | CLS Loss: 0.0477568618953228\n",
      "Epoch: 019, Loss: 3.7120, Train: 0.9827, Valid: 0.9773, Best: 0.9818\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 3.6790382862091064 | KNN Loss: 3.6481313705444336 | CLS Loss: 0.03090699389576912\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 3.722856283187866 | KNN Loss: 3.662731409072876 | CLS Loss: 0.06012483313679695\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 3.766709089279175 | KNN Loss: 3.714262008666992 | CLS Loss: 0.05244704335927963\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 3.6939327716827393 | KNN Loss: 3.661628007888794 | CLS Loss: 0.032304659485816956\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 3.7001571655273438 | KNN Loss: 3.658712863922119 | CLS Loss: 0.0414443202316761\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 3.7541439533233643 | KNN Loss: 3.6970162391662598 | CLS Loss: 0.05712781846523285\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 3.6964285373687744 | KNN Loss: 3.6438326835632324 | CLS Loss: 0.0525958426296711\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 3.726592540740967 | KNN Loss: 3.708923816680908 | CLS Loss: 0.01766861043870449\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 3.7205889225006104 | KNN Loss: 3.6155190467834473 | CLS Loss: 0.10506998002529144\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 3.7021842002868652 | KNN Loss: 3.6431643962860107 | CLS Loss: 0.05901980772614479\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 3.721165895462036 | KNN Loss: 3.6659626960754395 | CLS Loss: 0.05520327016711235\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 3.69120717048645 | KNN Loss: 3.648588180541992 | CLS Loss: 0.04261898994445801\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 3.715167999267578 | KNN Loss: 3.6696178913116455 | CLS Loss: 0.04554999619722366\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 3.7614669799804688 | KNN Loss: 3.689987897872925 | CLS Loss: 0.0714791789650917\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 3.710913896560669 | KNN Loss: 3.630493402481079 | CLS Loss: 0.08042050153017044\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 3.704319477081299 | KNN Loss: 3.658109664916992 | CLS Loss: 0.046209756284952164\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 3.7871432304382324 | KNN Loss: 3.70573353767395 | CLS Loss: 0.08140964806079865\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 3.7305681705474854 | KNN Loss: 3.678255319595337 | CLS Loss: 0.05231286585330963\n",
      "Epoch: 020, Loss: 3.7151, Train: 0.9864, Valid: 0.9825, Best: 0.9825\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 3.7108397483825684 | KNN Loss: 3.6774327754974365 | CLS Loss: 0.03340704366564751\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 3.7050530910491943 | KNN Loss: 3.6645395755767822 | CLS Loss: 0.04051349684596062\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 3.6897177696228027 | KNN Loss: 3.6710405349731445 | CLS Loss: 0.018677324056625366\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 3.729417324066162 | KNN Loss: 3.6625163555145264 | CLS Loss: 0.0669010654091835\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 3.7115955352783203 | KNN Loss: 3.684401273727417 | CLS Loss: 0.027194300666451454\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 3.709259510040283 | KNN Loss: 3.664538860321045 | CLS Loss: 0.04472056031227112\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 3.7331161499023438 | KNN Loss: 3.675649642944336 | CLS Loss: 0.05746662616729736\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 3.732912302017212 | KNN Loss: 3.6930506229400635 | CLS Loss: 0.039861585944890976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 3.7312204837799072 | KNN Loss: 3.6779186725616455 | CLS Loss: 0.05330183357000351\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 3.702188730239868 | KNN Loss: 3.6583821773529053 | CLS Loss: 0.04380656033754349\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 3.6925582885742188 | KNN Loss: 3.6545724868774414 | CLS Loss: 0.03798582777380943\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 3.6783676147460938 | KNN Loss: 3.662086248397827 | CLS Loss: 0.016281459480524063\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 3.6803810596466064 | KNN Loss: 3.65169620513916 | CLS Loss: 0.028684748336672783\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 3.6873257160186768 | KNN Loss: 3.6547253131866455 | CLS Loss: 0.03260049968957901\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 3.706716775894165 | KNN Loss: 3.6632566452026367 | CLS Loss: 0.04346016049385071\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 3.7160792350769043 | KNN Loss: 3.6735153198242188 | CLS Loss: 0.04256397858262062\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 3.7136945724487305 | KNN Loss: 3.6426310539245605 | CLS Loss: 0.07106363028287888\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 3.749237060546875 | KNN Loss: 3.675341844558716 | CLS Loss: 0.07389520108699799\n",
      "Epoch: 021, Loss: 3.7095, Train: 0.9862, Valid: 0.9798, Best: 0.9825\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 3.705840826034546 | KNN Loss: 3.68166446685791 | CLS Loss: 0.024176450446248055\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 3.7284321784973145 | KNN Loss: 3.6709420680999756 | CLS Loss: 0.05749017745256424\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 3.698076009750366 | KNN Loss: 3.643394947052002 | CLS Loss: 0.054680995643138885\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 3.7329165935516357 | KNN Loss: 3.6715922355651855 | CLS Loss: 0.06132432073354721\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 3.7115933895111084 | KNN Loss: 3.6623268127441406 | CLS Loss: 0.04926664009690285\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 3.708348274230957 | KNN Loss: 3.6265554428100586 | CLS Loss: 0.08179280906915665\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 3.7122509479522705 | KNN Loss: 3.6602373123168945 | CLS Loss: 0.05201367288827896\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 3.7248241901397705 | KNN Loss: 3.6916041374206543 | CLS Loss: 0.03322000429034233\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 3.6707894802093506 | KNN Loss: 3.614696741104126 | CLS Loss: 0.056092776358127594\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 3.6882145404815674 | KNN Loss: 3.641789197921753 | CLS Loss: 0.04642530530691147\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 3.7498106956481934 | KNN Loss: 3.678300619125366 | CLS Loss: 0.07151003926992416\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 3.6874501705169678 | KNN Loss: 3.6620934009552 | CLS Loss: 0.025356831029057503\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 3.7030997276306152 | KNN Loss: 3.6386008262634277 | CLS Loss: 0.06449882686138153\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 3.717240333557129 | KNN Loss: 3.6536407470703125 | CLS Loss: 0.06359969824552536\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 3.6633145809173584 | KNN Loss: 3.6130123138427734 | CLS Loss: 0.050302207469940186\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 3.7023794651031494 | KNN Loss: 3.6401002407073975 | CLS Loss: 0.062279265373945236\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 3.686499834060669 | KNN Loss: 3.6441826820373535 | CLS Loss: 0.042317166924476624\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 3.669116735458374 | KNN Loss: 3.622692108154297 | CLS Loss: 0.04642457515001297\n",
      "Epoch: 022, Loss: 3.7083, Train: 0.9874, Valid: 0.9814, Best: 0.9825\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 3.6853251457214355 | KNN Loss: 3.644733190536499 | CLS Loss: 0.040592011064291\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 3.683692693710327 | KNN Loss: 3.629901885986328 | CLS Loss: 0.05379088222980499\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 3.705956220626831 | KNN Loss: 3.6519501209259033 | CLS Loss: 0.05400610715150833\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 3.7005717754364014 | KNN Loss: 3.6655795574188232 | CLS Loss: 0.03499210625886917\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 3.703956127166748 | KNN Loss: 3.6366496086120605 | CLS Loss: 0.06730649620294571\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 3.6731488704681396 | KNN Loss: 3.6183419227600098 | CLS Loss: 0.05480698123574257\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 3.681540012359619 | KNN Loss: 3.639491081237793 | CLS Loss: 0.04204905033111572\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 3.690103530883789 | KNN Loss: 3.6692938804626465 | CLS Loss: 0.020809661597013474\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 3.710745334625244 | KNN Loss: 3.669020175933838 | CLS Loss: 0.04172520339488983\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 3.6937732696533203 | KNN Loss: 3.6394920349121094 | CLS Loss: 0.054281312972307205\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 3.697791576385498 | KNN Loss: 3.6348767280578613 | CLS Loss: 0.06291496753692627\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 3.696138858795166 | KNN Loss: 3.655449390411377 | CLS Loss: 0.04068940132856369\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 3.7139763832092285 | KNN Loss: 3.672766923904419 | CLS Loss: 0.041209474205970764\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 3.6949856281280518 | KNN Loss: 3.6425979137420654 | CLS Loss: 0.052387744188308716\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 3.767073631286621 | KNN Loss: 3.6809651851654053 | CLS Loss: 0.0861085057258606\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 3.6731979846954346 | KNN Loss: 3.6421947479248047 | CLS Loss: 0.03100316785275936\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 3.704805850982666 | KNN Loss: 3.6512351036071777 | CLS Loss: 0.053570814430713654\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 3.718932867050171 | KNN Loss: 3.674408435821533 | CLS Loss: 0.044524457305669785\n",
      "Epoch: 023, Loss: 3.7071, Train: 0.9867, Valid: 0.9817, Best: 0.9825\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 3.7274816036224365 | KNN Loss: 3.660003185272217 | CLS Loss: 0.06747831404209137\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 3.7460436820983887 | KNN Loss: 3.7173492908477783 | CLS Loss: 0.028694337233901024\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 3.715363025665283 | KNN Loss: 3.656508445739746 | CLS Loss: 0.058854490518569946\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 3.6954305171966553 | KNN Loss: 3.6589503288269043 | CLS Loss: 0.03648018091917038\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 3.6654891967773438 | KNN Loss: 3.6296606063842773 | CLS Loss: 0.035828568041324615\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 3.6852774620056152 | KNN Loss: 3.6402029991149902 | CLS Loss: 0.04507436230778694\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 3.6654231548309326 | KNN Loss: 3.6230053901672363 | CLS Loss: 0.04241788014769554\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 3.6693127155303955 | KNN Loss: 3.6478958129882812 | CLS Loss: 0.021416915580630302\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 3.704869508743286 | KNN Loss: 3.679537773132324 | CLS Loss: 0.025331664830446243\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 3.697648763656616 | KNN Loss: 3.645341157913208 | CLS Loss: 0.05230768024921417\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 3.699781656265259 | KNN Loss: 3.6437015533447266 | CLS Loss: 0.05608015134930611\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 3.67287278175354 | KNN Loss: 3.6401240825653076 | CLS Loss: 0.03274868428707123\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 3.7188456058502197 | KNN Loss: 3.640313148498535 | CLS Loss: 0.07853254675865173\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 3.67413067817688 | KNN Loss: 3.65018630027771 | CLS Loss: 0.023944469168782234\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 3.671522378921509 | KNN Loss: 3.6319360733032227 | CLS Loss: 0.039586249738931656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 3.7082808017730713 | KNN Loss: 3.677102565765381 | CLS Loss: 0.031178202480077744\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 3.707207679748535 | KNN Loss: 3.6545321941375732 | CLS Loss: 0.052675433456897736\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 3.671010971069336 | KNN Loss: 3.603168249130249 | CLS Loss: 0.06784262508153915\n",
      "Epoch: 024, Loss: 3.6938, Train: 0.9883, Valid: 0.9824, Best: 0.9825\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 3.677830696105957 | KNN Loss: 3.6054742336273193 | CLS Loss: 0.07235658168792725\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 3.7444167137145996 | KNN Loss: 3.69122576713562 | CLS Loss: 0.053190965205430984\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 3.7102222442626953 | KNN Loss: 3.6525917053222656 | CLS Loss: 0.05763062834739685\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 3.710568428039551 | KNN Loss: 3.6350183486938477 | CLS Loss: 0.07554997503757477\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 3.6939382553100586 | KNN Loss: 3.6426119804382324 | CLS Loss: 0.051326192915439606\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 3.713290214538574 | KNN Loss: 3.628450870513916 | CLS Loss: 0.08483928442001343\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 3.691793203353882 | KNN Loss: 3.6450588703155518 | CLS Loss: 0.046734217554330826\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 3.7092831134796143 | KNN Loss: 3.6753785610198975 | CLS Loss: 0.03390466421842575\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 3.7284626960754395 | KNN Loss: 3.687540054321289 | CLS Loss: 0.04092268645763397\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 3.710345506668091 | KNN Loss: 3.6750333309173584 | CLS Loss: 0.035312265157699585\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 3.7199740409851074 | KNN Loss: 3.6875181198120117 | CLS Loss: 0.032455924898386\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 3.674095630645752 | KNN Loss: 3.6385457515716553 | CLS Loss: 0.035549793392419815\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 3.7143688201904297 | KNN Loss: 3.6676034927368164 | CLS Loss: 0.04676525667309761\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 3.6831648349761963 | KNN Loss: 3.666987419128418 | CLS Loss: 0.01617739163339138\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 3.6886491775512695 | KNN Loss: 3.6596829891204834 | CLS Loss: 0.02896609529852867\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 3.7073171138763428 | KNN Loss: 3.649535655975342 | CLS Loss: 0.057781368494033813\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 3.6960508823394775 | KNN Loss: 3.6607325077056885 | CLS Loss: 0.03531837835907936\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 3.7162370681762695 | KNN Loss: 3.673924446105957 | CLS Loss: 0.04231259599328041\n",
      "Epoch: 025, Loss: 3.7076, Train: 0.9887, Valid: 0.9829, Best: 0.9829\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 3.7335691452026367 | KNN Loss: 3.7017011642456055 | CLS Loss: 0.03186805173754692\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 3.7223618030548096 | KNN Loss: 3.683091640472412 | CLS Loss: 0.039270125329494476\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 3.707982063293457 | KNN Loss: 3.686037063598633 | CLS Loss: 0.021945029497146606\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 3.6700470447540283 | KNN Loss: 3.638314962387085 | CLS Loss: 0.03173217922449112\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 3.681307554244995 | KNN Loss: 3.640745162963867 | CLS Loss: 0.040562357753515244\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 3.680729389190674 | KNN Loss: 3.65708589553833 | CLS Loss: 0.0236436128616333\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 3.6678693294525146 | KNN Loss: 3.650244951248169 | CLS Loss: 0.017624471336603165\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 3.677060604095459 | KNN Loss: 3.644535779953003 | CLS Loss: 0.03252487629652023\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 3.6831092834472656 | KNN Loss: 3.651898145675659 | CLS Loss: 0.03121115453541279\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 3.7103404998779297 | KNN Loss: 3.650070905685425 | CLS Loss: 0.060269564390182495\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 3.682232141494751 | KNN Loss: 3.6484408378601074 | CLS Loss: 0.03379138931632042\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 3.725888967514038 | KNN Loss: 3.672253370285034 | CLS Loss: 0.05363570526242256\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 3.6882853507995605 | KNN Loss: 3.6589629650115967 | CLS Loss: 0.029322266578674316\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 3.697676658630371 | KNN Loss: 3.6776347160339355 | CLS Loss: 0.020041903480887413\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 3.667480230331421 | KNN Loss: 3.6324386596679688 | CLS Loss: 0.03504159674048424\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 3.7173168659210205 | KNN Loss: 3.6417717933654785 | CLS Loss: 0.0755450576543808\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 3.7173380851745605 | KNN Loss: 3.6789915561676025 | CLS Loss: 0.038346629589796066\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 3.7173244953155518 | KNN Loss: 3.6429896354675293 | CLS Loss: 0.07433497160673141\n",
      "Epoch: 026, Loss: 3.7049, Train: 0.9897, Valid: 0.9843, Best: 0.9843\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 3.7023251056671143 | KNN Loss: 3.6742429733276367 | CLS Loss: 0.028082245960831642\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 3.682131052017212 | KNN Loss: 3.617440938949585 | CLS Loss: 0.06469003111124039\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 3.7223877906799316 | KNN Loss: 3.6654701232910156 | CLS Loss: 0.056917548179626465\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 3.6847102642059326 | KNN Loss: 3.6478171348571777 | CLS Loss: 0.0368930846452713\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 3.6847658157348633 | KNN Loss: 3.6481380462646484 | CLS Loss: 0.03662781044840813\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 3.653724431991577 | KNN Loss: 3.624138832092285 | CLS Loss: 0.029585497453808784\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 3.6674587726593018 | KNN Loss: 3.643437147140503 | CLS Loss: 0.024021698161959648\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 3.7220585346221924 | KNN Loss: 3.667053461074829 | CLS Loss: 0.05500506982207298\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 3.7163639068603516 | KNN Loss: 3.6577653884887695 | CLS Loss: 0.058598414063453674\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 3.6665878295898438 | KNN Loss: 3.6207435131073 | CLS Loss: 0.04584428668022156\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 3.7178328037261963 | KNN Loss: 3.669081449508667 | CLS Loss: 0.048751380294561386\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 3.720729351043701 | KNN Loss: 3.682589292526245 | CLS Loss: 0.03813999891281128\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 3.679919958114624 | KNN Loss: 3.635558605194092 | CLS Loss: 0.04436124488711357\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 3.673067569732666 | KNN Loss: 3.647386074066162 | CLS Loss: 0.025681566447019577\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 3.685037851333618 | KNN Loss: 3.6374573707580566 | CLS Loss: 0.04758041724562645\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 3.702698230743408 | KNN Loss: 3.655991315841675 | CLS Loss: 0.046706896275281906\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 3.703994035720825 | KNN Loss: 3.669121026992798 | CLS Loss: 0.03487289696931839\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 3.690343141555786 | KNN Loss: 3.660285711288452 | CLS Loss: 0.030057400465011597\n",
      "Epoch: 027, Loss: 3.6913, Train: 0.9884, Valid: 0.9820, Best: 0.9843\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 3.674818277359009 | KNN Loss: 3.652454137802124 | CLS Loss: 0.02236422710120678\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 3.654291868209839 | KNN Loss: 3.6294426918029785 | CLS Loss: 0.02484908699989319\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 3.723245859146118 | KNN Loss: 3.6726622581481934 | CLS Loss: 0.050583615899086\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 3.662684679031372 | KNN Loss: 3.6264877319335938 | CLS Loss: 0.03619693964719772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 3.6742031574249268 | KNN Loss: 3.65909743309021 | CLS Loss: 0.015105719678103924\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 3.69950008392334 | KNN Loss: 3.6642954349517822 | CLS Loss: 0.03520473465323448\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 3.681307077407837 | KNN Loss: 3.657381534576416 | CLS Loss: 0.023925427347421646\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 3.6771240234375 | KNN Loss: 3.6539933681488037 | CLS Loss: 0.023130672052502632\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 3.686328411102295 | KNN Loss: 3.6419615745544434 | CLS Loss: 0.04436672478914261\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 3.6734156608581543 | KNN Loss: 3.6384098529815674 | CLS Loss: 0.03500586748123169\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 3.6955769062042236 | KNN Loss: 3.6351115703582764 | CLS Loss: 0.06046542152762413\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 3.6680774688720703 | KNN Loss: 3.6322779655456543 | CLS Loss: 0.0357995443046093\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 3.6844942569732666 | KNN Loss: 3.6596150398254395 | CLS Loss: 0.024879300966858864\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 3.6590888500213623 | KNN Loss: 3.632610559463501 | CLS Loss: 0.026478227227926254\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 3.7054836750030518 | KNN Loss: 3.645824432373047 | CLS Loss: 0.05965922027826309\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 3.7092299461364746 | KNN Loss: 3.6505472660064697 | CLS Loss: 0.05868279188871384\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 3.776360034942627 | KNN Loss: 3.72802734375 | CLS Loss: 0.048332735896110535\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 3.744717836380005 | KNN Loss: 3.7023465633392334 | CLS Loss: 0.04237125813961029\n",
      "Epoch: 028, Loss: 3.6874, Train: 0.9895, Valid: 0.9842, Best: 0.9843\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 3.721238374710083 | KNN Loss: 3.6920390129089355 | CLS Loss: 0.02919924631714821\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 3.727499485015869 | KNN Loss: 3.685933828353882 | CLS Loss: 0.04156576097011566\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 3.6546151638031006 | KNN Loss: 3.627020835876465 | CLS Loss: 0.027594441547989845\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 3.6723055839538574 | KNN Loss: 3.6476635932922363 | CLS Loss: 0.024642040953040123\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 3.6832613945007324 | KNN Loss: 3.6339914798736572 | CLS Loss: 0.049269989132881165\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 3.696058511734009 | KNN Loss: 3.670766830444336 | CLS Loss: 0.02529176138341427\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 3.706451416015625 | KNN Loss: 3.6555824279785156 | CLS Loss: 0.05086900666356087\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 3.7192444801330566 | KNN Loss: 3.7003486156463623 | CLS Loss: 0.018895747140049934\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 3.725513219833374 | KNN Loss: 3.6727969646453857 | CLS Loss: 0.052716296166181564\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 3.7052276134490967 | KNN Loss: 3.6631271839141846 | CLS Loss: 0.042100466787815094\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 3.667151927947998 | KNN Loss: 3.631357192993164 | CLS Loss: 0.03579484298825264\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 3.715359926223755 | KNN Loss: 3.6941189765930176 | CLS Loss: 0.0212408360093832\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 3.7326109409332275 | KNN Loss: 3.6628949642181396 | CLS Loss: 0.06971589475870132\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 3.701580286026001 | KNN Loss: 3.6391561031341553 | CLS Loss: 0.06242416426539421\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 3.6733765602111816 | KNN Loss: 3.6547672748565674 | CLS Loss: 0.018609292805194855\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 3.683030128479004 | KNN Loss: 3.6531200408935547 | CLS Loss: 0.029910018667578697\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 3.699000120162964 | KNN Loss: 3.665876865386963 | CLS Loss: 0.0331232063472271\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 3.6890761852264404 | KNN Loss: 3.6533877849578857 | CLS Loss: 0.03568835183978081\n",
      "Epoch: 029, Loss: 3.6951, Train: 0.9900, Valid: 0.9846, Best: 0.9846\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 3.6570069789886475 | KNN Loss: 3.63539719581604 | CLS Loss: 0.021609829738736153\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 3.664717435836792 | KNN Loss: 3.620455503463745 | CLS Loss: 0.044261857867240906\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 3.6779510974884033 | KNN Loss: 3.6193978786468506 | CLS Loss: 0.05855325981974602\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 3.71451735496521 | KNN Loss: 3.681041717529297 | CLS Loss: 0.033475544303655624\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 3.6685006618499756 | KNN Loss: 3.6484715938568115 | CLS Loss: 0.02002895623445511\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 3.7136244773864746 | KNN Loss: 3.6581716537475586 | CLS Loss: 0.05545283108949661\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 3.6625759601593018 | KNN Loss: 3.609098196029663 | CLS Loss: 0.053477801382541656\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 3.725904941558838 | KNN Loss: 3.6555118560791016 | CLS Loss: 0.07039299607276917\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 3.6947598457336426 | KNN Loss: 3.6540331840515137 | CLS Loss: 0.040726568549871445\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 3.6738064289093018 | KNN Loss: 3.6304872035980225 | CLS Loss: 0.04331919550895691\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 3.7232303619384766 | KNN Loss: 3.683807849884033 | CLS Loss: 0.03942245617508888\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 3.6860158443450928 | KNN Loss: 3.6754848957061768 | CLS Loss: 0.010531000792980194\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 3.7066025733947754 | KNN Loss: 3.647860288619995 | CLS Loss: 0.05874226987361908\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 3.728820323944092 | KNN Loss: 3.6746268272399902 | CLS Loss: 0.05419342219829559\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 3.708301544189453 | KNN Loss: 3.637192487716675 | CLS Loss: 0.07110904902219772\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 3.68133807182312 | KNN Loss: 3.660093307495117 | CLS Loss: 0.021244827657938004\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 3.6646642684936523 | KNN Loss: 3.624760389328003 | CLS Loss: 0.039903875440359116\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 3.706157922744751 | KNN Loss: 3.6656923294067383 | CLS Loss: 0.040465500205755234\n",
      "Epoch: 030, Loss: 3.6865, Train: 0.9906, Valid: 0.9848, Best: 0.9848\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 3.686164140701294 | KNN Loss: 3.6356375217437744 | CLS Loss: 0.05052664503455162\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 3.668964385986328 | KNN Loss: 3.623119592666626 | CLS Loss: 0.0458449125289917\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 3.6754369735717773 | KNN Loss: 3.6388778686523438 | CLS Loss: 0.036559201776981354\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 3.697350263595581 | KNN Loss: 3.6600778102874756 | CLS Loss: 0.037272438406944275\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 3.6992063522338867 | KNN Loss: 3.671381950378418 | CLS Loss: 0.02782438136637211\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 3.6825437545776367 | KNN Loss: 3.6494927406311035 | CLS Loss: 0.03305096551775932\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 3.683032989501953 | KNN Loss: 3.6443700790405273 | CLS Loss: 0.03866288810968399\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 3.669630289077759 | KNN Loss: 3.6623218059539795 | CLS Loss: 0.007308584172278643\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 3.6570141315460205 | KNN Loss: 3.6421310901641846 | CLS Loss: 0.014883014373481274\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 3.65952467918396 | KNN Loss: 3.639063835144043 | CLS Loss: 0.02046078070998192\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 3.6890058517456055 | KNN Loss: 3.654855728149414 | CLS Loss: 0.0341501384973526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 3.6898162364959717 | KNN Loss: 3.653327226638794 | CLS Loss: 0.036488939076662064\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 3.675814390182495 | KNN Loss: 3.630084753036499 | CLS Loss: 0.04572966694831848\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 3.6825597286224365 | KNN Loss: 3.6712446212768555 | CLS Loss: 0.011315049603581429\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 3.6810450553894043 | KNN Loss: 3.6249330043792725 | CLS Loss: 0.05611199885606766\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 3.6789464950561523 | KNN Loss: 3.654362201690674 | CLS Loss: 0.024584298953413963\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 3.716630697250366 | KNN Loss: 3.671271324157715 | CLS Loss: 0.04535936191678047\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 3.671799421310425 | KNN Loss: 3.6574580669403076 | CLS Loss: 0.014341408386826515\n",
      "Epoch: 031, Loss: 3.6868, Train: 0.9889, Valid: 0.9824, Best: 0.9848\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 3.698024034500122 | KNN Loss: 3.6568520069122314 | CLS Loss: 0.041172053664922714\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 3.6503779888153076 | KNN Loss: 3.5962328910827637 | CLS Loss: 0.05414508655667305\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 3.693521738052368 | KNN Loss: 3.6322715282440186 | CLS Loss: 0.06125020608305931\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 3.6900997161865234 | KNN Loss: 3.6395537853240967 | CLS Loss: 0.05054585263133049\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 3.683269500732422 | KNN Loss: 3.639530658721924 | CLS Loss: 0.043738920241594315\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 3.659709930419922 | KNN Loss: 3.635843276977539 | CLS Loss: 0.023866761475801468\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 3.7003118991851807 | KNN Loss: 3.6408815383911133 | CLS Loss: 0.0594303160905838\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 3.6739559173583984 | KNN Loss: 3.661208152770996 | CLS Loss: 0.012747876346111298\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 3.707098960876465 | KNN Loss: 3.662503242492676 | CLS Loss: 0.04459565877914429\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 3.7248713970184326 | KNN Loss: 3.6606056690216064 | CLS Loss: 0.06426568329334259\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 3.7134292125701904 | KNN Loss: 3.68416166305542 | CLS Loss: 0.0292674507945776\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 3.6844868659973145 | KNN Loss: 3.6314313411712646 | CLS Loss: 0.05305543914437294\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 3.6958627700805664 | KNN Loss: 3.651779890060425 | CLS Loss: 0.04408290982246399\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 3.696948528289795 | KNN Loss: 3.660297393798828 | CLS Loss: 0.036651212722063065\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 3.690948963165283 | KNN Loss: 3.650141954421997 | CLS Loss: 0.04080699756741524\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 3.6761527061462402 | KNN Loss: 3.6497485637664795 | CLS Loss: 0.026404084637761116\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 3.6934516429901123 | KNN Loss: 3.655247449874878 | CLS Loss: 0.03820430114865303\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 3.688746213912964 | KNN Loss: 3.656721353530884 | CLS Loss: 0.032024823129177094\n",
      "Epoch: 032, Loss: 3.6847, Train: 0.9913, Valid: 0.9841, Best: 0.9848\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 3.612755298614502 | KNN Loss: 3.571171760559082 | CLS Loss: 0.041583526879549026\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 3.7720389366149902 | KNN Loss: 3.7012112140655518 | CLS Loss: 0.07082770019769669\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 3.7184252738952637 | KNN Loss: 3.655186176300049 | CLS Loss: 0.06323908269405365\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 3.641110897064209 | KNN Loss: 3.606093645095825 | CLS Loss: 0.03501724451780319\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 3.669907331466675 | KNN Loss: 3.6388511657714844 | CLS Loss: 0.031056083738803864\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 3.647092819213867 | KNN Loss: 3.6309049129486084 | CLS Loss: 0.016187962144613266\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 3.6763827800750732 | KNN Loss: 3.6354873180389404 | CLS Loss: 0.04089541360735893\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 3.7022624015808105 | KNN Loss: 3.6606335639953613 | CLS Loss: 0.04162892699241638\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 3.671987533569336 | KNN Loss: 3.6200690269470215 | CLS Loss: 0.05191858112812042\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 3.6577565670013428 | KNN Loss: 3.6440317630767822 | CLS Loss: 0.013724790886044502\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 3.6815128326416016 | KNN Loss: 3.648796558380127 | CLS Loss: 0.032716311514377594\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 3.6731152534484863 | KNN Loss: 3.6009716987609863 | CLS Loss: 0.07214353233575821\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 3.703195095062256 | KNN Loss: 3.649670124053955 | CLS Loss: 0.053524889051914215\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 3.667717456817627 | KNN Loss: 3.6467790603637695 | CLS Loss: 0.020938392728567123\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 3.671123504638672 | KNN Loss: 3.6524441242218018 | CLS Loss: 0.018679417669773102\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 3.707930326461792 | KNN Loss: 3.6913909912109375 | CLS Loss: 0.016539230942726135\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 3.6924569606781006 | KNN Loss: 3.673766851425171 | CLS Loss: 0.018690062686800957\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 3.651942253112793 | KNN Loss: 3.624579906463623 | CLS Loss: 0.027362260967493057\n",
      "Epoch: 033, Loss: 3.6813, Train: 0.9909, Valid: 0.9852, Best: 0.9852\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 3.693875789642334 | KNN Loss: 3.652225971221924 | CLS Loss: 0.041649702936410904\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 3.6824028491973877 | KNN Loss: 3.638213872909546 | CLS Loss: 0.04418903589248657\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 3.68034029006958 | KNN Loss: 3.6196727752685547 | CLS Loss: 0.060667525976896286\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 3.6414260864257812 | KNN Loss: 3.590178966522217 | CLS Loss: 0.0512470118701458\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 3.6676366329193115 | KNN Loss: 3.635686159133911 | CLS Loss: 0.03195037692785263\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 3.6383371353149414 | KNN Loss: 3.6211812496185303 | CLS Loss: 0.017155898734927177\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 3.6890361309051514 | KNN Loss: 3.6511552333831787 | CLS Loss: 0.037880945950746536\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 3.615786552429199 | KNN Loss: 3.5803327560424805 | CLS Loss: 0.03545380383729935\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 3.7116663455963135 | KNN Loss: 3.678781747817993 | CLS Loss: 0.032884664833545685\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 3.6454501152038574 | KNN Loss: 3.6268022060394287 | CLS Loss: 0.018647825345396996\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 3.6972196102142334 | KNN Loss: 3.646878719329834 | CLS Loss: 0.050340909510850906\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 3.673767328262329 | KNN Loss: 3.653546094894409 | CLS Loss: 0.02022123523056507\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 3.6820614337921143 | KNN Loss: 3.6560444831848145 | CLS Loss: 0.026016995310783386\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 3.647830009460449 | KNN Loss: 3.6231534481048584 | CLS Loss: 0.024676615372300148\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 3.676128625869751 | KNN Loss: 3.6375696659088135 | CLS Loss: 0.03855886682868004\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 3.649625778198242 | KNN Loss: 3.6214711666107178 | CLS Loss: 0.028154660016298294\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 3.674015760421753 | KNN Loss: 3.6329171657562256 | CLS Loss: 0.04109859839081764\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 3.6833884716033936 | KNN Loss: 3.658891201019287 | CLS Loss: 0.024497345089912415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 3.6727, Train: 0.9908, Valid: 0.9837, Best: 0.9852\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 3.66903018951416 | KNN Loss: 3.6490793228149414 | CLS Loss: 0.019950777292251587\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 3.7062532901763916 | KNN Loss: 3.665992259979248 | CLS Loss: 0.040260955691337585\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 3.638197183609009 | KNN Loss: 3.615208625793457 | CLS Loss: 0.02298852987587452\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 3.691382646560669 | KNN Loss: 3.6681060791015625 | CLS Loss: 0.023276664316654205\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 3.6589534282684326 | KNN Loss: 3.6350064277648926 | CLS Loss: 0.023947114124894142\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 3.6544852256774902 | KNN Loss: 3.5937671661376953 | CLS Loss: 0.06071798503398895\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 3.687897205352783 | KNN Loss: 3.6643226146698 | CLS Loss: 0.023574480786919594\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 3.677678108215332 | KNN Loss: 3.6305747032165527 | CLS Loss: 0.04710344225168228\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 3.6375012397766113 | KNN Loss: 3.6202120780944824 | CLS Loss: 0.0172891728579998\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 3.6960463523864746 | KNN Loss: 3.6446259021759033 | CLS Loss: 0.05142049118876457\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 3.6553502082824707 | KNN Loss: 3.612736463546753 | CLS Loss: 0.042613666504621506\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 3.6711652278900146 | KNN Loss: 3.631002902984619 | CLS Loss: 0.040162283927202225\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 3.655890941619873 | KNN Loss: 3.618587017059326 | CLS Loss: 0.03730399161577225\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 3.64198899269104 | KNN Loss: 3.593872547149658 | CLS Loss: 0.048116493970155716\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 3.6250739097595215 | KNN Loss: 3.604647636413574 | CLS Loss: 0.02042638696730137\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 3.6588313579559326 | KNN Loss: 3.636953115463257 | CLS Loss: 0.0218781940639019\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 3.6874656677246094 | KNN Loss: 3.653158664703369 | CLS Loss: 0.034307122230529785\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 3.634138584136963 | KNN Loss: 3.6116063594818115 | CLS Loss: 0.02253216691315174\n",
      "Epoch: 035, Loss: 3.6691, Train: 0.9921, Valid: 0.9851, Best: 0.9852\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 3.6703855991363525 | KNN Loss: 3.6335995197296143 | CLS Loss: 0.036786116659641266\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 3.6769590377807617 | KNN Loss: 3.657747268676758 | CLS Loss: 0.01921185292303562\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 3.6535677909851074 | KNN Loss: 3.6282777786254883 | CLS Loss: 0.025289997458457947\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 3.683525562286377 | KNN Loss: 3.6323091983795166 | CLS Loss: 0.05121640861034393\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 3.663479804992676 | KNN Loss: 3.62957763671875 | CLS Loss: 0.03390206769108772\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 3.665255308151245 | KNN Loss: 3.6346335411071777 | CLS Loss: 0.030621839687228203\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 3.6790926456451416 | KNN Loss: 3.66737961769104 | CLS Loss: 0.01171307172626257\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 3.6479532718658447 | KNN Loss: 3.636425256729126 | CLS Loss: 0.011527908965945244\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 3.6908717155456543 | KNN Loss: 3.654841661453247 | CLS Loss: 0.036029934883117676\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 3.6660401821136475 | KNN Loss: 3.6411736011505127 | CLS Loss: 0.024866659194231033\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 3.652223587036133 | KNN Loss: 3.6230998039245605 | CLS Loss: 0.029123814776539803\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 3.6848599910736084 | KNN Loss: 3.6348485946655273 | CLS Loss: 0.050011374056339264\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 3.6632587909698486 | KNN Loss: 3.645503282546997 | CLS Loss: 0.017755446955561638\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 3.6741645336151123 | KNN Loss: 3.6357247829437256 | CLS Loss: 0.03843975067138672\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 3.6900105476379395 | KNN Loss: 3.6425247192382812 | CLS Loss: 0.0474858283996582\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 3.692847967147827 | KNN Loss: 3.652815580368042 | CLS Loss: 0.04003240913152695\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 3.679119825363159 | KNN Loss: 3.6365087032318115 | CLS Loss: 0.04261117801070213\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 3.6631367206573486 | KNN Loss: 3.6251158714294434 | CLS Loss: 0.038020938634872437\n",
      "Epoch: 036, Loss: 3.6700, Train: 0.9917, Valid: 0.9850, Best: 0.9852\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 3.653069496154785 | KNN Loss: 3.6294546127319336 | CLS Loss: 0.02361493557691574\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 3.640260934829712 | KNN Loss: 3.6201910972595215 | CLS Loss: 0.020069781690835953\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 3.654592275619507 | KNN Loss: 3.6297755241394043 | CLS Loss: 0.024816760793328285\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 3.6574442386627197 | KNN Loss: 3.6137518882751465 | CLS Loss: 0.043692246079444885\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 3.6860194206237793 | KNN Loss: 3.6461641788482666 | CLS Loss: 0.039855122566223145\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 3.6862995624542236 | KNN Loss: 3.6459689140319824 | CLS Loss: 0.040330544114112854\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 3.7147834300994873 | KNN Loss: 3.666534423828125 | CLS Loss: 0.04824891313910484\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 3.6804938316345215 | KNN Loss: 3.667003631591797 | CLS Loss: 0.013490164652466774\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 3.6411173343658447 | KNN Loss: 3.624695301055908 | CLS Loss: 0.016422150656580925\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 3.654021739959717 | KNN Loss: 3.625627040863037 | CLS Loss: 0.02839464507997036\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 3.7223100662231445 | KNN Loss: 3.682941436767578 | CLS Loss: 0.03936856985092163\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 3.670445203781128 | KNN Loss: 3.627736806869507 | CLS Loss: 0.04270845651626587\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 3.667043447494507 | KNN Loss: 3.642608642578125 | CLS Loss: 0.024434834718704224\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 3.7072410583496094 | KNN Loss: 3.6220593452453613 | CLS Loss: 0.08518163859844208\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 3.676581621170044 | KNN Loss: 3.642317295074463 | CLS Loss: 0.0342642143368721\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 3.6467020511627197 | KNN Loss: 3.6175310611724854 | CLS Loss: 0.029170958325266838\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 3.678483009338379 | KNN Loss: 3.6304585933685303 | CLS Loss: 0.04802441596984863\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 3.668651819229126 | KNN Loss: 3.6358466148376465 | CLS Loss: 0.03280526399612427\n",
      "Epoch: 037, Loss: 3.6756, Train: 0.9910, Valid: 0.9847, Best: 0.9852\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 3.695080280303955 | KNN Loss: 3.623749017715454 | CLS Loss: 0.07133127003908157\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 3.7143585681915283 | KNN Loss: 3.694397211074829 | CLS Loss: 0.019961275160312653\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 3.647484540939331 | KNN Loss: 3.600710868835449 | CLS Loss: 0.04677361622452736\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 3.6575376987457275 | KNN Loss: 3.6327574253082275 | CLS Loss: 0.02478034980595112\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 3.66607666015625 | KNN Loss: 3.6364543437957764 | CLS Loss: 0.029622364789247513\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 3.6951053142547607 | KNN Loss: 3.6596455574035645 | CLS Loss: 0.0354597270488739\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 3.670121669769287 | KNN Loss: 3.6233069896698 | CLS Loss: 0.04681474715471268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 3.6436147689819336 | KNN Loss: 3.6138155460357666 | CLS Loss: 0.02979922853410244\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 3.683253288269043 | KNN Loss: 3.6731791496276855 | CLS Loss: 0.010074188932776451\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 3.6697933673858643 | KNN Loss: 3.6583645343780518 | CLS Loss: 0.011428726837038994\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 3.6550073623657227 | KNN Loss: 3.6068708896636963 | CLS Loss: 0.04813650622963905\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 3.681947708129883 | KNN Loss: 3.653435468673706 | CLS Loss: 0.028512325137853622\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 3.7096524238586426 | KNN Loss: 3.6866910457611084 | CLS Loss: 0.022961309179663658\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 3.6898062229156494 | KNN Loss: 3.6535158157348633 | CLS Loss: 0.03629042208194733\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 3.657222032546997 | KNN Loss: 3.6350347995758057 | CLS Loss: 0.022187137976288795\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 3.7094309329986572 | KNN Loss: 3.655243396759033 | CLS Loss: 0.05418752506375313\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 3.707918643951416 | KNN Loss: 3.6686418056488037 | CLS Loss: 0.039276789873838425\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 3.6706295013427734 | KNN Loss: 3.621886968612671 | CLS Loss: 0.048742521554231644\n",
      "Epoch: 038, Loss: 3.6787, Train: 0.9904, Valid: 0.9836, Best: 0.9852\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 3.6912808418273926 | KNN Loss: 3.640744209289551 | CLS Loss: 0.05053653195500374\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 3.6273012161254883 | KNN Loss: 3.5987703800201416 | CLS Loss: 0.028530720621347427\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 3.667647123336792 | KNN Loss: 3.652916669845581 | CLS Loss: 0.014730395749211311\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 3.6792478561401367 | KNN Loss: 3.6524691581726074 | CLS Loss: 0.0267788115888834\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 3.6804773807525635 | KNN Loss: 3.6557369232177734 | CLS Loss: 0.024740511551499367\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 3.684351921081543 | KNN Loss: 3.654921531677246 | CLS Loss: 0.029430506750941277\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 3.6948792934417725 | KNN Loss: 3.6501545906066895 | CLS Loss: 0.04472481086850166\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 3.68778395652771 | KNN Loss: 3.630155086517334 | CLS Loss: 0.057628847658634186\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 3.6635618209838867 | KNN Loss: 3.6519930362701416 | CLS Loss: 0.011568775400519371\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 3.698857307434082 | KNN Loss: 3.6476025581359863 | CLS Loss: 0.05125473067164421\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 3.6501293182373047 | KNN Loss: 3.6345510482788086 | CLS Loss: 0.01557836215943098\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 3.663771152496338 | KNN Loss: 3.6300365924835205 | CLS Loss: 0.0337345227599144\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 3.679478645324707 | KNN Loss: 3.632910966873169 | CLS Loss: 0.04656773433089256\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 3.711331367492676 | KNN Loss: 3.6775901317596436 | CLS Loss: 0.0337413027882576\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 3.675917863845825 | KNN Loss: 3.642455816268921 | CLS Loss: 0.033462125808000565\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 3.6641647815704346 | KNN Loss: 3.6376936435699463 | CLS Loss: 0.026471180841326714\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 3.6907150745391846 | KNN Loss: 3.655076503753662 | CLS Loss: 0.035638678818941116\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 3.7120580673217773 | KNN Loss: 3.6712613105773926 | CLS Loss: 0.0407966673374176\n",
      "Epoch: 039, Loss: 3.6774, Train: 0.9906, Valid: 0.9846, Best: 0.9852\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 3.704897403717041 | KNN Loss: 3.6810946464538574 | CLS Loss: 0.023802869021892548\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 3.659588098526001 | KNN Loss: 3.635241746902466 | CLS Loss: 0.024346334859728813\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 3.7508127689361572 | KNN Loss: 3.7243504524230957 | CLS Loss: 0.026462381705641747\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 3.642317295074463 | KNN Loss: 3.6303842067718506 | CLS Loss: 0.01193314604461193\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 3.6902222633361816 | KNN Loss: 3.6517434120178223 | CLS Loss: 0.038478948175907135\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 3.678346872329712 | KNN Loss: 3.6228067874908447 | CLS Loss: 0.05553997680544853\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 3.6546082496643066 | KNN Loss: 3.6265196800231934 | CLS Loss: 0.028088657185435295\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 3.694856643676758 | KNN Loss: 3.662102222442627 | CLS Loss: 0.03275449201464653\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 3.6839957237243652 | KNN Loss: 3.64119029045105 | CLS Loss: 0.04280540347099304\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 3.693603515625 | KNN Loss: 3.6631557941436768 | CLS Loss: 0.030447758734226227\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 3.6564998626708984 | KNN Loss: 3.6077499389648438 | CLS Loss: 0.048749830573797226\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 3.712510585784912 | KNN Loss: 3.684645414352417 | CLS Loss: 0.027865247800946236\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 3.651336669921875 | KNN Loss: 3.6184165477752686 | CLS Loss: 0.03292018175125122\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 3.6542937755584717 | KNN Loss: 3.636172294616699 | CLS Loss: 0.018121495842933655\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 3.691763162612915 | KNN Loss: 3.653106927871704 | CLS Loss: 0.03865629434585571\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 3.641003131866455 | KNN Loss: 3.608633518218994 | CLS Loss: 0.032369595021009445\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 3.6967434883117676 | KNN Loss: 3.66151762008667 | CLS Loss: 0.03522598370909691\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 3.661044120788574 | KNN Loss: 3.6455204486846924 | CLS Loss: 0.015523784793913364\n",
      "Epoch: 040, Loss: 3.6763, Train: 0.9917, Valid: 0.9848, Best: 0.9852\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 3.644923210144043 | KNN Loss: 3.630316734313965 | CLS Loss: 0.01460641622543335\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 3.646512985229492 | KNN Loss: 3.6306543350219727 | CLS Loss: 0.01585855521261692\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 3.6648194789886475 | KNN Loss: 3.6026458740234375 | CLS Loss: 0.06217356398701668\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 3.6327922344207764 | KNN Loss: 3.6100175380706787 | CLS Loss: 0.02277478761970997\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 3.6483161449432373 | KNN Loss: 3.614339590072632 | CLS Loss: 0.03397653251886368\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 3.670694351196289 | KNN Loss: 3.630249500274658 | CLS Loss: 0.04044486582279205\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 3.6703832149505615 | KNN Loss: 3.6576411724090576 | CLS Loss: 0.012742068618535995\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 3.6324338912963867 | KNN Loss: 3.608837604522705 | CLS Loss: 0.023596247658133507\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 3.652775764465332 | KNN Loss: 3.629561185836792 | CLS Loss: 0.023214463144540787\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 3.6720452308654785 | KNN Loss: 3.6455466747283936 | CLS Loss: 0.02649848908185959\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 3.661311626434326 | KNN Loss: 3.6235947608947754 | CLS Loss: 0.03771693632006645\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 3.6351025104522705 | KNN Loss: 3.6092047691345215 | CLS Loss: 0.025897735729813576\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 3.6794025897979736 | KNN Loss: 3.6627957820892334 | CLS Loss: 0.01660679653286934\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 3.6661407947540283 | KNN Loss: 3.630807399749756 | CLS Loss: 0.03533337265253067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 3.675118923187256 | KNN Loss: 3.6515920162200928 | CLS Loss: 0.02352684922516346\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 3.710148572921753 | KNN Loss: 3.6831130981445312 | CLS Loss: 0.02703559212386608\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 3.6759989261627197 | KNN Loss: 3.629619598388672 | CLS Loss: 0.04637935757637024\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 3.6849188804626465 | KNN Loss: 3.6351089477539062 | CLS Loss: 0.04980981722474098\n",
      "Epoch: 041, Loss: 3.6709, Train: 0.9924, Valid: 0.9857, Best: 0.9857\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 3.695998191833496 | KNN Loss: 3.6695501804351807 | CLS Loss: 0.026448095217347145\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 3.6669323444366455 | KNN Loss: 3.6379847526550293 | CLS Loss: 0.02894764393568039\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 3.6435353755950928 | KNN Loss: 3.616520404815674 | CLS Loss: 0.027014879509806633\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 3.6649012565612793 | KNN Loss: 3.6323859691619873 | CLS Loss: 0.03251522034406662\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 3.699317455291748 | KNN Loss: 3.6573994159698486 | CLS Loss: 0.0419180653989315\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 3.65944766998291 | KNN Loss: 3.642824411392212 | CLS Loss: 0.016623346135020256\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 3.670827627182007 | KNN Loss: 3.6253228187561035 | CLS Loss: 0.04550490528345108\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 3.716832399368286 | KNN Loss: 3.6893391609191895 | CLS Loss: 0.027493204921483994\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 3.7099812030792236 | KNN Loss: 3.6454269886016846 | CLS Loss: 0.06455422192811966\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 3.6847336292266846 | KNN Loss: 3.643150806427002 | CLS Loss: 0.041582927107810974\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 3.695267677307129 | KNN Loss: 3.6493847370147705 | CLS Loss: 0.04588297754526138\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 3.6674869060516357 | KNN Loss: 3.6376285552978516 | CLS Loss: 0.029858386144042015\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 3.672145128250122 | KNN Loss: 3.64109206199646 | CLS Loss: 0.031053055077791214\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 3.7084343433380127 | KNN Loss: 3.685655117034912 | CLS Loss: 0.02277933433651924\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 3.639127731323242 | KNN Loss: 3.6145877838134766 | CLS Loss: 0.024539915844798088\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 3.637908935546875 | KNN Loss: 3.605431318283081 | CLS Loss: 0.03247771039605141\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 3.6706082820892334 | KNN Loss: 3.621567726135254 | CLS Loss: 0.049040574580430984\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 3.679567575454712 | KNN Loss: 3.6473910808563232 | CLS Loss: 0.032176386564970016\n",
      "Epoch: 042, Loss: 3.6720, Train: 0.9921, Valid: 0.9847, Best: 0.9857\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 3.6477763652801514 | KNN Loss: 3.6326744556427 | CLS Loss: 0.015101795084774494\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 3.6364920139312744 | KNN Loss: 3.6034724712371826 | CLS Loss: 0.03301948681473732\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 3.649320602416992 | KNN Loss: 3.616405963897705 | CLS Loss: 0.032914530485868454\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 3.6440789699554443 | KNN Loss: 3.593032121658325 | CLS Loss: 0.051046766340732574\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 3.6320884227752686 | KNN Loss: 3.6171157360076904 | CLS Loss: 0.014972611330449581\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 3.635112762451172 | KNN Loss: 3.6159207820892334 | CLS Loss: 0.0191919207572937\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 3.686746835708618 | KNN Loss: 3.672682046890259 | CLS Loss: 0.014064835384488106\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 3.676823377609253 | KNN Loss: 3.6534626483917236 | CLS Loss: 0.023360708728432655\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 3.6930294036865234 | KNN Loss: 3.650390386581421 | CLS Loss: 0.04263893887400627\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 3.721029758453369 | KNN Loss: 3.6622297763824463 | CLS Loss: 0.05880008265376091\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 3.638888359069824 | KNN Loss: 3.6115150451660156 | CLS Loss: 0.027373310178518295\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 3.6562085151672363 | KNN Loss: 3.633408308029175 | CLS Loss: 0.022800102829933167\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 3.7231879234313965 | KNN Loss: 3.6769602298736572 | CLS Loss: 0.04622766003012657\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 3.68448805809021 | KNN Loss: 3.6560165882110596 | CLS Loss: 0.028471488505601883\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 3.6427156925201416 | KNN Loss: 3.6214261054992676 | CLS Loss: 0.021289659664034843\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 3.700498342514038 | KNN Loss: 3.6598992347717285 | CLS Loss: 0.04059901833534241\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 3.6579205989837646 | KNN Loss: 3.6516802310943604 | CLS Loss: 0.006240355782210827\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 3.6839840412139893 | KNN Loss: 3.655379056930542 | CLS Loss: 0.02860509231686592\n",
      "Epoch: 043, Loss: 3.6668, Train: 0.9927, Valid: 0.9862, Best: 0.9862\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 3.674823045730591 | KNN Loss: 3.6584134101867676 | CLS Loss: 0.016409743577241898\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 3.682328701019287 | KNN Loss: 3.6498916149139404 | CLS Loss: 0.03243698924779892\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 3.684666156768799 | KNN Loss: 3.658590316772461 | CLS Loss: 0.026075735688209534\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 3.6281795501708984 | KNN Loss: 3.6152541637420654 | CLS Loss: 0.012925487011671066\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 3.682443857192993 | KNN Loss: 3.653236150741577 | CLS Loss: 0.02920767106115818\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 3.701521635055542 | KNN Loss: 3.6820740699768066 | CLS Loss: 0.01944764330983162\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 3.657244920730591 | KNN Loss: 3.635690689086914 | CLS Loss: 0.021554263308644295\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 3.677837371826172 | KNN Loss: 3.6351637840270996 | CLS Loss: 0.042673517018556595\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 3.6876564025878906 | KNN Loss: 3.626399040222168 | CLS Loss: 0.061257362365722656\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 3.6524457931518555 | KNN Loss: 3.6136980056762695 | CLS Loss: 0.0387478843331337\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 3.689077854156494 | KNN Loss: 3.628396987915039 | CLS Loss: 0.06068075820803642\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 3.675795078277588 | KNN Loss: 3.6297717094421387 | CLS Loss: 0.04602326080203056\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 3.6763768196105957 | KNN Loss: 3.6501922607421875 | CLS Loss: 0.026184603571891785\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 3.657395362854004 | KNN Loss: 3.633251428604126 | CLS Loss: 0.02414395660161972\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 3.6594886779785156 | KNN Loss: 3.620927095413208 | CLS Loss: 0.03856160491704941\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 3.700758695602417 | KNN Loss: 3.6522183418273926 | CLS Loss: 0.048540323972702026\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 3.696411371231079 | KNN Loss: 3.635023355484009 | CLS Loss: 0.061387963593006134\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 3.6429049968719482 | KNN Loss: 3.6137747764587402 | CLS Loss: 0.029130300506949425\n",
      "Epoch: 044, Loss: 3.6705, Train: 0.9912, Valid: 0.9856, Best: 0.9862\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 3.6635189056396484 | KNN Loss: 3.643247127532959 | CLS Loss: 0.02027175761759281\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 3.6512320041656494 | KNN Loss: 3.602376937866211 | CLS Loss: 0.04885508865118027\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 3.714423656463623 | KNN Loss: 3.686636447906494 | CLS Loss: 0.02778729982674122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 3.674020767211914 | KNN Loss: 3.6628055572509766 | CLS Loss: 0.011215245351195335\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 3.638474941253662 | KNN Loss: 3.6134133338928223 | CLS Loss: 0.025061555206775665\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 3.6613900661468506 | KNN Loss: 3.6379590034484863 | CLS Loss: 0.02343105338513851\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 3.6373536586761475 | KNN Loss: 3.607299327850342 | CLS Loss: 0.0300543662160635\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 3.6596665382385254 | KNN Loss: 3.6432206630706787 | CLS Loss: 0.016445988789200783\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 3.6829710006713867 | KNN Loss: 3.6282901763916016 | CLS Loss: 0.054680801928043365\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 3.650747060775757 | KNN Loss: 3.6377227306365967 | CLS Loss: 0.01302428636699915\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 3.6886324882507324 | KNN Loss: 3.651376962661743 | CLS Loss: 0.03725549206137657\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 3.6879167556762695 | KNN Loss: 3.668056011199951 | CLS Loss: 0.019860664382576942\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 3.6755964756011963 | KNN Loss: 3.637906074523926 | CLS Loss: 0.037690456956624985\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 3.655211925506592 | KNN Loss: 3.6219253540039062 | CLS Loss: 0.03328659385442734\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 3.6632049083709717 | KNN Loss: 3.6301677227020264 | CLS Loss: 0.03303723409771919\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 3.670236825942993 | KNN Loss: 3.6442179679870605 | CLS Loss: 0.02601894550025463\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 3.675577163696289 | KNN Loss: 3.6094484329223633 | CLS Loss: 0.06612872332334518\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 3.714383840560913 | KNN Loss: 3.668841600418091 | CLS Loss: 0.04554218426346779\n",
      "Epoch: 045, Loss: 3.6672, Train: 0.9914, Valid: 0.9839, Best: 0.9862\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 3.6699981689453125 | KNN Loss: 3.646864175796509 | CLS Loss: 0.02313399873673916\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 3.6412622928619385 | KNN Loss: 3.597304582595825 | CLS Loss: 0.04395771771669388\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 3.6610655784606934 | KNN Loss: 3.6240851879119873 | CLS Loss: 0.03698031231760979\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 3.6163277626037598 | KNN Loss: 3.594409227371216 | CLS Loss: 0.021918561309576035\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 3.630000114440918 | KNN Loss: 3.6268699169158936 | CLS Loss: 0.003130124881863594\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 3.69854474067688 | KNN Loss: 3.6587181091308594 | CLS Loss: 0.03982652351260185\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 3.6617536544799805 | KNN Loss: 3.627322196960449 | CLS Loss: 0.03443136438727379\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 3.682637929916382 | KNN Loss: 3.656968593597412 | CLS Loss: 0.025669420138001442\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 3.673450469970703 | KNN Loss: 3.6405324935913086 | CLS Loss: 0.03291792795062065\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 3.661080837249756 | KNN Loss: 3.63860821723938 | CLS Loss: 0.022472653537988663\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 3.6587600708007812 | KNN Loss: 3.645859718322754 | CLS Loss: 0.012900429777801037\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 3.753192901611328 | KNN Loss: 3.703603506088257 | CLS Loss: 0.04958944022655487\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 3.7241299152374268 | KNN Loss: 3.675156593322754 | CLS Loss: 0.04897328093647957\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 3.6866753101348877 | KNN Loss: 3.6720938682556152 | CLS Loss: 0.014581548050045967\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 3.6522622108459473 | KNN Loss: 3.607211112976074 | CLS Loss: 0.045050982385873795\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 3.6975345611572266 | KNN Loss: 3.6349759101867676 | CLS Loss: 0.0625585988163948\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 3.6452558040618896 | KNN Loss: 3.6212589740753174 | CLS Loss: 0.023996863514184952\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 3.684875965118408 | KNN Loss: 3.648871898651123 | CLS Loss: 0.03600415587425232\n",
      "Epoch: 046, Loss: 3.6788, Train: 0.9925, Valid: 0.9856, Best: 0.9862\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 3.6374404430389404 | KNN Loss: 3.6090731620788574 | CLS Loss: 0.028367340564727783\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 3.6385657787323 | KNN Loss: 3.608100414276123 | CLS Loss: 0.030465437099337578\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 3.6818344593048096 | KNN Loss: 3.65267014503479 | CLS Loss: 0.02916434407234192\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 3.6743345260620117 | KNN Loss: 3.6495509147644043 | CLS Loss: 0.024783551692962646\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 3.691439151763916 | KNN Loss: 3.628156900405884 | CLS Loss: 0.06328228861093521\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 3.6373767852783203 | KNN Loss: 3.6298675537109375 | CLS Loss: 0.007509209215641022\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 3.654893159866333 | KNN Loss: 3.641904592514038 | CLS Loss: 0.01298866979777813\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 3.651766777038574 | KNN Loss: 3.6200332641601562 | CLS Loss: 0.0317334309220314\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 3.6365761756896973 | KNN Loss: 3.6225826740264893 | CLS Loss: 0.013993482105433941\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 3.6777231693267822 | KNN Loss: 3.6420183181762695 | CLS Loss: 0.0357048362493515\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 3.686983346939087 | KNN Loss: 3.651845693588257 | CLS Loss: 0.03513755276799202\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 3.6442480087280273 | KNN Loss: 3.6081326007843018 | CLS Loss: 0.03611546382308006\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 3.6681203842163086 | KNN Loss: 3.6459765434265137 | CLS Loss: 0.022143743932247162\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 3.656323194503784 | KNN Loss: 3.628802537918091 | CLS Loss: 0.02752062864601612\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 3.6088924407958984 | KNN Loss: 3.583040237426758 | CLS Loss: 0.02585219219326973\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 3.6511449813842773 | KNN Loss: 3.619291305541992 | CLS Loss: 0.0318535640835762\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 3.67215633392334 | KNN Loss: 3.6380767822265625 | CLS Loss: 0.034079473465681076\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 3.6604390144348145 | KNN Loss: 3.6388766765594482 | CLS Loss: 0.021562378853559494\n",
      "Epoch: 047, Loss: 3.6645, Train: 0.9933, Valid: 0.9863, Best: 0.9863\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 3.6721086502075195 | KNN Loss: 3.66277813911438 | CLS Loss: 0.009330487810075283\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 3.6688244342803955 | KNN Loss: 3.623631238937378 | CLS Loss: 0.04519321024417877\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 3.6593844890594482 | KNN Loss: 3.6411139965057373 | CLS Loss: 0.018270455300807953\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 3.641892433166504 | KNN Loss: 3.6120107173919678 | CLS Loss: 0.029881732538342476\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 3.641462564468384 | KNN Loss: 3.6173739433288574 | CLS Loss: 0.024088606238365173\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 3.6742920875549316 | KNN Loss: 3.615892171859741 | CLS Loss: 0.05839989334344864\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 3.6604835987091064 | KNN Loss: 3.6209564208984375 | CLS Loss: 0.03952721133828163\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 3.663377046585083 | KNN Loss: 3.647890090942383 | CLS Loss: 0.015487028285861015\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 3.668651819229126 | KNN Loss: 3.64888596534729 | CLS Loss: 0.01976582035422325\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 3.6649534702301025 | KNN Loss: 3.6404318809509277 | CLS Loss: 0.02452169544994831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 3.6621346473693848 | KNN Loss: 3.635104179382324 | CLS Loss: 0.027030566707253456\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 3.6518406867980957 | KNN Loss: 3.6111538410186768 | CLS Loss: 0.040686801075935364\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 3.6415610313415527 | KNN Loss: 3.622943878173828 | CLS Loss: 0.018617264926433563\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 3.664109945297241 | KNN Loss: 3.6110951900482178 | CLS Loss: 0.053014837205410004\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 3.6380250453948975 | KNN Loss: 3.6337947845458984 | CLS Loss: 0.00423037214204669\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 3.6721742153167725 | KNN Loss: 3.6584389209747314 | CLS Loss: 0.01373538002371788\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 3.6348464488983154 | KNN Loss: 3.6189370155334473 | CLS Loss: 0.015909496694803238\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 3.7076098918914795 | KNN Loss: 3.644193410873413 | CLS Loss: 0.06341654807329178\n",
      "Epoch: 048, Loss: 3.6657, Train: 0.9889, Valid: 0.9814, Best: 0.9863\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 3.6742546558380127 | KNN Loss: 3.6553449630737305 | CLS Loss: 0.018909577280282974\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 3.6602766513824463 | KNN Loss: 3.625670909881592 | CLS Loss: 0.03460574522614479\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 3.6442108154296875 | KNN Loss: 3.6223671436309814 | CLS Loss: 0.021843766793608665\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 3.62951922416687 | KNN Loss: 3.6153981685638428 | CLS Loss: 0.014120950363576412\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 3.7011208534240723 | KNN Loss: 3.659318208694458 | CLS Loss: 0.041802648454904556\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 3.690274477005005 | KNN Loss: 3.6595706939697266 | CLS Loss: 0.030703896656632423\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 3.6399428844451904 | KNN Loss: 3.6266050338745117 | CLS Loss: 0.013337964192032814\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 3.6699349880218506 | KNN Loss: 3.6231818199157715 | CLS Loss: 0.046753279864788055\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 3.6836111545562744 | KNN Loss: 3.659630060195923 | CLS Loss: 0.02398120053112507\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 3.690272569656372 | KNN Loss: 3.6619150638580322 | CLS Loss: 0.02835751697421074\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 3.6890130043029785 | KNN Loss: 3.6340391635894775 | CLS Loss: 0.054973769932985306\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 3.681361198425293 | KNN Loss: 3.659639596939087 | CLS Loss: 0.021721508353948593\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 3.7146060466766357 | KNN Loss: 3.6669347286224365 | CLS Loss: 0.04767125844955444\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 3.718118190765381 | KNN Loss: 3.674121856689453 | CLS Loss: 0.04399628937244415\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 3.66591739654541 | KNN Loss: 3.6458489894866943 | CLS Loss: 0.020068496465682983\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 3.6785404682159424 | KNN Loss: 3.6434381008148193 | CLS Loss: 0.035102419555187225\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 3.667235851287842 | KNN Loss: 3.637899398803711 | CLS Loss: 0.02933654375374317\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 3.6738221645355225 | KNN Loss: 3.6310436725616455 | CLS Loss: 0.04277846962213516\n",
      "Epoch: 049, Loss: 3.6810, Train: 0.9928, Valid: 0.9863, Best: 0.9863\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 3.652017593383789 | KNN Loss: 3.640587329864502 | CLS Loss: 0.011430316604673862\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 3.6517512798309326 | KNN Loss: 3.629753351211548 | CLS Loss: 0.021998003125190735\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 3.6391079425811768 | KNN Loss: 3.6229825019836426 | CLS Loss: 0.016125502064824104\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 3.638125419616699 | KNN Loss: 3.621328592300415 | CLS Loss: 0.016796907410025597\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 3.6175997257232666 | KNN Loss: 3.600100040435791 | CLS Loss: 0.017499703913927078\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 3.657392740249634 | KNN Loss: 3.6153411865234375 | CLS Loss: 0.04205159842967987\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 3.6799325942993164 | KNN Loss: 3.6593425273895264 | CLS Loss: 0.020590052008628845\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 3.6530203819274902 | KNN Loss: 3.637087345123291 | CLS Loss: 0.01593298651278019\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 3.694410800933838 | KNN Loss: 3.6806466579437256 | CLS Loss: 0.013764229603111744\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 3.6595213413238525 | KNN Loss: 3.636357069015503 | CLS Loss: 0.0231641698628664\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 3.6747143268585205 | KNN Loss: 3.6538779735565186 | CLS Loss: 0.020836371928453445\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 3.648533582687378 | KNN Loss: 3.631700038909912 | CLS Loss: 0.01683356799185276\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 3.6661880016326904 | KNN Loss: 3.647754669189453 | CLS Loss: 0.018433276563882828\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 3.6440579891204834 | KNN Loss: 3.6227803230285645 | CLS Loss: 0.021277766674757004\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 3.6302905082702637 | KNN Loss: 3.5990042686462402 | CLS Loss: 0.03128625452518463\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 3.671051263809204 | KNN Loss: 3.6328039169311523 | CLS Loss: 0.03824735805392265\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 3.6460301876068115 | KNN Loss: 3.6250498294830322 | CLS Loss: 0.0209803469479084\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 3.679757595062256 | KNN Loss: 3.6545820236206055 | CLS Loss: 0.025175562128424644\n",
      "Epoch: 050, Loss: 3.6684, Train: 0.9930, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 3.652836322784424 | KNN Loss: 3.6179311275482178 | CLS Loss: 0.03490529581904411\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 3.6720783710479736 | KNN Loss: 3.6558713912963867 | CLS Loss: 0.01620704121887684\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 3.7196006774902344 | KNN Loss: 3.678866386413574 | CLS Loss: 0.04073426127433777\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 3.6774919033050537 | KNN Loss: 3.639756679534912 | CLS Loss: 0.03773530572652817\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 3.6406009197235107 | KNN Loss: 3.614759922027588 | CLS Loss: 0.025840958580374718\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 3.665680408477783 | KNN Loss: 3.6493425369262695 | CLS Loss: 0.01633777841925621\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 3.658626079559326 | KNN Loss: 3.645519971847534 | CLS Loss: 0.013106204569339752\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 3.6660921573638916 | KNN Loss: 3.629686117172241 | CLS Loss: 0.03640609234571457\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 3.6608192920684814 | KNN Loss: 3.633033514022827 | CLS Loss: 0.027785737067461014\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 3.6839261054992676 | KNN Loss: 3.6686158180236816 | CLS Loss: 0.015310357324779034\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 3.6542484760284424 | KNN Loss: 3.630978584289551 | CLS Loss: 0.02326996810734272\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 3.6407527923583984 | KNN Loss: 3.613503932952881 | CLS Loss: 0.027248840779066086\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 3.6800155639648438 | KNN Loss: 3.6419715881347656 | CLS Loss: 0.03804391622543335\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 3.6463820934295654 | KNN Loss: 3.623746156692505 | CLS Loss: 0.022636031731963158\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 3.682047128677368 | KNN Loss: 3.65608549118042 | CLS Loss: 0.025961749255657196\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 3.6432600021362305 | KNN Loss: 3.5962822437286377 | CLS Loss: 0.04697781428694725\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 3.6423752307891846 | KNN Loss: 3.616816759109497 | CLS Loss: 0.02555847354233265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 3.6501994132995605 | KNN Loss: 3.6316144466400146 | CLS Loss: 0.018585067242383957\n",
      "Epoch: 051, Loss: 3.6710, Train: 0.9931, Valid: 0.9864, Best: 0.9866\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 3.643723249435425 | KNN Loss: 3.6131808757781982 | CLS Loss: 0.030542319640517235\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 3.6688201427459717 | KNN Loss: 3.632675886154175 | CLS Loss: 0.03614432364702225\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 3.660720109939575 | KNN Loss: 3.6442432403564453 | CLS Loss: 0.016476891934871674\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 3.6683483123779297 | KNN Loss: 3.6474688053131104 | CLS Loss: 0.020879516378045082\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 3.726088523864746 | KNN Loss: 3.683061122894287 | CLS Loss: 0.043027304112911224\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 3.6515748500823975 | KNN Loss: 3.6245107650756836 | CLS Loss: 0.02706417813897133\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 3.6527607440948486 | KNN Loss: 3.6393582820892334 | CLS Loss: 0.013402486220002174\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 3.6582436561584473 | KNN Loss: 3.6381759643554688 | CLS Loss: 0.02006765827536583\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 3.630185127258301 | KNN Loss: 3.6181421279907227 | CLS Loss: 0.012042981572449207\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 3.6560170650482178 | KNN Loss: 3.619112253189087 | CLS Loss: 0.036904748529195786\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 3.723202705383301 | KNN Loss: 3.6939430236816406 | CLS Loss: 0.029259750619530678\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 3.6702206134796143 | KNN Loss: 3.6187212467193604 | CLS Loss: 0.05149942636489868\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 3.667853593826294 | KNN Loss: 3.6577980518341064 | CLS Loss: 0.010055584833025932\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 3.716526746749878 | KNN Loss: 3.6621692180633545 | CLS Loss: 0.05435753986239433\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 3.655134677886963 | KNN Loss: 3.59395694732666 | CLS Loss: 0.06117779389023781\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 3.6923155784606934 | KNN Loss: 3.633481740951538 | CLS Loss: 0.058833781629800797\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 3.661817789077759 | KNN Loss: 3.6367177963256836 | CLS Loss: 0.025100022554397583\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 3.6419172286987305 | KNN Loss: 3.6089327335357666 | CLS Loss: 0.032984428107738495\n",
      "Epoch: 052, Loss: 3.6641, Train: 0.9930, Valid: 0.9861, Best: 0.9866\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 3.644312858581543 | KNN Loss: 3.619259834289551 | CLS Loss: 0.025053074583411217\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 3.654118776321411 | KNN Loss: 3.6294913291931152 | CLS Loss: 0.02462751418352127\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 3.6626360416412354 | KNN Loss: 3.6360273361206055 | CLS Loss: 0.026608655229210854\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 3.6656856536865234 | KNN Loss: 3.6430742740631104 | CLS Loss: 0.02261142060160637\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 3.66866397857666 | KNN Loss: 3.626840353012085 | CLS Loss: 0.04182367026805878\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 3.6768062114715576 | KNN Loss: 3.658439874649048 | CLS Loss: 0.018366223201155663\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 3.643199920654297 | KNN Loss: 3.6168735027313232 | CLS Loss: 0.026326512917876244\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 3.6739909648895264 | KNN Loss: 3.6449577808380127 | CLS Loss: 0.02903313748538494\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 3.6241228580474854 | KNN Loss: 3.6141278743743896 | CLS Loss: 0.00999508798122406\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 3.6835854053497314 | KNN Loss: 3.659389019012451 | CLS Loss: 0.024196378886699677\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 3.6583192348480225 | KNN Loss: 3.619845390319824 | CLS Loss: 0.038473863154649734\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 3.6736056804656982 | KNN Loss: 3.6308822631835938 | CLS Loss: 0.0427234023809433\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 3.6365671157836914 | KNN Loss: 3.6244349479675293 | CLS Loss: 0.012132189236581326\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 3.6473309993743896 | KNN Loss: 3.6352529525756836 | CLS Loss: 0.012077967636287212\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 3.6690688133239746 | KNN Loss: 3.6540377140045166 | CLS Loss: 0.015031218528747559\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 3.668278217315674 | KNN Loss: 3.6287646293640137 | CLS Loss: 0.03951365128159523\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 3.6705780029296875 | KNN Loss: 3.6365866661071777 | CLS Loss: 0.03399139270186424\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 3.6574087142944336 | KNN Loss: 3.6172471046447754 | CLS Loss: 0.04016153886914253\n",
      "Epoch: 053, Loss: 3.6589, Train: 0.9941, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 3.7082364559173584 | KNN Loss: 3.679736614227295 | CLS Loss: 0.028499742969870567\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 3.632969379425049 | KNN Loss: 3.626164436340332 | CLS Loss: 0.006804898846894503\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 3.6677448749542236 | KNN Loss: 3.6514947414398193 | CLS Loss: 0.016250107437372208\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 3.693085193634033 | KNN Loss: 3.6510465145111084 | CLS Loss: 0.042038559913635254\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 3.651015043258667 | KNN Loss: 3.611901044845581 | CLS Loss: 0.039113957434892654\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 3.65280818939209 | KNN Loss: 3.639690399169922 | CLS Loss: 0.013117735274136066\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 3.6393003463745117 | KNN Loss: 3.605062246322632 | CLS Loss: 0.03423813730478287\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 3.665477991104126 | KNN Loss: 3.6241350173950195 | CLS Loss: 0.04134305194020271\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 3.6563899517059326 | KNN Loss: 3.6437442302703857 | CLS Loss: 0.012645830400288105\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 3.644284248352051 | KNN Loss: 3.6231112480163574 | CLS Loss: 0.02117302268743515\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 3.672559976577759 | KNN Loss: 3.6558566093444824 | CLS Loss: 0.0167034063488245\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 3.662492275238037 | KNN Loss: 3.6264584064483643 | CLS Loss: 0.03603387251496315\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 3.6477675437927246 | KNN Loss: 3.629556655883789 | CLS Loss: 0.018210778012871742\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 3.6922595500946045 | KNN Loss: 3.670684337615967 | CLS Loss: 0.02157529443502426\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 3.637615919113159 | KNN Loss: 3.6286916732788086 | CLS Loss: 0.00892435573041439\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 3.643233060836792 | KNN Loss: 3.6107373237609863 | CLS Loss: 0.032495830208063126\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 3.6597886085510254 | KNN Loss: 3.6531007289886475 | CLS Loss: 0.00668794522061944\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 3.6308438777923584 | KNN Loss: 3.6082675457000732 | CLS Loss: 0.022576404735445976\n",
      "Epoch: 054, Loss: 3.6614, Train: 0.9929, Valid: 0.9853, Best: 0.9866\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 3.6164286136627197 | KNN Loss: 3.604349136352539 | CLS Loss: 0.012079463340342045\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 3.6722829341888428 | KNN Loss: 3.655270576477051 | CLS Loss: 0.017012380063533783\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 3.682126045227051 | KNN Loss: 3.6484975814819336 | CLS Loss: 0.03362840414047241\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 3.6424477100372314 | KNN Loss: 3.6282846927642822 | CLS Loss: 0.01416307594627142\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 3.707810163497925 | KNN Loss: 3.6712570190429688 | CLS Loss: 0.03655311465263367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 3.6232404708862305 | KNN Loss: 3.6008400917053223 | CLS Loss: 0.022400496527552605\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 3.67880916595459 | KNN Loss: 3.6511306762695312 | CLS Loss: 0.027678564190864563\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 3.6708579063415527 | KNN Loss: 3.6291024684906006 | CLS Loss: 0.041755400598049164\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 3.662759780883789 | KNN Loss: 3.643327474594116 | CLS Loss: 0.019432326778769493\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 3.719548225402832 | KNN Loss: 3.6568658351898193 | CLS Loss: 0.06268235296010971\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 3.6348793506622314 | KNN Loss: 3.616398334503174 | CLS Loss: 0.01848096214234829\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 3.664475202560425 | KNN Loss: 3.6424765586853027 | CLS Loss: 0.021998753771185875\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 3.6665384769439697 | KNN Loss: 3.6308844089508057 | CLS Loss: 0.035654015839099884\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 3.727004051208496 | KNN Loss: 3.7009658813476562 | CLS Loss: 0.026038149371743202\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 3.716325521469116 | KNN Loss: 3.6997945308685303 | CLS Loss: 0.01653110794723034\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 3.6753814220428467 | KNN Loss: 3.6681602001190186 | CLS Loss: 0.0072211152873933315\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 3.6951775550842285 | KNN Loss: 3.6622111797332764 | CLS Loss: 0.03296634554862976\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 3.693510055541992 | KNN Loss: 3.6655445098876953 | CLS Loss: 0.027965661138296127\n",
      "Epoch: 055, Loss: 3.6596, Train: 0.9935, Valid: 0.9854, Best: 0.9866\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 3.6587421894073486 | KNN Loss: 3.639876127243042 | CLS Loss: 0.0188661590218544\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 3.6450729370117188 | KNN Loss: 3.615138053894043 | CLS Loss: 0.029934875667095184\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 3.6360840797424316 | KNN Loss: 3.606706142425537 | CLS Loss: 0.0293778944760561\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 3.672799825668335 | KNN Loss: 3.636608839035034 | CLS Loss: 0.036191072314977646\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 3.6527299880981445 | KNN Loss: 3.612567663192749 | CLS Loss: 0.04016236215829849\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 3.6322362422943115 | KNN Loss: 3.5993638038635254 | CLS Loss: 0.03287235274910927\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 3.6677358150482178 | KNN Loss: 3.6533639430999756 | CLS Loss: 0.0143717797473073\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 3.659238576889038 | KNN Loss: 3.647639036178589 | CLS Loss: 0.011599515564739704\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 3.666496992111206 | KNN Loss: 3.656378746032715 | CLS Loss: 0.010118188336491585\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 3.6632072925567627 | KNN Loss: 3.6336967945098877 | CLS Loss: 0.029510455206036568\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 3.629196882247925 | KNN Loss: 3.6196250915527344 | CLS Loss: 0.00957181304693222\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 3.715916395187378 | KNN Loss: 3.6667213439941406 | CLS Loss: 0.049194976687431335\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 3.701888084411621 | KNN Loss: 3.6719536781311035 | CLS Loss: 0.029934411868453026\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 3.6938424110412598 | KNN Loss: 3.644484281539917 | CLS Loss: 0.04935808107256889\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 3.6527247428894043 | KNN Loss: 3.6382274627685547 | CLS Loss: 0.014497239142656326\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 3.6706666946411133 | KNN Loss: 3.6178863048553467 | CLS Loss: 0.052780404686927795\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 3.6749486923217773 | KNN Loss: 3.616812229156494 | CLS Loss: 0.058136388659477234\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 3.656564950942993 | KNN Loss: 3.6446568965911865 | CLS Loss: 0.011908164247870445\n",
      "Epoch: 056, Loss: 3.6657, Train: 0.9890, Valid: 0.9820, Best: 0.9866\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 3.6924853324890137 | KNN Loss: 3.671947479248047 | CLS Loss: 0.020537784323096275\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 3.729240894317627 | KNN Loss: 3.6823816299438477 | CLS Loss: 0.04685916006565094\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 3.6603281497955322 | KNN Loss: 3.6387131214141846 | CLS Loss: 0.021615078672766685\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 3.669651985168457 | KNN Loss: 3.655231475830078 | CLS Loss: 0.014420488849282265\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 3.6373744010925293 | KNN Loss: 3.6140296459198 | CLS Loss: 0.02334476448595524\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 3.682471752166748 | KNN Loss: 3.6469192504882812 | CLS Loss: 0.03555253520607948\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 3.6511991024017334 | KNN Loss: 3.6322879791259766 | CLS Loss: 0.018911035731434822\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 3.6889777183532715 | KNN Loss: 3.6755905151367188 | CLS Loss: 0.013387157581746578\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 3.686577796936035 | KNN Loss: 3.633045196533203 | CLS Loss: 0.05353260412812233\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 3.6898043155670166 | KNN Loss: 3.6590323448181152 | CLS Loss: 0.030771875753998756\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 3.6359949111938477 | KNN Loss: 3.612175226211548 | CLS Loss: 0.02381974458694458\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 3.6376171112060547 | KNN Loss: 3.6086227893829346 | CLS Loss: 0.028994355350732803\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 3.698420286178589 | KNN Loss: 3.662501573562622 | CLS Loss: 0.03591882809996605\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 3.653244733810425 | KNN Loss: 3.6336591243743896 | CLS Loss: 0.019585635513067245\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 3.7004811763763428 | KNN Loss: 3.6385021209716797 | CLS Loss: 0.061979107558727264\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 3.6537632942199707 | KNN Loss: 3.6325275897979736 | CLS Loss: 0.02123572863638401\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 3.6591129302978516 | KNN Loss: 3.636413097381592 | CLS Loss: 0.022699950262904167\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 3.6633095741271973 | KNN Loss: 3.647472858428955 | CLS Loss: 0.01583673059940338\n",
      "Epoch: 057, Loss: 3.6600, Train: 0.9936, Valid: 0.9861, Best: 0.9866\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 3.6569981575012207 | KNN Loss: 3.630851984024048 | CLS Loss: 0.026146233081817627\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 3.6550798416137695 | KNN Loss: 3.6386594772338867 | CLS Loss: 0.0164203904569149\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 3.6697800159454346 | KNN Loss: 3.618530035018921 | CLS Loss: 0.051249969750642776\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 3.698322057723999 | KNN Loss: 3.6877851486206055 | CLS Loss: 0.010536831803619862\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 3.6494035720825195 | KNN Loss: 3.6215622425079346 | CLS Loss: 0.027841348201036453\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 3.6685123443603516 | KNN Loss: 3.654923439025879 | CLS Loss: 0.0135888010263443\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 3.7084271907806396 | KNN Loss: 3.682579755783081 | CLS Loss: 0.02584735117852688\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 3.6735432147979736 | KNN Loss: 3.6352758407592773 | CLS Loss: 0.038267478346824646\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 3.6628448963165283 | KNN Loss: 3.6508688926696777 | CLS Loss: 0.011976073496043682\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 3.6180832386016846 | KNN Loss: 3.589262008666992 | CLS Loss: 0.02882111817598343\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 3.675180196762085 | KNN Loss: 3.635540008544922 | CLS Loss: 0.039640285074710846\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 3.6190104484558105 | KNN Loss: 3.596024751663208 | CLS Loss: 0.022985776886343956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 3.6733193397521973 | KNN Loss: 3.6568078994750977 | CLS Loss: 0.016511349007487297\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 3.6703085899353027 | KNN Loss: 3.6463091373443604 | CLS Loss: 0.023999441415071487\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 3.7099149227142334 | KNN Loss: 3.674295663833618 | CLS Loss: 0.03561931848526001\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 3.6543710231781006 | KNN Loss: 3.639430522918701 | CLS Loss: 0.014940431341528893\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 3.637864351272583 | KNN Loss: 3.611377000808716 | CLS Loss: 0.02648734487593174\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 3.6436285972595215 | KNN Loss: 3.619504690170288 | CLS Loss: 0.02412392385303974\n",
      "Epoch: 058, Loss: 3.6595, Train: 0.9936, Valid: 0.9860, Best: 0.9866\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 3.6654913425445557 | KNN Loss: 3.6352896690368652 | CLS Loss: 0.03020167350769043\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 3.626718044281006 | KNN Loss: 3.61043381690979 | CLS Loss: 0.016284318640828133\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 3.664830446243286 | KNN Loss: 3.6180574893951416 | CLS Loss: 0.046772900968790054\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 3.6261746883392334 | KNN Loss: 3.613978147506714 | CLS Loss: 0.012196436524391174\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 3.6447105407714844 | KNN Loss: 3.6273655891418457 | CLS Loss: 0.01734486222267151\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 3.6612794399261475 | KNN Loss: 3.638986349105835 | CLS Loss: 0.022293133661150932\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 3.659529209136963 | KNN Loss: 3.6266653537750244 | CLS Loss: 0.03286391496658325\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 3.700434446334839 | KNN Loss: 3.669252395629883 | CLS Loss: 0.031182127073407173\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 3.6929514408111572 | KNN Loss: 3.6600327491760254 | CLS Loss: 0.03291863575577736\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 3.6508328914642334 | KNN Loss: 3.6223204135894775 | CLS Loss: 0.0285123772919178\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 3.6452696323394775 | KNN Loss: 3.6216816902160645 | CLS Loss: 0.02358788065612316\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 3.683030366897583 | KNN Loss: 3.6543760299682617 | CLS Loss: 0.02865441143512726\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 3.6688385009765625 | KNN Loss: 3.644497871398926 | CLS Loss: 0.02434072270989418\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 3.643285036087036 | KNN Loss: 3.62166166305542 | CLS Loss: 0.021623482927680016\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 3.6952056884765625 | KNN Loss: 3.6873109340667725 | CLS Loss: 0.007894729264080524\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 3.649136543273926 | KNN Loss: 3.604156732559204 | CLS Loss: 0.04497971013188362\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 3.720369815826416 | KNN Loss: 3.672581195831299 | CLS Loss: 0.04778870940208435\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 3.621002435684204 | KNN Loss: 3.612776041030884 | CLS Loss: 0.008226300589740276\n",
      "Epoch: 059, Loss: 3.6569, Train: 0.9939, Valid: 0.9856, Best: 0.9866\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 3.660155773162842 | KNN Loss: 3.6095893383026123 | CLS Loss: 0.05056636780500412\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 3.634312868118286 | KNN Loss: 3.6016998291015625 | CLS Loss: 0.032613132148981094\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 3.6277756690979004 | KNN Loss: 3.6200060844421387 | CLS Loss: 0.007769692223519087\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 3.656196355819702 | KNN Loss: 3.644537925720215 | CLS Loss: 0.011658387258648872\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 3.6506011486053467 | KNN Loss: 3.617295026779175 | CLS Loss: 0.03330602869391441\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 3.669123649597168 | KNN Loss: 3.640423059463501 | CLS Loss: 0.028700659051537514\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 3.708418130874634 | KNN Loss: 3.677516460418701 | CLS Loss: 0.03090156801044941\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 3.65836238861084 | KNN Loss: 3.636516571044922 | CLS Loss: 0.02184578776359558\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 3.640517234802246 | KNN Loss: 3.5976202487945557 | CLS Loss: 0.042897023260593414\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 3.6484572887420654 | KNN Loss: 3.636274576187134 | CLS Loss: 0.012182696722447872\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 3.6218409538269043 | KNN Loss: 3.613172769546509 | CLS Loss: 0.008668128401041031\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 3.6445767879486084 | KNN Loss: 3.6364214420318604 | CLS Loss: 0.008155426010489464\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 3.6300947666168213 | KNN Loss: 3.606133460998535 | CLS Loss: 0.023961368948221207\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 3.629668712615967 | KNN Loss: 3.6101279258728027 | CLS Loss: 0.019540902227163315\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 3.66866135597229 | KNN Loss: 3.6136434078216553 | CLS Loss: 0.055017899721860886\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 3.6458346843719482 | KNN Loss: 3.6242074966430664 | CLS Loss: 0.02162720449268818\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 3.637807846069336 | KNN Loss: 3.610313653945923 | CLS Loss: 0.027494236826896667\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 3.7054860591888428 | KNN Loss: 3.678401470184326 | CLS Loss: 0.027084607630968094\n",
      "Epoch: 060, Loss: 3.6561, Train: 0.9930, Valid: 0.9861, Best: 0.9866\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 3.6543331146240234 | KNN Loss: 3.6442863941192627 | CLS Loss: 0.010046743787825108\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 3.6566689014434814 | KNN Loss: 3.6455187797546387 | CLS Loss: 0.01115020364522934\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 3.7008907794952393 | KNN Loss: 3.6842191219329834 | CLS Loss: 0.016671661287546158\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 3.7431375980377197 | KNN Loss: 3.7270708084106445 | CLS Loss: 0.01606675423681736\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 3.6337971687316895 | KNN Loss: 3.6222853660583496 | CLS Loss: 0.011511840857565403\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 3.6586356163024902 | KNN Loss: 3.6460976600646973 | CLS Loss: 0.012538068927824497\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 3.6575422286987305 | KNN Loss: 3.6341359615325928 | CLS Loss: 0.023406293243169785\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 3.6925957202911377 | KNN Loss: 3.673719882965088 | CLS Loss: 0.01887572556734085\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 3.620429277420044 | KNN Loss: 3.5722384452819824 | CLS Loss: 0.048190888017416\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 3.659747362136841 | KNN Loss: 3.645895481109619 | CLS Loss: 0.013851775787770748\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 3.6377785205841064 | KNN Loss: 3.6240978240966797 | CLS Loss: 0.013680641539394855\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 3.6448490619659424 | KNN Loss: 3.6221351623535156 | CLS Loss: 0.022713858634233475\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 3.6218767166137695 | KNN Loss: 3.613217830657959 | CLS Loss: 0.008658789098262787\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 3.63566255569458 | KNN Loss: 3.6170597076416016 | CLS Loss: 0.01860296167433262\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 3.6970438957214355 | KNN Loss: 3.632321834564209 | CLS Loss: 0.06472209841012955\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 3.6609580516815186 | KNN Loss: 3.641741991043091 | CLS Loss: 0.019216107204556465\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 3.687169313430786 | KNN Loss: 3.6323466300964355 | CLS Loss: 0.0548226535320282\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 3.6674482822418213 | KNN Loss: 3.629929304122925 | CLS Loss: 0.03751898184418678\n",
      "Epoch: 061, Loss: 3.6620, Train: 0.9923, Valid: 0.9857, Best: 0.9866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 3.635624647140503 | KNN Loss: 3.6134488582611084 | CLS Loss: 0.02217579260468483\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 3.6664607524871826 | KNN Loss: 3.6211302280426025 | CLS Loss: 0.04533042758703232\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 3.6346020698547363 | KNN Loss: 3.6162123680114746 | CLS Loss: 0.018389767035841942\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 3.657862663269043 | KNN Loss: 3.6349878311157227 | CLS Loss: 0.022874891757965088\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 3.674889087677002 | KNN Loss: 3.64983868598938 | CLS Loss: 0.025050325319170952\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 3.653926134109497 | KNN Loss: 3.614013671875 | CLS Loss: 0.03991256281733513\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 3.651498556137085 | KNN Loss: 3.5997302532196045 | CLS Loss: 0.05176827311515808\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 3.6652157306671143 | KNN Loss: 3.647865056991577 | CLS Loss: 0.01735057681798935\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 3.673499345779419 | KNN Loss: 3.6476924419403076 | CLS Loss: 0.02580697275698185\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 3.6866397857666016 | KNN Loss: 3.6630289554595947 | CLS Loss: 0.02361086755990982\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 3.658890962600708 | KNN Loss: 3.620753526687622 | CLS Loss: 0.03813745081424713\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 3.6415817737579346 | KNN Loss: 3.619460105895996 | CLS Loss: 0.022121679037809372\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 3.6052446365356445 | KNN Loss: 3.581346273422241 | CLS Loss: 0.023898480460047722\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 3.6453075408935547 | KNN Loss: 3.6278645992279053 | CLS Loss: 0.01744292490184307\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 3.6192519664764404 | KNN Loss: 3.600935220718384 | CLS Loss: 0.018316790461540222\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 3.674755334854126 | KNN Loss: 3.6369404792785645 | CLS Loss: 0.037814926356077194\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 3.6633951663970947 | KNN Loss: 3.634730815887451 | CLS Loss: 0.028664445504546165\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 3.682562828063965 | KNN Loss: 3.645850896835327 | CLS Loss: 0.03671196848154068\n",
      "Epoch: 062, Loss: 3.6545, Train: 0.9940, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 3.6687378883361816 | KNN Loss: 3.6380443572998047 | CLS Loss: 0.0306935366243124\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 3.627089262008667 | KNN Loss: 3.609555959701538 | CLS Loss: 0.01753339171409607\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 3.677586793899536 | KNN Loss: 3.643298387527466 | CLS Loss: 0.034288354218006134\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 3.649580955505371 | KNN Loss: 3.6232175827026367 | CLS Loss: 0.02636343240737915\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 3.692485809326172 | KNN Loss: 3.6663100719451904 | CLS Loss: 0.02617563307285309\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 3.6438820362091064 | KNN Loss: 3.626863718032837 | CLS Loss: 0.01701832190155983\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 3.662931203842163 | KNN Loss: 3.6349523067474365 | CLS Loss: 0.02797885425388813\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 3.631185293197632 | KNN Loss: 3.6116321086883545 | CLS Loss: 0.01955310069024563\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 3.686483383178711 | KNN Loss: 3.6566648483276367 | CLS Loss: 0.029818527400493622\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 3.684736967086792 | KNN Loss: 3.6628270149230957 | CLS Loss: 0.021910015493631363\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 3.648098945617676 | KNN Loss: 3.6421337127685547 | CLS Loss: 0.00596529571339488\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 3.6251721382141113 | KNN Loss: 3.617577075958252 | CLS Loss: 0.007595078554004431\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 3.643913984298706 | KNN Loss: 3.626546859741211 | CLS Loss: 0.017367234453558922\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 3.6168882846832275 | KNN Loss: 3.600900888442993 | CLS Loss: 0.015987368300557137\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 3.6590192317962646 | KNN Loss: 3.6397414207458496 | CLS Loss: 0.01927775889635086\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 3.650174379348755 | KNN Loss: 3.637441396713257 | CLS Loss: 0.012733094394207\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 3.690049886703491 | KNN Loss: 3.6676530838012695 | CLS Loss: 0.02239682339131832\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 3.6540539264678955 | KNN Loss: 3.615325689315796 | CLS Loss: 0.038728199899196625\n",
      "Epoch: 063, Loss: 3.6584, Train: 0.9938, Valid: 0.9853, Best: 0.9871\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 3.620469570159912 | KNN Loss: 3.601672410964966 | CLS Loss: 0.01879715546965599\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 3.6219825744628906 | KNN Loss: 3.6038718223571777 | CLS Loss: 0.01811078190803528\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 3.671931505203247 | KNN Loss: 3.6476399898529053 | CLS Loss: 0.02429148182272911\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 3.667309284210205 | KNN Loss: 3.6298410892486572 | CLS Loss: 0.03746825084090233\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 3.650150775909424 | KNN Loss: 3.605498790740967 | CLS Loss: 0.044651903212070465\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 3.658940076828003 | KNN Loss: 3.6287691593170166 | CLS Loss: 0.030170850455760956\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 3.6317138671875 | KNN Loss: 3.611664295196533 | CLS Loss: 0.020049646496772766\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 3.6423521041870117 | KNN Loss: 3.6277425289154053 | CLS Loss: 0.014609558507800102\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 3.667184591293335 | KNN Loss: 3.6569716930389404 | CLS Loss: 0.010212896391749382\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 3.6345393657684326 | KNN Loss: 3.6229212284088135 | CLS Loss: 0.011618117801845074\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 3.659855842590332 | KNN Loss: 3.6386117935180664 | CLS Loss: 0.02124394103884697\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 3.6403181552886963 | KNN Loss: 3.636145830154419 | CLS Loss: 0.004172353073954582\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 3.628743886947632 | KNN Loss: 3.615833282470703 | CLS Loss: 0.012910506688058376\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 3.6291282176971436 | KNN Loss: 3.598837375640869 | CLS Loss: 0.03029075637459755\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 3.6528422832489014 | KNN Loss: 3.6087961196899414 | CLS Loss: 0.04404618963599205\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 3.6669914722442627 | KNN Loss: 3.658158779144287 | CLS Loss: 0.008832634426653385\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 3.649306297302246 | KNN Loss: 3.618520975112915 | CLS Loss: 0.03078535757958889\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 3.680807590484619 | KNN Loss: 3.6439430713653564 | CLS Loss: 0.03686443716287613\n",
      "Epoch: 064, Loss: 3.6512, Train: 0.9934, Valid: 0.9855, Best: 0.9871\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 3.6550052165985107 | KNN Loss: 3.61879301071167 | CLS Loss: 0.03621222823858261\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 3.65630841255188 | KNN Loss: 3.647481679916382 | CLS Loss: 0.008826675824820995\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 3.6285619735717773 | KNN Loss: 3.5844457149505615 | CLS Loss: 0.0441163070499897\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 3.640408754348755 | KNN Loss: 3.608834981918335 | CLS Loss: 0.031573761254549026\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 3.7337522506713867 | KNN Loss: 3.6839754581451416 | CLS Loss: 0.049776796251535416\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 3.6686019897460938 | KNN Loss: 3.6586077213287354 | CLS Loss: 0.00999433733522892\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 3.623882532119751 | KNN Loss: 3.6116786003112793 | CLS Loss: 0.012204041704535484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 3.6487972736358643 | KNN Loss: 3.6241044998168945 | CLS Loss: 0.024692706763744354\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 3.6401638984680176 | KNN Loss: 3.635779857635498 | CLS Loss: 0.004384030122309923\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 3.662536144256592 | KNN Loss: 3.646332025527954 | CLS Loss: 0.016204185783863068\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 3.675102710723877 | KNN Loss: 3.655867099761963 | CLS Loss: 0.019235599786043167\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 3.6989712715148926 | KNN Loss: 3.684954881668091 | CLS Loss: 0.014016365632414818\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 3.6574454307556152 | KNN Loss: 3.6245100498199463 | CLS Loss: 0.032935336232185364\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 3.692349910736084 | KNN Loss: 3.6638948917388916 | CLS Loss: 0.028454937040805817\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 3.6678965091705322 | KNN Loss: 3.6301867961883545 | CLS Loss: 0.03770976513624191\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 3.6400556564331055 | KNN Loss: 3.6227564811706543 | CLS Loss: 0.01729925535619259\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 3.614640235900879 | KNN Loss: 3.608358383178711 | CLS Loss: 0.006281822454184294\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 3.7032198905944824 | KNN Loss: 3.6503403186798096 | CLS Loss: 0.052879489958286285\n",
      "Epoch: 065, Loss: 3.6549, Train: 0.9946, Valid: 0.9867, Best: 0.9871\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 3.6086018085479736 | KNN Loss: 3.5955111980438232 | CLS Loss: 0.013090579770505428\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 3.649096727371216 | KNN Loss: 3.6231062412261963 | CLS Loss: 0.02599051222205162\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 3.635469436645508 | KNN Loss: 3.6164417266845703 | CLS Loss: 0.01902768947184086\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 3.618659257888794 | KNN Loss: 3.6013667583465576 | CLS Loss: 0.017292598262429237\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 3.63818621635437 | KNN Loss: 3.6259284019470215 | CLS Loss: 0.012257826514542103\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 3.6579935550689697 | KNN Loss: 3.64336895942688 | CLS Loss: 0.014624498784542084\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 3.6378257274627686 | KNN Loss: 3.621802568435669 | CLS Loss: 0.01602311059832573\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 3.6358914375305176 | KNN Loss: 3.6307380199432373 | CLS Loss: 0.005153318401426077\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 3.662081718444824 | KNN Loss: 3.636056423187256 | CLS Loss: 0.02602527290582657\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 3.6710476875305176 | KNN Loss: 3.656782627105713 | CLS Loss: 0.01426512561738491\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 3.6565632820129395 | KNN Loss: 3.629375457763672 | CLS Loss: 0.027187731117010117\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 3.6421589851379395 | KNN Loss: 3.6030704975128174 | CLS Loss: 0.03908845782279968\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 3.6544127464294434 | KNN Loss: 3.626403570175171 | CLS Loss: 0.028009233996272087\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 3.656888723373413 | KNN Loss: 3.6290886402130127 | CLS Loss: 0.027800196781754494\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 3.6640536785125732 | KNN Loss: 3.636242151260376 | CLS Loss: 0.02781141735613346\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 3.6650378704071045 | KNN Loss: 3.6231961250305176 | CLS Loss: 0.04184176027774811\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 3.6159937381744385 | KNN Loss: 3.6027047634124756 | CLS Loss: 0.013288869522511959\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 3.643488883972168 | KNN Loss: 3.6304931640625 | CLS Loss: 0.012995770201086998\n",
      "Epoch: 066, Loss: 3.6524, Train: 0.9940, Valid: 0.9865, Best: 0.9871\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 3.6400930881500244 | KNN Loss: 3.6296634674072266 | CLS Loss: 0.01042951550334692\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 3.6522672176361084 | KNN Loss: 3.622922420501709 | CLS Loss: 0.029344739392399788\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 3.620347499847412 | KNN Loss: 3.6157522201538086 | CLS Loss: 0.004595339298248291\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 3.656209707260132 | KNN Loss: 3.633153200149536 | CLS Loss: 0.023056551814079285\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 3.672701358795166 | KNN Loss: 3.668790578842163 | CLS Loss: 0.0039108977653086185\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 3.624147653579712 | KNN Loss: 3.605443239212036 | CLS Loss: 0.018704351037740707\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 3.6301419734954834 | KNN Loss: 3.610023260116577 | CLS Loss: 0.020118609070777893\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 3.669546604156494 | KNN Loss: 3.657085418701172 | CLS Loss: 0.012461300939321518\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 3.5955777168273926 | KNN Loss: 3.582041025161743 | CLS Loss: 0.013536793179810047\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 3.6328516006469727 | KNN Loss: 3.6167709827423096 | CLS Loss: 0.016080591827630997\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 3.6621906757354736 | KNN Loss: 3.6463754177093506 | CLS Loss: 0.015815140679478645\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 3.6191883087158203 | KNN Loss: 3.5869367122650146 | CLS Loss: 0.03225156292319298\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 3.657834768295288 | KNN Loss: 3.6498444080352783 | CLS Loss: 0.00799040962010622\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 3.63649845123291 | KNN Loss: 3.6197168827056885 | CLS Loss: 0.01678156852722168\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 3.6368675231933594 | KNN Loss: 3.603541374206543 | CLS Loss: 0.03332605957984924\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 3.635279417037964 | KNN Loss: 3.626077175140381 | CLS Loss: 0.009202306158840656\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 3.6314361095428467 | KNN Loss: 3.6077725887298584 | CLS Loss: 0.02366359904408455\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 3.623905897140503 | KNN Loss: 3.6036341190338135 | CLS Loss: 0.020271772518754005\n",
      "Epoch: 067, Loss: 3.6482, Train: 0.9941, Valid: 0.9858, Best: 0.9871\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 3.6823058128356934 | KNN Loss: 3.657741069793701 | CLS Loss: 0.024564675986766815\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 3.634514570236206 | KNN Loss: 3.6249313354492188 | CLS Loss: 0.009583326987922192\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 3.6330482959747314 | KNN Loss: 3.6097679138183594 | CLS Loss: 0.02328038401901722\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 3.615678310394287 | KNN Loss: 3.588654041290283 | CLS Loss: 0.027024246752262115\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 3.619001626968384 | KNN Loss: 3.6025006771087646 | CLS Loss: 0.016501033678650856\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 3.650871753692627 | KNN Loss: 3.6264986991882324 | CLS Loss: 0.02437306009232998\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 3.6374011039733887 | KNN Loss: 3.6299405097961426 | CLS Loss: 0.007460524328052998\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 3.6391611099243164 | KNN Loss: 3.6248621940612793 | CLS Loss: 0.01429881900548935\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 3.642772674560547 | KNN Loss: 3.6270101070404053 | CLS Loss: 0.015762651339173317\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 3.6205809116363525 | KNN Loss: 3.591747283935547 | CLS Loss: 0.02883356437087059\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 3.619502544403076 | KNN Loss: 3.5966548919677734 | CLS Loss: 0.02284770831465721\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 3.690415143966675 | KNN Loss: 3.6773641109466553 | CLS Loss: 0.013051088899374008\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 3.660294771194458 | KNN Loss: 3.6294760704040527 | CLS Loss: 0.030818816274404526\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 3.6439332962036133 | KNN Loss: 3.6150057315826416 | CLS Loss: 0.028927545994520187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 3.6745409965515137 | KNN Loss: 3.646989583969116 | CLS Loss: 0.02755132131278515\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 3.740340232849121 | KNN Loss: 3.6903610229492188 | CLS Loss: 0.049979183822870255\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 3.6219089031219482 | KNN Loss: 3.6049227714538574 | CLS Loss: 0.016986172646284103\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 3.6177713871002197 | KNN Loss: 3.5958950519561768 | CLS Loss: 0.02187643013894558\n",
      "Epoch: 068, Loss: 3.6499, Train: 0.9946, Valid: 0.9869, Best: 0.9871\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 3.644516706466675 | KNN Loss: 3.6328940391540527 | CLS Loss: 0.011622578836977482\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 3.6498193740844727 | KNN Loss: 3.6263158321380615 | CLS Loss: 0.023503422737121582\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 3.661085844039917 | KNN Loss: 3.6435465812683105 | CLS Loss: 0.01753927581012249\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 3.6676125526428223 | KNN Loss: 3.649286985397339 | CLS Loss: 0.018325528129935265\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 3.652705192565918 | KNN Loss: 3.641798496246338 | CLS Loss: 0.01090678945183754\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 3.6176555156707764 | KNN Loss: 3.601743459701538 | CLS Loss: 0.01591210998594761\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 3.627206563949585 | KNN Loss: 3.590527057647705 | CLS Loss: 0.0366794615983963\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 3.6438817977905273 | KNN Loss: 3.61568284034729 | CLS Loss: 0.02819894440472126\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 3.642338514328003 | KNN Loss: 3.630223512649536 | CLS Loss: 0.012114908546209335\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 3.6538617610931396 | KNN Loss: 3.6277289390563965 | CLS Loss: 0.026132844388484955\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 3.6534910202026367 | KNN Loss: 3.6378021240234375 | CLS Loss: 0.01568886823952198\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 3.668445587158203 | KNN Loss: 3.651334762573242 | CLS Loss: 0.01711074262857437\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 3.6638479232788086 | KNN Loss: 3.6496829986572266 | CLS Loss: 0.014164896681904793\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 3.675431251525879 | KNN Loss: 3.654823064804077 | CLS Loss: 0.02060808055102825\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 3.677072286605835 | KNN Loss: 3.657989740371704 | CLS Loss: 0.019082454964518547\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 3.632246255874634 | KNN Loss: 3.617708683013916 | CLS Loss: 0.014537512324750423\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 3.667182207107544 | KNN Loss: 3.6423227787017822 | CLS Loss: 0.024859320372343063\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 3.648954391479492 | KNN Loss: 3.6241133213043213 | CLS Loss: 0.024840958416461945\n",
      "Epoch: 069, Loss: 3.6594, Train: 0.9943, Valid: 0.9863, Best: 0.9871\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 3.684140205383301 | KNN Loss: 3.6736316680908203 | CLS Loss: 0.010508492588996887\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 3.647193193435669 | KNN Loss: 3.621760606765747 | CLS Loss: 0.025432514026761055\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 3.6266818046569824 | KNN Loss: 3.617870330810547 | CLS Loss: 0.008811420761048794\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 3.665424346923828 | KNN Loss: 3.646244525909424 | CLS Loss: 0.01917981542646885\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 3.6922621726989746 | KNN Loss: 3.64151930809021 | CLS Loss: 0.05074289068579674\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 3.638235092163086 | KNN Loss: 3.612839460372925 | CLS Loss: 0.025395642966032028\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 3.6779401302337646 | KNN Loss: 3.669666051864624 | CLS Loss: 0.008274069987237453\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 3.6477785110473633 | KNN Loss: 3.619509220123291 | CLS Loss: 0.028269298374652863\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 3.631537914276123 | KNN Loss: 3.6155459880828857 | CLS Loss: 0.01599203422665596\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 3.6844165325164795 | KNN Loss: 3.6639599800109863 | CLS Loss: 0.02045665867626667\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 3.618557929992676 | KNN Loss: 3.5986454486846924 | CLS Loss: 0.01991237886250019\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 3.649245023727417 | KNN Loss: 3.6420390605926514 | CLS Loss: 0.0072060758247971535\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 3.6932876110076904 | KNN Loss: 3.672847032546997 | CLS Loss: 0.02044060081243515\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 3.6312735080718994 | KNN Loss: 3.5940446853637695 | CLS Loss: 0.03722884878516197\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 3.655214548110962 | KNN Loss: 3.6333587169647217 | CLS Loss: 0.021855788305401802\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 3.649735689163208 | KNN Loss: 3.6357321739196777 | CLS Loss: 0.014003414660692215\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 3.6638548374176025 | KNN Loss: 3.656346321105957 | CLS Loss: 0.007508587092161179\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 3.639295816421509 | KNN Loss: 3.6056711673736572 | CLS Loss: 0.03362470865249634\n",
      "Epoch: 070, Loss: 3.6503, Train: 0.9948, Valid: 0.9868, Best: 0.9871\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 3.626772403717041 | KNN Loss: 3.594160318374634 | CLS Loss: 0.032612115144729614\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 3.6969993114471436 | KNN Loss: 3.68021559715271 | CLS Loss: 0.01678374968469143\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 3.6778409481048584 | KNN Loss: 3.651237964630127 | CLS Loss: 0.026602938771247864\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 3.6341843605041504 | KNN Loss: 3.631441593170166 | CLS Loss: 0.0027426560409367085\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 3.6700046062469482 | KNN Loss: 3.616851568222046 | CLS Loss: 0.05315307155251503\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 3.627837657928467 | KNN Loss: 3.6114654541015625 | CLS Loss: 0.0163723211735487\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 3.6153109073638916 | KNN Loss: 3.6055169105529785 | CLS Loss: 0.009793927893042564\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 3.6558938026428223 | KNN Loss: 3.6402087211608887 | CLS Loss: 0.01568502001464367\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 3.6847288608551025 | KNN Loss: 3.6794567108154297 | CLS Loss: 0.005272211506962776\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 3.642777681350708 | KNN Loss: 3.618499755859375 | CLS Loss: 0.024277906864881516\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 3.6747519969940186 | KNN Loss: 3.663255214691162 | CLS Loss: 0.011496759951114655\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 3.6701860427856445 | KNN Loss: 3.6345713138580322 | CLS Loss: 0.035614755004644394\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 3.6456573009490967 | KNN Loss: 3.6216650009155273 | CLS Loss: 0.023992275819182396\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 3.64923095703125 | KNN Loss: 3.604524612426758 | CLS Loss: 0.04470636323094368\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 3.645432233810425 | KNN Loss: 3.611091375350952 | CLS Loss: 0.03434086591005325\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 3.6298580169677734 | KNN Loss: 3.596691131591797 | CLS Loss: 0.033166900277137756\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 3.6682968139648438 | KNN Loss: 3.638516426086426 | CLS Loss: 0.029780330136418343\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 3.650007963180542 | KNN Loss: 3.6338748931884766 | CLS Loss: 0.016132982447743416\n",
      "Epoch: 071, Loss: 3.6523, Train: 0.9944, Valid: 0.9863, Best: 0.9871\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 3.6533074378967285 | KNN Loss: 3.6398355960845947 | CLS Loss: 0.01347188651561737\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 3.6867520809173584 | KNN Loss: 3.6473827362060547 | CLS Loss: 0.03936922922730446\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 3.64070987701416 | KNN Loss: 3.609328269958496 | CLS Loss: 0.031381674110889435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 3.6593809127807617 | KNN Loss: 3.633129835128784 | CLS Loss: 0.02625107578933239\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 3.6406376361846924 | KNN Loss: 3.6021127700805664 | CLS Loss: 0.038524918258190155\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 3.6645243167877197 | KNN Loss: 3.6356539726257324 | CLS Loss: 0.028870441019535065\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 3.6215262413024902 | KNN Loss: 3.6087350845336914 | CLS Loss: 0.012791207991540432\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 3.698610305786133 | KNN Loss: 3.669224500656128 | CLS Loss: 0.02938583306968212\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 3.6752636432647705 | KNN Loss: 3.6679985523223877 | CLS Loss: 0.007265185937285423\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 3.608842611312866 | KNN Loss: 3.585810422897339 | CLS Loss: 0.023032132536172867\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 3.6437437534332275 | KNN Loss: 3.6302120685577393 | CLS Loss: 0.013531788252294064\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 3.6409292221069336 | KNN Loss: 3.6233558654785156 | CLS Loss: 0.01757347397506237\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 3.6387295722961426 | KNN Loss: 3.5965476036071777 | CLS Loss: 0.042181987315416336\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 3.6844584941864014 | KNN Loss: 3.642458200454712 | CLS Loss: 0.042000219225883484\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 3.623351812362671 | KNN Loss: 3.5985336303710938 | CLS Loss: 0.02481825463473797\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 3.702261447906494 | KNN Loss: 3.6771860122680664 | CLS Loss: 0.025075530633330345\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 3.6412343978881836 | KNN Loss: 3.610546588897705 | CLS Loss: 0.030687758699059486\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 3.7244200706481934 | KNN Loss: 3.6982245445251465 | CLS Loss: 0.02619543857872486\n",
      "Epoch: 072, Loss: 3.6573, Train: 0.9931, Valid: 0.9851, Best: 0.9871\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 3.6395761966705322 | KNN Loss: 3.6100823879241943 | CLS Loss: 0.02949381060898304\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 3.6602492332458496 | KNN Loss: 3.625465154647827 | CLS Loss: 0.03478400781750679\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 3.6695709228515625 | KNN Loss: 3.657536506652832 | CLS Loss: 0.012034519575536251\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 3.650264263153076 | KNN Loss: 3.637596368789673 | CLS Loss: 0.012667851522564888\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 3.6571333408355713 | KNN Loss: 3.6121015548706055 | CLS Loss: 0.045031700283288956\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 3.619298219680786 | KNN Loss: 3.6045589447021484 | CLS Loss: 0.014739176258444786\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 3.657503366470337 | KNN Loss: 3.606480836868286 | CLS Loss: 0.0510224923491478\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 3.6154630184173584 | KNN Loss: 3.5948736667633057 | CLS Loss: 0.02058929018676281\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 3.6177666187286377 | KNN Loss: 3.6054863929748535 | CLS Loss: 0.012280178256332874\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 3.642796277999878 | KNN Loss: 3.6219868659973145 | CLS Loss: 0.020809371024370193\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 3.6330578327178955 | KNN Loss: 3.6212899684906006 | CLS Loss: 0.011767949908971786\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 3.6567013263702393 | KNN Loss: 3.6449594497680664 | CLS Loss: 0.011741980910301208\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 3.6595418453216553 | KNN Loss: 3.6447932720184326 | CLS Loss: 0.014748595654964447\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 3.63649845123291 | KNN Loss: 3.613002061843872 | CLS Loss: 0.023496439680457115\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 3.6441473960876465 | KNN Loss: 3.631532669067383 | CLS Loss: 0.012614836916327477\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 3.601832866668701 | KNN Loss: 3.5822839736938477 | CLS Loss: 0.019548820331692696\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 3.6422860622406006 | KNN Loss: 3.6219966411590576 | CLS Loss: 0.020289452746510506\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 3.6372833251953125 | KNN Loss: 3.629448890686035 | CLS Loss: 0.007834440097212791\n",
      "Epoch: 073, Loss: 3.6491, Train: 0.9948, Valid: 0.9861, Best: 0.9871\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 3.649548053741455 | KNN Loss: 3.625194787979126 | CLS Loss: 0.024353373795747757\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 3.641563653945923 | KNN Loss: 3.6364917755126953 | CLS Loss: 0.005071764811873436\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 3.639758825302124 | KNN Loss: 3.6293413639068604 | CLS Loss: 0.010417480021715164\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 3.6101276874542236 | KNN Loss: 3.601181983947754 | CLS Loss: 0.008945727720856667\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 3.6296679973602295 | KNN Loss: 3.616279125213623 | CLS Loss: 0.013388879597187042\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 3.6779799461364746 | KNN Loss: 3.6637165546417236 | CLS Loss: 0.014263467863202095\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 3.646059989929199 | KNN Loss: 3.6138556003570557 | CLS Loss: 0.03220447152853012\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 3.6090331077575684 | KNN Loss: 3.6021831035614014 | CLS Loss: 0.006850003264844418\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 3.6348695755004883 | KNN Loss: 3.6283650398254395 | CLS Loss: 0.006504575256258249\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 3.625195026397705 | KNN Loss: 3.607820510864258 | CLS Loss: 0.017374634742736816\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 3.6445212364196777 | KNN Loss: 3.6322104930877686 | CLS Loss: 0.012310713529586792\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 3.6531972885131836 | KNN Loss: 3.61372709274292 | CLS Loss: 0.039470259100198746\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 3.621131658554077 | KNN Loss: 3.604816198348999 | CLS Loss: 0.016315553337335587\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 3.6389691829681396 | KNN Loss: 3.6236374378204346 | CLS Loss: 0.015331749804317951\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 3.6372315883636475 | KNN Loss: 3.630871057510376 | CLS Loss: 0.006360519677400589\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 3.6511423587799072 | KNN Loss: 3.6428985595703125 | CLS Loss: 0.008243868127465248\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 3.6164214611053467 | KNN Loss: 3.5889673233032227 | CLS Loss: 0.027454033493995667\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 3.6769156455993652 | KNN Loss: 3.6531484127044678 | CLS Loss: 0.023767225444316864\n",
      "Epoch: 074, Loss: 3.6471, Train: 0.9938, Valid: 0.9858, Best: 0.9871\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 3.6494855880737305 | KNN Loss: 3.624422073364258 | CLS Loss: 0.025063563138246536\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 3.627779245376587 | KNN Loss: 3.612793207168579 | CLS Loss: 0.014986041001975536\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 3.6548056602478027 | KNN Loss: 3.6431217193603516 | CLS Loss: 0.011683947406709194\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 3.671627998352051 | KNN Loss: 3.6511547565460205 | CLS Loss: 0.020473264157772064\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 3.6763505935668945 | KNN Loss: 3.6512649059295654 | CLS Loss: 0.025085702538490295\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 3.6911027431488037 | KNN Loss: 3.6583526134490967 | CLS Loss: 0.03275016322731972\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 3.664365530014038 | KNN Loss: 3.641080141067505 | CLS Loss: 0.023285312578082085\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 3.6204490661621094 | KNN Loss: 3.59256649017334 | CLS Loss: 0.02788252755999565\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 3.6346828937530518 | KNN Loss: 3.61466121673584 | CLS Loss: 0.0200215931981802\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 3.6247212886810303 | KNN Loss: 3.6146085262298584 | CLS Loss: 0.0101127615198493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 3.629589557647705 | KNN Loss: 3.620208740234375 | CLS Loss: 0.009380880743265152\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 3.6835131645202637 | KNN Loss: 3.6481447219848633 | CLS Loss: 0.03536849468946457\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 3.6549484729766846 | KNN Loss: 3.6391243934631348 | CLS Loss: 0.01582399196922779\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 3.670414924621582 | KNN Loss: 3.6283726692199707 | CLS Loss: 0.042042337357997894\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 3.6243300437927246 | KNN Loss: 3.6124939918518066 | CLS Loss: 0.011835956946015358\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 3.66377592086792 | KNN Loss: 3.6246390342712402 | CLS Loss: 0.03913681209087372\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 3.6479074954986572 | KNN Loss: 3.6244730949401855 | CLS Loss: 0.023434314876794815\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 3.7073044776916504 | KNN Loss: 3.675973653793335 | CLS Loss: 0.03133074566721916\n",
      "Epoch: 075, Loss: 3.6525, Train: 0.9921, Valid: 0.9827, Best: 0.9871\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 3.6457958221435547 | KNN Loss: 3.6099789142608643 | CLS Loss: 0.03581700846552849\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 3.65370774269104 | KNN Loss: 3.627145290374756 | CLS Loss: 0.02656242996454239\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 3.631373405456543 | KNN Loss: 3.612993001937866 | CLS Loss: 0.01838036999106407\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 3.649975061416626 | KNN Loss: 3.632730007171631 | CLS Loss: 0.01724506914615631\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 3.6080074310302734 | KNN Loss: 3.59790301322937 | CLS Loss: 0.010104401968419552\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 3.6414601802825928 | KNN Loss: 3.635427951812744 | CLS Loss: 0.006032283883541822\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 3.6418263912200928 | KNN Loss: 3.631467580795288 | CLS Loss: 0.010358922183513641\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 3.6096253395080566 | KNN Loss: 3.591385841369629 | CLS Loss: 0.018239570781588554\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 3.68078875541687 | KNN Loss: 3.6543712615966797 | CLS Loss: 0.02641759067773819\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 3.65801739692688 | KNN Loss: 3.6382365226745605 | CLS Loss: 0.01978076435625553\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 3.620734930038452 | KNN Loss: 3.6103012561798096 | CLS Loss: 0.010433675721287727\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 3.6311376094818115 | KNN Loss: 3.6055052280426025 | CLS Loss: 0.02563246339559555\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 3.6941373348236084 | KNN Loss: 3.6706643104553223 | CLS Loss: 0.023473065346479416\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 3.664443254470825 | KNN Loss: 3.643138885498047 | CLS Loss: 0.021304337307810783\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 3.664879560470581 | KNN Loss: 3.6218292713165283 | CLS Loss: 0.04305022954940796\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 3.647401809692383 | KNN Loss: 3.6239027976989746 | CLS Loss: 0.023499123752117157\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 3.688215494155884 | KNN Loss: 3.6654272079467773 | CLS Loss: 0.022788330912590027\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 3.6505517959594727 | KNN Loss: 3.630579948425293 | CLS Loss: 0.019971938803792\n",
      "Epoch: 076, Loss: 3.6488, Train: 0.9957, Valid: 0.9862, Best: 0.9871\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 3.59515643119812 | KNN Loss: 3.5853490829467773 | CLS Loss: 0.009807281196117401\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 3.662048578262329 | KNN Loss: 3.65161395072937 | CLS Loss: 0.010434678755700588\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 3.620591402053833 | KNN Loss: 3.6054587364196777 | CLS Loss: 0.015132583677768707\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 3.618311882019043 | KNN Loss: 3.6079089641571045 | CLS Loss: 0.010403008200228214\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 3.6498119831085205 | KNN Loss: 3.6277689933776855 | CLS Loss: 0.02204292081296444\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 3.6339008808135986 | KNN Loss: 3.625959634780884 | CLS Loss: 0.00794132612645626\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 3.6528093814849854 | KNN Loss: 3.6416893005371094 | CLS Loss: 0.01112018059939146\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 3.609593629837036 | KNN Loss: 3.6025450229644775 | CLS Loss: 0.007048592437058687\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 3.616147756576538 | KNN Loss: 3.6052298545837402 | CLS Loss: 0.01091780699789524\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 3.6052205562591553 | KNN Loss: 3.5969207286834717 | CLS Loss: 0.00829975213855505\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 3.6351284980773926 | KNN Loss: 3.5966179370880127 | CLS Loss: 0.03851067274808884\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 3.628026247024536 | KNN Loss: 3.609388589859009 | CLS Loss: 0.01863756962120533\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 3.675584316253662 | KNN Loss: 3.646655321121216 | CLS Loss: 0.02892904169857502\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 3.629701614379883 | KNN Loss: 3.6183547973632812 | CLS Loss: 0.011346934363245964\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 3.6310393810272217 | KNN Loss: 3.6109511852264404 | CLS Loss: 0.02008809521794319\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 3.645684242248535 | KNN Loss: 3.6148934364318848 | CLS Loss: 0.03079080395400524\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 3.66768741607666 | KNN Loss: 3.6534109115600586 | CLS Loss: 0.014276547357439995\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 3.6535656452178955 | KNN Loss: 3.633887529373169 | CLS Loss: 0.019678080454468727\n",
      "Epoch: 077, Loss: 3.6461, Train: 0.9950, Valid: 0.9849, Best: 0.9871\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 3.7055439949035645 | KNN Loss: 3.690863847732544 | CLS Loss: 0.01468014344573021\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 3.637242317199707 | KNN Loss: 3.6331467628479004 | CLS Loss: 0.004095515701919794\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 3.588797092437744 | KNN Loss: 3.5834577083587646 | CLS Loss: 0.005339297465980053\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 3.63394832611084 | KNN Loss: 3.6076693534851074 | CLS Loss: 0.026279084384441376\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 3.661675214767456 | KNN Loss: 3.6371757984161377 | CLS Loss: 0.02449950948357582\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 3.6276261806488037 | KNN Loss: 3.623053550720215 | CLS Loss: 0.004572709556668997\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 3.605959415435791 | KNN Loss: 3.5884554386138916 | CLS Loss: 0.017504015937447548\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 3.6379168033599854 | KNN Loss: 3.636131763458252 | CLS Loss: 0.0017850310541689396\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 3.647231340408325 | KNN Loss: 3.625422716140747 | CLS Loss: 0.021808555349707603\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 3.6357736587524414 | KNN Loss: 3.620985984802246 | CLS Loss: 0.014787781983613968\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 3.6409752368927 | KNN Loss: 3.606877326965332 | CLS Loss: 0.03409788757562637\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 3.6509599685668945 | KNN Loss: 3.6431822776794434 | CLS Loss: 0.0077777341939508915\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 3.6633124351501465 | KNN Loss: 3.644681453704834 | CLS Loss: 0.018631083890795708\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 3.660142421722412 | KNN Loss: 3.6352782249450684 | CLS Loss: 0.024864187464118004\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 3.6224918365478516 | KNN Loss: 3.608271837234497 | CLS Loss: 0.014219934120774269\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 3.6339123249053955 | KNN Loss: 3.627772092819214 | CLS Loss: 0.006140327081084251\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 3.6687467098236084 | KNN Loss: 3.658529043197632 | CLS Loss: 0.010217636823654175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 3.6806752681732178 | KNN Loss: 3.656628131866455 | CLS Loss: 0.02404705435037613\n",
      "Epoch: 078, Loss: 3.6440, Train: 0.9943, Valid: 0.9852, Best: 0.9871\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 3.6794559955596924 | KNN Loss: 3.6505236625671387 | CLS Loss: 0.028932280838489532\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 3.6548264026641846 | KNN Loss: 3.630750894546509 | CLS Loss: 0.02407558634877205\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 3.6762869358062744 | KNN Loss: 3.6091275215148926 | CLS Loss: 0.06715936958789825\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 3.6240711212158203 | KNN Loss: 3.6055538654327393 | CLS Loss: 0.01851736381649971\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 3.6293253898620605 | KNN Loss: 3.615821361541748 | CLS Loss: 0.01350412517786026\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 3.6440300941467285 | KNN Loss: 3.640756368637085 | CLS Loss: 0.0032736710272729397\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 3.6486775875091553 | KNN Loss: 3.6323838233947754 | CLS Loss: 0.016293805092573166\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 3.6041927337646484 | KNN Loss: 3.5949654579162598 | CLS Loss: 0.009227349422872066\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 3.6928088665008545 | KNN Loss: 3.670536518096924 | CLS Loss: 0.022272372618317604\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 3.6414427757263184 | KNN Loss: 3.608088493347168 | CLS Loss: 0.03335439786314964\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 3.6287577152252197 | KNN Loss: 3.612666368484497 | CLS Loss: 0.01609145477414131\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 3.613591194152832 | KNN Loss: 3.59751033782959 | CLS Loss: 0.01608084887266159\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 3.660327911376953 | KNN Loss: 3.6476364135742188 | CLS Loss: 0.012691467069089413\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 3.6459150314331055 | KNN Loss: 3.6269278526306152 | CLS Loss: 0.018987176939845085\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 3.5979726314544678 | KNN Loss: 3.5889651775360107 | CLS Loss: 0.009007344953715801\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 3.626821756362915 | KNN Loss: 3.603972911834717 | CLS Loss: 0.022848812863230705\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 3.689795732498169 | KNN Loss: 3.6729767322540283 | CLS Loss: 0.0168190635740757\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 3.646700143814087 | KNN Loss: 3.595250368118286 | CLS Loss: 0.051449816673994064\n",
      "Epoch: 079, Loss: 3.6453, Train: 0.9944, Valid: 0.9868, Best: 0.9871\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 3.639800548553467 | KNN Loss: 3.6068787574768066 | CLS Loss: 0.032921794801950455\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 3.665959596633911 | KNN Loss: 3.6423778533935547 | CLS Loss: 0.023581676185131073\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 3.6695477962493896 | KNN Loss: 3.6489057540893555 | CLS Loss: 0.020642036572098732\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 3.696682929992676 | KNN Loss: 3.668978691101074 | CLS Loss: 0.027704179286956787\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 3.6463749408721924 | KNN Loss: 3.612705707550049 | CLS Loss: 0.03366929292678833\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 3.6231045722961426 | KNN Loss: 3.619088649749756 | CLS Loss: 0.004015847109258175\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 3.675788164138794 | KNN Loss: 3.6694750785827637 | CLS Loss: 0.006313091143965721\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 3.6565446853637695 | KNN Loss: 3.6328952312469482 | CLS Loss: 0.023649534210562706\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 3.650169849395752 | KNN Loss: 3.6249520778656006 | CLS Loss: 0.025217734277248383\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 3.653848886489868 | KNN Loss: 3.6275203227996826 | CLS Loss: 0.026328587904572487\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 3.65450382232666 | KNN Loss: 3.648620128631592 | CLS Loss: 0.005883780773729086\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 3.6514194011688232 | KNN Loss: 3.6394152641296387 | CLS Loss: 0.012004183605313301\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 3.639718770980835 | KNN Loss: 3.6107237339019775 | CLS Loss: 0.028995037078857422\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 3.6880455017089844 | KNN Loss: 3.6625449657440186 | CLS Loss: 0.02550041861832142\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 3.6717722415924072 | KNN Loss: 3.644883394241333 | CLS Loss: 0.026888897642493248\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 3.627605676651001 | KNN Loss: 3.596560478210449 | CLS Loss: 0.03104517050087452\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 3.686173915863037 | KNN Loss: 3.6496167182922363 | CLS Loss: 0.036557238548994064\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 3.639369010925293 | KNN Loss: 3.620074510574341 | CLS Loss: 0.01929461397230625\n",
      "Epoch: 080, Loss: 3.6515, Train: 0.9952, Valid: 0.9866, Best: 0.9871\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 3.621711492538452 | KNN Loss: 3.6099162101745605 | CLS Loss: 0.011795181781053543\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 3.6649246215820312 | KNN Loss: 3.644641160964966 | CLS Loss: 0.020283574238419533\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 3.5967233180999756 | KNN Loss: 3.5899956226348877 | CLS Loss: 0.006727649364620447\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 3.6548750400543213 | KNN Loss: 3.6247096061706543 | CLS Loss: 0.03016548976302147\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 3.628202438354492 | KNN Loss: 3.616243362426758 | CLS Loss: 0.011959109455347061\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 3.6755213737487793 | KNN Loss: 3.670779228210449 | CLS Loss: 0.004742166958749294\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 3.6349294185638428 | KNN Loss: 3.605128049850464 | CLS Loss: 0.02980141155421734\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 3.6249148845672607 | KNN Loss: 3.59891676902771 | CLS Loss: 0.025998227298259735\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 3.6429944038391113 | KNN Loss: 3.6126766204833984 | CLS Loss: 0.03031785786151886\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 3.6372103691101074 | KNN Loss: 3.5958938598632812 | CLS Loss: 0.041316550225019455\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 3.698404312133789 | KNN Loss: 3.6725082397460938 | CLS Loss: 0.025896020233631134\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 3.6361732482910156 | KNN Loss: 3.6227219104766846 | CLS Loss: 0.013451417908072472\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 3.613502025604248 | KNN Loss: 3.599792718887329 | CLS Loss: 0.0137092350050807\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 3.6412103176116943 | KNN Loss: 3.627739429473877 | CLS Loss: 0.013470984064042568\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 3.659583806991577 | KNN Loss: 3.622732162475586 | CLS Loss: 0.03685171902179718\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 3.6222658157348633 | KNN Loss: 3.6123404502868652 | CLS Loss: 0.009925341233611107\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 3.663254499435425 | KNN Loss: 3.6580278873443604 | CLS Loss: 0.0052266851998865604\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 3.7062554359436035 | KNN Loss: 3.653116464614868 | CLS Loss: 0.05313888564705849\n",
      "Epoch: 081, Loss: 3.6501, Train: 0.9950, Valid: 0.9850, Best: 0.9871\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 3.657902240753174 | KNN Loss: 3.6438822746276855 | CLS Loss: 0.014019852504134178\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 3.658939838409424 | KNN Loss: 3.645557403564453 | CLS Loss: 0.01338237151503563\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 3.7003650665283203 | KNN Loss: 3.6496872901916504 | CLS Loss: 0.050677839666604996\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 3.634096622467041 | KNN Loss: 3.615009069442749 | CLS Loss: 0.01908758655190468\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 3.616848945617676 | KNN Loss: 3.60691237449646 | CLS Loss: 0.009936562739312649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 3.6693270206451416 | KNN Loss: 3.64971661567688 | CLS Loss: 0.019610371440649033\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 3.680440902709961 | KNN Loss: 3.6684892177581787 | CLS Loss: 0.011951753869652748\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 3.6179721355438232 | KNN Loss: 3.6015796661376953 | CLS Loss: 0.016392365097999573\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 3.64730167388916 | KNN Loss: 3.6203465461730957 | CLS Loss: 0.02695503830909729\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 3.6373231410980225 | KNN Loss: 3.616776466369629 | CLS Loss: 0.020546643063426018\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 3.655268430709839 | KNN Loss: 3.648651361465454 | CLS Loss: 0.006617000326514244\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 3.67612361907959 | KNN Loss: 3.6556308269500732 | CLS Loss: 0.020492851734161377\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 3.622727394104004 | KNN Loss: 3.609153985977173 | CLS Loss: 0.013573486357927322\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 3.612755298614502 | KNN Loss: 3.606419801712036 | CLS Loss: 0.00633553322404623\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 3.6339046955108643 | KNN Loss: 3.6132352352142334 | CLS Loss: 0.020669542253017426\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 3.7178733348846436 | KNN Loss: 3.6948070526123047 | CLS Loss: 0.023066211491823196\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 3.669487237930298 | KNN Loss: 3.6555097103118896 | CLS Loss: 0.013977634720504284\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 3.6838717460632324 | KNN Loss: 3.6555283069610596 | CLS Loss: 0.02834334596991539\n",
      "Epoch: 082, Loss: 3.6573, Train: 0.9949, Valid: 0.9863, Best: 0.9871\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 3.6911914348602295 | KNN Loss: 3.6704251766204834 | CLS Loss: 0.02076633833348751\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 3.626204490661621 | KNN Loss: 3.608781576156616 | CLS Loss: 0.017422858625650406\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 3.6674256324768066 | KNN Loss: 3.658958911895752 | CLS Loss: 0.008466793224215508\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 3.611469268798828 | KNN Loss: 3.5765984058380127 | CLS Loss: 0.0348709411919117\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 3.6608402729034424 | KNN Loss: 3.641644239425659 | CLS Loss: 0.019196005538105965\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 3.62558650970459 | KNN Loss: 3.6028482913970947 | CLS Loss: 0.02273814007639885\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 3.621112108230591 | KNN Loss: 3.6153109073638916 | CLS Loss: 0.005801253020763397\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 3.671849012374878 | KNN Loss: 3.6375088691711426 | CLS Loss: 0.03434021770954132\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 3.6456198692321777 | KNN Loss: 3.6286215782165527 | CLS Loss: 0.016998229548335075\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 3.606903314590454 | KNN Loss: 3.58835506439209 | CLS Loss: 0.018548160791397095\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 3.643237352371216 | KNN Loss: 3.6339027881622314 | CLS Loss: 0.009334573522210121\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 3.635821580886841 | KNN Loss: 3.6177380084991455 | CLS Loss: 0.01808352582156658\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 3.647275447845459 | KNN Loss: 3.625919818878174 | CLS Loss: 0.02135556749999523\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 3.647345542907715 | KNN Loss: 3.6253538131713867 | CLS Loss: 0.021991640329360962\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 3.663790225982666 | KNN Loss: 3.632624864578247 | CLS Loss: 0.03116532228887081\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 3.621312141418457 | KNN Loss: 3.612049102783203 | CLS Loss: 0.009263123385608196\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 3.632103681564331 | KNN Loss: 3.6125974655151367 | CLS Loss: 0.019506104290485382\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 3.628176212310791 | KNN Loss: 3.6026997566223145 | CLS Loss: 0.02547643519937992\n",
      "Epoch: 083, Loss: 3.6441, Train: 0.9958, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 3.601810932159424 | KNN Loss: 3.594118118286133 | CLS Loss: 0.00769290653988719\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 3.6479570865631104 | KNN Loss: 3.6335067749023438 | CLS Loss: 0.014450288377702236\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 3.6490414142608643 | KNN Loss: 3.62357234954834 | CLS Loss: 0.025469016283750534\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 3.637380361557007 | KNN Loss: 3.62428879737854 | CLS Loss: 0.013091669417917728\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 3.667410135269165 | KNN Loss: 3.648705005645752 | CLS Loss: 0.01870514266192913\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 3.6825413703918457 | KNN Loss: 3.6521990299224854 | CLS Loss: 0.0303422212600708\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 3.637458086013794 | KNN Loss: 3.6308443546295166 | CLS Loss: 0.006613618228584528\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 3.6464011669158936 | KNN Loss: 3.639113187789917 | CLS Loss: 0.007287986576557159\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 3.656451463699341 | KNN Loss: 3.643890857696533 | CLS Loss: 0.012560682371258736\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 3.599637985229492 | KNN Loss: 3.59234619140625 | CLS Loss: 0.007291789632290602\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 3.640151023864746 | KNN Loss: 3.6322853565216064 | CLS Loss: 0.007865682244300842\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 3.6341335773468018 | KNN Loss: 3.6174051761627197 | CLS Loss: 0.016728349030017853\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 3.620194435119629 | KNN Loss: 3.6095924377441406 | CLS Loss: 0.010602098889648914\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 3.6087732315063477 | KNN Loss: 3.5969672203063965 | CLS Loss: 0.011805898509919643\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 3.66841721534729 | KNN Loss: 3.6568613052368164 | CLS Loss: 0.011556021869182587\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 3.662721633911133 | KNN Loss: 3.6304407119750977 | CLS Loss: 0.032281018793582916\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 3.6301727294921875 | KNN Loss: 3.627214193344116 | CLS Loss: 0.0029585000593215227\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 3.5926947593688965 | KNN Loss: 3.5896079540252686 | CLS Loss: 0.0030867436435073614\n",
      "Epoch: 084, Loss: 3.6427, Train: 0.9962, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 3.602104902267456 | KNN Loss: 3.578690767288208 | CLS Loss: 0.023414157330989838\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 3.6062874794006348 | KNN Loss: 3.5975534915924072 | CLS Loss: 0.008733965456485748\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 3.613598346710205 | KNN Loss: 3.6053435802459717 | CLS Loss: 0.008254696615040302\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 3.629648208618164 | KNN Loss: 3.620856523513794 | CLS Loss: 0.00879178661853075\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 3.649702548980713 | KNN Loss: 3.641864776611328 | CLS Loss: 0.00783772673457861\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 3.6780245304107666 | KNN Loss: 3.665985584259033 | CLS Loss: 0.012038961984217167\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 3.6385462284088135 | KNN Loss: 3.624924421310425 | CLS Loss: 0.013621754944324493\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 3.65039324760437 | KNN Loss: 3.6246635913848877 | CLS Loss: 0.0257295873016119\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 3.6558752059936523 | KNN Loss: 3.624288320541382 | CLS Loss: 0.03158681094646454\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 3.7130866050720215 | KNN Loss: 3.676163911819458 | CLS Loss: 0.03692276030778885\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 3.6621768474578857 | KNN Loss: 3.6473779678344727 | CLS Loss: 0.014798827469348907\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 3.656294345855713 | KNN Loss: 3.637202501296997 | CLS Loss: 0.01909184642136097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 3.710954427719116 | KNN Loss: 3.6796069145202637 | CLS Loss: 0.031347621232271194\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 3.6440553665161133 | KNN Loss: 3.63805890083313 | CLS Loss: 0.005996455438435078\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 3.621293544769287 | KNN Loss: 3.6140012741088867 | CLS Loss: 0.007292275782674551\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 3.638615369796753 | KNN Loss: 3.624866247177124 | CLS Loss: 0.013749146834015846\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 3.6559500694274902 | KNN Loss: 3.633148193359375 | CLS Loss: 0.02280183508992195\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 3.66935133934021 | KNN Loss: 3.6571555137634277 | CLS Loss: 0.012195764109492302\n",
      "Epoch: 085, Loss: 3.6441, Train: 0.9932, Valid: 0.9849, Best: 0.9873\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 3.624724864959717 | KNN Loss: 3.612138271331787 | CLS Loss: 0.012586616910994053\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 3.6173794269561768 | KNN Loss: 3.5984153747558594 | CLS Loss: 0.018963949754834175\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 3.62218976020813 | KNN Loss: 3.5986595153808594 | CLS Loss: 0.02353014051914215\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 3.6240787506103516 | KNN Loss: 3.6094601154327393 | CLS Loss: 0.014618579298257828\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 3.6396453380584717 | KNN Loss: 3.6061148643493652 | CLS Loss: 0.0335305891931057\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 3.642817258834839 | KNN Loss: 3.6145596504211426 | CLS Loss: 0.028257519006729126\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 3.6351659297943115 | KNN Loss: 3.6205637454986572 | CLS Loss: 0.014602106995880604\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 3.6051266193389893 | KNN Loss: 3.588120222091675 | CLS Loss: 0.017006289213895798\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 3.656646251678467 | KNN Loss: 3.6442015171051025 | CLS Loss: 0.012444733642041683\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 3.6559321880340576 | KNN Loss: 3.6278810501098633 | CLS Loss: 0.0280512273311615\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 3.644587755203247 | KNN Loss: 3.6231179237365723 | CLS Loss: 0.02146989293396473\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 3.705487012863159 | KNN Loss: 3.672750473022461 | CLS Loss: 0.032736651599407196\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 3.669215202331543 | KNN Loss: 3.6375420093536377 | CLS Loss: 0.03167325630784035\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 3.661311626434326 | KNN Loss: 3.6446611881256104 | CLS Loss: 0.016650322824716568\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 3.6641860008239746 | KNN Loss: 3.629945755004883 | CLS Loss: 0.03424036130309105\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 3.599745512008667 | KNN Loss: 3.593271017074585 | CLS Loss: 0.006474541034549475\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 3.6395785808563232 | KNN Loss: 3.6295812129974365 | CLS Loss: 0.009997311048209667\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 3.6028199195861816 | KNN Loss: 3.586425542831421 | CLS Loss: 0.01639436185359955\n",
      "Epoch: 086, Loss: 3.6453, Train: 0.9950, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 3.680168628692627 | KNN Loss: 3.6488094329833984 | CLS Loss: 0.03135911747813225\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 3.6537153720855713 | KNN Loss: 3.629809856414795 | CLS Loss: 0.023905564099550247\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 3.624526023864746 | KNN Loss: 3.615875005722046 | CLS Loss: 0.008650993928313255\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 3.6429810523986816 | KNN Loss: 3.639826774597168 | CLS Loss: 0.0031541672069579363\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 3.6542129516601562 | KNN Loss: 3.636488914489746 | CLS Loss: 0.017723925411701202\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 3.629944086074829 | KNN Loss: 3.616847515106201 | CLS Loss: 0.013096651062369347\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 3.6266555786132812 | KNN Loss: 3.602858066558838 | CLS Loss: 0.02379756234586239\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 3.6733055114746094 | KNN Loss: 3.6332101821899414 | CLS Loss: 0.040095310658216476\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 3.638915777206421 | KNN Loss: 3.63080096244812 | CLS Loss: 0.008114742115139961\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 3.622997760772705 | KNN Loss: 3.6084625720977783 | CLS Loss: 0.01453509833663702\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 3.6003658771514893 | KNN Loss: 3.5990397930145264 | CLS Loss: 0.0013260040432214737\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 3.623541831970215 | KNN Loss: 3.6113228797912598 | CLS Loss: 0.01221904531121254\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 3.6736321449279785 | KNN Loss: 3.63025164604187 | CLS Loss: 0.04338045418262482\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 3.671370029449463 | KNN Loss: 3.654486894607544 | CLS Loss: 0.016883250325918198\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 3.6387720108032227 | KNN Loss: 3.604193925857544 | CLS Loss: 0.03457812964916229\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 3.6662449836730957 | KNN Loss: 3.6471691131591797 | CLS Loss: 0.01907576248049736\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 3.606691837310791 | KNN Loss: 3.591292142868042 | CLS Loss: 0.01539967767894268\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 3.6271092891693115 | KNN Loss: 3.606747627258301 | CLS Loss: 0.02036159299314022\n",
      "Epoch: 087, Loss: 3.6417, Train: 0.9951, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 3.645714044570923 | KNN Loss: 3.64266300201416 | CLS Loss: 0.003050954779610038\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 3.6954703330993652 | KNN Loss: 3.6700215339660645 | CLS Loss: 0.025448746979236603\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 3.600404739379883 | KNN Loss: 3.587470293045044 | CLS Loss: 0.012934477999806404\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 3.6722214221954346 | KNN Loss: 3.6400306224823 | CLS Loss: 0.0321907214820385\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 3.6451945304870605 | KNN Loss: 3.638532876968384 | CLS Loss: 0.006661687977612019\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 3.676046133041382 | KNN Loss: 3.655803918838501 | CLS Loss: 0.020242225378751755\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 3.639374017715454 | KNN Loss: 3.619159698486328 | CLS Loss: 0.020214375108480453\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 3.6283347606658936 | KNN Loss: 3.61570405960083 | CLS Loss: 0.01263066753745079\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 3.6424858570098877 | KNN Loss: 3.609952926635742 | CLS Loss: 0.032532814890146255\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 3.643455743789673 | KNN Loss: 3.5983266830444336 | CLS Loss: 0.045128993690013885\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 3.618269681930542 | KNN Loss: 3.607640504837036 | CLS Loss: 0.010629130527377129\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 3.6440303325653076 | KNN Loss: 3.623701810836792 | CLS Loss: 0.020328594371676445\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 3.6797871589660645 | KNN Loss: 3.6638033390045166 | CLS Loss: 0.015983862802386284\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 3.64506459236145 | KNN Loss: 3.6382460594177246 | CLS Loss: 0.006818585563451052\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 3.6222243309020996 | KNN Loss: 3.617083787918091 | CLS Loss: 0.005140600726008415\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 3.6391282081604004 | KNN Loss: 3.6238656044006348 | CLS Loss: 0.015262624248862267\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 3.6456615924835205 | KNN Loss: 3.6326181888580322 | CLS Loss: 0.013043304905295372\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 3.619323492050171 | KNN Loss: 3.592595100402832 | CLS Loss: 0.02672846056520939\n",
      "Epoch: 088, Loss: 3.6436, Train: 0.9942, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 3.674119234085083 | KNN Loss: 3.656846761703491 | CLS Loss: 0.017272530123591423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 3.6185052394866943 | KNN Loss: 3.606656551361084 | CLS Loss: 0.011848701164126396\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 3.6562089920043945 | KNN Loss: 3.6352710723876953 | CLS Loss: 0.02093781717121601\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 3.7009100914001465 | KNN Loss: 3.6621413230895996 | CLS Loss: 0.038768887519836426\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 3.687605857849121 | KNN Loss: 3.667494773864746 | CLS Loss: 0.02011103183031082\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 3.594698905944824 | KNN Loss: 3.573939561843872 | CLS Loss: 0.02075928822159767\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 3.657963275909424 | KNN Loss: 3.635880947113037 | CLS Loss: 0.022082427516579628\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 3.621464252471924 | KNN Loss: 3.6160178184509277 | CLS Loss: 0.0054463171400129795\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 3.648895502090454 | KNN Loss: 3.61338210105896 | CLS Loss: 0.03551335260272026\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 3.6490206718444824 | KNN Loss: 3.6266069412231445 | CLS Loss: 0.022413766011595726\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 3.6246156692504883 | KNN Loss: 3.6134748458862305 | CLS Loss: 0.01114073395729065\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 3.626326560974121 | KNN Loss: 3.601698160171509 | CLS Loss: 0.02462834119796753\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 3.6129796504974365 | KNN Loss: 3.5786728858947754 | CLS Loss: 0.034306786954402924\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 3.654986619949341 | KNN Loss: 3.6311681270599365 | CLS Loss: 0.023818401619791985\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 3.634432315826416 | KNN Loss: 3.6258552074432373 | CLS Loss: 0.008577169850468636\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 3.630584239959717 | KNN Loss: 3.6127326488494873 | CLS Loss: 0.017851650714874268\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 3.644996166229248 | KNN Loss: 3.637585163116455 | CLS Loss: 0.007411085534840822\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 3.6548614501953125 | KNN Loss: 3.645643711090088 | CLS Loss: 0.009217717684805393\n",
      "Epoch: 089, Loss: 3.6432, Train: 0.9960, Valid: 0.9875, Best: 0.9875\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 3.600818157196045 | KNN Loss: 3.5963571071624756 | CLS Loss: 0.00446105794981122\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 3.6019043922424316 | KNN Loss: 3.5857393741607666 | CLS Loss: 0.016165079548954964\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 3.651921272277832 | KNN Loss: 3.6273202896118164 | CLS Loss: 0.024601072072982788\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 3.6190645694732666 | KNN Loss: 3.6023364067077637 | CLS Loss: 0.016728078946471214\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 3.632110118865967 | KNN Loss: 3.620159864425659 | CLS Loss: 0.011950177140533924\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 3.6432766914367676 | KNN Loss: 3.6339643001556396 | CLS Loss: 0.0093124033883214\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 3.597572088241577 | KNN Loss: 3.593324899673462 | CLS Loss: 0.004247185308486223\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 3.6685245037078857 | KNN Loss: 3.6455156803131104 | CLS Loss: 0.02300887554883957\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 3.6767778396606445 | KNN Loss: 3.642787456512451 | CLS Loss: 0.03399044647812843\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 3.646899938583374 | KNN Loss: 3.612154006958008 | CLS Loss: 0.03474584221839905\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 3.6342358589172363 | KNN Loss: 3.6099867820739746 | CLS Loss: 0.024249175563454628\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 3.625 | KNN Loss: 3.615004539489746 | CLS Loss: 0.009995512664318085\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 3.657604694366455 | KNN Loss: 3.642650604248047 | CLS Loss: 0.014954090118408203\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 3.6336989402770996 | KNN Loss: 3.6261746883392334 | CLS Loss: 0.007524152286350727\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 3.6300978660583496 | KNN Loss: 3.619230031967163 | CLS Loss: 0.010867834091186523\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 3.638129949569702 | KNN Loss: 3.614828109741211 | CLS Loss: 0.023301899433135986\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 3.6190578937530518 | KNN Loss: 3.599226713180542 | CLS Loss: 0.019831065088510513\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 3.613708019256592 | KNN Loss: 3.598177909851074 | CLS Loss: 0.015530018135905266\n",
      "Epoch: 090, Loss: 3.6404, Train: 0.9948, Valid: 0.9864, Best: 0.9875\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 3.628600835800171 | KNN Loss: 3.6032814979553223 | CLS Loss: 0.025319376960396767\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 3.6360833644866943 | KNN Loss: 3.6292593479156494 | CLS Loss: 0.00682405661791563\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 3.6150317192077637 | KNN Loss: 3.599266529083252 | CLS Loss: 0.015765070915222168\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 3.638768196105957 | KNN Loss: 3.619729995727539 | CLS Loss: 0.019038263708353043\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 3.6494152545928955 | KNN Loss: 3.644887685775757 | CLS Loss: 0.004527477081865072\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 3.612847328186035 | KNN Loss: 3.60719895362854 | CLS Loss: 0.005648410879075527\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 3.6357131004333496 | KNN Loss: 3.619807720184326 | CLS Loss: 0.01590549573302269\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 3.649230480194092 | KNN Loss: 3.635129451751709 | CLS Loss: 0.014101081527769566\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 3.6519861221313477 | KNN Loss: 3.6303486824035645 | CLS Loss: 0.021637478843331337\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 3.6111197471618652 | KNN Loss: 3.58652400970459 | CLS Loss: 0.024595754221081734\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 3.6760833263397217 | KNN Loss: 3.649965763092041 | CLS Loss: 0.026117581874132156\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 3.6463491916656494 | KNN Loss: 3.6314494609832764 | CLS Loss: 0.014899740926921368\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 3.633345603942871 | KNN Loss: 3.6222124099731445 | CLS Loss: 0.011133244261145592\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 3.6380412578582764 | KNN Loss: 3.6262285709381104 | CLS Loss: 0.01181261520832777\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 3.613199234008789 | KNN Loss: 3.6050283908843994 | CLS Loss: 0.00817087385803461\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 3.659710168838501 | KNN Loss: 3.6337432861328125 | CLS Loss: 0.025966892018914223\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 3.636329174041748 | KNN Loss: 3.6281626224517822 | CLS Loss: 0.008166645653545856\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 3.631693124771118 | KNN Loss: 3.6049246788024902 | CLS Loss: 0.02676837146282196\n",
      "Epoch: 091, Loss: 3.6409, Train: 0.9951, Valid: 0.9860, Best: 0.9875\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 3.660163640975952 | KNN Loss: 3.652153968811035 | CLS Loss: 0.008009558543562889\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 3.61635422706604 | KNN Loss: 3.608772039413452 | CLS Loss: 0.007582251448184252\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 3.6619575023651123 | KNN Loss: 3.642531394958496 | CLS Loss: 0.01942620240151882\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 3.679694652557373 | KNN Loss: 3.6549837589263916 | CLS Loss: 0.024710889905691147\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 3.6181788444519043 | KNN Loss: 3.601047992706299 | CLS Loss: 0.017130907624959946\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 3.643908977508545 | KNN Loss: 3.6260030269622803 | CLS Loss: 0.017905835062265396\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 3.6351025104522705 | KNN Loss: 3.627716064453125 | CLS Loss: 0.007386563345789909\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 3.6189138889312744 | KNN Loss: 3.61112904548645 | CLS Loss: 0.0077848839573562145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 3.6609861850738525 | KNN Loss: 3.633877754211426 | CLS Loss: 0.02710840106010437\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 3.6494057178497314 | KNN Loss: 3.6150572299957275 | CLS Loss: 0.0343485027551651\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 3.6334824562072754 | KNN Loss: 3.6219983100891113 | CLS Loss: 0.011484050191938877\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 3.658475160598755 | KNN Loss: 3.627619504928589 | CLS Loss: 0.03085567243397236\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 3.6442413330078125 | KNN Loss: 3.625507116317749 | CLS Loss: 0.01873416267335415\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 3.648421049118042 | KNN Loss: 3.6352591514587402 | CLS Loss: 0.013161790557205677\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 3.6441667079925537 | KNN Loss: 3.634119749069214 | CLS Loss: 0.010047038085758686\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 3.66007137298584 | KNN Loss: 3.6403985023498535 | CLS Loss: 0.019672859460115433\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 3.6552343368530273 | KNN Loss: 3.632049322128296 | CLS Loss: 0.023184940218925476\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 3.694509506225586 | KNN Loss: 3.652843952178955 | CLS Loss: 0.04166567325592041\n",
      "Epoch: 092, Loss: 3.6453, Train: 0.9953, Valid: 0.9867, Best: 0.9875\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 3.655750274658203 | KNN Loss: 3.6420412063598633 | CLS Loss: 0.01370905339717865\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 3.6382219791412354 | KNN Loss: 3.6316559314727783 | CLS Loss: 0.006566096097230911\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 3.6304469108581543 | KNN Loss: 3.5972018241882324 | CLS Loss: 0.033245135098695755\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 3.6237728595733643 | KNN Loss: 3.612691640853882 | CLS Loss: 0.011081223376095295\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 3.6407580375671387 | KNN Loss: 3.6250252723693848 | CLS Loss: 0.015732882544398308\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 3.681011915206909 | KNN Loss: 3.6528544425964355 | CLS Loss: 0.028157444670796394\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 3.644759178161621 | KNN Loss: 3.626767158508301 | CLS Loss: 0.017992036417126656\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 3.686567544937134 | KNN Loss: 3.6693544387817383 | CLS Loss: 0.01721314713358879\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 3.6706175804138184 | KNN Loss: 3.6612777709960938 | CLS Loss: 0.009339733049273491\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 3.666188955307007 | KNN Loss: 3.643815755844116 | CLS Loss: 0.022373119369149208\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 3.6255815029144287 | KNN Loss: 3.604003429412842 | CLS Loss: 0.021578127518296242\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 3.6534221172332764 | KNN Loss: 3.6224639415740967 | CLS Loss: 0.03095817193388939\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 3.683924436569214 | KNN Loss: 3.6514029502868652 | CLS Loss: 0.0325215682387352\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 3.646383762359619 | KNN Loss: 3.6320676803588867 | CLS Loss: 0.014316128566861153\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 3.6275649070739746 | KNN Loss: 3.6140923500061035 | CLS Loss: 0.013472660444676876\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 3.6526033878326416 | KNN Loss: 3.6236305236816406 | CLS Loss: 0.028972890228033066\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 3.6372628211975098 | KNN Loss: 3.605802536010742 | CLS Loss: 0.03146030753850937\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 3.6853556632995605 | KNN Loss: 3.668166399002075 | CLS Loss: 0.01718936674296856\n",
      "Epoch: 093, Loss: 3.6461, Train: 0.9954, Valid: 0.9864, Best: 0.9875\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 3.6148834228515625 | KNN Loss: 3.5983200073242188 | CLS Loss: 0.016563517972826958\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 3.6176061630249023 | KNN Loss: 3.6002864837646484 | CLS Loss: 0.017319608479738235\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 3.6350412368774414 | KNN Loss: 3.6194427013397217 | CLS Loss: 0.015598420985043049\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 3.639997720718384 | KNN Loss: 3.629638195037842 | CLS Loss: 0.010359428822994232\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 3.6617465019226074 | KNN Loss: 3.655092477798462 | CLS Loss: 0.006654075346887112\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 3.5877935886383057 | KNN Loss: 3.5820834636688232 | CLS Loss: 0.005710137542337179\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 3.640857219696045 | KNN Loss: 3.612666606903076 | CLS Loss: 0.0281907320022583\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 3.595782995223999 | KNN Loss: 3.584074020385742 | CLS Loss: 0.011709017679095268\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 3.6264877319335938 | KNN Loss: 3.595747947692871 | CLS Loss: 0.030739838257431984\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 3.6301496028900146 | KNN Loss: 3.612450122833252 | CLS Loss: 0.017699507996439934\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 3.6375505924224854 | KNN Loss: 3.61976957321167 | CLS Loss: 0.017781024798750877\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 3.6265108585357666 | KNN Loss: 3.6071228981018066 | CLS Loss: 0.019387930631637573\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 3.652218818664551 | KNN Loss: 3.6355278491973877 | CLS Loss: 0.01669100485742092\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 3.6331987380981445 | KNN Loss: 3.621382474899292 | CLS Loss: 0.011816325597465038\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 3.6348793506622314 | KNN Loss: 3.6240460872650146 | CLS Loss: 0.01083330623805523\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 3.644986152648926 | KNN Loss: 3.6254124641418457 | CLS Loss: 0.019573623314499855\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 3.6298131942749023 | KNN Loss: 3.623220443725586 | CLS Loss: 0.006592797115445137\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 3.654278039932251 | KNN Loss: 3.633676290512085 | CLS Loss: 0.02060163952410221\n",
      "Epoch: 094, Loss: 3.6391, Train: 0.9955, Valid: 0.9865, Best: 0.9875\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 3.716564893722534 | KNN Loss: 3.705665349960327 | CLS Loss: 0.010899445042014122\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 3.6835319995880127 | KNN Loss: 3.664503574371338 | CLS Loss: 0.01902850717306137\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 3.66949462890625 | KNN Loss: 3.6289045810699463 | CLS Loss: 0.040590014308691025\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 3.634119987487793 | KNN Loss: 3.622723340988159 | CLS Loss: 0.011396700516343117\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 3.646178722381592 | KNN Loss: 3.638759136199951 | CLS Loss: 0.007419544272124767\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 3.6077725887298584 | KNN Loss: 3.5995171070098877 | CLS Loss: 0.008255555294454098\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 3.616255283355713 | KNN Loss: 3.6097207069396973 | CLS Loss: 0.006534646265208721\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 3.620696783065796 | KNN Loss: 3.59086012840271 | CLS Loss: 0.029836583882570267\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 3.6381521224975586 | KNN Loss: 3.6316611766815186 | CLS Loss: 0.006491045001894236\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 3.642970323562622 | KNN Loss: 3.6362314224243164 | CLS Loss: 0.0067388215102255344\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 3.6612889766693115 | KNN Loss: 3.6485533714294434 | CLS Loss: 0.012735648080706596\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 3.7012619972229004 | KNN Loss: 3.6790947914123535 | CLS Loss: 0.02216728776693344\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 3.626793622970581 | KNN Loss: 3.6150636672973633 | CLS Loss: 0.01173001155257225\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 3.6881444454193115 | KNN Loss: 3.6742489337921143 | CLS Loss: 0.0138956094160676\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 3.6430299282073975 | KNN Loss: 3.624021053314209 | CLS Loss: 0.01900891400873661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 3.6398766040802 | KNN Loss: 3.6279990673065186 | CLS Loss: 0.011877420358359814\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 3.6895132064819336 | KNN Loss: 3.673330068588257 | CLS Loss: 0.01618315279483795\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 3.6631927490234375 | KNN Loss: 3.6479098796844482 | CLS Loss: 0.015282964333891869\n",
      "Epoch: 095, Loss: 3.6446, Train: 0.9958, Valid: 0.9865, Best: 0.9875\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 3.6321237087249756 | KNN Loss: 3.6211249828338623 | CLS Loss: 0.010998680256307125\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 3.65777587890625 | KNN Loss: 3.6440787315368652 | CLS Loss: 0.013697213493287563\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 3.624239444732666 | KNN Loss: 3.6049747467041016 | CLS Loss: 0.019264714792370796\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 3.6720454692840576 | KNN Loss: 3.6416194438934326 | CLS Loss: 0.03042605333030224\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 3.626620292663574 | KNN Loss: 3.6176035404205322 | CLS Loss: 0.009016776457428932\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 3.5902159214019775 | KNN Loss: 3.5838139057159424 | CLS Loss: 0.006402053404599428\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 3.6545145511627197 | KNN Loss: 3.620204210281372 | CLS Loss: 0.03431027755141258\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 3.6362459659576416 | KNN Loss: 3.611841917037964 | CLS Loss: 0.024404160678386688\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 3.678539752960205 | KNN Loss: 3.665241241455078 | CLS Loss: 0.013298521749675274\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 3.671980857849121 | KNN Loss: 3.653470516204834 | CLS Loss: 0.018510449677705765\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 3.647453546524048 | KNN Loss: 3.6089084148406982 | CLS Loss: 0.0385451540350914\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 3.6378350257873535 | KNN Loss: 3.631455421447754 | CLS Loss: 0.006379695143550634\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 3.626361608505249 | KNN Loss: 3.61366868019104 | CLS Loss: 0.012692962773144245\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 3.6500816345214844 | KNN Loss: 3.6345067024230957 | CLS Loss: 0.015574892982840538\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 3.650226593017578 | KNN Loss: 3.642754316329956 | CLS Loss: 0.007472209166735411\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 3.6445508003234863 | KNN Loss: 3.6398251056671143 | CLS Loss: 0.004725578706711531\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 3.643705368041992 | KNN Loss: 3.6048498153686523 | CLS Loss: 0.0388556532561779\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 3.6401991844177246 | KNN Loss: 3.6091203689575195 | CLS Loss: 0.031078921630978584\n",
      "Epoch: 096, Loss: 3.6406, Train: 0.9965, Valid: 0.9863, Best: 0.9875\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 3.630345106124878 | KNN Loss: 3.6082944869995117 | CLS Loss: 0.022050512954592705\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 3.6409711837768555 | KNN Loss: 3.6269218921661377 | CLS Loss: 0.014049320481717587\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 3.6143341064453125 | KNN Loss: 3.600172758102417 | CLS Loss: 0.014161268249154091\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 3.6451048851013184 | KNN Loss: 3.6288700103759766 | CLS Loss: 0.01623481884598732\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 3.6552956104278564 | KNN Loss: 3.6452832221984863 | CLS Loss: 0.010012274608016014\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 3.615302562713623 | KNN Loss: 3.610267162322998 | CLS Loss: 0.005035303998738527\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 3.655329465866089 | KNN Loss: 3.636944532394409 | CLS Loss: 0.018384868279099464\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 3.624014377593994 | KNN Loss: 3.604560375213623 | CLS Loss: 0.019454002380371094\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 3.6209347248077393 | KNN Loss: 3.615894079208374 | CLS Loss: 0.00504068098962307\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 3.638334035873413 | KNN Loss: 3.6223106384277344 | CLS Loss: 0.016023514792323112\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 3.6474907398223877 | KNN Loss: 3.6185803413391113 | CLS Loss: 0.028910309076309204\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 3.6498100757598877 | KNN Loss: 3.630308151245117 | CLS Loss: 0.01950191706418991\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 3.6702051162719727 | KNN Loss: 3.6517791748046875 | CLS Loss: 0.01842598430812359\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 3.6317927837371826 | KNN Loss: 3.612821102142334 | CLS Loss: 0.018971595913171768\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 3.6562983989715576 | KNN Loss: 3.641451835632324 | CLS Loss: 0.014846513979136944\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 3.622272491455078 | KNN Loss: 3.601016044616699 | CLS Loss: 0.02125639282166958\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 3.6307597160339355 | KNN Loss: 3.61051607131958 | CLS Loss: 0.02024361677467823\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 3.6442675590515137 | KNN Loss: 3.6283130645751953 | CLS Loss: 0.015954531729221344\n",
      "Epoch: 097, Loss: 3.6392, Train: 0.9953, Valid: 0.9855, Best: 0.9875\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 3.6439523696899414 | KNN Loss: 3.6384828090667725 | CLS Loss: 0.005469669587910175\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 3.6510167121887207 | KNN Loss: 3.6329545974731445 | CLS Loss: 0.018062110990285873\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 3.6279852390289307 | KNN Loss: 3.609910488128662 | CLS Loss: 0.018074804916977882\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 3.6621081829071045 | KNN Loss: 3.6451711654663086 | CLS Loss: 0.016937073320150375\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 3.6402995586395264 | KNN Loss: 3.6272976398468018 | CLS Loss: 0.013001845218241215\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 3.662324905395508 | KNN Loss: 3.639845371246338 | CLS Loss: 0.02247951552271843\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 3.601560592651367 | KNN Loss: 3.586150646209717 | CLS Loss: 0.015409953892230988\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 3.676481008529663 | KNN Loss: 3.652738094329834 | CLS Loss: 0.023742957040667534\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 3.663909912109375 | KNN Loss: 3.6461691856384277 | CLS Loss: 0.017740817740559578\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 3.6715519428253174 | KNN Loss: 3.649691104888916 | CLS Loss: 0.021860871464014053\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 3.63318133354187 | KNN Loss: 3.6157784461975098 | CLS Loss: 0.017402898520231247\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 3.6083009243011475 | KNN Loss: 3.5856220722198486 | CLS Loss: 0.02267894707620144\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 3.6574389934539795 | KNN Loss: 3.647728443145752 | CLS Loss: 0.00971065741032362\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 3.6438088417053223 | KNN Loss: 3.6339006423950195 | CLS Loss: 0.009908126667141914\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 3.636857509613037 | KNN Loss: 3.6287057399749756 | CLS Loss: 0.00815177708864212\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 3.631904125213623 | KNN Loss: 3.609691858291626 | CLS Loss: 0.022212259471416473\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 3.624410390853882 | KNN Loss: 3.601087808609009 | CLS Loss: 0.023322492837905884\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 3.621170997619629 | KNN Loss: 3.6102676391601562 | CLS Loss: 0.010903310030698776\n",
      "Epoch: 098, Loss: 3.6396, Train: 0.9961, Valid: 0.9865, Best: 0.9875\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 3.640357255935669 | KNN Loss: 3.6106510162353516 | CLS Loss: 0.02970617264509201\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 3.6314539909362793 | KNN Loss: 3.622008800506592 | CLS Loss: 0.00944509543478489\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 3.617119312286377 | KNN Loss: 3.608468770980835 | CLS Loss: 0.008650611154735088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 3.590543746948242 | KNN Loss: 3.574340581893921 | CLS Loss: 0.016203269362449646\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 3.664567708969116 | KNN Loss: 3.6438872814178467 | CLS Loss: 0.02068045176565647\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 3.652207851409912 | KNN Loss: 3.617781162261963 | CLS Loss: 0.0344267301261425\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 3.632126808166504 | KNN Loss: 3.613577127456665 | CLS Loss: 0.018549608066678047\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 3.626056671142578 | KNN Loss: 3.6199591159820557 | CLS Loss: 0.006097497418522835\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 3.6516902446746826 | KNN Loss: 3.6312856674194336 | CLS Loss: 0.020404508337378502\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 3.620685338973999 | KNN Loss: 3.6141581535339355 | CLS Loss: 0.006527135148644447\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 3.6380841732025146 | KNN Loss: 3.632899761199951 | CLS Loss: 0.005184513982385397\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 3.6294500827789307 | KNN Loss: 3.6102302074432373 | CLS Loss: 0.01921992003917694\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 3.6592776775360107 | KNN Loss: 3.6469228267669678 | CLS Loss: 0.012354924343526363\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 3.6624367237091064 | KNN Loss: 3.6279239654541016 | CLS Loss: 0.03451279550790787\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 3.6118991374969482 | KNN Loss: 3.5992255210876465 | CLS Loss: 0.012673672288656235\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 3.614112377166748 | KNN Loss: 3.5913302898406982 | CLS Loss: 0.02278212457895279\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 3.59657621383667 | KNN Loss: 3.5787737369537354 | CLS Loss: 0.0178024061024189\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 3.593940258026123 | KNN Loss: 3.5820040702819824 | CLS Loss: 0.011936236172914505\n",
      "Epoch: 099, Loss: 3.6356, Train: 0.9956, Valid: 0.9866, Best: 0.9875\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 3.6427721977233887 | KNN Loss: 3.634589672088623 | CLS Loss: 0.008182581514120102\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 3.6335108280181885 | KNN Loss: 3.6252145767211914 | CLS Loss: 0.008296257816255093\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 3.6340198516845703 | KNN Loss: 3.628706216812134 | CLS Loss: 0.005313740577548742\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 3.6050140857696533 | KNN Loss: 3.592604637145996 | CLS Loss: 0.012409524992108345\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 3.601165771484375 | KNN Loss: 3.5931131839752197 | CLS Loss: 0.00805262103676796\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 3.6157279014587402 | KNN Loss: 3.5901219844818115 | CLS Loss: 0.025605812668800354\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 3.6332809925079346 | KNN Loss: 3.625877618789673 | CLS Loss: 0.007403383497148752\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 3.5909688472747803 | KNN Loss: 3.5850462913513184 | CLS Loss: 0.005922654177993536\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 3.606240749359131 | KNN Loss: 3.6005992889404297 | CLS Loss: 0.005641561467200518\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 3.6883010864257812 | KNN Loss: 3.6800880432128906 | CLS Loss: 0.008213071152567863\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 3.6140289306640625 | KNN Loss: 3.604794502258301 | CLS Loss: 0.009234357625246048\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 3.6527788639068604 | KNN Loss: 3.64028263092041 | CLS Loss: 0.012496246956288815\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 3.6168384552001953 | KNN Loss: 3.611147165298462 | CLS Loss: 0.005691293627023697\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 3.6405844688415527 | KNN Loss: 3.6256051063537598 | CLS Loss: 0.014979270286858082\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 3.6780903339385986 | KNN Loss: 3.6471798419952393 | CLS Loss: 0.03091040439903736\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 3.632322311401367 | KNN Loss: 3.6266534328460693 | CLS Loss: 0.005668879486620426\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 3.703761577606201 | KNN Loss: 3.681417465209961 | CLS Loss: 0.0223441943526268\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 3.7042698860168457 | KNN Loss: 3.693009853363037 | CLS Loss: 0.011259973980486393\n",
      "Epoch: 100, Loss: 3.6356, Train: 0.9946, Valid: 0.9862, Best: 0.9875\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 3.6604878902435303 | KNN Loss: 3.6458685398101807 | CLS Loss: 0.014619407244026661\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 3.646118402481079 | KNN Loss: 3.615673542022705 | CLS Loss: 0.030444948002696037\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 3.6338181495666504 | KNN Loss: 3.6082651615142822 | CLS Loss: 0.025553051382303238\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 3.626145601272583 | KNN Loss: 3.6217617988586426 | CLS Loss: 0.004383921157568693\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 3.634497880935669 | KNN Loss: 3.630978584289551 | CLS Loss: 0.003519413061439991\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 3.6730754375457764 | KNN Loss: 3.634673833847046 | CLS Loss: 0.03840159252285957\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 3.660654306411743 | KNN Loss: 3.6457295417785645 | CLS Loss: 0.014924652874469757\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 3.6426146030426025 | KNN Loss: 3.6132869720458984 | CLS Loss: 0.029327640309929848\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 3.6386444568634033 | KNN Loss: 3.6156654357910156 | CLS Loss: 0.02297896519303322\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 3.6380059719085693 | KNN Loss: 3.6287851333618164 | CLS Loss: 0.009220818988978863\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 3.6135716438293457 | KNN Loss: 3.6049160957336426 | CLS Loss: 0.00865558534860611\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 3.637059211730957 | KNN Loss: 3.632507085800171 | CLS Loss: 0.004552143160253763\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 3.627717971801758 | KNN Loss: 3.602647542953491 | CLS Loss: 0.02507035806775093\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 3.6944899559020996 | KNN Loss: 3.686636209487915 | CLS Loss: 0.007853729650378227\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 3.636603832244873 | KNN Loss: 3.6214771270751953 | CLS Loss: 0.015126739628612995\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 3.637869358062744 | KNN Loss: 3.620361328125 | CLS Loss: 0.017507921904325485\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 3.6102027893066406 | KNN Loss: 3.599642276763916 | CLS Loss: 0.01056046225130558\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 3.6589884757995605 | KNN Loss: 3.642486095428467 | CLS Loss: 0.01650233566761017\n",
      "Epoch: 101, Loss: 3.6493, Train: 0.9947, Valid: 0.9852, Best: 0.9875\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 3.6531527042388916 | KNN Loss: 3.6438722610473633 | CLS Loss: 0.0092803705483675\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 3.6490864753723145 | KNN Loss: 3.6335999965667725 | CLS Loss: 0.015486383810639381\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 3.64313006401062 | KNN Loss: 3.632833242416382 | CLS Loss: 0.010296848602592945\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 3.611628770828247 | KNN Loss: 3.608888626098633 | CLS Loss: 0.0027400339022278786\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 3.635063648223877 | KNN Loss: 3.6238484382629395 | CLS Loss: 0.011215237900614738\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 3.6357579231262207 | KNN Loss: 3.6283137798309326 | CLS Loss: 0.007444249466061592\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 3.603825807571411 | KNN Loss: 3.591115951538086 | CLS Loss: 0.01270987931638956\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 3.6161062717437744 | KNN Loss: 3.6035544872283936 | CLS Loss: 0.012551872059702873\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 3.6300923824310303 | KNN Loss: 3.613197088241577 | CLS Loss: 0.01689525879919529\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 3.6864330768585205 | KNN Loss: 3.676084518432617 | CLS Loss: 0.010348559357225895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 3.598004102706909 | KNN Loss: 3.5810935497283936 | CLS Loss: 0.016910653561353683\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 3.6251959800720215 | KNN Loss: 3.615276336669922 | CLS Loss: 0.009919758886098862\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 3.6302168369293213 | KNN Loss: 3.6213455200195312 | CLS Loss: 0.008871311321854591\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 3.6304023265838623 | KNN Loss: 3.615344524383545 | CLS Loss: 0.015057907439768314\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 3.61515736579895 | KNN Loss: 3.6048765182495117 | CLS Loss: 0.01028084009885788\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 3.663729667663574 | KNN Loss: 3.6584222316741943 | CLS Loss: 0.005307443905621767\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 3.6596312522888184 | KNN Loss: 3.657477855682373 | CLS Loss: 0.0021534189581871033\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 3.5944266319274902 | KNN Loss: 3.582568883895874 | CLS Loss: 0.011857789009809494\n",
      "Epoch: 102, Loss: 3.6371, Train: 0.9968, Valid: 0.9876, Best: 0.9876\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 3.641118049621582 | KNN Loss: 3.638216972351074 | CLS Loss: 0.0029011378064751625\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 3.6158041954040527 | KNN Loss: 3.600095748901367 | CLS Loss: 0.015708453953266144\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 3.6382253170013428 | KNN Loss: 3.6247379779815674 | CLS Loss: 0.013487229123711586\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 3.6435904502868652 | KNN Loss: 3.6320838928222656 | CLS Loss: 0.011506523005664349\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 3.6483635902404785 | KNN Loss: 3.6258771419525146 | CLS Loss: 0.022486405447125435\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 3.632185697555542 | KNN Loss: 3.6254498958587646 | CLS Loss: 0.006735772825777531\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 3.6789321899414062 | KNN Loss: 3.6498591899871826 | CLS Loss: 0.02907293289899826\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 3.6738672256469727 | KNN Loss: 3.656369686126709 | CLS Loss: 0.017497504130005836\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 3.6967170238494873 | KNN Loss: 3.6661884784698486 | CLS Loss: 0.030528442934155464\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 3.622012138366699 | KNN Loss: 3.608743906021118 | CLS Loss: 0.013268300332129002\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 3.5921859741210938 | KNN Loss: 3.587392568588257 | CLS Loss: 0.004793458618223667\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 3.6509478092193604 | KNN Loss: 3.6411256790161133 | CLS Loss: 0.009822139516472816\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 3.6628148555755615 | KNN Loss: 3.6536037921905518 | CLS Loss: 0.009211063385009766\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 3.640061140060425 | KNN Loss: 3.618969440460205 | CLS Loss: 0.021091798320412636\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 3.660700559616089 | KNN Loss: 3.6234476566314697 | CLS Loss: 0.03725280985236168\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 3.639280319213867 | KNN Loss: 3.6091721057891846 | CLS Loss: 0.03010822832584381\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 3.621389150619507 | KNN Loss: 3.6097359657287598 | CLS Loss: 0.011653078719973564\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 3.650792360305786 | KNN Loss: 3.62652325630188 | CLS Loss: 0.02426905930042267\n",
      "Epoch: 103, Loss: 3.6470, Train: 0.9942, Valid: 0.9852, Best: 0.9876\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 3.6554410457611084 | KNN Loss: 3.6484813690185547 | CLS Loss: 0.006959565915167332\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 3.665170907974243 | KNN Loss: 3.6609132289886475 | CLS Loss: 0.004257566295564175\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 3.637974977493286 | KNN Loss: 3.6259491443634033 | CLS Loss: 0.012025896459817886\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 3.6308844089508057 | KNN Loss: 3.618553876876831 | CLS Loss: 0.012330524623394012\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 3.6804146766662598 | KNN Loss: 3.6654837131500244 | CLS Loss: 0.01493104174733162\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 3.626955986022949 | KNN Loss: 3.612856864929199 | CLS Loss: 0.014099168591201305\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 3.621912717819214 | KNN Loss: 3.6122512817382812 | CLS Loss: 0.009661388583481312\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 3.6467418670654297 | KNN Loss: 3.630540609359741 | CLS Loss: 0.016201362013816833\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 3.613797664642334 | KNN Loss: 3.6061391830444336 | CLS Loss: 0.007658559828996658\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 3.6081128120422363 | KNN Loss: 3.603412389755249 | CLS Loss: 0.004700401797890663\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 3.6184678077697754 | KNN Loss: 3.6065289974212646 | CLS Loss: 0.011938784271478653\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 3.69134521484375 | KNN Loss: 3.663203239440918 | CLS Loss: 0.028141865506768227\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 3.6332454681396484 | KNN Loss: 3.611480951309204 | CLS Loss: 0.02176457643508911\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 3.6382522583007812 | KNN Loss: 3.6126821041107178 | CLS Loss: 0.025570213794708252\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 3.658909559249878 | KNN Loss: 3.653136730194092 | CLS Loss: 0.0057727559469640255\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 3.658869981765747 | KNN Loss: 3.6411991119384766 | CLS Loss: 0.017670786008238792\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 3.6041367053985596 | KNN Loss: 3.5959551334381104 | CLS Loss: 0.008181597106158733\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 3.6713435649871826 | KNN Loss: 3.644335985183716 | CLS Loss: 0.02700764872133732\n",
      "Epoch: 104, Loss: 3.6399, Train: 0.9948, Valid: 0.9842, Best: 0.9876\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 3.6229605674743652 | KNN Loss: 3.589313268661499 | CLS Loss: 0.03364734724164009\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 3.62160062789917 | KNN Loss: 3.592980146408081 | CLS Loss: 0.028620528057217598\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 3.6471920013427734 | KNN Loss: 3.6231186389923096 | CLS Loss: 0.024073364213109016\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 3.621182918548584 | KNN Loss: 3.607062339782715 | CLS Loss: 0.014120503328740597\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 3.604335069656372 | KNN Loss: 3.598818063735962 | CLS Loss: 0.0055170813575387\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 3.6195244789123535 | KNN Loss: 3.6161048412323 | CLS Loss: 0.003419585758820176\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 3.6472294330596924 | KNN Loss: 3.626727819442749 | CLS Loss: 0.0205016378313303\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 3.639920473098755 | KNN Loss: 3.605069875717163 | CLS Loss: 0.03485069051384926\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 3.627187967300415 | KNN Loss: 3.6208059787750244 | CLS Loss: 0.006381935905665159\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 3.6499476432800293 | KNN Loss: 3.632133960723877 | CLS Loss: 0.017813770100474358\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 3.63067364692688 | KNN Loss: 3.6265995502471924 | CLS Loss: 0.0040740929543972015\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 3.6439244747161865 | KNN Loss: 3.6235294342041016 | CLS Loss: 0.02039497345685959\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 3.663381338119507 | KNN Loss: 3.632613182067871 | CLS Loss: 0.030768243595957756\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 3.6229169368743896 | KNN Loss: 3.614234209060669 | CLS Loss: 0.008682715706527233\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 3.6464316844940186 | KNN Loss: 3.6208038330078125 | CLS Loss: 0.0256277397274971\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 3.6144566535949707 | KNN Loss: 3.6100971698760986 | CLS Loss: 0.004359422717243433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 3.687199354171753 | KNN Loss: 3.673489570617676 | CLS Loss: 0.013709687627851963\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 3.6546335220336914 | KNN Loss: 3.6253554821014404 | CLS Loss: 0.029278073459863663\n",
      "Epoch: 105, Loss: 3.6456, Train: 0.9939, Valid: 0.9849, Best: 0.9876\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 3.595285177230835 | KNN Loss: 3.587592601776123 | CLS Loss: 0.007692515384405851\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 3.605112075805664 | KNN Loss: 3.594559907913208 | CLS Loss: 0.010552093386650085\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 3.6308014392852783 | KNN Loss: 3.6164045333862305 | CLS Loss: 0.014397014863789082\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 3.6385042667388916 | KNN Loss: 3.622450828552246 | CLS Loss: 0.016053510829806328\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 3.634216070175171 | KNN Loss: 3.624659776687622 | CLS Loss: 0.009556321427226067\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 3.62416410446167 | KNN Loss: 3.6126272678375244 | CLS Loss: 0.011536813341081142\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 3.6333343982696533 | KNN Loss: 3.6263515949249268 | CLS Loss: 0.0069828638806939125\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 3.6657917499542236 | KNN Loss: 3.6276724338531494 | CLS Loss: 0.038119278848171234\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 3.6140153408050537 | KNN Loss: 3.5972702503204346 | CLS Loss: 0.01674516499042511\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 3.6887693405151367 | KNN Loss: 3.659546375274658 | CLS Loss: 0.029223063960671425\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 3.614527702331543 | KNN Loss: 3.598275661468506 | CLS Loss: 0.016252022236585617\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 3.6526167392730713 | KNN Loss: 3.639854669570923 | CLS Loss: 0.012761975638568401\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 3.6245474815368652 | KNN Loss: 3.6084587574005127 | CLS Loss: 0.016088834032416344\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 3.6074283123016357 | KNN Loss: 3.5862205028533936 | CLS Loss: 0.021207692101597786\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 3.6289970874786377 | KNN Loss: 3.6227335929870605 | CLS Loss: 0.006263557821512222\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 3.6231255531311035 | KNN Loss: 3.61710524559021 | CLS Loss: 0.006020315922796726\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 3.686856508255005 | KNN Loss: 3.6723546981811523 | CLS Loss: 0.01450170949101448\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 3.6122653484344482 | KNN Loss: 3.5965394973754883 | CLS Loss: 0.015725858509540558\n",
      "Epoch: 106, Loss: 3.6349, Train: 0.9957, Valid: 0.9848, Best: 0.9876\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 3.6191372871398926 | KNN Loss: 3.617260456085205 | CLS Loss: 0.0018767789006233215\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 3.621847629547119 | KNN Loss: 3.598022699356079 | CLS Loss: 0.02382487803697586\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 3.6275391578674316 | KNN Loss: 3.6177139282226562 | CLS Loss: 0.009825295768678188\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 3.6510889530181885 | KNN Loss: 3.6474392414093018 | CLS Loss: 0.0036496140528470278\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 3.5804107189178467 | KNN Loss: 3.5783565044403076 | CLS Loss: 0.0020543334539979696\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 3.6109328269958496 | KNN Loss: 3.6009445190429688 | CLS Loss: 0.009988226927816868\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 3.627622127532959 | KNN Loss: 3.604590892791748 | CLS Loss: 0.023031223565340042\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 3.6067392826080322 | KNN Loss: 3.589892625808716 | CLS Loss: 0.01684664376080036\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 3.640078067779541 | KNN Loss: 3.619095802307129 | CLS Loss: 0.020982209593057632\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 3.6384854316711426 | KNN Loss: 3.6353683471679688 | CLS Loss: 0.003117077052593231\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 3.636172294616699 | KNN Loss: 3.6241812705993652 | CLS Loss: 0.011991060338914394\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 3.636220932006836 | KNN Loss: 3.609766721725464 | CLS Loss: 0.02645421214401722\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 3.686061143875122 | KNN Loss: 3.655407190322876 | CLS Loss: 0.030654052272439003\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 3.5828840732574463 | KNN Loss: 3.5792601108551025 | CLS Loss: 0.00362395984120667\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 3.6328938007354736 | KNN Loss: 3.6030166149139404 | CLS Loss: 0.02987723797559738\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 3.606461524963379 | KNN Loss: 3.5945141315460205 | CLS Loss: 0.011947371996939182\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 3.5966784954071045 | KNN Loss: 3.5928092002868652 | CLS Loss: 0.0038692806847393513\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 3.7022414207458496 | KNN Loss: 3.667454719543457 | CLS Loss: 0.03478667885065079\n",
      "Epoch: 107, Loss: 3.6278, Train: 0.9957, Valid: 0.9872, Best: 0.9876\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 3.6794369220733643 | KNN Loss: 3.6519052982330322 | CLS Loss: 0.02753172442317009\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 3.6041781902313232 | KNN Loss: 3.583824634552002 | CLS Loss: 0.02035357803106308\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 3.6569700241088867 | KNN Loss: 3.64573073387146 | CLS Loss: 0.011239230632781982\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 3.658921003341675 | KNN Loss: 3.651742696762085 | CLS Loss: 0.007178257219493389\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 3.676985502243042 | KNN Loss: 3.6539690494537354 | CLS Loss: 0.023016400635242462\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 3.6071882247924805 | KNN Loss: 3.6000096797943115 | CLS Loss: 0.007178488187491894\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 3.622546672821045 | KNN Loss: 3.6070384979248047 | CLS Loss: 0.015508277341723442\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 3.6354494094848633 | KNN Loss: 3.617274284362793 | CLS Loss: 0.01817505806684494\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 3.6383790969848633 | KNN Loss: 3.59604549407959 | CLS Loss: 0.04233362153172493\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 3.638880729675293 | KNN Loss: 3.6283538341522217 | CLS Loss: 0.010526972822844982\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 3.620615005493164 | KNN Loss: 3.6021456718444824 | CLS Loss: 0.018469318747520447\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 3.602482557296753 | KNN Loss: 3.593956232070923 | CLS Loss: 0.008526389487087727\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 3.628314256668091 | KNN Loss: 3.6075148582458496 | CLS Loss: 0.020799385383725166\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 3.623448371887207 | KNN Loss: 3.6155171394348145 | CLS Loss: 0.007931262254714966\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 3.6152820587158203 | KNN Loss: 3.6068923473358154 | CLS Loss: 0.008389666676521301\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 3.7043869495391846 | KNN Loss: 3.6977479457855225 | CLS Loss: 0.006639018189162016\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 3.6084883213043213 | KNN Loss: 3.601252317428589 | CLS Loss: 0.0072359065525233746\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 3.5945374965667725 | KNN Loss: 3.586402177810669 | CLS Loss: 0.008135412819683552\n",
      "Epoch: 108, Loss: 3.6374, Train: 0.9968, Valid: 0.9863, Best: 0.9876\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 3.6164050102233887 | KNN Loss: 3.603501081466675 | CLS Loss: 0.012903858907520771\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 3.6281213760375977 | KNN Loss: 3.59625244140625 | CLS Loss: 0.03186902403831482\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 3.614767551422119 | KNN Loss: 3.6106131076812744 | CLS Loss: 0.004154411610215902\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 3.6191768646240234 | KNN Loss: 3.610116481781006 | CLS Loss: 0.009060410782694817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 3.603267192840576 | KNN Loss: 3.59265398979187 | CLS Loss: 0.01061319001019001\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 3.6370372772216797 | KNN Loss: 3.6281139850616455 | CLS Loss: 0.008923223242163658\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 3.6509816646575928 | KNN Loss: 3.6451058387756348 | CLS Loss: 0.005875799804925919\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 3.6125121116638184 | KNN Loss: 3.605048894882202 | CLS Loss: 0.007463289424777031\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 3.6549787521362305 | KNN Loss: 3.6410744190216064 | CLS Loss: 0.013904359191656113\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 3.6227829456329346 | KNN Loss: 3.6138699054718018 | CLS Loss: 0.008913114666938782\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 3.6348259449005127 | KNN Loss: 3.624406337738037 | CLS Loss: 0.010419672355055809\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 3.7000041007995605 | KNN Loss: 3.682346820831299 | CLS Loss: 0.017657309770584106\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 3.6545255184173584 | KNN Loss: 3.6335384845733643 | CLS Loss: 0.02098691649734974\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 3.6217408180236816 | KNN Loss: 3.6015050411224365 | CLS Loss: 0.020235782489180565\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 3.647028684616089 | KNN Loss: 3.6417315006256104 | CLS Loss: 0.00529726967215538\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 3.639921188354492 | KNN Loss: 3.616565704345703 | CLS Loss: 0.02335541881620884\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 3.6457130908966064 | KNN Loss: 3.629910707473755 | CLS Loss: 0.015802351757884026\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 3.5962231159210205 | KNN Loss: 3.589690923690796 | CLS Loss: 0.006532246246933937\n",
      "Epoch: 109, Loss: 3.6333, Train: 0.9963, Valid: 0.9865, Best: 0.9876\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 3.6456174850463867 | KNN Loss: 3.6416451930999756 | CLS Loss: 0.003972211387008429\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 3.6472480297088623 | KNN Loss: 3.62309193611145 | CLS Loss: 0.024156151339411736\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 3.6389353275299072 | KNN Loss: 3.632309913635254 | CLS Loss: 0.006625492591410875\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 3.642592191696167 | KNN Loss: 3.6271190643310547 | CLS Loss: 0.015473137609660625\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 3.606151580810547 | KNN Loss: 3.587977409362793 | CLS Loss: 0.018174106255173683\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 3.6116020679473877 | KNN Loss: 3.607839345932007 | CLS Loss: 0.0037626675330102444\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 3.5973598957061768 | KNN Loss: 3.583770275115967 | CLS Loss: 0.013589607551693916\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 3.609419345855713 | KNN Loss: 3.58935284614563 | CLS Loss: 0.02006654627621174\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 3.6060285568237305 | KNN Loss: 3.583317518234253 | CLS Loss: 0.022711094468832016\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 3.6116766929626465 | KNN Loss: 3.5983338356018066 | CLS Loss: 0.013342772610485554\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 3.661142110824585 | KNN Loss: 3.6411685943603516 | CLS Loss: 0.01997358351945877\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 3.6481614112854004 | KNN Loss: 3.63712215423584 | CLS Loss: 0.01103932410478592\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 3.6305975914001465 | KNN Loss: 3.6232352256774902 | CLS Loss: 0.00736243138089776\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 3.6499741077423096 | KNN Loss: 3.63861083984375 | CLS Loss: 0.011363191530108452\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 3.615952730178833 | KNN Loss: 3.6087934970855713 | CLS Loss: 0.007159197703003883\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 3.6461341381073 | KNN Loss: 3.635605573654175 | CLS Loss: 0.010528597980737686\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 3.6928141117095947 | KNN Loss: 3.6811232566833496 | CLS Loss: 0.011690947227180004\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 3.6294565200805664 | KNN Loss: 3.6208887100219727 | CLS Loss: 0.00856779795140028\n",
      "Epoch: 110, Loss: 3.6364, Train: 0.9951, Valid: 0.9873, Best: 0.9876\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 3.618070125579834 | KNN Loss: 3.608003616333008 | CLS Loss: 0.010066574439406395\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 3.609018087387085 | KNN Loss: 3.600407600402832 | CLS Loss: 0.008610429242253304\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 3.6447179317474365 | KNN Loss: 3.6371912956237793 | CLS Loss: 0.007526710629463196\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 3.6265196800231934 | KNN Loss: 3.6190104484558105 | CLS Loss: 0.007509234361350536\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 3.6187901496887207 | KNN Loss: 3.6118271350860596 | CLS Loss: 0.006962923798710108\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 3.6539571285247803 | KNN Loss: 3.6484482288360596 | CLS Loss: 0.0055089956149458885\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 3.6456072330474854 | KNN Loss: 3.617323875427246 | CLS Loss: 0.028283361345529556\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 3.619189500808716 | KNN Loss: 3.587477445602417 | CLS Loss: 0.03171215578913689\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 3.6054837703704834 | KNN Loss: 3.600693941116333 | CLS Loss: 0.004789778497070074\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 3.6071434020996094 | KNN Loss: 3.6059913635253906 | CLS Loss: 0.0011521377600729465\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 3.5927202701568604 | KNN Loss: 3.5746212005615234 | CLS Loss: 0.01809915155172348\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 3.6146533489227295 | KNN Loss: 3.5883078575134277 | CLS Loss: 0.026345429942011833\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 3.6623966693878174 | KNN Loss: 3.65260648727417 | CLS Loss: 0.009790287353098392\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 3.637021541595459 | KNN Loss: 3.608790874481201 | CLS Loss: 0.028230583295226097\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 3.614548683166504 | KNN Loss: 3.6026601791381836 | CLS Loss: 0.011888538487255573\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 3.626089096069336 | KNN Loss: 3.6001687049865723 | CLS Loss: 0.025920359417796135\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 3.659792184829712 | KNN Loss: 3.630992889404297 | CLS Loss: 0.028799312189221382\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 3.633880138397217 | KNN Loss: 3.6214730739593506 | CLS Loss: 0.012407134287059307\n",
      "Epoch: 111, Loss: 3.6349, Train: 0.9938, Valid: 0.9837, Best: 0.9876\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 3.651921272277832 | KNN Loss: 3.6356730461120605 | CLS Loss: 0.016248313710093498\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 3.6206130981445312 | KNN Loss: 3.611257791519165 | CLS Loss: 0.00935520138591528\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 3.6232101917266846 | KNN Loss: 3.6177690029144287 | CLS Loss: 0.005441077519208193\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 3.6926233768463135 | KNN Loss: 3.6796722412109375 | CLS Loss: 0.012951172888278961\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 3.6283326148986816 | KNN Loss: 3.612696886062622 | CLS Loss: 0.01563575491309166\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 3.6387481689453125 | KNN Loss: 3.621006488800049 | CLS Loss: 0.017741594463586807\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 3.609286308288574 | KNN Loss: 3.59786319732666 | CLS Loss: 0.01142301969230175\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 3.695279359817505 | KNN Loss: 3.684669017791748 | CLS Loss: 0.010610301978886127\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 3.609592914581299 | KNN Loss: 3.606743574142456 | CLS Loss: 0.002849371638149023\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 3.6232385635375977 | KNN Loss: 3.618896245956421 | CLS Loss: 0.004342360887676477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 3.639369249343872 | KNN Loss: 3.6178033351898193 | CLS Loss: 0.0215659961104393\n",
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 3.6339588165283203 | KNN Loss: 3.6301848888397217 | CLS Loss: 0.003773984033614397\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 3.6596360206604004 | KNN Loss: 3.6250369548797607 | CLS Loss: 0.03459900617599487\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 3.6661224365234375 | KNN Loss: 3.64313006401062 | CLS Loss: 0.022992491722106934\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 3.6625897884368896 | KNN Loss: 3.631444215774536 | CLS Loss: 0.03114561177790165\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 3.6347053050994873 | KNN Loss: 3.6217122077941895 | CLS Loss: 0.012993120588362217\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 3.617220640182495 | KNN Loss: 3.611640691757202 | CLS Loss: 0.005579921416938305\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 3.641202688217163 | KNN Loss: 3.628265619277954 | CLS Loss: 0.012937105260789394\n",
      "Epoch: 112, Loss: 3.6429, Train: 0.9950, Valid: 0.9851, Best: 0.9876\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 3.61655330657959 | KNN Loss: 3.592832088470459 | CLS Loss: 0.023721130564808846\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 3.7118403911590576 | KNN Loss: 3.7034637928009033 | CLS Loss: 0.008376690559089184\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 3.668917655944824 | KNN Loss: 3.6604745388031006 | CLS Loss: 0.008443119935691357\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 3.5946195125579834 | KNN Loss: 3.587573289871216 | CLS Loss: 0.00704623106867075\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 3.637334108352661 | KNN Loss: 3.6348955631256104 | CLS Loss: 0.002438583876937628\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 3.6638708114624023 | KNN Loss: 3.637667655944824 | CLS Loss: 0.02620324119925499\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 3.6486167907714844 | KNN Loss: 3.630061388015747 | CLS Loss: 0.018555335700511932\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 3.6387600898742676 | KNN Loss: 3.6143271923065186 | CLS Loss: 0.024432936683297157\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 3.6402289867401123 | KNN Loss: 3.6211977005004883 | CLS Loss: 0.019031357020139694\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 3.655250310897827 | KNN Loss: 3.647355794906616 | CLS Loss: 0.007894489914178848\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 3.6113555431365967 | KNN Loss: 3.6018660068511963 | CLS Loss: 0.009489466436207294\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 3.6656646728515625 | KNN Loss: 3.6415517330169678 | CLS Loss: 0.02411297708749771\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 3.6432130336761475 | KNN Loss: 3.6274282932281494 | CLS Loss: 0.015784651041030884\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 3.6348283290863037 | KNN Loss: 3.614295721054077 | CLS Loss: 0.020532693713903427\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 3.626338243484497 | KNN Loss: 3.6063055992126465 | CLS Loss: 0.020032713189721107\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 3.634909152984619 | KNN Loss: 3.614596366882324 | CLS Loss: 0.020312903448939323\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 3.6635942459106445 | KNN Loss: 3.6576032638549805 | CLS Loss: 0.005990956909954548\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 3.6431362628936768 | KNN Loss: 3.630760431289673 | CLS Loss: 0.012375864200294018\n",
      "Epoch: 113, Loss: 3.6397, Train: 0.9961, Valid: 0.9863, Best: 0.9876\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 3.609616756439209 | KNN Loss: 3.59342098236084 | CLS Loss: 0.016195761039853096\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 3.6081104278564453 | KNN Loss: 3.595534563064575 | CLS Loss: 0.01257587131112814\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 3.6681969165802 | KNN Loss: 3.654611587524414 | CLS Loss: 0.013585389591753483\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 3.614560604095459 | KNN Loss: 3.6105191707611084 | CLS Loss: 0.004041548818349838\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 3.661511182785034 | KNN Loss: 3.6505212783813477 | CLS Loss: 0.010990018025040627\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 3.60953688621521 | KNN Loss: 3.593491554260254 | CLS Loss: 0.016045235097408295\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 3.603768825531006 | KNN Loss: 3.5979106426239014 | CLS Loss: 0.005858194082975388\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 3.636915922164917 | KNN Loss: 3.6361522674560547 | CLS Loss: 0.0007636133814230561\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 3.6145036220550537 | KNN Loss: 3.6098124980926514 | CLS Loss: 0.004691179376095533\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 3.5924081802368164 | KNN Loss: 3.5904440879821777 | CLS Loss: 0.001963976537808776\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 3.6684556007385254 | KNN Loss: 3.645650625228882 | CLS Loss: 0.022805053740739822\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 3.619030714035034 | KNN Loss: 3.602207660675049 | CLS Loss: 0.01682308316230774\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 3.623904228210449 | KNN Loss: 3.6069111824035645 | CLS Loss: 0.016993070021271706\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 3.6332170963287354 | KNN Loss: 3.5999221801757812 | CLS Loss: 0.03329496085643768\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 3.6217997074127197 | KNN Loss: 3.6123898029327393 | CLS Loss: 0.00940994918346405\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 3.6100876331329346 | KNN Loss: 3.588587760925293 | CLS Loss: 0.021499983966350555\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 3.642603874206543 | KNN Loss: 3.6318418979644775 | CLS Loss: 0.010762079618871212\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 3.596043109893799 | KNN Loss: 3.5932631492614746 | CLS Loss: 0.002780037932097912\n",
      "Epoch: 114, Loss: 3.6304, Train: 0.9969, Valid: 0.9866, Best: 0.9876\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 3.6177587509155273 | KNN Loss: 3.6007766723632812 | CLS Loss: 0.016982028260827065\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 3.6497437953948975 | KNN Loss: 3.6383187770843506 | CLS Loss: 0.01142499502748251\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 3.6383886337280273 | KNN Loss: 3.6224937438964844 | CLS Loss: 0.015894880518317223\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 3.620504140853882 | KNN Loss: 3.6181178092956543 | CLS Loss: 0.002386222593486309\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 3.6349213123321533 | KNN Loss: 3.6200571060180664 | CLS Loss: 0.014864109456539154\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 3.611016035079956 | KNN Loss: 3.58939790725708 | CLS Loss: 0.021618053317070007\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 3.596712350845337 | KNN Loss: 3.5910518169403076 | CLS Loss: 0.005660648457705975\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 3.5888848304748535 | KNN Loss: 3.586007833480835 | CLS Loss: 0.0028770954813808203\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 3.6065964698791504 | KNN Loss: 3.5979113578796387 | CLS Loss: 0.008685064502060413\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 3.632930040359497 | KNN Loss: 3.6094768047332764 | CLS Loss: 0.023453310132026672\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 3.6651387214660645 | KNN Loss: 3.649073839187622 | CLS Loss: 0.016064859926700592\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 3.6195178031921387 | KNN Loss: 3.589553117752075 | CLS Loss: 0.02996460162103176\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 3.619004011154175 | KNN Loss: 3.606132984161377 | CLS Loss: 0.012870951555669308\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 3.629801034927368 | KNN Loss: 3.6018993854522705 | CLS Loss: 0.027901723980903625\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 3.680637836456299 | KNN Loss: 3.660888671875 | CLS Loss: 0.01974928379058838\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 3.6205246448516846 | KNN Loss: 3.6153934001922607 | CLS Loss: 0.005131341051310301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 3.6638641357421875 | KNN Loss: 3.634939432144165 | CLS Loss: 0.028924688696861267\n",
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 3.625331401824951 | KNN Loss: 3.614860773086548 | CLS Loss: 0.010470605455338955\n",
      "Epoch: 115, Loss: 3.6360, Train: 0.9949, Valid: 0.9855, Best: 0.9876\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 3.6388189792633057 | KNN Loss: 3.627091884613037 | CLS Loss: 0.01172720268368721\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 3.6111295223236084 | KNN Loss: 3.5981829166412354 | CLS Loss: 0.012946641072630882\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 3.620400905609131 | KNN Loss: 3.607592821121216 | CLS Loss: 0.012808116152882576\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 3.593369722366333 | KNN Loss: 3.575413942337036 | CLS Loss: 0.01795574650168419\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 3.632918119430542 | KNN Loss: 3.618520975112915 | CLS Loss: 0.014397196471691132\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 3.626676082611084 | KNN Loss: 3.611351728439331 | CLS Loss: 0.015324396081268787\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 3.623039484024048 | KNN Loss: 3.6163129806518555 | CLS Loss: 0.006726536899805069\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 3.6083762645721436 | KNN Loss: 3.5804224014282227 | CLS Loss: 0.02795376442372799\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 3.6238315105438232 | KNN Loss: 3.618989944458008 | CLS Loss: 0.004841673653572798\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 3.7121706008911133 | KNN Loss: 3.6863138675689697 | CLS Loss: 0.025856614112854004\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 3.68674373626709 | KNN Loss: 3.6749682426452637 | CLS Loss: 0.011775397695600986\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 3.6355655193328857 | KNN Loss: 3.611318826675415 | CLS Loss: 0.024246659129858017\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 3.6087145805358887 | KNN Loss: 3.5966567993164062 | CLS Loss: 0.012057863175868988\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 3.618985652923584 | KNN Loss: 3.617520570755005 | CLS Loss: 0.0014650804223492742\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 3.631277561187744 | KNN Loss: 3.6225497722625732 | CLS Loss: 0.00872768834233284\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 3.612220287322998 | KNN Loss: 3.583281993865967 | CLS Loss: 0.028938204050064087\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 3.635849952697754 | KNN Loss: 3.6302993297576904 | CLS Loss: 0.005550590343773365\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 3.594499111175537 | KNN Loss: 3.584090232849121 | CLS Loss: 0.010408814065158367\n",
      "Epoch: 116, Loss: 3.6405, Train: 0.9962, Valid: 0.9864, Best: 0.9876\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 3.70375657081604 | KNN Loss: 3.6941769123077393 | CLS Loss: 0.009579739533364773\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 3.602886199951172 | KNN Loss: 3.587895154953003 | CLS Loss: 0.014990955591201782\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 3.5914254188537598 | KNN Loss: 3.5767641067504883 | CLS Loss: 0.014661234803497791\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 3.5987322330474854 | KNN Loss: 3.5939087867736816 | CLS Loss: 0.004823481664061546\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 3.682029962539673 | KNN Loss: 3.663175344467163 | CLS Loss: 0.018854649737477303\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 3.6489179134368896 | KNN Loss: 3.634788990020752 | CLS Loss: 0.014128967188298702\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 3.608426570892334 | KNN Loss: 3.6050922870635986 | CLS Loss: 0.0033343113027513027\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 3.702451229095459 | KNN Loss: 3.6572299003601074 | CLS Loss: 0.04522129148244858\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 3.6384408473968506 | KNN Loss: 3.6263818740844727 | CLS Loss: 0.012059072032570839\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 3.601078510284424 | KNN Loss: 3.59842848777771 | CLS Loss: 0.002649959409609437\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 3.6085033416748047 | KNN Loss: 3.5896265506744385 | CLS Loss: 0.01887688972055912\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 3.6296300888061523 | KNN Loss: 3.627676010131836 | CLS Loss: 0.001954059349372983\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 3.6568777561187744 | KNN Loss: 3.6371395587921143 | CLS Loss: 0.01973826251924038\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 3.6040401458740234 | KNN Loss: 3.593653440475464 | CLS Loss: 0.010386714711785316\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 3.6396872997283936 | KNN Loss: 3.6363365650177 | CLS Loss: 0.0033507610205560923\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 3.611013650894165 | KNN Loss: 3.602057695388794 | CLS Loss: 0.008956057950854301\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 3.6123993396759033 | KNN Loss: 3.608646869659424 | CLS Loss: 0.0037525601219385862\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 3.6498258113861084 | KNN Loss: 3.6222267150878906 | CLS Loss: 0.02759912610054016\n",
      "Epoch: 117, Loss: 3.6364, Train: 0.9967, Valid: 0.9870, Best: 0.9876\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 3.612422227859497 | KNN Loss: 3.603450059890747 | CLS Loss: 0.008972062729299068\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 3.6127350330352783 | KNN Loss: 3.6095962524414062 | CLS Loss: 0.003138855565339327\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 3.615407943725586 | KNN Loss: 3.6033473014831543 | CLS Loss: 0.01206054538488388\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 3.693161725997925 | KNN Loss: 3.6783595085144043 | CLS Loss: 0.01480227429419756\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 3.633082151412964 | KNN Loss: 3.6219658851623535 | CLS Loss: 0.011116379871964455\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 3.6619017124176025 | KNN Loss: 3.639554738998413 | CLS Loss: 0.022346967831254005\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 3.6462042331695557 | KNN Loss: 3.631176233291626 | CLS Loss: 0.01502800639718771\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 3.612259864807129 | KNN Loss: 3.6065027713775635 | CLS Loss: 0.005757198203355074\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 3.7402572631835938 | KNN Loss: 3.7202301025390625 | CLS Loss: 0.0200271587818861\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 3.6575326919555664 | KNN Loss: 3.6378817558288574 | CLS Loss: 0.01965087465941906\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 3.6871955394744873 | KNN Loss: 3.66709303855896 | CLS Loss: 0.020102547481656075\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 3.6152679920196533 | KNN Loss: 3.6048545837402344 | CLS Loss: 0.01041333470493555\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 3.6840531826019287 | KNN Loss: 3.6634552478790283 | CLS Loss: 0.020598046481609344\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 3.6281466484069824 | KNN Loss: 3.5782060623168945 | CLS Loss: 0.049940671771764755\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 3.6115477085113525 | KNN Loss: 3.6008076667785645 | CLS Loss: 0.01074012741446495\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 3.6554300785064697 | KNN Loss: 3.6461448669433594 | CLS Loss: 0.009285303764045238\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 3.6187539100646973 | KNN Loss: 3.6116154193878174 | CLS Loss: 0.007138424087315798\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 3.651487350463867 | KNN Loss: 3.6431612968444824 | CLS Loss: 0.008325968869030476\n",
      "Epoch: 118, Loss: 3.6378, Train: 0.9955, Valid: 0.9845, Best: 0.9876\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 3.6115994453430176 | KNN Loss: 3.6083123683929443 | CLS Loss: 0.003287005005404353\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 3.6201844215393066 | KNN Loss: 3.6044325828552246 | CLS Loss: 0.015751810744404793\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 3.656843662261963 | KNN Loss: 3.630615472793579 | CLS Loss: 0.02622811682522297\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 3.626706838607788 | KNN Loss: 3.616579055786133 | CLS Loss: 0.010127859190106392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 3.6227574348449707 | KNN Loss: 3.618394136428833 | CLS Loss: 0.00436341343447566\n",
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 3.623582363128662 | KNN Loss: 3.6167571544647217 | CLS Loss: 0.006825141608715057\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 3.6019954681396484 | KNN Loss: 3.5815632343292236 | CLS Loss: 0.02043216861784458\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 3.642270088195801 | KNN Loss: 3.628070592880249 | CLS Loss: 0.014199549332261086\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 3.601231098175049 | KNN Loss: 3.5870089530944824 | CLS Loss: 0.014222201891243458\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 3.6364803314208984 | KNN Loss: 3.626359701156616 | CLS Loss: 0.010120580904185772\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 3.6075737476348877 | KNN Loss: 3.594346284866333 | CLS Loss: 0.013227449730038643\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 3.6275248527526855 | KNN Loss: 3.6032185554504395 | CLS Loss: 0.024306267499923706\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 3.6343538761138916 | KNN Loss: 3.612691879272461 | CLS Loss: 0.021661901846528053\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 3.6139214038848877 | KNN Loss: 3.596921443939209 | CLS Loss: 0.016999896615743637\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 3.5840561389923096 | KNN Loss: 3.580811023712158 | CLS Loss: 0.0032451068982481956\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 3.6580398082733154 | KNN Loss: 3.635136604309082 | CLS Loss: 0.02290317416191101\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 3.6872284412384033 | KNN Loss: 3.6705849170684814 | CLS Loss: 0.016643468290567398\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 3.602259397506714 | KNN Loss: 3.592794179916382 | CLS Loss: 0.009465313516557217\n",
      "Epoch: 119, Loss: 3.6327, Train: 0.9957, Valid: 0.9847, Best: 0.9876\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 3.642327308654785 | KNN Loss: 3.619939088821411 | CLS Loss: 0.022388223558664322\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 3.6076042652130127 | KNN Loss: 3.594003677368164 | CLS Loss: 0.013600500300526619\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 3.6660349369049072 | KNN Loss: 3.652550458908081 | CLS Loss: 0.013484572991728783\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 3.631645679473877 | KNN Loss: 3.6241207122802734 | CLS Loss: 0.0075250230729579926\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 3.630605697631836 | KNN Loss: 3.613112688064575 | CLS Loss: 0.017493080347776413\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 3.6716814041137695 | KNN Loss: 3.6437551975250244 | CLS Loss: 0.027926145121455193\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 3.633040428161621 | KNN Loss: 3.6144001483917236 | CLS Loss: 0.018640194088220596\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 3.636448383331299 | KNN Loss: 3.6147313117980957 | CLS Loss: 0.021717149764299393\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 3.616076707839966 | KNN Loss: 3.614777088165283 | CLS Loss: 0.0012995940633118153\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 3.5954201221466064 | KNN Loss: 3.589866876602173 | CLS Loss: 0.005553361494094133\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 3.6226260662078857 | KNN Loss: 3.614698648452759 | CLS Loss: 0.007927381433546543\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 3.639646530151367 | KNN Loss: 3.626703977584839 | CLS Loss: 0.012942569330334663\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 3.6546618938446045 | KNN Loss: 3.642338275909424 | CLS Loss: 0.012323634698987007\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 3.6341190338134766 | KNN Loss: 3.6201090812683105 | CLS Loss: 0.01401001401245594\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 3.59230899810791 | KNN Loss: 3.58381986618042 | CLS Loss: 0.008489195257425308\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 3.6486542224884033 | KNN Loss: 3.6156883239746094 | CLS Loss: 0.03296583890914917\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 3.6381821632385254 | KNN Loss: 3.6280646324157715 | CLS Loss: 0.01011752337217331\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 3.710559606552124 | KNN Loss: 3.697671413421631 | CLS Loss: 0.012888138182461262\n",
      "Epoch: 120, Loss: 3.6333, Train: 0.9960, Valid: 0.9866, Best: 0.9876\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 3.61600399017334 | KNN Loss: 3.603721857070923 | CLS Loss: 0.012282212264835835\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 3.647010326385498 | KNN Loss: 3.631385564804077 | CLS Loss: 0.01562467496842146\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 3.6410183906555176 | KNN Loss: 3.6344923973083496 | CLS Loss: 0.006525971926748753\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 3.6330208778381348 | KNN Loss: 3.6221487522125244 | CLS Loss: 0.010872195474803448\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 3.621530532836914 | KNN Loss: 3.6148269176483154 | CLS Loss: 0.006703508086502552\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 3.6322150230407715 | KNN Loss: 3.615619659423828 | CLS Loss: 0.016595391556620598\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 3.624636650085449 | KNN Loss: 3.6171798706054688 | CLS Loss: 0.007456850726157427\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 3.670440673828125 | KNN Loss: 3.653923273086548 | CLS Loss: 0.016517361626029015\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 3.679696559906006 | KNN Loss: 3.6385133266448975 | CLS Loss: 0.041183218359947205\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 3.638993978500366 | KNN Loss: 3.6236398220062256 | CLS Loss: 0.01535411924123764\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 3.6471049785614014 | KNN Loss: 3.63006854057312 | CLS Loss: 0.01703653670847416\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 3.631833553314209 | KNN Loss: 3.614757776260376 | CLS Loss: 0.017075803130865097\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 3.658545970916748 | KNN Loss: 3.6486001014709473 | CLS Loss: 0.00994592159986496\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 3.622807025909424 | KNN Loss: 3.6144397258758545 | CLS Loss: 0.008367279544472694\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 3.6457295417785645 | KNN Loss: 3.621095895767212 | CLS Loss: 0.024633556604385376\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 3.669976234436035 | KNN Loss: 3.6559526920318604 | CLS Loss: 0.014023501425981522\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 3.6537206172943115 | KNN Loss: 3.632401466369629 | CLS Loss: 0.02131914533674717\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 3.6364405155181885 | KNN Loss: 3.6061654090881348 | CLS Loss: 0.03027511201798916\n",
      "Epoch: 121, Loss: 3.6371, Train: 0.9965, Valid: 0.9863, Best: 0.9876\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 3.616136312484741 | KNN Loss: 3.6080634593963623 | CLS Loss: 0.008072908036410809\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 3.657622814178467 | KNN Loss: 3.6402523517608643 | CLS Loss: 0.017370490357279778\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 3.6857850551605225 | KNN Loss: 3.6809310913085938 | CLS Loss: 0.004854068160057068\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 3.6177399158477783 | KNN Loss: 3.6124789714813232 | CLS Loss: 0.005260828882455826\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 3.599942207336426 | KNN Loss: 3.582197427749634 | CLS Loss: 0.017744669690728188\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 3.648118257522583 | KNN Loss: 3.631509304046631 | CLS Loss: 0.01660905033349991\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 3.625581979751587 | KNN Loss: 3.60284161567688 | CLS Loss: 0.022740408778190613\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 3.665475845336914 | KNN Loss: 3.6434524059295654 | CLS Loss: 0.02202337235212326\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 3.6679906845092773 | KNN Loss: 3.6455576419830322 | CLS Loss: 0.022433150559663773\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 3.667452096939087 | KNN Loss: 3.649324893951416 | CLS Loss: 0.018127145245671272\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 3.637751817703247 | KNN Loss: 3.6227519512176514 | CLS Loss: 0.014999979175627232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 3.64738130569458 | KNN Loss: 3.6198973655700684 | CLS Loss: 0.02748394012451172\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 3.5880374908447266 | KNN Loss: 3.5774731636047363 | CLS Loss: 0.01056424155831337\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 3.676305055618286 | KNN Loss: 3.641549825668335 | CLS Loss: 0.03475524112582207\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 3.6424403190612793 | KNN Loss: 3.6222097873687744 | CLS Loss: 0.02023046277463436\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 3.6325597763061523 | KNN Loss: 3.621894598007202 | CLS Loss: 0.010665112175047398\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 3.602773666381836 | KNN Loss: 3.5993573665618896 | CLS Loss: 0.003416236490011215\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 3.6067333221435547 | KNN Loss: 3.582409620285034 | CLS Loss: 0.02432367391884327\n",
      "Epoch: 122, Loss: 3.6387, Train: 0.9972, Valid: 0.9868, Best: 0.9876\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 3.634007692337036 | KNN Loss: 3.6302742958068848 | CLS Loss: 0.003733487566933036\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 3.5819504261016846 | KNN Loss: 3.5660393238067627 | CLS Loss: 0.015911109745502472\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 3.6242868900299072 | KNN Loss: 3.6125142574310303 | CLS Loss: 0.01177262607961893\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 3.596891403198242 | KNN Loss: 3.5845229625701904 | CLS Loss: 0.012368511408567429\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 3.6144962310791016 | KNN Loss: 3.605755090713501 | CLS Loss: 0.008741166442632675\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 3.6349356174468994 | KNN Loss: 3.6185836791992188 | CLS Loss: 0.016351940110325813\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 3.6163249015808105 | KNN Loss: 3.6051321029663086 | CLS Loss: 0.011192750185728073\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 3.630331039428711 | KNN Loss: 3.6171140670776367 | CLS Loss: 0.013217082247138023\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 3.6092946529388428 | KNN Loss: 3.6023881435394287 | CLS Loss: 0.0069066183641552925\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 3.6490981578826904 | KNN Loss: 3.6458652019500732 | CLS Loss: 0.0032329102978110313\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 3.6779465675354004 | KNN Loss: 3.669093608856201 | CLS Loss: 0.008852893486618996\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 3.640279769897461 | KNN Loss: 3.635394811630249 | CLS Loss: 0.004884942900389433\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 3.6619300842285156 | KNN Loss: 3.655884027481079 | CLS Loss: 0.006046089343726635\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 3.6437883377075195 | KNN Loss: 3.640897035598755 | CLS Loss: 0.0028914171271026134\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 3.590947151184082 | KNN Loss: 3.582171678543091 | CLS Loss: 0.00877535529434681\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 3.6775217056274414 | KNN Loss: 3.6606364250183105 | CLS Loss: 0.01688537560403347\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 3.6013448238372803 | KNN Loss: 3.565763235092163 | CLS Loss: 0.035581640899181366\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 3.6176400184631348 | KNN Loss: 3.6038811206817627 | CLS Loss: 0.013758910819888115\n",
      "Epoch: 123, Loss: 3.6282, Train: 0.9971, Valid: 0.9867, Best: 0.9876\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 3.6307194232940674 | KNN Loss: 3.6295714378356934 | CLS Loss: 0.0011480443645268679\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 3.6119799613952637 | KNN Loss: 3.603257656097412 | CLS Loss: 0.008722200058400631\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 3.66373348236084 | KNN Loss: 3.660632610321045 | CLS Loss: 0.003100932575762272\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 3.6607260704040527 | KNN Loss: 3.62666916847229 | CLS Loss: 0.03405700996518135\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 3.6292710304260254 | KNN Loss: 3.62554669380188 | CLS Loss: 0.0037242264952510595\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 3.5814368724823 | KNN Loss: 3.570915460586548 | CLS Loss: 0.010521376505494118\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 3.6093714237213135 | KNN Loss: 3.596381187438965 | CLS Loss: 0.01299015711992979\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 3.661314010620117 | KNN Loss: 3.632936954498291 | CLS Loss: 0.028377020731568336\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 3.6202914714813232 | KNN Loss: 3.6177432537078857 | CLS Loss: 0.002548186806961894\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 3.6512022018432617 | KNN Loss: 3.6293444633483887 | CLS Loss: 0.02185770496726036\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 3.6212546825408936 | KNN Loss: 3.6083879470825195 | CLS Loss: 0.012866700068116188\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 3.615783214569092 | KNN Loss: 3.5932765007019043 | CLS Loss: 0.022506648674607277\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 3.608654022216797 | KNN Loss: 3.5848827362060547 | CLS Loss: 0.02377140149474144\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 3.61122727394104 | KNN Loss: 3.604160785675049 | CLS Loss: 0.007066425867378712\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 3.613924741744995 | KNN Loss: 3.593083620071411 | CLS Loss: 0.0208412054926157\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 3.6426913738250732 | KNN Loss: 3.603079080581665 | CLS Loss: 0.03961235657334328\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 3.5868008136749268 | KNN Loss: 3.5807669162750244 | CLS Loss: 0.006034004036337137\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 3.628777503967285 | KNN Loss: 3.6133217811584473 | CLS Loss: 0.015455801039934158\n",
      "Epoch: 124, Loss: 3.6258, Train: 0.9953, Valid: 0.9848, Best: 0.9876\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 3.610574722290039 | KNN Loss: 3.5865211486816406 | CLS Loss: 0.024053607136011124\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 3.6135966777801514 | KNN Loss: 3.597996711730957 | CLS Loss: 0.015599934384226799\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 3.6386559009552 | KNN Loss: 3.6282424926757812 | CLS Loss: 0.010413458570837975\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 3.607637882232666 | KNN Loss: 3.601548671722412 | CLS Loss: 0.006089170463383198\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 3.6176035404205322 | KNN Loss: 3.6111159324645996 | CLS Loss: 0.006487553007900715\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 3.586042881011963 | KNN Loss: 3.5758190155029297 | CLS Loss: 0.010223892517387867\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 3.701050281524658 | KNN Loss: 3.688173294067383 | CLS Loss: 0.012876997701823711\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 3.6243231296539307 | KNN Loss: 3.620589017868042 | CLS Loss: 0.0037340850103646517\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 3.617196798324585 | KNN Loss: 3.6091082096099854 | CLS Loss: 0.008088560774922371\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 3.6248607635498047 | KNN Loss: 3.6105501651763916 | CLS Loss: 0.014310535043478012\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 3.6606814861297607 | KNN Loss: 3.646979570388794 | CLS Loss: 0.013701931573450565\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 3.6634552478790283 | KNN Loss: 3.6503031253814697 | CLS Loss: 0.01315213181078434\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 3.597418785095215 | KNN Loss: 3.5825717449188232 | CLS Loss: 0.014846974983811378\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 3.6404941082000732 | KNN Loss: 3.629392385482788 | CLS Loss: 0.011101643554866314\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 3.6526360511779785 | KNN Loss: 3.6388144493103027 | CLS Loss: 0.013821614906191826\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 3.6402432918548584 | KNN Loss: 3.6298904418945312 | CLS Loss: 0.010352854616940022\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 3.618248701095581 | KNN Loss: 3.6100456714630127 | CLS Loss: 0.00820301566272974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 3.6330528259277344 | KNN Loss: 3.611884593963623 | CLS Loss: 0.02116812951862812\n",
      "Epoch: 125, Loss: 3.6303, Train: 0.9971, Valid: 0.9872, Best: 0.9876\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 3.6070337295532227 | KNN Loss: 3.6008448600769043 | CLS Loss: 0.006188869010657072\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 3.612562417984009 | KNN Loss: 3.6066770553588867 | CLS Loss: 0.005885340739041567\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 3.6351852416992188 | KNN Loss: 3.61542010307312 | CLS Loss: 0.019765105098485947\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 3.6569817066192627 | KNN Loss: 3.641549825668335 | CLS Loss: 0.015431815758347511\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 3.6285853385925293 | KNN Loss: 3.6270718574523926 | CLS Loss: 0.0015135523863136768\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 3.6108267307281494 | KNN Loss: 3.6027166843414307 | CLS Loss: 0.008109988644719124\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 3.6203975677490234 | KNN Loss: 3.599156379699707 | CLS Loss: 0.021241163834929466\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 3.6334147453308105 | KNN Loss: 3.629891872406006 | CLS Loss: 0.00352296675555408\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 3.637219190597534 | KNN Loss: 3.6075024604797363 | CLS Loss: 0.029716841876506805\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 3.633720874786377 | KNN Loss: 3.615755558013916 | CLS Loss: 0.017965352162718773\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 3.6035518646240234 | KNN Loss: 3.60146164894104 | CLS Loss: 0.002090128604322672\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 3.7030856609344482 | KNN Loss: 3.6967062950134277 | CLS Loss: 0.006379298400133848\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 3.6233837604522705 | KNN Loss: 3.605982780456543 | CLS Loss: 0.017401073127985\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 3.609971046447754 | KNN Loss: 3.5927674770355225 | CLS Loss: 0.01720355451107025\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 3.590627670288086 | KNN Loss: 3.5790960788726807 | CLS Loss: 0.011531614698469639\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 3.6292760372161865 | KNN Loss: 3.6207616329193115 | CLS Loss: 0.00851451326161623\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 3.601125717163086 | KNN Loss: 3.5865092277526855 | CLS Loss: 0.014616486616432667\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 3.6064014434814453 | KNN Loss: 3.598205804824829 | CLS Loss: 0.008195544593036175\n",
      "Epoch: 126, Loss: 3.6277, Train: 0.9969, Valid: 0.9862, Best: 0.9876\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 3.592237710952759 | KNN Loss: 3.585484027862549 | CLS Loss: 0.006753739435225725\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 3.621725559234619 | KNN Loss: 3.6158804893493652 | CLS Loss: 0.00584512809291482\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 3.6145732402801514 | KNN Loss: 3.5998024940490723 | CLS Loss: 0.01477071549743414\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 3.618309736251831 | KNN Loss: 3.6096744537353516 | CLS Loss: 0.008635333739221096\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 3.6248607635498047 | KNN Loss: 3.6146793365478516 | CLS Loss: 0.010181525722146034\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 3.6164777278900146 | KNN Loss: 3.6004528999328613 | CLS Loss: 0.016024792566895485\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 3.6105265617370605 | KNN Loss: 3.6073203086853027 | CLS Loss: 0.0032062302343547344\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 3.594397783279419 | KNN Loss: 3.5926122665405273 | CLS Loss: 0.001785631407983601\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 3.606266498565674 | KNN Loss: 3.5983099937438965 | CLS Loss: 0.007956433109939098\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 3.614630937576294 | KNN Loss: 3.6139421463012695 | CLS Loss: 0.0006887793424539268\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 3.6107864379882812 | KNN Loss: 3.602780342102051 | CLS Loss: 0.008006160147488117\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 3.617628812789917 | KNN Loss: 3.6125378608703613 | CLS Loss: 0.005090951919555664\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 3.6224114894866943 | KNN Loss: 3.608731746673584 | CLS Loss: 0.01367969624698162\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 3.617753267288208 | KNN Loss: 3.613927125930786 | CLS Loss: 0.0038260475266724825\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 3.606018304824829 | KNN Loss: 3.5919148921966553 | CLS Loss: 0.014103363268077374\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 3.5983211994171143 | KNN Loss: 3.582648992538452 | CLS Loss: 0.015672164037823677\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 3.6250832080841064 | KNN Loss: 3.605890989303589 | CLS Loss: 0.019192272797226906\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 3.6583211421966553 | KNN Loss: 3.633141040802002 | CLS Loss: 0.025180146098136902\n",
      "Epoch: 127, Loss: 3.6222, Train: 0.9959, Valid: 0.9865, Best: 0.9876\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 3.6208977699279785 | KNN Loss: 3.6090540885925293 | CLS Loss: 0.011843732558190823\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 3.643906354904175 | KNN Loss: 3.6218771934509277 | CLS Loss: 0.022029206156730652\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 3.6270430088043213 | KNN Loss: 3.6249685287475586 | CLS Loss: 0.0020744469948112965\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 3.580328941345215 | KNN Loss: 3.5735418796539307 | CLS Loss: 0.006787077523767948\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 3.616128444671631 | KNN Loss: 3.606729507446289 | CLS Loss: 0.00939902476966381\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 3.6041009426116943 | KNN Loss: 3.5953521728515625 | CLS Loss: 0.00874878279864788\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 3.6248302459716797 | KNN Loss: 3.6132330894470215 | CLS Loss: 0.011597215197980404\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 3.6062519550323486 | KNN Loss: 3.6001784801483154 | CLS Loss: 0.006073430180549622\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 3.650536060333252 | KNN Loss: 3.6272056102752686 | CLS Loss: 0.02333035320043564\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 3.628845691680908 | KNN Loss: 3.61877703666687 | CLS Loss: 0.010068591684103012\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 3.6823902130126953 | KNN Loss: 3.680865526199341 | CLS Loss: 0.001524689607322216\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 3.6415789127349854 | KNN Loss: 3.625366449356079 | CLS Loss: 0.01621251367032528\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 3.654041051864624 | KNN Loss: 3.648216962814331 | CLS Loss: 0.005824022460728884\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 3.5913028717041016 | KNN Loss: 3.575995922088623 | CLS Loss: 0.015307043679058552\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 3.61419939994812 | KNN Loss: 3.599426746368408 | CLS Loss: 0.01477257814258337\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 3.6203691959381104 | KNN Loss: 3.614976167678833 | CLS Loss: 0.005392936058342457\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 3.5994553565979004 | KNN Loss: 3.5825843811035156 | CLS Loss: 0.016870856285095215\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 3.631197690963745 | KNN Loss: 3.61126446723938 | CLS Loss: 0.019933311268687248\n",
      "Epoch: 128, Loss: 3.6266, Train: 0.9967, Valid: 0.9857, Best: 0.9876\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 3.5970351696014404 | KNN Loss: 3.5842626094818115 | CLS Loss: 0.012772565707564354\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 3.6497769355773926 | KNN Loss: 3.6344547271728516 | CLS Loss: 0.015322267077863216\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 3.6580262184143066 | KNN Loss: 3.646272659301758 | CLS Loss: 0.011753503233194351\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 3.599104642868042 | KNN Loss: 3.593717575073242 | CLS Loss: 0.005387177690863609\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 3.6310832500457764 | KNN Loss: 3.611165761947632 | CLS Loss: 0.019917532801628113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 3.5954298973083496 | KNN Loss: 3.5792620182037354 | CLS Loss: 0.01616794802248478\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 3.6653692722320557 | KNN Loss: 3.660672187805176 | CLS Loss: 0.004697154741734266\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 3.63822603225708 | KNN Loss: 3.63690185546875 | CLS Loss: 0.001324193668551743\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 3.617915391921997 | KNN Loss: 3.600184679031372 | CLS Loss: 0.017730824649333954\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 3.6822149753570557 | KNN Loss: 3.65476655960083 | CLS Loss: 0.02744852751493454\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 3.638619899749756 | KNN Loss: 3.633920907974243 | CLS Loss: 0.0046988981775939465\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 3.681699275970459 | KNN Loss: 3.6619575023651123 | CLS Loss: 0.019741810858249664\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 3.6591529846191406 | KNN Loss: 3.643249273300171 | CLS Loss: 0.01590360887348652\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 3.6246979236602783 | KNN Loss: 3.616152048110962 | CLS Loss: 0.008545948192477226\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 3.6916143894195557 | KNN Loss: 3.6561267375946045 | CLS Loss: 0.03548770397901535\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 3.6128647327423096 | KNN Loss: 3.599544048309326 | CLS Loss: 0.013320667669177055\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 3.6510579586029053 | KNN Loss: 3.6330440044403076 | CLS Loss: 0.01801394857466221\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 3.6304028034210205 | KNN Loss: 3.6129627227783203 | CLS Loss: 0.01744014583528042\n",
      "Epoch: 129, Loss: 3.6401, Train: 0.9964, Valid: 0.9874, Best: 0.9876\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 3.634897232055664 | KNN Loss: 3.6298654079437256 | CLS Loss: 0.005031744483858347\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 3.617581605911255 | KNN Loss: 3.6079792976379395 | CLS Loss: 0.009602375328540802\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 3.641298294067383 | KNN Loss: 3.6283960342407227 | CLS Loss: 0.01290222816169262\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 3.6558690071105957 | KNN Loss: 3.639822483062744 | CLS Loss: 0.016046518459916115\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 3.63222074508667 | KNN Loss: 3.61405348777771 | CLS Loss: 0.018167242407798767\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 3.6636199951171875 | KNN Loss: 3.6465537548065186 | CLS Loss: 0.017066344618797302\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 3.66335391998291 | KNN Loss: 3.6531894207000732 | CLS Loss: 0.010164542123675346\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 3.610382080078125 | KNN Loss: 3.6063125133514404 | CLS Loss: 0.004069685470312834\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 3.6269125938415527 | KNN Loss: 3.6216068267822266 | CLS Loss: 0.005305678118020296\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 3.6173441410064697 | KNN Loss: 3.6155614852905273 | CLS Loss: 0.0017825631657615304\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 3.632042169570923 | KNN Loss: 3.6237785816192627 | CLS Loss: 0.008263577707111835\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 3.618398666381836 | KNN Loss: 3.6041676998138428 | CLS Loss: 0.014230849221348763\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 3.6096787452697754 | KNN Loss: 3.597736120223999 | CLS Loss: 0.011942530982196331\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 3.637876272201538 | KNN Loss: 3.624337673187256 | CLS Loss: 0.013538540340960026\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 3.641796112060547 | KNN Loss: 3.6353418827056885 | CLS Loss: 0.006454203277826309\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 3.6301567554473877 | KNN Loss: 3.6214113235473633 | CLS Loss: 0.008745390921831131\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 3.644249677658081 | KNN Loss: 3.640547752380371 | CLS Loss: 0.003701820969581604\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 3.639916181564331 | KNN Loss: 3.6377549171447754 | CLS Loss: 0.0021612353157252073\n",
      "Epoch: 130, Loss: 3.6343, Train: 0.9964, Valid: 0.9858, Best: 0.9876\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 3.61106538772583 | KNN Loss: 3.609110116958618 | CLS Loss: 0.001955215120688081\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 3.618903636932373 | KNN Loss: 3.601551055908203 | CLS Loss: 0.017352623865008354\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 3.639542579650879 | KNN Loss: 3.6177825927734375 | CLS Loss: 0.021759899333119392\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 3.6241281032562256 | KNN Loss: 3.6002185344696045 | CLS Loss: 0.023909665644168854\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 3.6844773292541504 | KNN Loss: 3.6729636192321777 | CLS Loss: 0.011513604782521725\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 3.640805721282959 | KNN Loss: 3.637105703353882 | CLS Loss: 0.003699997905641794\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 3.6208994388580322 | KNN Loss: 3.607793092727661 | CLS Loss: 0.013106293976306915\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 3.619020700454712 | KNN Loss: 3.5874087810516357 | CLS Loss: 0.0316118560731411\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 3.671621799468994 | KNN Loss: 3.6624159812927246 | CLS Loss: 0.009205755777657032\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 3.6200101375579834 | KNN Loss: 3.6073837280273438 | CLS Loss: 0.01262641791254282\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 3.622643232345581 | KNN Loss: 3.61540150642395 | CLS Loss: 0.007241739891469479\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 3.6114792823791504 | KNN Loss: 3.6012158393859863 | CLS Loss: 0.010263554751873016\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 3.6486735343933105 | KNN Loss: 3.6463840007781982 | CLS Loss: 0.00228944537229836\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 3.611070394515991 | KNN Loss: 3.5902931690216064 | CLS Loss: 0.020777279511094093\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 3.7125210762023926 | KNN Loss: 3.691023826599121 | CLS Loss: 0.021497350186109543\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 3.6445109844207764 | KNN Loss: 3.609835386276245 | CLS Loss: 0.034675609320402145\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 3.661302328109741 | KNN Loss: 3.652245044708252 | CLS Loss: 0.009057300165295601\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 3.654442310333252 | KNN Loss: 3.604074478149414 | CLS Loss: 0.05036771297454834\n",
      "Epoch: 131, Loss: 3.6325, Train: 0.9952, Valid: 0.9844, Best: 0.9876\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 3.593595266342163 | KNN Loss: 3.5877087116241455 | CLS Loss: 0.005886512342840433\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 3.6501173973083496 | KNN Loss: 3.6420772075653076 | CLS Loss: 0.008040142245590687\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 3.628074884414673 | KNN Loss: 3.616567611694336 | CLS Loss: 0.011507205665111542\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 3.627645492553711 | KNN Loss: 3.595735788345337 | CLS Loss: 0.03190966695547104\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 3.6155741214752197 | KNN Loss: 3.590510606765747 | CLS Loss: 0.025063421577215195\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 3.6044578552246094 | KNN Loss: 3.586193084716797 | CLS Loss: 0.018264809623360634\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 3.6571836471557617 | KNN Loss: 3.6258318424224854 | CLS Loss: 0.03135189786553383\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 3.6293349266052246 | KNN Loss: 3.6100521087646484 | CLS Loss: 0.019282832741737366\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 3.640998601913452 | KNN Loss: 3.6319289207458496 | CLS Loss: 0.009069683961570263\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 3.6022706031799316 | KNN Loss: 3.596970558166504 | CLS Loss: 0.005300160031765699\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 3.647885799407959 | KNN Loss: 3.6259829998016357 | CLS Loss: 0.021902834996581078\n",
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 3.634716749191284 | KNN Loss: 3.6313557624816895 | CLS Loss: 0.0033609436359256506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 3.652517795562744 | KNN Loss: 3.620737314224243 | CLS Loss: 0.0317804254591465\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 3.640562057495117 | KNN Loss: 3.62310791015625 | CLS Loss: 0.017454082146286964\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 3.6282551288604736 | KNN Loss: 3.6213486194610596 | CLS Loss: 0.006906555965542793\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 3.6288001537323 | KNN Loss: 3.6045637130737305 | CLS Loss: 0.024236558005213737\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 3.6037237644195557 | KNN Loss: 3.599393129348755 | CLS Loss: 0.0043307337909936905\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 3.626636266708374 | KNN Loss: 3.608339786529541 | CLS Loss: 0.018296506255865097\n",
      "Epoch: 132, Loss: 3.6245, Train: 0.9964, Valid: 0.9861, Best: 0.9876\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 3.626883029937744 | KNN Loss: 3.624532461166382 | CLS Loss: 0.0023506709840148687\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 3.61807918548584 | KNN Loss: 3.611523151397705 | CLS Loss: 0.006556009873747826\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 3.5939993858337402 | KNN Loss: 3.590721845626831 | CLS Loss: 0.003277476876974106\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 3.6285433769226074 | KNN Loss: 3.6183624267578125 | CLS Loss: 0.010181060060858727\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 3.6427719593048096 | KNN Loss: 3.6274895668029785 | CLS Loss: 0.01528229471296072\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 3.620795965194702 | KNN Loss: 3.5953619480133057 | CLS Loss: 0.02543405070900917\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 3.6131513118743896 | KNN Loss: 3.6028783321380615 | CLS Loss: 0.010272984392940998\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 3.6437087059020996 | KNN Loss: 3.6244356632232666 | CLS Loss: 0.019273068755865097\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 3.6280603408813477 | KNN Loss: 3.625375270843506 | CLS Loss: 0.0026850311551243067\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 3.6200644969940186 | KNN Loss: 3.608363389968872 | CLS Loss: 0.011701074428856373\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 3.6600916385650635 | KNN Loss: 3.6481895446777344 | CLS Loss: 0.011902022175490856\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 3.6104650497436523 | KNN Loss: 3.5955607891082764 | CLS Loss: 0.01490425318479538\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 3.6399199962615967 | KNN Loss: 3.630117654800415 | CLS Loss: 0.009802385233342648\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 3.6624996662139893 | KNN Loss: 3.6455135345458984 | CLS Loss: 0.016986224800348282\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 3.6420352458953857 | KNN Loss: 3.6210696697235107 | CLS Loss: 0.020965462550520897\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 3.6097793579101562 | KNN Loss: 3.600332498550415 | CLS Loss: 0.009446850046515465\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 3.6215786933898926 | KNN Loss: 3.612363338470459 | CLS Loss: 0.009215421974658966\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 3.6580889225006104 | KNN Loss: 3.644944429397583 | CLS Loss: 0.013144491240382195\n",
      "Epoch: 133, Loss: 3.6374, Train: 0.9966, Valid: 0.9864, Best: 0.9876\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 3.643770456314087 | KNN Loss: 3.639456272125244 | CLS Loss: 0.004314261022955179\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 3.6144275665283203 | KNN Loss: 3.6042399406433105 | CLS Loss: 0.010187643580138683\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 3.605581045150757 | KNN Loss: 3.5983402729034424 | CLS Loss: 0.0072408816777169704\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 3.5969109535217285 | KNN Loss: 3.558760643005371 | CLS Loss: 0.0381503663957119\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 3.622927665710449 | KNN Loss: 3.613828659057617 | CLS Loss: 0.009098922833800316\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 3.657104969024658 | KNN Loss: 3.6234655380249023 | CLS Loss: 0.03363938257098198\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 3.6238040924072266 | KNN Loss: 3.6099984645843506 | CLS Loss: 0.013805515132844448\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 3.625154972076416 | KNN Loss: 3.6144750118255615 | CLS Loss: 0.010679845698177814\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 3.662886381149292 | KNN Loss: 3.618032217025757 | CLS Loss: 0.04485420510172844\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 3.6272597312927246 | KNN Loss: 3.620603322982788 | CLS Loss: 0.006656426936388016\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 3.637378692626953 | KNN Loss: 3.603649854660034 | CLS Loss: 0.03372881934046745\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 3.625852584838867 | KNN Loss: 3.6162068843841553 | CLS Loss: 0.009645702317357063\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 3.6785542964935303 | KNN Loss: 3.6420633792877197 | CLS Loss: 0.03649096563458443\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 3.611599922180176 | KNN Loss: 3.5897789001464844 | CLS Loss: 0.0218210332095623\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 3.6036946773529053 | KNN Loss: 3.59039044380188 | CLS Loss: 0.01330422330647707\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 3.6582698822021484 | KNN Loss: 3.6458401679992676 | CLS Loss: 0.012429596856236458\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 3.67449688911438 | KNN Loss: 3.660537004470825 | CLS Loss: 0.013959814794361591\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 3.6266636848449707 | KNN Loss: 3.604097604751587 | CLS Loss: 0.022565994411706924\n",
      "Epoch: 134, Loss: 3.6334, Train: 0.9964, Valid: 0.9860, Best: 0.9876\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 3.6205108165740967 | KNN Loss: 3.6044085025787354 | CLS Loss: 0.016102278605103493\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 3.6666998863220215 | KNN Loss: 3.6576461791992188 | CLS Loss: 0.00905376672744751\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 3.6725802421569824 | KNN Loss: 3.6653265953063965 | CLS Loss: 0.007253621704876423\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 3.613334894180298 | KNN Loss: 3.5979716777801514 | CLS Loss: 0.015363332815468311\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 3.6826534271240234 | KNN Loss: 3.676683187484741 | CLS Loss: 0.005970288999378681\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 3.6471927165985107 | KNN Loss: 3.636021852493286 | CLS Loss: 0.011170832440257072\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 3.6824028491973877 | KNN Loss: 3.6725711822509766 | CLS Loss: 0.009831770323216915\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 3.6080408096313477 | KNN Loss: 3.5917088985443115 | CLS Loss: 0.01633201353251934\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 3.6208131313323975 | KNN Loss: 3.600478172302246 | CLS Loss: 0.020334908738732338\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 3.643862247467041 | KNN Loss: 3.627105236053467 | CLS Loss: 0.016757065430283546\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 3.6534175872802734 | KNN Loss: 3.6397671699523926 | CLS Loss: 0.013650314882397652\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 3.6437342166900635 | KNN Loss: 3.633040189743042 | CLS Loss: 0.01069391518831253\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 3.6311428546905518 | KNN Loss: 3.6216580867767334 | CLS Loss: 0.009484886191785336\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 3.675929307937622 | KNN Loss: 3.670403480529785 | CLS Loss: 0.005525777116417885\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 3.6547632217407227 | KNN Loss: 3.645110607147217 | CLS Loss: 0.009652520529925823\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 3.6031746864318848 | KNN Loss: 3.59432053565979 | CLS Loss: 0.008854041807353497\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 3.5946013927459717 | KNN Loss: 3.571094512939453 | CLS Loss: 0.023506810888648033\n",
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 3.606849431991577 | KNN Loss: 3.597919225692749 | CLS Loss: 0.008930293843150139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Loss: 3.6318, Train: 0.9968, Valid: 0.9855, Best: 0.9876\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 3.651228427886963 | KNN Loss: 3.6492791175842285 | CLS Loss: 0.001949426019564271\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 3.621546745300293 | KNN Loss: 3.604398250579834 | CLS Loss: 0.017148494720458984\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 3.6652674674987793 | KNN Loss: 3.6407558917999268 | CLS Loss: 0.02451159618794918\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 3.6104776859283447 | KNN Loss: 3.5993235111236572 | CLS Loss: 0.011154129169881344\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 3.620788335800171 | KNN Loss: 3.6153926849365234 | CLS Loss: 0.005395571701228619\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 3.6073827743530273 | KNN Loss: 3.584610939025879 | CLS Loss: 0.022771866992115974\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 3.6058828830718994 | KNN Loss: 3.5982143878936768 | CLS Loss: 0.007668403908610344\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 3.6492340564727783 | KNN Loss: 3.639925241470337 | CLS Loss: 0.009308918379247189\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 3.633547306060791 | KNN Loss: 3.62481689453125 | CLS Loss: 0.008730311878025532\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 3.6896004676818848 | KNN Loss: 3.6803035736083984 | CLS Loss: 0.009296966716647148\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 3.6283321380615234 | KNN Loss: 3.617471694946289 | CLS Loss: 0.010860531590878963\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 3.648911714553833 | KNN Loss: 3.640455484390259 | CLS Loss: 0.008456125855445862\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 3.6210367679595947 | KNN Loss: 3.6109681129455566 | CLS Loss: 0.01006869412958622\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 3.637340784072876 | KNN Loss: 3.622180700302124 | CLS Loss: 0.015160133130848408\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 3.6552412509918213 | KNN Loss: 3.6429386138916016 | CLS Loss: 0.012302725575864315\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 3.6499781608581543 | KNN Loss: 3.6329410076141357 | CLS Loss: 0.017037266865372658\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 3.6437056064605713 | KNN Loss: 3.6262600421905518 | CLS Loss: 0.01744551956653595\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 3.6072380542755127 | KNN Loss: 3.6001029014587402 | CLS Loss: 0.0071350461803376675\n",
      "Epoch: 136, Loss: 3.6301, Train: 0.9968, Valid: 0.9860, Best: 0.9876\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 3.617135524749756 | KNN Loss: 3.613377094268799 | CLS Loss: 0.003758311504498124\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 3.6142420768737793 | KNN Loss: 3.604924201965332 | CLS Loss: 0.009317846968770027\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 3.6587963104248047 | KNN Loss: 3.6392107009887695 | CLS Loss: 0.01958560198545456\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 3.6340439319610596 | KNN Loss: 3.607259750366211 | CLS Loss: 0.026784271001815796\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 3.615669012069702 | KNN Loss: 3.607182741165161 | CLS Loss: 0.008486228995025158\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 3.6265439987182617 | KNN Loss: 3.6179323196411133 | CLS Loss: 0.008611631579697132\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 3.625927686691284 | KNN Loss: 3.606233835220337 | CLS Loss: 0.019693778827786446\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 3.596234083175659 | KNN Loss: 3.591647148132324 | CLS Loss: 0.00458690756931901\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 3.6195499897003174 | KNN Loss: 3.602717638015747 | CLS Loss: 0.016832435503602028\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 3.6377604007720947 | KNN Loss: 3.6294238567352295 | CLS Loss: 0.008336592465639114\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 3.658174514770508 | KNN Loss: 3.6482272148132324 | CLS Loss: 0.009947186335921288\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 3.622939109802246 | KNN Loss: 3.5917112827301025 | CLS Loss: 0.031227827072143555\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 3.6057963371276855 | KNN Loss: 3.5927951335906982 | CLS Loss: 0.013001257553696632\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 3.658083915710449 | KNN Loss: 3.6413416862487793 | CLS Loss: 0.01674213819205761\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 3.6167104244232178 | KNN Loss: 3.6107139587402344 | CLS Loss: 0.005996352061629295\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 3.595848798751831 | KNN Loss: 3.5921857357025146 | CLS Loss: 0.0036631450057029724\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 3.594831943511963 | KNN Loss: 3.589319944381714 | CLS Loss: 0.005511954426765442\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 3.6351399421691895 | KNN Loss: 3.6186115741729736 | CLS Loss: 0.016528405249118805\n",
      "Epoch: 137, Loss: 3.6249, Train: 0.9972, Valid: 0.9864, Best: 0.9876\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 3.6313588619232178 | KNN Loss: 3.625657081604004 | CLS Loss: 0.005701770074665546\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 3.633057117462158 | KNN Loss: 3.6259710788726807 | CLS Loss: 0.0070859333500266075\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 3.631591320037842 | KNN Loss: 3.6283466815948486 | CLS Loss: 0.003244600724428892\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 3.6107709407806396 | KNN Loss: 3.593851327896118 | CLS Loss: 0.01691954955458641\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 3.620293140411377 | KNN Loss: 3.6160035133361816 | CLS Loss: 0.0042896452359855175\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 3.6421897411346436 | KNN Loss: 3.6292994022369385 | CLS Loss: 0.012890334241092205\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 3.6438584327697754 | KNN Loss: 3.6214418411254883 | CLS Loss: 0.02241656929254532\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 3.6611685752868652 | KNN Loss: 3.6293437480926514 | CLS Loss: 0.031824905425310135\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 3.6380457878112793 | KNN Loss: 3.63093638420105 | CLS Loss: 0.007109339814633131\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 3.5790092945098877 | KNN Loss: 3.571211099624634 | CLS Loss: 0.0077982740476727486\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 3.646596908569336 | KNN Loss: 3.6190199851989746 | CLS Loss: 0.027576830238103867\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 3.6299073696136475 | KNN Loss: 3.6158947944641113 | CLS Loss: 0.014012647792696953\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 3.6485748291015625 | KNN Loss: 3.6206321716308594 | CLS Loss: 0.027942663058638573\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 3.624650478363037 | KNN Loss: 3.603229284286499 | CLS Loss: 0.021421199664473534\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 3.6594345569610596 | KNN Loss: 3.6483848094940186 | CLS Loss: 0.011049640364944935\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 3.6516852378845215 | KNN Loss: 3.634608745574951 | CLS Loss: 0.01707659848034382\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 3.606126546859741 | KNN Loss: 3.598729372024536 | CLS Loss: 0.007397092878818512\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 3.6052234172821045 | KNN Loss: 3.601186513900757 | CLS Loss: 0.004036818630993366\n",
      "Epoch: 138, Loss: 3.6289, Train: 0.9965, Valid: 0.9862, Best: 0.9876\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 3.6098923683166504 | KNN Loss: 3.607391357421875 | CLS Loss: 0.002501047682017088\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 3.6386234760284424 | KNN Loss: 3.619103193283081 | CLS Loss: 0.019520353525877\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 3.6131341457366943 | KNN Loss: 3.5981831550598145 | CLS Loss: 0.01495096180588007\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 3.668606758117676 | KNN Loss: 3.654357433319092 | CLS Loss: 0.01424923911690712\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 3.630936861038208 | KNN Loss: 3.620669364929199 | CLS Loss: 0.010267481207847595\n",
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 3.640249729156494 | KNN Loss: 3.6102230548858643 | CLS Loss: 0.030026622116565704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 3.6040139198303223 | KNN Loss: 3.5955166816711426 | CLS Loss: 0.008497237227857113\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 3.6183176040649414 | KNN Loss: 3.609783411026001 | CLS Loss: 0.008534112013876438\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 3.6277382373809814 | KNN Loss: 3.622814893722534 | CLS Loss: 0.00492327893152833\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 3.679542303085327 | KNN Loss: 3.6577162742614746 | CLS Loss: 0.02182612754404545\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 3.6138951778411865 | KNN Loss: 3.5937552452087402 | CLS Loss: 0.020140044391155243\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 3.6832289695739746 | KNN Loss: 3.6762146949768066 | CLS Loss: 0.007014315575361252\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 3.612980365753174 | KNN Loss: 3.600708484649658 | CLS Loss: 0.012271893210709095\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 3.651127338409424 | KNN Loss: 3.6320667266845703 | CLS Loss: 0.01906050182878971\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 3.611872673034668 | KNN Loss: 3.6065151691436768 | CLS Loss: 0.0053574806079268456\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 3.644526243209839 | KNN Loss: 3.626352548599243 | CLS Loss: 0.01817363128066063\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 3.6370317935943604 | KNN Loss: 3.6203737258911133 | CLS Loss: 0.016658009961247444\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 3.627610206604004 | KNN Loss: 3.61398983001709 | CLS Loss: 0.01362049113959074\n",
      "Epoch: 139, Loss: 3.6263, Train: 0.9967, Valid: 0.9854, Best: 0.9876\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 3.6178014278411865 | KNN Loss: 3.6135759353637695 | CLS Loss: 0.004225548822432756\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 3.5912210941314697 | KNN Loss: 3.587641954421997 | CLS Loss: 0.0035790940746665\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 3.636277198791504 | KNN Loss: 3.629209041595459 | CLS Loss: 0.0070681143552064896\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 3.6214969158172607 | KNN Loss: 3.5898709297180176 | CLS Loss: 0.03162596747279167\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 3.6163699626922607 | KNN Loss: 3.6101489067077637 | CLS Loss: 0.0062209791503846645\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 3.6457111835479736 | KNN Loss: 3.6383070945739746 | CLS Loss: 0.007404114119708538\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 3.6464061737060547 | KNN Loss: 3.6087448596954346 | CLS Loss: 0.03766142204403877\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 3.627267837524414 | KNN Loss: 3.612166166305542 | CLS Loss: 0.015101585537195206\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 3.6375722885131836 | KNN Loss: 3.6239013671875 | CLS Loss: 0.013670884072780609\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 3.6161491870880127 | KNN Loss: 3.614077091217041 | CLS Loss: 0.0020720011088997126\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 3.63232159614563 | KNN Loss: 3.610412359237671 | CLS Loss: 0.021909143775701523\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 3.671509027481079 | KNN Loss: 3.6613502502441406 | CLS Loss: 0.010158680379390717\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 3.6492910385131836 | KNN Loss: 3.62628173828125 | CLS Loss: 0.023009315133094788\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 3.6377527713775635 | KNN Loss: 3.624389886856079 | CLS Loss: 0.013362975791096687\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 3.6234400272369385 | KNN Loss: 3.6083080768585205 | CLS Loss: 0.01513204351067543\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 3.617213010787964 | KNN Loss: 3.611692428588867 | CLS Loss: 0.005520616192370653\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 3.6391215324401855 | KNN Loss: 3.628047466278076 | CLS Loss: 0.011074141599237919\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 3.5980358123779297 | KNN Loss: 3.5944950580596924 | CLS Loss: 0.0035406998358666897\n",
      "Epoch: 140, Loss: 3.6271, Train: 0.9969, Valid: 0.9865, Best: 0.9876\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 3.6094563007354736 | KNN Loss: 3.603818416595459 | CLS Loss: 0.005637823604047298\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 3.639226198196411 | KNN Loss: 3.6351983547210693 | CLS Loss: 0.004027814604341984\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 3.671140432357788 | KNN Loss: 3.666188955307007 | CLS Loss: 0.004951500799506903\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 3.591463804244995 | KNN Loss: 3.5806000232696533 | CLS Loss: 0.010863885283470154\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 3.6164398193359375 | KNN Loss: 3.6015877723693848 | CLS Loss: 0.014852042309939861\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 3.621124744415283 | KNN Loss: 3.599316120147705 | CLS Loss: 0.021808546036481857\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 3.586203098297119 | KNN Loss: 3.5833933353424072 | CLS Loss: 0.0028096437454223633\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 3.6458895206451416 | KNN Loss: 3.6408214569091797 | CLS Loss: 0.005068004596978426\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 3.621732473373413 | KNN Loss: 3.604153871536255 | CLS Loss: 0.017578519880771637\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 3.6336355209350586 | KNN Loss: 3.6118173599243164 | CLS Loss: 0.021818235516548157\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 3.6410186290740967 | KNN Loss: 3.6374337673187256 | CLS Loss: 0.0035848922561854124\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 3.6821112632751465 | KNN Loss: 3.672732353210449 | CLS Loss: 0.009378856047987938\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 3.60109281539917 | KNN Loss: 3.592742443084717 | CLS Loss: 0.008350363001227379\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 3.6024210453033447 | KNN Loss: 3.5824646949768066 | CLS Loss: 0.01995641551911831\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 3.6313726902008057 | KNN Loss: 3.6240837574005127 | CLS Loss: 0.007289004046469927\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 3.6329517364501953 | KNN Loss: 3.618619680404663 | CLS Loss: 0.014331970363855362\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 3.626821994781494 | KNN Loss: 3.6234395503997803 | CLS Loss: 0.0033825356513261795\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 3.718897581100464 | KNN Loss: 3.7007241249084473 | CLS Loss: 0.01817352883517742\n",
      "Epoch: 141, Loss: 3.6320, Train: 0.9969, Valid: 0.9862, Best: 0.9876\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 3.6107325553894043 | KNN Loss: 3.606203079223633 | CLS Loss: 0.004529534373432398\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 3.608750104904175 | KNN Loss: 3.588576316833496 | CLS Loss: 0.020173799246549606\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 3.6701536178588867 | KNN Loss: 3.663794994354248 | CLS Loss: 0.0063585881143808365\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 3.621086359024048 | KNN Loss: 3.589986801147461 | CLS Loss: 0.031099561601877213\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 3.628133773803711 | KNN Loss: 3.614745855331421 | CLS Loss: 0.013387897051870823\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 3.635249376296997 | KNN Loss: 3.631631374359131 | CLS Loss: 0.003617956768721342\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 3.6395537853240967 | KNN Loss: 3.629915237426758 | CLS Loss: 0.009638510644435883\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 3.625262498855591 | KNN Loss: 3.6218364238739014 | CLS Loss: 0.003426180686801672\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 3.609869956970215 | KNN Loss: 3.6063313484191895 | CLS Loss: 0.003538699820637703\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 3.6618165969848633 | KNN Loss: 3.6495182514190674 | CLS Loss: 0.012298397719860077\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 3.7244837284088135 | KNN Loss: 3.6902451515197754 | CLS Loss: 0.03423851728439331\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 3.691458225250244 | KNN Loss: 3.655744791030884 | CLS Loss: 0.03571344539523125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 3.629305839538574 | KNN Loss: 3.6237807273864746 | CLS Loss: 0.005525009706616402\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 3.602107524871826 | KNN Loss: 3.5902013778686523 | CLS Loss: 0.011906190775334835\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 3.6525707244873047 | KNN Loss: 3.6429953575134277 | CLS Loss: 0.009575475007295609\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 3.6267483234405518 | KNN Loss: 3.6000771522521973 | CLS Loss: 0.02667112462222576\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 3.609285354614258 | KNN Loss: 3.596386432647705 | CLS Loss: 0.012899026274681091\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 3.6330983638763428 | KNN Loss: 3.6079976558685303 | CLS Loss: 0.025100799277424812\n",
      "Epoch: 142, Loss: 3.6361, Train: 0.9966, Valid: 0.9856, Best: 0.9876\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 3.5815141201019287 | KNN Loss: 3.5699427127838135 | CLS Loss: 0.011571464128792286\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 3.6840271949768066 | KNN Loss: 3.663486957550049 | CLS Loss: 0.020540330559015274\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 3.6426985263824463 | KNN Loss: 3.6392250061035156 | CLS Loss: 0.0034736045636236668\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 3.6741485595703125 | KNN Loss: 3.6344170570373535 | CLS Loss: 0.039731599390506744\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 3.604881525039673 | KNN Loss: 3.599581003189087 | CLS Loss: 0.005300462245941162\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 3.6039960384368896 | KNN Loss: 3.6002111434936523 | CLS Loss: 0.003784999717026949\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 3.59674334526062 | KNN Loss: 3.5911285877227783 | CLS Loss: 0.005614775232970715\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 3.6136863231658936 | KNN Loss: 3.597470760345459 | CLS Loss: 0.016215629875659943\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 3.6955649852752686 | KNN Loss: 3.6915841102600098 | CLS Loss: 0.003980856854468584\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 3.6480815410614014 | KNN Loss: 3.615558624267578 | CLS Loss: 0.03252287581562996\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 3.6562135219573975 | KNN Loss: 3.6288318634033203 | CLS Loss: 0.02738158404827118\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 3.646317720413208 | KNN Loss: 3.6395046710968018 | CLS Loss: 0.006812931038439274\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 3.6241047382354736 | KNN Loss: 3.613821506500244 | CLS Loss: 0.01028313860297203\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 3.6578099727630615 | KNN Loss: 3.6169252395629883 | CLS Loss: 0.040884628891944885\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 3.611980438232422 | KNN Loss: 3.6077847480773926 | CLS Loss: 0.004195656627416611\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 3.609149694442749 | KNN Loss: 3.605825424194336 | CLS Loss: 0.0033243554644286633\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 3.5899109840393066 | KNN Loss: 3.583750009536743 | CLS Loss: 0.006161075085401535\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 3.6042520999908447 | KNN Loss: 3.5982911586761475 | CLS Loss: 0.0059609501622617245\n",
      "Epoch: 143, Loss: 3.6314, Train: 0.9954, Valid: 0.9842, Best: 0.9876\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 3.6289663314819336 | KNN Loss: 3.6154518127441406 | CLS Loss: 0.013514457270503044\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 3.626469850540161 | KNN Loss: 3.6023073196411133 | CLS Loss: 0.024162529036402702\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 3.636914014816284 | KNN Loss: 3.630199909210205 | CLS Loss: 0.006714063696563244\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 3.6158478260040283 | KNN Loss: 3.5995256900787354 | CLS Loss: 0.01632225327193737\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 3.621752977371216 | KNN Loss: 3.616896152496338 | CLS Loss: 0.0048568700440227985\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 3.6310527324676514 | KNN Loss: 3.628889560699463 | CLS Loss: 0.002163129625841975\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 3.6493966579437256 | KNN Loss: 3.625197649002075 | CLS Loss: 0.02419893443584442\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 3.6674110889434814 | KNN Loss: 3.6260621547698975 | CLS Loss: 0.041348885744810104\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 3.626519203186035 | KNN Loss: 3.6193950176239014 | CLS Loss: 0.007124234922230244\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 3.6652426719665527 | KNN Loss: 3.656388282775879 | CLS Loss: 0.008854420855641365\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 3.622119188308716 | KNN Loss: 3.603367805480957 | CLS Loss: 0.018751366063952446\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 3.6247949600219727 | KNN Loss: 3.618837833404541 | CLS Loss: 0.005957191810011864\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 3.6352579593658447 | KNN Loss: 3.6279938220977783 | CLS Loss: 0.007264152634888887\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 3.6158835887908936 | KNN Loss: 3.6045615673065186 | CLS Loss: 0.01132198516279459\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 3.644292116165161 | KNN Loss: 3.6355156898498535 | CLS Loss: 0.008776403963565826\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 3.611053705215454 | KNN Loss: 3.6031711101531982 | CLS Loss: 0.007882651872932911\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 3.6927242279052734 | KNN Loss: 3.6875288486480713 | CLS Loss: 0.005195449572056532\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 3.61952543258667 | KNN Loss: 3.6141247749328613 | CLS Loss: 0.005400565918534994\n",
      "Epoch: 144, Loss: 3.6283, Train: 0.9975, Valid: 0.9852, Best: 0.9876\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 3.614393949508667 | KNN Loss: 3.607556104660034 | CLS Loss: 0.006837749853730202\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 3.626643419265747 | KNN Loss: 3.5923421382904053 | CLS Loss: 0.034301258623600006\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 3.6274678707122803 | KNN Loss: 3.617474317550659 | CLS Loss: 0.00999352615326643\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 3.6101086139678955 | KNN Loss: 3.6064348220825195 | CLS Loss: 0.003673784201964736\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 3.6135473251342773 | KNN Loss: 3.600059747695923 | CLS Loss: 0.013487614691257477\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 3.6454925537109375 | KNN Loss: 3.642803907394409 | CLS Loss: 0.0026887317653745413\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 3.6109049320220947 | KNN Loss: 3.58808970451355 | CLS Loss: 0.02281532622873783\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 3.581573009490967 | KNN Loss: 3.563286781311035 | CLS Loss: 0.018286271020770073\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 3.618319272994995 | KNN Loss: 3.6098263263702393 | CLS Loss: 0.008493009023368359\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 3.599128007888794 | KNN Loss: 3.593395709991455 | CLS Loss: 0.005732315126806498\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 3.6407663822174072 | KNN Loss: 3.6311044692993164 | CLS Loss: 0.009661994874477386\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 3.6796975135803223 | KNN Loss: 3.6673526763916016 | CLS Loss: 0.012344776652753353\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 3.674591302871704 | KNN Loss: 3.6692025661468506 | CLS Loss: 0.0053888424299657345\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 3.6149075031280518 | KNN Loss: 3.5976271629333496 | CLS Loss: 0.01728030852973461\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 3.630470037460327 | KNN Loss: 3.605823278427124 | CLS Loss: 0.02464677393436432\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 3.69864559173584 | KNN Loss: 3.6507890224456787 | CLS Loss: 0.04785647988319397\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 3.6298837661743164 | KNN Loss: 3.6131508350372314 | CLS Loss: 0.016732946038246155\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 3.6554925441741943 | KNN Loss: 3.647361993789673 | CLS Loss: 0.008130497299134731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, Loss: 3.6263, Train: 0.9961, Valid: 0.9857, Best: 0.9876\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 3.630467176437378 | KNN Loss: 3.6008429527282715 | CLS Loss: 0.029624175280332565\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 3.669983386993408 | KNN Loss: 3.662234306335449 | CLS Loss: 0.0077491640113294125\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 3.641341209411621 | KNN Loss: 3.6309127807617188 | CLS Loss: 0.010428446345031261\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 3.6484375 | KNN Loss: 3.643630027770996 | CLS Loss: 0.004807477351278067\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 3.574648857116699 | KNN Loss: 3.569812059402466 | CLS Loss: 0.00483689084649086\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 3.6487419605255127 | KNN Loss: 3.6372599601745605 | CLS Loss: 0.011482003144919872\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 3.6397705078125 | KNN Loss: 3.634249210357666 | CLS Loss: 0.005521188955754042\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 3.60428786277771 | KNN Loss: 3.601361036300659 | CLS Loss: 0.002926842775195837\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 3.636152505874634 | KNN Loss: 3.6313467025756836 | CLS Loss: 0.004805809818208218\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 3.624091386795044 | KNN Loss: 3.6118438243865967 | CLS Loss: 0.012247642502188683\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 3.605508804321289 | KNN Loss: 3.6034204959869385 | CLS Loss: 0.002088331850245595\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 3.63903546333313 | KNN Loss: 3.6359519958496094 | CLS Loss: 0.0030835247598588467\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 3.6457204818725586 | KNN Loss: 3.6281092166900635 | CLS Loss: 0.017611179500818253\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 3.635371685028076 | KNN Loss: 3.626814842224121 | CLS Loss: 0.008556948974728584\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 3.650238513946533 | KNN Loss: 3.630405902862549 | CLS Loss: 0.019832495599985123\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 3.635261297225952 | KNN Loss: 3.6141717433929443 | CLS Loss: 0.021089520305395126\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 3.631478786468506 | KNN Loss: 3.6151368618011475 | CLS Loss: 0.016341879963874817\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 3.6775622367858887 | KNN Loss: 3.6450462341308594 | CLS Loss: 0.032515984028577805\n",
      "Epoch: 146, Loss: 3.6353, Train: 0.9972, Valid: 0.9868, Best: 0.9876\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 3.6021668910980225 | KNN Loss: 3.5997443199157715 | CLS Loss: 0.00242257141508162\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 3.5992543697357178 | KNN Loss: 3.5979676246643066 | CLS Loss: 0.0012867471668869257\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 3.627117156982422 | KNN Loss: 3.615485668182373 | CLS Loss: 0.01163158193230629\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 3.670768976211548 | KNN Loss: 3.634558916091919 | CLS Loss: 0.03620995208621025\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 3.621750593185425 | KNN Loss: 3.6048686504364014 | CLS Loss: 0.016881925985217094\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 3.618734836578369 | KNN Loss: 3.6057310104370117 | CLS Loss: 0.013003753498196602\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 3.6266818046569824 | KNN Loss: 3.6212317943573 | CLS Loss: 0.00544999074190855\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 3.62243914604187 | KNN Loss: 3.615692615509033 | CLS Loss: 0.006746612023562193\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 3.6253414154052734 | KNN Loss: 3.6230063438415527 | CLS Loss: 0.002335001016035676\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 3.596508026123047 | KNN Loss: 3.586784601211548 | CLS Loss: 0.009723491035401821\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 3.6188809871673584 | KNN Loss: 3.615351438522339 | CLS Loss: 0.0035295214038342237\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 3.604931354522705 | KNN Loss: 3.599062442779541 | CLS Loss: 0.005868852604180574\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 3.599848747253418 | KNN Loss: 3.596601724624634 | CLS Loss: 0.003247035201638937\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 3.649806022644043 | KNN Loss: 3.637171745300293 | CLS Loss: 0.012634354643523693\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 3.595186233520508 | KNN Loss: 3.585205078125 | CLS Loss: 0.009981269016861916\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 3.604351282119751 | KNN Loss: 3.6004626750946045 | CLS Loss: 0.003888529259711504\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 3.616741418838501 | KNN Loss: 3.607361316680908 | CLS Loss: 0.009380203671753407\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 3.62317156791687 | KNN Loss: 3.6149635314941406 | CLS Loss: 0.008208017796278\n",
      "Epoch: 147, Loss: 3.6297, Train: 0.9969, Valid: 0.9856, Best: 0.9876\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 3.5911130905151367 | KNN Loss: 3.586777925491333 | CLS Loss: 0.0043350872583687305\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 3.599306106567383 | KNN Loss: 3.5957534313201904 | CLS Loss: 0.0035526216961443424\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 3.5986833572387695 | KNN Loss: 3.57295823097229 | CLS Loss: 0.025725064799189568\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 3.6147348880767822 | KNN Loss: 3.606879234313965 | CLS Loss: 0.007855737581849098\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 3.6018097400665283 | KNN Loss: 3.5832693576812744 | CLS Loss: 0.01854034885764122\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 3.669757127761841 | KNN Loss: 3.6622347831726074 | CLS Loss: 0.0075223143212497234\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 3.6066954135894775 | KNN Loss: 3.590006113052368 | CLS Loss: 0.016689270734786987\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 3.600907802581787 | KNN Loss: 3.5941171646118164 | CLS Loss: 0.006790648680180311\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 3.5884156227111816 | KNN Loss: 3.586252450942993 | CLS Loss: 0.0021631482522934675\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 3.6224727630615234 | KNN Loss: 3.621230125427246 | CLS Loss: 0.0012425690656527877\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 3.6675994396209717 | KNN Loss: 3.648500919342041 | CLS Loss: 0.019098611548542976\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 3.5990781784057617 | KNN Loss: 3.5920321941375732 | CLS Loss: 0.007045892998576164\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 3.6254894733428955 | KNN Loss: 3.606832265853882 | CLS Loss: 0.01865723356604576\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 3.6650238037109375 | KNN Loss: 3.643402338027954 | CLS Loss: 0.02162136137485504\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 3.5950708389282227 | KNN Loss: 3.589550256729126 | CLS Loss: 0.0055204760283231735\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 3.629765510559082 | KNN Loss: 3.6131019592285156 | CLS Loss: 0.016663499176502228\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 3.62030029296875 | KNN Loss: 3.5989015102386475 | CLS Loss: 0.02139880508184433\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 3.630882740020752 | KNN Loss: 3.621814489364624 | CLS Loss: 0.009068319573998451\n",
      "Epoch: 148, Loss: 3.6252, Train: 0.9956, Valid: 0.9846, Best: 0.9876\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 3.6151509284973145 | KNN Loss: 3.6060996055603027 | CLS Loss: 0.009051335975527763\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 3.620788812637329 | KNN Loss: 3.6186695098876953 | CLS Loss: 0.0021192424464970827\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 3.675661325454712 | KNN Loss: 3.6492390632629395 | CLS Loss: 0.02642224356532097\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 3.6607913970947266 | KNN Loss: 3.64652943611145 | CLS Loss: 0.014261969365179539\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 3.661878824234009 | KNN Loss: 3.6499714851379395 | CLS Loss: 0.011907455511391163\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 3.614969491958618 | KNN Loss: 3.606236457824707 | CLS Loss: 0.008732929825782776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 3.631011724472046 | KNN Loss: 3.6190078258514404 | CLS Loss: 0.01200378593057394\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 3.628061294555664 | KNN Loss: 3.625187397003174 | CLS Loss: 0.002873779507353902\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 3.6225202083587646 | KNN Loss: 3.5924363136291504 | CLS Loss: 0.03008384257555008\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 3.6766152381896973 | KNN Loss: 3.6687607765197754 | CLS Loss: 0.00785440020263195\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 3.6344192028045654 | KNN Loss: 3.621608018875122 | CLS Loss: 0.012811115942895412\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 3.65803861618042 | KNN Loss: 3.647348642349243 | CLS Loss: 0.010689914226531982\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 3.686155319213867 | KNN Loss: 3.6373753547668457 | CLS Loss: 0.048779960721731186\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 3.640346050262451 | KNN Loss: 3.6288366317749023 | CLS Loss: 0.011509425938129425\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 3.6492300033569336 | KNN Loss: 3.640493392944336 | CLS Loss: 0.008736547082662582\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 3.6044342517852783 | KNN Loss: 3.596710205078125 | CLS Loss: 0.0077240122482180595\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 3.603088617324829 | KNN Loss: 3.5778391361236572 | CLS Loss: 0.02524959109723568\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 3.5875680446624756 | KNN Loss: 3.583958625793457 | CLS Loss: 0.0036095071118324995\n",
      "Epoch: 149, Loss: 3.6310, Train: 0.9966, Valid: 0.9851, Best: 0.9876\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 3.609139919281006 | KNN Loss: 3.5716283321380615 | CLS Loss: 0.03751151263713837\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 3.6157169342041016 | KNN Loss: 3.5910415649414062 | CLS Loss: 0.024675482884049416\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 3.609473466873169 | KNN Loss: 3.592198610305786 | CLS Loss: 0.017274955287575722\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 3.6081910133361816 | KNN Loss: 3.5964736938476562 | CLS Loss: 0.011717383749783039\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 3.619476556777954 | KNN Loss: 3.6028800010681152 | CLS Loss: 0.01659667119383812\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 3.6199088096618652 | KNN Loss: 3.61674427986145 | CLS Loss: 0.0031644294504076242\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 3.5934460163116455 | KNN Loss: 3.5881052017211914 | CLS Loss: 0.005340867675840855\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 3.6472480297088623 | KNN Loss: 3.632552146911621 | CLS Loss: 0.01469593495130539\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 3.59252667427063 | KNN Loss: 3.572192430496216 | CLS Loss: 0.020334254950284958\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 3.6148452758789062 | KNN Loss: 3.5932962894439697 | CLS Loss: 0.02154904045164585\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 3.6150248050689697 | KNN Loss: 3.610398769378662 | CLS Loss: 0.004625992849469185\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 3.6331989765167236 | KNN Loss: 3.612298011779785 | CLS Loss: 0.020900936797261238\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 3.6803388595581055 | KNN Loss: 3.670881748199463 | CLS Loss: 0.009457017295062542\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 3.6359152793884277 | KNN Loss: 3.6105072498321533 | CLS Loss: 0.025407986715435982\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 3.6341679096221924 | KNN Loss: 3.6257340908050537 | CLS Loss: 0.00843372754752636\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 3.599045991897583 | KNN Loss: 3.584501266479492 | CLS Loss: 0.014544663019478321\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 3.6282742023468018 | KNN Loss: 3.608978271484375 | CLS Loss: 0.019295871257781982\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 3.618851661682129 | KNN Loss: 3.5937180519104004 | CLS Loss: 0.02513362094759941\n",
      "Epoch: 150, Loss: 3.6200, Train: 0.9973, Valid: 0.9868, Best: 0.9876\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 3.6436731815338135 | KNN Loss: 3.6365208625793457 | CLS Loss: 0.007152313366532326\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 3.6213786602020264 | KNN Loss: 3.597189426422119 | CLS Loss: 0.024189285933971405\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 3.589625835418701 | KNN Loss: 3.5865957736968994 | CLS Loss: 0.003030163701623678\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 3.647563934326172 | KNN Loss: 3.6384143829345703 | CLS Loss: 0.009149660356342793\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 3.614741563796997 | KNN Loss: 3.6024134159088135 | CLS Loss: 0.012328263372182846\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 3.644942045211792 | KNN Loss: 3.6357741355895996 | CLS Loss: 0.009168014861643314\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 3.593372344970703 | KNN Loss: 3.575587749481201 | CLS Loss: 0.017784664407372475\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 3.6113369464874268 | KNN Loss: 3.6059834957122803 | CLS Loss: 0.005353344138711691\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 3.577955961227417 | KNN Loss: 3.5743916034698486 | CLS Loss: 0.0035642480943351984\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 3.6111841201782227 | KNN Loss: 3.600151538848877 | CLS Loss: 0.011032621376216412\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 3.626006603240967 | KNN Loss: 3.6159467697143555 | CLS Loss: 0.010059913620352745\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 3.609772205352783 | KNN Loss: 3.6055805683135986 | CLS Loss: 0.004191623069345951\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 3.6315724849700928 | KNN Loss: 3.6193952560424805 | CLS Loss: 0.012177346274256706\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 3.6473069190979004 | KNN Loss: 3.6317083835601807 | CLS Loss: 0.015598518773913383\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 3.628190279006958 | KNN Loss: 3.6112453937530518 | CLS Loss: 0.01694490946829319\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 3.646024465560913 | KNN Loss: 3.62034273147583 | CLS Loss: 0.02568178065121174\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 3.602867841720581 | KNN Loss: 3.599210262298584 | CLS Loss: 0.0036575316917151213\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 3.6356892585754395 | KNN Loss: 3.6300559043884277 | CLS Loss: 0.005633421242237091\n",
      "Epoch: 151, Loss: 3.6234, Train: 0.9979, Valid: 0.9868, Best: 0.9876\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 3.6256396770477295 | KNN Loss: 3.6235358715057373 | CLS Loss: 0.002103740582242608\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 3.6167867183685303 | KNN Loss: 3.6062886714935303 | CLS Loss: 0.010498124174773693\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 3.663245439529419 | KNN Loss: 3.6597537994384766 | CLS Loss: 0.0034916591830551624\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 3.575760841369629 | KNN Loss: 3.573960065841675 | CLS Loss: 0.0018007502658292651\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 3.6136269569396973 | KNN Loss: 3.605945587158203 | CLS Loss: 0.007681339047849178\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 3.63067364692688 | KNN Loss: 3.626751661300659 | CLS Loss: 0.003922077361494303\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 3.5725743770599365 | KNN Loss: 3.563507556915283 | CLS Loss: 0.009066922590136528\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 3.6074025630950928 | KNN Loss: 3.5973100662231445 | CLS Loss: 0.010092523880302906\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 3.6121280193328857 | KNN Loss: 3.6048645973205566 | CLS Loss: 0.007263413164764643\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 3.622464179992676 | KNN Loss: 3.6110074520111084 | CLS Loss: 0.011456632055342197\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 3.6647565364837646 | KNN Loss: 3.6489315032958984 | CLS Loss: 0.01582493633031845\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 3.6018483638763428 | KNN Loss: 3.586205005645752 | CLS Loss: 0.015643268823623657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 3.648953676223755 | KNN Loss: 3.6344218254089355 | CLS Loss: 0.014531935565173626\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 3.6194186210632324 | KNN Loss: 3.598566770553589 | CLS Loss: 0.02085183933377266\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 3.588383197784424 | KNN Loss: 3.577138662338257 | CLS Loss: 0.01124450284987688\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 3.650620460510254 | KNN Loss: 3.644127368927002 | CLS Loss: 0.006493148393929005\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 3.6075587272644043 | KNN Loss: 3.5925955772399902 | CLS Loss: 0.014963115565478802\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 3.636598587036133 | KNN Loss: 3.6303563117980957 | CLS Loss: 0.00624237023293972\n",
      "Epoch: 152, Loss: 3.6270, Train: 0.9962, Valid: 0.9873, Best: 0.9876\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 3.6427061557769775 | KNN Loss: 3.6322102546691895 | CLS Loss: 0.010495840571820736\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 3.701875686645508 | KNN Loss: 3.68220853805542 | CLS Loss: 0.019667232409119606\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 3.6305580139160156 | KNN Loss: 3.6232361793518066 | CLS Loss: 0.007321744691580534\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 3.657735824584961 | KNN Loss: 3.6310770511627197 | CLS Loss: 0.026658808812499046\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 3.6442198753356934 | KNN Loss: 3.640030860900879 | CLS Loss: 0.004189006052911282\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 3.587010383605957 | KNN Loss: 3.5796592235565186 | CLS Loss: 0.007351231295615435\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 3.6850366592407227 | KNN Loss: 3.6779778003692627 | CLS Loss: 0.007058972027152777\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 3.5971291065216064 | KNN Loss: 3.5899579524993896 | CLS Loss: 0.007171142380684614\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 3.662146806716919 | KNN Loss: 3.654001474380493 | CLS Loss: 0.008145386353135109\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 3.614952802658081 | KNN Loss: 3.589592933654785 | CLS Loss: 0.025359800085425377\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 3.6291768550872803 | KNN Loss: 3.6112425327301025 | CLS Loss: 0.017934242263436317\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 3.62331223487854 | KNN Loss: 3.593423366546631 | CLS Loss: 0.02988891489803791\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 3.5831820964813232 | KNN Loss: 3.5692923069000244 | CLS Loss: 0.01388981007039547\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 3.6602256298065186 | KNN Loss: 3.613914966583252 | CLS Loss: 0.0463106594979763\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 3.636338710784912 | KNN Loss: 3.61495041847229 | CLS Loss: 0.021388348191976547\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 3.6254167556762695 | KNN Loss: 3.61383056640625 | CLS Loss: 0.011586202308535576\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 3.63899302482605 | KNN Loss: 3.6314361095428467 | CLS Loss: 0.0075569539330899715\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 3.657457113265991 | KNN Loss: 3.6483612060546875 | CLS Loss: 0.009095827117562294\n",
      "Epoch: 153, Loss: 3.6329, Train: 0.9968, Valid: 0.9852, Best: 0.9876\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 3.6270031929016113 | KNN Loss: 3.6255300045013428 | CLS Loss: 0.0014730796683579683\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 3.6361300945281982 | KNN Loss: 3.6275274753570557 | CLS Loss: 0.008602690882980824\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 3.6531150341033936 | KNN Loss: 3.634688377380371 | CLS Loss: 0.01842658407986164\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 3.654794931411743 | KNN Loss: 3.6034560203552246 | CLS Loss: 0.051339004188776016\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 3.6525251865386963 | KNN Loss: 3.6421399116516113 | CLS Loss: 0.010385212488472462\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 3.6050148010253906 | KNN Loss: 3.598151206970215 | CLS Loss: 0.006863617338240147\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 3.649434804916382 | KNN Loss: 3.6233270168304443 | CLS Loss: 0.02610776200890541\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 3.622952461242676 | KNN Loss: 3.5963985919952393 | CLS Loss: 0.026553917676210403\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 3.6212122440338135 | KNN Loss: 3.6090633869171143 | CLS Loss: 0.01214881893247366\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 3.59609055519104 | KNN Loss: 3.5843236446380615 | CLS Loss: 0.011766820214688778\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 3.6100070476531982 | KNN Loss: 3.595339775085449 | CLS Loss: 0.014667201787233353\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 3.6187617778778076 | KNN Loss: 3.608680248260498 | CLS Loss: 0.010081474669277668\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 3.6314516067504883 | KNN Loss: 3.625150442123413 | CLS Loss: 0.006301144603639841\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 3.6244101524353027 | KNN Loss: 3.622100591659546 | CLS Loss: 0.002309526549652219\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 3.6204802989959717 | KNN Loss: 3.6076245307922363 | CLS Loss: 0.012855655513703823\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 3.620619297027588 | KNN Loss: 3.604168176651001 | CLS Loss: 0.0164510365575552\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 3.5984134674072266 | KNN Loss: 3.588179588317871 | CLS Loss: 0.01023397408425808\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 3.65360164642334 | KNN Loss: 3.6401333808898926 | CLS Loss: 0.0134682422503829\n",
      "Epoch: 154, Loss: 3.6312, Train: 0.9977, Valid: 0.9873, Best: 0.9876\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 3.614619016647339 | KNN Loss: 3.607787609100342 | CLS Loss: 0.006831304170191288\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 3.6241559982299805 | KNN Loss: 3.6140918731689453 | CLS Loss: 0.01006415393203497\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 3.6482622623443604 | KNN Loss: 3.640300989151001 | CLS Loss: 0.007961169816553593\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 3.6342058181762695 | KNN Loss: 3.6184120178222656 | CLS Loss: 0.015793778002262115\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 3.612506866455078 | KNN Loss: 3.6004836559295654 | CLS Loss: 0.012023228220641613\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 3.6146504878997803 | KNN Loss: 3.602412462234497 | CLS Loss: 0.012237964197993279\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 3.5960710048675537 | KNN Loss: 3.5919833183288574 | CLS Loss: 0.0040876478888094425\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 3.6876349449157715 | KNN Loss: 3.6732168197631836 | CLS Loss: 0.01441818568855524\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 3.639739990234375 | KNN Loss: 3.6345152854919434 | CLS Loss: 0.0052248090505599976\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 3.636138677597046 | KNN Loss: 3.610290765762329 | CLS Loss: 0.025847874581813812\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 3.6259870529174805 | KNN Loss: 3.618441104888916 | CLS Loss: 0.0075459349900484085\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 3.621483564376831 | KNN Loss: 3.6120831966400146 | CLS Loss: 0.00940045528113842\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 3.6647403240203857 | KNN Loss: 3.6631276607513428 | CLS Loss: 0.001612665830180049\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 3.6602847576141357 | KNN Loss: 3.640310525894165 | CLS Loss: 0.019974235445261\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 3.63067364692688 | KNN Loss: 3.6170308589935303 | CLS Loss: 0.013642681762576103\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 3.6051125526428223 | KNN Loss: 3.600198268890381 | CLS Loss: 0.004914368037134409\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 3.5963785648345947 | KNN Loss: 3.5739998817443848 | CLS Loss: 0.02237863279879093\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 3.6375882625579834 | KNN Loss: 3.6163980960845947 | CLS Loss: 0.02119010128080845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155, Loss: 3.6246, Train: 0.9973, Valid: 0.9871, Best: 0.9876\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 3.58880352973938 | KNN Loss: 3.5806405544281006 | CLS Loss: 0.00816306658089161\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 3.617133855819702 | KNN Loss: 3.6070237159729004 | CLS Loss: 0.010110078379511833\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 3.6441988945007324 | KNN Loss: 3.634873867034912 | CLS Loss: 0.009325118735432625\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 3.6147701740264893 | KNN Loss: 3.612868547439575 | CLS Loss: 0.0019017342710867524\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 3.5938832759857178 | KNN Loss: 3.590275526046753 | CLS Loss: 0.003607644699513912\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 3.5858376026153564 | KNN Loss: 3.579669713973999 | CLS Loss: 0.0061679743230342865\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 3.6042098999023438 | KNN Loss: 3.5838799476623535 | CLS Loss: 0.020329907536506653\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 3.611398458480835 | KNN Loss: 3.6011598110198975 | CLS Loss: 0.01023863349109888\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 3.6774425506591797 | KNN Loss: 3.652273416519165 | CLS Loss: 0.02516905404627323\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 3.611034631729126 | KNN Loss: 3.604436159133911 | CLS Loss: 0.006598585285246372\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 3.64241886138916 | KNN Loss: 3.6377902030944824 | CLS Loss: 0.00462874723598361\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 3.598198175430298 | KNN Loss: 3.5943663120269775 | CLS Loss: 0.003831911599263549\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 3.614948034286499 | KNN Loss: 3.6000263690948486 | CLS Loss: 0.01492168940603733\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 3.648405075073242 | KNN Loss: 3.617826461791992 | CLS Loss: 0.03057849407196045\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 3.593998670578003 | KNN Loss: 3.586500406265259 | CLS Loss: 0.007498339284211397\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 3.6422841548919678 | KNN Loss: 3.633650541305542 | CLS Loss: 0.008633555844426155\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 3.6414546966552734 | KNN Loss: 3.630357503890991 | CLS Loss: 0.011097298003733158\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 3.600419521331787 | KNN Loss: 3.586451530456543 | CLS Loss: 0.013968066312372684\n",
      "Epoch: 156, Loss: 3.6229, Train: 0.9963, Valid: 0.9860, Best: 0.9876\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 3.6333699226379395 | KNN Loss: 3.6223318576812744 | CLS Loss: 0.011038015596568584\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 3.6165895462036133 | KNN Loss: 3.606032371520996 | CLS Loss: 0.010557104833424091\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 3.7234890460968018 | KNN Loss: 3.69254994392395 | CLS Loss: 0.030939150601625443\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 3.637068510055542 | KNN Loss: 3.618190050125122 | CLS Loss: 0.0188783910125494\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 3.639082431793213 | KNN Loss: 3.62481951713562 | CLS Loss: 0.014262967742979527\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 3.60323429107666 | KNN Loss: 3.5876452922821045 | CLS Loss: 0.015589047223329544\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 3.6883585453033447 | KNN Loss: 3.6844289302825928 | CLS Loss: 0.00392970209941268\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 3.614992141723633 | KNN Loss: 3.6082253456115723 | CLS Loss: 0.0067668575793504715\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 3.628328323364258 | KNN Loss: 3.605008363723755 | CLS Loss: 0.023319991305470467\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 3.5662386417388916 | KNN Loss: 3.5643599033355713 | CLS Loss: 0.0018786832224577665\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 3.6653294563293457 | KNN Loss: 3.6398086547851562 | CLS Loss: 0.025520727038383484\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 3.65392804145813 | KNN Loss: 3.6323444843292236 | CLS Loss: 0.021583478897809982\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 3.6383020877838135 | KNN Loss: 3.6333930492401123 | CLS Loss: 0.0049091484397649765\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 3.6605896949768066 | KNN Loss: 3.6429944038391113 | CLS Loss: 0.017595326527953148\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 3.626603603363037 | KNN Loss: 3.6146674156188965 | CLS Loss: 0.011936244554817677\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 3.6497414112091064 | KNN Loss: 3.6356148719787598 | CLS Loss: 0.014126649126410484\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 3.5976154804229736 | KNN Loss: 3.5953195095062256 | CLS Loss: 0.0022960312198847532\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 3.630613088607788 | KNN Loss: 3.6199138164520264 | CLS Loss: 0.010699312202632427\n",
      "Epoch: 157, Loss: 3.6278, Train: 0.9968, Valid: 0.9860, Best: 0.9876\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 3.6136088371276855 | KNN Loss: 3.598534107208252 | CLS Loss: 0.015074808150529861\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 3.5799872875213623 | KNN Loss: 3.57121205329895 | CLS Loss: 0.008775350637733936\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 3.62872576713562 | KNN Loss: 3.61025071144104 | CLS Loss: 0.018475009128451347\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 3.594841957092285 | KNN Loss: 3.5859296321868896 | CLS Loss: 0.008912438526749611\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 3.598773956298828 | KNN Loss: 3.5878758430480957 | CLS Loss: 0.010898120701313019\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 3.6312501430511475 | KNN Loss: 3.6218302249908447 | CLS Loss: 0.009419848211109638\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 3.640029191970825 | KNN Loss: 3.62776517868042 | CLS Loss: 0.012264080345630646\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 3.64540433883667 | KNN Loss: 3.6347415447235107 | CLS Loss: 0.010662856511771679\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 3.634181022644043 | KNN Loss: 3.6290597915649414 | CLS Loss: 0.005121245514601469\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 3.597332715988159 | KNN Loss: 3.5931529998779297 | CLS Loss: 0.004179667681455612\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 3.6202070713043213 | KNN Loss: 3.614750623703003 | CLS Loss: 0.005456395912915468\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 3.622917890548706 | KNN Loss: 3.6112639904022217 | CLS Loss: 0.011653808876872063\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 3.633366584777832 | KNN Loss: 3.6291511058807373 | CLS Loss: 0.004215559922158718\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 3.5924904346466064 | KNN Loss: 3.5766100883483887 | CLS Loss: 0.015880310907959938\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 3.6100504398345947 | KNN Loss: 3.5982697010040283 | CLS Loss: 0.011780704371631145\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 3.5919768810272217 | KNN Loss: 3.5880281925201416 | CLS Loss: 0.00394876254722476\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 3.6088054180145264 | KNN Loss: 3.592911720275879 | CLS Loss: 0.01589363068342209\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 3.6244640350341797 | KNN Loss: 3.619621992111206 | CLS Loss: 0.004841930232942104\n",
      "Epoch: 158, Loss: 3.6254, Train: 0.9971, Valid: 0.9857, Best: 0.9876\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 3.6437158584594727 | KNN Loss: 3.6382405757904053 | CLS Loss: 0.005475387908518314\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 3.616459369659424 | KNN Loss: 3.6067943572998047 | CLS Loss: 0.009665067307651043\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 3.6139121055603027 | KNN Loss: 3.6052985191345215 | CLS Loss: 0.008613673970103264\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 3.608638286590576 | KNN Loss: 3.6024036407470703 | CLS Loss: 0.006234591826796532\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 3.627270221710205 | KNN Loss: 3.6134121417999268 | CLS Loss: 0.013858099468052387\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 3.6405510902404785 | KNN Loss: 3.6179287433624268 | CLS Loss: 0.02262239158153534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 3.646608829498291 | KNN Loss: 3.640458106994629 | CLS Loss: 0.006150651257485151\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 3.6408417224884033 | KNN Loss: 3.6133334636688232 | CLS Loss: 0.027508312836289406\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 3.6237363815307617 | KNN Loss: 3.5896825790405273 | CLS Loss: 0.034053727984428406\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 3.622403144836426 | KNN Loss: 3.6150670051574707 | CLS Loss: 0.007336210925132036\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 3.598031997680664 | KNN Loss: 3.5888750553131104 | CLS Loss: 0.00915694609284401\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 3.6189346313476562 | KNN Loss: 3.6119136810302734 | CLS Loss: 0.007020971737802029\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 3.583162546157837 | KNN Loss: 3.576295852661133 | CLS Loss: 0.006866663694381714\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 3.6065237522125244 | KNN Loss: 3.5920636653900146 | CLS Loss: 0.01446019858121872\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 3.6153366565704346 | KNN Loss: 3.6125056743621826 | CLS Loss: 0.0028309603221714497\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 3.6381142139434814 | KNN Loss: 3.5988376140594482 | CLS Loss: 0.03927669674158096\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 3.578594446182251 | KNN Loss: 3.572335958480835 | CLS Loss: 0.006258431356400251\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 3.634789228439331 | KNN Loss: 3.628255844116211 | CLS Loss: 0.006533341947942972\n",
      "Epoch: 159, Loss: 3.6247, Train: 0.9971, Valid: 0.9864, Best: 0.9876\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 3.602431058883667 | KNN Loss: 3.5992445945739746 | CLS Loss: 0.0031864598859101534\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 3.617722988128662 | KNN Loss: 3.6110305786132812 | CLS Loss: 0.006692299619317055\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 3.6453752517700195 | KNN Loss: 3.6307430267333984 | CLS Loss: 0.014632176607847214\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 3.588941812515259 | KNN Loss: 3.587406873703003 | CLS Loss: 0.001534820068627596\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 3.606334924697876 | KNN Loss: 3.601557731628418 | CLS Loss: 0.004777137190103531\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 3.6408796310424805 | KNN Loss: 3.635430335998535 | CLS Loss: 0.005449309013783932\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 3.6696109771728516 | KNN Loss: 3.6363790035247803 | CLS Loss: 0.03323208913207054\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 3.6348376274108887 | KNN Loss: 3.6242618560791016 | CLS Loss: 0.010575694963335991\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 3.6340224742889404 | KNN Loss: 3.6181135177612305 | CLS Loss: 0.0159088596701622\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 3.604591131210327 | KNN Loss: 3.5928094387054443 | CLS Loss: 0.011781701818108559\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 3.6805732250213623 | KNN Loss: 3.6374778747558594 | CLS Loss: 0.043095413595438004\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 3.6593990325927734 | KNN Loss: 3.6419906616210938 | CLS Loss: 0.017408372834324837\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 3.632848024368286 | KNN Loss: 3.6249985694885254 | CLS Loss: 0.007849354296922684\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 3.622584581375122 | KNN Loss: 3.6140410900115967 | CLS Loss: 0.008543410338461399\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 3.608302593231201 | KNN Loss: 3.6058757305145264 | CLS Loss: 0.0024269819259643555\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 3.618154764175415 | KNN Loss: 3.6158339977264404 | CLS Loss: 0.0023207722697407007\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 3.6167352199554443 | KNN Loss: 3.6084060668945312 | CLS Loss: 0.008329213596880436\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 3.6092300415039062 | KNN Loss: 3.5889158248901367 | CLS Loss: 0.020314300432801247\n",
      "Epoch: 160, Loss: 3.6277, Train: 0.9972, Valid: 0.9863, Best: 0.9876\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 3.609710454940796 | KNN Loss: 3.5876893997192383 | CLS Loss: 0.02202107571065426\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 3.63224196434021 | KNN Loss: 3.6142642498016357 | CLS Loss: 0.01797780953347683\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 3.636575937271118 | KNN Loss: 3.6326072216033936 | CLS Loss: 0.003968601115047932\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 3.6035709381103516 | KNN Loss: 3.598492383956909 | CLS Loss: 0.005078558810055256\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 3.6035983562469482 | KNN Loss: 3.5984959602355957 | CLS Loss: 0.0051024481654167175\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 3.633819103240967 | KNN Loss: 3.6129109859466553 | CLS Loss: 0.020907998085021973\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 3.6454362869262695 | KNN Loss: 3.625589609146118 | CLS Loss: 0.01984657160937786\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 3.6380832195281982 | KNN Loss: 3.6217734813690186 | CLS Loss: 0.016309767961502075\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 3.6005353927612305 | KNN Loss: 3.5941619873046875 | CLS Loss: 0.0063734157010912895\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 3.6060078144073486 | KNN Loss: 3.5817437171936035 | CLS Loss: 0.024264197796583176\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 3.6708335876464844 | KNN Loss: 3.636807441711426 | CLS Loss: 0.03402615711092949\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 3.64711856842041 | KNN Loss: 3.6373801231384277 | CLS Loss: 0.00973852351307869\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 3.6099202632904053 | KNN Loss: 3.6025230884552 | CLS Loss: 0.0073971496894955635\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 3.6122822761535645 | KNN Loss: 3.608790874481201 | CLS Loss: 0.003491299459710717\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 3.6286606788635254 | KNN Loss: 3.6016414165496826 | CLS Loss: 0.027019331231713295\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 3.627127170562744 | KNN Loss: 3.6052935123443604 | CLS Loss: 0.021833710372447968\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 3.635044574737549 | KNN Loss: 3.627030611038208 | CLS Loss: 0.00801405031234026\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 3.657583236694336 | KNN Loss: 3.6516101360321045 | CLS Loss: 0.005973002407699823\n",
      "Epoch: 161, Loss: 3.6266, Train: 0.9965, Valid: 0.9857, Best: 0.9876\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 3.6128337383270264 | KNN Loss: 3.5963022708892822 | CLS Loss: 0.01653142087161541\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 3.606947183609009 | KNN Loss: 3.5984818935394287 | CLS Loss: 0.008465368300676346\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 3.59395432472229 | KNN Loss: 3.5842275619506836 | CLS Loss: 0.009726811200380325\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 3.6493093967437744 | KNN Loss: 3.6366143226623535 | CLS Loss: 0.01269500982016325\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 3.608847141265869 | KNN Loss: 3.602332353591919 | CLS Loss: 0.006514774169772863\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 3.630746603012085 | KNN Loss: 3.6252496242523193 | CLS Loss: 0.005497009493410587\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 3.6234614849090576 | KNN Loss: 3.6060802936553955 | CLS Loss: 0.017381196841597557\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 3.6354870796203613 | KNN Loss: 3.632608413696289 | CLS Loss: 0.0028786060865968466\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 3.590869188308716 | KNN Loss: 3.581390380859375 | CLS Loss: 0.009478885680437088\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 3.617177724838257 | KNN Loss: 3.612039089202881 | CLS Loss: 0.0051386249251663685\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 3.6549859046936035 | KNN Loss: 3.625985860824585 | CLS Loss: 0.029000042006373405\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 3.644310474395752 | KNN Loss: 3.619926691055298 | CLS Loss: 0.02438371814787388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 3.654322385787964 | KNN Loss: 3.631718158721924 | CLS Loss: 0.02260415069758892\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 3.6650290489196777 | KNN Loss: 3.651296615600586 | CLS Loss: 0.013732338324189186\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 3.612222671508789 | KNN Loss: 3.600280284881592 | CLS Loss: 0.011942435055971146\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 3.6138627529144287 | KNN Loss: 3.6079585552215576 | CLS Loss: 0.005904106423258781\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 3.6468663215637207 | KNN Loss: 3.644155263900757 | CLS Loss: 0.002710946137085557\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 3.7044856548309326 | KNN Loss: 3.6938228607177734 | CLS Loss: 0.010662887245416641\n",
      "Epoch: 162, Loss: 3.6274, Train: 0.9971, Valid: 0.9871, Best: 0.9876\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 3.582772731781006 | KNN Loss: 3.575026750564575 | CLS Loss: 0.007746066898107529\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 3.663067579269409 | KNN Loss: 3.6464591026306152 | CLS Loss: 0.016608459874987602\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 3.6216742992401123 | KNN Loss: 3.610462188720703 | CLS Loss: 0.011212105862796307\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 3.6061062812805176 | KNN Loss: 3.602344274520874 | CLS Loss: 0.003762032138183713\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 3.6755707263946533 | KNN Loss: 3.663565158843994 | CLS Loss: 0.012005532160401344\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 3.6083905696868896 | KNN Loss: 3.6039750576019287 | CLS Loss: 0.004415431525558233\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 3.6489033699035645 | KNN Loss: 3.630329132080078 | CLS Loss: 0.018574263900518417\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 3.653724431991577 | KNN Loss: 3.6413166522979736 | CLS Loss: 0.012407801114022732\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 3.613903045654297 | KNN Loss: 3.6132121086120605 | CLS Loss: 0.0006908702780492604\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 3.656393051147461 | KNN Loss: 3.644662857055664 | CLS Loss: 0.011730172671377659\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 3.6452155113220215 | KNN Loss: 3.6180214881896973 | CLS Loss: 0.027194000780582428\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 3.66288685798645 | KNN Loss: 3.6303720474243164 | CLS Loss: 0.03251470997929573\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 3.6489861011505127 | KNN Loss: 3.6241259574890137 | CLS Loss: 0.02486017718911171\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 3.6300108432769775 | KNN Loss: 3.6261379718780518 | CLS Loss: 0.0038729081861674786\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 3.6559321880340576 | KNN Loss: 3.616337776184082 | CLS Loss: 0.039594441652297974\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 3.638545513153076 | KNN Loss: 3.624025344848633 | CLS Loss: 0.014520146884024143\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 3.6732234954833984 | KNN Loss: 3.6501197814941406 | CLS Loss: 0.023103762418031693\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 3.6385140419006348 | KNN Loss: 3.627744436264038 | CLS Loss: 0.010769600979983807\n",
      "Epoch: 163, Loss: 3.6278, Train: 0.9966, Valid: 0.9859, Best: 0.9876\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 3.6585464477539062 | KNN Loss: 3.6476218700408936 | CLS Loss: 0.01092445943504572\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 3.6209187507629395 | KNN Loss: 3.604245662689209 | CLS Loss: 0.016672972589731216\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 3.6267049312591553 | KNN Loss: 3.614384412765503 | CLS Loss: 0.012320403009653091\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 3.6087069511413574 | KNN Loss: 3.584359645843506 | CLS Loss: 0.024347200989723206\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 3.6217949390411377 | KNN Loss: 3.6133103370666504 | CLS Loss: 0.00848468393087387\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 3.6113483905792236 | KNN Loss: 3.603581666946411 | CLS Loss: 0.00776668218895793\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 3.6004300117492676 | KNN Loss: 3.590679883956909 | CLS Loss: 0.009750132448971272\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 3.5816235542297363 | KNN Loss: 3.575789213180542 | CLS Loss: 0.005834398325532675\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 3.6223397254943848 | KNN Loss: 3.6182727813720703 | CLS Loss: 0.004067025613039732\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 3.6225128173828125 | KNN Loss: 3.613847255706787 | CLS Loss: 0.008665652945637703\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 3.611443281173706 | KNN Loss: 3.6038882732391357 | CLS Loss: 0.007554927840828896\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 3.6041295528411865 | KNN Loss: 3.594548463821411 | CLS Loss: 0.009581184014678001\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 3.626157522201538 | KNN Loss: 3.6192142963409424 | CLS Loss: 0.006943292450159788\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 3.6266446113586426 | KNN Loss: 3.616508722305298 | CLS Loss: 0.01013597846031189\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 3.643988609313965 | KNN Loss: 3.611865282058716 | CLS Loss: 0.03212333843111992\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 3.624208927154541 | KNN Loss: 3.622497797012329 | CLS Loss: 0.0017111797351390123\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 3.5974621772766113 | KNN Loss: 3.5947072505950928 | CLS Loss: 0.002754896180704236\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 3.6191635131835938 | KNN Loss: 3.610915422439575 | CLS Loss: 0.00824806746095419\n",
      "Epoch: 164, Loss: 3.6270, Train: 0.9965, Valid: 0.9862, Best: 0.9876\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 3.6295342445373535 | KNN Loss: 3.616273880004883 | CLS Loss: 0.013260403648018837\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 3.6008949279785156 | KNN Loss: 3.5943026542663574 | CLS Loss: 0.006592193152755499\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 3.629272222518921 | KNN Loss: 3.60797381401062 | CLS Loss: 0.02129836566746235\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 3.6145846843719482 | KNN Loss: 3.59940767288208 | CLS Loss: 0.015177123248577118\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 3.6103594303131104 | KNN Loss: 3.6076018810272217 | CLS Loss: 0.0027574829291552305\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 3.6424107551574707 | KNN Loss: 3.63891863822937 | CLS Loss: 0.0034920289181172848\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 3.596439838409424 | KNN Loss: 3.590691566467285 | CLS Loss: 0.0057483091950416565\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 3.609612464904785 | KNN Loss: 3.6054866313934326 | CLS Loss: 0.004125870298594236\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 3.604508876800537 | KNN Loss: 3.5969862937927246 | CLS Loss: 0.007522528991103172\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 3.6204144954681396 | KNN Loss: 3.612531900405884 | CLS Loss: 0.007882582023739815\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 3.6182777881622314 | KNN Loss: 3.5938172340393066 | CLS Loss: 0.02446056716144085\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 3.5763721466064453 | KNN Loss: 3.5695409774780273 | CLS Loss: 0.006831164006143808\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 3.679494619369507 | KNN Loss: 3.6553239822387695 | CLS Loss: 0.024170607328414917\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 3.609276294708252 | KNN Loss: 3.6059346199035645 | CLS Loss: 0.0033416503574699163\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 3.636579751968384 | KNN Loss: 3.629185199737549 | CLS Loss: 0.007394473534077406\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 3.6380157470703125 | KNN Loss: 3.6154282093048096 | CLS Loss: 0.0225876085460186\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 3.590052843093872 | KNN Loss: 3.5850541591644287 | CLS Loss: 0.0049987370148301125\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 3.61161470413208 | KNN Loss: 3.6069817543029785 | CLS Loss: 0.004633049480617046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165, Loss: 3.6256, Train: 0.9963, Valid: 0.9856, Best: 0.9876\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 3.64422607421875 | KNN Loss: 3.634563684463501 | CLS Loss: 0.009662310592830181\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 3.6277756690979004 | KNN Loss: 3.624656915664673 | CLS Loss: 0.003118707099929452\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 3.5975778102874756 | KNN Loss: 3.5925686359405518 | CLS Loss: 0.0050091990269720554\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 3.624056816101074 | KNN Loss: 3.6207542419433594 | CLS Loss: 0.0033026766031980515\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 3.600933074951172 | KNN Loss: 3.5862720012664795 | CLS Loss: 0.014661001041531563\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 3.6075472831726074 | KNN Loss: 3.604901075363159 | CLS Loss: 0.0026461449451744556\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 3.6233067512512207 | KNN Loss: 3.619687795639038 | CLS Loss: 0.0036189446691423655\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 3.619056224822998 | KNN Loss: 3.6104750633239746 | CLS Loss: 0.008581249043345451\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 3.5907084941864014 | KNN Loss: 3.5825135707855225 | CLS Loss: 0.008194941096007824\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 3.658207654953003 | KNN Loss: 3.6424200534820557 | CLS Loss: 0.01578771322965622\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 3.6651880741119385 | KNN Loss: 3.6496500968933105 | CLS Loss: 0.015538071282207966\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 3.653653860092163 | KNN Loss: 3.644440174102783 | CLS Loss: 0.00921377819031477\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 3.6914353370666504 | KNN Loss: 3.6624128818511963 | CLS Loss: 0.02902238629758358\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 3.595425844192505 | KNN Loss: 3.587547540664673 | CLS Loss: 0.00787834171205759\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 3.6274280548095703 | KNN Loss: 3.6188840866088867 | CLS Loss: 0.008544031530618668\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 3.6037111282348633 | KNN Loss: 3.5903477668762207 | CLS Loss: 0.013363420031964779\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 3.6095645427703857 | KNN Loss: 3.602886915206909 | CLS Loss: 0.00667769368737936\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 3.6517279148101807 | KNN Loss: 3.6294758319854736 | CLS Loss: 0.022251995280385017\n",
      "Epoch: 166, Loss: 3.6248, Train: 0.9966, Valid: 0.9869, Best: 0.9876\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 3.596034049987793 | KNN Loss: 3.582908868789673 | CLS Loss: 0.013125263154506683\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 3.596139430999756 | KNN Loss: 3.592104434967041 | CLS Loss: 0.004034917801618576\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 3.5940096378326416 | KNN Loss: 3.575251817703247 | CLS Loss: 0.018757831305265427\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 3.6230733394622803 | KNN Loss: 3.61619234085083 | CLS Loss: 0.006880989298224449\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 3.619185447692871 | KNN Loss: 3.6126434803009033 | CLS Loss: 0.0065419431775808334\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 3.599836826324463 | KNN Loss: 3.577806234359741 | CLS Loss: 0.022030651569366455\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 3.6210358142852783 | KNN Loss: 3.6000397205352783 | CLS Loss: 0.020996034145355225\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 3.617443561553955 | KNN Loss: 3.604640245437622 | CLS Loss: 0.012803367339074612\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 3.600802183151245 | KNN Loss: 3.596822500228882 | CLS Loss: 0.003979680594056845\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 3.5823814868927 | KNN Loss: 3.5764238834381104 | CLS Loss: 0.005957703571766615\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 3.6044445037841797 | KNN Loss: 3.5990123748779297 | CLS Loss: 0.005432118196040392\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 3.657989263534546 | KNN Loss: 3.6499364376068115 | CLS Loss: 0.008052762597799301\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 3.603485107421875 | KNN Loss: 3.6021904945373535 | CLS Loss: 0.0012945443158969283\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 3.5921270847320557 | KNN Loss: 3.5886316299438477 | CLS Loss: 0.003495503216981888\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 3.6435985565185547 | KNN Loss: 3.6282758712768555 | CLS Loss: 0.01532264705747366\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 3.662580728530884 | KNN Loss: 3.6556265354156494 | CLS Loss: 0.006954239681363106\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 3.595323085784912 | KNN Loss: 3.5889856815338135 | CLS Loss: 0.006337387952953577\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 3.5874791145324707 | KNN Loss: 3.5793325901031494 | CLS Loss: 0.00814643781632185\n",
      "Epoch: 167, Loss: 3.6190, Train: 0.9967, Valid: 0.9851, Best: 0.9876\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 3.6409449577331543 | KNN Loss: 3.6309945583343506 | CLS Loss: 0.009950331412255764\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 3.6684515476226807 | KNN Loss: 3.6471641063690186 | CLS Loss: 0.021287336945533752\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 3.5858309268951416 | KNN Loss: 3.5827853679656982 | CLS Loss: 0.0030455347150564194\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 3.6459131240844727 | KNN Loss: 3.6440954208374023 | CLS Loss: 0.00181770755443722\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 3.608729124069214 | KNN Loss: 3.6057047843933105 | CLS Loss: 0.0030244130175560713\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 3.6280875205993652 | KNN Loss: 3.6127395629882812 | CLS Loss: 0.015347976237535477\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 3.6504180431365967 | KNN Loss: 3.6457583904266357 | CLS Loss: 0.004659621976315975\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 3.6415162086486816 | KNN Loss: 3.6224801540374756 | CLS Loss: 0.019036030396819115\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 3.622720241546631 | KNN Loss: 3.6058764457702637 | CLS Loss: 0.016843749210238457\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 3.5846805572509766 | KNN Loss: 3.581589937210083 | CLS Loss: 0.0030906405299901962\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 3.618760824203491 | KNN Loss: 3.6045541763305664 | CLS Loss: 0.014206753112375736\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 3.6157283782958984 | KNN Loss: 3.6148109436035156 | CLS Loss: 0.0009175032027997077\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 3.595082998275757 | KNN Loss: 3.5685291290283203 | CLS Loss: 0.026553863659501076\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 3.6087117195129395 | KNN Loss: 3.5936119556427 | CLS Loss: 0.015099695883691311\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 3.604875326156616 | KNN Loss: 3.6041953563690186 | CLS Loss: 0.0006799045950174332\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 3.587824583053589 | KNN Loss: 3.585764169692993 | CLS Loss: 0.0020603269804269075\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 3.6066830158233643 | KNN Loss: 3.589604139328003 | CLS Loss: 0.017078889533877373\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 3.689284324645996 | KNN Loss: 3.6880946159362793 | CLS Loss: 0.0011897010263055563\n",
      "Epoch: 168, Loss: 3.6240, Train: 0.9967, Valid: 0.9850, Best: 0.9876\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 3.6136069297790527 | KNN Loss: 3.611551284790039 | CLS Loss: 0.0020555821247398853\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 3.585264205932617 | KNN Loss: 3.580496072769165 | CLS Loss: 0.0047681634314358234\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 3.603835105895996 | KNN Loss: 3.5906548500061035 | CLS Loss: 0.013180212117731571\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 3.589599847793579 | KNN Loss: 3.5869553089141846 | CLS Loss: 0.0026444862596690655\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 3.63570237159729 | KNN Loss: 3.615572690963745 | CLS Loss: 0.020129630342125893\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 3.639631986618042 | KNN Loss: 3.62045955657959 | CLS Loss: 0.01917240396142006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 3.59635591506958 | KNN Loss: 3.58709979057312 | CLS Loss: 0.009256059303879738\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 3.6413075923919678 | KNN Loss: 3.630943775177002 | CLS Loss: 0.010363870300352573\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 3.664003849029541 | KNN Loss: 3.6574158668518066 | CLS Loss: 0.006588030606508255\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 3.619335651397705 | KNN Loss: 3.6113383769989014 | CLS Loss: 0.007997189648449421\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 3.6831157207489014 | KNN Loss: 3.6601810455322266 | CLS Loss: 0.02293458580970764\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 3.6903533935546875 | KNN Loss: 3.6694326400756836 | CLS Loss: 0.020920682698488235\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 3.6932919025421143 | KNN Loss: 3.687347173690796 | CLS Loss: 0.005944840610027313\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 3.617133378982544 | KNN Loss: 3.5861263275146484 | CLS Loss: 0.031006937846541405\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 3.5911827087402344 | KNN Loss: 3.584794044494629 | CLS Loss: 0.006388613488525152\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 3.639478921890259 | KNN Loss: 3.632899761199951 | CLS Loss: 0.006579176057130098\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 3.652103900909424 | KNN Loss: 3.6439707279205322 | CLS Loss: 0.008133110590279102\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 3.6638612747192383 | KNN Loss: 3.651343584060669 | CLS Loss: 0.012517809867858887\n",
      "Epoch: 169, Loss: 3.6367, Train: 0.9956, Valid: 0.9850, Best: 0.9876\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 3.5968775749206543 | KNN Loss: 3.594632148742676 | CLS Loss: 0.0022454489953815937\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 3.6086084842681885 | KNN Loss: 3.579179525375366 | CLS Loss: 0.029428869485855103\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 3.614661455154419 | KNN Loss: 3.604051113128662 | CLS Loss: 0.01061027217656374\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 3.6228229999542236 | KNN Loss: 3.618997812271118 | CLS Loss: 0.0038252624217420816\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 3.6089959144592285 | KNN Loss: 3.601180076599121 | CLS Loss: 0.007815774530172348\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 3.6506295204162598 | KNN Loss: 3.6394243240356445 | CLS Loss: 0.01120522990822792\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 3.620643377304077 | KNN Loss: 3.608973264694214 | CLS Loss: 0.011670174077153206\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 3.6284048557281494 | KNN Loss: 3.6214749813079834 | CLS Loss: 0.0069299438036978245\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 3.627197265625 | KNN Loss: 3.6195216178894043 | CLS Loss: 0.007675673812627792\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 3.6308071613311768 | KNN Loss: 3.6277527809143066 | CLS Loss: 0.0030544844921678305\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 3.604971408843994 | KNN Loss: 3.5936810970306396 | CLS Loss: 0.011290338821709156\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 3.6438205242156982 | KNN Loss: 3.625528335571289 | CLS Loss: 0.018292110413312912\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 3.6473000049591064 | KNN Loss: 3.631359815597534 | CLS Loss: 0.01594029739499092\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 3.6310296058654785 | KNN Loss: 3.6128060817718506 | CLS Loss: 0.018223479390144348\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 3.6116886138916016 | KNN Loss: 3.599597930908203 | CLS Loss: 0.012090685777366161\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 3.6592185497283936 | KNN Loss: 3.653021812438965 | CLS Loss: 0.006196803413331509\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 3.650251626968384 | KNN Loss: 3.6309256553649902 | CLS Loss: 0.01932608149945736\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 3.620748281478882 | KNN Loss: 3.594393491744995 | CLS Loss: 0.026354873552918434\n",
      "Epoch: 170, Loss: 3.6313, Train: 0.9973, Valid: 0.9868, Best: 0.9876\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 3.619466543197632 | KNN Loss: 3.613893508911133 | CLS Loss: 0.0055729690939188\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 3.626300811767578 | KNN Loss: 3.62257981300354 | CLS Loss: 0.003721027635037899\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 3.63653826713562 | KNN Loss: 3.6181094646453857 | CLS Loss: 0.018428843468427658\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 3.6116645336151123 | KNN Loss: 3.606663703918457 | CLS Loss: 0.005000722128897905\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 3.625863790512085 | KNN Loss: 3.6218221187591553 | CLS Loss: 0.004041722975671291\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 3.6682066917419434 | KNN Loss: 3.652790069580078 | CLS Loss: 0.015416628681123257\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 3.630781412124634 | KNN Loss: 3.6216070652008057 | CLS Loss: 0.009174416773021221\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 3.5965442657470703 | KNN Loss: 3.5926733016967773 | CLS Loss: 0.0038710799999535084\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 3.594400405883789 | KNN Loss: 3.592043161392212 | CLS Loss: 0.0023573366925120354\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 3.684499740600586 | KNN Loss: 3.666642904281616 | CLS Loss: 0.01785690151154995\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 3.685814619064331 | KNN Loss: 3.6758835315704346 | CLS Loss: 0.009931010194122791\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 3.596156358718872 | KNN Loss: 3.5881755352020264 | CLS Loss: 0.00798086728900671\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 3.6117262840270996 | KNN Loss: 3.607792377471924 | CLS Loss: 0.003933831118047237\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 3.5899038314819336 | KNN Loss: 3.5860981941223145 | CLS Loss: 0.0038057053461670876\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 3.6180942058563232 | KNN Loss: 3.6016106605529785 | CLS Loss: 0.016483541578054428\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 3.651733636856079 | KNN Loss: 3.643246650695801 | CLS Loss: 0.00848697591573\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 3.6375386714935303 | KNN Loss: 3.6183018684387207 | CLS Loss: 0.019236810505390167\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 3.655560255050659 | KNN Loss: 3.62919282913208 | CLS Loss: 0.026367316022515297\n",
      "Epoch: 171, Loss: 3.6288, Train: 0.9961, Valid: 0.9852, Best: 0.9876\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 3.6093435287475586 | KNN Loss: 3.6008849143981934 | CLS Loss: 0.008458548225462437\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 3.6242737770080566 | KNN Loss: 3.6193156242370605 | CLS Loss: 0.004958231933414936\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 3.652336359024048 | KNN Loss: 3.6431543827056885 | CLS Loss: 0.00918208435177803\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 3.637063503265381 | KNN Loss: 3.6270928382873535 | CLS Loss: 0.009970764629542828\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 3.5956053733825684 | KNN Loss: 3.588592290878296 | CLS Loss: 0.0070131681859493256\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 3.6507680416107178 | KNN Loss: 3.6328251361846924 | CLS Loss: 0.01794286258518696\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 3.620150089263916 | KNN Loss: 3.616478204727173 | CLS Loss: 0.0036718377377837896\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 3.6690666675567627 | KNN Loss: 3.6597750186920166 | CLS Loss: 0.009291764348745346\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 3.625312566757202 | KNN Loss: 3.6088576316833496 | CLS Loss: 0.01645498350262642\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 3.6051557064056396 | KNN Loss: 3.603943109512329 | CLS Loss: 0.0012126554502174258\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 3.586859703063965 | KNN Loss: 3.5833017826080322 | CLS Loss: 0.0035578650422394276\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 3.64192271232605 | KNN Loss: 3.6054859161376953 | CLS Loss: 0.036436714231967926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 3.580548048019409 | KNN Loss: 3.57124662399292 | CLS Loss: 0.009301463142037392\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 3.6521294116973877 | KNN Loss: 3.649071455001831 | CLS Loss: 0.0030578547157347202\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 3.655874252319336 | KNN Loss: 3.645141363143921 | CLS Loss: 0.010732807219028473\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 3.622750997543335 | KNN Loss: 3.597238540649414 | CLS Loss: 0.025512436404824257\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 3.5924313068389893 | KNN Loss: 3.5897388458251953 | CLS Loss: 0.0026924856938421726\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 3.5869181156158447 | KNN Loss: 3.577371597290039 | CLS Loss: 0.009546566754579544\n",
      "Epoch: 172, Loss: 3.6239, Train: 0.9977, Valid: 0.9870, Best: 0.9876\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 3.5847556591033936 | KNN Loss: 3.5813450813293457 | CLS Loss: 0.0034105628728866577\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 3.614271402359009 | KNN Loss: 3.5946667194366455 | CLS Loss: 0.01960478350520134\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 3.6118385791778564 | KNN Loss: 3.6083152294158936 | CLS Loss: 0.003523327875882387\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 3.619525194168091 | KNN Loss: 3.610283136367798 | CLS Loss: 0.009242016822099686\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 3.6022305488586426 | KNN Loss: 3.595247268676758 | CLS Loss: 0.006983320694416761\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 3.6431808471679688 | KNN Loss: 3.634584426879883 | CLS Loss: 0.008596374653279781\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 3.6892716884613037 | KNN Loss: 3.658247470855713 | CLS Loss: 0.031024152413010597\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 3.607393980026245 | KNN Loss: 3.6011486053466797 | CLS Loss: 0.006245452910661697\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 3.622530221939087 | KNN Loss: 3.6217565536499023 | CLS Loss: 0.0007737391861155629\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 3.616088628768921 | KNN Loss: 3.6100728511810303 | CLS Loss: 0.00601588748395443\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 3.642266273498535 | KNN Loss: 3.637554883956909 | CLS Loss: 0.004711432382464409\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 3.5972912311553955 | KNN Loss: 3.5852324962615967 | CLS Loss: 0.012058684602379799\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 3.6104369163513184 | KNN Loss: 3.59527587890625 | CLS Loss: 0.015161043964326382\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 3.641225576400757 | KNN Loss: 3.631723642349243 | CLS Loss: 0.009501843713223934\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 3.6383657455444336 | KNN Loss: 3.629019260406494 | CLS Loss: 0.009346365928649902\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 3.6063194274902344 | KNN Loss: 3.6012537479400635 | CLS Loss: 0.0050656660459935665\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 3.6019604206085205 | KNN Loss: 3.593470573425293 | CLS Loss: 0.008489803411066532\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 3.588667154312134 | KNN Loss: 3.586315870285034 | CLS Loss: 0.0023513382766395807\n",
      "Epoch: 173, Loss: 3.6177, Train: 0.9977, Valid: 0.9871, Best: 0.9876\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 3.6336605548858643 | KNN Loss: 3.6248252391815186 | CLS Loss: 0.008835233747959137\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 3.6484594345092773 | KNN Loss: 3.6353371143341064 | CLS Loss: 0.01312243565917015\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 3.6139235496520996 | KNN Loss: 3.6099941730499268 | CLS Loss: 0.003929357510060072\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 3.6212310791015625 | KNN Loss: 3.6159512996673584 | CLS Loss: 0.00527985580265522\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 3.6196062564849854 | KNN Loss: 3.6128909587860107 | CLS Loss: 0.006715303752571344\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 3.6410646438598633 | KNN Loss: 3.6367924213409424 | CLS Loss: 0.004272317048162222\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 3.644882917404175 | KNN Loss: 3.643224000930786 | CLS Loss: 0.0016588922590017319\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 3.6328353881835938 | KNN Loss: 3.6272075176239014 | CLS Loss: 0.005627775564789772\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 3.616375207901001 | KNN Loss: 3.6046905517578125 | CLS Loss: 0.011684617958962917\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 3.598710060119629 | KNN Loss: 3.5955591201782227 | CLS Loss: 0.003151038195937872\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 3.6025049686431885 | KNN Loss: 3.595738410949707 | CLS Loss: 0.006766463629901409\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 3.610117197036743 | KNN Loss: 3.6055643558502197 | CLS Loss: 0.004552959930151701\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 3.5885729789733887 | KNN Loss: 3.559722423553467 | CLS Loss: 0.028850503265857697\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 3.6130967140197754 | KNN Loss: 3.608815908432007 | CLS Loss: 0.004280867986381054\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 3.607790470123291 | KNN Loss: 3.5994105339050293 | CLS Loss: 0.008379846811294556\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 3.6711270809173584 | KNN Loss: 3.6337246894836426 | CLS Loss: 0.03740241006016731\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 3.613316535949707 | KNN Loss: 3.6118056774139404 | CLS Loss: 0.0015108888037502766\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 3.650291919708252 | KNN Loss: 3.64639949798584 | CLS Loss: 0.003892310196533799\n",
      "Epoch: 174, Loss: 3.6245, Train: 0.9969, Valid: 0.9860, Best: 0.9876\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 3.661280632019043 | KNN Loss: 3.6426143646240234 | CLS Loss: 0.018666313961148262\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 3.625805616378784 | KNN Loss: 3.6235172748565674 | CLS Loss: 0.0022882327903062105\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 3.6067216396331787 | KNN Loss: 3.5974738597869873 | CLS Loss: 0.009247839450836182\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 3.6260037422180176 | KNN Loss: 3.6050608158111572 | CLS Loss: 0.020942965522408485\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 3.680384635925293 | KNN Loss: 3.6674535274505615 | CLS Loss: 0.01293121837079525\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 3.6293225288391113 | KNN Loss: 3.624072551727295 | CLS Loss: 0.005250073969364166\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 3.6355888843536377 | KNN Loss: 3.621553897857666 | CLS Loss: 0.014034915715456009\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 3.598060369491577 | KNN Loss: 3.594541311264038 | CLS Loss: 0.0035189574118703604\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 3.6371638774871826 | KNN Loss: 3.6316874027252197 | CLS Loss: 0.0054764412343502045\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 3.6187853813171387 | KNN Loss: 3.605888605117798 | CLS Loss: 0.012896792031824589\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 3.655428409576416 | KNN Loss: 3.644453287124634 | CLS Loss: 0.010975129902362823\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 3.5912811756134033 | KNN Loss: 3.581650733947754 | CLS Loss: 0.009630460292100906\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 3.633539915084839 | KNN Loss: 3.6238346099853516 | CLS Loss: 0.009705297648906708\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 3.6711549758911133 | KNN Loss: 3.6268341541290283 | CLS Loss: 0.044320859014987946\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 3.590885877609253 | KNN Loss: 3.5803897380828857 | CLS Loss: 0.010496098548173904\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 3.6410465240478516 | KNN Loss: 3.636218786239624 | CLS Loss: 0.004827774129807949\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 3.5934622287750244 | KNN Loss: 3.5885684490203857 | CLS Loss: 0.004893861711025238\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 3.6384270191192627 | KNN Loss: 3.6269009113311768 | CLS Loss: 0.011526040732860565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175, Loss: 3.6220, Train: 0.9971, Valid: 0.9859, Best: 0.9876\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 3.6143691539764404 | KNN Loss: 3.6049280166625977 | CLS Loss: 0.009441026486456394\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 3.605889320373535 | KNN Loss: 3.597479820251465 | CLS Loss: 0.008409553207457066\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 3.615475654602051 | KNN Loss: 3.6118106842041016 | CLS Loss: 0.003664921037852764\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 3.632847309112549 | KNN Loss: 3.6202259063720703 | CLS Loss: 0.012621358968317509\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 3.5956640243530273 | KNN Loss: 3.585963487625122 | CLS Loss: 0.009700545109808445\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 3.6137568950653076 | KNN Loss: 3.599789619445801 | CLS Loss: 0.013967392034828663\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 3.607226848602295 | KNN Loss: 3.60377836227417 | CLS Loss: 0.0034485303331166506\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 3.68652606010437 | KNN Loss: 3.6710760593414307 | CLS Loss: 0.015449978411197662\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 3.6435868740081787 | KNN Loss: 3.632720947265625 | CLS Loss: 0.010866007767617702\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 3.5995399951934814 | KNN Loss: 3.595229148864746 | CLS Loss: 0.004310882184654474\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 3.649367332458496 | KNN Loss: 3.639054298400879 | CLS Loss: 0.010313091799616814\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 3.6071553230285645 | KNN Loss: 3.594130754470825 | CLS Loss: 0.01302465982735157\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 3.6183173656463623 | KNN Loss: 3.616985559463501 | CLS Loss: 0.0013317788252606988\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 3.5894086360931396 | KNN Loss: 3.582016706466675 | CLS Loss: 0.007391852792352438\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 3.6012909412384033 | KNN Loss: 3.600079298019409 | CLS Loss: 0.0012115983990952373\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 3.6036763191223145 | KNN Loss: 3.5924057960510254 | CLS Loss: 0.011270417831838131\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 3.616929531097412 | KNN Loss: 3.6097090244293213 | CLS Loss: 0.007220594212412834\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 3.6208279132843018 | KNN Loss: 3.6152193546295166 | CLS Loss: 0.005608532577753067\n",
      "Epoch: 176, Loss: 3.6167, Train: 0.9969, Valid: 0.9864, Best: 0.9876\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 3.643296957015991 | KNN Loss: 3.6408088207244873 | CLS Loss: 0.0024880601558834314\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 3.6463751792907715 | KNN Loss: 3.614018678665161 | CLS Loss: 0.03235647454857826\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 3.64261794090271 | KNN Loss: 3.6157803535461426 | CLS Loss: 0.02683749422430992\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 3.621342897415161 | KNN Loss: 3.6182985305786133 | CLS Loss: 0.0030444690492004156\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 3.5955121517181396 | KNN Loss: 3.5828428268432617 | CLS Loss: 0.012669399380683899\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 3.6176652908325195 | KNN Loss: 3.6046953201293945 | CLS Loss: 0.01296988595277071\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 3.567209482192993 | KNN Loss: 3.562241554260254 | CLS Loss: 0.004967998247593641\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 3.5765645503997803 | KNN Loss: 3.5568714141845703 | CLS Loss: 0.01969309151172638\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 3.6122419834136963 | KNN Loss: 3.6007819175720215 | CLS Loss: 0.0114601356908679\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 3.6375839710235596 | KNN Loss: 3.6157872676849365 | CLS Loss: 0.021796636283397675\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 3.6197192668914795 | KNN Loss: 3.6178269386291504 | CLS Loss: 0.0018923964817076921\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 3.618534803390503 | KNN Loss: 3.6126182079315186 | CLS Loss: 0.005916644353419542\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 3.621331214904785 | KNN Loss: 3.608708143234253 | CLS Loss: 0.012623078189790249\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 3.665963888168335 | KNN Loss: 3.664048433303833 | CLS Loss: 0.0019154358888044953\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 3.6771578788757324 | KNN Loss: 3.640383720397949 | CLS Loss: 0.03677421808242798\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 3.6338980197906494 | KNN Loss: 3.6242411136627197 | CLS Loss: 0.00965690053999424\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 3.663565158843994 | KNN Loss: 3.6516923904418945 | CLS Loss: 0.011872737668454647\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 3.666656970977783 | KNN Loss: 3.6584601402282715 | CLS Loss: 0.008196786977350712\n",
      "Epoch: 177, Loss: 3.6205, Train: 0.9969, Valid: 0.9865, Best: 0.9876\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 3.6059374809265137 | KNN Loss: 3.598904848098755 | CLS Loss: 0.007032614666968584\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 3.627133369445801 | KNN Loss: 3.600799560546875 | CLS Loss: 0.026333879679441452\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 3.573850154876709 | KNN Loss: 3.569148063659668 | CLS Loss: 0.00470203161239624\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 3.6322736740112305 | KNN Loss: 3.6110098361968994 | CLS Loss: 0.021263808012008667\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 3.618537664413452 | KNN Loss: 3.6168665885925293 | CLS Loss: 0.0016710769850760698\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 3.6574015617370605 | KNN Loss: 3.648458957672119 | CLS Loss: 0.008942658081650734\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 3.615046739578247 | KNN Loss: 3.6106879711151123 | CLS Loss: 0.004358740523457527\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 3.6246581077575684 | KNN Loss: 3.6235880851745605 | CLS Loss: 0.0010699867270886898\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 3.638754367828369 | KNN Loss: 3.6357269287109375 | CLS Loss: 0.0030274856835603714\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 3.654111385345459 | KNN Loss: 3.632286310195923 | CLS Loss: 0.0218251533806324\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 3.6119909286499023 | KNN Loss: 3.610048770904541 | CLS Loss: 0.0019421386532485485\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 3.7605721950531006 | KNN Loss: 3.7545676231384277 | CLS Loss: 0.006004687864333391\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 3.6427457332611084 | KNN Loss: 3.6298117637634277 | CLS Loss: 0.012934005819261074\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 3.61035418510437 | KNN Loss: 3.605172872543335 | CLS Loss: 0.0051812781020998955\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 3.6631438732147217 | KNN Loss: 3.6447513103485107 | CLS Loss: 0.01839260384440422\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 3.598573923110962 | KNN Loss: 3.5882883071899414 | CLS Loss: 0.010285608470439911\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 3.64015531539917 | KNN Loss: 3.637458324432373 | CLS Loss: 0.002696894109249115\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 3.6293179988861084 | KNN Loss: 3.6190993785858154 | CLS Loss: 0.010218609124422073\n",
      "Epoch: 178, Loss: 3.6271, Train: 0.9976, Valid: 0.9871, Best: 0.9876\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 3.6093881130218506 | KNN Loss: 3.6073036193847656 | CLS Loss: 0.0020845031831413507\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 3.6015939712524414 | KNN Loss: 3.588491439819336 | CLS Loss: 0.013102592900395393\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 3.6532211303710938 | KNN Loss: 3.641528606414795 | CLS Loss: 0.011692491360008717\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 3.6431078910827637 | KNN Loss: 3.637758255004883 | CLS Loss: 0.005349717102944851\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 3.61431622505188 | KNN Loss: 3.596196413040161 | CLS Loss: 0.018119841814041138\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 3.6391022205352783 | KNN Loss: 3.636082410812378 | CLS Loss: 0.0030197061132639647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 3.652689218521118 | KNN Loss: 3.627095937728882 | CLS Loss: 0.025593332946300507\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 3.6557202339172363 | KNN Loss: 3.6421141624450684 | CLS Loss: 0.01360598485916853\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 3.61965274810791 | KNN Loss: 3.614889144897461 | CLS Loss: 0.0047636511735618114\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 3.6102490425109863 | KNN Loss: 3.606499433517456 | CLS Loss: 0.0037496844306588173\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 3.626084327697754 | KNN Loss: 3.6149988174438477 | CLS Loss: 0.011085602454841137\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 3.698547601699829 | KNN Loss: 3.6567821502685547 | CLS Loss: 0.04176536574959755\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 3.6583595275878906 | KNN Loss: 3.6436009407043457 | CLS Loss: 0.014758583158254623\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 3.669281482696533 | KNN Loss: 3.6548988819122314 | CLS Loss: 0.014382707886397839\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 3.649362087249756 | KNN Loss: 3.643834114074707 | CLS Loss: 0.005527968052774668\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 3.6590006351470947 | KNN Loss: 3.6455276012420654 | CLS Loss: 0.013472951017320156\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 3.615563154220581 | KNN Loss: 3.608804702758789 | CLS Loss: 0.006758565548807383\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 3.6021013259887695 | KNN Loss: 3.5791940689086914 | CLS Loss: 0.022907307371497154\n",
      "Epoch: 179, Loss: 3.6351, Train: 0.9968, Valid: 0.9867, Best: 0.9876\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 3.614147186279297 | KNN Loss: 3.6049439907073975 | CLS Loss: 0.009203187189996243\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 3.661900758743286 | KNN Loss: 3.6546242237091064 | CLS Loss: 0.007276517804712057\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 3.61443829536438 | KNN Loss: 3.604203224182129 | CLS Loss: 0.01023518294095993\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 3.6638238430023193 | KNN Loss: 3.6428840160369873 | CLS Loss: 0.02093970961868763\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 3.6209464073181152 | KNN Loss: 3.617081880569458 | CLS Loss: 0.0038645341992378235\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 3.6821303367614746 | KNN Loss: 3.6801083087921143 | CLS Loss: 0.0020220130681991577\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 3.6186962127685547 | KNN Loss: 3.607449531555176 | CLS Loss: 0.01124660950154066\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 3.5963494777679443 | KNN Loss: 3.584015369415283 | CLS Loss: 0.012334213592112064\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 3.6807198524475098 | KNN Loss: 3.6704018115997314 | CLS Loss: 0.010318011045455933\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 3.6320455074310303 | KNN Loss: 3.6063320636749268 | CLS Loss: 0.02571352943778038\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 3.621772527694702 | KNN Loss: 3.6193981170654297 | CLS Loss: 0.002374335890635848\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 3.6146905422210693 | KNN Loss: 3.60825252532959 | CLS Loss: 0.006438094656914473\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 3.619234085083008 | KNN Loss: 3.6105732917785645 | CLS Loss: 0.00866068433970213\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 3.6552953720092773 | KNN Loss: 3.646526575088501 | CLS Loss: 0.00876870658248663\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 3.62131404876709 | KNN Loss: 3.60359263420105 | CLS Loss: 0.017721375450491905\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 3.60360050201416 | KNN Loss: 3.600104808807373 | CLS Loss: 0.0034957565367221832\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 3.6361262798309326 | KNN Loss: 3.603058338165283 | CLS Loss: 0.03306783363223076\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 3.6484334468841553 | KNN Loss: 3.6411843299865723 | CLS Loss: 0.007249188143759966\n",
      "Epoch: 180, Loss: 3.6294, Train: 0.9955, Valid: 0.9857, Best: 0.9876\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 3.6371381282806396 | KNN Loss: 3.6239418983459473 | CLS Loss: 0.013196283020079136\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 3.609168291091919 | KNN Loss: 3.602174758911133 | CLS Loss: 0.006993604823946953\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 3.6493022441864014 | KNN Loss: 3.6345760822296143 | CLS Loss: 0.01472612377256155\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 3.612409830093384 | KNN Loss: 3.6051318645477295 | CLS Loss: 0.007278082426637411\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 3.6332480907440186 | KNN Loss: 3.6226625442504883 | CLS Loss: 0.010585435666143894\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 3.5867695808410645 | KNN Loss: 3.582797050476074 | CLS Loss: 0.00397248612716794\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 3.618793487548828 | KNN Loss: 3.609243392944336 | CLS Loss: 0.009549994021654129\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 3.614820957183838 | KNN Loss: 3.6102099418640137 | CLS Loss: 0.004611132200807333\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 3.6243855953216553 | KNN Loss: 3.61612868309021 | CLS Loss: 0.008256888017058372\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 3.6044161319732666 | KNN Loss: 3.599470853805542 | CLS Loss: 0.004945168271660805\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 3.630171060562134 | KNN Loss: 3.6191558837890625 | CLS Loss: 0.011015258729457855\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 3.607754945755005 | KNN Loss: 3.60125470161438 | CLS Loss: 0.006500178016722202\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 3.597583532333374 | KNN Loss: 3.593639850616455 | CLS Loss: 0.00394371896982193\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 3.6110081672668457 | KNN Loss: 3.6084702014923096 | CLS Loss: 0.002538068452849984\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 3.6531190872192383 | KNN Loss: 3.6464595794677734 | CLS Loss: 0.006659447215497494\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 3.61186146736145 | KNN Loss: 3.5920400619506836 | CLS Loss: 0.019821476191282272\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 3.630127429962158 | KNN Loss: 3.6186699867248535 | CLS Loss: 0.011457525193691254\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 3.6314196586608887 | KNN Loss: 3.6247506141662598 | CLS Loss: 0.006669049151241779\n",
      "Epoch: 181, Loss: 3.6267, Train: 0.9958, Valid: 0.9852, Best: 0.9876\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 3.706477165222168 | KNN Loss: 3.6712493896484375 | CLS Loss: 0.035227809101343155\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 3.5925676822662354 | KNN Loss: 3.582216739654541 | CLS Loss: 0.010350983589887619\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 3.622532367706299 | KNN Loss: 3.6034162044525146 | CLS Loss: 0.01911618933081627\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 3.639622211456299 | KNN Loss: 3.6323981285095215 | CLS Loss: 0.007224030792713165\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 3.599954605102539 | KNN Loss: 3.596282720565796 | CLS Loss: 0.003671846352517605\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 3.657181739807129 | KNN Loss: 3.6380271911621094 | CLS Loss: 0.019154585897922516\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 3.659607410430908 | KNN Loss: 3.6464250087738037 | CLS Loss: 0.013182372786104679\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 3.6695802211761475 | KNN Loss: 3.6439874172210693 | CLS Loss: 0.025592904537916183\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 3.675245523452759 | KNN Loss: 3.661120653152466 | CLS Loss: 0.014124870300292969\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 3.6107277870178223 | KNN Loss: 3.599186658859253 | CLS Loss: 0.011541170999407768\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 3.6527326107025146 | KNN Loss: 3.6408870220184326 | CLS Loss: 0.011845631524920464\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 3.602019786834717 | KNN Loss: 3.599036931991577 | CLS Loss: 0.0029827728867530823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 3.6429431438446045 | KNN Loss: 3.6204166412353516 | CLS Loss: 0.02252655103802681\n",
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 3.639878749847412 | KNN Loss: 3.6379127502441406 | CLS Loss: 0.001965959556400776\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 3.5996601581573486 | KNN Loss: 3.5913119316101074 | CLS Loss: 0.00834817998111248\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 3.6642725467681885 | KNN Loss: 3.6548068523406982 | CLS Loss: 0.00946575403213501\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 3.6733999252319336 | KNN Loss: 3.6675338745117188 | CLS Loss: 0.005866130348294973\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 3.634690523147583 | KNN Loss: 3.6240346431732178 | CLS Loss: 0.010655797086656094\n",
      "Epoch: 182, Loss: 3.6295, Train: 0.9956, Valid: 0.9859, Best: 0.9876\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 3.628014087677002 | KNN Loss: 3.602497100830078 | CLS Loss: 0.025517094880342484\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 3.6241390705108643 | KNN Loss: 3.6095752716064453 | CLS Loss: 0.014563714154064655\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 3.609236478805542 | KNN Loss: 3.593947649002075 | CLS Loss: 0.015288785099983215\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 3.5924935340881348 | KNN Loss: 3.5857043266296387 | CLS Loss: 0.006789150182157755\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 3.5822525024414062 | KNN Loss: 3.5784449577331543 | CLS Loss: 0.003807536792010069\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 3.6076369285583496 | KNN Loss: 3.6041483879089355 | CLS Loss: 0.003488546935841441\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 3.6280620098114014 | KNN Loss: 3.6046488285064697 | CLS Loss: 0.02341306395828724\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 3.6166276931762695 | KNN Loss: 3.6076431274414062 | CLS Loss: 0.008984647691249847\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 3.591334104537964 | KNN Loss: 3.584322214126587 | CLS Loss: 0.007011923473328352\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 3.6221306324005127 | KNN Loss: 3.607051372528076 | CLS Loss: 0.01507927943021059\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 3.6059937477111816 | KNN Loss: 3.600961208343506 | CLS Loss: 0.005032602697610855\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 3.6017770767211914 | KNN Loss: 3.5938515663146973 | CLS Loss: 0.007925597950816154\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 3.6130712032318115 | KNN Loss: 3.607170581817627 | CLS Loss: 0.005900607910007238\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 3.6482491493225098 | KNN Loss: 3.6462461948394775 | CLS Loss: 0.0020030331797897816\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 3.605424165725708 | KNN Loss: 3.5967960357666016 | CLS Loss: 0.00862808246165514\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 3.642263650894165 | KNN Loss: 3.6275813579559326 | CLS Loss: 0.014682217501103878\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 3.609858512878418 | KNN Loss: 3.5877630710601807 | CLS Loss: 0.022095557302236557\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 3.6047825813293457 | KNN Loss: 3.600597381591797 | CLS Loss: 0.004185135941952467\n",
      "Epoch: 183, Loss: 3.6262, Train: 0.9960, Valid: 0.9854, Best: 0.9876\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 3.592935800552368 | KNN Loss: 3.5643234252929688 | CLS Loss: 0.028612399473786354\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 3.6226069927215576 | KNN Loss: 3.6176247596740723 | CLS Loss: 0.004982191137969494\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 3.638430595397949 | KNN Loss: 3.6182219982147217 | CLS Loss: 0.020208684727549553\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 3.650796890258789 | KNN Loss: 3.632220983505249 | CLS Loss: 0.01857594959437847\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 3.6714067459106445 | KNN Loss: 3.639779806137085 | CLS Loss: 0.03162701800465584\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 3.654280662536621 | KNN Loss: 3.6507256031036377 | CLS Loss: 0.0035551271867007017\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 3.6402039527893066 | KNN Loss: 3.6357309818267822 | CLS Loss: 0.004473061300814152\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 3.605696678161621 | KNN Loss: 3.602531909942627 | CLS Loss: 0.003164786146953702\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 3.5875651836395264 | KNN Loss: 3.582820177078247 | CLS Loss: 0.0047449697740375996\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 3.601837635040283 | KNN Loss: 3.5932209491729736 | CLS Loss: 0.008616749197244644\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 3.624605178833008 | KNN Loss: 3.6109459400177 | CLS Loss: 0.013659183867275715\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 3.625392198562622 | KNN Loss: 3.60719895362854 | CLS Loss: 0.01819324679672718\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 3.6302812099456787 | KNN Loss: 3.615960121154785 | CLS Loss: 0.014321126975119114\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 3.6275813579559326 | KNN Loss: 3.6138672828674316 | CLS Loss: 0.013714184053242207\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 3.5836708545684814 | KNN Loss: 3.5746679306030273 | CLS Loss: 0.00900281872600317\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 3.620542526245117 | KNN Loss: 3.6000397205352783 | CLS Loss: 0.020502885803580284\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 3.6500449180603027 | KNN Loss: 3.6457724571228027 | CLS Loss: 0.004272480495274067\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 3.6934072971343994 | KNN Loss: 3.6528921127319336 | CLS Loss: 0.04051526263356209\n",
      "Epoch: 184, Loss: 3.6257, Train: 0.9955, Valid: 0.9865, Best: 0.9876\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 3.653769016265869 | KNN Loss: 3.646981954574585 | CLS Loss: 0.006786994636058807\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 3.6179099082946777 | KNN Loss: 3.6066319942474365 | CLS Loss: 0.011277910321950912\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 3.6020805835723877 | KNN Loss: 3.598874092102051 | CLS Loss: 0.0032065301202237606\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 3.613891124725342 | KNN Loss: 3.6072399616241455 | CLS Loss: 0.006651108618825674\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 3.627290725708008 | KNN Loss: 3.6055166721343994 | CLS Loss: 0.021773941814899445\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 3.6068172454833984 | KNN Loss: 3.603625535964966 | CLS Loss: 0.003191702999174595\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 3.6222352981567383 | KNN Loss: 3.6086976528167725 | CLS Loss: 0.0135376937687397\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 3.6355669498443604 | KNN Loss: 3.627837657928467 | CLS Loss: 0.007729371543973684\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 3.595966339111328 | KNN Loss: 3.593606472015381 | CLS Loss: 0.002359784906730056\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 3.6207215785980225 | KNN Loss: 3.6197969913482666 | CLS Loss: 0.0009245164110325277\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 3.59248423576355 | KNN Loss: 3.583174467086792 | CLS Loss: 0.009309671819210052\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 3.6366872787475586 | KNN Loss: 3.629955530166626 | CLS Loss: 0.00673185708001256\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 3.612971544265747 | KNN Loss: 3.605100393295288 | CLS Loss: 0.00787106528878212\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 3.6409339904785156 | KNN Loss: 3.6374974250793457 | CLS Loss: 0.0034366713371127844\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 3.6336312294006348 | KNN Loss: 3.625166893005371 | CLS Loss: 0.008464250713586807\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 3.6456501483917236 | KNN Loss: 3.6205906867980957 | CLS Loss: 0.025059347972273827\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 3.5963988304138184 | KNN Loss: 3.5866968631744385 | CLS Loss: 0.009701966308057308\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 3.6050257682800293 | KNN Loss: 3.6022887229919434 | CLS Loss: 0.0027371307369321585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, Loss: 3.6264, Train: 0.9976, Valid: 0.9869, Best: 0.9876\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 3.5996034145355225 | KNN Loss: 3.5942909717559814 | CLS Loss: 0.0053123896941542625\n",
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 3.618114471435547 | KNN Loss: 3.615853786468506 | CLS Loss: 0.0022606896236538887\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 3.621063470840454 | KNN Loss: 3.613410234451294 | CLS Loss: 0.007653196342289448\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 3.5906076431274414 | KNN Loss: 3.5887577533721924 | CLS Loss: 0.0018499090801924467\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 3.614187002182007 | KNN Loss: 3.6103265285491943 | CLS Loss: 0.0038604652509093285\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 3.6237847805023193 | KNN Loss: 3.610759973526001 | CLS Loss: 0.013024895451962948\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 3.643181324005127 | KNN Loss: 3.6329989433288574 | CLS Loss: 0.010182498022913933\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 3.6025400161743164 | KNN Loss: 3.59607195854187 | CLS Loss: 0.006468127481639385\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 3.5911142826080322 | KNN Loss: 3.5843148231506348 | CLS Loss: 0.006799553520977497\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 3.6530845165252686 | KNN Loss: 3.6430163383483887 | CLS Loss: 0.010068267583847046\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 3.676260232925415 | KNN Loss: 3.6516237258911133 | CLS Loss: 0.0246364064514637\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 3.5957040786743164 | KNN Loss: 3.5884997844696045 | CLS Loss: 0.007204405963420868\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 3.641268491744995 | KNN Loss: 3.6275691986083984 | CLS Loss: 0.013699254021048546\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 3.5975308418273926 | KNN Loss: 3.5943779945373535 | CLS Loss: 0.0031529187690466642\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 3.6559035778045654 | KNN Loss: 3.6493430137634277 | CLS Loss: 0.006560558918863535\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 3.618858575820923 | KNN Loss: 3.6130664348602295 | CLS Loss: 0.0057921819388866425\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 3.647385597229004 | KNN Loss: 3.636888027191162 | CLS Loss: 0.010497630573809147\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 3.6324143409729004 | KNN Loss: 3.6250967979431152 | CLS Loss: 0.007317485753446817\n",
      "Epoch: 186, Loss: 3.6299, Train: 0.9964, Valid: 0.9854, Best: 0.9876\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 3.6151981353759766 | KNN Loss: 3.605344772338867 | CLS Loss: 0.009853414259850979\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 3.660109519958496 | KNN Loss: 3.6538562774658203 | CLS Loss: 0.006253225263208151\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 3.600532054901123 | KNN Loss: 3.587270736694336 | CLS Loss: 0.013261264190077782\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 3.582655191421509 | KNN Loss: 3.574537992477417 | CLS Loss: 0.008117309771478176\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 3.5900630950927734 | KNN Loss: 3.5858685970306396 | CLS Loss: 0.004194539040327072\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 3.5914340019226074 | KNN Loss: 3.5838866233825684 | CLS Loss: 0.007547489833086729\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 3.644038677215576 | KNN Loss: 3.629523515701294 | CLS Loss: 0.014515219256281853\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 3.683730363845825 | KNN Loss: 3.6685843467712402 | CLS Loss: 0.01514610555022955\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 3.626633644104004 | KNN Loss: 3.617931842803955 | CLS Loss: 0.008701682090759277\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 3.660142183303833 | KNN Loss: 3.608827590942383 | CLS Loss: 0.051314692944288254\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 3.6165332794189453 | KNN Loss: 3.5787410736083984 | CLS Loss: 0.03779229894280434\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 3.7165071964263916 | KNN Loss: 3.689755439758301 | CLS Loss: 0.02675171196460724\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 3.643791913986206 | KNN Loss: 3.637857675552368 | CLS Loss: 0.005934131797403097\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 3.642944097518921 | KNN Loss: 3.638695001602173 | CLS Loss: 0.004249158315360546\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 3.612159490585327 | KNN Loss: 3.609410285949707 | CLS Loss: 0.0027491156943142414\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 3.627769947052002 | KNN Loss: 3.6110541820526123 | CLS Loss: 0.016715828329324722\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 3.5909175872802734 | KNN Loss: 3.5872762203216553 | CLS Loss: 0.003641273593530059\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 3.62652850151062 | KNN Loss: 3.597764253616333 | CLS Loss: 0.02876427210867405\n",
      "Epoch: 187, Loss: 3.6280, Train: 0.9970, Valid: 0.9869, Best: 0.9876\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 3.621647834777832 | KNN Loss: 3.616007089614868 | CLS Loss: 0.005640698596835136\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 3.612245559692383 | KNN Loss: 3.606647491455078 | CLS Loss: 0.005598098039627075\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 3.6456854343414307 | KNN Loss: 3.634777784347534 | CLS Loss: 0.010907573625445366\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 3.5983335971832275 | KNN Loss: 3.5935497283935547 | CLS Loss: 0.004783758893609047\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 3.6859779357910156 | KNN Loss: 3.6573915481567383 | CLS Loss: 0.028586409986019135\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 3.6012792587280273 | KNN Loss: 3.592590570449829 | CLS Loss: 0.008688576519489288\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 3.6153557300567627 | KNN Loss: 3.6096506118774414 | CLS Loss: 0.005705026909708977\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 3.606325387954712 | KNN Loss: 3.5958292484283447 | CLS Loss: 0.010496072471141815\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 3.6388981342315674 | KNN Loss: 3.615811347961426 | CLS Loss: 0.023086901754140854\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 3.581465721130371 | KNN Loss: 3.564852714538574 | CLS Loss: 0.016613025218248367\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 3.6620309352874756 | KNN Loss: 3.646919012069702 | CLS Loss: 0.015111822634935379\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 3.614790678024292 | KNN Loss: 3.611046075820923 | CLS Loss: 0.0037446196656674147\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 3.5951812267303467 | KNN Loss: 3.591585874557495 | CLS Loss: 0.0035954590421169996\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 3.5823400020599365 | KNN Loss: 3.574204921722412 | CLS Loss: 0.008135139010846615\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 3.603315830230713 | KNN Loss: 3.595959424972534 | CLS Loss: 0.0073564485646784306\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 3.6320104598999023 | KNN Loss: 3.627891778945923 | CLS Loss: 0.004118791315704584\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 3.6024436950683594 | KNN Loss: 3.5949974060058594 | CLS Loss: 0.007446339353919029\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 3.6666407585144043 | KNN Loss: 3.654059648513794 | CLS Loss: 0.012581017799675465\n",
      "Epoch: 188, Loss: 3.6198, Train: 0.9960, Valid: 0.9853, Best: 0.9876\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 3.661391258239746 | KNN Loss: 3.6416587829589844 | CLS Loss: 0.019732531160116196\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 3.6296823024749756 | KNN Loss: 3.6169872283935547 | CLS Loss: 0.012695173732936382\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 3.5970027446746826 | KNN Loss: 3.586111545562744 | CLS Loss: 0.010891219601035118\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 3.6746022701263428 | KNN Loss: 3.6665284633636475 | CLS Loss: 0.008073761127889156\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 3.699159860610962 | KNN Loss: 3.6853785514831543 | CLS Loss: 0.01378141064196825\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 3.6071534156799316 | KNN Loss: 3.5999319553375244 | CLS Loss: 0.0072215585969388485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 3.592528820037842 | KNN Loss: 3.585294485092163 | CLS Loss: 0.007234451826661825\n",
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 3.591280937194824 | KNN Loss: 3.5898499488830566 | CLS Loss: 0.0014308879617601633\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 3.579073429107666 | KNN Loss: 3.5757646560668945 | CLS Loss: 0.0033087963238358498\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 3.6223948001861572 | KNN Loss: 3.6163384914398193 | CLS Loss: 0.0060562132857739925\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 3.6112325191497803 | KNN Loss: 3.6046500205993652 | CLS Loss: 0.006582415662705898\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 3.6086058616638184 | KNN Loss: 3.594255208969116 | CLS Loss: 0.014350628480315208\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 3.5999295711517334 | KNN Loss: 3.596799612045288 | CLS Loss: 0.003129939315840602\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 3.5991926193237305 | KNN Loss: 3.5841662883758545 | CLS Loss: 0.015026435256004333\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 3.679450511932373 | KNN Loss: 3.6616530418395996 | CLS Loss: 0.017797496169805527\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 3.682241678237915 | KNN Loss: 3.6583099365234375 | CLS Loss: 0.023931637406349182\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 3.6503822803497314 | KNN Loss: 3.6392226219177246 | CLS Loss: 0.011159726418554783\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 3.633626937866211 | KNN Loss: 3.6147758960723877 | CLS Loss: 0.018850969150662422\n",
      "Epoch: 189, Loss: 3.6254, Train: 0.9959, Valid: 0.9852, Best: 0.9876\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 3.650200605392456 | KNN Loss: 3.6387619972229004 | CLS Loss: 0.011438669636845589\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 3.626758098602295 | KNN Loss: 3.605281114578247 | CLS Loss: 0.021477052941918373\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 3.584193229675293 | KNN Loss: 3.573685884475708 | CLS Loss: 0.010507424362003803\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 3.6091699600219727 | KNN Loss: 3.59993839263916 | CLS Loss: 0.009231624193489552\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 3.6245338916778564 | KNN Loss: 3.611687660217285 | CLS Loss: 0.012846180237829685\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 3.6216073036193848 | KNN Loss: 3.5804805755615234 | CLS Loss: 0.04112662002444267\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 3.6026480197906494 | KNN Loss: 3.5929038524627686 | CLS Loss: 0.00974420364946127\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 3.6374075412750244 | KNN Loss: 3.612567186355591 | CLS Loss: 0.0248403437435627\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 3.6357107162475586 | KNN Loss: 3.6277754306793213 | CLS Loss: 0.007935374043881893\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 3.5887699127197266 | KNN Loss: 3.587411880493164 | CLS Loss: 0.001358012086711824\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 3.6261935234069824 | KNN Loss: 3.619081497192383 | CLS Loss: 0.007111941464245319\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 3.631115436553955 | KNN Loss: 3.6097352504730225 | CLS Loss: 0.021380146965384483\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 3.6016416549682617 | KNN Loss: 3.5999300479888916 | CLS Loss: 0.0017115037189796567\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 3.6444272994995117 | KNN Loss: 3.615636110305786 | CLS Loss: 0.02879120223224163\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 3.5995094776153564 | KNN Loss: 3.597141742706299 | CLS Loss: 0.00236777076497674\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 3.6195359230041504 | KNN Loss: 3.61493182182312 | CLS Loss: 0.004604043439030647\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 3.618614435195923 | KNN Loss: 3.6047234535217285 | CLS Loss: 0.013890896923840046\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 3.687173843383789 | KNN Loss: 3.653832197189331 | CLS Loss: 0.03334162384271622\n",
      "Epoch: 190, Loss: 3.6222, Train: 0.9966, Valid: 0.9857, Best: 0.9876\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 3.640061855316162 | KNN Loss: 3.6339261531829834 | CLS Loss: 0.006135667208582163\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 3.6313188076019287 | KNN Loss: 3.624279499053955 | CLS Loss: 0.007039322517812252\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 3.636725902557373 | KNN Loss: 3.61921763420105 | CLS Loss: 0.017508283257484436\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 3.628502130508423 | KNN Loss: 3.621640205383301 | CLS Loss: 0.006862025707960129\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 3.6703991889953613 | KNN Loss: 3.6563756465911865 | CLS Loss: 0.01402349304407835\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 3.599660634994507 | KNN Loss: 3.5778496265411377 | CLS Loss: 0.02181110717356205\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 3.620807647705078 | KNN Loss: 3.6158041954040527 | CLS Loss: 0.005003529135137796\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 3.608208417892456 | KNN Loss: 3.6001739501953125 | CLS Loss: 0.00803449284285307\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 3.6782612800598145 | KNN Loss: 3.670358180999756 | CLS Loss: 0.00790311861783266\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 3.620758056640625 | KNN Loss: 3.614638566970825 | CLS Loss: 0.006119465455412865\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 3.620983362197876 | KNN Loss: 3.6008317470550537 | CLS Loss: 0.0201515294611454\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 3.6199185848236084 | KNN Loss: 3.611781597137451 | CLS Loss: 0.008136891759932041\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 3.62489652633667 | KNN Loss: 3.6143267154693604 | CLS Loss: 0.010569770820438862\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 3.6113791465759277 | KNN Loss: 3.6072866916656494 | CLS Loss: 0.004092526622116566\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 3.669036388397217 | KNN Loss: 3.6556236743927 | CLS Loss: 0.01341263484209776\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 3.594883680343628 | KNN Loss: 3.5825612545013428 | CLS Loss: 0.012322405353188515\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 3.629948854446411 | KNN Loss: 3.6277358531951904 | CLS Loss: 0.002213098807260394\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 3.696726083755493 | KNN Loss: 3.683900833129883 | CLS Loss: 0.01282517984509468\n",
      "Epoch: 191, Loss: 3.6229, Train: 0.9948, Valid: 0.9838, Best: 0.9876\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 3.6348214149475098 | KNN Loss: 3.6239025592803955 | CLS Loss: 0.010918889194726944\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 3.690213203430176 | KNN Loss: 3.670846462249756 | CLS Loss: 0.01936676725745201\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 3.6686935424804688 | KNN Loss: 3.664041757583618 | CLS Loss: 0.004651858936995268\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 3.6384940147399902 | KNN Loss: 3.618166446685791 | CLS Loss: 0.02032759226858616\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 3.6218678951263428 | KNN Loss: 3.60684871673584 | CLS Loss: 0.015019293874502182\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 3.652493715286255 | KNN Loss: 3.635101318359375 | CLS Loss: 0.017392484471201897\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 3.6043167114257812 | KNN Loss: 3.600862503051758 | CLS Loss: 0.0034542495850473642\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 3.691948890686035 | KNN Loss: 3.674865484237671 | CLS Loss: 0.017083408311009407\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 3.636411190032959 | KNN Loss: 3.6276659965515137 | CLS Loss: 0.00874507799744606\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 3.6085286140441895 | KNN Loss: 3.5969204902648926 | CLS Loss: 0.0116081228479743\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 3.612891435623169 | KNN Loss: 3.5968947410583496 | CLS Loss: 0.015996644273400307\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 3.6865344047546387 | KNN Loss: 3.682344913482666 | CLS Loss: 0.004189487546682358\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 3.595670223236084 | KNN Loss: 3.5841050148010254 | CLS Loss: 0.011565161868929863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 3.637855052947998 | KNN Loss: 3.6268444061279297 | CLS Loss: 0.01101070735603571\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 3.6233179569244385 | KNN Loss: 3.614175319671631 | CLS Loss: 0.009142590686678886\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 3.5889978408813477 | KNN Loss: 3.583848714828491 | CLS Loss: 0.005149089731276035\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 3.6393251419067383 | KNN Loss: 3.6283762454986572 | CLS Loss: 0.010948811657726765\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 3.6060292720794678 | KNN Loss: 3.5987157821655273 | CLS Loss: 0.007313478272408247\n",
      "Epoch: 192, Loss: 3.6251, Train: 0.9975, Valid: 0.9870, Best: 0.9876\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 3.5758273601531982 | KNN Loss: 3.570014476776123 | CLS Loss: 0.005812915973365307\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 3.5749545097351074 | KNN Loss: 3.5733964443206787 | CLS Loss: 0.0015581520274281502\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 3.6122286319732666 | KNN Loss: 3.6087539196014404 | CLS Loss: 0.003474742639809847\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 3.6474971771240234 | KNN Loss: 3.6188454627990723 | CLS Loss: 0.028651805594563484\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 3.6030516624450684 | KNN Loss: 3.602106809616089 | CLS Loss: 0.0009449463104829192\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 3.6183595657348633 | KNN Loss: 3.6148812770843506 | CLS Loss: 0.003478379687294364\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 3.595308780670166 | KNN Loss: 3.57995867729187 | CLS Loss: 0.015350054018199444\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 3.6437010765075684 | KNN Loss: 3.6255855560302734 | CLS Loss: 0.018115518614649773\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 3.651487112045288 | KNN Loss: 3.625278949737549 | CLS Loss: 0.026208069175481796\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 3.6932520866394043 | KNN Loss: 3.6712615489959717 | CLS Loss: 0.021990537643432617\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 3.618751287460327 | KNN Loss: 3.5908994674682617 | CLS Loss: 0.027851728722453117\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 3.6402056217193604 | KNN Loss: 3.629716157913208 | CLS Loss: 0.010489440523087978\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 3.6053242683410645 | KNN Loss: 3.6001696586608887 | CLS Loss: 0.005154665559530258\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 3.6133198738098145 | KNN Loss: 3.605822801589966 | CLS Loss: 0.007497178390622139\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 3.6027050018310547 | KNN Loss: 3.5951740741729736 | CLS Loss: 0.0075309062376618385\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 3.6067769527435303 | KNN Loss: 3.600487470626831 | CLS Loss: 0.006289467215538025\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 3.6406900882720947 | KNN Loss: 3.6300768852233887 | CLS Loss: 0.010613222606480122\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 3.597306489944458 | KNN Loss: 3.5923914909362793 | CLS Loss: 0.004914951045066118\n",
      "Epoch: 193, Loss: 3.6238, Train: 0.9982, Valid: 0.9878, Best: 0.9878\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 3.635413885116577 | KNN Loss: 3.632596254348755 | CLS Loss: 0.002817693864926696\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 3.5884041786193848 | KNN Loss: 3.584214448928833 | CLS Loss: 0.004189767874777317\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 3.614814519882202 | KNN Loss: 3.6099400520324707 | CLS Loss: 0.004874584265053272\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 3.615349054336548 | KNN Loss: 3.6065127849578857 | CLS Loss: 0.008836241438984871\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 3.6657512187957764 | KNN Loss: 3.6491312980651855 | CLS Loss: 0.016620010137557983\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 3.607666254043579 | KNN Loss: 3.6043639183044434 | CLS Loss: 0.00330223492346704\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 3.5974855422973633 | KNN Loss: 3.5866308212280273 | CLS Loss: 0.010854806751012802\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 3.581427574157715 | KNN Loss: 3.5782225131988525 | CLS Loss: 0.0032051559537649155\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 3.608781337738037 | KNN Loss: 3.599699020385742 | CLS Loss: 0.009082223288714886\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 3.599263906478882 | KNN Loss: 3.596109390258789 | CLS Loss: 0.003154610050842166\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 3.606053352355957 | KNN Loss: 3.5909855365753174 | CLS Loss: 0.015067730098962784\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 3.6382665634155273 | KNN Loss: 3.6368765830993652 | CLS Loss: 0.0013898814795538783\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 3.6065471172332764 | KNN Loss: 3.60280442237854 | CLS Loss: 0.0037427449133247137\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 3.612647533416748 | KNN Loss: 3.605055809020996 | CLS Loss: 0.00759182358160615\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 3.624330759048462 | KNN Loss: 3.6180429458618164 | CLS Loss: 0.006287813652306795\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 3.5884687900543213 | KNN Loss: 3.5838494300842285 | CLS Loss: 0.00461933296173811\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 3.654557704925537 | KNN Loss: 3.6450536251068115 | CLS Loss: 0.009504074230790138\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 3.615440845489502 | KNN Loss: 3.6140758991241455 | CLS Loss: 0.0013650103937834501\n",
      "Epoch: 194, Loss: 3.6120, Train: 0.9973, Valid: 0.9857, Best: 0.9878\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 3.6452155113220215 | KNN Loss: 3.6352508068084717 | CLS Loss: 0.009964775294065475\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 3.599764347076416 | KNN Loss: 3.5919811725616455 | CLS Loss: 0.007783223874866962\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 3.634808301925659 | KNN Loss: 3.6300249099731445 | CLS Loss: 0.00478347996249795\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 3.5943009853363037 | KNN Loss: 3.5786185264587402 | CLS Loss: 0.01568250171840191\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 3.597588300704956 | KNN Loss: 3.589560031890869 | CLS Loss: 0.008028306998312473\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 3.658676862716675 | KNN Loss: 3.6538596153259277 | CLS Loss: 0.0048171659000217915\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 3.5879249572753906 | KNN Loss: 3.5838894844055176 | CLS Loss: 0.004035489168018103\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 3.609110116958618 | KNN Loss: 3.588125228881836 | CLS Loss: 0.020984873175621033\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 3.6003036499023438 | KNN Loss: 3.593921661376953 | CLS Loss: 0.006381944287568331\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 3.596787929534912 | KNN Loss: 3.5802457332611084 | CLS Loss: 0.01654224283993244\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 3.6506693363189697 | KNN Loss: 3.6472232341766357 | CLS Loss: 0.003446162212640047\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 3.615858793258667 | KNN Loss: 3.6061699390411377 | CLS Loss: 0.009688958525657654\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 3.620943307876587 | KNN Loss: 3.602419376373291 | CLS Loss: 0.01852385886013508\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 3.5939133167266846 | KNN Loss: 3.5880463123321533 | CLS Loss: 0.005867029540240765\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 3.618706703186035 | KNN Loss: 3.614093780517578 | CLS Loss: 0.004612975753843784\n",
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 3.587851047515869 | KNN Loss: 3.579329252243042 | CLS Loss: 0.008521883748471737\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 3.639223337173462 | KNN Loss: 3.629004716873169 | CLS Loss: 0.010218620300292969\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 3.6486783027648926 | KNN Loss: 3.625333070755005 | CLS Loss: 0.023345308378338814\n",
      "Epoch: 195, Loss: 3.6223, Train: 0.9965, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 3.6103804111480713 | KNN Loss: 3.6021227836608887 | CLS Loss: 0.008257594890892506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 3.6029610633850098 | KNN Loss: 3.580819606781006 | CLS Loss: 0.022141383960843086\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 3.607645273208618 | KNN Loss: 3.6037845611572266 | CLS Loss: 0.003860811935737729\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 3.6153924465179443 | KNN Loss: 3.6134893894195557 | CLS Loss: 0.0019030848052352667\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 3.616936445236206 | KNN Loss: 3.612663507461548 | CLS Loss: 0.004272931255400181\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 3.619908094406128 | KNN Loss: 3.6017515659332275 | CLS Loss: 0.01815658062696457\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 3.6128487586975098 | KNN Loss: 3.608612537384033 | CLS Loss: 0.004236267879605293\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 3.5964102745056152 | KNN Loss: 3.593170166015625 | CLS Loss: 0.0032401911448687315\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 3.668031930923462 | KNN Loss: 3.6478769779205322 | CLS Loss: 0.020154990255832672\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 3.6540322303771973 | KNN Loss: 3.6131744384765625 | CLS Loss: 0.040857769548892975\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 3.627376079559326 | KNN Loss: 3.615455150604248 | CLS Loss: 0.011921033263206482\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 3.6551427841186523 | KNN Loss: 3.644258499145508 | CLS Loss: 0.010884387418627739\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 3.5939419269561768 | KNN Loss: 3.588566780090332 | CLS Loss: 0.005375043489038944\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 3.6586179733276367 | KNN Loss: 3.6537094116210938 | CLS Loss: 0.004908578936010599\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 3.604590892791748 | KNN Loss: 3.5973122119903564 | CLS Loss: 0.007278729695826769\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 3.6013343334198 | KNN Loss: 3.595069408416748 | CLS Loss: 0.006265014410018921\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 3.624105215072632 | KNN Loss: 3.6011195182800293 | CLS Loss: 0.022985786199569702\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 3.588948965072632 | KNN Loss: 3.5833592414855957 | CLS Loss: 0.005589732434600592\n",
      "Epoch: 196, Loss: 3.6245, Train: 0.9972, Valid: 0.9870, Best: 0.9878\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 3.610595941543579 | KNN Loss: 3.6073453426361084 | CLS Loss: 0.003250496694818139\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 3.6112210750579834 | KNN Loss: 3.6045167446136475 | CLS Loss: 0.006704328581690788\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 3.6203606128692627 | KNN Loss: 3.613550901412964 | CLS Loss: 0.006809600163251162\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 3.601966142654419 | KNN Loss: 3.5957231521606445 | CLS Loss: 0.006242990493774414\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 3.616462469100952 | KNN Loss: 3.613696813583374 | CLS Loss: 0.0027655542362481356\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 3.629692792892456 | KNN Loss: 3.623981237411499 | CLS Loss: 0.005711487494409084\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 3.5970821380615234 | KNN Loss: 3.5523552894592285 | CLS Loss: 0.0447268970310688\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 3.6069881916046143 | KNN Loss: 3.60139536857605 | CLS Loss: 0.005592728964984417\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 3.6355881690979004 | KNN Loss: 3.6249923706054688 | CLS Loss: 0.010595687665045261\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 3.656984567642212 | KNN Loss: 3.6469202041625977 | CLS Loss: 0.010064404457807541\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 3.642641067504883 | KNN Loss: 3.6053929328918457 | CLS Loss: 0.03724805265665054\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 3.625028133392334 | KNN Loss: 3.6162214279174805 | CLS Loss: 0.008806784637272358\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 3.6506094932556152 | KNN Loss: 3.622037410736084 | CLS Loss: 0.028572123497724533\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 3.592414140701294 | KNN Loss: 3.578047037124634 | CLS Loss: 0.014367102645337582\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 3.6537981033325195 | KNN Loss: 3.640364408493042 | CLS Loss: 0.013433627784252167\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 3.688108444213867 | KNN Loss: 3.6743576526641846 | CLS Loss: 0.013750885613262653\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 3.6247642040252686 | KNN Loss: 3.60361385345459 | CLS Loss: 0.021150268614292145\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 3.6232078075408936 | KNN Loss: 3.6172914505004883 | CLS Loss: 0.005916278343647718\n",
      "Epoch: 197, Loss: 3.6232, Train: 0.9968, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 3.6173977851867676 | KNN Loss: 3.6088361740112305 | CLS Loss: 0.008561658672988415\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 3.6337714195251465 | KNN Loss: 3.606590509414673 | CLS Loss: 0.027180902659893036\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 3.599419116973877 | KNN Loss: 3.59348726272583 | CLS Loss: 0.005931777413934469\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 3.6085007190704346 | KNN Loss: 3.5961692333221436 | CLS Loss: 0.012331435456871986\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 3.5973939895629883 | KNN Loss: 3.5818421840667725 | CLS Loss: 0.015551852062344551\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 3.6236650943756104 | KNN Loss: 3.6144025325775146 | CLS Loss: 0.009262565523386002\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 3.616696834564209 | KNN Loss: 3.6049516201019287 | CLS Loss: 0.011745302937924862\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 3.6015260219573975 | KNN Loss: 3.5996696949005127 | CLS Loss: 0.0018562248442322016\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 3.6430740356445312 | KNN Loss: 3.6180737018585205 | CLS Loss: 0.02500038407742977\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 3.6032819747924805 | KNN Loss: 3.5858757495880127 | CLS Loss: 0.017406215891242027\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 3.6060681343078613 | KNN Loss: 3.596592664718628 | CLS Loss: 0.00947537086904049\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 3.6405189037323 | KNN Loss: 3.6372246742248535 | CLS Loss: 0.0032942427787929773\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 3.594961166381836 | KNN Loss: 3.5839390754699707 | CLS Loss: 0.011021971702575684\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 3.60532546043396 | KNN Loss: 3.5922884941101074 | CLS Loss: 0.013037003576755524\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 3.6201894283294678 | KNN Loss: 3.608874797821045 | CLS Loss: 0.01131462026387453\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 3.6325366497039795 | KNN Loss: 3.625087022781372 | CLS Loss: 0.007449688855558634\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 3.6348040103912354 | KNN Loss: 3.627692222595215 | CLS Loss: 0.007111771497875452\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 3.632406234741211 | KNN Loss: 3.6263322830200195 | CLS Loss: 0.006073859520256519\n",
      "Epoch: 198, Loss: 3.6263, Train: 0.9975, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 3.609171152114868 | KNN Loss: 3.603285789489746 | CLS Loss: 0.005885288584977388\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 3.6084234714508057 | KNN Loss: 3.5952138900756836 | CLS Loss: 0.013209475204348564\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 3.609923839569092 | KNN Loss: 3.5995471477508545 | CLS Loss: 0.010376619175076485\n",
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 3.619894027709961 | KNN Loss: 3.6107077598571777 | CLS Loss: 0.009186307899653912\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 3.6313209533691406 | KNN Loss: 3.6184334754943848 | CLS Loss: 0.012887374497950077\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 3.6136868000030518 | KNN Loss: 3.601278066635132 | CLS Loss: 0.012408849783241749\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 3.620128631591797 | KNN Loss: 3.616621255874634 | CLS Loss: 0.0035074225161224604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 3.5943009853363037 | KNN Loss: 3.5925846099853516 | CLS Loss: 0.0017163126030936837\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 3.597454786300659 | KNN Loss: 3.5926666259765625 | CLS Loss: 0.004788219463080168\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 3.6179463863372803 | KNN Loss: 3.605574131011963 | CLS Loss: 0.012372189201414585\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 3.617128372192383 | KNN Loss: 3.605790376663208 | CLS Loss: 0.011337882839143276\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 3.601569175720215 | KNN Loss: 3.578174114227295 | CLS Loss: 0.023395152762532234\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 3.665844440460205 | KNN Loss: 3.6365015506744385 | CLS Loss: 0.029342852532863617\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 3.6328747272491455 | KNN Loss: 3.616969108581543 | CLS Loss: 0.01590556465089321\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 3.6267547607421875 | KNN Loss: 3.60923433303833 | CLS Loss: 0.017520379275083542\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 3.5934956073760986 | KNN Loss: 3.580745220184326 | CLS Loss: 0.012750355526804924\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 3.5857009887695312 | KNN Loss: 3.582479476928711 | CLS Loss: 0.003221438266336918\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 3.639580726623535 | KNN Loss: 3.6219305992126465 | CLS Loss: 0.01765013113617897\n",
      "Epoch: 199, Loss: 3.6187, Train: 0.9972, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 3.597188949584961 | KNN Loss: 3.5954623222351074 | CLS Loss: 0.001726703718304634\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 3.599825143814087 | KNN Loss: 3.5841259956359863 | CLS Loss: 0.01569909229874611\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 3.5960326194763184 | KNN Loss: 3.581514358520508 | CLS Loss: 0.014518183656036854\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 3.612138271331787 | KNN Loss: 3.5962374210357666 | CLS Loss: 0.015900960192084312\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 3.6495325565338135 | KNN Loss: 3.6437630653381348 | CLS Loss: 0.0057694376446306705\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 3.609466075897217 | KNN Loss: 3.6006276607513428 | CLS Loss: 0.008838321082293987\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 3.6259500980377197 | KNN Loss: 3.6176297664642334 | CLS Loss: 0.008320380933582783\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 3.641432523727417 | KNN Loss: 3.6314032077789307 | CLS Loss: 0.010029221884906292\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 3.619626522064209 | KNN Loss: 3.5962555408477783 | CLS Loss: 0.023371033370494843\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 3.6671946048736572 | KNN Loss: 3.64292049407959 | CLS Loss: 0.024274000898003578\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 3.6686556339263916 | KNN Loss: 3.6431009769439697 | CLS Loss: 0.02555454894900322\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 3.6975719928741455 | KNN Loss: 3.689484119415283 | CLS Loss: 0.008087828755378723\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 3.627814531326294 | KNN Loss: 3.6241085529327393 | CLS Loss: 0.0037060813046991825\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 3.633706569671631 | KNN Loss: 3.6090800762176514 | CLS Loss: 0.02462652325630188\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 3.60471773147583 | KNN Loss: 3.593533754348755 | CLS Loss: 0.01118398830294609\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 3.662233591079712 | KNN Loss: 3.648183822631836 | CLS Loss: 0.014049653895199299\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 3.6537790298461914 | KNN Loss: 3.6387364864349365 | CLS Loss: 0.015042567625641823\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 3.6138861179351807 | KNN Loss: 3.5974998474121094 | CLS Loss: 0.016386235132813454\n",
      "Epoch: 200, Loss: 3.6283, Train: 0.9975, Valid: 0.9878, Best: 0.9878\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9878, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3806163b0bdd4aaebe3b9e0e5fd73985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91b4d8bad0d47a69bdff9438dacfe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da47c2da464a422bb395020f2a6e4e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d424f9478d54e1fb5d89f3b50fe7edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2244b8fe9bb44eaaf0fd35a0271aae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9780731807592161\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da577ea8afae4518baca087f16b7c265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "Epoch: 00 | Batch: 000 / 042 | Total loss: 1.413 | Reg loss: 0.009 | Tree loss: 1.413 | Accuracy: 0.064453 | 0.308 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 042 | Total loss: 1.185 | Reg loss: 0.004 | Tree loss: 1.185 | Accuracy: 0.794922 | 0.22 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 042 | Total loss: 1.109 | Reg loss: 0.007 | Tree loss: 1.109 | Accuracy: 0.744141 | 0.218 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 042 | Total loss: 1.049 | Reg loss: 0.009 | Tree loss: 1.049 | Accuracy: 0.728516 | 0.217 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 042 | Total loss: 0.921 | Reg loss: 0.010 | Tree loss: 0.921 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 042 | Total loss: 0.830 | Reg loss: 0.012 | Tree loss: 0.830 | Accuracy: 0.820312 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 042 | Total loss: 0.883 | Reg loss: 0.013 | Tree loss: 0.883 | Accuracy: 0.761719 | 0.226 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 042 | Total loss: 0.859 | Reg loss: 0.014 | Tree loss: 0.859 | Accuracy: 0.755859 | 0.225 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 042 | Total loss: 0.820 | Reg loss: 0.015 | Tree loss: 0.820 | Accuracy: 0.773438 | 0.224 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 042 | Total loss: 0.819 | Reg loss: 0.015 | Tree loss: 0.819 | Accuracy: 0.765625 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 042 | Total loss: 0.845 | Reg loss: 0.016 | Tree loss: 0.845 | Accuracy: 0.738281 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 042 | Total loss: 0.747 | Reg loss: 0.017 | Tree loss: 0.747 | Accuracy: 0.789062 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 042 | Total loss: 0.768 | Reg loss: 0.017 | Tree loss: 0.768 | Accuracy: 0.775391 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 042 | Total loss: 0.715 | Reg loss: 0.018 | Tree loss: 0.715 | Accuracy: 0.802734 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 042 | Total loss: 0.735 | Reg loss: 0.018 | Tree loss: 0.735 | Accuracy: 0.779297 | 0.226 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 042 | Total loss: 0.789 | Reg loss: 0.019 | Tree loss: 0.789 | Accuracy: 0.742188 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 042 | Total loss: 0.743 | Reg loss: 0.019 | Tree loss: 0.743 | Accuracy: 0.759766 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 042 | Total loss: 0.734 | Reg loss: 0.019 | Tree loss: 0.734 | Accuracy: 0.761719 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 042 | Total loss: 0.719 | Reg loss: 0.020 | Tree loss: 0.719 | Accuracy: 0.765625 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 042 | Total loss: 0.789 | Reg loss: 0.020 | Tree loss: 0.789 | Accuracy: 0.718750 | 0.226 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 20 | Batch: 000 / 042 | Total loss: 0.750 | Reg loss: 0.020 | Tree loss: 0.750 | Accuracy: 0.746094 | 0.226 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 042 | Total loss: 0.714 | Reg loss: 0.021 | Tree loss: 0.714 | Accuracy: 0.742188 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 042 | Total loss: 0.725 | Reg loss: 0.021 | Tree loss: 0.725 | Accuracy: 0.748047 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Batch: 000 / 042 | Total loss: 0.677 | Reg loss: 0.021 | Tree loss: 0.677 | Accuracy: 0.763672 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 042 | Total loss: 0.688 | Reg loss: 0.021 | Tree loss: 0.688 | Accuracy: 0.759766 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.022 | Tree loss: 0.615 | Accuracy: 0.808594 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 042 | Total loss: 0.690 | Reg loss: 0.022 | Tree loss: 0.690 | Accuracy: 0.781250 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 042 | Total loss: 0.684 | Reg loss: 0.022 | Tree loss: 0.684 | Accuracy: 0.775391 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 042 | Total loss: 0.758 | Reg loss: 0.022 | Tree loss: 0.758 | Accuracy: 0.744141 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 042 | Total loss: 0.651 | Reg loss: 0.022 | Tree loss: 0.651 | Accuracy: 0.781250 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 042 | Total loss: 0.685 | Reg loss: 0.022 | Tree loss: 0.685 | Accuracy: 0.769531 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 042 | Total loss: 0.646 | Reg loss: 0.022 | Tree loss: 0.646 | Accuracy: 0.775391 | 0.227 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 042 | Total loss: 0.670 | Reg loss: 0.023 | Tree loss: 0.670 | Accuracy: 0.765625 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 042 | Total loss: 0.695 | Reg loss: 0.023 | Tree loss: 0.695 | Accuracy: 0.761719 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 042 | Total loss: 0.688 | Reg loss: 0.023 | Tree loss: 0.688 | Accuracy: 0.759766 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 35 | Batch: 000 / 042 | Total loss: 0.706 | Reg loss: 0.023 | Tree loss: 0.706 | Accuracy: 0.757812 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 042 | Total loss: 0.626 | Reg loss: 0.023 | Tree loss: 0.626 | Accuracy: 0.798828 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 042 | Total loss: 0.645 | Reg loss: 0.023 | Tree loss: 0.645 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 042 | Total loss: 0.684 | Reg loss: 0.023 | Tree loss: 0.684 | Accuracy: 0.757812 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 042 | Total loss: 0.712 | Reg loss: 0.023 | Tree loss: 0.712 | Accuracy: 0.742188 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 40 | Batch: 000 / 042 | Total loss: 0.708 | Reg loss: 0.023 | Tree loss: 0.708 | Accuracy: 0.755859 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 042 | Total loss: 0.675 | Reg loss: 0.023 | Tree loss: 0.675 | Accuracy: 0.750000 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 042 | Total loss: 0.650 | Reg loss: 0.024 | Tree loss: 0.650 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 042 | Total loss: 0.621 | Reg loss: 0.024 | Tree loss: 0.621 | Accuracy: 0.783203 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 042 | Total loss: 0.688 | Reg loss: 0.024 | Tree loss: 0.688 | Accuracy: 0.755859 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 042 | Total loss: 0.671 | Reg loss: 0.024 | Tree loss: 0.671 | Accuracy: 0.761719 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Batch: 000 / 042 | Total loss: 0.650 | Reg loss: 0.024 | Tree loss: 0.650 | Accuracy: 0.783203 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 042 | Total loss: 0.607 | Reg loss: 0.024 | Tree loss: 0.607 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 042 | Total loss: 0.627 | Reg loss: 0.024 | Tree loss: 0.627 | Accuracy: 0.802734 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 49 | Batch: 000 / 042 | Total loss: 0.632 | Reg loss: 0.024 | Tree loss: 0.632 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 50 | Batch: 000 / 042 | Total loss: 0.635 | Reg loss: 0.024 | Tree loss: 0.635 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 51 | Batch: 000 / 042 | Total loss: 0.569 | Reg loss: 0.024 | Tree loss: 0.569 | Accuracy: 0.820312 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 52 | Batch: 000 / 042 | Total loss: 0.656 | Reg loss: 0.024 | Tree loss: 0.656 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 53 | Batch: 000 / 042 | Total loss: 0.663 | Reg loss: 0.024 | Tree loss: 0.663 | Accuracy: 0.779297 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 54 | Batch: 000 / 042 | Total loss: 0.653 | Reg loss: 0.024 | Tree loss: 0.653 | Accuracy: 0.783203 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 55 | Batch: 000 / 042 | Total loss: 0.719 | Reg loss: 0.024 | Tree loss: 0.719 | Accuracy: 0.757812 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 56 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.024 | Tree loss: 0.587 | Accuracy: 0.816406 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 57 | Batch: 000 / 042 | Total loss: 0.595 | Reg loss: 0.024 | Tree loss: 0.595 | Accuracy: 0.812500 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 58 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.024 | Tree loss: 0.631 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 59 | Batch: 000 / 042 | Total loss: 0.638 | Reg loss: 0.024 | Tree loss: 0.638 | Accuracy: 0.783203 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 60 | Batch: 000 / 042 | Total loss: 0.535 | Reg loss: 0.024 | Tree loss: 0.535 | Accuracy: 0.826172 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 61 | Batch: 000 / 042 | Total loss: 0.617 | Reg loss: 0.024 | Tree loss: 0.617 | Accuracy: 0.796875 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 62 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.024 | Tree loss: 0.628 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 63 | Batch: 000 / 042 | Total loss: 0.577 | Reg loss: 0.024 | Tree loss: 0.577 | Accuracy: 0.814453 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 64 | Batch: 000 / 042 | Total loss: 0.671 | Reg loss: 0.024 | Tree loss: 0.671 | Accuracy: 0.759766 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 65 | Batch: 000 / 042 | Total loss: 0.647 | Reg loss: 0.024 | Tree loss: 0.647 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 66 | Batch: 000 / 042 | Total loss: 0.630 | Reg loss: 0.025 | Tree loss: 0.630 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 67 | Batch: 000 / 042 | Total loss: 0.684 | Reg loss: 0.025 | Tree loss: 0.684 | Accuracy: 0.755859 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 68 | Batch: 000 / 042 | Total loss: 0.645 | Reg loss: 0.025 | Tree loss: 0.645 | Accuracy: 0.767578 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 70 | Batch: 000 / 042 | Total loss: 0.624 | Reg loss: 0.025 | Tree loss: 0.624 | Accuracy: 0.804688 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 71 | Batch: 000 / 042 | Total loss: 0.652 | Reg loss: 0.025 | Tree loss: 0.652 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 72 | Batch: 000 / 042 | Total loss: 0.662 | Reg loss: 0.025 | Tree loss: 0.662 | Accuracy: 0.767578 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 73 | Batch: 000 / 042 | Total loss: 0.633 | Reg loss: 0.025 | Tree loss: 0.633 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 74 | Batch: 000 / 042 | Total loss: 0.642 | Reg loss: 0.025 | Tree loss: 0.642 | Accuracy: 0.777344 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 75 | Batch: 000 / 042 | Total loss: 0.627 | Reg loss: 0.025 | Tree loss: 0.627 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 76 | Batch: 000 / 042 | Total loss: 0.589 | Reg loss: 0.025 | Tree loss: 0.589 | Accuracy: 0.810547 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 77 | Batch: 000 / 042 | Total loss: 0.608 | Reg loss: 0.025 | Tree loss: 0.608 | Accuracy: 0.800781 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 78 | Batch: 000 / 042 | Total loss: 0.625 | Reg loss: 0.025 | Tree loss: 0.625 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 79 | Batch: 000 / 042 | Total loss: 0.676 | Reg loss: 0.025 | Tree loss: 0.676 | Accuracy: 0.763672 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 80 | Batch: 000 / 042 | Total loss: 0.597 | Reg loss: 0.025 | Tree loss: 0.597 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 81 | Batch: 000 / 042 | Total loss: 0.660 | Reg loss: 0.025 | Tree loss: 0.660 | Accuracy: 0.777344 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 82 | Batch: 000 / 042 | Total loss: 0.655 | Reg loss: 0.025 | Tree loss: 0.655 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 83 | Batch: 000 / 042 | Total loss: 0.639 | Reg loss: 0.025 | Tree loss: 0.639 | Accuracy: 0.798828 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 84 | Batch: 000 / 042 | Total loss: 0.633 | Reg loss: 0.025 | Tree loss: 0.633 | Accuracy: 0.781250 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 85 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.798828 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 86 | Batch: 000 / 042 | Total loss: 0.625 | Reg loss: 0.025 | Tree loss: 0.625 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 87 | Batch: 000 / 042 | Total loss: 0.660 | Reg loss: 0.025 | Tree loss: 0.660 | Accuracy: 0.787109 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 88 | Batch: 000 / 042 | Total loss: 0.674 | Reg loss: 0.025 | Tree loss: 0.674 | Accuracy: 0.775391 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 89 | Batch: 000 / 042 | Total loss: 0.664 | Reg loss: 0.025 | Tree loss: 0.664 | Accuracy: 0.775391 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 90 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.802734 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 91 | Batch: 000 / 042 | Total loss: 0.622 | Reg loss: 0.025 | Tree loss: 0.622 | Accuracy: 0.787109 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9840425531914895\n",
      "Epoch: 92 | Batch: 000 / 042 | Total loss: 0.685 | Reg loss: 0.025 | Tree loss: 0.685 | Accuracy: 0.765625 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 93 | Batch: 000 / 042 | Total loss: 0.626 | Reg loss: 0.025 | Tree loss: 0.626 | Accuracy: 0.787109 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 94 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.798828 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 95 | Batch: 000 / 042 | Total loss: 0.623 | Reg loss: 0.025 | Tree loss: 0.623 | Accuracy: 0.783203 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 96 | Batch: 000 / 042 | Total loss: 0.637 | Reg loss: 0.025 | Tree loss: 0.637 | Accuracy: 0.775391 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 97 | Batch: 000 / 042 | Total loss: 0.679 | Reg loss: 0.025 | Tree loss: 0.679 | Accuracy: 0.771484 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 98 | Batch: 000 / 042 | Total loss: 0.598 | Reg loss: 0.025 | Tree loss: 0.598 | Accuracy: 0.804688 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 99 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.802734 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 100 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.025 | Tree loss: 0.616 | Accuracy: 0.806641 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 101 | Batch: 000 / 042 | Total loss: 0.684 | Reg loss: 0.025 | Tree loss: 0.684 | Accuracy: 0.761719 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 102 | Batch: 000 / 042 | Total loss: 0.639 | Reg loss: 0.025 | Tree loss: 0.639 | Accuracy: 0.791016 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 103 | Batch: 000 / 042 | Total loss: 0.632 | Reg loss: 0.025 | Tree loss: 0.632 | Accuracy: 0.792969 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 104 | Batch: 000 / 042 | Total loss: 0.585 | Reg loss: 0.025 | Tree loss: 0.585 | Accuracy: 0.810547 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 105 | Batch: 000 / 042 | Total loss: 0.670 | Reg loss: 0.025 | Tree loss: 0.670 | Accuracy: 0.769531 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 106 | Batch: 000 / 042 | Total loss: 0.625 | Reg loss: 0.025 | Tree loss: 0.625 | Accuracy: 0.800781 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 107 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 108 | Batch: 000 / 042 | Total loss: 0.610 | Reg loss: 0.025 | Tree loss: 0.610 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 109 | Batch: 000 / 042 | Total loss: 0.607 | Reg loss: 0.025 | Tree loss: 0.607 | Accuracy: 0.808594 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 110 | Batch: 000 / 042 | Total loss: 0.666 | Reg loss: 0.025 | Tree loss: 0.666 | Accuracy: 0.771484 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 111 | Batch: 000 / 042 | Total loss: 0.690 | Reg loss: 0.025 | Tree loss: 0.690 | Accuracy: 0.753906 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 112 | Batch: 000 / 042 | Total loss: 0.667 | Reg loss: 0.025 | Tree loss: 0.667 | Accuracy: 0.767578 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 113 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.798828 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 114 | Batch: 000 / 042 | Total loss: 0.688 | Reg loss: 0.025 | Tree loss: 0.688 | Accuracy: 0.757812 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115 | Batch: 000 / 042 | Total loss: 0.604 | Reg loss: 0.025 | Tree loss: 0.604 | Accuracy: 0.800781 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 116 | Batch: 000 / 042 | Total loss: 0.623 | Reg loss: 0.025 | Tree loss: 0.623 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 117 | Batch: 000 / 042 | Total loss: 0.604 | Reg loss: 0.025 | Tree loss: 0.604 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 118 | Batch: 000 / 042 | Total loss: 0.660 | Reg loss: 0.025 | Tree loss: 0.660 | Accuracy: 0.773438 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 119 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.025 | Tree loss: 0.628 | Accuracy: 0.798828 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 120 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.025 | Tree loss: 0.619 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 121 | Batch: 000 / 042 | Total loss: 0.607 | Reg loss: 0.025 | Tree loss: 0.607 | Accuracy: 0.804688 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 122 | Batch: 000 / 042 | Total loss: 0.617 | Reg loss: 0.025 | Tree loss: 0.617 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 123 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.806641 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 124 | Batch: 000 / 042 | Total loss: 0.618 | Reg loss: 0.025 | Tree loss: 0.618 | Accuracy: 0.806641 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 125 | Batch: 000 / 042 | Total loss: 0.640 | Reg loss: 0.025 | Tree loss: 0.640 | Accuracy: 0.787109 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 126 | Batch: 000 / 042 | Total loss: 0.610 | Reg loss: 0.025 | Tree loss: 0.610 | Accuracy: 0.814453 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 127 | Batch: 000 / 042 | Total loss: 0.624 | Reg loss: 0.025 | Tree loss: 0.624 | Accuracy: 0.781250 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 128 | Batch: 000 / 042 | Total loss: 0.623 | Reg loss: 0.025 | Tree loss: 0.623 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 129 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.025 | Tree loss: 0.631 | Accuracy: 0.789062 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 130 | Batch: 000 / 042 | Total loss: 0.656 | Reg loss: 0.025 | Tree loss: 0.656 | Accuracy: 0.783203 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 131 | Batch: 000 / 042 | Total loss: 0.686 | Reg loss: 0.025 | Tree loss: 0.686 | Accuracy: 0.753906 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 132 | Batch: 000 / 042 | Total loss: 0.589 | Reg loss: 0.025 | Tree loss: 0.589 | Accuracy: 0.802734 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 133 | Batch: 000 / 042 | Total loss: 0.600 | Reg loss: 0.025 | Tree loss: 0.600 | Accuracy: 0.808594 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 134 | Batch: 000 / 042 | Total loss: 0.613 | Reg loss: 0.025 | Tree loss: 0.613 | Accuracy: 0.794922 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 135 | Batch: 000 / 042 | Total loss: 0.650 | Reg loss: 0.025 | Tree loss: 0.650 | Accuracy: 0.789062 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 136 | Batch: 000 / 042 | Total loss: 0.626 | Reg loss: 0.025 | Tree loss: 0.626 | Accuracy: 0.787109 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 137 | Batch: 000 / 042 | Total loss: 0.578 | Reg loss: 0.025 | Tree loss: 0.578 | Accuracy: 0.816406 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 | Batch: 000 / 042 | Total loss: 0.582 | Reg loss: 0.025 | Tree loss: 0.582 | Accuracy: 0.820312 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 139 | Batch: 000 / 042 | Total loss: 0.599 | Reg loss: 0.025 | Tree loss: 0.599 | Accuracy: 0.810547 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 140 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.025 | Tree loss: 0.619 | Accuracy: 0.792969 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 141 | Batch: 000 / 042 | Total loss: 0.665 | Reg loss: 0.025 | Tree loss: 0.665 | Accuracy: 0.761719 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 142 | Batch: 000 / 042 | Total loss: 0.634 | Reg loss: 0.025 | Tree loss: 0.634 | Accuracy: 0.794922 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 143 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.025 | Tree loss: 0.628 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 144 | Batch: 000 / 042 | Total loss: 0.568 | Reg loss: 0.025 | Tree loss: 0.568 | Accuracy: 0.820312 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 145 | Batch: 000 / 042 | Total loss: 0.624 | Reg loss: 0.025 | Tree loss: 0.624 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 146 | Batch: 000 / 042 | Total loss: 0.579 | Reg loss: 0.025 | Tree loss: 0.579 | Accuracy: 0.814453 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 147 | Batch: 000 / 042 | Total loss: 0.623 | Reg loss: 0.025 | Tree loss: 0.623 | Accuracy: 0.785156 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 148 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.025 | Tree loss: 0.616 | Accuracy: 0.802734 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 149 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 150 | Batch: 000 / 042 | Total loss: 0.626 | Reg loss: 0.025 | Tree loss: 0.626 | Accuracy: 0.802734 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 151 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.796875 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 152 | Batch: 000 / 042 | Total loss: 0.708 | Reg loss: 0.025 | Tree loss: 0.708 | Accuracy: 0.742188 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 153 | Batch: 000 / 042 | Total loss: 0.561 | Reg loss: 0.025 | Tree loss: 0.561 | Accuracy: 0.828125 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 154 | Batch: 000 / 042 | Total loss: 0.654 | Reg loss: 0.025 | Tree loss: 0.654 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 155 | Batch: 000 / 042 | Total loss: 0.638 | Reg loss: 0.025 | Tree loss: 0.638 | Accuracy: 0.781250 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 156 | Batch: 000 / 042 | Total loss: 0.709 | Reg loss: 0.025 | Tree loss: 0.709 | Accuracy: 0.748047 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 157 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.025 | Tree loss: 0.603 | Accuracy: 0.796875 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 158 | Batch: 000 / 042 | Total loss: 0.650 | Reg loss: 0.025 | Tree loss: 0.650 | Accuracy: 0.773438 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 159 | Batch: 000 / 042 | Total loss: 0.590 | Reg loss: 0.025 | Tree loss: 0.590 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 160 | Batch: 000 / 042 | Total loss: 0.622 | Reg loss: 0.025 | Tree loss: 0.622 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.025 | Tree loss: 0.587 | Accuracy: 0.816406 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 162 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.025 | Tree loss: 0.619 | Accuracy: 0.806641 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 163 | Batch: 000 / 042 | Total loss: 0.668 | Reg loss: 0.025 | Tree loss: 0.668 | Accuracy: 0.773438 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 164 | Batch: 000 / 042 | Total loss: 0.683 | Reg loss: 0.025 | Tree loss: 0.683 | Accuracy: 0.761719 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 165 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 166 | Batch: 000 / 042 | Total loss: 0.682 | Reg loss: 0.025 | Tree loss: 0.682 | Accuracy: 0.763672 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 167 | Batch: 000 / 042 | Total loss: 0.627 | Reg loss: 0.025 | Tree loss: 0.627 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 168 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 169 | Batch: 000 / 042 | Total loss: 0.663 | Reg loss: 0.025 | Tree loss: 0.663 | Accuracy: 0.763672 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 170 | Batch: 000 / 042 | Total loss: 0.621 | Reg loss: 0.025 | Tree loss: 0.621 | Accuracy: 0.800781 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 171 | Batch: 000 / 042 | Total loss: 0.669 | Reg loss: 0.025 | Tree loss: 0.669 | Accuracy: 0.773438 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 172 | Batch: 000 / 042 | Total loss: 0.613 | Reg loss: 0.025 | Tree loss: 0.613 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 173 | Batch: 000 / 042 | Total loss: 0.691 | Reg loss: 0.025 | Tree loss: 0.691 | Accuracy: 0.755859 | 0.228 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 174 | Batch: 000 / 042 | Total loss: 0.629 | Reg loss: 0.025 | Tree loss: 0.629 | Accuracy: 0.802734 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 175 | Batch: 000 / 042 | Total loss: 0.584 | Reg loss: 0.025 | Tree loss: 0.584 | Accuracy: 0.814453 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 176 | Batch: 000 / 042 | Total loss: 0.608 | Reg loss: 0.025 | Tree loss: 0.608 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 177 | Batch: 000 / 042 | Total loss: 0.610 | Reg loss: 0.025 | Tree loss: 0.610 | Accuracy: 0.804688 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 178 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.804688 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 179 | Batch: 000 / 042 | Total loss: 0.549 | Reg loss: 0.025 | Tree loss: 0.549 | Accuracy: 0.832031 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 180 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.025 | Tree loss: 0.631 | Accuracy: 0.779297 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 181 | Batch: 000 / 042 | Total loss: 0.640 | Reg loss: 0.025 | Tree loss: 0.640 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 182 | Batch: 000 / 042 | Total loss: 0.597 | Reg loss: 0.025 | Tree loss: 0.597 | Accuracy: 0.800781 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 183 | Batch: 000 / 042 | Total loss: 0.627 | Reg loss: 0.025 | Tree loss: 0.627 | Accuracy: 0.781250 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184 | Batch: 000 / 042 | Total loss: 0.578 | Reg loss: 0.025 | Tree loss: 0.578 | Accuracy: 0.802734 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 185 | Batch: 000 / 042 | Total loss: 0.579 | Reg loss: 0.025 | Tree loss: 0.579 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 186 | Batch: 000 / 042 | Total loss: 0.687 | Reg loss: 0.025 | Tree loss: 0.687 | Accuracy: 0.755859 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 187 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.025 | Tree loss: 0.631 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 188 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 189 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 190 | Batch: 000 / 042 | Total loss: 0.636 | Reg loss: 0.025 | Tree loss: 0.636 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 191 | Batch: 000 / 042 | Total loss: 0.655 | Reg loss: 0.025 | Tree loss: 0.655 | Accuracy: 0.777344 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 192 | Batch: 000 / 042 | Total loss: 0.618 | Reg loss: 0.025 | Tree loss: 0.618 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 193 | Batch: 000 / 042 | Total loss: 0.625 | Reg loss: 0.025 | Tree loss: 0.625 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 194 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.025 | Tree loss: 0.587 | Accuracy: 0.816406 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 195 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 196 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.025 | Tree loss: 0.603 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 197 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.025 | Tree loss: 0.603 | Accuracy: 0.814453 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 198 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.804688 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 199 | Batch: 000 / 042 | Total loss: 0.623 | Reg loss: 0.025 | Tree loss: 0.623 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 200 | Batch: 000 / 042 | Total loss: 0.635 | Reg loss: 0.025 | Tree loss: 0.635 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 201 | Batch: 000 / 042 | Total loss: 0.685 | Reg loss: 0.025 | Tree loss: 0.685 | Accuracy: 0.763672 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 202 | Batch: 000 / 042 | Total loss: 0.629 | Reg loss: 0.025 | Tree loss: 0.629 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 203 | Batch: 000 / 042 | Total loss: 0.585 | Reg loss: 0.025 | Tree loss: 0.585 | Accuracy: 0.808594 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 204 | Batch: 000 / 042 | Total loss: 0.652 | Reg loss: 0.025 | Tree loss: 0.652 | Accuracy: 0.779297 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 205 | Batch: 000 / 042 | Total loss: 0.604 | Reg loss: 0.025 | Tree loss: 0.604 | Accuracy: 0.808594 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 206 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.810547 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207 | Batch: 000 / 042 | Total loss: 0.608 | Reg loss: 0.025 | Tree loss: 0.608 | Accuracy: 0.812500 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 208 | Batch: 000 / 042 | Total loss: 0.635 | Reg loss: 0.025 | Tree loss: 0.635 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 209 | Batch: 000 / 042 | Total loss: 0.621 | Reg loss: 0.025 | Tree loss: 0.621 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 210 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.024 | Tree loss: 0.619 | Accuracy: 0.806641 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 211 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.025 | Tree loss: 0.628 | Accuracy: 0.796875 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 212 | Batch: 000 / 042 | Total loss: 0.597 | Reg loss: 0.025 | Tree loss: 0.597 | Accuracy: 0.806641 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 213 | Batch: 000 / 042 | Total loss: 0.672 | Reg loss: 0.025 | Tree loss: 0.672 | Accuracy: 0.765625 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 214 | Batch: 000 / 042 | Total loss: 0.666 | Reg loss: 0.025 | Tree loss: 0.666 | Accuracy: 0.765625 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 215 | Batch: 000 / 042 | Total loss: 0.576 | Reg loss: 0.025 | Tree loss: 0.576 | Accuracy: 0.800781 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 216 | Batch: 000 / 042 | Total loss: 0.626 | Reg loss: 0.025 | Tree loss: 0.626 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 217 | Batch: 000 / 042 | Total loss: 0.629 | Reg loss: 0.025 | Tree loss: 0.629 | Accuracy: 0.787109 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 218 | Batch: 000 / 042 | Total loss: 0.629 | Reg loss: 0.025 | Tree loss: 0.629 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 219 | Batch: 000 / 042 | Total loss: 0.652 | Reg loss: 0.024 | Tree loss: 0.652 | Accuracy: 0.783203 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 220 | Batch: 000 / 042 | Total loss: 0.643 | Reg loss: 0.025 | Tree loss: 0.643 | Accuracy: 0.775391 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 221 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.802734 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 222 | Batch: 000 / 042 | Total loss: 0.643 | Reg loss: 0.025 | Tree loss: 0.643 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 223 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.804688 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 224 | Batch: 000 / 042 | Total loss: 0.591 | Reg loss: 0.025 | Tree loss: 0.591 | Accuracy: 0.802734 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 225 | Batch: 000 / 042 | Total loss: 0.614 | Reg loss: 0.025 | Tree loss: 0.614 | Accuracy: 0.792969 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 226 | Batch: 000 / 042 | Total loss: 0.571 | Reg loss: 0.025 | Tree loss: 0.571 | Accuracy: 0.816406 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 227 | Batch: 000 / 042 | Total loss: 0.585 | Reg loss: 0.025 | Tree loss: 0.585 | Accuracy: 0.820312 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 228 | Batch: 000 / 042 | Total loss: 0.624 | Reg loss: 0.025 | Tree loss: 0.624 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 229 | Batch: 000 / 042 | Total loss: 0.670 | Reg loss: 0.024 | Tree loss: 0.670 | Accuracy: 0.771484 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230 | Batch: 000 / 042 | Total loss: 0.640 | Reg loss: 0.024 | Tree loss: 0.640 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 231 | Batch: 000 / 042 | Total loss: 0.633 | Reg loss: 0.024 | Tree loss: 0.633 | Accuracy: 0.789062 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 232 | Batch: 000 / 042 | Total loss: 0.600 | Reg loss: 0.024 | Tree loss: 0.600 | Accuracy: 0.814453 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 233 | Batch: 000 / 042 | Total loss: 0.583 | Reg loss: 0.024 | Tree loss: 0.583 | Accuracy: 0.814453 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 234 | Batch: 000 / 042 | Total loss: 0.610 | Reg loss: 0.024 | Tree loss: 0.610 | Accuracy: 0.814453 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 235 | Batch: 000 / 042 | Total loss: 0.669 | Reg loss: 0.024 | Tree loss: 0.669 | Accuracy: 0.767578 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 236 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.024 | Tree loss: 0.616 | Accuracy: 0.796875 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 237 | Batch: 000 / 042 | Total loss: 0.633 | Reg loss: 0.024 | Tree loss: 0.633 | Accuracy: 0.785156 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 238 | Batch: 000 / 042 | Total loss: 0.632 | Reg loss: 0.024 | Tree loss: 0.632 | Accuracy: 0.779297 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 239 | Batch: 000 / 042 | Total loss: 0.655 | Reg loss: 0.024 | Tree loss: 0.655 | Accuracy: 0.769531 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 240 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.024 | Tree loss: 0.631 | Accuracy: 0.783203 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 241 | Batch: 000 / 042 | Total loss: 0.634 | Reg loss: 0.024 | Tree loss: 0.634 | Accuracy: 0.791016 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 242 | Batch: 000 / 042 | Total loss: 0.633 | Reg loss: 0.024 | Tree loss: 0.633 | Accuracy: 0.794922 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 243 | Batch: 000 / 042 | Total loss: 0.694 | Reg loss: 0.024 | Tree loss: 0.694 | Accuracy: 0.759766 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 244 | Batch: 000 / 042 | Total loss: 0.600 | Reg loss: 0.024 | Tree loss: 0.600 | Accuracy: 0.812500 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 245 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.024 | Tree loss: 0.612 | Accuracy: 0.808594 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 246 | Batch: 000 / 042 | Total loss: 0.634 | Reg loss: 0.024 | Tree loss: 0.634 | Accuracy: 0.792969 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 247 | Batch: 000 / 042 | Total loss: 0.630 | Reg loss: 0.024 | Tree loss: 0.630 | Accuracy: 0.798828 | 0.229 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 248 | Batch: 000 / 042 | Total loss: 0.665 | Reg loss: 0.024 | Tree loss: 0.665 | Accuracy: 0.759766 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 249 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.024 | Tree loss: 0.628 | Accuracy: 0.785156 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 250 | Batch: 000 / 042 | Total loss: 0.624 | Reg loss: 0.024 | Tree loss: 0.624 | Accuracy: 0.787109 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 251 | Batch: 000 / 042 | Total loss: 0.641 | Reg loss: 0.024 | Tree loss: 0.641 | Accuracy: 0.792969 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 252 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.024 | Tree loss: 0.619 | Accuracy: 0.806641 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 253 | Batch: 000 / 042 | Total loss: 0.625 | Reg loss: 0.025 | Tree loss: 0.625 | Accuracy: 0.794922 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 254 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.024 | Tree loss: 0.619 | Accuracy: 0.792969 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 255 | Batch: 000 / 042 | Total loss: 0.596 | Reg loss: 0.025 | Tree loss: 0.596 | Accuracy: 0.800781 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 256 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.024 | Tree loss: 0.603 | Accuracy: 0.810547 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 257 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.794922 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 258 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.802734 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 259 | Batch: 000 / 042 | Total loss: 0.653 | Reg loss: 0.025 | Tree loss: 0.653 | Accuracy: 0.792969 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 260 | Batch: 000 / 042 | Total loss: 0.578 | Reg loss: 0.025 | Tree loss: 0.578 | Accuracy: 0.822266 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 261 | Batch: 000 / 042 | Total loss: 0.590 | Reg loss: 0.025 | Tree loss: 0.590 | Accuracy: 0.804688 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 262 | Batch: 000 / 042 | Total loss: 0.573 | Reg loss: 0.025 | Tree loss: 0.573 | Accuracy: 0.808594 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 263 | Batch: 000 / 042 | Total loss: 0.637 | Reg loss: 0.025 | Tree loss: 0.637 | Accuracy: 0.792969 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 264 | Batch: 000 / 042 | Total loss: 0.659 | Reg loss: 0.025 | Tree loss: 0.659 | Accuracy: 0.769531 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 265 | Batch: 000 / 042 | Total loss: 0.598 | Reg loss: 0.025 | Tree loss: 0.598 | Accuracy: 0.812500 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 266 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.804688 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 267 | Batch: 000 / 042 | Total loss: 0.561 | Reg loss: 0.025 | Tree loss: 0.561 | Accuracy: 0.830078 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 268 | Batch: 000 / 042 | Total loss: 0.637 | Reg loss: 0.025 | Tree loss: 0.637 | Accuracy: 0.791016 | 0.23 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 269 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.025 | Tree loss: 0.616 | Accuracy: 0.806641 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 270 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.789062 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 271 | Batch: 000 / 042 | Total loss: 0.653 | Reg loss: 0.025 | Tree loss: 0.653 | Accuracy: 0.777344 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 272 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.025 | Tree loss: 0.616 | Accuracy: 0.779297 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 273 | Batch: 000 / 042 | Total loss: 0.607 | Reg loss: 0.025 | Tree loss: 0.607 | Accuracy: 0.814453 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 274 | Batch: 000 / 042 | Total loss: 0.584 | Reg loss: 0.025 | Tree loss: 0.584 | Accuracy: 0.820312 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 275 | Batch: 000 / 042 | Total loss: 0.594 | Reg loss: 0.025 | Tree loss: 0.594 | Accuracy: 0.800781 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 276 | Batch: 000 / 042 | Total loss: 0.641 | Reg loss: 0.025 | Tree loss: 0.641 | Accuracy: 0.789062 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 277 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.025 | Tree loss: 0.631 | Accuracy: 0.787109 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 278 | Batch: 000 / 042 | Total loss: 0.609 | Reg loss: 0.025 | Tree loss: 0.609 | Accuracy: 0.787109 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 279 | Batch: 000 / 042 | Total loss: 0.664 | Reg loss: 0.025 | Tree loss: 0.664 | Accuracy: 0.765625 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 280 | Batch: 000 / 042 | Total loss: 0.612 | Reg loss: 0.025 | Tree loss: 0.612 | Accuracy: 0.800781 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 281 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.798828 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 282 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.025 | Tree loss: 0.616 | Accuracy: 0.792969 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 283 | Batch: 000 / 042 | Total loss: 0.640 | Reg loss: 0.025 | Tree loss: 0.640 | Accuracy: 0.777344 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 284 | Batch: 000 / 042 | Total loss: 0.556 | Reg loss: 0.025 | Tree loss: 0.556 | Accuracy: 0.832031 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 285 | Batch: 000 / 042 | Total loss: 0.657 | Reg loss: 0.025 | Tree loss: 0.657 | Accuracy: 0.789062 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 286 | Batch: 000 / 042 | Total loss: 0.579 | Reg loss: 0.025 | Tree loss: 0.579 | Accuracy: 0.810547 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 287 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.025 | Tree loss: 0.587 | Accuracy: 0.822266 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 288 | Batch: 000 / 042 | Total loss: 0.655 | Reg loss: 0.025 | Tree loss: 0.655 | Accuracy: 0.769531 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 289 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.804688 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 290 | Batch: 000 / 042 | Total loss: 0.586 | Reg loss: 0.025 | Tree loss: 0.586 | Accuracy: 0.814453 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 291 | Batch: 000 / 042 | Total loss: 0.680 | Reg loss: 0.025 | Tree loss: 0.680 | Accuracy: 0.767578 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 292 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.810547 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 293 | Batch: 000 / 042 | Total loss: 0.647 | Reg loss: 0.025 | Tree loss: 0.647 | Accuracy: 0.781250 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 294 | Batch: 000 / 042 | Total loss: 0.584 | Reg loss: 0.025 | Tree loss: 0.584 | Accuracy: 0.814453 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 295 | Batch: 000 / 042 | Total loss: 0.592 | Reg loss: 0.025 | Tree loss: 0.592 | Accuracy: 0.794922 | 0.231 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 296 | Batch: 000 / 042 | Total loss: 0.598 | Reg loss: 0.025 | Tree loss: 0.598 | Accuracy: 0.806641 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 297 | Batch: 000 / 042 | Total loss: 0.644 | Reg loss: 0.025 | Tree loss: 0.644 | Accuracy: 0.781250 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 298 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.025 | Tree loss: 0.619 | Accuracy: 0.802734 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299 | Batch: 000 / 042 | Total loss: 0.524 | Reg loss: 0.025 | Tree loss: 0.524 | Accuracy: 0.841797 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 300 | Batch: 000 / 042 | Total loss: 0.588 | Reg loss: 0.025 | Tree loss: 0.588 | Accuracy: 0.818359 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 301 | Batch: 000 / 042 | Total loss: 0.579 | Reg loss: 0.025 | Tree loss: 0.579 | Accuracy: 0.833984 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 302 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.025 | Tree loss: 0.603 | Accuracy: 0.804688 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 303 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.802734 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 304 | Batch: 000 / 042 | Total loss: 0.663 | Reg loss: 0.025 | Tree loss: 0.663 | Accuracy: 0.787109 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 305 | Batch: 000 / 042 | Total loss: 0.702 | Reg loss: 0.025 | Tree loss: 0.702 | Accuracy: 0.763672 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 306 | Batch: 000 / 042 | Total loss: 0.613 | Reg loss: 0.025 | Tree loss: 0.613 | Accuracy: 0.798828 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 307 | Batch: 000 / 042 | Total loss: 0.604 | Reg loss: 0.025 | Tree loss: 0.604 | Accuracy: 0.798828 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 308 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.796875 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 309 | Batch: 000 / 042 | Total loss: 0.583 | Reg loss: 0.025 | Tree loss: 0.583 | Accuracy: 0.814453 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 310 | Batch: 000 / 042 | Total loss: 0.660 | Reg loss: 0.025 | Tree loss: 0.660 | Accuracy: 0.769531 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 311 | Batch: 000 / 042 | Total loss: 0.649 | Reg loss: 0.025 | Tree loss: 0.649 | Accuracy: 0.779297 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 312 | Batch: 000 / 042 | Total loss: 0.590 | Reg loss: 0.025 | Tree loss: 0.590 | Accuracy: 0.808594 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 313 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.025 | Tree loss: 0.628 | Accuracy: 0.798828 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 314 | Batch: 000 / 042 | Total loss: 0.561 | Reg loss: 0.025 | Tree loss: 0.561 | Accuracy: 0.826172 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 315 | Batch: 000 / 042 | Total loss: 0.656 | Reg loss: 0.025 | Tree loss: 0.656 | Accuracy: 0.775391 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 316 | Batch: 000 / 042 | Total loss: 0.592 | Reg loss: 0.025 | Tree loss: 0.592 | Accuracy: 0.808594 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 317 | Batch: 000 / 042 | Total loss: 0.617 | Reg loss: 0.025 | Tree loss: 0.617 | Accuracy: 0.798828 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 318 | Batch: 000 / 042 | Total loss: 0.621 | Reg loss: 0.025 | Tree loss: 0.621 | Accuracy: 0.787109 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 319 | Batch: 000 / 042 | Total loss: 0.585 | Reg loss: 0.025 | Tree loss: 0.585 | Accuracy: 0.820312 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 320 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.812500 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 321 | Batch: 000 / 042 | Total loss: 0.614 | Reg loss: 0.025 | Tree loss: 0.614 | Accuracy: 0.810547 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 322 | Batch: 000 / 042 | Total loss: 0.621 | Reg loss: 0.025 | Tree loss: 0.621 | Accuracy: 0.785156 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 323 | Batch: 000 / 042 | Total loss: 0.678 | Reg loss: 0.025 | Tree loss: 0.678 | Accuracy: 0.769531 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 324 | Batch: 000 / 042 | Total loss: 0.648 | Reg loss: 0.025 | Tree loss: 0.648 | Accuracy: 0.789062 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 325 | Batch: 000 / 042 | Total loss: 0.548 | Reg loss: 0.025 | Tree loss: 0.548 | Accuracy: 0.837891 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 326 | Batch: 000 / 042 | Total loss: 0.629 | Reg loss: 0.025 | Tree loss: 0.629 | Accuracy: 0.794922 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 327 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.025 | Tree loss: 0.619 | Accuracy: 0.808594 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 328 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.025 | Tree loss: 0.603 | Accuracy: 0.798828 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 329 | Batch: 000 / 042 | Total loss: 0.636 | Reg loss: 0.025 | Tree loss: 0.636 | Accuracy: 0.777344 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 330 | Batch: 000 / 042 | Total loss: 0.576 | Reg loss: 0.025 | Tree loss: 0.576 | Accuracy: 0.839844 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 331 | Batch: 000 / 042 | Total loss: 0.681 | Reg loss: 0.025 | Tree loss: 0.681 | Accuracy: 0.775391 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 332 | Batch: 000 / 042 | Total loss: 0.635 | Reg loss: 0.025 | Tree loss: 0.635 | Accuracy: 0.794922 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 333 | Batch: 000 / 042 | Total loss: 0.609 | Reg loss: 0.025 | Tree loss: 0.609 | Accuracy: 0.794922 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 334 | Batch: 000 / 042 | Total loss: 0.642 | Reg loss: 0.025 | Tree loss: 0.642 | Accuracy: 0.789062 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 335 | Batch: 000 / 042 | Total loss: 0.657 | Reg loss: 0.025 | Tree loss: 0.657 | Accuracy: 0.779297 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 336 | Batch: 000 / 042 | Total loss: 0.665 | Reg loss: 0.025 | Tree loss: 0.665 | Accuracy: 0.769531 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 337 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.025 | Tree loss: 0.587 | Accuracy: 0.820312 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 338 | Batch: 000 / 042 | Total loss: 0.671 | Reg loss: 0.025 | Tree loss: 0.671 | Accuracy: 0.771484 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 339 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.804688 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 340 | Batch: 000 / 042 | Total loss: 0.619 | Reg loss: 0.025 | Tree loss: 0.619 | Accuracy: 0.802734 | 0.232 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 341 | Batch: 000 / 042 | Total loss: 0.604 | Reg loss: 0.025 | Tree loss: 0.604 | Accuracy: 0.802734 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 342 | Batch: 000 / 042 | Total loss: 0.638 | Reg loss: 0.025 | Tree loss: 0.638 | Accuracy: 0.785156 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 343 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.025 | Tree loss: 0.628 | Accuracy: 0.798828 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 344 | Batch: 000 / 042 | Total loss: 0.601 | Reg loss: 0.025 | Tree loss: 0.601 | Accuracy: 0.812500 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9840425531914895\n",
      "Epoch: 345 | Batch: 000 / 042 | Total loss: 0.617 | Reg loss: 0.025 | Tree loss: 0.617 | Accuracy: 0.796875 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 346 | Batch: 000 / 042 | Total loss: 0.571 | Reg loss: 0.025 | Tree loss: 0.571 | Accuracy: 0.826172 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 347 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.025 | Tree loss: 0.587 | Accuracy: 0.820312 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 348 | Batch: 000 / 042 | Total loss: 0.589 | Reg loss: 0.025 | Tree loss: 0.589 | Accuracy: 0.806641 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 349 | Batch: 000 / 042 | Total loss: 0.616 | Reg loss: 0.025 | Tree loss: 0.616 | Accuracy: 0.796875 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 350 | Batch: 000 / 042 | Total loss: 0.573 | Reg loss: 0.025 | Tree loss: 0.573 | Accuracy: 0.818359 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 351 | Batch: 000 / 042 | Total loss: 0.618 | Reg loss: 0.025 | Tree loss: 0.618 | Accuracy: 0.798828 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 352 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.800781 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 353 | Batch: 000 / 042 | Total loss: 0.630 | Reg loss: 0.025 | Tree loss: 0.630 | Accuracy: 0.783203 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 354 | Batch: 000 / 042 | Total loss: 0.668 | Reg loss: 0.025 | Tree loss: 0.668 | Accuracy: 0.777344 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 355 | Batch: 000 / 042 | Total loss: 0.592 | Reg loss: 0.025 | Tree loss: 0.592 | Accuracy: 0.798828 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 356 | Batch: 000 / 042 | Total loss: 0.586 | Reg loss: 0.025 | Tree loss: 0.586 | Accuracy: 0.812500 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 357 | Batch: 000 / 042 | Total loss: 0.594 | Reg loss: 0.025 | Tree loss: 0.594 | Accuracy: 0.796875 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 358 | Batch: 000 / 042 | Total loss: 0.677 | Reg loss: 0.025 | Tree loss: 0.677 | Accuracy: 0.783203 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 359 | Batch: 000 / 042 | Total loss: 0.614 | Reg loss: 0.025 | Tree loss: 0.614 | Accuracy: 0.794922 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 360 | Batch: 000 / 042 | Total loss: 0.627 | Reg loss: 0.025 | Tree loss: 0.627 | Accuracy: 0.789062 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 361 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.796875 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 362 | Batch: 000 / 042 | Total loss: 0.617 | Reg loss: 0.025 | Tree loss: 0.617 | Accuracy: 0.802734 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 363 | Batch: 000 / 042 | Total loss: 0.600 | Reg loss: 0.025 | Tree loss: 0.600 | Accuracy: 0.822266 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 364 | Batch: 000 / 042 | Total loss: 0.647 | Reg loss: 0.025 | Tree loss: 0.647 | Accuracy: 0.791016 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 365 | Batch: 000 / 042 | Total loss: 0.657 | Reg loss: 0.025 | Tree loss: 0.657 | Accuracy: 0.783203 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 366 | Batch: 000 / 042 | Total loss: 0.650 | Reg loss: 0.025 | Tree loss: 0.650 | Accuracy: 0.787109 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 367 | Batch: 000 / 042 | Total loss: 0.592 | Reg loss: 0.025 | Tree loss: 0.592 | Accuracy: 0.818359 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 368 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.791016 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 369 | Batch: 000 / 042 | Total loss: 0.591 | Reg loss: 0.025 | Tree loss: 0.591 | Accuracy: 0.810547 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 370 | Batch: 000 / 042 | Total loss: 0.608 | Reg loss: 0.025 | Tree loss: 0.608 | Accuracy: 0.808594 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 371 | Batch: 000 / 042 | Total loss: 0.587 | Reg loss: 0.025 | Tree loss: 0.587 | Accuracy: 0.816406 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 372 | Batch: 000 / 042 | Total loss: 0.646 | Reg loss: 0.025 | Tree loss: 0.646 | Accuracy: 0.792969 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 373 | Batch: 000 / 042 | Total loss: 0.668 | Reg loss: 0.025 | Tree loss: 0.668 | Accuracy: 0.761719 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 374 | Batch: 000 / 042 | Total loss: 0.615 | Reg loss: 0.025 | Tree loss: 0.615 | Accuracy: 0.794922 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 375 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.781250 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 376 | Batch: 000 / 042 | Total loss: 0.673 | Reg loss: 0.025 | Tree loss: 0.673 | Accuracy: 0.751953 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 377 | Batch: 000 / 042 | Total loss: 0.654 | Reg loss: 0.025 | Tree loss: 0.654 | Accuracy: 0.779297 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 378 | Batch: 000 / 042 | Total loss: 0.627 | Reg loss: 0.025 | Tree loss: 0.627 | Accuracy: 0.806641 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 379 | Batch: 000 / 042 | Total loss: 0.568 | Reg loss: 0.025 | Tree loss: 0.568 | Accuracy: 0.832031 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 380 | Batch: 000 / 042 | Total loss: 0.631 | Reg loss: 0.025 | Tree loss: 0.631 | Accuracy: 0.781250 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 381 | Batch: 000 / 042 | Total loss: 0.669 | Reg loss: 0.025 | Tree loss: 0.669 | Accuracy: 0.763672 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 382 | Batch: 000 / 042 | Total loss: 0.591 | Reg loss: 0.025 | Tree loss: 0.591 | Accuracy: 0.806641 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 383 | Batch: 000 / 042 | Total loss: 0.628 | Reg loss: 0.025 | Tree loss: 0.628 | Accuracy: 0.789062 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 384 | Batch: 000 / 042 | Total loss: 0.651 | Reg loss: 0.025 | Tree loss: 0.651 | Accuracy: 0.785156 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 385 | Batch: 000 / 042 | Total loss: 0.666 | Reg loss: 0.025 | Tree loss: 0.666 | Accuracy: 0.769531 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 386 | Batch: 000 / 042 | Total loss: 0.641 | Reg loss: 0.025 | Tree loss: 0.641 | Accuracy: 0.794922 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 387 | Batch: 000 / 042 | Total loss: 0.630 | Reg loss: 0.025 | Tree loss: 0.630 | Accuracy: 0.802734 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 388 | Batch: 000 / 042 | Total loss: 0.617 | Reg loss: 0.025 | Tree loss: 0.617 | Accuracy: 0.808594 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 389 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.796875 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 390 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.806641 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 391 | Batch: 000 / 042 | Total loss: 0.606 | Reg loss: 0.025 | Tree loss: 0.606 | Accuracy: 0.804688 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 392 | Batch: 000 / 042 | Total loss: 0.640 | Reg loss: 0.025 | Tree loss: 0.640 | Accuracy: 0.791016 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 393 | Batch: 000 / 042 | Total loss: 0.600 | Reg loss: 0.025 | Tree loss: 0.600 | Accuracy: 0.820312 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 394 | Batch: 000 / 042 | Total loss: 0.618 | Reg loss: 0.025 | Tree loss: 0.618 | Accuracy: 0.808594 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 395 | Batch: 000 / 042 | Total loss: 0.605 | Reg loss: 0.025 | Tree loss: 0.605 | Accuracy: 0.802734 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 396 | Batch: 000 / 042 | Total loss: 0.641 | Reg loss: 0.025 | Tree loss: 0.641 | Accuracy: 0.794922 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 397 | Batch: 000 / 042 | Total loss: 0.603 | Reg loss: 0.025 | Tree loss: 0.603 | Accuracy: 0.800781 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 398 | Batch: 000 / 042 | Total loss: 0.572 | Reg loss: 0.025 | Tree loss: 0.572 | Accuracy: 0.824219 | 0.233 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 399 | Batch: 000 / 042 | Total loss: 0.611 | Reg loss: 0.025 | Tree loss: 0.611 | Accuracy: 0.800781 | 0.233 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3061515fa3d432d81a9813264190016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad16ce230ff45c183a8cfe2d16433e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2efcd182094dea81e5a59c21379f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15a2b55753c41b5818b1eebf3f896f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 5.666666666666667\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "============== Pattern 1 ==============\n",
      "507\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "485\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "10797\n",
      "============== Pattern 11 ==============\n",
      "7571\n",
      "============== Pattern 12 ==============\n",
      "10\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "1903\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "============== Pattern 19 ==============\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "Average comprehensibility: 32.666666666666664\n",
      "std comprehensibility: 10.514540197058336\n",
      "var comprehensibility: 110.55555555555556\n",
      "minimum comprehensibility: 12\n",
      "maximum comprehensibility: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    }
   ],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
