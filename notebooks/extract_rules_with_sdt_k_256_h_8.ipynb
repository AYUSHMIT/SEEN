{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from queue import LifoQueue\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import network.cpc\n",
    "from network.cpc import CDCK2\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from utils.ClassificationUtiols import onehot_coding\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn import tree as tt\n",
    "\n",
    "# IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: /home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_256/models/epoch_45.pt\n",
      "sensor names: (18 total)\n",
      "- speed\n",
      "- steering_angle\n",
      "- wheel_speed_0\n",
      "- wheel_speed_1\n",
      "- wheel_speed_2\n",
      "- wheel_speed_3\n",
      "- accelerometer_0\n",
      "- accelerometer_1\n",
      "- accelerometer_2\n",
      "- gyro_0\n",
      "- gyro_1\n",
      "- gyro_2\n",
      "- gyro_bias_0\n",
      "- gyro_bias_1\n",
      "- gyro_bias_2\n",
      "- gyro_uncalibrated_0\n",
      "- gyro_uncalibrated_1\n",
      "- gyro_uncalibrated_2\n",
      "Multihorizon size of the model: 30\n",
      "Test split ratio: 0.2\n",
      "Total number of windows in the dataset (without splitting): 101465\n"
     ]
    }
   ],
   "source": [
    "model_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_256/models/epoch_45.pt'\n",
    "dataset_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_256/data/test_data_protocol_4.file'\n",
    "\n",
    "print(f\"Load the model from: {model_path}\")\n",
    "model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "with open(dataset_path, 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "all_sensors = dataset.dataset.all_signals    \n",
    "print(f\"sensor names: ({len(all_sensors)} total)\")\n",
    "\n",
    "for s in all_sensors:\n",
    "    print(f\"- {s}\")\n",
    "    \n",
    "print(f\"Multihorizon size of the model: {model.timestep}\")\n",
    "print(f\"Test split ratio: {len(dataset) / len(dataset.dataset)}\")\n",
    "print(f\"Total number of windows in the dataset (without splitting): {len(dataset.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2fa4d466af4c3e9714a907cc27be9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20293.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projections = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "device = 'cuda'\n",
    "model = model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(total=len(loader.dataset))\n",
    "    for batch in loader:\n",
    "        hidden = CDCK2.init_hidden(len(batch))\n",
    "        batch = batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        y = model.predict(batch, hidden).detach().cpu()\n",
    "        projections = torch.cat([projections, y.detach().cpu()])\n",
    "        samples = torch.cat([samples, batch.detach().cpu()])\n",
    "        bar.update(y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM and calculate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901a66a023d24e719215be2d96f1837e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "best_score = float('inf')\n",
    "clusters = None\n",
    "range_ = list(range(2, 30))\n",
    "for k in tqdm(range_):\n",
    "    y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "    cur_score = davies_bouldin_score(projections, y)\n",
    "    scores.append(cur_score)\n",
    "    \n",
    "    if cur_score < best_score:\n",
    "        best_score = cur_score\n",
    "        clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('DB Score')\n",
    "plt.plot(range_, scores)\n",
    "best_k = range_[np.argmin(scores)]\n",
    "plt.axvline(best_k, color='r')\n",
    "plt.show()\n",
    "\n",
    "labels = set(clusters)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEWCAYAAAAKFbKeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACKqklEQVR4nO2deZgU1dWH39s9C8MmDPuwKoICgqMCOqiIQUD9NKImuGDQuIwalxhJwC0Rs7hgUJO4MRGNRlwmorgEIkoccRlB0RECyCoIjiiLyD5b3++P29VdXV1VXb3N9Mzc93mgp6uqq29vde4595zfEVJKNBqNRqNpKvgaegAajUaj0aQSbdg0Go1G06TQhk2j0Wg0TQpt2DQajUbTpNCGTaPRaDRNCm3YNBqNRtOk0IZNo3FBCDFKCLElBed5XAjx21SMSaPRuKMNm0ZTD0gpr5FS/gFSZyyD5/o/IcT7QohdQoitQoi/CyHamPbnCiGeFELsDu6/2fL4QiHEUiHE/uBtYSrGpdE0JNqwaZotQoishh5DCjgE+CNQAAwAegD3m/ZPA/oBvYFTgSlCiNMBhBA5wKvAs0B74Gng1eB2jabRog2bptEhhNgohLhVCLFSCPG9EOIpIUQL0/6zhBAVQS/mQyHEEMtjpwohlgH7hBBZsc5nee4CIcQcIcQ2IcSXQogbg9vzhRBbhBBnB++3FkKsE0JMCt7/hxDij0KIVsB8oEAIsTf4ryDoMXUwPc9xwefIdnsvpJTPSSn/I6XcL6X8Hvg7cKLpkEnAH6SU30spVwX3XxbcNwrIAh6SUlZJKf8KCOBHsT8FjSZz0YZN01iZCIwD+gL9gTsAhBDHAk8CVwMdgJnAa0KIXNNjLwL+D2gnpax1O58ZIYQPeB34HOgOjAZuEkKMk1LuBC4H/i6E6Aw8CFRIKZ8xn0NKuQ84A6iUUrYO/qsEyoAJpkMvAV6QUtYEDfRJHt+XkcCK4Hjbozy5z037PwcGBf8eBCyTkbp6y0z7NZpGiTZsmsbKw1LKzUGD8ieUsQK4CpgppVwspayTUj4NVAEnmB771+BjD3g4n5lhQCcp5e+llNVSyg0oD+hCACnlAuBfwEKU4bw6jtfzNMqYIYTwB5//n8HztpNSvh/rBEKIMcClwO+Cm1oHb38wHfYD0Ma037zPul+jaZRow6ZprGw2/b0J5ZmAWkuaHPRydgkhdgE9Tfutj411PjO9USFE87lvA7qYjikBjgKeklLuiOP1vAoMFEIcBowBfpBSLvH6YCHECcBzwE+klGuCm/cGb9uaDm0L7DHtN++z7tdoGiXasGkaKz1Nf/cCKoN/bwb+FPRyjH8tpZTPm463a2nhdD4zm4EvLeduI6U8E0Ke1kzgGeBaIcThDmOPen4p5UGgFBUS/RlBb80LQohjgNeAy6WUC03n/B74BjjadPjRBEOVwdshQghh2j/EtF+jaZRow6ZprFwnhOghhMhHeU0vBrf/HbhGCHG8ULQKpsTHCq85nc/MEmB3MPkkTwjhF0IcJYQYFtx/W/D2cuDPwDNBY2flW6CDEOIQy/ZnUIkdP0ZlKsZECHEU8B/gBinl6zaHPAPcIYRoL4Q4EhWq/UdwXxlQB9wYLAu4Prj9v16eW6PJVLRh0zRWngMWABuC//4IIKX8BHXxfhj4HlhHOAsw7vOZkVLWAWcDhcCXwHbgCeAQIcRxwM3ApOBx96E8s1tszvMF8DywIRjSLAhu/wAIAJ9KKTcaxwczJ092GPdkoBMwy5Rlafa47gTWo8Kr7wL3Syn/E3y+amA8KnNyF8ogjw9u12gaLUI3GtU0NoQQG4ErpZRvZ+L5khzLf4HnpJRPNPRYNJrGSlMoUNVomgTBkOaxwDkNPRaNpjGjQ5EaTQYghHgaeBu4SUqpsxI1miTQoUiNRqPRNCm0x6bRaDSaJkWTWGPr2LGj7NOnT0MPQ6PRaBoVS5cu3S6l7NTQ40g1TcKw9enTh08++aShh6HRaDSNCiHEpoYeQzrQoUiNRqPRNCm0YdNoNBpNk0IbNo1Go9E0KZrEGptGo9FoUsPSpUs7Z2VlPYHqUpGpzk8A+F9tbe2Vxx133HfWndqwaTQajSZEVlbWE127dh3QqVOn730+X0YWOgcCAbFt27aBW7dufQIlGh5Bg1vjoEL6Z0KIN4L384UQbwkh1gZv2zf0GDUajaYZcVSnTp12Z6pRA/D5fLJTp04/oLzK6P31PB47fgmsMt2/BVgopeyH6kQcpY6u0TRLOhSBGKhuNZr04ctko2YQHKOtDWtQwyaE6AH8H6r1h8E5wNPBv59GtdXQaJo3HYpg5w/q750/qPvlFXBPibrVaDQhGtpjewiYgloINOgipfwGIHjb2e6BQohiIcQnQohPtm3blvaBajQNimHUzPdPvQx++1cYfTlMnQHjroSS0gYZnkaTal566aW2ffr0OapXr15H3XbbbV3jeWyDGTYhxFnAd1LKpYk8XkpZIqUcKqUc2qlTk1OE0WgUJaVw/AX2+6qqoS4ABw7C9Fmw4EO4ehpcMkUbOU2jpra2ll/96le95s2bt2bNmjUr5syZk7906dIWXh/fkB7bicCPg00eXwB+JIR4FvhWCNENIHgblcqp0TQLps5QhmrJ8vgeN/uNsJE75jwdqtSkn7fLW3HrA115u7xVKk5XVlbWqnfv3lUDBw6sbtGihTzvvPN2vvTSS+28Pr7BDJuU8lYpZQ8pZR/gQuC/UspLgNeAS4OHXQq82kBD1GgajvIK+PNTyZ+n4gsYOUkbN036eLu8FWdd25/pT3bnrGv7p8K4bd68Oad79+7Vxv0ePXpUf/311zleH9/Qa2x23AuMEUKsBcYE72s0zhhJFEbWYNthjT8UV7YEZCD2cV6orVXnM1NeAdfeBddO00ZPkxwLy9tQU+sjEIDaWh8Ly9ske0q7PqFCCM+ZmhlRoC2lLAPKgn/vAEY35Hg0jYjyCpU8ceBgeNuefSoUt+BDuP2v8NrDUFTYUCNMjFHDoUWLyNeVDHc9Ch3aQfEE9Z6deplaowN4vBRa5MD5Y+HZ6al5PlDPU7ZEvZbG9v5rvDO6aA8PPhOgttZHVlaA0UVJd4Dv1atXhIe2ZcuWnIKCghqvj28SHbSHDh0qdduaZkZJKfzlGVi9Cerq3I8VAn5zOVSsUhfv4gn1M8ZkMQxDh3YqLLk2RR1GcnKgutp+X24O9O0Jv/xZYu9TSSlc/0eoqY3c3q4NtGsLt17VeN7/ZoAQYqmUcqh52+eff77x6KOP3h7Xid4ub8XC8jaMLtrDaUX7kh1XTU0Nhx566OC33357dZ8+fWqOPvroAbNnz94wdOjQiJne559/3vHoo4/uY318RnhsGk1clJSqxAivSKmyBkF5cdCwF9dWx8L+g9CyBez71Pm4osKwpzNnQeoMm5NRA+XFrVyv3t9rpsGYE+HNv0ce4+SJuX0uu/aof8Z+bdyaFqcV7UuFQTPIzs5mxowZX51++un96+rquPjii7dbjZob2rBpGh9zFiT/+DlvwXufwMlDofBIlUnYtyfce3N6w2aGUQN1Kwaqv/NyYXB/uOJ8+4v++WPDRhlg5FBAQsVq2L03PWOVwIIPoM9psPFtta28AkZcHD6mT3fo1Q0GHgalb3o775wF2rBpYnLBBRf8cMEFF/wQ+8hotGHTND6sF/l4WbYGtgYjLQs+UP8Avv4WTpoIj92ZvgvvfodJ54EqldZvpPZbn9+4P2cBFA6Ah/4Z9ryys5Qx3rYTjjgU+veBF+fDpsrUjHlTJXQbCdu/V96vmY1fq3+L4lgKOH9sasal0TiQiVmRGo07xRNg5jTlJbTIAQHkZHt77NgTw0bNjoBUa0TpyBT0es6HnlGGpNWxqtjaoHgCvPmEWq+qMa2j19Sqc6/ZCG9+AONHKw/rw+eCnl0K2LodautUQXiitMhRn5v21jRpRhs2TeOkeAKseAMOVEBgJZQ9DX4PX2fDO3OjLhCdHp8KvJ5z1QZlSPYfVCFSs3EDtbaVbTLkPl/Y6FTXhJ+nqBDefUYZuLtvgilXqJBnLFq39DbOeGmZp42apl7Qhk2TesorIGuwWj9qUVg/z1lUCI/+LjXnys1RxiPVjBoOeZ5VgcK8XqZujdqz6U/ACUOga0fw+yEQCIcI/f7osRcVwq3FcN9kWOih6PsXF8HwweATyhPu2jH+MftsLi1nnBz/eTSaBNCGTZNajOQCIwW/qrr+jNtnq2IfE4ujj4SFT6YngaSoUJ377puUFzVzmrfHtWkdrj17/EWY+1+1prV1e3SpQ+9u6tZJ9b+oUBktN6bPUu+lEMpQvvxXyD/E21h7dFGv7bHfQZZpCX/siamtkdNoXNDJI5rUYhduq3JJL08pSdZkjrVJbU815hR+r3y9FX7xe2/v49pNSkLLMHi9usFtxZEhwMUvgm9QdCKIGaMOrbpGGTprdwErXTvCN4vC94sKVZanLtDWNADaY9OkFqcQnv8olQwhBoJvoFo3SnUvsUnjVfFxIggBo4albixeOONq78dWfOH92NpaZbSkVBmNV0+DcVdFHhNYoeronPD5lLeWkw2VLjrkbVsrz/Ou66NlzIwQqDZqmjj56U9/2ic/P//ofv36DUrk8dqwaVKDodN44kT79ZVAIJzqLlFJEbc9pOSwUmXcigqh7B/hUF88a0M52elZV7OjvAKyB8MPSSsPeWfBB6pbgJl9n4Jcqd4rM36/CiX+4QYVOu3X2/6cuTmw74AynFdPC3cUOPd6989UN0jVxODyyy/f/tprr61N9PE6FKlJHnN3Z8NT8IqRxZeqWb051PdtDFWgKVfA7j2AgEnn1I9nUV4BJ12iDH198/JbKoHESlGhMm7PvApI5fka70VJqZqE2OEUGp37X5j/vkoW6doh8nxWbU+fUGtxA/uq5B/t3TVK3mZTq4V81WY0vfacRu+kFUjOOOOMvatXr04w/KINmyYVxFp/cSOdnpKdfZ1yReKakeOuCquVJLoW98yrDWPUwL1g22ntL1GVl6pqmLtQ/V3yEhzWEzZuUWUJZgJSTW4qvlBJR7rOrdHxNptancUr/Wuo8z3I0sAbnLsmFcYtGXQoUpM8wmZbx/zobcaajgAmnqVChunKQIToUGT+IcpjefMJldhw7g2qELrLSdFhOivjrlLhvANV6ta6ZuWZBhQdr6lV4eJTfqa6cntp65MKlZBAANZtijZqdlyXpuJ4TdpYyFdtaqjzBYBaAr6FfJV025pk0R6bJnl+c0VYZBhUOvnnqyOPyc1xF/xNB98sUoZr6/bIrL3yCjhlUqQC/fRZymtw8sSshd3vLE5sTHv2J/a4VLJoqbp1ku8yY+ybNSf+Tt6JEAikNjStSTuj6bXnQZYGagn4svAFRtOrHheP7dEemyZ57pusQnyH91K3i1+MXn+pt5R/C98sUgkS5lT0siXRbVVAGS87L8auDq9Ngk2CFy9L7HHp4upp0Gaou5dUPEHJdHlRdkkGny99xfGatHEavfe9wblrfsOwrzMhDAkNaNiEEC2EEEuEEJ8LIVYIIe4Kbs8XQrwlhFgbvG3fUGPUxMF9k2Htf9RtW4e0+XNvSC7MNO4qFUoz/ztlEvQ/A/IK1b/co5WX5hZmGzVcCQfb8cu7o7fZGeV7fpXIK4DzxsQ+RtjFdtPI3v1qfcvtsxk1XJVSpHNsPz5VhaYBCs9T3yOrnJgmIzmN3vvu4eStqTJqZ5999qEnnXTSkV9++WVuly5dhjz44INxyd80WKNRIYQAWkkp9wohsoH3gV8C5wE7pZT3CiFuAdpLKae6nUs3Gs0wjFYsTkw8y5sKRbx916y4JSKUV6jw48KPVMdtM70Lwm1aQHlsZuPm90NtEmG5TifB9p3O+w3Fj0BAeTEXnO6cmZhKrrlAdTZwwujDtmsPPPYi7Nmrkn8Kj0xNmLJbJ5jzl+isUa/fF03cpKzRaAORcY1GpbKoRiOp7OA/CZwDjApufxooA1wNmybDaNMq2liYmf0GbPvePbMwWaMG7n2/igrhlb+pv62G2Jo9eLAibNxyc9T9ZNjxvfv+7Gz4222wY1dYtWPkUPuWNV5okaN+WTHDwTEmuebMSWvZQHmF0rB871M17kT4ZltkrzeDVxYmdj5Ns6VBk0eEEH5gKXA48IiUcrEQoouU8hsAKeU3QojODo8tBooBevXqVV9D1hx/AXy6UhXt/uzH9nJJuz9WIshWHUMzxnqWk+FJtpkopLbvV7LGzKBDkXOdnxBw8nH2zU6LJ0S+V+ZknVgcrFZZqlUuXmJOjqo3iwdrJ+1XHg5vv+UB+GiZswEecBj07Oat20JewuVMmmZKgyaPSCnrpJSFQA9guBDiqDgeWyKlHCqlHNqpU6e0jVETZOoM5dksWa7StldtUMohp15mvzZTu1xpL7rhZry8GqXCI5WRbZGj/hlq9PHUQ1mlpdykppLFreZPSnhvKSxf436OCovYc6f2kOU33c9X/8y4hT6zs6DwiNjPC2oyMu5K9X04aaL6Doy4OHL91GiXU1Whwoit8iLPkZMDs/6oPPaJZ8V+zh0/wLXTdBlA/REIBAL1vNAbP8Ex2haFZkS6v5RylxCiDDgd+FYI0S3orXUDXITqNPVCq2OdOz9XVSvvwQjrmXnz7+piNPJn9jVMbsareAKs3xztmYwcqi6G5jBdsnTKjww/Wo2CF7wWb/t97s06pVQh2PWb7VVCILqD+B9/GW3Ec4Z4Hjo1te7duw3M4WFrB/O5C2H+e/DOPyJVRgYdDtcFw4t2yibPTlefaayw8+OlqtD7pGPhYBVccb4u5E4f/9u2bdvATp06/eDz+Rqw8NKZQCAgtm3bdgjwP7v9DZk80gmoCRq1PGABcB9wCrDDlDySL6V0TY3SySNpxKgDi8X4H8GUKyMNTUkp/ObPsHtv9PFeEwKs4a50YF3Pi1f9wijeNnDqEhDvuqHbOEpKlcdrp6BitA6y0qMLbPnW/Tn7dIcv37LfN+7KaINmZfxoNcm5ZEo44SXLD4v+6f75lVfAhJthy1b385tp3VL1jnOaAGhiYpc8snTp0s5ZWVlPAEeRuSVhAeB/tbW1Vx533HFRzk9DGrYhqOQQP+rNK5VS/l4I0QEoBXoBXwE/lVK6xFG0YUsrsTIcrbRtrS5kB6ucvTxQtWWZREmpKkL+8mtliE8Z5l02q+UxSpHEIC8X9n8WfZyTYZh4ljKM2yxJJWNHKJWUeLn2LtW3zcqUK2KvzXVsD9sc1r2SSegZOVSFJ51I5tw6azJh7AxbU6DBrLGUcpmU8hgp5RAp5VFSyt8Ht++QUo6WUvYL3roaNU2aibd78u69ah3Jzaj1LkhuTKnEUJoHFYrbtlOFV+ORzTIbNbv7BoUD7LeXzlfp/VY65Ue3gvGEw2TVS8LJ5ec57yueoLzIsSNiNyu1sn6z+/5kkoWe+7def9NEkBFrbJoM5ptFqlDWLX0/Hqw1YunA8L6qa1QyyVffqHCqANoforLxcoPiy3+brTL3AjbG4N2PEx/D8RcoBRYz7Rwk9GrqwuHe/EPUZOKYAeFQnuHleQ2PThoPT86NryQAVAJJrLCeOTtz4FkqicgLsZJErOuG8SAljLoUyp7WjU01QAOGIlOJDkXWA1NnxJdibqZdG3UxTMdaSHmF6i69diO0zIPv96hGm6mgX29YMz/2cXbhWiHgg9mRF1hryxYnZk5THoz5Qt8yD/Yt9TBo03P96DKV6u8Fu/F6epyHULVPQN2K2McZExJjIpIIfp/KukynuHYTQociNc2b+yarnl1GE8+Z06CPS0gxy6/WVT58Dr5fnD6jNuJiJV6876Bao0qVUQN4+h5vx1kbdYLyIk69THk12YOVB1dUqC64scJ4V08jqmXC/gPqXF4pKoTLxns//pwfpc8QnDbC23HFE5SX+/JfE3+uuoCaODwzN/FzaBo92mPTRDPwLFj9JRxxKKyMIeVUXqEuIiX/Cofz/H54L0YWXCqIJU2VCD4f9OoGt14VX2ZkeYVak3ML2Q4frC7c5RVw8s/cC9gP7wXrvorebk66GXcVvPWhMqJCQLZfeXb7D0CdjDx/dpYKb36yIrofXG5OZJp+PJibzBqMPRHKP4d9+2DoUdEhWS+UV8DonzuvV8bC74P3ntVeWwy0x6ZpHuQMUesmAaluY3kJRYXQqyAsjisEXPWT+rmgpNqogbrob6qEm+6NLyGhqDB2FqVRJ1ZUCGePcj82lliyUWJgTEylhOpapeNYXRttNI1aNaTSZJw5LeyBJ2rUwF4MesEHsHef+g4tXZlYYkdRocos/fA5uGaCKsTv3F7djh+tykt8LjXEdQEVotY0S7THpgnjlCQiBIwZ4XzhNtaOjGSN+lrf8LK+k5MNJxytPJX9B7yf2++HP9wAtxZ7O943yFkqy4zhtRWeB59/Eb3fvNZl9/qmXKHCutYSg0QwzpUodn3t7Bh5HLz7z8Sfx43swd4amGZaeUmGoD02TdPmkinOYTQp3dPfjbWjP9zQ8EatRxd1Ie3RRV24qz5X2ouxEjbM+IQyiF77gomB3owaKK+p20jY7iCEnJfr/v5Nn6U+h5NTcC2aPiu5NPmyJe4qKgYbtng739QZ0O/02N3MzVx5vrfj4q3H1DRqtGHTKF7yUEf0notXXFSovJv6MGrHX+C8r3KbUpjf9r0KWZVXwE33eDc8bVopiSqvBjqRfmFbtzsbtv0Hw8am8Ej7YxZ8ALt2q7Uscwg4J0tloOZk2dfF2VG2JK6hRzBquFqf88W4jFzsIenFyLpd95W69WrcJo1XWZAajQlt2JoiJaXKKzCacfY5LfZjsrNjHzO4f/JjS5bjL3Dv/RUIKCNmaFiOvhw+9tgrrHeB6kwQj4F+vcx+u1ypLvpOuLWQMcoqHv2ds9FYshymXQeBFeq5PpgN066HeTOhapkSoZYrldfqRjLdqg1P/Y83qjU7JwPz+juxz/XyW9H3S0rD32H/IHvvsqgQyv6h1goHHBbP6DVNGL3G1tRwkiaKVRjtpU5NiLBS+9794e1O2ojpwOuaCqj1rKUrnMNlXTvCXdcnJ6bb/3RYa8le9Png/Wft9Rq90LWjysys3Abf/wD7HNYG775JGeHQGme1eu5jBkSLBA88C774UlURSKBjO3j1EbWvbAl0aAefrSJKpDge3DJDRx4Hldvhux0qccYqgWXWlgRlpOyKvz98To2tpBQeekZ9J3/5s/BrNbRF//la5OP1GpstTXWNTRu2pobTWoIAAjF+3HnHKI3HRKgv4xbLYzPIyVHNOm+6VyW1ZPnh+CGq+LdlLvxyUmrU4U+ZBItsvnsjj4NFcRRUx0tuDvz1NqWo/8n/7MWNc3OUgThhCBwzUHVE6NAO/vxktDG2Eq8QtIHXQn6fgPdNBeHXTlMK/rG45gJluK2Tt0TH28zRhi2D0YaN8AzWSeLIi5SVkyq8V+prVhyr48DIoeFmnenqDpBInZXf7167BsoDsftNGtvzcuHS8erifv0fY2ckJooAPnjO+T1z6y4wdQY88A9vnrXhgTkJN1vp0x0650dPbrp2VPJvmrjQhi2DafaGzYsyulejYxiCDu3CPc/mLvQ2C0+lYYtlkKyhK1AX/4v/L/1K716V6PNahLMxjTR/UK/t0lth49fQpQOcNUoZqh27VB2a3XvduyDcM87vV+G8uQuTfimuGC1orHht82NIZC1d6WzQr5kAj02LT93f54suMoewkUyEqTPgb88q775bZzhrZOIh2UZEUzVsWgS5KRBLGX3mNO/nKiqM/jEXFULfnnDP31U2Xm1d5BobqGzCRCmvCDehPGagCq/ZXbTzD4Ed5fbnOPpIeOx36b8QlVd4vwAvfNLeOBcVumtQ9u2pDELlNtUtoX3byEaodXXpN2qgnqO8Ivo9tX7f5iywN2yGYHKWm4RYMKtzxy5ng2UlEIB+vSLDqQL1Xnv9/A3FHIRaEzRPkrZsVWHRmf+C31yu+701QrRhawpYldEH9lUewLad9qEic2PMli1g36exn8Os6m5gFHS3aaWyCROhvEJpKrplCRrs/EGtIQ4fDCvWRe5bt6l+Zte3PODtOMN7tRvT8RfAx/8LK2fUBVTTzEPaKBX8+yar97qkVIUb7Rq1WsnJVt5GqrEzFtbvm1sn9A5F7uHXSeeoW6N0oLpGhVzdDFx2Fjx9LzzynGpZg4QWLbxneJZXwKjLYnc/kFJ5z9NneWuWqskYtGFrChgGx2nNw4y12/P+g9DqWG/GzUqixsyc4HL3TfG3V1myPLpOKxmPMR42OPQV69FF1WvFmt2bk1/qTMsAe/erf8aFNF6qa9QF3+uam98Xu7ja77M3Fl6/b+UV0TqSZqZcETYURumA4eFOeySsg2kgBJx8XHj9tKgQrrs4/jXUsiVQE+ckoLZOrT8b4c4+pykvul0bVWKhDV5G0ZAdtHsCzwBdUW2+S6SUfxFC5AMvAn2AjcAEKaVDNaui2a+xxYOTFFM6Ez9iZTJ6SaqIRbqz4qbOgMdeCAoMmwyCNXxmdHN2WiP0D7Lv/ZZJCFRo99EkQ7v3lMBtD9nvi0fOK9UJQOUVMHJSYp0g7r4JZpZGhoYhcg21EaHX2FJPLTBZSvmpEKINsFQI8RZwGbBQSnmvEOIW4BZgagOOs2lx8tBIjw1UODJdeEnPH3w4VKxWf2dlwVmneFtDMvqWxfJSk8UuhT3brxqEWkNms9+A7l3CDUytvcGystITMkyUFjmqZ1uLXBjSP7r+LRlGDQ/XzRlY0/y9YLfu64SxXrt1O3TtEE4AOf4C+HQlHDtQGaArz/eWhWll1HB7Y71kuaoVjNUNQ1MvNJjyiJTyGynlp8G/9wCrgO7AOcDTwcOeBsY3yACbIiWlgIxUaPC6xpYon3rwBA2jBnDzpSoTT66M3bds/WZ484n01y89Z3OxqnHxMKfPgoMHlWdXXRMpW3XTpNSPLxlqalV5RKqNGiiD8sFz0L2rCmsOH6wajsZj1Mor4NwbYNDZcO717tqWxnrt4y+qidHjpWotrdtIZXhq69Tt8ReotT2X5gBR+ETsrMtVG+CUnyWnv6lJCRkhqSWE6AMcAywGukgpvwFl/IDODo8pFkJ8IoT4ZNu2bfU21kbLuKtUNt+CD8O1blOuSK9RAzVDjoeKVeG/F7+oQnstcu2P/fNT9XMRyUvAozW8lCx/5DrVfZPV+354r9iG2wmfT+lI9uiiygCSoS6gCsyXLFffjxIPRdLxUFQIW/4Ltf+LHaorr1DhS+MzNboHzF0IK9fD3P+qdS4nfc6yJdHecHV1dM3jkuVqXI9Piz3+Pt2D77FQv6GSUvfPbdFSZUy1cWtQGtywCSFaA3OAm6SUu70+TkpZIqUcKqUc2qlTp/QNsCkwdUZ0+BGUZ5GIiG88xLvuYM2we3Y6HPgM2rWNPjYQSE7E1ytff5f4Y38+PnqWf99kWPsflRkZLz6fKmv47GXY/I4quk/UQNoRq3QkXZSUquartz+kvK7yCpj+hH0yzOw37EWSO7SLLchsMHUGfLZS1erl2Uyc8g9RE5DO+Wo9LRBQGcBXT1Oerdt7Xl1dP99LjSMNatiEENkoozZbSvlycPO3Qohuwf3dgCSuKhogWmDWzOw30j+7dAr5jBwaVqcHdSFxCoVlOSwHJyPi65UDcfRxszJpvP32Vsd67zgAKvvumguUBqX1PVr8onrvcjwIWceicEDy54iX8gq49vcqgUiiSj9ueUB5aE6Yv9PjrlKZtldPi0xCcmtEev+TKlQ5d2F0MpUQ8MZjagJiF0qfNUe953Klc41ofXwvNY40mGETQghgFrBKSmkuDnoNuDT496XAq/U9tozHGrKJRaxuzKmcXY67SnXh7lAUDmt172J/7HtLwxd3n08VJttRUpqebtmeiWcxxkR2lvOazP44+sONPRG+XwyP3el8vvsmq95zWTbtavIPUSG18aNje3ft2ngfV6q45YHoJJxPYnizxne6z2n20Qhwzz51m1Rc/H/h99kulF5gWh0pnhD9ng4f7Pw5lVcoXcxr71Lf63h+xxrPNGRW5InAz4DlQoiK4LbbgHuBUiHEFcBXwE8bZngZirkOzdxt2Q0jrdpOvy83J3WzS/PYdv4QVugofdBeg9J8cQkE1PGPPQ+Pmi7g5RVwzV3Oz/nM3PTXECVaEnPq8c77nDQhrcTb5frYgdFZqL/+eWQncCehYut6oBeSTcUvKbUXkY5l+O+brL5v1rR7L+Rkq9+BYUyzs2DC6bB4mTKY5vd78Ysq29FYl87Oim4FtPhFNZb3PlFZx26d5t0Kw73ouWo8obUiMxVD1HjTN0pvUAh7NYZ+vd3lmewwywlNOid1hsGuRm7sCJW5eO717qElK0Y9mFstFKjw3GN3JjRczyRae5aVBY/c4ayjaJbm6tpReVbHDIAPPlWtan5+XmJyTuYLcV4L+6apU2cEZaQEVFfBgL7hwmevGO1yDh5U5zn5ODjhaGXoCjpHFmA74bVbg5mcbPjb7d6lzax07RiZUOJlgpiKWrpjzo3MALbD51MTkXqS8WqqdWzasKWS8goVVtmw2ZsKBUSqpLup8zuRmwMHKxIZbeppdWz0TNsonE62c4ATAw5TKfTpTPk/5WeJt6ARwllv0E0hP1nS1dXAzD0lKtnD6RLiRYbKqe2PGx8+B9MejpT1iod2bZTYtBlDjNmNZN5TO9Fur/TooqIeafgctWHLYDLCsNl9cTu1V80c3Vp/JDrrNKjPJp+xsOsFZ1Y0SebHHYt0Ko+UV6iMvWTUUcwhxfowOumgvALOuQ62BYWABhwGX2xwNmwAfQrguT87v06vfdgMsvxQszzx344QcPKx0ROVkUPh3Weijy8phb/8U3nQld+pqIm16N4Lhwz3pvnpRjLdCxxoqoatwdP9mwShsI6Fbd/DyZc4Lw5f94fknjeTjJoXnp2uLiDpIJ1p6kWF8N4/1aw+UabPUt+DqTOU53rbQ3DixamvG0sXhsdtGDVQ0YVY8+KNlepxTq9z0vho3U83Du2hbhOZxAhUTeS9k6GrpUToYFU4saP98WqSZmRarlyv1vJqau2L7t0YdxX4BiZv1AAuvSX5czQTtGFLBW4XpzqXWisvjRjt8PuVJ9SYjJrBvTd7rzWyktfCvuYI3BXmDfqcFr5gdRsZ33MXFapQVeER8T3OzISbI5M2JHDNtOSy4swZsiWlMO7K9BjLRISZzVw9zf51GpMGL++rT8DT94TvW7MRBxym1lyvmaA8+GsuUIXsRlKrzw8P3aKe867rIh87arhK7Hi8NDpMaaWuLvYxEE6mSlVQbO1X6rvbeqh9HZ8mhFb3T5apM9y/5E4K6ZCY+G+6JbCSoVtH+GZ75H0rRYVqcTzeC2XvAritGAb3VwkL1TUqrNS/t/o3uH/0Y8y6gfMWRapSbN2uyhKql8U3jkfvhBMnJpYpuWVr9DZJfH3EzDhlNxprT6kMzVamoJx0+iz7xqVFhfDZK+E1x8IBQQ9HhusAjea3ZUtg+Rr4xe/DYtR+Pxw3MLKRa9mSYEscCRVfqO11daooGyI7FHTKh6dejq/LxPRZqjzF7T1+L03LI/v2hz933SvOFr3GlgyxEiJiZVvFu04w4DAlsmp0Jm6RG+69ZnS7TjTl2ksLkljrQl47KxvHPvQMbNjirRebQZYffnQCHNYdVm6A9z8Nr3v87TaYvwgWL4cf9nirFUsknGuoYlSsBiRs3xXdeDUeElkfjPXdMbJRU0Uq1oO9lqfYPfeNd7t/Tz58TvVn+9eb4QlMTg6ceXKkoLY1i9ZpcuCFWIr+1hZRqaZTe/guufM31TU27bElQ6w4u7nQ0w7jYjZrjkqPPuNk+GwVPD03nDbfrRMcPximXKnOZc08dMsoa5kHD051v2iaL1gLPlTCwtZZoJHWbadWb/d6vGT6GY1LQynjwdcrcE+tr62zv1hUV6t6t3gnags+iF+VvagQXnk4clsyF7Gb7lUep5cLvjEJWb3R/Tgvodl4KJ6gvhv3P5l4XZ+U7t7pJVPghXlqojJsMDx0q1pXMnfKdsLOi66uBmS4gWlOdrixKajv3v1PJvZaAApcpPyMbgItW9hPsKxdDxKhVV6SJ2i6aI8tGdw8NqfZXDIp3i0K4/NuDNw8gkFnq8Vx6/GD+6uZ7JqNgIQvNqoLjt8Pf7ghsuA3WazeoLkOq74wvOFYlJQq1Qir8c0/RIXP7NZNW+bCfpseeAax3lPDQ1zwoTcv1O+H2uXhx5q/o7k58NfbEg9TGp/VV9/E3/bF51OSYHaGLV3ezTVBJX+7aEOsGslYOGUpWmvz7BrAjh0Bn36RnKJOCjKBm6rHpg1bsjiFaNq2hh+WeDsW7H8k5gv+3IWJh0ycwlJO4xGohXbr+p/Ppy6M8aY6J8LUGUq9364oPR34hGqp4kYi4Tgh4JDW9uuweS3CnoTTe5pIU0whILDCfeKV7EWxvAJOusT75+MTKgRofU5DLCCelP94cEuRT6a20i0M6T8q9vtSeCR8/kViXlubVvDn36RkDbWpGjYdikwWI0RjNTp790Uf+5BNnYyBue28kfTw5CtQV6vCf62TCTsIGHSW8hp6dVX3t38PX26xP1xin9Ry2gkw7fr6qb26b7L6F69iSaIccWjsYxIpKfhgdvSkxGx4Yq1bli2Jv9PzsKPCj3VizoLkLoxFharLQKzw78ihah3YTuGmpBSu+2Ninay90Kk9XPwblUlrV8RfVKgUbuKtrXQzalNneDP2RkKLGznZavJTWwMFXWD0CalVCmrCaMOWCu6bDC/Oj9StG3pU9HFmJXs7Rlysfmgvv63WnIwLRnUN+FsnPj5ziGfj14mf5/yxqf9RlZTCb/4cWefj98Gjv1MXoilXwrz3oabGWVYsWVq28BaGLBzgXe1i/OiwpJTxnr38VqQWYazO0F5CskIoT9qYiJgvum66j6lYgzMMxfV/tG8v06a1fdEzKKN+fRxGrWtHlRBklWxzY9v34bo7w9O2GrdnpyuR7n+8Aj/sjQ71G9m4s+aoNTVjrduOZBJRBNCrALbtVMbs5OO8SZJpbNF1bKnC6IuV5Xee0f3yZ7HPM/sNpQ1pGDUh1Mytf5+UDjdufEJlXqYSI7RnLV6tCwoidxupLhR/uw3+9EsYOijx57JTvTc4qp+3c8SjfL//QORFyejB5jU924tR8/vh8TvVeppcqf6Zv3dFhZHd0gFyslKr0lI8QRkvu64Boy0i0Oaau7Il9sbQia3b4zNqdjh53PdNhm/fV9J0U64IF4wbosTFE9T7+srD7oYmGVWd3t3VxHj/QfU7m7tQTXSzBqvfQWMp5M8QHD02IcRg4O9Ad2A+MFVK+X1w3xIppW44ZCVWU02nsKUT2VlwxXmqlueZV+PX1EslAQllH6c2aSRWaG/rdvUDN9K1e3SNfU5ztllersqua5HrnphgbkPixqjh0YkALXLU5MN60V3wobogfbPI27nNlFe4G7UBh8HPfhy7vOP4C6LPU13r7L0kSlFhdOdqiFTBN2fWItwnGunCi5dqhMAToW9P+Ppbb8e2zFOTHwOncpG6OvU7SPVn1sRx89geA6YBg4E1wPtCiL7BfSnoaNhMuW+yWkvLaxH72LoAfLoqfGGPR7EjwRZiriz4QF0sU9VDKt5w2Jat6nXlt4vcPrAvjP+Rel8DK8Pey/7PlDfh1tvLJ6LbkDhRVAgP36FU+30+dTvkCJWW3t3G6G7dDm2HeXxxQcorVOq6GzdNUhMMJ6M28CzVkcBNNf/qaSp0dk+J8grEQFWwnijbv4+83zk/cnxlS5RRqwuoi3Ui2b1uxOoz17VjeoSmzaovn1iSj9yWHrL8ynMeO0LdXn5e7Oe78e7Ex9rMcFtjay2l/E/w7z8LIZYC/xFC/IzUicQ0T4oKlbRPrAy7QEBdnIwLVG4ODDg0svWF36+UNzrlw/ot8HVQ3cLuE/L5VIgzViZsp/bwx1/aj2/JcvUDTkV2pHGhsa6xuSGBX1+mvBWvQsJnnGwfJvL5VAJEPK+heEKwFOIJldRi/nzs2LNPXfS8XlTLlrh/Pk5dxo0ykmVrIluyuGGNHNTUJqbGAqqbhfl8l50buX/UcJUEdSCOBqugDMCxA1V7phf/E+yybfP+VNeo76STwfT6nnjF7IEKn/1aoc+nxm83pt174eb74AFLnensN6Cqxr4MoKpaTUIe/a323GLg5gIIIcQhxh0p5TvA+cA/gd7pHliTpzioZ9fVRnbKiapqmHCG8kyuuUAlKJx9isroy28bNmp2CNQP//E71SzRzaM7f4waX5tW9vsDcQrBulE8QZVFGF7WxLNU6NAJIcLGzM1rMfPsdHXetq3VBXL8aKUn+P6ziV0gigrj64D9l396P9Yt4WP44HCYrKRUec+dT1Lp5VdPU+HPZC/g8ax7mblvsjK6h/eyb45aVKgmQvFSF4BjB6jPcNEzcM6P7I9b9xUc1kN1CnfSE+1zWvzP74TZA3VKgInlme47EPacyyvUGu6/HoRt7ytFHKdzXj0tOe+6GeBYxyaEuBjYIKX8yLK9F/BbKeVVST+5EE8CZwHfSSmPCm7LB14E+gAbgQnG2p4TGdG2JhmMxfQO7ZSW3dYdaj1r1+7oY3OylVHxCW/NL1vkqpTrUcPCBqG8Ak69zPlHl52lQnhFhSqUtsdSulAf9WxTZ8CMf0SWHQihDHMmzFbjqWnzWvztdm5zd+VUyFuB+hztskzNrYZSjV1ro3hokQMHEwxjClSoOhUYpQrG+5eqbF3jt1e2BG7/i7v3noJejM2ujk1K+ZzD9q+ApI1akH8ADwPmnOBbgIVSynuFELcE709N0fNlJnZp304XL2OR3otRc2o1X1QI7/xDJaTYqUfU1Ialj3Z/rLaZjW8yupROlJTCr/8MeywhybwWKmxrPCeoxp8btoSbuZr7vDm95lRjGNdbH4SdP7gfe/ap8Z97cP9w09pThsGgw9VnUFSYuhY9j/0ObronMvEl/xDn41PBh8/FLoo2Jm92JGrUQKXTp4LyCiWD5hQWBRUZWLsp/nPX1KqQ7pQr1KS0qtrZaFZVh78TmggaXHlECNEHeMPksa0GRkkpvxFCdAPKpJSuPS0a1GMzlBNWblC1Z6OGq5BCvBd+u2LdeGe3WVnQtQN8t1Odx4u4r11auU/A+wmI1SZKLA/k7ptU2NGu4afdRbC+jBt4857Gj7ZXtXeivAJ+cRd88SVk5wSL/aX6u+wfSt0+FR7b+NGqjMS8NjbxLBX2sxtTqpqjGuf667P2odPO+eo7HAufD/r2gHPHxM40zj8EdpQnNNwo7imBO/4Se3I55QoVho43UcYoFzK/504RlqOPhIqX4zu/iWbnsTUgXaSU3wAEjZttLrYQohgoBujVq1c9Ds9En9Mii7IhnEhgDufFwsiEkzJSAV0I74KzI49TDRTjveisfEOlpZsvML++vH5ngbE8EMNTK1sSrYhiN7O3fibJMHVGdGG1GcNzu7vE+XkXf+79+awyT2YPpboaTpoI2SlKSn71v2GVEoPZb6iCZfNr9SqC7RUjQtGhXbSBnniWen4vJTFm3cmvv41MEJpyhdI5rfwO2rWFlevUeuSO76MNUo+uUPqA99c0ariSnAvEWI80S8L5fMq4WrNH7SjoFPbEjDH99Tb7yUwiXmEzIGb+uBAiahXTblt9I6UskVIOlVIO7dTJRWU71Rgpvh2K3C+gRkjBC2OuDBswKeGnN6u/AzG0C0Glvs+cBu/+M/GLzTeLIlOP67vHk1vaf5tW4dc1anhs9ZZUcskU9Rmu+0rdOjV3LJ6gPESnsR2Mo7D40lvd9wek/cw9O4G6MCnhY5uMzumzIguCzYkSqUoagnACVZ/uKhN3yhXKWzQSUdzo2jHy+/7s9Ojv8P6DaqK54APY8q1S9bDzsrZsVZMJryUsRYXwyB2xy2/MIcRAAE46Nva5fT6VbTviYhWx6XSSGlfxBGX0rfRvoEl9huOlMMouhhJHXCVuvg2GIAnefpfG54qPklIlSHvbQ7HXVcBbc8apM1TjQDPfmB4nV4Z/sFOuUNl8h/dWF/yJZ8GOD1OTTFE8QQklN0RihnGBa2ORDcs/JLzGB+qC8vidpI3yCuh/hso4yx4cXSIQS1nC6v0Y2DVBdeKrb7wfa8aujs4LTgEBsxdtpOr7/Sr0a3jQ5jquRCmeAF++pfqKmSdU901W3327Nb/eBfaF78Z3eM5b4BsUf7eAeAx2cTCrNjfH+2OmXKHqLd2wrqdt36mMXEmpMt5mg+/zqca3mijclEeKgBFAJyHEzaZdbYF0yga8BlwK3Bu8fTWNz+WdktL4+32NGq5++G7rEi+/Fb3N2ufJ2ufssWnex+CFS6bA8/PUj8on1CL7hNPVWuGuPVCxCjZvDa/FdWoPrz6S2nCl0Z/Ny3FGYsWq9XBIW1iXgnCMORzsxNffutekLX4xumWJzwervlT1R+Yuz06cMiy+C3J2FvzqUvV3ojqFdpi96KJCOO801cTzwEE4+RK1nmv1HLP8cMEZ0Wt05RXq81q2WoUFb73K+wRqR3ns9b1LpsAL81WYOpk+Z26lFnYsX+N9/axlCzV2Q/s0nm7doK49g/srgz9+dOrWO5sobun+pwCjgGuAx0279gCvSynXJv3kQjwffI6OwLfAncBcoBToBXwF/FRK6bqSnLbkEXNTx0TWbbKzVH8uIeDXP1dfSuuPNJZw6sxpqiu0WeF+YF+lO5mMd2XOJEwEAXzwXGb8sHKGRNZfJZIG7bU3V1aWqqeK9bqd2rHE6roM8SUNGe12rOP327Qd8kp2VmSRdiLivkYSil3CD6gL/YEqNf7B/ZXodSLfpWS/x9bxxsO4K72LYpvfj2dehYXl3hqomjGSqFJIs0sekVK+C7wrhPiHlDItK5RSyoscdo1Ox/N5oqRUKXlXblOx92QwLrZShi8Mf5utZnl+n/KKtu1UxZgr10HHdpGqImC/YLxyfXj74P4w4VfwzTaV4eZFQzAVFwOJezfk+qR6WbgJa6K1Pcb6XSyPPBDw9rqLCu1DW5/GqKNyWsdzHI9USUzP/1mVRlRVKy/xkTtiZ05mZdkXF59qES+2iyrEYvYbMP89NaGzM7BGgXudVC1czG2b4uH1svjHBirE2aubUv+feJZ91/hYXtH5Y70ZtuGDw0Zt9OXuKfxOCOL3KJsxXrIic4UQJaiC6dDxUsoYweJGgvEFXrEO3vzAW9ZSotw/CwhePAOBSOMyc5qq1bIaNjdmzVGL/8a1eNUGNWvPa+Geufbi/ERGH0mm/dCSLFSlqFBlo156q2rtI4Tyts0XIKMw3evrtjvuWJM3ZnfxTMSIbKqER55Tn7n5fE6G7fBe8JvL1aSobAnc+XCkx7thc+Tx53lIp7dj5w9w16Pejx/9c5VIIoBf2vRPs6NNa+9ybGYCAfjMIU3eOvFzMrjmJYLCASp0b9R5GiH888eGjzOScBIp5n58WmZMIhsJMevYhBCfo0KRS4HQ1EtKuTS9Q/NOwqHI8go48eLMUb6MVbzaumWkCvjRwS68dvToAr+91v7iEKvDb5/u9b/GlukkWsdVXgETblYetXmNzSmF3hr2G3sivLM4ttRVTjZUWcoK7MpRjEnPtEfUedu0Ur0Dzet6dpJYqfDy83IhLw927vJ2fI8uUPpg7A4GblqdTrRpFZmYZDDuqug1ziw/1CTwHFasHpsQ6l/PrlAbsJfEa9cG5s2Mfg/M3xOn1+KBphqK9GLYlkopj6un8SREwoatx4/c9RWTIZHiTLnSXsLK4JoL4JgB4SSSWXNi/6jtem/Z/XhzspVqfH2n+jdX7imB3/5VpdD7/fCHG8LrJ9bauZJSuPb37pMRJ7moPqfBV5XQpSPceIkyzNMeif78x56oPDWnej0IKm7cE/2d8/lUKnustkpCwJgRSjZum8fIiM8XWa9mJVF5sc75qgebwSVT4IV56vOwI1UyY7EUfAzBBCMpyO6zsFvzTNC4NWfDNg2Vcv8KECrIiZXQUZ8kbNiS1a1zwqwccNoVkX2X3DB+PC2PsW+qaA2JWH/UVo8OVJnAm09En2vcVfDeJ3DyUG8KJZrUEvLYatSkIlbRcyzjZk34cHteu6iA0/fEadxV1cpQnT1KdU/4bKUybCtjNEdNBGvShF0C1qPPq3rBnGzIzVZRmP0HofBIJaL8xruqls3AbAhieaNCeKsptRtbOuh3uqqttJKA8W3Ohu1Lm81SSnmYzfYGoV4Mm9+nFAq8ZEeav2BOF5KosZh+PHaZZMbMde5CePJlZcRuDUp2Gh7c4P6qzs6cEOCmqmBkfZrXATT1R7wXwfIKOPta2GFTQ9mjC2x+x/2xz8yFp+baRxHi6aodIdq9Cp6Y46xwnwrMEzqzgLdAhXGtr8f6WsorVIKV2bBBWHrNSDxyYvyPVPdsN6yTzFjr3MnglKWqDVuIBteKTAVpM2xCwNUTYNI5QYkrD4bQbqH53BvCzUKdaNMadpuy6Mor4OJfw8agIXUK91h/xHZhRlAK87P+CJfeYp9mXHhk4inXzYgSljGHNZxPf4qp59YhU2fAc29EX6DBvYygvAJGXeZcO5VIGMvw3A5WxVfbmQjmNb9r77IX7rZi/A6nzoD7n3Qeo1wJbYfCnv32+72Udzh5fGlIzw9hdy3Shi2EF0mtlkKIO4KZkQgh+gkhbLRdGiFuqgGd2qssuceClf1tXD77nGylBuKUPXXGybHHsmdvpIyR0W/MIBCAj2w0B629vuyOARW3H3Gxc+1MxRdwyqTUdMZuopSwjKt5iwVs4mreYio26hfJYCiftChUExQzxizdzqgBXHG+evy1d8G10yI/x2fmRho1s/RX146JJR4YGX71MTG+/0nTb8Pj85UtCb9nscZ4raXqaMBh6rd8902xjVpJqXMYs76zhuMtFWnCeJHUegqoRqmQAGwB/pi2EdUnTk0+hw9WEj9G77JTJkWvXRm0ba2SLtbOt/8BlFeovk1esIoB/+IPkfftBH+tP9rDunt7LjuMdjWNlHG8REv+wjheSsv5ryeyY8B0PqacOAv3yyuUB3/8BZETmZLS4MRjkwqLLfhAHWNIVj3louBeeKS6PfUy5c08Xqo8tJBxs2hYDjtKXbjlSntpKmOc105ThtJusmPIbMXSS0wFUsL1f1TjmDReJdvEokM77yUK1iapK9/w3sjWTcC7vqMfjz5fv8+XwXj5VvaVUk4HagCklAdw77/ceLjNIUww3lQfPn2We6r17r3qmNxC+xlT2RLv6w9mGaO2w7wpR1i7XCejHZed1fC1abEuqA6M4yUWsIkD1LKATQhmxG90YlBj4y2UsdnmSAeMSdLchSqz8OppyqAZnpaVJctVXeLJP4MfXGq1Kr5QkkvmdaIak1jxpHNUdEIIpfSxZLkyollH2X9njdDl46XKUJ56WfRnYXTEPu0Ezy8/KWpqVWnOtEfgvX+q36hb9/nHXoh9TrPnet9kWPuf+LOCnQS809msFew7bMfbHqcJ48WwVQsh8gjGAIQQfTFlRzZqiifYz/7MF3cvQsagwjLTZ6l4u/VcXme1Zg/NKeXfijU7qqhQzcYLj4ycfvTo4n6egX29t9lJgqksoh+z7MN41gvqiIs9h1fe4+uobSN4noE8ldyATXSlZfiOVP9GzV3j3RCXLYmeJD0U7Jbs1turrs658WZoPJbHZ5vEiosK4a+3UXLj0Yz791hKrgy2N6wL2HctMMKMBlXVcN6NkHeManE0dYbyJOcuVHWOftP3OzdHRTzSgUR5stMeUf3tvlmkvusjbZYJ1m6Mfb7eBcmPyRDwHj5YGVvDE043b/5dTUTNdGiX/udtJHi54t4J/AfoKYSYDSwEprg/pBFRuzy81ub3Ra+TXXF+fOeb/UbkBa6oUHUq9kJdXfTaihnrFxns1++KCpWqQmCl+pHJlarQ1e7xQqgMrif+kHajdgnzmM7HrGMX0/k42riZLqjlJ3TmnluGUL7odRW6i2E0TsY+BLuKnRzP7FQMn2+4Vhm3AIjaWkQgwKljv2Zqrw3Ono0ZO2949Zepa8fj96mL6zUTVEPSokLKqeSe+TOYuvMNrn7wWBaM687VJSeGjRtEq53s2hN97q3bVaLI1u3KGN72kLpdsjyy9qtT+/R7/Qs/Cr/PRYVqQmY1bv36xD7PrS6/tXgonqASd175W/2GHx++I/L+XdfX33NnOJ6yIoUQHYATUD7AR1JKm7a3DUfaO2jHWwRqlw3llK1oJS8X9n9mrxohVwbDVr9XxbQ/PjU+4dbyCnUxWv0lHHGoMop2RaJpoJxKRhC5BtCd1mzh6sjxjbiYqXcP5c+/GYxxuWy3u5riWesYf/pllA1uwSh6UkT0bFvg7N2Npy9TGG77uD6UsInwxVwSGY4qp5IyNjOKnkzjQxbUbgJ/5O9m7Pwt7MrPpaB9N/ofcSwVfGefOemUzeZWmG/GKOx1IjcH3vlHyKiNrnqOar9ECgj4REgPc+ybX/PmGW+qx1iVRuIR97XD51MakW+UKV3TdOD3w6O/DWcEm0tk/H4VrrQrs8k/BIYOajolLkmW7DTVrEivhq070JtIrcgUp4QlTtoNG0TXjkw8SxkqOwUFp+xIQ1XAjbEnhgumDdWIXsF6m0bMPSzmNt6P2DaS7rzLhYAyHtNZwqKdq9jZPtgh2iJK7JOCgA+yECziwggjZaThv80mHEqYycbHu1wQ8bhWPMR+otcyDeNmZ5BVUF6GvayI35CICAEPIJ+bOC5s4OwMW7u20K1j7O8GqBBzhYOMmsH40fDK37hnyRPccez3BLJ8iDqJNMVnZhZ/QPGTa1S3dOu6UqJqHmaMyV0inQG8Yhgwc42bURcI0YbNTnasmdNUDVtMEWQhxH3ABcAKCF0zJKQ61znDMX78ZqkjsPesRlys5K+M+jeDlW9EyyWZH282atDojZmZUfQkBz/VQSPiA/7HdrJ5gDpkOC2jfQ4hoyEjjUcg+Gctkmt5mwomAeE0fIM2ZLOH6DWpGgLcwiIq2cd59ONr9toaNTNnMid6owj9Z9kevW0VO0NjK2aIfQeBXbvVP1QItmxUV0aVKak34++ij4JrvZ97EMmeuxDGXUWHMw4hMKwrSGXUJv5zHds653H+nI0UP7Hauc7KmPnPmqN6A54xEv78ZHxtVlasU7f3TYa+PYPn6qyiBDfenZpEB2unhaLC8N/XTos+vuzp5J9T0yjwojyyGhgipczYhJF68diciBW2ycmOXPj30o+riVJOJc+wgjmsZRsxZMaMr6Uw3bfYjSkMox25zGUdSwhrfo6lN5+wlZ2WHCcfOHpz0U8/Ofj0qakNGk5XFjPRNSRdXtSZU8rOpCbLh78uQFYd1GYJcqoDLBw9P2zcPHLPrLO5Y1JHAlk+fLUB/vjbpdx6r0l26/De8Mw93sPQp0yKrQdpIISqAzWf2+hF9sRLqnOCHX4/nFgI738WWwU/Jye0lhiFtZA76MVqImmqHpuX5JENQHa6B9JocUr3NbBmsy1ZDq2P9ZQQ0dQoooA91MQ2aqCMmLDctzCdj7mD9/mMyAv++fRnB9czkzEMIJ8+tGU8felGa0/jHEB+6O9cTz+RyGG2sgmEFKDKMsrfvIt7Zp1N+QmdKT+hM+fOGc3x5WdRcuURTJ86hJpsH/gEdVk+qnJ81GX5qM72UTaqKwAlVx7BuPnjIpM/HBg1ZxW51QH8NQFyqwOMWrQ1Mgt43SbVDdvr9/Dem73VkIHySo1yg5JSVZM38mfK2DgZtZZ5KrT47j+VfNzdN6mQf48ukd5wv94RCTK2mEsccnPUOqKm2eDFY5sDHI3KhjSLIN+Y1oEJcTrwF8APPCGlvNfp2Ab12EClQG9NIJ8mO6teUuwziVb8hf2kVlfQj+Bs+rKfmlDChjnhw1hTm8oipuOuspGLj4P8KnTfGuaMxUzGcB1vU2upefuQi1jOdnUuCQQC+Oskddlhw9nm+2r2tM8JhysD4A9IcmqUx7b8qPZcXRKuX5pZ/IEKKboQCm2+u5Wi7S0o73AwOrwZj/ST4XXNeUs1yXXC+G4vX+N9vc6uXU4y1IcgcSOnqXpsXhqNvhb8V28IIfzAI8AYlNLJx0KI16SsjwKRBBjSPzHDZih9NJMfXTmVHEixUQPIwc8UhoUMmDXh40MuoogC7mMkFXzHApwbwv+ESE+omCFcy1ueQpityaKYIfyKd6g1vc5c/MxlXdioCpRXZvTjApCSPe0iAyMtD9Ryx3vZjFp+gKK11Vw820hAUYbvzmnHsKNjLqPKtrL8qPbMuqI/BZX7mXL/8pDRKvroO/V3VhblJ3Zm9LwzqM7xhcObi7fFl55vrGM9dmdYWHnhYqj8Ftq3gzYtVcbtlCvUcdNiiAcLoGN7+Pl5qW+ZZF5z0zQrYho2KeXTQogcoH9w02opZYxq0aQZDqyTUm4AEEK8AJwDZKZh89oi3komKH3UI2VsRuCs9nc47fgNw7g/WOvmlYX8NCLT0ZrFOILno1L4nXiR1YykBzs4wKjlByl6YzWPTTiSq/vGyEQEBqKUMHrTllWEvZn25Np7ioLIRBIRGX9tm92SW8+4Ec4Ayrexr2VkGHBrQUtu/+Nx+AKSuqyw5/fG2b1YNPLfkWtyj9xB2fY3qTbCm1IlphT9/BeJX/y9GA7rb2PkUFWqsu17OGWYbpmkSQteRJBHAWtRHtSjwBohxMj0DovuEKFVtCW4zTyuYiHEJ0KIT7Zt25bm4cTAUB8Y2BdatrA/pvBIVQZgVinIkDBkCcsYx0uUYN/PK9Z+r4yiJ7kuc6nz6EcxQ/gNw+I+9z0s9iShdX5ofmZPHQGu5W3ukO9zar/FXNt+CYOv+Atdq2IvM1+BUty4ici+vC3sXrMQIIP/EGGjJsL7T8jtHT6+a0d+/lQw09BkDKXfFzZqQQ+wNktw1mun0XbnJVzy9EhVuL1jF6MOGUhOcM0tpybAqB7D0l/LZfw2xo5Qt+8+o9rrHKzQRk2TNjx10AYullKuDt7vDzyfzq7aQoifAuOklFcG7/8MGC6lvMHu+AZfY7OjpDScLj3lyowwYHZY15BmMoZihtCBh6OyCgEmMoBBdHAsko6Fsfa1iyoq+I5dVPFxMKOxBVkh76uEZfyad9lLNd1pRSk/5kzmsIvoNHE/gjokfgTvcWF03RmRRdeXMI/ZrIo9WClBSkRAInx+Ag7TwIHk80tzrRqR7W3ms4G5RBcq5+CnJX7b12TU3M1lHY9SQW1tLSPf2sx3XVqw4bA21AH7Dsk1ZY061dWp4vE3f/w25ORQfv9EyvK+Y1T+URSN/1ns90DTpGmqa2xeDNsyKeWQWNtSOighioBpUspxwfu3Akgp77E7PiMNWyPBEA82cEqVtyKA3zCM+0jceS9hGdfwVig06UPwR07kVo63Pf5Q/s5Gdkdsy8PPAVMtmlH0bU7TH0vvUFKJ9TkdMRdhy2CtgSkxLw8/w+jKvYyMaeDLqeRkXqDO9KwCuDpoCB83ecLj6ctwujGKnpHrchBpsKQE4Yssh3Co/wP4cMQbFH28A/5wA9xazECe4gt20oE8XmN8QpMUTeOnORu2J1E/G6Px10QgS0r587QNSogsYA0wGvga+BjlNdr2Z9eGLXGsHls2wlbF3gnDw4uXcio5kecjnkkAvWjDV+zhEHIYRU828gPbOcjFDKAv7SLG2pWWZOFjC2Hl+x60ZnNQpqsbj7GVcLuhKQxjBp9EGBhXbGrnzBhJKeVUMpZ/sZdautKSb7jW9vVO52NeZz0SlVCykJ8CMIpSaqgjGz9lTAgZmZ7MjHhtEeOxMbaO45WSa2au5rGbl8LCJxlY9FnEGiBEfo5t+St7qKEN2ewmrcnPmgamORu2XOA64CTUz2YR8Gi6C7aFEGcCD6HS/Z+UUv7J6Vht2JJjKov4M58QiMOgGYylN2/yk7geU04lZ/EKOzkY1+OmMIy+tIvoYG31OKcEvciBPBV18W6JP6bSSDzczUmMomdU6NPJuEF0KPZ8+jOYjlGlCQCn8AKLbLoWAFFGLBsfNU65mxKu+Sybx6pGQlEhfh6I+qwF8AEXMY6XIlRbWuLnDooSDj1rMpumati8ZEVWCSEeRtWxBVBZkWlv/COlnAfMS/fzaKAduQkZNYBO5lYuDphrygBG8kJUnZcXXmYta7ki5FmUsCwqjGqERr8gusbqYAqNGsBc1tluN3uJVoooYDnbQ7qZC9gUMsZW7mVkVAgzhMmo9aEtlbgIKAs45thREHzfjqB9lNGXqKxVqxTZfur4LR+QE/QwtXHTNAa8aEX+H/A4sB71czpUCHG1lHJ+ugenqR+s4sRWCunIo4xhOduZxXIq2cOW4IV0NqsYSY9QUfQtLOJTvqOKWuoAgQyZE1VIfVhCRg1U1qSZOayJOsaQ7bKjHbkx1w7jYQlbQ8Y6HmaxPOL+dD7ma/byLGdGbC+igPe4kDI2U8bmCCNulE1k4+N0+vB3yzmt3Mw7oQnBSn4elRzkRzCKnrY6m3VIDlDLCJ4nn1x2kNntUcqp5Be8xQZ2czZ9o95XTdPHSyjyC+AsKeW64P2+wL+llEfWw/g8oUORyeGmh2gYNfNM/XhmR2kzTmOEs3dhwoeIMHbxYK1Fs64PTmQApaym1sb/NBJI4lER8cJYerOanRFtbwaQz0qcl6CP4WkqiC7oj/U4c6alOXwJMJp/UU0dOfg5me62RejWsPFUFvEcqziMQyKSYIw1Nj/Yfk4t8XMSPezb8jQw1hZEoL4X2rjZ02xDkcB3hlELsgEs4nyaRss4XnLdX8F2TuR5etOGvdSy3UbncQGbXNU8zASQXMMQVrKDj/iGagIhfUWBsFXlh0j9RgPjojqL5bTAzwt84WhY32Ez0xjBAPKjwnDJspHiUKJKV1q6GieAHIefndEUdTETbfcXMyTCkJgnGwv5acQ6nZ8ZUStu1s9IdTeopSdtI861mxspp5KTbMomQIUnjc98EVtYy/d8wlYC2LcUqg/cSjjm82Xan99Owk3TcHgxbCuEEPOAUlT046coiavzAKSUL6dxfJo0Uk4lb3swSBLYaJkFJ0oOfiYxKOrHX04lp+Dc9WA1Nn3vgMF0ZDnbY0p11RDgGVaw38FwJko5lREe71b2U8IyV09mFD0jPF4zS9jKVBZFrLl5uWgWURCx7yIGuNbqmQ2BcWv2asrY7ElGzPoctUhG8HwoY7Q+aMGDVLmM9gwOTevzl1MZ8pgFgo60IIDkMo5KqhxGkzheDFsL4FvglOD9bUA+cDbqmqcNWyOknEpOpdRzG5dEEKi1m0NpyyA60pVWtkYN1IXUMasPlfBgRxmb49KfTLVWpZ2HOYc1robtTTa6nvN+PmY8h4dKCcxhRq8JHM9yJi+xOuKC39WU6GP1Yqz3lUqMn6oEE27K2Fwvhq0bj7katTZkpzwMadQA5uHnQX7EDg5QTV0wWiBDyUPT+ThUhxhqW6SpF7xkRaatXk2TfszrMuZswj9QnvBFyysSeITTPK3DjKKnY8q629rTLo/JIH4EkxhEWyfdxhQSS7ZrFTtc9xsZikUUUMbm0EWzmrq4DMZBfhURIjWXIJzBoRHeltWrKaKAd5jAM6xgIZtYyw9R55/o4hUmklSTCG4ZqPnkcgaHRXjUhnhMFj5ak00ufnLw05u2gMqcHUVP2pFLB/L4jG8BQhMycxnJfuo8r9kuYatrmFmTWrwkjxwK3AD0wWQIpZQ/TuvI4kAnj9gTT8uVlmQxlC5MZCCzWelcPxUnhsyVl4uxUcS8mp0cQX6EYr8TRqKDE9n4+D8OZQrDQ+fyMSNqJS6fXPZR4zr7h3DtWhmbWcGOqAu7H6h1EFwuYRmzWB4VhrQ2QM0xFWqbPTaJuiCPokfctYN2XMI85vMlZ3BoTK/GGu4zsiON19RQa2xt+At7bbzwiQwAokOliZKLn3eYYCvX5hU/glpuTsl4UkVTTR7xYtg+B2YByzH9/qSU76Z3aN5p7obN2qZFMpmpLOJvfOYp9JZjUbyAOPQUPdCJPE6kIMK4pAo7I2XgVB8GkMMDIYUVs+pGFjNc/Vjr2pG5x5u1l5sZt0lGb9rwPGeFyhSs4dpyKpnE/IiOB4kUxieLUSKQSSn/1u8+hD/31vyFfSkMPV/DkAj5s3gxq+JkCs3ZsC2WUtqL92UIzdmw2f2w48VOFsuq6OFENj4eZjQ7OMBf+dQ1NGQI+6bSuFllpzqRx684LqnsNLvX3o4c5nF+Ss9pMJ6+vMJ418e7lWRkISJqA7226GkqGJ5+JXu5gsGh77KTkHeiXMMQZrIsoSpMH/B+PSbUeKU5G7aLgX7AAiI7aH+a3qF5pzkbtnN51VEBIx7i6RwtgC605AQKosKFsbpU381JjiLHiWCkpQdI7cUj1enbTu+nlzEnMnkxGzfjtXQgjx0cCMl5FdKZduRyB+8TICyrle6Lb315fucy17argpWutKR/MDnpIHX8j21R0mv55PIG53EqpXGvTRt1nplm1KDpGjYvWZGDgZ8BPyIcipTB+5oGpiK4uJ0sVQRowYMh41bMEH5NWdT6Vaw07jUuNWLZ+CKSCo5nNkv5lm60opSzE/rhF1HA+1yU8hoia/p8sqxnF+3JQQL9yedr9tI3WBgNqp+cYXisr6MsojVhfBhrdAdt9F6sHqQE21T9PpTwFXvoRRs2UpzwWCDSi9pJFR14OG3GbQrDeYMvqQ1etvxAPi34nirqkKF2SHafs1lA20i8KacyqKfjHR8iY41aU8aLYTsXOKw+9CE18ZOHcwPMjuSRi5+vzQrxqEVsIKqY2Zo4sZsbQz/w1mSxwEOqudMMOQcfZaYwpFm9ZAt7k6p9SrURSjVWL/ZTvg0lWFzCPJ5jVVSXA7PnNIqe5JGVUKlCGZupilPEzJx5aVby2MQe+lCSlHGzhgZTGSq0UkQBi7ggoUmPnYj1dD6OO4/4MU7z/LxGIk4BrZjCcJaznb+wFIlqXptpKi+ZjBfD9jnQDq02kpHcxHG2Ia5utGQO59iGsCajIg9e0t6dVOqtxAqXVVmSKuwKlCcxn8s5KmnPK55sv/rgOZsi5pt4h6/YbbsmKYEzmcP3qL66RRSElEV2URXzczOHIUfRM+5aRbNX/ZWlMN98fyqLeJhPqSbAj+jlKZkl36LXmU9unKOLj1RNesqpjDvkH09LJ2uo+jXWR3xuxj5t3Lzh0BM4gi7AF0KIN4UQrxn/0j0wjTecvuj9aO94AXyD9bSzuaD4ExxDCx50NWpTGBa1za5t2Dp2cRvvM4pSyqlMaCxGNudODjKbVVySAQ0iOtIiatsStrom2uyimqksCt0vooBbOZ525IY8bj+CgRapsfEcHnHf7aIuUOUDwnTf6jX3ok3EY4z743iJ6XzMfuqoRbKATXTjMcfnMtjB9SFjlknZlXaUsIxxvEQJyxyFtd1Yb8piNejAwwhm0IGHI57HOjm1m4zYiX5r7PHisd2Z9lFoEsbNADjNMFeyk5l8HrW9lUtY04lWPORa+5WDLyrlfiBPuYbGqqnjHF7hO65zPOYS5vEiXxBA0o3WnM1hTGJQTEWNVGFXYmHeZw5/tU3QK/kbn/IEyyM8z1H0JAd/SInE2p5ntUcdzIkMYBAdYnrHGymOWmO7hHm2GZ5b2c8lzIvpJWeyMTMwh8oXsImRdI/7HC+zNuK7b11fFMxgOF0d5dWsxCr814SJ6bEF69W+ANoE/63KpBq25oh5JumUWGAnVmzGqoAOsI/auD2lWI07y7gg9Hc5lWTzgCcR4m0c5Hhm2+4zvLJaJAGUmO/jLONEnuegJdklHTqBdmFXIx2/hGWM5EXu4H1G8y/KqUy4D9wB6kKeZ08ep5zKUFjybA6jjkDUlMJOucWa/j+FYTzLmdzK8Z7CdBspJsBkNlJMCctc6xtTVfvYkFzCvChjs50Dbs3UbdnCHkpMdW9264lejRroMGQ8xDRsQogJwBKU+PEEYLEQIqnKUCHET4UQK4QQASHEUMu+W4UQ64QQq4UQ45J5nqaIEbZYwCau5i1WOMgz9ae9KcjkjTokp8YZBmzpEMDMwRcR1ioJGp540hicfvROXpgk2tB+GswavYR5HMLfOIanEw5zGtxiChGaKaeS61lIbdDgVFFLGZu5gsERx7Umi2sYwnC6eloLANjCPkbwPOVUspztzGU91TZGzCnBRDI59C+WMG8JyxjEU7TiIbJ4gB7M5Fzmci5z+QPlMceay4NJv8cNyes2CVBfsJPfMCyuX9TBoORWrA4aXnGa6Gmi8RKKvB0YJqX8DkAI0Ql4G5L6tP4HnAfMNG8UQgwELgQGAQXA20KI/lLK9IoaNiKscXanGfIUhjOF4VGKFbGIV49wHzfRiofYTx3ZCN61kVMqp5LrWJhge9ForDqHbqxiZ0RxcwXbGcHzjKdvQkooJSxzlBu7hUURHpMvWN5QRAHr2RVa89xPLZ/yHXtsTZM7P+V1BtHBcb8hJeUFI2RaxmbeYXNIxNc6pq/ZG5VZ60Y1AU7iBd5vgPY1yWA0KN1NdAJ4ANWo9gMuYjofU8G3njteLGATp/BClHRavCxNUWlPc8CLYfMZRi3IDrwlnTgipVwFIETU/Occ4AUpZRXwpRBiHTAcPEwTmwnn0z+mIshMU2PQtVwBRKYStyLH0TDk4I9bwHYfN7nuVy1Q4v9JO2XMPcuZvMKamGFQN+aynldZH3dB8g0sdNxnNXgdaRHSe3zD5AUEiC8EZeZr9vI7iqK+A35gsouEmBWjvi3RbgdWtRMrASTT+ZhXOCeh8yeCneC3V2Jl9QrC2aLz+JLqOL97qdBejdXEVxPGi2H7jxDiTQh96hcA89M0nu7AR6b7W4LbohBCFIMqqOnVq1eahpM5lLCMe1jMV+x2Pc6pFszapPI6ChlNKQeoow3ZoZm+U1uZZNgVU1rYnnscLtLjeInqFPzIJfAL3uIzLvV0/PHMjsvHMpIpXmZtStvlGJ9johdxUJONg0mMyUtI2WsiSyowZxYaRj+e9+UXMcTCjVer2ivpAFKm46VtzW+CTUVPQk1cSqSUr8R6nBDibaCrza7bpZSvOj3MbggO4yoBSkBJasUaT2MlHoX+bIRno1REAftjeFqJorT7lrCG76mhzrbliYFqH5LFLkv4Zyy9bS9M5rYhVnLx8VdGM4vljjViVpazPeYxBp8k4GXN50uqUmjUjE7i1olKvIyiJwKBTKMXsIqdjOOlehFr/gtLo+7H8/587uF7MJ0lTGE42cGsVDdmMialXTI08eFo2IQQhwNdpJQfBLtkvxzcPlII0VdK6SrCJqU8LYHxbIGIOFgPaMSr0EkSj1EDqM6AlhixtCKt1BKIMGpZ+LiAI2xTxktY5mrUzHJg5VQyitKYF6A68HzxTcTrHEoXFvIVDvMzVyYygPfZEspgdetLFy9FFPBrhqa8N50PQcD0WhewiWN4mkdN4fFkKKeSS5nHl+ymLTncw0iKGRL17sbzbpdT6en4SvYFe+RNCNW1tSU32DOvll1Uk0dWSCVkMB0TCvdOZAAL2cQeqiO6EzQ3cetkcPPYHgJus9m+P7jv7DSM5zXgOSHEA6jkkX6ojMxmideCzFRe8JKhhGVJXyhrCfA8qxhJj6gZt936lgACNj948wXoSVa4GrgFbGIqi2KuT/kRca9zHMYhvJPA4wC2sZ+NFDOVRbzMWs6mb9znSBRBIqaYCKNmUMF2TuFF3g2WfiQicWXULZpDoDup4mre4m4+4jZOiJgE3sRxns/tVYvTyG71qmZiVowp5QsqPHiFY+mdEWo5jR03w9ZHShnVfEhK+YkQok8yTyqEOBf4G9AJ+LcQokJKOU5KuUIIUQqsBGqB65pzRmSsRJEcfNzEcZ4TBtJNqpQRAsC1vMVgOoYuIJcwz3Z9a5httFthXIAmMSh0MV3Odlsv+Cn+F/N9PI4ucSV9CGAr+0IivFZ60Iot7HN8/Pn0j/CAjdtUfd4vs9Z2+0i6M5GBXMtbSWXxmakhwC0s4mO+DRWXL3TQHi2nkmdYEer8vYEfXH8Hm9jDLJYzkzEJrTuqsGykIW+Jn94cwi4O0o4WCWs1Gt/BUfQMdaFwoiF67DVV3AxbtA5QmLxknjS4Rme7Tiel/BPwp2TO31QwfkjmC3HvFCispwsvGZtOWL2hAGEx3nIqHbM4FzMx5rnNM2wljLsl6nzbYhS0g5KrijebcT4bbT2fHPxRa4A+4EjyI0Rve0ZWxPAcq1Ji2Jz6u2UhOIEC5vMlR5BPLXVsYS8HUpAwsYEfqKaOOmSorARUmcRHfEONrb/njaV8y0Ocyg4OMJiOcT22iAI+4CIuZR5fsZdTUtSh3PocxTEalWqjljoc+7EJIZ4H/iul/Ltl+xXAWCnlBbYPbACacz+2TOMYnnYMucQTyjM3Jb2HxdzG+7bHJbruYNf4060DNiTf1NUXTNbwIXiU07iVRVGCwFa5KTsDdDcnJSUU7da01I4pDKMv7fgLS1nFzoSNTyuyItaM8snle6pSlr5iaGj6EPSjHf1pn5au7Yni9v1JdZ9CrzTHfmw3Aa8IISZCKOVoKJCDamWj0UTxKGMcf7x1SFrid6w/m8mYiLYd5rYtdtzNSSGZKTuMkBaoMgYgGOLax9s2nmWsooR4MijtMPsjOzjAPYyM8MadyhusGEbe6BOWbu7nYz7gIlbw81DGq5cGnlb2WZIoUt2yxpg01SFZyU5WsjM0zixEqFVQpmGukdOkBkfDJqX8FhghhDgVOCq4+d9Syv/Wy8g0aSOZQtZYFFFAV1o6ptq7FVXPYY1taLGIAj7kIs5kDruopist2c7B0AU+n1zakMNODtKKbNqQHRU+m8kyfAkmcZjHlwr8poarRqGzAB4Kzh+NzySWLNVW9ifdH80LEpjA6wylS0jRxs6wdaUVW13WDBuSWmRSPf/ipZxKzmEu2znAkcHkLqckld9YutBrkseLCPI7Usq/Bf9po9aIuYR55PFQhNZkOtq6eKkfs+M9l5qfIgqYx/nczUn0p31EQsZOqtjEHvZQw1b2s5YfotaEJMkrN6RKXf3yYBH8M6wIZflJVN3X1bwVEs71kq1n7ZfmhVjhW6VhGVlSuoW9zGU9I3nRsYXLdg7YtijKJJIJJXulnEpO5Hm2cSD0uQ7kKUbRkyzL+zqW3hmT/NWU8KI8omnEGOG4hWyyLZSe7ZBa3xCc7NIaxJCAqqYuiRQDd8bS23V/MUO4gYUJKDxGssfSgcDKHNZQzBBP4SlrvzSvGMbN+H6sZAcHqeMKBofqAA1lGjNOGZ7qnJJ25HI47eLSJ7VDoBJsqhqhykcZm6O+oavYGUxcupBbWMR6fmAiA7RRSxPasDVhvBYpGxfSVNGG7JgXbys+3LPCVBGsyqiLt32IV95li+uaHcBPOSKu1iz+YMGy+UI3m1W8xBoO4xDbxxieoZfwVLIXfqearHG85JgJOYlBLGILKy3F8j4Eo+hJiU2vv2sYwjF04Q986FriYCCBM+jDcLqxgh38mw2ApJijQ8bAvIa6gR94n6/JQtCKbL5xiBqk67tjxm1CUkQB73JhPYyieaMNWxPGq67d+fQP9TgzuIYhCetG7uZG/MyIy6+pixEeMzfYzMJHdRokYauo4xlWuL5mo3jWi3ETwKOcxu8pj1LHr6LOVkVFQES6+kQGuD7XVvbTjcdSkkRiqP3P5HPHickA8imigNbkRO07nHYAUar3+bTgMcYAcCvveR7PGr5nCsMdswXdCqXLqeQWFvEJW0Pruk7F/KmmiALakRMlExdr0qRJHdqwNWFG0dM1YcIPnM3hzGFNVOr74yzjSVZQxoSEfozvc5Hn9QwvfePMKg5fsZsSljWY1vmznOmoDjGOl3iXLfSiNU9zZui98yqNJiEiycGLIU10TdOMF7X/bERI4caunm8P1bafeRdahv6Op+XQSnYygufpQxsK6RyRKWsY4Q7k8RnfRoRSB9ORMjZzLyPr1ZCYO6dfyJERNWuCcF2mJv1ow9aEKaLAVS3Dh4/XWe9o+Gri7M1mfe6j6cTnbIt57BG093xOo2D7aVaGxIX9CGpSYOay8YXKAhLFLpw6mI5RGoqxuJR5rOFKQBnSl1njGBrsajIciWKEep1oQza7uREgoiu0me8cDKxZ3upZzozQv/TCRvawkT3MZT0C9Xk7dRdYwtZQ+DcHP+8kMDHrxmMh1ROvnrB5DTgHPw9xKtn4Qv35shNoB6VJnKT6qmkyH2v3ZoPxHE4A6bpmleyP8TGcdbCN50xE59Lw3v7ISbzPRVRzM5LJoY7UOfjIxRfzy30IOUxkANcwhGsYEioITzVlbI57bcea6HMDx9oel4patnIq+R0f2E5wshBMYVjIqJVT6diTrs4h+LyDAxGlCxspZiIDaEUWXWnJFIaR49CJ3YokdsucuuCaZhV1jOB5snjAc/avYdRAecJZPBBhyKeyiH7MYmqwi3o5ldzDYs5kDgeopQ5JFXXs4ADvckHou5Vo5EOTGI7KI40JrTziTgnLeIilCOCXQakm6wzzZLpHhCOTWWMzY6f2P5EBKRd6tRZjx1IsSZVw9ECeYjXfcwTtHc+XaFNPa1q+VTFEhZndOzpMZRHPsYrDOMQ2NGenhuED2tGCMzg04nMqYRnX8FZcvrEPEAhXbUhjHFfyZlRCSirx8r1zUmVxEoV22j4ljqavDUlTVR7Rhq0ZY14TSOdssoRl3MmH7KaKc+mXMqOWxQzb4FkOfsqYANjXLaXSqJkTQNwkucyJGUYYLhsfx9DZNlTcjhy+5wbX53N7HSUsi5Ls8iN4z6K+cS1v2eoXmo2qMWlw0zm0Q0BojdeP4A+c6CobZdR/JXNFmsgAXuALW++zLTn8YHlPrbThL+xNQf88AZxD34yS9LKjqRo2vcbWjPHafiNZkm2KCfHpGxoCu7dyPB9aklhSqTzxhcW7qCKAYIZtAbTxXt/K8RETCsDWm5vH+VHnWMnPPXmIdjqYoEJ08a6ZllMZU5XeiTH05j2+DkUFYoW1iyjgcca4JtoI1ISgjkDEpKYTebzKeIoooDutbdsntbHJ5DQwPpMZnBpXD0QnJDCX9fybL9MW4tY4ow2bJuOJV7TXrL1XREHaGjTmkcV+m9m9k3EzsE4ojGzPDuSxgwOuHnQsT3Mqixw7LPiDdWYQ9sLecNB8NNbE3DJb25FDMUfzF5ba6myOoifTGBFXVMBo0DmKFyMK4YfTlSrq+IKdtKcFdzEiQnrMUGmxlq2Y6U5rx9c6khdCa3e9acMZHMrrbIgq04iXGgJcy9tUMCmp82jiQxs2TcJcwjzm82XUWkxDU1/aew+maHY/l3WU8DkCOJO+LGErH1HJwWBXZgMvBtqp0Ws/DgmVH5RTyamUuhZ3xxI6Nq9X9aVd1PuQR1bImMX7WRRRQAuyqDa9dnO4div7Qs+njGApNdQF69SccUqkuoVFEQkpm9jDfL5kC1fTk8djFpTnk+sq6Pw52zw1stWkDm3YNAlhnhkbt5lg3PrQtt4uIMUMiTuZwoo1ucatxiuWJ+hEPrmh0gFQWZqxFEvcjFpv2jCIDqGCY8NzmsMaCulMO3KTXrc9jLYxO07PYjnH0jlUpuD2OeTiD43TKgK+3kZqbhN7KGEZpfw4Zih2nweVnRl8TBmb+ZTvOJbOnvoIahKnQdL9hRD3CyG+EEIsE0K8IoRoZ9p3qxBinRBitRBiXEOMTxOb5ywXYOt9Jy5hHh14JC7x5Q+5yPOx9d3T6vGgooaZTq49eiNx6mKdKHY/aGuPt2Trqbayn9/yAaP5VyhkWcwQ3uQn3MdIbuX4pD3mR23eVysFtPJ8vkOC62slLIsQAS9hGRMZYPuYWSyPMNxOxGp3BFCH8jprCbCErRzPbM9j18RPQ9WxvQUcJaUcAqwBbgUQQgwELgQGAacDjwohvBW4aOoV6+xYAvew2LXViuHl7eQgs1nl2bgZbWsOpx3Z+OhOa8bTl2sYwkQG0Jk8etOGmYypdzHnYoZEKdr/nMGM4yVKWBZV92TlPPqldDx1TA79qH3Yhy+LKGAA+QmdX4BtF+xEMGrArN8ZY81sOF1dHz+F4UxiELkeauAuC3beup63I7ZfzVuOHv5ODgKqfCTVGpOf8G2Kz6gx0yChSCnlAtPdjyAk13AO8IKUsgr4UgixDhgOlNfzEJs8U1nEy6zlPPpxHyNt68DixdwfbSQ9olKd5/NlxPHW+24UUcBaroh7TPXBfYxkPIdTxmbK2BwKLZqTOIxt1ouocb+Ez9kTQ67aaxgylu4mqCSU45ntqErjRHawT3UtAU+Zjk5Y6yiNGjcv63+g6sSM79Y7TOBkXnBU0DGr6Nsp1PRjFjn4oro2rA92KCiigItjaHYCjKcvOznI+3wd04cLIClhWUZ01WiKZILyyOXA/ODf3SFiCrgluC0KIUSxEOITIcQn27bFlm3ShDHWddaxi+l8TCse4mSe53GW8TjLOJXSmE0u88l13LeTKuaynhE8j2AGHXgYUDqBZqz3GzNFFNCBPMeMRHAOO97HSL7nBmqZbOsZjOfwuMKxXlnMxJBiixmn0Jwy3hN4hwn8gRNdC65jYe7WYPb8nmFFTKOWT27EBGEu61wlsZ2yIQ3Wscu2FZH5jIPo4HoOUI1WT+dQhEf/bhbLPR2niZ+0eWxCiLfBNpZwu5Ty1eAxtwO1EAo4230jbL+xUsoSoARUgXbSA25GWC+w1q7WxoXG7aK1g+s9p+HvpIoOPBxa68nETEqvlFPJdD6mkr2h3mUG97DY9bFewo52X+S5rOPfbEhbPZS1d9p8vgx5h07d1pMdh7lbg9nzW8kO18f5iFwzLKeSx23a5JgpYVnIEMbKYDRjvhiNomeE9qMTxuuyU5mxqpQUxDC4msRJm8cmpTxNSnmUzT/DqF0KnAVMlGH5ky0QEdvoATFcB41nyqnkFF6I2QTSZ6p3ckMymd4eG10aF5NnOZMdXNdojdoInmcu61jC1ohu1wDfuaSFT2QA7cilhGWua5EtHdaLaggktZ7lhpsnbSSFpDpkZuh9Wj2/7RxwfVw2/tDarBHO3G1pD2Ol1jRxuyeOjFk/IvQ5FVHAw4wmy+WSaXwXbuAY2/0+VHE5wdtM7zbemGkQSS0hxOnAA8ApUsptpu2DgOdQ62oFwEKgn5TSNTahJbViU06l6zqEgUBl+sV7IXNSuzDIJzcqO8+OS5jH66znMNryKGNiegbxrg0mIyNm56G2JZsfggLBWTzg+P7m4KfWJBPsQzCULuzkYMREYyZj+BX/jfKis/HZemwteJAqAq5yXl5Id02iF8UUgHOZ61pqYJCLjzyy2eXB+xpJ94jmni15yLFTghk7GTDlsbvX+A0g37HX3gdcVC8ydl5pqpJaDWXY1gG5EIo7fCSlvCa473bUulstcJOUcr79WcJow+ZOCcu4P7imFos2ZHMthQnXInXg4ahQTzxGzbxA70P1dXMTzjV3CM+1tCkxLkIVbGM3VVHjikdey0nRwkc4WcPNsMWDAC5mACPpwSyWU0DriGQJA8OoGSRr3NKFVeMyDz+XMsh2IqJUQF6kNiERL3usn7OdMLcVAbQgy3EdMRFB6N60YSPFcTwi/WjDlsFow+aMUbeTKG3J4Wz61kvosAOPhFKsDYbTle85wLcciBrHPSzmdt6PuLiM53A+4ZuYahEGd3NSTAPups4/nK6hYttYXquTErwbZg3E6PNFe5Dpkg9LBj8P2Pais05EDLx4RbHIwc9A2jt6/dk84Nr+ZgD5zGKc4/ci1u9qJN1ZxNeh+6loL5QOtGHLYLRhc8Z6sW1NVkLq5WPpbdtEM5W46fyZMQxEb9rwFXuS8pH8MVqquBk1O3X9cbzEe3zNYDpyLJ15ihXUEiALHz9nEOV846n5qhM9aEUpPw7KTtW/x+YllNuHEjaxhzz8DKYTX7Hbscv3eA7nFc6x3ZdIOQI4G0zr63DTwTQ6RNgZ3WdYwUyXDu5GyBHIqLCjHdqwZTDasDljnVnOZAyD6UgZmx17lTmRSmV8J4w1tlZk8Y3DxTDV+BCcRi+mMSLq9Vl7ugngcJPuYiyshiAVrVkg/Fmkao3NC2qd9nnqAD/wns33wTBqVtqQzR4H6amB5If6BJrpwUxXEeIsBO1oweUcxXgOj7sOs5xKLmVeVFNXCK+vrWBHaO3RqWuAlYYQCkgUbdgyGG3Y3HFK2bZbD3Pjbk5Ku2SVYQhWsMOT95YMeWRRRR2BYBdxPz4eYXTEe2RdHwLIwseiJFLvkw0PQ/18FlaO4ekI/cZCOvIZlwLhz81psjSW3q5hWlDG8kKTuPIpvBARzrMynr68wvj4XoSFcio5kznsoho/eEgpcWY8h9uuhWYyTdWwaRHkZoBTP7RfM8yz15aNL2mNQTe8hiGToQetKeXsiOSSm3iHJWxFotQ0ruYtruYtJjKA+XzJ95Y1P4LHxdvXzEwxQ1jElojXO5EBvMxaDrqu/IRJ52fhxOcWUWLDyHnp2VZIZ95ik+trq0OJQM9mFRMZwL2MjGgnM5yufMK3BJDBdPnhSb0eazgyUaPmQ/AYpzUaL605oA1bM2YUPckjy3b9yIwPwcOMTuhCXk4lv+AtNrCbs+nLdRQynSV8xndUUcdODtqqPqQKH3AE+dzEcaEQLIQLjJc6aPa5GVm/xzo/N57lTLrTOiRr1o5cnmeV5xBlQ3gFdmMzPt9Yn2A7cgkwGR8zPL3G2aziXb6iH+05gvyQJ5TKru9G6DIZOpDL65zXqLy05oAORTZzLmEec1nLPhfjlsiaQTmV3MIi11BSsgigCy3pSkuqCZCDj5xgHzBrucJUFnE/HyNRocRHGM0slntKTrBmM3oNRY7jJf7LV2Tj4waOdW2n45bmblXLSEfmoznDsiV+9nGT6zEGhXRkA7tjFkmrx6uu2m/yk1ASxuOmAnc38snlHkam1CuKFer0Qn2sO6eTphqK1IatmXEJ8/gXqwkgaYHfU4bkFIbF1eOshGVcy9u2Kd6J0posRgRlQ61rhV7Gk+yaltm4CeBPMda47FL/W5PNLyh0fC9LWMb1LAyWcQuOoD03mZIqnNZKk8XOYOXi405GhDxTp/T7XPz0pI2nGkmDfhzCrxnODg7QgTz+wIeeyzPAOdkkXrrxmGO2Zizy8LMwRuZlY0AbtgxGGzZvJLqO1Yk8vuMXjvvN6h/H0IVf8HZKCpVBeQ+1yFC4ciIDeJ8tfMUeutCSGzk2Zlgq0bRxM35ExGuK5cW24CFHMV+3icLxzLZtRmmX3Zoq4+ak+elHkIWPWgIp+zytZONDICJUWbwyku5MZCCfBcPJ8Xal6MKjfBdDwsuJVCSuZAJN1bDpNbZmxOsJFrzaXdQMY7aVfREzeR8ktGJm6OhZmzZapaXMhnkr+7mN913rlsqp5DO+i2ssdi1MrO+BYWScjEsnWjh6IdP52NawmQ3wErYyjpdCtYNzWBNx7BzWpD1ZoQ6ZRpOmMIsKC+Ac+jKcbvyZj2Nm7C7i64hQ4uMsow3Z/JlRnt6byzjKU/q+FQFJJ65o0ksmtK3R1BNtyU7ocV1oGXH/EuYxItjmxhqeiseodSaPmYxBMpk6JtOTtgmNr4o6x0SAMjbHFRL1Icj32AH7ehY6ihmfRV/Xx/ZRjSlClFMZ5VW+Z7pon0//iH3W+8lgt2aXiz9UvO6Ps81mok05JTCX9dzG++ykijYJfF/3UBMlTu3EfYxkCsPI89CotCst6UweI+nOB418Xa05oD22ZkIJy+JaxzBzE8eF/p7KopSk5QtgrkUq6jz6JTSDdmMUPfHj8+R5+BE8ymlRqfhO1CEd0/4nMYi/s9zxWa1FzHbK/SebWhEaHkg61thAGTdzxqExJvMa22d8hwC+Yo/rBOZiBvA8XyS9xrqHGvLwk0dWXPWWANfwFovYEqqJm8oi/sH/yCOLCzgylFx0HyMjGu1uDf5GPuKbiPW38RzOY4xJ6vVo6g+9xtZMiKVj6IShhWi0W9nI7qTH4gMec1gjMhtOAZxCT/7F6qg1NsMwCFQrE6v8kZGVuYqd7OCA64VYAFczJLRGM4inWGmjzp6NCHVg9iHIdZHiMsbwC96KKGq2YnhLVukuswZlphEr47WQjjzKmFCNYLpoiT8qVG1/XBb7LUlSApXd+rClIN/A6ORt9IuLJdHVWGmqa2zasDUTEs0MPJx2HMYhCRlFMwL4DcNYw04q2RfVpDMRnGqaVOr8Cx5LnZWhHWoyJHZqIxNNihjx1lK5qcmbU+tTWaNVH7TiL1EGw2AKwxjP4SlX6jcznK4pMZzmz9ZMY/s8EkEbtgxGGzZvmGu5vJKKi0cf2vIc/8dytkcY15F0595gEoX1ApLMRcWq7+iV4XTlIU6N8kZS4T25Gbdk69LMWY31IVZt4JZla/T1A1Je+mGQTy5tyeUb9kYlHcVLvCUtTQVt2DIYbdi8E66VkviALrRiFD0ZRAdWsIOXWcNB6miBnxs4lpdZG1eNkhWjGHoHB0Kdp624tXNxarBpxhCz/Yq9nEIPpjEiIaFhHyBMaf2Gl+nlgjeVRTzHKjrSghMosE09tzMETsXQXnAylm3IYTS96kW38BLm8QJf2K4l+hG8x4UsZ3tM45ZoNq2ZRNoCmcnElj/ppqkaNp080swoZkhIWsreG4oOySSa0FFIR/pwCNezkFoCjtlybhejGgKcyRy+5wbb/Va9vwVsYgGbEs7MM1+gJbA7RtLCVBYxg09Cj9vCXirYzuMsiwpxPcuZjKQH1wYlqJIxanbhUoM9VDOXdbzKuoS6obthNmR+4Di6OibIGMk1RiH7tQ7SW4LohrLGRKGKWrbZ6HXa0fin6JpU0VAdtP8AnIOapH0HXCalrAzuuxW4AqVJeqOU8s1Y59MeW3qJt7C7LdlcQyF/47OYOpRe6UpLhtApIiOwnEou5t8pSWhxIgcfVZZ2MFNZxMusJZ8WMcO06Qhxxft5uCl1lLCMO/mAnRykDdnkkcVuaiKauhph4TI2x73WapacMhqIvs76UMpHPw8tgEpYxq94x3E9z4mx9KaQzrzMWo6nG/uo4SMq+Zb9tkawsctjJUJT9dgayrC1lVLuDv59IzBQSnmNEGIg8DwwHCgA3gb6SyldU5+0YUs/xsXNKZxokGw4yAsj6c5uqljG9pSkJbQlh0I6OWb5mUNUbp6SHa3JZg83Jj1GM3adxr1gVU+JxUQGcB2FjOZfVFMXd6l2Prns4Pp4h+lKPEbdaPhpZ6zsWjblkeWa5doUaaqGrUEKtA2jFqQV4WvhOcALUsoqKeWXwDrQJf6ZQBEF3MrxXMFg1+PqY5q0iK+pSIFR86Fm6T9wA+ttmk1CuNi4nEqO4em4jBpEKmukijM4NGrbeA5HMplCOjo+Ll7DNJ8vKWNzTKM2nK50pSWtyCI3eEnpSsuUGzVQ4dwPuYix9I55rMS+PhBgB9czkQHkmVZjqqlzPF7TuGiwNTYhxJ+AScAPwKnBzd2Bj0yHbQlus3t8MVAM0KtXr/QNVBOBEc66m4/YTRUt6rHTdTJYPcketKKUH4daoTh1ar6YAVE1ZvHwkxQqhBg8y5lsY38oLKh6kw0D4FHGpCzF/gwOZRQ9ycFPNXX48UVoOvqAixxS5dNJEQWcT39PYdEO5Dnue5YzQ5+tUa/WEH3uNKknbYZNCPE20NVm1+1SylellLcDtwfX1K4H7sRejcd2qiilLAGlSzR06FC9bpwCvKbYG41Ly6nkPF6txxEmhgBakMUNHEMF30Upd7jN0p/lTO5hMdVxtqH0I7iQI9N20T+f/qxmJweo5TKOivi8WuBjb9D8eO0K7QPak2u7xraQn9oqkjRkyG4+Gzwd95lDvz2DIgoiXl9zCkM2ZdJm2KSUp3k89Dng3yjDtgUipkw9wEGMT5NSjJmr0cH5aDrxGKe5qmqcwotpCbWlGrOqiEEJy5jFcgpozRkcGlKxN2NoFRpei5PHNoB8dlNNXw7hXkam/eJoLbY3slZ3UxXV3yyWUcvGx684zjXBpYiCiNdUnxd/lXDyMZXsDRX1l1PJax4Nm5e2NNbXp2n8NEgoUgjRT0q5Nnj3x8AXwb9fA54TQjyASh7pByxpgCE2O8rYHDJqAJ+zjZG8wCIutP3Rl7E5442aU88sq2H4Nxu4meN4kKWh19QSP7uDSR9FFHADx/Acq9hiClkaBeb1fVGcxfKobX/mE2SMNTQ/MDgod5WqMadLncNOtmsJW5nFcsZzuOeC77mso5xKbbiaGQ21xnavEOIIVLr/JuAaACnlCiFEKbASqAWui5URqUkNdmsLtS4iv6PoiQ+RFkWJePAFo9dZ+BhIe9bwPXWotS2nMKC1BUwNAdqRy7tcYHuRLmFZRC3fePoyheFR74txkd9FVVTI0xDZXckODlKXsKRYOZXstelW7eVzqAMq2M5JPB9VNxYPhrfbAj8fsZU6AuTE0M2Mh3IqHQvsl7CVPR66dZsZwfPNMpW/OdMghk1Keb7Lvj8Bf6rH4WhQXsnFDIhIpc5COC6mF1HAY5yWdGfqZJjJmBjF5vZYEw+y8YUeb3cO62ucy/qoJpOGoovZizWeYzAdOZXSiMajRslEPMbNHC5OhgBKrT+RRplOmqNGRmEqjMck5rua6bUJKOE8wwpt2JoRWnlEE+JZzqQ7rZnNKk/rRcZFeSrvssthFp2sVFI+ubYtS8wdpOO9YBmPM9bY3KSnnPqtjeMlzqc/69nFbFY5ZlXOYQ07OGCbfBJvs1BruDgZ3mNLQo+zerugknOMjEJzF4m2ZHO/x6afZmJJuB1L57j1S/8eDN8eQxd2cEAnijRxtFakJmHMHZ+d6EpLdlIVd1ahwUzGsJ5dIfWIQXSo14tSZx5lGwcSfrzhVVo9NmNfPBf9RDs0OJFIeM46Bj+CqxjMJAYxjQ9tU/DbkM1uboxI2HGbTJhFnQ160CoiWzPeQnk7kpE0ayo01QJt7bFpEmIcL3maNbenBXdxIp/xLVvZzwdsidD+60pLtnPA1g8ZSffQhb8hlNePZ3ZSRs3IqiyigHeYkPQa244kxmJHIuG5SG+3VcRa43sOyi17qKEFD0Yo8M9lHW3JiSgrMMjBF+q/Byokvlktw4c4hR5JG7b91NGWv4aShDRNB23YNAnhdBGz8gU7uYl3IhILrJl0RmLFu2yJuFgNpENaxu6VT5Js17OHmpB3U8yQpL1Mc7F0Q2LUMVo5me6ORdN2bWV2U81sVlHKF1Rzc2j73xgd4RU+gtfKofjZQ03azq1pOBpEUkvT+DnZXhAGUDNuI1tRAlXURhRBG/JcxoVeJaKMYRbjyMWPAHLxM4lB6XwJMbGqBahu3fH/ZOzWpRKhiALKmEAbcpI+lx+R8vf3TX5CJ1rE/bgaJIIZ3MNiyqmkmCHMZAxj6e0Yrk3l2MfxUsrOpckMtGHTJIRbM0ufRcDKF8w6jIURsvsTJ/GOTf1ZfdOTthH3e9OWd7mA8RzOcLoykzFke2iQ8ynfMZVFKRlTEQVcy9EJP74N2YynL+851Cd6oYRljOMlSlhGOZUhgwTwKucGpybxcxvvM4rSkHF7k584hmuLKGAiAxJ6Hiteow+axoNOHtEkjFMyw0QG8DJrqaIOP4KHGZ3SnmD1hfX1OXkPXhMZUtnCxmido9qxVLOG7+lIHgPpEKWyksoiardO4F1pyV2cyGA6chavJNSBAMKdzL2M1ar2P5MxzGYln/Gd5zBjfXYdzzSaavKINmyapChhGXfzEdvYTw5+ijma+xiZNkWK+qaEZcxhTZS+pBW7TD4rPWjNZq5O5fDqFWtTVyemMIyH+DSptcB4Wsg4fdf6UMIm9rg+tjkbNWi6hk0nj2iSwimRoKno7zm9PjMlFn1GJzomsP6USXht6fIya6lNMsHlQHBd1st3yOm7tpFijmc2S/mWbrQMdXPQNH30GptGkyRek0NWsNOx4LsxYMioxeI8+uFPwaXln6xM+hyLmUgtN7OZa7RRa0Zow6bRJMn5Hnuu1RJolI0sjQSR5Wwn38HrzMZHb9owhWG0I5dfcVyCKSRhkq1T0zRfdChSo0mSYoawnl2OSRUGWfjoQB7XBhNSrEkemYjXdbX/41CmMJyTeYE6JH4ErchibwxdS6/94jSaeNCGTaNJAe3IjXlMEd24kf+GpLWeZAVlGVDW4MZoSj0d9zob+B87qAuWedQhYxo1I0u0hGXcyQdRvdMGkJ/YoDXNHh2K1GhSgJc6va/YE5EpWBNUxM9kDnj0pySSr2JkIPoQCFSh+0QGhEofihnCN1yLZDIDyMeHYAD5rOTnSY5e01zRHptGU09sZDfZ+EKtbbKDiviZjFN3BSsBoJBOrvqhj3FaTGV9bcw0qUAbNo0mBXhZhwK4gqNCfzeGNbYdXE8HHo5p3HzAeA6nH+2Zz5ecwaFsYz/vsoVetOZpzsz416ppOjSoYRNC/Bq4H+gkpdwe3HYrcAVqTflGKeWbDThEjSalNAZjZmUH1wPuReiG93krx9fXsDQaRxpsjU0I0RMYA3xl2jYQuBAYBJwOPCqE8DfMCDWa1JGNSKj/WSYxhWGO+37eCA22punSkMkjDwJTIKIR1znAC1LKKinll8A6YHhDDE6jiQfJZNvtH3IRkslUc3Ojv/Dfx0jG0jtqe04GdGLQaMw0SChSCPFj4Gsp5edCRJRxdgc+Mt3fEtxmd45ioBigV69eaRqpRuMdyeSIcJ2TsWvMvMlPQp2wW+C3FV3WaBqatBk2IcTbQFebXbcDtwFj7R5ms81WpVlKWQKUgBJBTnCYGk1KaYrGzIoX/UyNpiFJm2GTUtq2vRVCDAYOBQxvrQfwqRBiOMpDM+c/94BGLK6n0Wg0mnqn3tfYpJTLpZSdpZR9pJR9UMbsWCnlVuA14EIhRK4Q4lCgH7Ckvseo0Wg0msZLRtWxSSlXCCFKgZVALXCdlFJLyWk0Go3GMw1u2IJem/n+n4A/NcxoNBqNRtPY0VqRGo1Go2lSaMOm0Wg0miaFkLLxZ8oLIbYBm2x2dQS21/NwEkWPNT3osaYHPdb0UN9j7S2l7FSPz1cvNAnD5oQQ4hMp5dCGHocX9FjTgx5retBjTQ+NaayZjA5FajQajaZJoQ2bRqPRaJoUTd2wlTT0AOJAjzU96LGmBz3W9NCYxpqxNOk1No1Go9E0P5q6x6bRaDSaZoY2bBqNRqNpUjRZwyaE+LUQQgohOpq23SqEWCeEWC2EGNeQ4wuO5w9CiGVCiAohxAIhRIFpX6aN9X4hxBfB8b4ihGhn2pdpY/2pEGKFECIghBhq2ZdRYwUQQpweHM86IcQtDT0eK0KIJ4UQ3wkh/mfali+EeEsIsTZ4274hxxgcU08hxDtCiFXBz/+XGTzWFkKIJUKIz4NjvStTx9ookVI2uX+o1jdvooq2Owa3DQQ+B3JRbXPWA/4GHmdb0983Ao9n8FjHAlnBv+8D7svgsQ4AjgDKgKGm7Zk4Vn9wHIcBOcHxDWzIMdmMcSRwLPA/07bpwC3Bv28xvg8NPM5uqE4hAG2ANcHPPBPHKoDWwb+zgcXACZk41sb4r6l6bA8CU4hsUnoO8IKUskpK+SWwDhjeEIMzkFLuNt1tRXi8mTjWBVLK2uDdj1C98iAzx7pKSrnaZlfGjTX4/OuklBuklNXAC6hxZgxSykXATsvmc4Cng38/DYyvzzHZIaX8Rkr5afDvPcAqoDuZOVYppdwbvJsd/CfJwLE2RpqcYRNC/Bj4Wkr5uWVXd2Cz6f6W4LYGRQjxJyHEZmAi8Lvg5owcq4nLgfnBvzN9rGYycayZOCYvdJFSfgPKoACdG3g8EQgh+gDHoDyhjByrEMIvhKgAvgPeklJm7FgbGw3etiYRhBBvA11tdt0O3IYKm0U9zGZb2msd3MYqpXxVSnk7cLsQ4lbgeuBOMnSswWNuR/XKm208zOb4jBir3cNstjV0vUsmjqlRI4RoDcwBbpJS7hbC7i1ueKTqNVkYXK9+RQhxVAMPqcnQKA2blPI0u+1CiMGotZPPg1/mHsCnQojhqJlwT9PhPYDKNA/Vcaw2PAf8G2XYMnKsQohLgbOA0TK4CECGjtWBBhlrDDJxTF74VgjRTUr5jRCiG8rraHCEENkoozZbSvlycHNGjtVASrlLCFEGnE6Gj7Wx0KRCkVLK5VLKzlLKPlI1MN2CWkzeCrwGXCiEyBVCHAr0A5Y04HARQvQz3f0x8EXw70wc6+nAVODHUsr9pl0ZN1YXMnGsHwP9hBCHCiFygAtR48x0XgMuDf59KeDkJdcbQs1mZwGrpJQPmHZl4lg7GZnFQog84DTU7z/jxtooaejslXT+AzYSzIoM3r8dlYG2GjgjA8Y3B/gfsAx4HeiewWNdh1oLqgj+ezyDx3oualJTBXwLvJmpYw2O6UxUBt96VCi1wcdkGd/zwDdATfB9vQLoACwE1gZv8zNgnCehwrjLTN/TMzN0rEOAz4Jj/R/wu+D2jBtrY/ynJbU0Go1G06RoUqFIjUaj0Wi0YdNoNBpNk0IbNo1Go9E0KbRh02g0Gk2TQhs2jUaj0TQptGHTNGmEEF2FEC8IIdYLIVYKIeYJIfo39LiSQQgxSggxwmHfkUKIciFElRDi1/U9No0mE2iUyiMajReCBbuvAE9LKS8MbisEuqDqxhoro4C9wIc2+3aiOkWMr8fxaDQZhfbYNE2ZU4EaKeXjxgYpZYWU8j2huF8I8T8hxHIhxAUQ8obeFUKUCiHWCCHuFUJMDPbOWi6E6Bs87h9CiMeFEO8FjzsruL2FEOKp4LGfCSFODW6/TAjxshDiP8FeW9ONMQkhxga9rE+FEP8Kah0ihNgohLgruH150BvrA1wD/EqoPn4nm1+wlPI7KeXHqGJqjaZZoj02TVPmKGCpw77zgELgaKAj8LEQYlFw39Gonm47gQ3AE1LK4cHGlTcANwWP6wOcAvQF3hFCHA5cByClHCyEOBJYYAp9FqIU56uA1UKIvwEHgDuA06SU+4QQU4Gbgd8HH7NdSnmsEOIXwK+llFcKIR4H9kop/5zwO6PRNGG0YdM0V04CnpdKYf1bIcS7wDBgN/CxDLYOEUKsBxYEH7Mc5QUalEopA8BaIcQG4Mjgef8GIKX8QgixCTAM20Ip5Q/B864EegPtUM0wPwgKd+cA5abnMIR8l6KMsUajiYE2bJqmzArgJw773HqZVJn+DpjuB4j8zVj16GQc560LnkugenFdFOMxxvEajSYGeo1N05T5L5ArhLjK2CCEGCaEOAVYBFwQbPbYCRhJ/Er/PxVC+ILrboehhJUXoZrGEgxB9gpud+Ij4MRgGBMhREsPWZt7gDZxjlWjaTZow6Zpskil8H0uMCaY7r8CmIbqd/YKSln9c5QBnCJVe6N4WA28i+omfo2U8iDwKOAXQiwHXgQuk1JWOZ1ASrkNuAx4XgixDGXojozxvK8D59oljwTLG7ag1unuEEJsEUK0jfN1aTSNGq3ur9EkgBDiH8AbUsqXGnosGo0mEu2xaTQajaZJoT02jUaj0TQptMem0Wg0miaFNmwajUajaVJow6bRaDSaJoU2bBqNRqNpUmjDptFoNJomxf8DpYJbWH/rRfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 200\n",
    "\n",
    "p = reduce_dims_and_plot(projections,\n",
    "                         y=clusters,\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnormalized_samples = samples.clone()\n",
    "\n",
    "# for col, sensor in enumerate(tqdm(dataset.dataset.all_signals)):\n",
    "#     denormalizer = dataset.dataset.get_denormalization_for_sensor(sensor)\n",
    "#     unnormalized_samples[:, col, :] = denormalizer(unnormalized_samples[:, col, :])\n",
    "\n",
    "sampled = samples[..., range(0, samples.shape[-1], 200)]\n",
    "\n",
    "samples_f = sampled.flatten(1)\n",
    "tree_dataset = list(zip(samples_f, clusters))\n",
    "batch_size = 2000\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 500\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "tree_depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT accuracy: 0.9770856945744838\n"
     ]
    }
   ],
   "source": [
    "tree = SDT(input_dim=samples_f.shape[1], output_dim=len(labels), depth=tree_depth, lamda=1e-3, use_cuda=True)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)\n",
    "clf = DecisionTreeClassifier(max_depth=tree_depth).fit(samples_f, clusters)\n",
    "print(f\"DT accuracy: {clf.score(samples_f, clusters)}\")\n",
    "tree.initialize_from_decision_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.3839454013649659\n",
      "layer 0: 0.988950276243094\n",
      "layer 1: 0.988950276243094\n",
      "layer 2: 0.7417127071823204\n",
      "layer 3: 0.7417127071823204\n",
      "layer 4: 0.6799033149171271\n",
      "layer 5: 0.5253798342541436\n",
      "layer 6: 0.41721339779005523\n",
      "Epoch: 00 | Batch: 000 / 011 | Total loss: 0.698 | Reg loss: 0.015 | Tree loss: 0.698 | Accuracy: 0.504500 | 1.089 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 011 | Total loss: 0.698 | Reg loss: 0.015 | Tree loss: 0.698 | Accuracy: 0.519500 | 0.656 sec/iter\n",
      "Epoch: 00 | Batch: 002 / 011 | Total loss: 0.698 | Reg loss: 0.014 | Tree loss: 0.698 | Accuracy: 0.490000 | 0.511 sec/iter\n",
      "Epoch: 00 | Batch: 003 / 011 | Total loss: 0.691 | Reg loss: 0.014 | Tree loss: 0.691 | Accuracy: 0.539000 | 0.447 sec/iter\n",
      "Epoch: 00 | Batch: 004 / 011 | Total loss: 0.693 | Reg loss: 0.014 | Tree loss: 0.693 | Accuracy: 0.540000 | 0.41 sec/iter\n",
      "Epoch: 00 | Batch: 005 / 011 | Total loss: 0.690 | Reg loss: 0.014 | Tree loss: 0.690 | Accuracy: 0.564500 | 0.388 sec/iter\n",
      "Epoch: 00 | Batch: 006 / 011 | Total loss: 0.686 | Reg loss: 0.014 | Tree loss: 0.686 | Accuracy: 0.580500 | 0.374 sec/iter\n",
      "Epoch: 00 | Batch: 007 / 011 | Total loss: 0.683 | Reg loss: 0.014 | Tree loss: 0.683 | Accuracy: 0.602500 | 0.363 sec/iter\n",
      "Epoch: 00 | Batch: 008 / 011 | Total loss: 0.682 | Reg loss: 0.014 | Tree loss: 0.682 | Accuracy: 0.588500 | 0.355 sec/iter\n",
      "Epoch: 00 | Batch: 009 / 011 | Total loss: 0.685 | Reg loss: 0.013 | Tree loss: 0.685 | Accuracy: 0.574500 | 0.348 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 011 | Total loss: 0.683 | Reg loss: 0.013 | Tree loss: 0.683 | Accuracy: 0.597270 | 0.341 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 01 | Batch: 000 / 011 | Total loss: 0.694 | Reg loss: 0.012 | Tree loss: 0.694 | Accuracy: 0.633500 | 0.922 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 011 | Total loss: 0.693 | Reg loss: 0.012 | Tree loss: 0.693 | Accuracy: 0.648500 | 0.875 sec/iter\n",
      "Epoch: 01 | Batch: 002 / 011 | Total loss: 0.690 | Reg loss: 0.012 | Tree loss: 0.690 | Accuracy: 0.603000 | 0.835 sec/iter\n",
      "Epoch: 01 | Batch: 003 / 011 | Total loss: 0.690 | Reg loss: 0.012 | Tree loss: 0.690 | Accuracy: 0.580500 | 0.8 sec/iter\n",
      "Epoch: 01 | Batch: 004 / 011 | Total loss: 0.683 | Reg loss: 0.012 | Tree loss: 0.683 | Accuracy: 0.589500 | 0.769 sec/iter\n",
      "Epoch: 01 | Batch: 005 / 011 | Total loss: 0.687 | Reg loss: 0.013 | Tree loss: 0.687 | Accuracy: 0.562500 | 0.742 sec/iter\n",
      "Epoch: 01 | Batch: 006 / 011 | Total loss: 0.688 | Reg loss: 0.013 | Tree loss: 0.688 | Accuracy: 0.555000 | 0.719 sec/iter\n",
      "Epoch: 01 | Batch: 007 / 011 | Total loss: 0.687 | Reg loss: 0.013 | Tree loss: 0.687 | Accuracy: 0.554000 | 0.697 sec/iter\n",
      "Epoch: 01 | Batch: 008 / 011 | Total loss: 0.685 | Reg loss: 0.013 | Tree loss: 0.685 | Accuracy: 0.559500 | 0.676 sec/iter\n",
      "Epoch: 01 | Batch: 009 / 011 | Total loss: 0.680 | Reg loss: 0.013 | Tree loss: 0.680 | Accuracy: 0.592500 | 0.657 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 011 | Total loss: 0.680 | Reg loss: 0.013 | Tree loss: 0.680 | Accuracy: 0.651877 | 0.638 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 02 | Batch: 000 / 011 | Total loss: 0.696 | Reg loss: 0.012 | Tree loss: 0.696 | Accuracy: 0.620500 | 0.7 sec/iter\n",
      "Epoch: 02 | Batch: 001 / 011 | Total loss: 0.690 | Reg loss: 0.012 | Tree loss: 0.690 | Accuracy: 0.655000 | 0.684 sec/iter\n",
      "Epoch: 02 | Batch: 002 / 011 | Total loss: 0.689 | Reg loss: 0.012 | Tree loss: 0.689 | Accuracy: 0.682500 | 0.67 sec/iter\n",
      "Epoch: 02 | Batch: 003 / 011 | Total loss: 0.689 | Reg loss: 0.012 | Tree loss: 0.689 | Accuracy: 0.604000 | 0.656 sec/iter\n",
      "Epoch: 02 | Batch: 004 / 011 | Total loss: 0.685 | Reg loss: 0.012 | Tree loss: 0.685 | Accuracy: 0.597000 | 0.643 sec/iter\n",
      "Epoch: 02 | Batch: 005 / 011 | Total loss: 0.684 | Reg loss: 0.012 | Tree loss: 0.684 | Accuracy: 0.582000 | 0.632 sec/iter\n",
      "Epoch: 02 | Batch: 006 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.596500 | 0.621 sec/iter\n",
      "Epoch: 02 | Batch: 007 / 011 | Total loss: 0.682 | Reg loss: 0.012 | Tree loss: 0.682 | Accuracy: 0.589500 | 0.609 sec/iter\n",
      "Epoch: 02 | Batch: 008 / 011 | Total loss: 0.682 | Reg loss: 0.012 | Tree loss: 0.682 | Accuracy: 0.592000 | 0.598 sec/iter\n",
      "Epoch: 02 | Batch: 009 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.591000 | 0.588 sec/iter\n",
      "Epoch: 02 | Batch: 010 / 011 | Total loss: 0.684 | Reg loss: 0.012 | Tree loss: 0.684 | Accuracy: 0.597270 | 0.579 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 03 | Batch: 000 / 011 | Total loss: 0.694 | Reg loss: 0.012 | Tree loss: 0.694 | Accuracy: 0.617000 | 0.702 sec/iter\n",
      "Epoch: 03 | Batch: 001 / 011 | Total loss: 0.691 | Reg loss: 0.012 | Tree loss: 0.691 | Accuracy: 0.551500 | 0.689 sec/iter\n",
      "Epoch: 03 | Batch: 002 / 011 | Total loss: 0.691 | Reg loss: 0.012 | Tree loss: 0.691 | Accuracy: 0.554000 | 0.676 sec/iter\n",
      "Epoch: 03 | Batch: 003 / 011 | Total loss: 0.690 | Reg loss: 0.012 | Tree loss: 0.690 | Accuracy: 0.655500 | 0.664 sec/iter\n",
      "Epoch: 03 | Batch: 004 / 011 | Total loss: 0.685 | Reg loss: 0.012 | Tree loss: 0.685 | Accuracy: 0.719500 | 0.653 sec/iter\n",
      "Epoch: 03 | Batch: 005 / 011 | Total loss: 0.683 | Reg loss: 0.012 | Tree loss: 0.683 | Accuracy: 0.676000 | 0.643 sec/iter\n",
      "Epoch: 03 | Batch: 006 / 011 | Total loss: 0.683 | Reg loss: 0.012 | Tree loss: 0.683 | Accuracy: 0.618000 | 0.634 sec/iter\n",
      "Epoch: 03 | Batch: 007 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.597500 | 0.626 sec/iter\n",
      "Epoch: 03 | Batch: 008 / 011 | Total loss: 0.679 | Reg loss: 0.012 | Tree loss: 0.679 | Accuracy: 0.589000 | 0.617 sec/iter\n",
      "Epoch: 03 | Batch: 009 / 011 | Total loss: 0.671 | Reg loss: 0.012 | Tree loss: 0.671 | Accuracy: 0.602500 | 0.609 sec/iter\n",
      "Epoch: 03 | Batch: 010 / 011 | Total loss: 0.677 | Reg loss: 0.012 | Tree loss: 0.677 | Accuracy: 0.593857 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 04 | Batch: 000 / 011 | Total loss: 0.691 | Reg loss: 0.012 | Tree loss: 0.691 | Accuracy: 0.643500 | 0.702 sec/iter\n",
      "Epoch: 04 | Batch: 001 / 011 | Total loss: 0.687 | Reg loss: 0.012 | Tree loss: 0.687 | Accuracy: 0.687000 | 0.693 sec/iter\n",
      "Epoch: 04 | Batch: 002 / 011 | Total loss: 0.685 | Reg loss: 0.012 | Tree loss: 0.685 | Accuracy: 0.652000 | 0.684 sec/iter\n",
      "Epoch: 04 | Batch: 003 / 011 | Total loss: 0.683 | Reg loss: 0.012 | Tree loss: 0.683 | Accuracy: 0.613000 | 0.676 sec/iter\n",
      "Epoch: 04 | Batch: 004 / 011 | Total loss: 0.682 | Reg loss: 0.012 | Tree loss: 0.682 | Accuracy: 0.593500 | 0.667 sec/iter\n",
      "Epoch: 04 | Batch: 005 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.596000 | 0.659 sec/iter\n",
      "Epoch: 04 | Batch: 006 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.580500 | 0.652 sec/iter\n",
      "Epoch: 04 | Batch: 007 / 011 | Total loss: 0.678 | Reg loss: 0.012 | Tree loss: 0.678 | Accuracy: 0.584500 | 0.644 sec/iter\n",
      "Epoch: 04 | Batch: 008 / 011 | Total loss: 0.681 | Reg loss: 0.012 | Tree loss: 0.681 | Accuracy: 0.569500 | 0.636 sec/iter\n",
      "Epoch: 04 | Batch: 009 / 011 | Total loss: 0.681 | Reg loss: 0.012 | Tree loss: 0.681 | Accuracy: 0.574000 | 0.629 sec/iter\n",
      "Epoch: 04 | Batch: 010 / 011 | Total loss: 0.662 | Reg loss: 0.012 | Tree loss: 0.662 | Accuracy: 0.655290 | 0.622 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 05 | Batch: 000 / 011 | Total loss: 0.688 | Reg loss: 0.012 | Tree loss: 0.688 | Accuracy: 0.653500 | 0.694 sec/iter\n",
      "Epoch: 05 | Batch: 001 / 011 | Total loss: 0.686 | Reg loss: 0.012 | Tree loss: 0.686 | Accuracy: 0.681000 | 0.687 sec/iter\n",
      "Epoch: 05 | Batch: 002 / 011 | Total loss: 0.684 | Reg loss: 0.012 | Tree loss: 0.684 | Accuracy: 0.721500 | 0.68 sec/iter\n",
      "Epoch: 05 | Batch: 003 / 011 | Total loss: 0.684 | Reg loss: 0.012 | Tree loss: 0.684 | Accuracy: 0.676000 | 0.673 sec/iter\n",
      "Epoch: 05 | Batch: 004 / 011 | Total loss: 0.681 | Reg loss: 0.012 | Tree loss: 0.681 | Accuracy: 0.628000 | 0.667 sec/iter\n",
      "Epoch: 05 | Batch: 005 / 011 | Total loss: 0.676 | Reg loss: 0.012 | Tree loss: 0.676 | Accuracy: 0.618500 | 0.66 sec/iter\n",
      "Epoch: 05 | Batch: 006 / 011 | Total loss: 0.679 | Reg loss: 0.012 | Tree loss: 0.679 | Accuracy: 0.587500 | 0.654 sec/iter\n",
      "Epoch: 05 | Batch: 007 / 011 | Total loss: 0.681 | Reg loss: 0.012 | Tree loss: 0.681 | Accuracy: 0.574500 | 0.648 sec/iter\n",
      "Epoch: 05 | Batch: 008 / 011 | Total loss: 0.678 | Reg loss: 0.012 | Tree loss: 0.678 | Accuracy: 0.575500 | 0.643 sec/iter\n",
      "Epoch: 05 | Batch: 009 / 011 | Total loss: 0.674 | Reg loss: 0.012 | Tree loss: 0.674 | Accuracy: 0.588500 | 0.637 sec/iter\n",
      "Epoch: 05 | Batch: 010 / 011 | Total loss: 0.686 | Reg loss: 0.012 | Tree loss: 0.686 | Accuracy: 0.535836 | 0.632 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 06 | Batch: 000 / 011 | Total loss: 0.685 | Reg loss: 0.012 | Tree loss: 0.685 | Accuracy: 0.678000 | 0.647 sec/iter\n",
      "Epoch: 06 | Batch: 001 / 011 | Total loss: 0.689 | Reg loss: 0.012 | Tree loss: 0.689 | Accuracy: 0.667500 | 0.641 sec/iter\n",
      "Epoch: 06 | Batch: 002 / 011 | Total loss: 0.682 | Reg loss: 0.012 | Tree loss: 0.682 | Accuracy: 0.699500 | 0.636 sec/iter\n",
      "Epoch: 06 | Batch: 003 / 011 | Total loss: 0.685 | Reg loss: 0.012 | Tree loss: 0.685 | Accuracy: 0.685500 | 0.63 sec/iter\n",
      "Epoch: 06 | Batch: 004 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.691000 | 0.625 sec/iter\n",
      "Epoch: 06 | Batch: 005 / 011 | Total loss: 0.675 | Reg loss: 0.012 | Tree loss: 0.675 | Accuracy: 0.643000 | 0.621 sec/iter\n",
      "Epoch: 06 | Batch: 006 / 011 | Total loss: 0.677 | Reg loss: 0.012 | Tree loss: 0.677 | Accuracy: 0.614500 | 0.616 sec/iter\n",
      "Epoch: 06 | Batch: 007 / 011 | Total loss: 0.675 | Reg loss: 0.012 | Tree loss: 0.675 | Accuracy: 0.595000 | 0.611 sec/iter\n",
      "Epoch: 06 | Batch: 008 / 011 | Total loss: 0.674 | Reg loss: 0.012 | Tree loss: 0.674 | Accuracy: 0.588000 | 0.607 sec/iter\n",
      "Epoch: 06 | Batch: 009 / 011 | Total loss: 0.671 | Reg loss: 0.012 | Tree loss: 0.671 | Accuracy: 0.602000 | 0.603 sec/iter\n",
      "Epoch: 06 | Batch: 010 / 011 | Total loss: 0.676 | Reg loss: 0.012 | Tree loss: 0.676 | Accuracy: 0.573379 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 07 | Batch: 000 / 011 | Total loss: 0.684 | Reg loss: 0.012 | Tree loss: 0.684 | Accuracy: 0.692000 | 0.656 sec/iter\n",
      "Epoch: 07 | Batch: 001 / 011 | Total loss: 0.683 | Reg loss: 0.012 | Tree loss: 0.683 | Accuracy: 0.700500 | 0.651 sec/iter\n",
      "Epoch: 07 | Batch: 002 / 011 | Total loss: 0.683 | Reg loss: 0.012 | Tree loss: 0.683 | Accuracy: 0.700500 | 0.646 sec/iter\n",
      "Epoch: 07 | Batch: 003 / 011 | Total loss: 0.677 | Reg loss: 0.012 | Tree loss: 0.677 | Accuracy: 0.698000 | 0.642 sec/iter\n",
      "Epoch: 07 | Batch: 004 / 011 | Total loss: 0.677 | Reg loss: 0.012 | Tree loss: 0.677 | Accuracy: 0.650000 | 0.637 sec/iter\n",
      "Epoch: 07 | Batch: 005 / 011 | Total loss: 0.679 | Reg loss: 0.012 | Tree loss: 0.679 | Accuracy: 0.609000 | 0.632 sec/iter\n",
      "Epoch: 07 | Batch: 006 / 011 | Total loss: 0.670 | Reg loss: 0.012 | Tree loss: 0.670 | Accuracy: 0.622000 | 0.628 sec/iter\n",
      "Epoch: 07 | Batch: 007 / 011 | Total loss: 0.672 | Reg loss: 0.012 | Tree loss: 0.672 | Accuracy: 0.590500 | 0.623 sec/iter\n",
      "Epoch: 07 | Batch: 008 / 011 | Total loss: 0.675 | Reg loss: 0.012 | Tree loss: 0.675 | Accuracy: 0.574500 | 0.619 sec/iter\n",
      "Epoch: 07 | Batch: 009 / 011 | Total loss: 0.670 | Reg loss: 0.012 | Tree loss: 0.670 | Accuracy: 0.592000 | 0.615 sec/iter\n",
      "Epoch: 07 | Batch: 010 / 011 | Total loss: 0.664 | Reg loss: 0.012 | Tree loss: 0.664 | Accuracy: 0.587031 | 0.611 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 08 | Batch: 000 / 011 | Total loss: 0.681 | Reg loss: 0.012 | Tree loss: 0.681 | Accuracy: 0.689000 | 0.661 sec/iter\n",
      "Epoch: 08 | Batch: 001 / 011 | Total loss: 0.682 | Reg loss: 0.012 | Tree loss: 0.682 | Accuracy: 0.690000 | 0.657 sec/iter\n",
      "Epoch: 08 | Batch: 002 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.715000 | 0.653 sec/iter\n",
      "Epoch: 08 | Batch: 003 / 011 | Total loss: 0.673 | Reg loss: 0.012 | Tree loss: 0.673 | Accuracy: 0.722500 | 0.649 sec/iter\n",
      "Epoch: 08 | Batch: 004 / 011 | Total loss: 0.669 | Reg loss: 0.012 | Tree loss: 0.669 | Accuracy: 0.675500 | 0.645 sec/iter\n",
      "Epoch: 08 | Batch: 005 / 011 | Total loss: 0.673 | Reg loss: 0.012 | Tree loss: 0.673 | Accuracy: 0.616500 | 0.641 sec/iter\n",
      "Epoch: 08 | Batch: 006 / 011 | Total loss: 0.667 | Reg loss: 0.012 | Tree loss: 0.667 | Accuracy: 0.619000 | 0.637 sec/iter\n",
      "Epoch: 08 | Batch: 007 / 011 | Total loss: 0.673 | Reg loss: 0.012 | Tree loss: 0.673 | Accuracy: 0.580000 | 0.634 sec/iter\n",
      "Epoch: 08 | Batch: 008 / 011 | Total loss: 0.668 | Reg loss: 0.012 | Tree loss: 0.668 | Accuracy: 0.594500 | 0.63 sec/iter\n",
      "Epoch: 08 | Batch: 009 / 011 | Total loss: 0.664 | Reg loss: 0.012 | Tree loss: 0.664 | Accuracy: 0.597500 | 0.626 sec/iter\n",
      "Epoch: 08 | Batch: 010 / 011 | Total loss: 0.661 | Reg loss: 0.012 | Tree loss: 0.661 | Accuracy: 0.576792 | 0.623 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 09 | Batch: 000 / 011 | Total loss: 0.682 | Reg loss: 0.012 | Tree loss: 0.682 | Accuracy: 0.684500 | 0.627 sec/iter\n",
      "Epoch: 09 | Batch: 001 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.673500 | 0.623 sec/iter\n",
      "Epoch: 09 | Batch: 002 / 011 | Total loss: 0.674 | Reg loss: 0.012 | Tree loss: 0.674 | Accuracy: 0.737000 | 0.62 sec/iter\n",
      "Epoch: 09 | Batch: 003 / 011 | Total loss: 0.672 | Reg loss: 0.012 | Tree loss: 0.672 | Accuracy: 0.705000 | 0.617 sec/iter\n",
      "Epoch: 09 | Batch: 004 / 011 | Total loss: 0.666 | Reg loss: 0.012 | Tree loss: 0.666 | Accuracy: 0.701500 | 0.614 sec/iter\n",
      "Epoch: 09 | Batch: 005 / 011 | Total loss: 0.665 | Reg loss: 0.012 | Tree loss: 0.665 | Accuracy: 0.655000 | 0.61 sec/iter\n",
      "Epoch: 09 | Batch: 006 / 011 | Total loss: 0.666 | Reg loss: 0.012 | Tree loss: 0.666 | Accuracy: 0.621000 | 0.607 sec/iter\n",
      "Epoch: 09 | Batch: 007 / 011 | Total loss: 0.666 | Reg loss: 0.012 | Tree loss: 0.666 | Accuracy: 0.593000 | 0.605 sec/iter\n",
      "Epoch: 09 | Batch: 008 / 011 | Total loss: 0.660 | Reg loss: 0.012 | Tree loss: 0.660 | Accuracy: 0.601500 | 0.602 sec/iter\n",
      "Epoch: 09 | Batch: 009 / 011 | Total loss: 0.662 | Reg loss: 0.013 | Tree loss: 0.662 | Accuracy: 0.592000 | 0.599 sec/iter\n",
      "Epoch: 09 | Batch: 010 / 011 | Total loss: 0.656 | Reg loss: 0.013 | Tree loss: 0.656 | Accuracy: 0.627986 | 0.596 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 10 | Batch: 000 / 011 | Total loss: 0.680 | Reg loss: 0.012 | Tree loss: 0.680 | Accuracy: 0.676500 | 0.642 sec/iter\n",
      "Epoch: 10 | Batch: 001 / 011 | Total loss: 0.677 | Reg loss: 0.012 | Tree loss: 0.677 | Accuracy: 0.684500 | 0.639 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Batch: 002 / 011 | Total loss: 0.669 | Reg loss: 0.012 | Tree loss: 0.669 | Accuracy: 0.723500 | 0.636 sec/iter\n",
      "Epoch: 10 | Batch: 003 / 011 | Total loss: 0.669 | Reg loss: 0.012 | Tree loss: 0.669 | Accuracy: 0.716000 | 0.633 sec/iter\n",
      "Epoch: 10 | Batch: 004 / 011 | Total loss: 0.663 | Reg loss: 0.012 | Tree loss: 0.663 | Accuracy: 0.699000 | 0.63 sec/iter\n",
      "Epoch: 10 | Batch: 005 / 011 | Total loss: 0.656 | Reg loss: 0.012 | Tree loss: 0.656 | Accuracy: 0.667000 | 0.627 sec/iter\n",
      "Epoch: 10 | Batch: 006 / 011 | Total loss: 0.667 | Reg loss: 0.012 | Tree loss: 0.667 | Accuracy: 0.592000 | 0.624 sec/iter\n",
      "Epoch: 10 | Batch: 007 / 011 | Total loss: 0.655 | Reg loss: 0.013 | Tree loss: 0.655 | Accuracy: 0.604500 | 0.622 sec/iter\n",
      "Epoch: 10 | Batch: 008 / 011 | Total loss: 0.654 | Reg loss: 0.013 | Tree loss: 0.654 | Accuracy: 0.614000 | 0.619 sec/iter\n",
      "Epoch: 10 | Batch: 009 / 011 | Total loss: 0.657 | Reg loss: 0.013 | Tree loss: 0.657 | Accuracy: 0.589000 | 0.616 sec/iter\n",
      "Epoch: 10 | Batch: 010 / 011 | Total loss: 0.647 | Reg loss: 0.013 | Tree loss: 0.647 | Accuracy: 0.631399 | 0.614 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 11 | Batch: 000 / 011 | Total loss: 0.670 | Reg loss: 0.012 | Tree loss: 0.670 | Accuracy: 0.706000 | 0.653 sec/iter\n",
      "Epoch: 11 | Batch: 001 / 011 | Total loss: 0.676 | Reg loss: 0.012 | Tree loss: 0.676 | Accuracy: 0.672500 | 0.65 sec/iter\n",
      "Epoch: 11 | Batch: 002 / 011 | Total loss: 0.670 | Reg loss: 0.012 | Tree loss: 0.670 | Accuracy: 0.706000 | 0.647 sec/iter\n",
      "Epoch: 11 | Batch: 003 / 011 | Total loss: 0.661 | Reg loss: 0.012 | Tree loss: 0.661 | Accuracy: 0.720500 | 0.644 sec/iter\n",
      "Epoch: 11 | Batch: 004 / 011 | Total loss: 0.660 | Reg loss: 0.013 | Tree loss: 0.660 | Accuracy: 0.685500 | 0.641 sec/iter\n",
      "Epoch: 11 | Batch: 005 / 011 | Total loss: 0.653 | Reg loss: 0.013 | Tree loss: 0.653 | Accuracy: 0.651500 | 0.638 sec/iter\n",
      "Epoch: 11 | Batch: 006 / 011 | Total loss: 0.655 | Reg loss: 0.013 | Tree loss: 0.655 | Accuracy: 0.605500 | 0.635 sec/iter\n",
      "Epoch: 11 | Batch: 007 / 011 | Total loss: 0.649 | Reg loss: 0.013 | Tree loss: 0.649 | Accuracy: 0.619500 | 0.632 sec/iter\n",
      "Epoch: 11 | Batch: 008 / 011 | Total loss: 0.655 | Reg loss: 0.013 | Tree loss: 0.655 | Accuracy: 0.603000 | 0.629 sec/iter\n",
      "Epoch: 11 | Batch: 009 / 011 | Total loss: 0.640 | Reg loss: 0.013 | Tree loss: 0.640 | Accuracy: 0.646500 | 0.626 sec/iter\n",
      "Epoch: 11 | Batch: 010 / 011 | Total loss: 0.638 | Reg loss: 0.013 | Tree loss: 0.638 | Accuracy: 0.675768 | 0.623 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 12 | Batch: 000 / 011 | Total loss: 0.671 | Reg loss: 0.013 | Tree loss: 0.671 | Accuracy: 0.710500 | 0.657 sec/iter\n",
      "Epoch: 12 | Batch: 001 / 011 | Total loss: 0.666 | Reg loss: 0.013 | Tree loss: 0.666 | Accuracy: 0.704000 | 0.654 sec/iter\n",
      "Epoch: 12 | Batch: 002 / 011 | Total loss: 0.664 | Reg loss: 0.013 | Tree loss: 0.664 | Accuracy: 0.720500 | 0.651 sec/iter\n",
      "Epoch: 12 | Batch: 003 / 011 | Total loss: 0.660 | Reg loss: 0.013 | Tree loss: 0.660 | Accuracy: 0.722000 | 0.649 sec/iter\n",
      "Epoch: 12 | Batch: 004 / 011 | Total loss: 0.656 | Reg loss: 0.013 | Tree loss: 0.656 | Accuracy: 0.711500 | 0.646 sec/iter\n",
      "Epoch: 12 | Batch: 005 / 011 | Total loss: 0.647 | Reg loss: 0.013 | Tree loss: 0.647 | Accuracy: 0.666000 | 0.643 sec/iter\n",
      "Epoch: 12 | Batch: 006 / 011 | Total loss: 0.642 | Reg loss: 0.013 | Tree loss: 0.642 | Accuracy: 0.653500 | 0.64 sec/iter\n",
      "Epoch: 12 | Batch: 007 / 011 | Total loss: 0.635 | Reg loss: 0.013 | Tree loss: 0.635 | Accuracy: 0.660500 | 0.637 sec/iter\n",
      "Epoch: 12 | Batch: 008 / 011 | Total loss: 0.643 | Reg loss: 0.013 | Tree loss: 0.643 | Accuracy: 0.630500 | 0.635 sec/iter\n",
      "Epoch: 12 | Batch: 009 / 011 | Total loss: 0.631 | Reg loss: 0.013 | Tree loss: 0.631 | Accuracy: 0.648500 | 0.632 sec/iter\n",
      "Epoch: 12 | Batch: 010 / 011 | Total loss: 0.634 | Reg loss: 0.013 | Tree loss: 0.634 | Accuracy: 0.655290 | 0.629 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 13 | Batch: 000 / 011 | Total loss: 0.663 | Reg loss: 0.013 | Tree loss: 0.663 | Accuracy: 0.718500 | 0.651 sec/iter\n",
      "Epoch: 13 | Batch: 001 / 011 | Total loss: 0.661 | Reg loss: 0.013 | Tree loss: 0.661 | Accuracy: 0.707000 | 0.649 sec/iter\n",
      "Epoch: 13 | Batch: 002 / 011 | Total loss: 0.660 | Reg loss: 0.013 | Tree loss: 0.660 | Accuracy: 0.720000 | 0.646 sec/iter\n",
      "Epoch: 13 | Batch: 003 / 011 | Total loss: 0.651 | Reg loss: 0.013 | Tree loss: 0.651 | Accuracy: 0.716000 | 0.643 sec/iter\n",
      "Epoch: 13 | Batch: 004 / 011 | Total loss: 0.642 | Reg loss: 0.013 | Tree loss: 0.642 | Accuracy: 0.690500 | 0.64 sec/iter\n",
      "Epoch: 13 | Batch: 005 / 011 | Total loss: 0.647 | Reg loss: 0.013 | Tree loss: 0.647 | Accuracy: 0.629500 | 0.638 sec/iter\n",
      "Epoch: 13 | Batch: 006 / 011 | Total loss: 0.638 | Reg loss: 0.013 | Tree loss: 0.638 | Accuracy: 0.637000 | 0.635 sec/iter\n",
      "Epoch: 13 | Batch: 007 / 011 | Total loss: 0.635 | Reg loss: 0.013 | Tree loss: 0.635 | Accuracy: 0.644000 | 0.633 sec/iter\n",
      "Epoch: 13 | Batch: 008 / 011 | Total loss: 0.628 | Reg loss: 0.013 | Tree loss: 0.628 | Accuracy: 0.679000 | 0.63 sec/iter\n",
      "Epoch: 13 | Batch: 009 / 011 | Total loss: 0.624 | Reg loss: 0.013 | Tree loss: 0.624 | Accuracy: 0.703000 | 0.627 sec/iter\n",
      "Epoch: 13 | Batch: 010 / 011 | Total loss: 0.628 | Reg loss: 0.013 | Tree loss: 0.628 | Accuracy: 0.679181 | 0.625 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 14 | Batch: 000 / 011 | Total loss: 0.660 | Reg loss: 0.013 | Tree loss: 0.660 | Accuracy: 0.715500 | 0.625 sec/iter\n",
      "Epoch: 14 | Batch: 001 / 011 | Total loss: 0.659 | Reg loss: 0.013 | Tree loss: 0.659 | Accuracy: 0.703500 | 0.622 sec/iter\n",
      "Epoch: 14 | Batch: 002 / 011 | Total loss: 0.653 | Reg loss: 0.013 | Tree loss: 0.653 | Accuracy: 0.725500 | 0.62 sec/iter\n",
      "Epoch: 14 | Batch: 003 / 011 | Total loss: 0.643 | Reg loss: 0.013 | Tree loss: 0.643 | Accuracy: 0.725500 | 0.618 sec/iter\n",
      "Epoch: 14 | Batch: 004 / 011 | Total loss: 0.636 | Reg loss: 0.013 | Tree loss: 0.636 | Accuracy: 0.698500 | 0.616 sec/iter\n",
      "Epoch: 14 | Batch: 005 / 011 | Total loss: 0.633 | Reg loss: 0.013 | Tree loss: 0.633 | Accuracy: 0.665500 | 0.613 sec/iter\n",
      "Epoch: 14 | Batch: 006 / 011 | Total loss: 0.631 | Reg loss: 0.013 | Tree loss: 0.631 | Accuracy: 0.642000 | 0.611 sec/iter\n",
      "Epoch: 14 | Batch: 007 / 011 | Total loss: 0.628 | Reg loss: 0.013 | Tree loss: 0.628 | Accuracy: 0.658000 | 0.609 sec/iter\n",
      "Epoch: 14 | Batch: 008 / 011 | Total loss: 0.618 | Reg loss: 0.013 | Tree loss: 0.618 | Accuracy: 0.702500 | 0.607 sec/iter\n",
      "Epoch: 14 | Batch: 009 / 011 | Total loss: 0.610 | Reg loss: 0.014 | Tree loss: 0.610 | Accuracy: 0.708000 | 0.605 sec/iter\n",
      "Epoch: 14 | Batch: 010 / 011 | Total loss: 0.632 | Reg loss: 0.014 | Tree loss: 0.632 | Accuracy: 0.692833 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 15 | Batch: 000 / 011 | Total loss: 0.655 | Reg loss: 0.013 | Tree loss: 0.655 | Accuracy: 0.715000 | 0.613 sec/iter\n",
      "Epoch: 15 | Batch: 001 / 011 | Total loss: 0.647 | Reg loss: 0.013 | Tree loss: 0.647 | Accuracy: 0.722000 | 0.61 sec/iter\n",
      "Epoch: 15 | Batch: 002 / 011 | Total loss: 0.642 | Reg loss: 0.013 | Tree loss: 0.642 | Accuracy: 0.721000 | 0.608 sec/iter\n",
      "Epoch: 15 | Batch: 003 / 011 | Total loss: 0.639 | Reg loss: 0.013 | Tree loss: 0.639 | Accuracy: 0.714500 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Batch: 004 / 011 | Total loss: 0.633 | Reg loss: 0.013 | Tree loss: 0.633 | Accuracy: 0.695000 | 0.604 sec/iter\n",
      "Epoch: 15 | Batch: 005 / 011 | Total loss: 0.629 | Reg loss: 0.013 | Tree loss: 0.629 | Accuracy: 0.672500 | 0.602 sec/iter\n",
      "Epoch: 15 | Batch: 006 / 011 | Total loss: 0.620 | Reg loss: 0.013 | Tree loss: 0.620 | Accuracy: 0.672500 | 0.6 sec/iter\n",
      "Epoch: 15 | Batch: 007 / 011 | Total loss: 0.620 | Reg loss: 0.013 | Tree loss: 0.620 | Accuracy: 0.681000 | 0.598 sec/iter\n",
      "Epoch: 15 | Batch: 008 / 011 | Total loss: 0.608 | Reg loss: 0.014 | Tree loss: 0.608 | Accuracy: 0.710000 | 0.596 sec/iter\n",
      "Epoch: 15 | Batch: 009 / 011 | Total loss: 0.607 | Reg loss: 0.014 | Tree loss: 0.607 | Accuracy: 0.731500 | 0.594 sec/iter\n",
      "Epoch: 15 | Batch: 010 / 011 | Total loss: 0.597 | Reg loss: 0.014 | Tree loss: 0.597 | Accuracy: 0.778157 | 0.592 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 16 | Batch: 000 / 011 | Total loss: 0.647 | Reg loss: 0.013 | Tree loss: 0.647 | Accuracy: 0.733500 | 0.605 sec/iter\n",
      "Epoch: 16 | Batch: 001 / 011 | Total loss: 0.644 | Reg loss: 0.013 | Tree loss: 0.644 | Accuracy: 0.703000 | 0.603 sec/iter\n",
      "Epoch: 16 | Batch: 002 / 011 | Total loss: 0.631 | Reg loss: 0.013 | Tree loss: 0.631 | Accuracy: 0.717500 | 0.601 sec/iter\n",
      "Epoch: 16 | Batch: 003 / 011 | Total loss: 0.633 | Reg loss: 0.013 | Tree loss: 0.633 | Accuracy: 0.681500 | 0.599 sec/iter\n",
      "Epoch: 16 | Batch: 004 / 011 | Total loss: 0.622 | Reg loss: 0.013 | Tree loss: 0.622 | Accuracy: 0.658500 | 0.597 sec/iter\n",
      "Epoch: 16 | Batch: 005 / 011 | Total loss: 0.621 | Reg loss: 0.013 | Tree loss: 0.621 | Accuracy: 0.661500 | 0.595 sec/iter\n",
      "Epoch: 16 | Batch: 006 / 011 | Total loss: 0.614 | Reg loss: 0.013 | Tree loss: 0.614 | Accuracy: 0.692000 | 0.593 sec/iter\n",
      "Epoch: 16 | Batch: 007 / 011 | Total loss: 0.601 | Reg loss: 0.014 | Tree loss: 0.601 | Accuracy: 0.712000 | 0.591 sec/iter\n",
      "Epoch: 16 | Batch: 008 / 011 | Total loss: 0.597 | Reg loss: 0.014 | Tree loss: 0.597 | Accuracy: 0.737000 | 0.589 sec/iter\n",
      "Epoch: 16 | Batch: 009 / 011 | Total loss: 0.597 | Reg loss: 0.014 | Tree loss: 0.597 | Accuracy: 0.756000 | 0.587 sec/iter\n",
      "Epoch: 16 | Batch: 010 / 011 | Total loss: 0.601 | Reg loss: 0.014 | Tree loss: 0.601 | Accuracy: 0.764505 | 0.586 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 17 | Batch: 000 / 011 | Total loss: 0.645 | Reg loss: 0.013 | Tree loss: 0.645 | Accuracy: 0.716000 | 0.608 sec/iter\n",
      "Epoch: 17 | Batch: 001 / 011 | Total loss: 0.637 | Reg loss: 0.013 | Tree loss: 0.637 | Accuracy: 0.718500 | 0.607 sec/iter\n",
      "Epoch: 17 | Batch: 002 / 011 | Total loss: 0.630 | Reg loss: 0.013 | Tree loss: 0.630 | Accuracy: 0.716000 | 0.605 sec/iter\n",
      "Epoch: 17 | Batch: 003 / 011 | Total loss: 0.623 | Reg loss: 0.013 | Tree loss: 0.623 | Accuracy: 0.692500 | 0.603 sec/iter\n",
      "Epoch: 17 | Batch: 004 / 011 | Total loss: 0.607 | Reg loss: 0.013 | Tree loss: 0.607 | Accuracy: 0.695000 | 0.601 sec/iter\n",
      "Epoch: 17 | Batch: 005 / 011 | Total loss: 0.597 | Reg loss: 0.013 | Tree loss: 0.597 | Accuracy: 0.698000 | 0.599 sec/iter\n",
      "Epoch: 17 | Batch: 006 / 011 | Total loss: 0.609 | Reg loss: 0.014 | Tree loss: 0.609 | Accuracy: 0.686000 | 0.598 sec/iter\n",
      "Epoch: 17 | Batch: 007 / 011 | Total loss: 0.598 | Reg loss: 0.014 | Tree loss: 0.598 | Accuracy: 0.694500 | 0.596 sec/iter\n",
      "Epoch: 17 | Batch: 008 / 011 | Total loss: 0.585 | Reg loss: 0.014 | Tree loss: 0.585 | Accuracy: 0.754500 | 0.594 sec/iter\n",
      "Epoch: 17 | Batch: 009 / 011 | Total loss: 0.584 | Reg loss: 0.014 | Tree loss: 0.584 | Accuracy: 0.779000 | 0.592 sec/iter\n",
      "Epoch: 17 | Batch: 010 / 011 | Total loss: 0.589 | Reg loss: 0.014 | Tree loss: 0.589 | Accuracy: 0.771331 | 0.591 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 18 | Batch: 000 / 011 | Total loss: 0.632 | Reg loss: 0.013 | Tree loss: 0.632 | Accuracy: 0.736500 | 0.595 sec/iter\n",
      "Epoch: 18 | Batch: 001 / 011 | Total loss: 0.626 | Reg loss: 0.013 | Tree loss: 0.626 | Accuracy: 0.726000 | 0.593 sec/iter\n",
      "Epoch: 18 | Batch: 002 / 011 | Total loss: 0.622 | Reg loss: 0.013 | Tree loss: 0.622 | Accuracy: 0.690000 | 0.591 sec/iter\n",
      "Epoch: 18 | Batch: 003 / 011 | Total loss: 0.618 | Reg loss: 0.013 | Tree loss: 0.618 | Accuracy: 0.655000 | 0.59 sec/iter\n",
      "Epoch: 18 | Batch: 004 / 011 | Total loss: 0.611 | Reg loss: 0.013 | Tree loss: 0.611 | Accuracy: 0.654500 | 0.588 sec/iter\n",
      "Epoch: 18 | Batch: 005 / 011 | Total loss: 0.609 | Reg loss: 0.014 | Tree loss: 0.609 | Accuracy: 0.659500 | 0.586 sec/iter\n",
      "Epoch: 18 | Batch: 006 / 011 | Total loss: 0.597 | Reg loss: 0.014 | Tree loss: 0.597 | Accuracy: 0.717500 | 0.585 sec/iter\n",
      "Epoch: 18 | Batch: 007 / 011 | Total loss: 0.582 | Reg loss: 0.014 | Tree loss: 0.582 | Accuracy: 0.808000 | 0.583 sec/iter\n",
      "Epoch: 18 | Batch: 008 / 011 | Total loss: 0.583 | Reg loss: 0.014 | Tree loss: 0.583 | Accuracy: 0.808500 | 0.582 sec/iter\n",
      "Epoch: 18 | Batch: 009 / 011 | Total loss: 0.578 | Reg loss: 0.014 | Tree loss: 0.578 | Accuracy: 0.814000 | 0.58 sec/iter\n",
      "Epoch: 18 | Batch: 010 / 011 | Total loss: 0.570 | Reg loss: 0.014 | Tree loss: 0.570 | Accuracy: 0.815700 | 0.579 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 19 | Batch: 000 / 011 | Total loss: 0.625 | Reg loss: 0.013 | Tree loss: 0.625 | Accuracy: 0.719500 | 0.609 sec/iter\n",
      "Epoch: 19 | Batch: 001 / 011 | Total loss: 0.626 | Reg loss: 0.013 | Tree loss: 0.626 | Accuracy: 0.698000 | 0.608 sec/iter\n",
      "Epoch: 19 | Batch: 002 / 011 | Total loss: 0.618 | Reg loss: 0.013 | Tree loss: 0.618 | Accuracy: 0.685000 | 0.606 sec/iter\n",
      "Epoch: 19 | Batch: 003 / 011 | Total loss: 0.612 | Reg loss: 0.013 | Tree loss: 0.612 | Accuracy: 0.669000 | 0.605 sec/iter\n",
      "Epoch: 19 | Batch: 004 / 011 | Total loss: 0.609 | Reg loss: 0.014 | Tree loss: 0.609 | Accuracy: 0.657500 | 0.603 sec/iter\n",
      "Epoch: 19 | Batch: 005 / 011 | Total loss: 0.592 | Reg loss: 0.014 | Tree loss: 0.592 | Accuracy: 0.694500 | 0.602 sec/iter\n",
      "Epoch: 19 | Batch: 006 / 011 | Total loss: 0.580 | Reg loss: 0.014 | Tree loss: 0.580 | Accuracy: 0.720500 | 0.6 sec/iter\n",
      "Epoch: 19 | Batch: 007 / 011 | Total loss: 0.578 | Reg loss: 0.014 | Tree loss: 0.578 | Accuracy: 0.765000 | 0.599 sec/iter\n",
      "Epoch: 19 | Batch: 008 / 011 | Total loss: 0.574 | Reg loss: 0.014 | Tree loss: 0.574 | Accuracy: 0.802000 | 0.597 sec/iter\n",
      "Epoch: 19 | Batch: 009 / 011 | Total loss: 0.567 | Reg loss: 0.014 | Tree loss: 0.567 | Accuracy: 0.816000 | 0.596 sec/iter\n",
      "Epoch: 19 | Batch: 010 / 011 | Total loss: 0.559 | Reg loss: 0.014 | Tree loss: 0.559 | Accuracy: 0.784983 | 0.594 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 20 | Batch: 000 / 011 | Total loss: 0.631 | Reg loss: 0.013 | Tree loss: 0.631 | Accuracy: 0.710500 | 0.621 sec/iter\n",
      "Epoch: 20 | Batch: 001 / 011 | Total loss: 0.612 | Reg loss: 0.013 | Tree loss: 0.612 | Accuracy: 0.724000 | 0.619 sec/iter\n",
      "Epoch: 20 | Batch: 002 / 011 | Total loss: 0.603 | Reg loss: 0.014 | Tree loss: 0.603 | Accuracy: 0.699500 | 0.618 sec/iter\n",
      "Epoch: 20 | Batch: 003 / 011 | Total loss: 0.615 | Reg loss: 0.014 | Tree loss: 0.615 | Accuracy: 0.646500 | 0.616 sec/iter\n",
      "Epoch: 20 | Batch: 004 / 011 | Total loss: 0.606 | Reg loss: 0.014 | Tree loss: 0.606 | Accuracy: 0.644500 | 0.615 sec/iter\n",
      "Epoch: 20 | Batch: 005 / 011 | Total loss: 0.591 | Reg loss: 0.014 | Tree loss: 0.591 | Accuracy: 0.672500 | 0.613 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Batch: 006 / 011 | Total loss: 0.573 | Reg loss: 0.014 | Tree loss: 0.573 | Accuracy: 0.736500 | 0.612 sec/iter\n",
      "Epoch: 20 | Batch: 007 / 011 | Total loss: 0.560 | Reg loss: 0.014 | Tree loss: 0.560 | Accuracy: 0.815000 | 0.611 sec/iter\n",
      "Epoch: 20 | Batch: 008 / 011 | Total loss: 0.573 | Reg loss: 0.014 | Tree loss: 0.573 | Accuracy: 0.809500 | 0.609 sec/iter\n",
      "Epoch: 20 | Batch: 009 / 011 | Total loss: 0.559 | Reg loss: 0.014 | Tree loss: 0.559 | Accuracy: 0.813000 | 0.608 sec/iter\n",
      "Epoch: 20 | Batch: 010 / 011 | Total loss: 0.553 | Reg loss: 0.014 | Tree loss: 0.553 | Accuracy: 0.798635 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 21 | Batch: 000 / 011 | Total loss: 0.618 | Reg loss: 0.014 | Tree loss: 0.618 | Accuracy: 0.713000 | 0.629 sec/iter\n",
      "Epoch: 21 | Batch: 001 / 011 | Total loss: 0.600 | Reg loss: 0.014 | Tree loss: 0.600 | Accuracy: 0.736000 | 0.627 sec/iter\n",
      "Epoch: 21 | Batch: 002 / 011 | Total loss: 0.607 | Reg loss: 0.014 | Tree loss: 0.607 | Accuracy: 0.707000 | 0.626 sec/iter\n",
      "Epoch: 21 | Batch: 003 / 011 | Total loss: 0.609 | Reg loss: 0.014 | Tree loss: 0.609 | Accuracy: 0.689000 | 0.624 sec/iter\n",
      "Epoch: 21 | Batch: 004 / 011 | Total loss: 0.588 | Reg loss: 0.014 | Tree loss: 0.588 | Accuracy: 0.699000 | 0.623 sec/iter\n",
      "Epoch: 21 | Batch: 005 / 011 | Total loss: 0.577 | Reg loss: 0.014 | Tree loss: 0.577 | Accuracy: 0.710500 | 0.621 sec/iter\n",
      "Epoch: 21 | Batch: 006 / 011 | Total loss: 0.564 | Reg loss: 0.014 | Tree loss: 0.564 | Accuracy: 0.729500 | 0.62 sec/iter\n",
      "Epoch: 21 | Batch: 007 / 011 | Total loss: 0.558 | Reg loss: 0.014 | Tree loss: 0.558 | Accuracy: 0.806500 | 0.619 sec/iter\n",
      "Epoch: 21 | Batch: 008 / 011 | Total loss: 0.555 | Reg loss: 0.014 | Tree loss: 0.555 | Accuracy: 0.814000 | 0.617 sec/iter\n",
      "Epoch: 21 | Batch: 009 / 011 | Total loss: 0.559 | Reg loss: 0.014 | Tree loss: 0.559 | Accuracy: 0.795500 | 0.616 sec/iter\n",
      "Epoch: 21 | Batch: 010 / 011 | Total loss: 0.551 | Reg loss: 0.014 | Tree loss: 0.551 | Accuracy: 0.815700 | 0.614 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 22 | Batch: 000 / 011 | Total loss: 0.615 | Reg loss: 0.014 | Tree loss: 0.615 | Accuracy: 0.700000 | 0.641 sec/iter\n",
      "Epoch: 22 | Batch: 001 / 011 | Total loss: 0.604 | Reg loss: 0.014 | Tree loss: 0.604 | Accuracy: 0.723000 | 0.639 sec/iter\n",
      "Epoch: 22 | Batch: 002 / 011 | Total loss: 0.600 | Reg loss: 0.014 | Tree loss: 0.600 | Accuracy: 0.709000 | 0.637 sec/iter\n",
      "Epoch: 22 | Batch: 003 / 011 | Total loss: 0.598 | Reg loss: 0.014 | Tree loss: 0.598 | Accuracy: 0.702000 | 0.636 sec/iter\n",
      "Epoch: 22 | Batch: 004 / 011 | Total loss: 0.577 | Reg loss: 0.014 | Tree loss: 0.577 | Accuracy: 0.720500 | 0.634 sec/iter\n",
      "Epoch: 22 | Batch: 005 / 011 | Total loss: 0.572 | Reg loss: 0.014 | Tree loss: 0.572 | Accuracy: 0.705000 | 0.633 sec/iter\n",
      "Epoch: 22 | Batch: 006 / 011 | Total loss: 0.557 | Reg loss: 0.014 | Tree loss: 0.557 | Accuracy: 0.737500 | 0.632 sec/iter\n",
      "Epoch: 22 | Batch: 007 / 011 | Total loss: 0.551 | Reg loss: 0.014 | Tree loss: 0.551 | Accuracy: 0.789500 | 0.63 sec/iter\n",
      "Epoch: 22 | Batch: 008 / 011 | Total loss: 0.552 | Reg loss: 0.014 | Tree loss: 0.552 | Accuracy: 0.811500 | 0.629 sec/iter\n",
      "Epoch: 22 | Batch: 009 / 011 | Total loss: 0.555 | Reg loss: 0.014 | Tree loss: 0.555 | Accuracy: 0.809500 | 0.627 sec/iter\n",
      "Epoch: 22 | Batch: 010 / 011 | Total loss: 0.549 | Reg loss: 0.014 | Tree loss: 0.549 | Accuracy: 0.771331 | 0.626 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 23 | Batch: 000 / 011 | Total loss: 0.624 | Reg loss: 0.014 | Tree loss: 0.624 | Accuracy: 0.688000 | 0.652 sec/iter\n",
      "Epoch: 23 | Batch: 001 / 011 | Total loss: 0.585 | Reg loss: 0.014 | Tree loss: 0.585 | Accuracy: 0.741500 | 0.65 sec/iter\n",
      "Epoch: 23 | Batch: 002 / 011 | Total loss: 0.580 | Reg loss: 0.014 | Tree loss: 0.580 | Accuracy: 0.734000 | 0.649 sec/iter\n",
      "Epoch: 23 | Batch: 003 / 011 | Total loss: 0.590 | Reg loss: 0.014 | Tree loss: 0.590 | Accuracy: 0.695000 | 0.647 sec/iter\n",
      "Epoch: 23 | Batch: 004 / 011 | Total loss: 0.599 | Reg loss: 0.014 | Tree loss: 0.599 | Accuracy: 0.658000 | 0.646 sec/iter\n",
      "Epoch: 23 | Batch: 005 / 011 | Total loss: 0.570 | Reg loss: 0.014 | Tree loss: 0.570 | Accuracy: 0.718500 | 0.645 sec/iter\n",
      "Epoch: 23 | Batch: 006 / 011 | Total loss: 0.545 | Reg loss: 0.014 | Tree loss: 0.545 | Accuracy: 0.800000 | 0.643 sec/iter\n",
      "Epoch: 23 | Batch: 007 / 011 | Total loss: 0.548 | Reg loss: 0.014 | Tree loss: 0.548 | Accuracy: 0.804000 | 0.642 sec/iter\n",
      "Epoch: 23 | Batch: 008 / 011 | Total loss: 0.546 | Reg loss: 0.014 | Tree loss: 0.546 | Accuracy: 0.797500 | 0.64 sec/iter\n",
      "Epoch: 23 | Batch: 009 / 011 | Total loss: 0.542 | Reg loss: 0.014 | Tree loss: 0.542 | Accuracy: 0.810000 | 0.639 sec/iter\n",
      "Epoch: 23 | Batch: 010 / 011 | Total loss: 0.552 | Reg loss: 0.014 | Tree loss: 0.552 | Accuracy: 0.764505 | 0.638 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 24 | Batch: 000 / 011 | Total loss: 0.602 | Reg loss: 0.014 | Tree loss: 0.602 | Accuracy: 0.699000 | 0.647 sec/iter\n",
      "Epoch: 24 | Batch: 001 / 011 | Total loss: 0.593 | Reg loss: 0.014 | Tree loss: 0.593 | Accuracy: 0.724000 | 0.645 sec/iter\n",
      "Epoch: 24 | Batch: 002 / 011 | Total loss: 0.585 | Reg loss: 0.014 | Tree loss: 0.585 | Accuracy: 0.726500 | 0.644 sec/iter\n",
      "Epoch: 24 | Batch: 003 / 011 | Total loss: 0.592 | Reg loss: 0.014 | Tree loss: 0.592 | Accuracy: 0.703000 | 0.642 sec/iter\n",
      "Epoch: 24 | Batch: 004 / 011 | Total loss: 0.568 | Reg loss: 0.014 | Tree loss: 0.568 | Accuracy: 0.719500 | 0.641 sec/iter\n",
      "Epoch: 24 | Batch: 005 / 011 | Total loss: 0.551 | Reg loss: 0.014 | Tree loss: 0.551 | Accuracy: 0.730000 | 0.639 sec/iter\n",
      "Epoch: 24 | Batch: 006 / 011 | Total loss: 0.546 | Reg loss: 0.014 | Tree loss: 0.546 | Accuracy: 0.739500 | 0.638 sec/iter\n",
      "Epoch: 24 | Batch: 007 / 011 | Total loss: 0.541 | Reg loss: 0.014 | Tree loss: 0.541 | Accuracy: 0.787000 | 0.636 sec/iter\n",
      "Epoch: 24 | Batch: 008 / 011 | Total loss: 0.538 | Reg loss: 0.014 | Tree loss: 0.538 | Accuracy: 0.833500 | 0.635 sec/iter\n",
      "Epoch: 24 | Batch: 009 / 011 | Total loss: 0.539 | Reg loss: 0.014 | Tree loss: 0.539 | Accuracy: 0.806500 | 0.634 sec/iter\n",
      "Epoch: 24 | Batch: 010 / 011 | Total loss: 0.554 | Reg loss: 0.014 | Tree loss: 0.554 | Accuracy: 0.798635 | 0.632 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 25 | Batch: 000 / 011 | Total loss: 0.602 | Reg loss: 0.014 | Tree loss: 0.602 | Accuracy: 0.692000 | 0.648 sec/iter\n",
      "Epoch: 25 | Batch: 001 / 011 | Total loss: 0.582 | Reg loss: 0.014 | Tree loss: 0.582 | Accuracy: 0.725500 | 0.646 sec/iter\n",
      "Epoch: 25 | Batch: 002 / 011 | Total loss: 0.590 | Reg loss: 0.014 | Tree loss: 0.590 | Accuracy: 0.708500 | 0.645 sec/iter\n",
      "Epoch: 25 | Batch: 003 / 011 | Total loss: 0.577 | Reg loss: 0.014 | Tree loss: 0.577 | Accuracy: 0.706500 | 0.643 sec/iter\n",
      "Epoch: 25 | Batch: 004 / 011 | Total loss: 0.566 | Reg loss: 0.014 | Tree loss: 0.566 | Accuracy: 0.708500 | 0.642 sec/iter\n",
      "Epoch: 25 | Batch: 005 / 011 | Total loss: 0.559 | Reg loss: 0.014 | Tree loss: 0.559 | Accuracy: 0.727000 | 0.64 sec/iter\n",
      "Epoch: 25 | Batch: 006 / 011 | Total loss: 0.551 | Reg loss: 0.014 | Tree loss: 0.551 | Accuracy: 0.779000 | 0.639 sec/iter\n",
      "Epoch: 25 | Batch: 007 / 011 | Total loss: 0.530 | Reg loss: 0.014 | Tree loss: 0.530 | Accuracy: 0.821000 | 0.637 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Batch: 008 / 011 | Total loss: 0.536 | Reg loss: 0.014 | Tree loss: 0.536 | Accuracy: 0.797500 | 0.636 sec/iter\n",
      "Epoch: 25 | Batch: 009 / 011 | Total loss: 0.542 | Reg loss: 0.014 | Tree loss: 0.542 | Accuracy: 0.789000 | 0.635 sec/iter\n",
      "Epoch: 25 | Batch: 010 / 011 | Total loss: 0.527 | Reg loss: 0.014 | Tree loss: 0.527 | Accuracy: 0.808874 | 0.633 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 26 | Batch: 000 / 011 | Total loss: 0.613 | Reg loss: 0.014 | Tree loss: 0.613 | Accuracy: 0.667000 | 0.649 sec/iter\n",
      "Epoch: 26 | Batch: 001 / 011 | Total loss: 0.579 | Reg loss: 0.014 | Tree loss: 0.579 | Accuracy: 0.736500 | 0.647 sec/iter\n",
      "Epoch: 26 | Batch: 002 / 011 | Total loss: 0.570 | Reg loss: 0.014 | Tree loss: 0.570 | Accuracy: 0.723000 | 0.646 sec/iter\n",
      "Epoch: 26 | Batch: 003 / 011 | Total loss: 0.569 | Reg loss: 0.014 | Tree loss: 0.569 | Accuracy: 0.723500 | 0.645 sec/iter\n",
      "Epoch: 26 | Batch: 004 / 011 | Total loss: 0.569 | Reg loss: 0.014 | Tree loss: 0.569 | Accuracy: 0.703000 | 0.643 sec/iter\n",
      "Epoch: 26 | Batch: 005 / 011 | Total loss: 0.559 | Reg loss: 0.014 | Tree loss: 0.559 | Accuracy: 0.713000 | 0.642 sec/iter\n",
      "Epoch: 26 | Batch: 006 / 011 | Total loss: 0.547 | Reg loss: 0.014 | Tree loss: 0.547 | Accuracy: 0.732000 | 0.641 sec/iter\n",
      "Epoch: 26 | Batch: 007 / 011 | Total loss: 0.534 | Reg loss: 0.014 | Tree loss: 0.534 | Accuracy: 0.827500 | 0.639 sec/iter\n",
      "Epoch: 26 | Batch: 008 / 011 | Total loss: 0.532 | Reg loss: 0.014 | Tree loss: 0.532 | Accuracy: 0.831000 | 0.638 sec/iter\n",
      "Epoch: 26 | Batch: 009 / 011 | Total loss: 0.540 | Reg loss: 0.014 | Tree loss: 0.540 | Accuracy: 0.792500 | 0.636 sec/iter\n",
      "Epoch: 26 | Batch: 010 / 011 | Total loss: 0.540 | Reg loss: 0.014 | Tree loss: 0.540 | Accuracy: 0.788396 | 0.635 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 27 | Batch: 000 / 011 | Total loss: 0.596 | Reg loss: 0.014 | Tree loss: 0.596 | Accuracy: 0.693000 | 0.636 sec/iter\n",
      "Epoch: 27 | Batch: 001 / 011 | Total loss: 0.573 | Reg loss: 0.014 | Tree loss: 0.573 | Accuracy: 0.746500 | 0.635 sec/iter\n",
      "Epoch: 27 | Batch: 002 / 011 | Total loss: 0.573 | Reg loss: 0.014 | Tree loss: 0.573 | Accuracy: 0.713000 | 0.634 sec/iter\n",
      "Epoch: 27 | Batch: 003 / 011 | Total loss: 0.567 | Reg loss: 0.014 | Tree loss: 0.567 | Accuracy: 0.721500 | 0.632 sec/iter\n",
      "Epoch: 27 | Batch: 004 / 011 | Total loss: 0.556 | Reg loss: 0.014 | Tree loss: 0.556 | Accuracy: 0.720000 | 0.631 sec/iter\n",
      "Epoch: 27 | Batch: 005 / 011 | Total loss: 0.559 | Reg loss: 0.014 | Tree loss: 0.559 | Accuracy: 0.707000 | 0.63 sec/iter\n",
      "Epoch: 27 | Batch: 006 / 011 | Total loss: 0.538 | Reg loss: 0.014 | Tree loss: 0.538 | Accuracy: 0.783000 | 0.629 sec/iter\n",
      "Epoch: 27 | Batch: 007 / 011 | Total loss: 0.532 | Reg loss: 0.014 | Tree loss: 0.532 | Accuracy: 0.816500 | 0.627 sec/iter\n",
      "Epoch: 27 | Batch: 008 / 011 | Total loss: 0.539 | Reg loss: 0.014 | Tree loss: 0.539 | Accuracy: 0.801000 | 0.626 sec/iter\n",
      "Epoch: 27 | Batch: 009 / 011 | Total loss: 0.520 | Reg loss: 0.014 | Tree loss: 0.520 | Accuracy: 0.799500 | 0.625 sec/iter\n",
      "Epoch: 27 | Batch: 010 / 011 | Total loss: 0.523 | Reg loss: 0.015 | Tree loss: 0.523 | Accuracy: 0.778157 | 0.624 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 28 | Batch: 000 / 011 | Total loss: 0.595 | Reg loss: 0.014 | Tree loss: 0.595 | Accuracy: 0.694000 | 0.638 sec/iter\n",
      "Epoch: 28 | Batch: 001 / 011 | Total loss: 0.574 | Reg loss: 0.014 | Tree loss: 0.574 | Accuracy: 0.727000 | 0.637 sec/iter\n",
      "Epoch: 28 | Batch: 002 / 011 | Total loss: 0.577 | Reg loss: 0.014 | Tree loss: 0.577 | Accuracy: 0.708000 | 0.636 sec/iter\n",
      "Epoch: 28 | Batch: 003 / 011 | Total loss: 0.556 | Reg loss: 0.014 | Tree loss: 0.556 | Accuracy: 0.721000 | 0.634 sec/iter\n",
      "Epoch: 28 | Batch: 004 / 011 | Total loss: 0.566 | Reg loss: 0.014 | Tree loss: 0.566 | Accuracy: 0.698000 | 0.633 sec/iter\n",
      "Epoch: 28 | Batch: 005 / 011 | Total loss: 0.541 | Reg loss: 0.014 | Tree loss: 0.541 | Accuracy: 0.731000 | 0.632 sec/iter\n",
      "Epoch: 28 | Batch: 006 / 011 | Total loss: 0.523 | Reg loss: 0.014 | Tree loss: 0.523 | Accuracy: 0.804500 | 0.63 sec/iter\n",
      "Epoch: 28 | Batch: 007 / 011 | Total loss: 0.526 | Reg loss: 0.014 | Tree loss: 0.526 | Accuracy: 0.810000 | 0.629 sec/iter\n",
      "Epoch: 28 | Batch: 008 / 011 | Total loss: 0.524 | Reg loss: 0.014 | Tree loss: 0.524 | Accuracy: 0.803500 | 0.628 sec/iter\n",
      "Epoch: 28 | Batch: 009 / 011 | Total loss: 0.522 | Reg loss: 0.015 | Tree loss: 0.522 | Accuracy: 0.797000 | 0.627 sec/iter\n",
      "Epoch: 28 | Batch: 010 / 011 | Total loss: 0.525 | Reg loss: 0.015 | Tree loss: 0.525 | Accuracy: 0.791809 | 0.626 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 29 | Batch: 000 / 011 | Total loss: 0.588 | Reg loss: 0.014 | Tree loss: 0.588 | Accuracy: 0.683500 | 0.639 sec/iter\n",
      "Epoch: 29 | Batch: 001 / 011 | Total loss: 0.575 | Reg loss: 0.014 | Tree loss: 0.575 | Accuracy: 0.707500 | 0.638 sec/iter\n",
      "Epoch: 29 | Batch: 002 / 011 | Total loss: 0.557 | Reg loss: 0.014 | Tree loss: 0.557 | Accuracy: 0.735500 | 0.637 sec/iter\n",
      "Epoch: 29 | Batch: 003 / 011 | Total loss: 0.570 | Reg loss: 0.014 | Tree loss: 0.570 | Accuracy: 0.710000 | 0.636 sec/iter\n",
      "Epoch: 29 | Batch: 004 / 011 | Total loss: 0.548 | Reg loss: 0.014 | Tree loss: 0.548 | Accuracy: 0.717500 | 0.635 sec/iter\n",
      "Epoch: 29 | Batch: 005 / 011 | Total loss: 0.537 | Reg loss: 0.014 | Tree loss: 0.537 | Accuracy: 0.726500 | 0.633 sec/iter\n",
      "Epoch: 29 | Batch: 006 / 011 | Total loss: 0.525 | Reg loss: 0.014 | Tree loss: 0.525 | Accuracy: 0.762000 | 0.632 sec/iter\n",
      "Epoch: 29 | Batch: 007 / 011 | Total loss: 0.517 | Reg loss: 0.014 | Tree loss: 0.517 | Accuracy: 0.807500 | 0.631 sec/iter\n",
      "Epoch: 29 | Batch: 008 / 011 | Total loss: 0.521 | Reg loss: 0.015 | Tree loss: 0.521 | Accuracy: 0.819500 | 0.63 sec/iter\n",
      "Epoch: 29 | Batch: 009 / 011 | Total loss: 0.528 | Reg loss: 0.015 | Tree loss: 0.528 | Accuracy: 0.788500 | 0.629 sec/iter\n",
      "Epoch: 29 | Batch: 010 / 011 | Total loss: 0.518 | Reg loss: 0.015 | Tree loss: 0.518 | Accuracy: 0.774744 | 0.628 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 30 | Batch: 000 / 011 | Total loss: 0.586 | Reg loss: 0.014 | Tree loss: 0.586 | Accuracy: 0.692500 | 0.629 sec/iter\n",
      "Epoch: 30 | Batch: 001 / 011 | Total loss: 0.570 | Reg loss: 0.014 | Tree loss: 0.570 | Accuracy: 0.718500 | 0.628 sec/iter\n",
      "Epoch: 30 | Batch: 002 / 011 | Total loss: 0.563 | Reg loss: 0.014 | Tree loss: 0.563 | Accuracy: 0.718000 | 0.627 sec/iter\n",
      "Epoch: 30 | Batch: 003 / 011 | Total loss: 0.546 | Reg loss: 0.014 | Tree loss: 0.546 | Accuracy: 0.729000 | 0.626 sec/iter\n",
      "Epoch: 30 | Batch: 004 / 011 | Total loss: 0.544 | Reg loss: 0.014 | Tree loss: 0.544 | Accuracy: 0.725500 | 0.624 sec/iter\n",
      "Epoch: 30 | Batch: 005 / 011 | Total loss: 0.531 | Reg loss: 0.014 | Tree loss: 0.531 | Accuracy: 0.753000 | 0.623 sec/iter\n",
      "Epoch: 30 | Batch: 006 / 011 | Total loss: 0.526 | Reg loss: 0.014 | Tree loss: 0.526 | Accuracy: 0.794000 | 0.622 sec/iter\n",
      "Epoch: 30 | Batch: 007 / 011 | Total loss: 0.522 | Reg loss: 0.015 | Tree loss: 0.522 | Accuracy: 0.801500 | 0.621 sec/iter\n",
      "Epoch: 30 | Batch: 008 / 011 | Total loss: 0.508 | Reg loss: 0.015 | Tree loss: 0.508 | Accuracy: 0.825500 | 0.62 sec/iter\n",
      "Epoch: 30 | Batch: 009 / 011 | Total loss: 0.514 | Reg loss: 0.015 | Tree loss: 0.514 | Accuracy: 0.801000 | 0.619 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Batch: 010 / 011 | Total loss: 0.510 | Reg loss: 0.015 | Tree loss: 0.510 | Accuracy: 0.781570 | 0.618 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 31 | Batch: 000 / 011 | Total loss: 0.582 | Reg loss: 0.014 | Tree loss: 0.582 | Accuracy: 0.693500 | 0.631 sec/iter\n",
      "Epoch: 31 | Batch: 001 / 011 | Total loss: 0.572 | Reg loss: 0.014 | Tree loss: 0.572 | Accuracy: 0.712500 | 0.63 sec/iter\n",
      "Epoch: 31 | Batch: 002 / 011 | Total loss: 0.543 | Reg loss: 0.014 | Tree loss: 0.543 | Accuracy: 0.737000 | 0.629 sec/iter\n",
      "Epoch: 31 | Batch: 003 / 011 | Total loss: 0.555 | Reg loss: 0.014 | Tree loss: 0.555 | Accuracy: 0.716000 | 0.628 sec/iter\n",
      "Epoch: 31 | Batch: 004 / 011 | Total loss: 0.530 | Reg loss: 0.014 | Tree loss: 0.530 | Accuracy: 0.732000 | 0.626 sec/iter\n",
      "Epoch: 31 | Batch: 005 / 011 | Total loss: 0.536 | Reg loss: 0.015 | Tree loss: 0.536 | Accuracy: 0.742000 | 0.625 sec/iter\n",
      "Epoch: 31 | Batch: 006 / 011 | Total loss: 0.528 | Reg loss: 0.015 | Tree loss: 0.528 | Accuracy: 0.778500 | 0.624 sec/iter\n",
      "Epoch: 31 | Batch: 007 / 011 | Total loss: 0.516 | Reg loss: 0.015 | Tree loss: 0.516 | Accuracy: 0.805500 | 0.623 sec/iter\n",
      "Epoch: 31 | Batch: 008 / 011 | Total loss: 0.505 | Reg loss: 0.015 | Tree loss: 0.505 | Accuracy: 0.812500 | 0.622 sec/iter\n",
      "Epoch: 31 | Batch: 009 / 011 | Total loss: 0.520 | Reg loss: 0.015 | Tree loss: 0.520 | Accuracy: 0.793000 | 0.621 sec/iter\n",
      "Epoch: 31 | Batch: 010 / 011 | Total loss: 0.522 | Reg loss: 0.015 | Tree loss: 0.522 | Accuracy: 0.757679 | 0.619 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 32 | Batch: 000 / 011 | Total loss: 0.592 | Reg loss: 0.014 | Tree loss: 0.592 | Accuracy: 0.677000 | 0.629 sec/iter\n",
      "Epoch: 32 | Batch: 001 / 011 | Total loss: 0.556 | Reg loss: 0.015 | Tree loss: 0.556 | Accuracy: 0.720000 | 0.628 sec/iter\n",
      "Epoch: 32 | Batch: 002 / 011 | Total loss: 0.555 | Reg loss: 0.015 | Tree loss: 0.555 | Accuracy: 0.713000 | 0.627 sec/iter\n",
      "Epoch: 32 | Batch: 003 / 011 | Total loss: 0.539 | Reg loss: 0.015 | Tree loss: 0.539 | Accuracy: 0.735000 | 0.626 sec/iter\n",
      "Epoch: 32 | Batch: 004 / 011 | Total loss: 0.542 | Reg loss: 0.015 | Tree loss: 0.542 | Accuracy: 0.717000 | 0.625 sec/iter\n",
      "Epoch: 32 | Batch: 005 / 011 | Total loss: 0.527 | Reg loss: 0.015 | Tree loss: 0.527 | Accuracy: 0.742500 | 0.624 sec/iter\n",
      "Epoch: 32 | Batch: 006 / 011 | Total loss: 0.525 | Reg loss: 0.015 | Tree loss: 0.525 | Accuracy: 0.786000 | 0.622 sec/iter\n",
      "Epoch: 32 | Batch: 007 / 011 | Total loss: 0.511 | Reg loss: 0.015 | Tree loss: 0.511 | Accuracy: 0.820000 | 0.621 sec/iter\n",
      "Epoch: 32 | Batch: 008 / 011 | Total loss: 0.507 | Reg loss: 0.015 | Tree loss: 0.507 | Accuracy: 0.806000 | 0.62 sec/iter\n",
      "Epoch: 32 | Batch: 009 / 011 | Total loss: 0.508 | Reg loss: 0.015 | Tree loss: 0.508 | Accuracy: 0.813000 | 0.619 sec/iter\n",
      "Epoch: 32 | Batch: 010 / 011 | Total loss: 0.504 | Reg loss: 0.015 | Tree loss: 0.504 | Accuracy: 0.791809 | 0.618 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 33 | Batch: 000 / 011 | Total loss: 0.578 | Reg loss: 0.015 | Tree loss: 0.578 | Accuracy: 0.686500 | 0.626 sec/iter\n",
      "Epoch: 33 | Batch: 001 / 011 | Total loss: 0.562 | Reg loss: 0.015 | Tree loss: 0.562 | Accuracy: 0.702500 | 0.625 sec/iter\n",
      "Epoch: 33 | Batch: 002 / 011 | Total loss: 0.539 | Reg loss: 0.015 | Tree loss: 0.539 | Accuracy: 0.742000 | 0.623 sec/iter\n",
      "Epoch: 33 | Batch: 003 / 011 | Total loss: 0.535 | Reg loss: 0.015 | Tree loss: 0.535 | Accuracy: 0.727000 | 0.622 sec/iter\n",
      "Epoch: 33 | Batch: 004 / 011 | Total loss: 0.546 | Reg loss: 0.015 | Tree loss: 0.546 | Accuracy: 0.710000 | 0.621 sec/iter\n",
      "Epoch: 33 | Batch: 005 / 011 | Total loss: 0.530 | Reg loss: 0.015 | Tree loss: 0.530 | Accuracy: 0.741500 | 0.62 sec/iter\n",
      "Epoch: 33 | Batch: 006 / 011 | Total loss: 0.514 | Reg loss: 0.015 | Tree loss: 0.514 | Accuracy: 0.802000 | 0.619 sec/iter\n",
      "Epoch: 33 | Batch: 007 / 011 | Total loss: 0.504 | Reg loss: 0.015 | Tree loss: 0.504 | Accuracy: 0.833500 | 0.618 sec/iter\n",
      "Epoch: 33 | Batch: 008 / 011 | Total loss: 0.505 | Reg loss: 0.015 | Tree loss: 0.505 | Accuracy: 0.808000 | 0.617 sec/iter\n",
      "Epoch: 33 | Batch: 009 / 011 | Total loss: 0.514 | Reg loss: 0.015 | Tree loss: 0.514 | Accuracy: 0.795500 | 0.616 sec/iter\n",
      "Epoch: 33 | Batch: 010 / 011 | Total loss: 0.494 | Reg loss: 0.015 | Tree loss: 0.494 | Accuracy: 0.846416 | 0.615 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 34 | Batch: 000 / 011 | Total loss: 0.573 | Reg loss: 0.015 | Tree loss: 0.573 | Accuracy: 0.702500 | 0.622 sec/iter\n",
      "Epoch: 34 | Batch: 001 / 011 | Total loss: 0.557 | Reg loss: 0.015 | Tree loss: 0.557 | Accuracy: 0.713000 | 0.621 sec/iter\n",
      "Epoch: 34 | Batch: 002 / 011 | Total loss: 0.536 | Reg loss: 0.015 | Tree loss: 0.536 | Accuracy: 0.738000 | 0.62 sec/iter\n",
      "Epoch: 34 | Batch: 003 / 011 | Total loss: 0.523 | Reg loss: 0.015 | Tree loss: 0.523 | Accuracy: 0.739000 | 0.619 sec/iter\n",
      "Epoch: 34 | Batch: 004 / 011 | Total loss: 0.550 | Reg loss: 0.015 | Tree loss: 0.550 | Accuracy: 0.695500 | 0.618 sec/iter\n",
      "Epoch: 34 | Batch: 005 / 011 | Total loss: 0.522 | Reg loss: 0.015 | Tree loss: 0.522 | Accuracy: 0.748500 | 0.617 sec/iter\n",
      "Epoch: 34 | Batch: 006 / 011 | Total loss: 0.522 | Reg loss: 0.015 | Tree loss: 0.522 | Accuracy: 0.790500 | 0.615 sec/iter\n",
      "Epoch: 34 | Batch: 007 / 011 | Total loss: 0.494 | Reg loss: 0.015 | Tree loss: 0.494 | Accuracy: 0.821000 | 0.614 sec/iter\n",
      "Epoch: 34 | Batch: 008 / 011 | Total loss: 0.504 | Reg loss: 0.015 | Tree loss: 0.504 | Accuracy: 0.796000 | 0.613 sec/iter\n",
      "Epoch: 34 | Batch: 009 / 011 | Total loss: 0.504 | Reg loss: 0.015 | Tree loss: 0.504 | Accuracy: 0.807000 | 0.612 sec/iter\n",
      "Epoch: 34 | Batch: 010 / 011 | Total loss: 0.509 | Reg loss: 0.015 | Tree loss: 0.509 | Accuracy: 0.757679 | 0.611 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 35 | Batch: 000 / 011 | Total loss: 0.578 | Reg loss: 0.015 | Tree loss: 0.578 | Accuracy: 0.688500 | 0.612 sec/iter\n",
      "Epoch: 35 | Batch: 001 / 011 | Total loss: 0.556 | Reg loss: 0.015 | Tree loss: 0.556 | Accuracy: 0.713000 | 0.611 sec/iter\n",
      "Epoch: 35 | Batch: 002 / 011 | Total loss: 0.548 | Reg loss: 0.015 | Tree loss: 0.548 | Accuracy: 0.718000 | 0.61 sec/iter\n",
      "Epoch: 35 | Batch: 003 / 011 | Total loss: 0.537 | Reg loss: 0.015 | Tree loss: 0.537 | Accuracy: 0.724000 | 0.609 sec/iter\n",
      "Epoch: 35 | Batch: 004 / 011 | Total loss: 0.517 | Reg loss: 0.015 | Tree loss: 0.517 | Accuracy: 0.730500 | 0.608 sec/iter\n",
      "Epoch: 35 | Batch: 005 / 011 | Total loss: 0.518 | Reg loss: 0.015 | Tree loss: 0.518 | Accuracy: 0.752000 | 0.607 sec/iter\n",
      "Epoch: 35 | Batch: 006 / 011 | Total loss: 0.524 | Reg loss: 0.015 | Tree loss: 0.524 | Accuracy: 0.783000 | 0.606 sec/iter\n",
      "Epoch: 35 | Batch: 007 / 011 | Total loss: 0.495 | Reg loss: 0.015 | Tree loss: 0.495 | Accuracy: 0.825000 | 0.605 sec/iter\n",
      "Epoch: 35 | Batch: 008 / 011 | Total loss: 0.493 | Reg loss: 0.015 | Tree loss: 0.493 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 35 | Batch: 009 / 011 | Total loss: 0.496 | Reg loss: 0.015 | Tree loss: 0.496 | Accuracy: 0.811000 | 0.603 sec/iter\n",
      "Epoch: 35 | Batch: 010 / 011 | Total loss: 0.491 | Reg loss: 0.015 | Tree loss: 0.491 | Accuracy: 0.846416 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Batch: 000 / 011 | Total loss: 0.582 | Reg loss: 0.015 | Tree loss: 0.582 | Accuracy: 0.684000 | 0.606 sec/iter\n",
      "Epoch: 36 | Batch: 001 / 011 | Total loss: 0.546 | Reg loss: 0.015 | Tree loss: 0.546 | Accuracy: 0.710000 | 0.605 sec/iter\n",
      "Epoch: 36 | Batch: 002 / 011 | Total loss: 0.539 | Reg loss: 0.015 | Tree loss: 0.539 | Accuracy: 0.729000 | 0.604 sec/iter\n",
      "Epoch: 36 | Batch: 003 / 011 | Total loss: 0.519 | Reg loss: 0.015 | Tree loss: 0.519 | Accuracy: 0.750000 | 0.603 sec/iter\n",
      "Epoch: 36 | Batch: 004 / 011 | Total loss: 0.521 | Reg loss: 0.015 | Tree loss: 0.521 | Accuracy: 0.735500 | 0.603 sec/iter\n",
      "Epoch: 36 | Batch: 005 / 011 | Total loss: 0.510 | Reg loss: 0.015 | Tree loss: 0.510 | Accuracy: 0.771000 | 0.602 sec/iter\n",
      "Epoch: 36 | Batch: 006 / 011 | Total loss: 0.516 | Reg loss: 0.015 | Tree loss: 0.516 | Accuracy: 0.794000 | 0.601 sec/iter\n",
      "Epoch: 36 | Batch: 007 / 011 | Total loss: 0.490 | Reg loss: 0.015 | Tree loss: 0.490 | Accuracy: 0.796500 | 0.6 sec/iter\n",
      "Epoch: 36 | Batch: 008 / 011 | Total loss: 0.497 | Reg loss: 0.015 | Tree loss: 0.497 | Accuracy: 0.831000 | 0.599 sec/iter\n",
      "Epoch: 36 | Batch: 009 / 011 | Total loss: 0.497 | Reg loss: 0.015 | Tree loss: 0.497 | Accuracy: 0.810500 | 0.598 sec/iter\n",
      "Epoch: 36 | Batch: 010 / 011 | Total loss: 0.489 | Reg loss: 0.015 | Tree loss: 0.489 | Accuracy: 0.791809 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 37 | Batch: 000 / 011 | Total loss: 0.579 | Reg loss: 0.015 | Tree loss: 0.579 | Accuracy: 0.687000 | 0.603 sec/iter\n",
      "Epoch: 37 | Batch: 001 / 011 | Total loss: 0.545 | Reg loss: 0.015 | Tree loss: 0.545 | Accuracy: 0.707000 | 0.602 sec/iter\n",
      "Epoch: 37 | Batch: 002 / 011 | Total loss: 0.541 | Reg loss: 0.015 | Tree loss: 0.541 | Accuracy: 0.719500 | 0.601 sec/iter\n",
      "Epoch: 37 | Batch: 003 / 011 | Total loss: 0.520 | Reg loss: 0.015 | Tree loss: 0.520 | Accuracy: 0.737500 | 0.6 sec/iter\n",
      "Epoch: 37 | Batch: 004 / 011 | Total loss: 0.515 | Reg loss: 0.015 | Tree loss: 0.515 | Accuracy: 0.740000 | 0.599 sec/iter\n",
      "Epoch: 37 | Batch: 005 / 011 | Total loss: 0.523 | Reg loss: 0.015 | Tree loss: 0.523 | Accuracy: 0.741500 | 0.598 sec/iter\n",
      "Epoch: 37 | Batch: 006 / 011 | Total loss: 0.503 | Reg loss: 0.015 | Tree loss: 0.503 | Accuracy: 0.788500 | 0.597 sec/iter\n",
      "Epoch: 37 | Batch: 007 / 011 | Total loss: 0.485 | Reg loss: 0.015 | Tree loss: 0.485 | Accuracy: 0.821500 | 0.596 sec/iter\n",
      "Epoch: 37 | Batch: 008 / 011 | Total loss: 0.490 | Reg loss: 0.015 | Tree loss: 0.490 | Accuracy: 0.845000 | 0.595 sec/iter\n",
      "Epoch: 37 | Batch: 009 / 011 | Total loss: 0.489 | Reg loss: 0.015 | Tree loss: 0.489 | Accuracy: 0.818500 | 0.594 sec/iter\n",
      "Epoch: 37 | Batch: 010 / 011 | Total loss: 0.504 | Reg loss: 0.015 | Tree loss: 0.504 | Accuracy: 0.778157 | 0.593 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 38 | Batch: 000 / 011 | Total loss: 0.564 | Reg loss: 0.015 | Tree loss: 0.564 | Accuracy: 0.699500 | 0.602 sec/iter\n",
      "Epoch: 38 | Batch: 001 / 011 | Total loss: 0.547 | Reg loss: 0.015 | Tree loss: 0.547 | Accuracy: 0.703500 | 0.601 sec/iter\n",
      "Epoch: 38 | Batch: 002 / 011 | Total loss: 0.520 | Reg loss: 0.015 | Tree loss: 0.520 | Accuracy: 0.741500 | 0.6 sec/iter\n",
      "Epoch: 38 | Batch: 003 / 011 | Total loss: 0.522 | Reg loss: 0.015 | Tree loss: 0.522 | Accuracy: 0.737000 | 0.599 sec/iter\n",
      "Epoch: 38 | Batch: 004 / 011 | Total loss: 0.512 | Reg loss: 0.015 | Tree loss: 0.512 | Accuracy: 0.734000 | 0.599 sec/iter\n",
      "Epoch: 38 | Batch: 005 / 011 | Total loss: 0.528 | Reg loss: 0.015 | Tree loss: 0.528 | Accuracy: 0.736500 | 0.598 sec/iter\n",
      "Epoch: 38 | Batch: 006 / 011 | Total loss: 0.493 | Reg loss: 0.015 | Tree loss: 0.493 | Accuracy: 0.806500 | 0.597 sec/iter\n",
      "Epoch: 38 | Batch: 007 / 011 | Total loss: 0.495 | Reg loss: 0.015 | Tree loss: 0.495 | Accuracy: 0.792500 | 0.596 sec/iter\n",
      "Epoch: 38 | Batch: 008 / 011 | Total loss: 0.489 | Reg loss: 0.015 | Tree loss: 0.489 | Accuracy: 0.837500 | 0.595 sec/iter\n",
      "Epoch: 38 | Batch: 009 / 011 | Total loss: 0.485 | Reg loss: 0.015 | Tree loss: 0.485 | Accuracy: 0.818500 | 0.594 sec/iter\n",
      "Epoch: 38 | Batch: 010 / 011 | Total loss: 0.493 | Reg loss: 0.015 | Tree loss: 0.493 | Accuracy: 0.822526 | 0.594 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 39 | Batch: 000 / 011 | Total loss: 0.555 | Reg loss: 0.015 | Tree loss: 0.555 | Accuracy: 0.699500 | 0.598 sec/iter\n",
      "Epoch: 39 | Batch: 001 / 011 | Total loss: 0.550 | Reg loss: 0.015 | Tree loss: 0.550 | Accuracy: 0.697000 | 0.597 sec/iter\n",
      "Epoch: 39 | Batch: 002 / 011 | Total loss: 0.520 | Reg loss: 0.015 | Tree loss: 0.520 | Accuracy: 0.740500 | 0.597 sec/iter\n",
      "Epoch: 39 | Batch: 003 / 011 | Total loss: 0.507 | Reg loss: 0.015 | Tree loss: 0.507 | Accuracy: 0.739000 | 0.596 sec/iter\n",
      "Epoch: 39 | Batch: 004 / 011 | Total loss: 0.528 | Reg loss: 0.015 | Tree loss: 0.528 | Accuracy: 0.734000 | 0.595 sec/iter\n",
      "Epoch: 39 | Batch: 005 / 011 | Total loss: 0.509 | Reg loss: 0.015 | Tree loss: 0.509 | Accuracy: 0.775500 | 0.594 sec/iter\n",
      "Epoch: 39 | Batch: 006 / 011 | Total loss: 0.492 | Reg loss: 0.015 | Tree loss: 0.492 | Accuracy: 0.802500 | 0.593 sec/iter\n",
      "Epoch: 39 | Batch: 007 / 011 | Total loss: 0.495 | Reg loss: 0.015 | Tree loss: 0.495 | Accuracy: 0.795500 | 0.593 sec/iter\n",
      "Epoch: 39 | Batch: 008 / 011 | Total loss: 0.492 | Reg loss: 0.015 | Tree loss: 0.492 | Accuracy: 0.827500 | 0.592 sec/iter\n",
      "Epoch: 39 | Batch: 009 / 011 | Total loss: 0.488 | Reg loss: 0.015 | Tree loss: 0.488 | Accuracy: 0.806000 | 0.591 sec/iter\n",
      "Epoch: 39 | Batch: 010 / 011 | Total loss: 0.482 | Reg loss: 0.015 | Tree loss: 0.482 | Accuracy: 0.829352 | 0.59 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 40 | Batch: 000 / 011 | Total loss: 0.568 | Reg loss: 0.015 | Tree loss: 0.568 | Accuracy: 0.678500 | 0.602 sec/iter\n",
      "Epoch: 40 | Batch: 001 / 011 | Total loss: 0.543 | Reg loss: 0.015 | Tree loss: 0.543 | Accuracy: 0.708000 | 0.602 sec/iter\n",
      "Epoch: 40 | Batch: 002 / 011 | Total loss: 0.520 | Reg loss: 0.015 | Tree loss: 0.520 | Accuracy: 0.732500 | 0.601 sec/iter\n",
      "Epoch: 40 | Batch: 003 / 011 | Total loss: 0.508 | Reg loss: 0.015 | Tree loss: 0.508 | Accuracy: 0.743000 | 0.6 sec/iter\n",
      "Epoch: 40 | Batch: 004 / 011 | Total loss: 0.518 | Reg loss: 0.015 | Tree loss: 0.518 | Accuracy: 0.748500 | 0.599 sec/iter\n",
      "Epoch: 40 | Batch: 005 / 011 | Total loss: 0.509 | Reg loss: 0.015 | Tree loss: 0.509 | Accuracy: 0.768000 | 0.599 sec/iter\n",
      "Epoch: 40 | Batch: 006 / 011 | Total loss: 0.489 | Reg loss: 0.015 | Tree loss: 0.489 | Accuracy: 0.813000 | 0.598 sec/iter\n",
      "Epoch: 40 | Batch: 007 / 011 | Total loss: 0.496 | Reg loss: 0.015 | Tree loss: 0.496 | Accuracy: 0.789000 | 0.597 sec/iter\n",
      "Epoch: 40 | Batch: 008 / 011 | Total loss: 0.476 | Reg loss: 0.015 | Tree loss: 0.476 | Accuracy: 0.843500 | 0.596 sec/iter\n",
      "Epoch: 40 | Batch: 009 / 011 | Total loss: 0.479 | Reg loss: 0.015 | Tree loss: 0.479 | Accuracy: 0.826000 | 0.596 sec/iter\n",
      "Epoch: 40 | Batch: 010 / 011 | Total loss: 0.486 | Reg loss: 0.015 | Tree loss: 0.486 | Accuracy: 0.798635 | 0.595 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 41 | Batch: 000 / 011 | Total loss: 0.558 | Reg loss: 0.015 | Tree loss: 0.558 | Accuracy: 0.689500 | 0.609 sec/iter\n",
      "Epoch: 41 | Batch: 001 / 011 | Total loss: 0.557 | Reg loss: 0.015 | Tree loss: 0.557 | Accuracy: 0.689500 | 0.608 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Batch: 002 / 011 | Total loss: 0.518 | Reg loss: 0.015 | Tree loss: 0.518 | Accuracy: 0.722000 | 0.607 sec/iter\n",
      "Epoch: 41 | Batch: 003 / 011 | Total loss: 0.503 | Reg loss: 0.015 | Tree loss: 0.503 | Accuracy: 0.744500 | 0.606 sec/iter\n",
      "Epoch: 41 | Batch: 004 / 011 | Total loss: 0.510 | Reg loss: 0.015 | Tree loss: 0.510 | Accuracy: 0.753500 | 0.606 sec/iter\n",
      "Epoch: 41 | Batch: 005 / 011 | Total loss: 0.502 | Reg loss: 0.015 | Tree loss: 0.502 | Accuracy: 0.787000 | 0.605 sec/iter\n",
      "Epoch: 41 | Batch: 006 / 011 | Total loss: 0.493 | Reg loss: 0.015 | Tree loss: 0.493 | Accuracy: 0.793500 | 0.604 sec/iter\n",
      "Epoch: 41 | Batch: 007 / 011 | Total loss: 0.475 | Reg loss: 0.015 | Tree loss: 0.475 | Accuracy: 0.803500 | 0.604 sec/iter\n",
      "Epoch: 41 | Batch: 008 / 011 | Total loss: 0.480 | Reg loss: 0.015 | Tree loss: 0.480 | Accuracy: 0.846000 | 0.603 sec/iter\n",
      "Epoch: 41 | Batch: 009 / 011 | Total loss: 0.484 | Reg loss: 0.015 | Tree loss: 0.484 | Accuracy: 0.809500 | 0.602 sec/iter\n",
      "Epoch: 41 | Batch: 010 / 011 | Total loss: 0.504 | Reg loss: 0.015 | Tree loss: 0.504 | Accuracy: 0.774744 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 42 | Batch: 000 / 011 | Total loss: 0.560 | Reg loss: 0.015 | Tree loss: 0.560 | Accuracy: 0.694000 | 0.614 sec/iter\n",
      "Epoch: 42 | Batch: 001 / 011 | Total loss: 0.541 | Reg loss: 0.015 | Tree loss: 0.541 | Accuracy: 0.705500 | 0.613 sec/iter\n",
      "Epoch: 42 | Batch: 002 / 011 | Total loss: 0.510 | Reg loss: 0.015 | Tree loss: 0.510 | Accuracy: 0.731000 | 0.613 sec/iter\n",
      "Epoch: 42 | Batch: 003 / 011 | Total loss: 0.508 | Reg loss: 0.015 | Tree loss: 0.508 | Accuracy: 0.746500 | 0.612 sec/iter\n",
      "Epoch: 42 | Batch: 004 / 011 | Total loss: 0.509 | Reg loss: 0.015 | Tree loss: 0.509 | Accuracy: 0.747500 | 0.611 sec/iter\n",
      "Epoch: 42 | Batch: 005 / 011 | Total loss: 0.498 | Reg loss: 0.015 | Tree loss: 0.498 | Accuracy: 0.774000 | 0.611 sec/iter\n",
      "Epoch: 42 | Batch: 006 / 011 | Total loss: 0.500 | Reg loss: 0.015 | Tree loss: 0.500 | Accuracy: 0.786500 | 0.61 sec/iter\n",
      "Epoch: 42 | Batch: 007 / 011 | Total loss: 0.494 | Reg loss: 0.015 | Tree loss: 0.494 | Accuracy: 0.798500 | 0.609 sec/iter\n",
      "Epoch: 42 | Batch: 008 / 011 | Total loss: 0.483 | Reg loss: 0.015 | Tree loss: 0.483 | Accuracy: 0.837500 | 0.609 sec/iter\n",
      "Epoch: 42 | Batch: 009 / 011 | Total loss: 0.476 | Reg loss: 0.015 | Tree loss: 0.476 | Accuracy: 0.820500 | 0.608 sec/iter\n",
      "Epoch: 42 | Batch: 010 / 011 | Total loss: 0.473 | Reg loss: 0.015 | Tree loss: 0.473 | Accuracy: 0.819113 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 43 | Batch: 000 / 011 | Total loss: 0.548 | Reg loss: 0.015 | Tree loss: 0.548 | Accuracy: 0.702000 | 0.619 sec/iter\n",
      "Epoch: 43 | Batch: 001 / 011 | Total loss: 0.538 | Reg loss: 0.015 | Tree loss: 0.538 | Accuracy: 0.710500 | 0.619 sec/iter\n",
      "Epoch: 43 | Batch: 002 / 011 | Total loss: 0.512 | Reg loss: 0.015 | Tree loss: 0.512 | Accuracy: 0.734500 | 0.618 sec/iter\n",
      "Epoch: 43 | Batch: 003 / 011 | Total loss: 0.516 | Reg loss: 0.015 | Tree loss: 0.516 | Accuracy: 0.727500 | 0.617 sec/iter\n",
      "Epoch: 43 | Batch: 004 / 011 | Total loss: 0.490 | Reg loss: 0.015 | Tree loss: 0.490 | Accuracy: 0.763000 | 0.616 sec/iter\n",
      "Epoch: 43 | Batch: 005 / 011 | Total loss: 0.501 | Reg loss: 0.015 | Tree loss: 0.501 | Accuracy: 0.784500 | 0.616 sec/iter\n",
      "Epoch: 43 | Batch: 006 / 011 | Total loss: 0.489 | Reg loss: 0.015 | Tree loss: 0.489 | Accuracy: 0.803000 | 0.615 sec/iter\n",
      "Epoch: 43 | Batch: 007 / 011 | Total loss: 0.501 | Reg loss: 0.015 | Tree loss: 0.501 | Accuracy: 0.777000 | 0.614 sec/iter\n",
      "Epoch: 43 | Batch: 008 / 011 | Total loss: 0.472 | Reg loss: 0.015 | Tree loss: 0.472 | Accuracy: 0.850500 | 0.614 sec/iter\n",
      "Epoch: 43 | Batch: 009 / 011 | Total loss: 0.485 | Reg loss: 0.015 | Tree loss: 0.485 | Accuracy: 0.809000 | 0.613 sec/iter\n",
      "Epoch: 43 | Batch: 010 / 011 | Total loss: 0.451 | Reg loss: 0.015 | Tree loss: 0.451 | Accuracy: 0.846416 | 0.612 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 44 | Batch: 000 / 011 | Total loss: 0.563 | Reg loss: 0.015 | Tree loss: 0.563 | Accuracy: 0.678500 | 0.625 sec/iter\n",
      "Epoch: 44 | Batch: 001 / 011 | Total loss: 0.538 | Reg loss: 0.015 | Tree loss: 0.538 | Accuracy: 0.706000 | 0.625 sec/iter\n",
      "Epoch: 44 | Batch: 002 / 011 | Total loss: 0.510 | Reg loss: 0.015 | Tree loss: 0.510 | Accuracy: 0.727500 | 0.624 sec/iter\n",
      "Epoch: 44 | Batch: 003 / 011 | Total loss: 0.494 | Reg loss: 0.015 | Tree loss: 0.494 | Accuracy: 0.775000 | 0.623 sec/iter\n",
      "Epoch: 44 | Batch: 004 / 011 | Total loss: 0.500 | Reg loss: 0.015 | Tree loss: 0.500 | Accuracy: 0.786000 | 0.622 sec/iter\n",
      "Epoch: 44 | Batch: 005 / 011 | Total loss: 0.496 | Reg loss: 0.015 | Tree loss: 0.496 | Accuracy: 0.786000 | 0.622 sec/iter\n",
      "Epoch: 44 | Batch: 006 / 011 | Total loss: 0.496 | Reg loss: 0.015 | Tree loss: 0.496 | Accuracy: 0.784000 | 0.621 sec/iter\n",
      "Epoch: 44 | Batch: 007 / 011 | Total loss: 0.491 | Reg loss: 0.015 | Tree loss: 0.491 | Accuracy: 0.784500 | 0.62 sec/iter\n",
      "Epoch: 44 | Batch: 008 / 011 | Total loss: 0.468 | Reg loss: 0.015 | Tree loss: 0.468 | Accuracy: 0.850500 | 0.619 sec/iter\n",
      "Epoch: 44 | Batch: 009 / 011 | Total loss: 0.471 | Reg loss: 0.016 | Tree loss: 0.471 | Accuracy: 0.826000 | 0.619 sec/iter\n",
      "Epoch: 44 | Batch: 010 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.815700 | 0.618 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 45 | Batch: 000 / 011 | Total loss: 0.546 | Reg loss: 0.015 | Tree loss: 0.546 | Accuracy: 0.700000 | 0.631 sec/iter\n",
      "Epoch: 45 | Batch: 001 / 011 | Total loss: 0.530 | Reg loss: 0.015 | Tree loss: 0.530 | Accuracy: 0.706500 | 0.63 sec/iter\n",
      "Epoch: 45 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.015 | Tree loss: 0.505 | Accuracy: 0.734500 | 0.629 sec/iter\n",
      "Epoch: 45 | Batch: 003 / 011 | Total loss: 0.500 | Reg loss: 0.015 | Tree loss: 0.500 | Accuracy: 0.769000 | 0.628 sec/iter\n",
      "Epoch: 45 | Batch: 004 / 011 | Total loss: 0.495 | Reg loss: 0.015 | Tree loss: 0.495 | Accuracy: 0.777500 | 0.628 sec/iter\n",
      "Epoch: 45 | Batch: 005 / 011 | Total loss: 0.497 | Reg loss: 0.015 | Tree loss: 0.497 | Accuracy: 0.783000 | 0.627 sec/iter\n",
      "Epoch: 45 | Batch: 006 / 011 | Total loss: 0.488 | Reg loss: 0.016 | Tree loss: 0.488 | Accuracy: 0.800000 | 0.626 sec/iter\n",
      "Epoch: 45 | Batch: 007 / 011 | Total loss: 0.484 | Reg loss: 0.016 | Tree loss: 0.484 | Accuracy: 0.786500 | 0.626 sec/iter\n",
      "Epoch: 45 | Batch: 008 / 011 | Total loss: 0.468 | Reg loss: 0.016 | Tree loss: 0.468 | Accuracy: 0.812500 | 0.625 sec/iter\n",
      "Epoch: 45 | Batch: 009 / 011 | Total loss: 0.470 | Reg loss: 0.016 | Tree loss: 0.470 | Accuracy: 0.841500 | 0.624 sec/iter\n",
      "Epoch: 45 | Batch: 010 / 011 | Total loss: 0.504 | Reg loss: 0.016 | Tree loss: 0.504 | Accuracy: 0.781570 | 0.624 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 46 | Batch: 000 / 011 | Total loss: 0.540 | Reg loss: 0.015 | Tree loss: 0.540 | Accuracy: 0.708000 | 0.634 sec/iter\n",
      "Epoch: 46 | Batch: 001 / 011 | Total loss: 0.535 | Reg loss: 0.015 | Tree loss: 0.535 | Accuracy: 0.709000 | 0.633 sec/iter\n",
      "Epoch: 46 | Batch: 002 / 011 | Total loss: 0.510 | Reg loss: 0.015 | Tree loss: 0.510 | Accuracy: 0.716500 | 0.632 sec/iter\n",
      "Epoch: 46 | Batch: 003 / 011 | Total loss: 0.494 | Reg loss: 0.016 | Tree loss: 0.494 | Accuracy: 0.749500 | 0.631 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Batch: 004 / 011 | Total loss: 0.504 | Reg loss: 0.016 | Tree loss: 0.504 | Accuracy: 0.756500 | 0.631 sec/iter\n",
      "Epoch: 46 | Batch: 005 / 011 | Total loss: 0.502 | Reg loss: 0.016 | Tree loss: 0.502 | Accuracy: 0.772500 | 0.63 sec/iter\n",
      "Epoch: 46 | Batch: 006 / 011 | Total loss: 0.494 | Reg loss: 0.016 | Tree loss: 0.494 | Accuracy: 0.799000 | 0.629 sec/iter\n",
      "Epoch: 46 | Batch: 007 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.809000 | 0.628 sec/iter\n",
      "Epoch: 46 | Batch: 008 / 011 | Total loss: 0.468 | Reg loss: 0.016 | Tree loss: 0.468 | Accuracy: 0.833000 | 0.628 sec/iter\n",
      "Epoch: 46 | Batch: 009 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.831000 | 0.627 sec/iter\n",
      "Epoch: 46 | Batch: 010 / 011 | Total loss: 0.498 | Reg loss: 0.016 | Tree loss: 0.498 | Accuracy: 0.767918 | 0.626 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 47 | Batch: 000 / 011 | Total loss: 0.563 | Reg loss: 0.016 | Tree loss: 0.563 | Accuracy: 0.677500 | 0.633 sec/iter\n",
      "Epoch: 47 | Batch: 001 / 011 | Total loss: 0.539 | Reg loss: 0.016 | Tree loss: 0.539 | Accuracy: 0.700000 | 0.632 sec/iter\n",
      "Epoch: 47 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.016 | Tree loss: 0.505 | Accuracy: 0.731000 | 0.632 sec/iter\n",
      "Epoch: 47 | Batch: 003 / 011 | Total loss: 0.504 | Reg loss: 0.016 | Tree loss: 0.504 | Accuracy: 0.740500 | 0.631 sec/iter\n",
      "Epoch: 47 | Batch: 004 / 011 | Total loss: 0.484 | Reg loss: 0.016 | Tree loss: 0.484 | Accuracy: 0.769500 | 0.63 sec/iter\n",
      "Epoch: 47 | Batch: 005 / 011 | Total loss: 0.498 | Reg loss: 0.016 | Tree loss: 0.498 | Accuracy: 0.779500 | 0.629 sec/iter\n",
      "Epoch: 47 | Batch: 006 / 011 | Total loss: 0.492 | Reg loss: 0.016 | Tree loss: 0.492 | Accuracy: 0.800500 | 0.629 sec/iter\n",
      "Epoch: 47 | Batch: 007 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.810000 | 0.628 sec/iter\n",
      "Epoch: 47 | Batch: 008 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.833000 | 0.627 sec/iter\n",
      "Epoch: 47 | Batch: 009 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.840000 | 0.627 sec/iter\n",
      "Epoch: 47 | Batch: 010 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.815700 | 0.626 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 48 | Batch: 000 / 011 | Total loss: 0.558 | Reg loss: 0.016 | Tree loss: 0.558 | Accuracy: 0.693500 | 0.632 sec/iter\n",
      "Epoch: 48 | Batch: 001 / 011 | Total loss: 0.536 | Reg loss: 0.016 | Tree loss: 0.536 | Accuracy: 0.708500 | 0.632 sec/iter\n",
      "Epoch: 48 | Batch: 002 / 011 | Total loss: 0.508 | Reg loss: 0.016 | Tree loss: 0.508 | Accuracy: 0.723500 | 0.631 sec/iter\n",
      "Epoch: 48 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.016 | Tree loss: 0.482 | Accuracy: 0.776500 | 0.63 sec/iter\n",
      "Epoch: 48 | Batch: 004 / 011 | Total loss: 0.494 | Reg loss: 0.016 | Tree loss: 0.494 | Accuracy: 0.770000 | 0.629 sec/iter\n",
      "Epoch: 48 | Batch: 005 / 011 | Total loss: 0.494 | Reg loss: 0.016 | Tree loss: 0.494 | Accuracy: 0.790500 | 0.629 sec/iter\n",
      "Epoch: 48 | Batch: 006 / 011 | Total loss: 0.483 | Reg loss: 0.016 | Tree loss: 0.483 | Accuracy: 0.803000 | 0.628 sec/iter\n",
      "Epoch: 48 | Batch: 007 / 011 | Total loss: 0.475 | Reg loss: 0.016 | Tree loss: 0.475 | Accuracy: 0.805500 | 0.627 sec/iter\n",
      "Epoch: 48 | Batch: 008 / 011 | Total loss: 0.469 | Reg loss: 0.016 | Tree loss: 0.469 | Accuracy: 0.833500 | 0.627 sec/iter\n",
      "Epoch: 48 | Batch: 009 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.819000 | 0.626 sec/iter\n",
      "Epoch: 48 | Batch: 010 / 011 | Total loss: 0.452 | Reg loss: 0.016 | Tree loss: 0.452 | Accuracy: 0.832765 | 0.625 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 49 | Batch: 000 / 011 | Total loss: 0.545 | Reg loss: 0.016 | Tree loss: 0.545 | Accuracy: 0.698500 | 0.632 sec/iter\n",
      "Epoch: 49 | Batch: 001 / 011 | Total loss: 0.523 | Reg loss: 0.016 | Tree loss: 0.523 | Accuracy: 0.722500 | 0.632 sec/iter\n",
      "Epoch: 49 | Batch: 002 / 011 | Total loss: 0.504 | Reg loss: 0.016 | Tree loss: 0.504 | Accuracy: 0.729500 | 0.631 sec/iter\n",
      "Epoch: 49 | Batch: 003 / 011 | Total loss: 0.487 | Reg loss: 0.016 | Tree loss: 0.487 | Accuracy: 0.782500 | 0.63 sec/iter\n",
      "Epoch: 49 | Batch: 004 / 011 | Total loss: 0.503 | Reg loss: 0.016 | Tree loss: 0.503 | Accuracy: 0.758000 | 0.629 sec/iter\n",
      "Epoch: 49 | Batch: 005 / 011 | Total loss: 0.493 | Reg loss: 0.016 | Tree loss: 0.493 | Accuracy: 0.779000 | 0.629 sec/iter\n",
      "Epoch: 49 | Batch: 006 / 011 | Total loss: 0.495 | Reg loss: 0.016 | Tree loss: 0.495 | Accuracy: 0.782500 | 0.628 sec/iter\n",
      "Epoch: 49 | Batch: 007 / 011 | Total loss: 0.474 | Reg loss: 0.016 | Tree loss: 0.474 | Accuracy: 0.800500 | 0.627 sec/iter\n",
      "Epoch: 49 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.839500 | 0.627 sec/iter\n",
      "Epoch: 49 | Batch: 009 / 011 | Total loss: 0.455 | Reg loss: 0.016 | Tree loss: 0.455 | Accuracy: 0.823500 | 0.626 sec/iter\n",
      "Epoch: 49 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.016 | Tree loss: 0.433 | Accuracy: 0.849829 | 0.625 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 50 | Batch: 000 / 011 | Total loss: 0.561 | Reg loss: 0.016 | Tree loss: 0.561 | Accuracy: 0.687500 | 0.632 sec/iter\n",
      "Epoch: 50 | Batch: 001 / 011 | Total loss: 0.529 | Reg loss: 0.016 | Tree loss: 0.529 | Accuracy: 0.717000 | 0.631 sec/iter\n",
      "Epoch: 50 | Batch: 002 / 011 | Total loss: 0.508 | Reg loss: 0.016 | Tree loss: 0.508 | Accuracy: 0.742000 | 0.63 sec/iter\n",
      "Epoch: 50 | Batch: 003 / 011 | Total loss: 0.493 | Reg loss: 0.016 | Tree loss: 0.493 | Accuracy: 0.777500 | 0.63 sec/iter\n",
      "Epoch: 50 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.016 | Tree loss: 0.464 | Accuracy: 0.807500 | 0.629 sec/iter\n",
      "Epoch: 50 | Batch: 005 / 011 | Total loss: 0.478 | Reg loss: 0.016 | Tree loss: 0.478 | Accuracy: 0.803500 | 0.628 sec/iter\n",
      "Epoch: 50 | Batch: 006 / 011 | Total loss: 0.477 | Reg loss: 0.016 | Tree loss: 0.477 | Accuracy: 0.795000 | 0.628 sec/iter\n",
      "Epoch: 50 | Batch: 007 / 011 | Total loss: 0.469 | Reg loss: 0.016 | Tree loss: 0.469 | Accuracy: 0.803000 | 0.627 sec/iter\n",
      "Epoch: 50 | Batch: 008 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.811000 | 0.626 sec/iter\n",
      "Epoch: 50 | Batch: 009 / 011 | Total loss: 0.453 | Reg loss: 0.016 | Tree loss: 0.453 | Accuracy: 0.848500 | 0.626 sec/iter\n",
      "Epoch: 50 | Batch: 010 / 011 | Total loss: 0.468 | Reg loss: 0.016 | Tree loss: 0.468 | Accuracy: 0.802048 | 0.625 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 51 | Batch: 000 / 011 | Total loss: 0.542 | Reg loss: 0.016 | Tree loss: 0.542 | Accuracy: 0.704500 | 0.631 sec/iter\n",
      "Epoch: 51 | Batch: 001 / 011 | Total loss: 0.540 | Reg loss: 0.016 | Tree loss: 0.540 | Accuracy: 0.705000 | 0.63 sec/iter\n",
      "Epoch: 51 | Batch: 002 / 011 | Total loss: 0.510 | Reg loss: 0.016 | Tree loss: 0.510 | Accuracy: 0.741000 | 0.63 sec/iter\n",
      "Epoch: 51 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.016 | Tree loss: 0.484 | Accuracy: 0.783000 | 0.629 sec/iter\n",
      "Epoch: 51 | Batch: 004 / 011 | Total loss: 0.469 | Reg loss: 0.016 | Tree loss: 0.469 | Accuracy: 0.804500 | 0.628 sec/iter\n",
      "Epoch: 51 | Batch: 005 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.809000 | 0.628 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | Batch: 006 / 011 | Total loss: 0.492 | Reg loss: 0.016 | Tree loss: 0.492 | Accuracy: 0.796500 | 0.627 sec/iter\n",
      "Epoch: 51 | Batch: 007 / 011 | Total loss: 0.479 | Reg loss: 0.016 | Tree loss: 0.479 | Accuracy: 0.804000 | 0.626 sec/iter\n",
      "Epoch: 51 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.016 | Tree loss: 0.457 | Accuracy: 0.817000 | 0.626 sec/iter\n",
      "Epoch: 51 | Batch: 009 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.841000 | 0.625 sec/iter\n",
      "Epoch: 51 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.016 | Tree loss: 0.443 | Accuracy: 0.853242 | 0.624 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 52 | Batch: 000 / 011 | Total loss: 0.546 | Reg loss: 0.016 | Tree loss: 0.546 | Accuracy: 0.704500 | 0.626 sec/iter\n",
      "Epoch: 52 | Batch: 001 / 011 | Total loss: 0.527 | Reg loss: 0.016 | Tree loss: 0.527 | Accuracy: 0.725000 | 0.625 sec/iter\n",
      "Epoch: 52 | Batch: 002 / 011 | Total loss: 0.513 | Reg loss: 0.016 | Tree loss: 0.513 | Accuracy: 0.735000 | 0.624 sec/iter\n",
      "Epoch: 52 | Batch: 003 / 011 | Total loss: 0.474 | Reg loss: 0.016 | Tree loss: 0.474 | Accuracy: 0.794000 | 0.624 sec/iter\n",
      "Epoch: 52 | Batch: 004 / 011 | Total loss: 0.480 | Reg loss: 0.016 | Tree loss: 0.480 | Accuracy: 0.806500 | 0.623 sec/iter\n",
      "Epoch: 52 | Batch: 005 / 011 | Total loss: 0.480 | Reg loss: 0.016 | Tree loss: 0.480 | Accuracy: 0.799000 | 0.622 sec/iter\n",
      "Epoch: 52 | Batch: 006 / 011 | Total loss: 0.477 | Reg loss: 0.016 | Tree loss: 0.477 | Accuracy: 0.803500 | 0.622 sec/iter\n",
      "Epoch: 52 | Batch: 007 / 011 | Total loss: 0.455 | Reg loss: 0.016 | Tree loss: 0.455 | Accuracy: 0.820000 | 0.621 sec/iter\n",
      "Epoch: 52 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.802500 | 0.62 sec/iter\n",
      "Epoch: 52 | Batch: 009 / 011 | Total loss: 0.444 | Reg loss: 0.016 | Tree loss: 0.444 | Accuracy: 0.837000 | 0.62 sec/iter\n",
      "Epoch: 52 | Batch: 010 / 011 | Total loss: 0.457 | Reg loss: 0.016 | Tree loss: 0.457 | Accuracy: 0.846416 | 0.619 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 53 | Batch: 000 / 011 | Total loss: 0.542 | Reg loss: 0.016 | Tree loss: 0.542 | Accuracy: 0.704500 | 0.623 sec/iter\n",
      "Epoch: 53 | Batch: 001 / 011 | Total loss: 0.533 | Reg loss: 0.016 | Tree loss: 0.533 | Accuracy: 0.719500 | 0.622 sec/iter\n",
      "Epoch: 53 | Batch: 002 / 011 | Total loss: 0.505 | Reg loss: 0.016 | Tree loss: 0.505 | Accuracy: 0.751500 | 0.621 sec/iter\n",
      "Epoch: 53 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.016 | Tree loss: 0.481 | Accuracy: 0.763000 | 0.621 sec/iter\n",
      "Epoch: 53 | Batch: 004 / 011 | Total loss: 0.470 | Reg loss: 0.016 | Tree loss: 0.470 | Accuracy: 0.822000 | 0.62 sec/iter\n",
      "Epoch: 53 | Batch: 005 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.798000 | 0.619 sec/iter\n",
      "Epoch: 53 | Batch: 006 / 011 | Total loss: 0.481 | Reg loss: 0.016 | Tree loss: 0.481 | Accuracy: 0.799500 | 0.619 sec/iter\n",
      "Epoch: 53 | Batch: 007 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.803000 | 0.618 sec/iter\n",
      "Epoch: 53 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.794000 | 0.617 sec/iter\n",
      "Epoch: 53 | Batch: 009 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.820000 | 0.617 sec/iter\n",
      "Epoch: 53 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.016 | Tree loss: 0.440 | Accuracy: 0.866894 | 0.616 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 54 | Batch: 000 / 011 | Total loss: 0.542 | Reg loss: 0.016 | Tree loss: 0.542 | Accuracy: 0.724500 | 0.616 sec/iter\n",
      "Epoch: 54 | Batch: 001 / 011 | Total loss: 0.542 | Reg loss: 0.016 | Tree loss: 0.542 | Accuracy: 0.730500 | 0.615 sec/iter\n",
      "Epoch: 54 | Batch: 002 / 011 | Total loss: 0.525 | Reg loss: 0.016 | Tree loss: 0.525 | Accuracy: 0.733500 | 0.615 sec/iter\n",
      "Epoch: 54 | Batch: 003 / 011 | Total loss: 0.482 | Reg loss: 0.016 | Tree loss: 0.482 | Accuracy: 0.773000 | 0.614 sec/iter\n",
      "Epoch: 54 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.016 | Tree loss: 0.453 | Accuracy: 0.808500 | 0.613 sec/iter\n",
      "Epoch: 54 | Batch: 005 / 011 | Total loss: 0.479 | Reg loss: 0.016 | Tree loss: 0.479 | Accuracy: 0.788500 | 0.613 sec/iter\n",
      "Epoch: 54 | Batch: 006 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.810000 | 0.612 sec/iter\n",
      "Epoch: 54 | Batch: 007 / 011 | Total loss: 0.474 | Reg loss: 0.016 | Tree loss: 0.474 | Accuracy: 0.788000 | 0.611 sec/iter\n",
      "Epoch: 54 | Batch: 008 / 011 | Total loss: 0.473 | Reg loss: 0.016 | Tree loss: 0.473 | Accuracy: 0.795500 | 0.611 sec/iter\n",
      "Epoch: 54 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.016 | Tree loss: 0.454 | Accuracy: 0.807000 | 0.61 sec/iter\n",
      "Epoch: 54 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.016 | Tree loss: 0.427 | Accuracy: 0.890785 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 55 | Batch: 000 / 011 | Total loss: 0.549 | Reg loss: 0.016 | Tree loss: 0.549 | Accuracy: 0.722000 | 0.613 sec/iter\n",
      "Epoch: 55 | Batch: 001 / 011 | Total loss: 0.528 | Reg loss: 0.016 | Tree loss: 0.528 | Accuracy: 0.738500 | 0.613 sec/iter\n",
      "Epoch: 55 | Batch: 002 / 011 | Total loss: 0.513 | Reg loss: 0.016 | Tree loss: 0.513 | Accuracy: 0.758000 | 0.612 sec/iter\n",
      "Epoch: 55 | Batch: 003 / 011 | Total loss: 0.487 | Reg loss: 0.016 | Tree loss: 0.487 | Accuracy: 0.784500 | 0.611 sec/iter\n",
      "Epoch: 55 | Batch: 004 / 011 | Total loss: 0.461 | Reg loss: 0.016 | Tree loss: 0.461 | Accuracy: 0.815000 | 0.611 sec/iter\n",
      "Epoch: 55 | Batch: 005 / 011 | Total loss: 0.456 | Reg loss: 0.016 | Tree loss: 0.456 | Accuracy: 0.810500 | 0.61 sec/iter\n",
      "Epoch: 55 | Batch: 006 / 011 | Total loss: 0.468 | Reg loss: 0.016 | Tree loss: 0.468 | Accuracy: 0.807500 | 0.609 sec/iter\n",
      "Epoch: 55 | Batch: 007 / 011 | Total loss: 0.470 | Reg loss: 0.016 | Tree loss: 0.470 | Accuracy: 0.794000 | 0.609 sec/iter\n",
      "Epoch: 55 | Batch: 008 / 011 | Total loss: 0.450 | Reg loss: 0.016 | Tree loss: 0.450 | Accuracy: 0.811000 | 0.608 sec/iter\n",
      "Epoch: 55 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.016 | Tree loss: 0.454 | Accuracy: 0.819000 | 0.607 sec/iter\n",
      "Epoch: 55 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.016 | Tree loss: 0.423 | Accuracy: 0.883959 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 56 | Batch: 000 / 011 | Total loss: 0.535 | Reg loss: 0.016 | Tree loss: 0.535 | Accuracy: 0.728000 | 0.61 sec/iter\n",
      "Epoch: 56 | Batch: 001 / 011 | Total loss: 0.513 | Reg loss: 0.016 | Tree loss: 0.513 | Accuracy: 0.740000 | 0.61 sec/iter\n",
      "Epoch: 56 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.016 | Tree loss: 0.492 | Accuracy: 0.779500 | 0.609 sec/iter\n",
      "Epoch: 56 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.016 | Tree loss: 0.480 | Accuracy: 0.775500 | 0.609 sec/iter\n",
      "Epoch: 56 | Batch: 004 / 011 | Total loss: 0.479 | Reg loss: 0.016 | Tree loss: 0.479 | Accuracy: 0.792500 | 0.608 sec/iter\n",
      "Epoch: 56 | Batch: 005 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.802000 | 0.607 sec/iter\n",
      "Epoch: 56 | Batch: 006 / 011 | Total loss: 0.465 | Reg loss: 0.016 | Tree loss: 0.465 | Accuracy: 0.804000 | 0.607 sec/iter\n",
      "Epoch: 56 | Batch: 007 / 011 | Total loss: 0.478 | Reg loss: 0.016 | Tree loss: 0.478 | Accuracy: 0.793500 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | Batch: 008 / 011 | Total loss: 0.452 | Reg loss: 0.016 | Tree loss: 0.452 | Accuracy: 0.807500 | 0.606 sec/iter\n",
      "Epoch: 56 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.016 | Tree loss: 0.454 | Accuracy: 0.807000 | 0.605 sec/iter\n",
      "Epoch: 56 | Batch: 010 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.853242 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 57 | Batch: 000 / 011 | Total loss: 0.541 | Reg loss: 0.016 | Tree loss: 0.541 | Accuracy: 0.716000 | 0.605 sec/iter\n",
      "Epoch: 57 | Batch: 001 / 011 | Total loss: 0.523 | Reg loss: 0.016 | Tree loss: 0.523 | Accuracy: 0.760500 | 0.604 sec/iter\n",
      "Epoch: 57 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.016 | Tree loss: 0.490 | Accuracy: 0.772000 | 0.603 sec/iter\n",
      "Epoch: 57 | Batch: 003 / 011 | Total loss: 0.494 | Reg loss: 0.016 | Tree loss: 0.494 | Accuracy: 0.772500 | 0.603 sec/iter\n",
      "Epoch: 57 | Batch: 004 / 011 | Total loss: 0.451 | Reg loss: 0.016 | Tree loss: 0.451 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 57 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.016 | Tree loss: 0.463 | Accuracy: 0.806500 | 0.602 sec/iter\n",
      "Epoch: 57 | Batch: 006 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.809000 | 0.601 sec/iter\n",
      "Epoch: 57 | Batch: 007 / 011 | Total loss: 0.470 | Reg loss: 0.016 | Tree loss: 0.470 | Accuracy: 0.798000 | 0.601 sec/iter\n",
      "Epoch: 57 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.798500 | 0.6 sec/iter\n",
      "Epoch: 57 | Batch: 009 / 011 | Total loss: 0.454 | Reg loss: 0.016 | Tree loss: 0.454 | Accuracy: 0.810000 | 0.6 sec/iter\n",
      "Epoch: 57 | Batch: 010 / 011 | Total loss: 0.425 | Reg loss: 0.016 | Tree loss: 0.425 | Accuracy: 0.873720 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 58 | Batch: 000 / 011 | Total loss: 0.538 | Reg loss: 0.016 | Tree loss: 0.538 | Accuracy: 0.724500 | 0.606 sec/iter\n",
      "Epoch: 58 | Batch: 001 / 011 | Total loss: 0.497 | Reg loss: 0.016 | Tree loss: 0.497 | Accuracy: 0.770000 | 0.606 sec/iter\n",
      "Epoch: 58 | Batch: 002 / 011 | Total loss: 0.490 | Reg loss: 0.016 | Tree loss: 0.490 | Accuracy: 0.773000 | 0.605 sec/iter\n",
      "Epoch: 58 | Batch: 003 / 011 | Total loss: 0.469 | Reg loss: 0.016 | Tree loss: 0.469 | Accuracy: 0.796000 | 0.604 sec/iter\n",
      "Epoch: 58 | Batch: 004 / 011 | Total loss: 0.476 | Reg loss: 0.016 | Tree loss: 0.476 | Accuracy: 0.799000 | 0.604 sec/iter\n",
      "Epoch: 58 | Batch: 005 / 011 | Total loss: 0.463 | Reg loss: 0.016 | Tree loss: 0.463 | Accuracy: 0.792000 | 0.603 sec/iter\n",
      "Epoch: 58 | Batch: 006 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.804500 | 0.603 sec/iter\n",
      "Epoch: 58 | Batch: 007 / 011 | Total loss: 0.456 | Reg loss: 0.016 | Tree loss: 0.456 | Accuracy: 0.811000 | 0.602 sec/iter\n",
      "Epoch: 58 | Batch: 008 / 011 | Total loss: 0.454 | Reg loss: 0.016 | Tree loss: 0.454 | Accuracy: 0.806500 | 0.601 sec/iter\n",
      "Epoch: 58 | Batch: 009 / 011 | Total loss: 0.435 | Reg loss: 0.016 | Tree loss: 0.435 | Accuracy: 0.834500 | 0.601 sec/iter\n",
      "Epoch: 58 | Batch: 010 / 011 | Total loss: 0.431 | Reg loss: 0.016 | Tree loss: 0.431 | Accuracy: 0.843003 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 59 | Batch: 000 / 011 | Total loss: 0.517 | Reg loss: 0.016 | Tree loss: 0.517 | Accuracy: 0.743500 | 0.607 sec/iter\n",
      "Epoch: 59 | Batch: 001 / 011 | Total loss: 0.518 | Reg loss: 0.016 | Tree loss: 0.518 | Accuracy: 0.748500 | 0.606 sec/iter\n",
      "Epoch: 59 | Batch: 002 / 011 | Total loss: 0.500 | Reg loss: 0.016 | Tree loss: 0.500 | Accuracy: 0.772500 | 0.606 sec/iter\n",
      "Epoch: 59 | Batch: 003 / 011 | Total loss: 0.475 | Reg loss: 0.016 | Tree loss: 0.475 | Accuracy: 0.798500 | 0.605 sec/iter\n",
      "Epoch: 59 | Batch: 004 / 011 | Total loss: 0.474 | Reg loss: 0.016 | Tree loss: 0.474 | Accuracy: 0.800000 | 0.605 sec/iter\n",
      "Epoch: 59 | Batch: 005 / 011 | Total loss: 0.455 | Reg loss: 0.016 | Tree loss: 0.455 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 59 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 59 | Batch: 007 / 011 | Total loss: 0.461 | Reg loss: 0.016 | Tree loss: 0.461 | Accuracy: 0.807000 | 0.603 sec/iter\n",
      "Epoch: 59 | Batch: 008 / 011 | Total loss: 0.449 | Reg loss: 0.016 | Tree loss: 0.449 | Accuracy: 0.806500 | 0.602 sec/iter\n",
      "Epoch: 59 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.016 | Tree loss: 0.436 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 59 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.016 | Tree loss: 0.428 | Accuracy: 0.853242 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 60 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.016 | Tree loss: 0.518 | Accuracy: 0.749000 | 0.602 sec/iter\n",
      "Epoch: 60 | Batch: 001 / 011 | Total loss: 0.520 | Reg loss: 0.016 | Tree loss: 0.520 | Accuracy: 0.751500 | 0.602 sec/iter\n",
      "Epoch: 60 | Batch: 002 / 011 | Total loss: 0.497 | Reg loss: 0.016 | Tree loss: 0.497 | Accuracy: 0.767000 | 0.601 sec/iter\n",
      "Epoch: 60 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.016 | Tree loss: 0.477 | Accuracy: 0.792000 | 0.601 sec/iter\n",
      "Epoch: 60 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.805000 | 0.6 sec/iter\n",
      "Epoch: 60 | Batch: 005 / 011 | Total loss: 0.449 | Reg loss: 0.016 | Tree loss: 0.449 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 60 | Batch: 006 / 011 | Total loss: 0.457 | Reg loss: 0.016 | Tree loss: 0.457 | Accuracy: 0.815500 | 0.599 sec/iter\n",
      "Epoch: 60 | Batch: 007 / 011 | Total loss: 0.471 | Reg loss: 0.016 | Tree loss: 0.471 | Accuracy: 0.789000 | 0.599 sec/iter\n",
      "Epoch: 60 | Batch: 008 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.797500 | 0.598 sec/iter\n",
      "Epoch: 60 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.016 | Tree loss: 0.438 | Accuracy: 0.813000 | 0.598 sec/iter\n",
      "Epoch: 60 | Batch: 010 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.829352 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 61 | Batch: 000 / 011 | Total loss: 0.529 | Reg loss: 0.016 | Tree loss: 0.529 | Accuracy: 0.745500 | 0.604 sec/iter\n",
      "Epoch: 61 | Batch: 001 / 011 | Total loss: 0.527 | Reg loss: 0.016 | Tree loss: 0.527 | Accuracy: 0.752000 | 0.603 sec/iter\n",
      "Epoch: 61 | Batch: 002 / 011 | Total loss: 0.494 | Reg loss: 0.016 | Tree loss: 0.494 | Accuracy: 0.769000 | 0.603 sec/iter\n",
      "Epoch: 61 | Batch: 003 / 011 | Total loss: 0.477 | Reg loss: 0.016 | Tree loss: 0.477 | Accuracy: 0.781000 | 0.602 sec/iter\n",
      "Epoch: 61 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.016 | Tree loss: 0.453 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 61 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.016 | Tree loss: 0.450 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 61 | Batch: 006 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.805500 | 0.6 sec/iter\n",
      "Epoch: 61 | Batch: 007 / 011 | Total loss: 0.474 | Reg loss: 0.016 | Tree loss: 0.474 | Accuracy: 0.800000 | 0.6 sec/iter\n",
      "Epoch: 61 | Batch: 008 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.792000 | 0.599 sec/iter\n",
      "Epoch: 61 | Batch: 009 / 011 | Total loss: 0.440 | Reg loss: 0.016 | Tree loss: 0.440 | Accuracy: 0.809000 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.016 | Tree loss: 0.442 | Accuracy: 0.825939 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 62 | Batch: 000 / 011 | Total loss: 0.533 | Reg loss: 0.016 | Tree loss: 0.533 | Accuracy: 0.746000 | 0.607 sec/iter\n",
      "Epoch: 62 | Batch: 001 / 011 | Total loss: 0.505 | Reg loss: 0.016 | Tree loss: 0.505 | Accuracy: 0.778500 | 0.607 sec/iter\n",
      "Epoch: 62 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.016 | Tree loss: 0.484 | Accuracy: 0.780500 | 0.606 sec/iter\n",
      "Epoch: 62 | Batch: 003 / 011 | Total loss: 0.481 | Reg loss: 0.016 | Tree loss: 0.481 | Accuracy: 0.794000 | 0.606 sec/iter\n",
      "Epoch: 62 | Batch: 004 / 011 | Total loss: 0.444 | Reg loss: 0.016 | Tree loss: 0.444 | Accuracy: 0.818000 | 0.605 sec/iter\n",
      "Epoch: 62 | Batch: 005 / 011 | Total loss: 0.446 | Reg loss: 0.016 | Tree loss: 0.446 | Accuracy: 0.824000 | 0.605 sec/iter\n",
      "Epoch: 62 | Batch: 006 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.789000 | 0.604 sec/iter\n",
      "Epoch: 62 | Batch: 007 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.806000 | 0.604 sec/iter\n",
      "Epoch: 62 | Batch: 008 / 011 | Total loss: 0.463 | Reg loss: 0.016 | Tree loss: 0.463 | Accuracy: 0.791000 | 0.603 sec/iter\n",
      "Epoch: 62 | Batch: 009 / 011 | Total loss: 0.442 | Reg loss: 0.016 | Tree loss: 0.442 | Accuracy: 0.799500 | 0.603 sec/iter\n",
      "Epoch: 62 | Batch: 010 / 011 | Total loss: 0.435 | Reg loss: 0.016 | Tree loss: 0.435 | Accuracy: 0.839590 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 63 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.016 | Tree loss: 0.518 | Accuracy: 0.756000 | 0.609 sec/iter\n",
      "Epoch: 63 | Batch: 001 / 011 | Total loss: 0.521 | Reg loss: 0.016 | Tree loss: 0.521 | Accuracy: 0.767000 | 0.609 sec/iter\n",
      "Epoch: 63 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.016 | Tree loss: 0.491 | Accuracy: 0.768000 | 0.608 sec/iter\n",
      "Epoch: 63 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.016 | Tree loss: 0.470 | Accuracy: 0.795000 | 0.608 sec/iter\n",
      "Epoch: 63 | Batch: 004 / 011 | Total loss: 0.463 | Reg loss: 0.016 | Tree loss: 0.463 | Accuracy: 0.796500 | 0.608 sec/iter\n",
      "Epoch: 63 | Batch: 005 / 011 | Total loss: 0.450 | Reg loss: 0.016 | Tree loss: 0.450 | Accuracy: 0.819500 | 0.607 sec/iter\n",
      "Epoch: 63 | Batch: 006 / 011 | Total loss: 0.467 | Reg loss: 0.016 | Tree loss: 0.467 | Accuracy: 0.793500 | 0.607 sec/iter\n",
      "Epoch: 63 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.016 | Tree loss: 0.438 | Accuracy: 0.814000 | 0.606 sec/iter\n",
      "Epoch: 63 | Batch: 008 / 011 | Total loss: 0.457 | Reg loss: 0.016 | Tree loss: 0.457 | Accuracy: 0.794500 | 0.606 sec/iter\n",
      "Epoch: 63 | Batch: 009 / 011 | Total loss: 0.441 | Reg loss: 0.016 | Tree loss: 0.441 | Accuracy: 0.805000 | 0.605 sec/iter\n",
      "Epoch: 63 | Batch: 010 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.757679 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 64 | Batch: 000 / 011 | Total loss: 0.521 | Reg loss: 0.016 | Tree loss: 0.521 | Accuracy: 0.748000 | 0.614 sec/iter\n",
      "Epoch: 64 | Batch: 001 / 011 | Total loss: 0.518 | Reg loss: 0.016 | Tree loss: 0.518 | Accuracy: 0.771000 | 0.613 sec/iter\n",
      "Epoch: 64 | Batch: 002 / 011 | Total loss: 0.492 | Reg loss: 0.016 | Tree loss: 0.492 | Accuracy: 0.760000 | 0.613 sec/iter\n",
      "Epoch: 64 | Batch: 003 / 011 | Total loss: 0.484 | Reg loss: 0.016 | Tree loss: 0.484 | Accuracy: 0.776000 | 0.612 sec/iter\n",
      "Epoch: 64 | Batch: 004 / 011 | Total loss: 0.453 | Reg loss: 0.016 | Tree loss: 0.453 | Accuracy: 0.823000 | 0.612 sec/iter\n",
      "Epoch: 64 | Batch: 005 / 011 | Total loss: 0.440 | Reg loss: 0.016 | Tree loss: 0.440 | Accuracy: 0.837000 | 0.611 sec/iter\n",
      "Epoch: 64 | Batch: 006 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.798000 | 0.61 sec/iter\n",
      "Epoch: 64 | Batch: 007 / 011 | Total loss: 0.472 | Reg loss: 0.016 | Tree loss: 0.472 | Accuracy: 0.794500 | 0.61 sec/iter\n",
      "Epoch: 64 | Batch: 008 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.798500 | 0.609 sec/iter\n",
      "Epoch: 64 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.016 | Tree loss: 0.429 | Accuracy: 0.818500 | 0.609 sec/iter\n",
      "Epoch: 64 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.016 | Tree loss: 0.410 | Accuracy: 0.839590 | 0.609 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 65 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.016 | Tree loss: 0.518 | Accuracy: 0.743500 | 0.618 sec/iter\n",
      "Epoch: 65 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.016 | Tree loss: 0.510 | Accuracy: 0.761500 | 0.617 sec/iter\n",
      "Epoch: 65 | Batch: 002 / 011 | Total loss: 0.496 | Reg loss: 0.016 | Tree loss: 0.496 | Accuracy: 0.776000 | 0.617 sec/iter\n",
      "Epoch: 65 | Batch: 003 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.788000 | 0.616 sec/iter\n",
      "Epoch: 65 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.016 | Tree loss: 0.450 | Accuracy: 0.808500 | 0.616 sec/iter\n",
      "Epoch: 65 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.016 | Tree loss: 0.445 | Accuracy: 0.816000 | 0.615 sec/iter\n",
      "Epoch: 65 | Batch: 006 / 011 | Total loss: 0.455 | Reg loss: 0.016 | Tree loss: 0.455 | Accuracy: 0.801500 | 0.615 sec/iter\n",
      "Epoch: 65 | Batch: 007 / 011 | Total loss: 0.446 | Reg loss: 0.016 | Tree loss: 0.446 | Accuracy: 0.814000 | 0.614 sec/iter\n",
      "Epoch: 65 | Batch: 008 / 011 | Total loss: 0.456 | Reg loss: 0.016 | Tree loss: 0.456 | Accuracy: 0.800000 | 0.614 sec/iter\n",
      "Epoch: 65 | Batch: 009 / 011 | Total loss: 0.431 | Reg loss: 0.016 | Tree loss: 0.431 | Accuracy: 0.823500 | 0.614 sec/iter\n",
      "Epoch: 65 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.016 | Tree loss: 0.454 | Accuracy: 0.832765 | 0.613 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 66 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.016 | Tree loss: 0.515 | Accuracy: 0.755500 | 0.62 sec/iter\n",
      "Epoch: 66 | Batch: 001 / 011 | Total loss: 0.510 | Reg loss: 0.016 | Tree loss: 0.510 | Accuracy: 0.760500 | 0.62 sec/iter\n",
      "Epoch: 66 | Batch: 002 / 011 | Total loss: 0.485 | Reg loss: 0.016 | Tree loss: 0.485 | Accuracy: 0.781000 | 0.619 sec/iter\n",
      "Epoch: 66 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.016 | Tree loss: 0.467 | Accuracy: 0.795000 | 0.619 sec/iter\n",
      "Epoch: 66 | Batch: 004 / 011 | Total loss: 0.452 | Reg loss: 0.016 | Tree loss: 0.452 | Accuracy: 0.814000 | 0.618 sec/iter\n",
      "Epoch: 66 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.016 | Tree loss: 0.437 | Accuracy: 0.837500 | 0.618 sec/iter\n",
      "Epoch: 66 | Batch: 006 / 011 | Total loss: 0.453 | Reg loss: 0.016 | Tree loss: 0.453 | Accuracy: 0.817000 | 0.618 sec/iter\n",
      "Epoch: 66 | Batch: 007 / 011 | Total loss: 0.460 | Reg loss: 0.016 | Tree loss: 0.460 | Accuracy: 0.801000 | 0.617 sec/iter\n",
      "Epoch: 66 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.785000 | 0.617 sec/iter\n",
      "Epoch: 66 | Batch: 009 / 011 | Total loss: 0.446 | Reg loss: 0.016 | Tree loss: 0.446 | Accuracy: 0.803500 | 0.616 sec/iter\n",
      "Epoch: 66 | Batch: 010 / 011 | Total loss: 0.421 | Reg loss: 0.016 | Tree loss: 0.421 | Accuracy: 0.815700 | 0.616 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 67 | Batch: 000 / 011 | Total loss: 0.531 | Reg loss: 0.016 | Tree loss: 0.531 | Accuracy: 0.743000 | 0.623 sec/iter\n",
      "Epoch: 67 | Batch: 001 / 011 | Total loss: 0.509 | Reg loss: 0.016 | Tree loss: 0.509 | Accuracy: 0.758000 | 0.622 sec/iter\n",
      "Epoch: 67 | Batch: 002 / 011 | Total loss: 0.501 | Reg loss: 0.016 | Tree loss: 0.501 | Accuracy: 0.755000 | 0.622 sec/iter\n",
      "Epoch: 67 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.016 | Tree loss: 0.467 | Accuracy: 0.791500 | 0.622 sec/iter\n",
      "Epoch: 67 | Batch: 004 / 011 | Total loss: 0.436 | Reg loss: 0.016 | Tree loss: 0.436 | Accuracy: 0.816000 | 0.621 sec/iter\n",
      "Epoch: 67 | Batch: 005 / 011 | Total loss: 0.439 | Reg loss: 0.016 | Tree loss: 0.439 | Accuracy: 0.815500 | 0.621 sec/iter\n",
      "Epoch: 67 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.016 | Tree loss: 0.448 | Accuracy: 0.804000 | 0.62 sec/iter\n",
      "Epoch: 67 | Batch: 007 / 011 | Total loss: 0.464 | Reg loss: 0.016 | Tree loss: 0.464 | Accuracy: 0.797000 | 0.62 sec/iter\n",
      "Epoch: 67 | Batch: 008 / 011 | Total loss: 0.451 | Reg loss: 0.016 | Tree loss: 0.451 | Accuracy: 0.802000 | 0.619 sec/iter\n",
      "Epoch: 67 | Batch: 009 / 011 | Total loss: 0.427 | Reg loss: 0.016 | Tree loss: 0.427 | Accuracy: 0.808500 | 0.619 sec/iter\n",
      "Epoch: 67 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.016 | Tree loss: 0.433 | Accuracy: 0.788396 | 0.618 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 68 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.016 | Tree loss: 0.515 | Accuracy: 0.750000 | 0.627 sec/iter\n",
      "Epoch: 68 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.016 | Tree loss: 0.486 | Accuracy: 0.771000 | 0.626 sec/iter\n",
      "Epoch: 68 | Batch: 002 / 011 | Total loss: 0.506 | Reg loss: 0.016 | Tree loss: 0.506 | Accuracy: 0.746000 | 0.626 sec/iter\n",
      "Epoch: 68 | Batch: 003 / 011 | Total loss: 0.480 | Reg loss: 0.016 | Tree loss: 0.480 | Accuracy: 0.780000 | 0.625 sec/iter\n",
      "Epoch: 68 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.804000 | 0.625 sec/iter\n",
      "Epoch: 68 | Batch: 005 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.816000 | 0.624 sec/iter\n",
      "Epoch: 68 | Batch: 006 / 011 | Total loss: 0.438 | Reg loss: 0.016 | Tree loss: 0.438 | Accuracy: 0.816000 | 0.624 sec/iter\n",
      "Epoch: 68 | Batch: 007 / 011 | Total loss: 0.451 | Reg loss: 0.016 | Tree loss: 0.451 | Accuracy: 0.803000 | 0.623 sec/iter\n",
      "Epoch: 68 | Batch: 008 / 011 | Total loss: 0.452 | Reg loss: 0.016 | Tree loss: 0.452 | Accuracy: 0.782000 | 0.623 sec/iter\n",
      "Epoch: 68 | Batch: 009 / 011 | Total loss: 0.438 | Reg loss: 0.016 | Tree loss: 0.438 | Accuracy: 0.798000 | 0.622 sec/iter\n",
      "Epoch: 68 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.016 | Tree loss: 0.403 | Accuracy: 0.822526 | 0.622 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 69 | Batch: 000 / 011 | Total loss: 0.518 | Reg loss: 0.016 | Tree loss: 0.518 | Accuracy: 0.742000 | 0.622 sec/iter\n",
      "Epoch: 69 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.016 | Tree loss: 0.502 | Accuracy: 0.753000 | 0.621 sec/iter\n",
      "Epoch: 69 | Batch: 002 / 011 | Total loss: 0.489 | Reg loss: 0.016 | Tree loss: 0.489 | Accuracy: 0.775000 | 0.621 sec/iter\n",
      "Epoch: 69 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.796000 | 0.62 sec/iter\n",
      "Epoch: 69 | Batch: 004 / 011 | Total loss: 0.464 | Reg loss: 0.016 | Tree loss: 0.464 | Accuracy: 0.801500 | 0.62 sec/iter\n",
      "Epoch: 69 | Batch: 005 / 011 | Total loss: 0.423 | Reg loss: 0.016 | Tree loss: 0.423 | Accuracy: 0.841500 | 0.619 sec/iter\n",
      "Epoch: 69 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.016 | Tree loss: 0.448 | Accuracy: 0.813000 | 0.619 sec/iter\n",
      "Epoch: 69 | Batch: 007 / 011 | Total loss: 0.448 | Reg loss: 0.016 | Tree loss: 0.448 | Accuracy: 0.800000 | 0.618 sec/iter\n",
      "Epoch: 69 | Batch: 008 / 011 | Total loss: 0.462 | Reg loss: 0.016 | Tree loss: 0.462 | Accuracy: 0.790000 | 0.618 sec/iter\n",
      "Epoch: 69 | Batch: 009 / 011 | Total loss: 0.429 | Reg loss: 0.016 | Tree loss: 0.429 | Accuracy: 0.807500 | 0.618 sec/iter\n",
      "Epoch: 69 | Batch: 010 / 011 | Total loss: 0.443 | Reg loss: 0.016 | Tree loss: 0.443 | Accuracy: 0.843003 | 0.617 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 70 | Batch: 000 / 011 | Total loss: 0.506 | Reg loss: 0.016 | Tree loss: 0.506 | Accuracy: 0.748000 | 0.623 sec/iter\n",
      "Epoch: 70 | Batch: 001 / 011 | Total loss: 0.515 | Reg loss: 0.016 | Tree loss: 0.515 | Accuracy: 0.743500 | 0.622 sec/iter\n",
      "Epoch: 70 | Batch: 002 / 011 | Total loss: 0.509 | Reg loss: 0.016 | Tree loss: 0.509 | Accuracy: 0.752500 | 0.622 sec/iter\n",
      "Epoch: 70 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.016 | Tree loss: 0.459 | Accuracy: 0.800000 | 0.621 sec/iter\n",
      "Epoch: 70 | Batch: 004 / 011 | Total loss: 0.458 | Reg loss: 0.016 | Tree loss: 0.458 | Accuracy: 0.800500 | 0.621 sec/iter\n",
      "Epoch: 70 | Batch: 005 / 011 | Total loss: 0.432 | Reg loss: 0.016 | Tree loss: 0.432 | Accuracy: 0.837000 | 0.62 sec/iter\n",
      "Epoch: 70 | Batch: 006 / 011 | Total loss: 0.442 | Reg loss: 0.016 | Tree loss: 0.442 | Accuracy: 0.810500 | 0.62 sec/iter\n",
      "Epoch: 70 | Batch: 007 / 011 | Total loss: 0.443 | Reg loss: 0.016 | Tree loss: 0.443 | Accuracy: 0.808000 | 0.619 sec/iter\n",
      "Epoch: 70 | Batch: 008 / 011 | Total loss: 0.447 | Reg loss: 0.016 | Tree loss: 0.447 | Accuracy: 0.798500 | 0.619 sec/iter\n",
      "Epoch: 70 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809000 | 0.618 sec/iter\n",
      "Epoch: 70 | Batch: 010 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.894198 | 0.618 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 71 | Batch: 000 / 011 | Total loss: 0.515 | Reg loss: 0.016 | Tree loss: 0.515 | Accuracy: 0.742000 | 0.623 sec/iter\n",
      "Epoch: 71 | Batch: 001 / 011 | Total loss: 0.504 | Reg loss: 0.016 | Tree loss: 0.504 | Accuracy: 0.762000 | 0.623 sec/iter\n",
      "Epoch: 71 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.016 | Tree loss: 0.481 | Accuracy: 0.774500 | 0.622 sec/iter\n",
      "Epoch: 71 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.016 | Tree loss: 0.456 | Accuracy: 0.791000 | 0.622 sec/iter\n",
      "Epoch: 71 | Batch: 004 / 011 | Total loss: 0.440 | Reg loss: 0.016 | Tree loss: 0.440 | Accuracy: 0.810000 | 0.621 sec/iter\n",
      "Epoch: 71 | Batch: 005 / 011 | Total loss: 0.441 | Reg loss: 0.016 | Tree loss: 0.441 | Accuracy: 0.814500 | 0.621 sec/iter\n",
      "Epoch: 71 | Batch: 006 / 011 | Total loss: 0.444 | Reg loss: 0.016 | Tree loss: 0.444 | Accuracy: 0.807000 | 0.621 sec/iter\n",
      "Epoch: 71 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.016 | Tree loss: 0.438 | Accuracy: 0.817500 | 0.62 sec/iter\n",
      "Epoch: 71 | Batch: 008 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.796000 | 0.62 sec/iter\n",
      "Epoch: 71 | Batch: 009 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.823000 | 0.619 sec/iter\n",
      "Epoch: 71 | Batch: 010 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.802048 | 0.619 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 72 | Batch: 000 / 011 | Total loss: 0.503 | Reg loss: 0.016 | Tree loss: 0.503 | Accuracy: 0.752500 | 0.619 sec/iter\n",
      "Epoch: 72 | Batch: 001 / 011 | Total loss: 0.498 | Reg loss: 0.016 | Tree loss: 0.498 | Accuracy: 0.761000 | 0.619 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 | Batch: 002 / 011 | Total loss: 0.491 | Reg loss: 0.016 | Tree loss: 0.491 | Accuracy: 0.772000 | 0.618 sec/iter\n",
      "Epoch: 72 | Batch: 003 / 011 | Total loss: 0.467 | Reg loss: 0.016 | Tree loss: 0.467 | Accuracy: 0.784000 | 0.618 sec/iter\n",
      "Epoch: 72 | Batch: 004 / 011 | Total loss: 0.442 | Reg loss: 0.016 | Tree loss: 0.442 | Accuracy: 0.819500 | 0.617 sec/iter\n",
      "Epoch: 72 | Batch: 005 / 011 | Total loss: 0.426 | Reg loss: 0.016 | Tree loss: 0.426 | Accuracy: 0.834000 | 0.617 sec/iter\n",
      "Epoch: 72 | Batch: 006 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.801500 | 0.616 sec/iter\n",
      "Epoch: 72 | Batch: 007 / 011 | Total loss: 0.462 | Reg loss: 0.017 | Tree loss: 0.462 | Accuracy: 0.793500 | 0.616 sec/iter\n",
      "Epoch: 72 | Batch: 008 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.816000 | 0.616 sec/iter\n",
      "Epoch: 72 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.812500 | 0.615 sec/iter\n",
      "Epoch: 72 | Batch: 010 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.832765 | 0.615 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 73 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.016 | Tree loss: 0.499 | Accuracy: 0.750500 | 0.618 sec/iter\n",
      "Epoch: 73 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.016 | Tree loss: 0.491 | Accuracy: 0.754500 | 0.617 sec/iter\n",
      "Epoch: 73 | Batch: 002 / 011 | Total loss: 0.487 | Reg loss: 0.016 | Tree loss: 0.487 | Accuracy: 0.763500 | 0.617 sec/iter\n",
      "Epoch: 73 | Batch: 003 / 011 | Total loss: 0.453 | Reg loss: 0.017 | Tree loss: 0.453 | Accuracy: 0.796000 | 0.616 sec/iter\n",
      "Epoch: 73 | Batch: 004 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.809000 | 0.616 sec/iter\n",
      "Epoch: 73 | Batch: 005 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.821000 | 0.615 sec/iter\n",
      "Epoch: 73 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.808500 | 0.615 sec/iter\n",
      "Epoch: 73 | Batch: 007 / 011 | Total loss: 0.449 | Reg loss: 0.017 | Tree loss: 0.449 | Accuracy: 0.790000 | 0.614 sec/iter\n",
      "Epoch: 73 | Batch: 008 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.809500 | 0.614 sec/iter\n",
      "Epoch: 73 | Batch: 009 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.819500 | 0.613 sec/iter\n",
      "Epoch: 73 | Batch: 010 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.846416 | 0.613 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 74 | Batch: 000 / 011 | Total loss: 0.510 | Reg loss: 0.017 | Tree loss: 0.510 | Accuracy: 0.748500 | 0.616 sec/iter\n",
      "Epoch: 74 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.017 | Tree loss: 0.486 | Accuracy: 0.768500 | 0.615 sec/iter\n",
      "Epoch: 74 | Batch: 002 / 011 | Total loss: 0.478 | Reg loss: 0.017 | Tree loss: 0.478 | Accuracy: 0.778000 | 0.615 sec/iter\n",
      "Epoch: 74 | Batch: 003 / 011 | Total loss: 0.456 | Reg loss: 0.017 | Tree loss: 0.456 | Accuracy: 0.791500 | 0.614 sec/iter\n",
      "Epoch: 74 | Batch: 004 / 011 | Total loss: 0.448 | Reg loss: 0.017 | Tree loss: 0.448 | Accuracy: 0.819000 | 0.614 sec/iter\n",
      "Epoch: 74 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.813500 | 0.613 sec/iter\n",
      "Epoch: 74 | Batch: 006 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.799500 | 0.613 sec/iter\n",
      "Epoch: 74 | Batch: 007 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.818000 | 0.612 sec/iter\n",
      "Epoch: 74 | Batch: 008 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.822000 | 0.612 sec/iter\n",
      "Epoch: 74 | Batch: 009 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.809000 | 0.611 sec/iter\n",
      "Epoch: 74 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.883959 | 0.611 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 75 | Batch: 000 / 011 | Total loss: 0.509 | Reg loss: 0.017 | Tree loss: 0.509 | Accuracy: 0.751500 | 0.611 sec/iter\n",
      "Epoch: 75 | Batch: 001 / 011 | Total loss: 0.482 | Reg loss: 0.017 | Tree loss: 0.482 | Accuracy: 0.774500 | 0.611 sec/iter\n",
      "Epoch: 75 | Batch: 002 / 011 | Total loss: 0.467 | Reg loss: 0.017 | Tree loss: 0.467 | Accuracy: 0.775500 | 0.61 sec/iter\n",
      "Epoch: 75 | Batch: 003 / 011 | Total loss: 0.459 | Reg loss: 0.017 | Tree loss: 0.459 | Accuracy: 0.790000 | 0.61 sec/iter\n",
      "Epoch: 75 | Batch: 004 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.806000 | 0.609 sec/iter\n",
      "Epoch: 75 | Batch: 005 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.827000 | 0.609 sec/iter\n",
      "Epoch: 75 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.809500 | 0.609 sec/iter\n",
      "Epoch: 75 | Batch: 007 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.793500 | 0.608 sec/iter\n",
      "Epoch: 75 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.805500 | 0.608 sec/iter\n",
      "Epoch: 75 | Batch: 009 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.808000 | 0.607 sec/iter\n",
      "Epoch: 75 | Batch: 010 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.856655 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 76 | Batch: 000 / 011 | Total loss: 0.488 | Reg loss: 0.017 | Tree loss: 0.488 | Accuracy: 0.766500 | 0.612 sec/iter\n",
      "Epoch: 76 | Batch: 001 / 011 | Total loss: 0.502 | Reg loss: 0.017 | Tree loss: 0.502 | Accuracy: 0.752500 | 0.612 sec/iter\n",
      "Epoch: 76 | Batch: 002 / 011 | Total loss: 0.484 | Reg loss: 0.017 | Tree loss: 0.484 | Accuracy: 0.778500 | 0.611 sec/iter\n",
      "Epoch: 76 | Batch: 003 / 011 | Total loss: 0.449 | Reg loss: 0.017 | Tree loss: 0.449 | Accuracy: 0.802000 | 0.611 sec/iter\n",
      "Epoch: 76 | Batch: 004 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.819000 | 0.611 sec/iter\n",
      "Epoch: 76 | Batch: 005 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.817500 | 0.61 sec/iter\n",
      "Epoch: 76 | Batch: 006 / 011 | Total loss: 0.448 | Reg loss: 0.017 | Tree loss: 0.448 | Accuracy: 0.792000 | 0.61 sec/iter\n",
      "Epoch: 76 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.800000 | 0.609 sec/iter\n",
      "Epoch: 76 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.803500 | 0.609 sec/iter\n",
      "Epoch: 76 | Batch: 009 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.819000 | 0.608 sec/iter\n",
      "Epoch: 76 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.860068 | 0.608 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 77 | Batch: 000 / 011 | Total loss: 0.494 | Reg loss: 0.017 | Tree loss: 0.494 | Accuracy: 0.750000 | 0.611 sec/iter\n",
      "Epoch: 77 | Batch: 001 / 011 | Total loss: 0.475 | Reg loss: 0.017 | Tree loss: 0.475 | Accuracy: 0.776000 | 0.611 sec/iter\n",
      "Epoch: 77 | Batch: 002 / 011 | Total loss: 0.466 | Reg loss: 0.017 | Tree loss: 0.466 | Accuracy: 0.774000 | 0.611 sec/iter\n",
      "Epoch: 77 | Batch: 003 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.804000 | 0.61 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 | Batch: 004 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.812000 | 0.61 sec/iter\n",
      "Epoch: 77 | Batch: 005 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.826500 | 0.609 sec/iter\n",
      "Epoch: 77 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.800500 | 0.609 sec/iter\n",
      "Epoch: 77 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.800000 | 0.608 sec/iter\n",
      "Epoch: 77 | Batch: 008 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.795500 | 0.608 sec/iter\n",
      "Epoch: 77 | Batch: 009 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.806500 | 0.608 sec/iter\n",
      "Epoch: 77 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.853242 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 78 | Batch: 000 / 011 | Total loss: 0.499 | Reg loss: 0.017 | Tree loss: 0.499 | Accuracy: 0.739500 | 0.607 sec/iter\n",
      "Epoch: 78 | Batch: 001 / 011 | Total loss: 0.501 | Reg loss: 0.017 | Tree loss: 0.501 | Accuracy: 0.757500 | 0.607 sec/iter\n",
      "Epoch: 78 | Batch: 002 / 011 | Total loss: 0.480 | Reg loss: 0.017 | Tree loss: 0.480 | Accuracy: 0.773500 | 0.607 sec/iter\n",
      "Epoch: 78 | Batch: 003 / 011 | Total loss: 0.454 | Reg loss: 0.017 | Tree loss: 0.454 | Accuracy: 0.798000 | 0.606 sec/iter\n",
      "Epoch: 78 | Batch: 004 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.818000 | 0.606 sec/iter\n",
      "Epoch: 78 | Batch: 005 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.835000 | 0.605 sec/iter\n",
      "Epoch: 78 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.801000 | 0.605 sec/iter\n",
      "Epoch: 78 | Batch: 007 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.807500 | 0.605 sec/iter\n",
      "Epoch: 78 | Batch: 008 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.794000 | 0.604 sec/iter\n",
      "Epoch: 78 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.830500 | 0.604 sec/iter\n",
      "Epoch: 78 | Batch: 010 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.832765 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 79 | Batch: 000 / 011 | Total loss: 0.501 | Reg loss: 0.017 | Tree loss: 0.501 | Accuracy: 0.743000 | 0.609 sec/iter\n",
      "Epoch: 79 | Batch: 001 / 011 | Total loss: 0.488 | Reg loss: 0.017 | Tree loss: 0.488 | Accuracy: 0.754000 | 0.608 sec/iter\n",
      "Epoch: 79 | Batch: 002 / 011 | Total loss: 0.477 | Reg loss: 0.017 | Tree loss: 0.477 | Accuracy: 0.768500 | 0.608 sec/iter\n",
      "Epoch: 79 | Batch: 003 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.801500 | 0.607 sec/iter\n",
      "Epoch: 79 | Batch: 004 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.815500 | 0.607 sec/iter\n",
      "Epoch: 79 | Batch: 005 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.837500 | 0.607 sec/iter\n",
      "Epoch: 79 | Batch: 006 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.809000 | 0.606 sec/iter\n",
      "Epoch: 79 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.806000 | 0.606 sec/iter\n",
      "Epoch: 79 | Batch: 008 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.807000 | 0.605 sec/iter\n",
      "Epoch: 79 | Batch: 009 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 79 | Batch: 010 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.795222 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 80 | Batch: 000 / 011 | Total loss: 0.477 | Reg loss: 0.017 | Tree loss: 0.477 | Accuracy: 0.779500 | 0.61 sec/iter\n",
      "Epoch: 80 | Batch: 001 / 011 | Total loss: 0.494 | Reg loss: 0.017 | Tree loss: 0.494 | Accuracy: 0.755500 | 0.609 sec/iter\n",
      "Epoch: 80 | Batch: 002 / 011 | Total loss: 0.481 | Reg loss: 0.017 | Tree loss: 0.481 | Accuracy: 0.764000 | 0.609 sec/iter\n",
      "Epoch: 80 | Batch: 003 / 011 | Total loss: 0.470 | Reg loss: 0.017 | Tree loss: 0.470 | Accuracy: 0.782000 | 0.609 sec/iter\n",
      "Epoch: 80 | Batch: 004 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.833000 | 0.608 sec/iter\n",
      "Epoch: 80 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.826500 | 0.608 sec/iter\n",
      "Epoch: 80 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.789500 | 0.608 sec/iter\n",
      "Epoch: 80 | Batch: 007 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.790000 | 0.607 sec/iter\n",
      "Epoch: 80 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.811000 | 0.607 sec/iter\n",
      "Epoch: 80 | Batch: 009 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.788500 | 0.606 sec/iter\n",
      "Epoch: 80 | Batch: 010 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.832765 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 81 | Batch: 000 / 011 | Total loss: 0.475 | Reg loss: 0.017 | Tree loss: 0.475 | Accuracy: 0.767500 | 0.608 sec/iter\n",
      "Epoch: 81 | Batch: 001 / 011 | Total loss: 0.491 | Reg loss: 0.017 | Tree loss: 0.491 | Accuracy: 0.747500 | 0.608 sec/iter\n",
      "Epoch: 81 | Batch: 002 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.790500 | 0.608 sec/iter\n",
      "Epoch: 81 | Batch: 003 / 011 | Total loss: 0.471 | Reg loss: 0.017 | Tree loss: 0.471 | Accuracy: 0.777000 | 0.607 sec/iter\n",
      "Epoch: 81 | Batch: 004 / 011 | Total loss: 0.454 | Reg loss: 0.017 | Tree loss: 0.454 | Accuracy: 0.797000 | 0.607 sec/iter\n",
      "Epoch: 81 | Batch: 005 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.815500 | 0.607 sec/iter\n",
      "Epoch: 81 | Batch: 006 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.806500 | 0.606 sec/iter\n",
      "Epoch: 81 | Batch: 007 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.799500 | 0.606 sec/iter\n",
      "Epoch: 81 | Batch: 008 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.796000 | 0.606 sec/iter\n",
      "Epoch: 81 | Batch: 009 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.810500 | 0.605 sec/iter\n",
      "Epoch: 81 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.860068 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 82 | Batch: 000 / 011 | Total loss: 0.491 | Reg loss: 0.017 | Tree loss: 0.491 | Accuracy: 0.758500 | 0.608 sec/iter\n",
      "Epoch: 82 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.017 | Tree loss: 0.486 | Accuracy: 0.762500 | 0.608 sec/iter\n",
      "Epoch: 82 | Batch: 002 / 011 | Total loss: 0.471 | Reg loss: 0.017 | Tree loss: 0.471 | Accuracy: 0.782500 | 0.607 sec/iter\n",
      "Epoch: 82 | Batch: 003 / 011 | Total loss: 0.458 | Reg loss: 0.017 | Tree loss: 0.458 | Accuracy: 0.802500 | 0.607 sec/iter\n",
      "Epoch: 82 | Batch: 004 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.832000 | 0.607 sec/iter\n",
      "Epoch: 82 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.825500 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 | Batch: 006 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809000 | 0.606 sec/iter\n",
      "Epoch: 82 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 82 | Batch: 008 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.806000 | 0.605 sec/iter\n",
      "Epoch: 82 | Batch: 009 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 82 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.849829 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 83 | Batch: 000 / 011 | Total loss: 0.476 | Reg loss: 0.017 | Tree loss: 0.476 | Accuracy: 0.774500 | 0.609 sec/iter\n",
      "Epoch: 83 | Batch: 001 / 011 | Total loss: 0.486 | Reg loss: 0.017 | Tree loss: 0.486 | Accuracy: 0.754000 | 0.609 sec/iter\n",
      "Epoch: 83 | Batch: 002 / 011 | Total loss: 0.472 | Reg loss: 0.017 | Tree loss: 0.472 | Accuracy: 0.761500 | 0.609 sec/iter\n",
      "Epoch: 83 | Batch: 003 / 011 | Total loss: 0.452 | Reg loss: 0.017 | Tree loss: 0.452 | Accuracy: 0.788500 | 0.608 sec/iter\n",
      "Epoch: 83 | Batch: 004 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.815500 | 0.608 sec/iter\n",
      "Epoch: 83 | Batch: 005 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.835000 | 0.607 sec/iter\n",
      "Epoch: 83 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.790500 | 0.607 sec/iter\n",
      "Epoch: 83 | Batch: 007 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.802000 | 0.607 sec/iter\n",
      "Epoch: 83 | Batch: 008 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.817500 | 0.606 sec/iter\n",
      "Epoch: 83 | Batch: 009 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.814000 | 0.606 sec/iter\n",
      "Epoch: 83 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.863481 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 84 | Batch: 000 / 011 | Total loss: 0.490 | Reg loss: 0.017 | Tree loss: 0.490 | Accuracy: 0.757000 | 0.61 sec/iter\n",
      "Epoch: 84 | Batch: 001 / 011 | Total loss: 0.476 | Reg loss: 0.017 | Tree loss: 0.476 | Accuracy: 0.780000 | 0.61 sec/iter\n",
      "Epoch: 84 | Batch: 002 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.779500 | 0.61 sec/iter\n",
      "Epoch: 84 | Batch: 003 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.811500 | 0.61 sec/iter\n",
      "Epoch: 84 | Batch: 004 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.815500 | 0.609 sec/iter\n",
      "Epoch: 84 | Batch: 005 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.822000 | 0.609 sec/iter\n",
      "Epoch: 84 | Batch: 006 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.808500 | 0.609 sec/iter\n",
      "Epoch: 84 | Batch: 007 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.804500 | 0.608 sec/iter\n",
      "Epoch: 84 | Batch: 008 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.820000 | 0.608 sec/iter\n",
      "Epoch: 84 | Batch: 009 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.830000 | 0.608 sec/iter\n",
      "Epoch: 84 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.846416 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 85 | Batch: 000 / 011 | Total loss: 0.498 | Reg loss: 0.017 | Tree loss: 0.498 | Accuracy: 0.749500 | 0.614 sec/iter\n",
      "Epoch: 85 | Batch: 001 / 011 | Total loss: 0.466 | Reg loss: 0.017 | Tree loss: 0.466 | Accuracy: 0.790500 | 0.613 sec/iter\n",
      "Epoch: 85 | Batch: 002 / 011 | Total loss: 0.464 | Reg loss: 0.017 | Tree loss: 0.464 | Accuracy: 0.778000 | 0.613 sec/iter\n",
      "Epoch: 85 | Batch: 003 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.814000 | 0.613 sec/iter\n",
      "Epoch: 85 | Batch: 004 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.828500 | 0.612 sec/iter\n",
      "Epoch: 85 | Batch: 005 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.833000 | 0.612 sec/iter\n",
      "Epoch: 85 | Batch: 006 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.794000 | 0.612 sec/iter\n",
      "Epoch: 85 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809000 | 0.611 sec/iter\n",
      "Epoch: 85 | Batch: 008 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.814500 | 0.611 sec/iter\n",
      "Epoch: 85 | Batch: 009 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.825000 | 0.611 sec/iter\n",
      "Epoch: 85 | Batch: 010 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.846416 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 86 | Batch: 000 / 011 | Total loss: 0.477 | Reg loss: 0.017 | Tree loss: 0.477 | Accuracy: 0.778000 | 0.616 sec/iter\n",
      "Epoch: 86 | Batch: 001 / 011 | Total loss: 0.485 | Reg loss: 0.017 | Tree loss: 0.485 | Accuracy: 0.761500 | 0.616 sec/iter\n",
      "Epoch: 86 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.017 | Tree loss: 0.470 | Accuracy: 0.774500 | 0.616 sec/iter\n",
      "Epoch: 86 | Batch: 003 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.814000 | 0.616 sec/iter\n",
      "Epoch: 86 | Batch: 004 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.828000 | 0.615 sec/iter\n",
      "Epoch: 86 | Batch: 005 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.833000 | 0.615 sec/iter\n",
      "Epoch: 86 | Batch: 006 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.804000 | 0.615 sec/iter\n",
      "Epoch: 86 | Batch: 007 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.793000 | 0.614 sec/iter\n",
      "Epoch: 86 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.812500 | 0.614 sec/iter\n",
      "Epoch: 86 | Batch: 009 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.824000 | 0.614 sec/iter\n",
      "Epoch: 86 | Batch: 010 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.815700 | 0.613 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 87 | Batch: 000 / 011 | Total loss: 0.475 | Reg loss: 0.017 | Tree loss: 0.475 | Accuracy: 0.770500 | 0.62 sec/iter\n",
      "Epoch: 87 | Batch: 001 / 011 | Total loss: 0.484 | Reg loss: 0.017 | Tree loss: 0.484 | Accuracy: 0.751000 | 0.619 sec/iter\n",
      "Epoch: 87 | Batch: 002 / 011 | Total loss: 0.470 | Reg loss: 0.017 | Tree loss: 0.470 | Accuracy: 0.775000 | 0.619 sec/iter\n",
      "Epoch: 87 | Batch: 003 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.809500 | 0.619 sec/iter\n",
      "Epoch: 87 | Batch: 004 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.825000 | 0.618 sec/iter\n",
      "Epoch: 87 | Batch: 005 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.826000 | 0.618 sec/iter\n",
      "Epoch: 87 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.801500 | 0.618 sec/iter\n",
      "Epoch: 87 | Batch: 007 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.804000 | 0.617 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 | Batch: 008 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.810000 | 0.617 sec/iter\n",
      "Epoch: 87 | Batch: 009 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809000 | 0.617 sec/iter\n",
      "Epoch: 87 | Batch: 010 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.877133 | 0.616 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 88 | Batch: 000 / 011 | Total loss: 0.483 | Reg loss: 0.017 | Tree loss: 0.483 | Accuracy: 0.766000 | 0.623 sec/iter\n",
      "Epoch: 88 | Batch: 001 / 011 | Total loss: 0.460 | Reg loss: 0.017 | Tree loss: 0.460 | Accuracy: 0.780500 | 0.622 sec/iter\n",
      "Epoch: 88 | Batch: 002 / 011 | Total loss: 0.458 | Reg loss: 0.017 | Tree loss: 0.458 | Accuracy: 0.785500 | 0.622 sec/iter\n",
      "Epoch: 88 | Batch: 003 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.800500 | 0.622 sec/iter\n",
      "Epoch: 88 | Batch: 004 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.826500 | 0.621 sec/iter\n",
      "Epoch: 88 | Batch: 005 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.838000 | 0.621 sec/iter\n",
      "Epoch: 88 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.801500 | 0.621 sec/iter\n",
      "Epoch: 88 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.800000 | 0.62 sec/iter\n",
      "Epoch: 88 | Batch: 008 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.821000 | 0.62 sec/iter\n",
      "Epoch: 88 | Batch: 009 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.834500 | 0.619 sec/iter\n",
      "Epoch: 88 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.849829 | 0.619 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 89 | Batch: 000 / 011 | Total loss: 0.475 | Reg loss: 0.017 | Tree loss: 0.475 | Accuracy: 0.782500 | 0.624 sec/iter\n",
      "Epoch: 89 | Batch: 001 / 011 | Total loss: 0.456 | Reg loss: 0.017 | Tree loss: 0.456 | Accuracy: 0.790000 | 0.623 sec/iter\n",
      "Epoch: 89 | Batch: 002 / 011 | Total loss: 0.452 | Reg loss: 0.017 | Tree loss: 0.452 | Accuracy: 0.796000 | 0.623 sec/iter\n",
      "Epoch: 89 | Batch: 003 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.799500 | 0.623 sec/iter\n",
      "Epoch: 89 | Batch: 004 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.833000 | 0.622 sec/iter\n",
      "Epoch: 89 | Batch: 005 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.806000 | 0.622 sec/iter\n",
      "Epoch: 89 | Batch: 006 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.819500 | 0.621 sec/iter\n",
      "Epoch: 89 | Batch: 007 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.813500 | 0.621 sec/iter\n",
      "Epoch: 89 | Batch: 008 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.816000 | 0.621 sec/iter\n",
      "Epoch: 89 | Batch: 009 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.829500 | 0.62 sec/iter\n",
      "Epoch: 89 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.819113 | 0.62 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 90 | Batch: 000 / 011 | Total loss: 0.465 | Reg loss: 0.017 | Tree loss: 0.465 | Accuracy: 0.787000 | 0.623 sec/iter\n",
      "Epoch: 90 | Batch: 001 / 011 | Total loss: 0.461 | Reg loss: 0.017 | Tree loss: 0.461 | Accuracy: 0.772500 | 0.623 sec/iter\n",
      "Epoch: 90 | Batch: 002 / 011 | Total loss: 0.455 | Reg loss: 0.017 | Tree loss: 0.455 | Accuracy: 0.784000 | 0.623 sec/iter\n",
      "Epoch: 90 | Batch: 003 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.813000 | 0.622 sec/iter\n",
      "Epoch: 90 | Batch: 004 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.835500 | 0.622 sec/iter\n",
      "Epoch: 90 | Batch: 005 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.811500 | 0.622 sec/iter\n",
      "Epoch: 90 | Batch: 006 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.807500 | 0.621 sec/iter\n",
      "Epoch: 90 | Batch: 007 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.817000 | 0.621 sec/iter\n",
      "Epoch: 90 | Batch: 008 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.808000 | 0.621 sec/iter\n",
      "Epoch: 90 | Batch: 009 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.845000 | 0.62 sec/iter\n",
      "Epoch: 90 | Batch: 010 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.894198 | 0.62 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 91 | Batch: 000 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.788500 | 0.623 sec/iter\n",
      "Epoch: 91 | Batch: 001 / 011 | Total loss: 0.461 | Reg loss: 0.017 | Tree loss: 0.461 | Accuracy: 0.770500 | 0.623 sec/iter\n",
      "Epoch: 91 | Batch: 002 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.795000 | 0.623 sec/iter\n",
      "Epoch: 91 | Batch: 003 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.802500 | 0.622 sec/iter\n",
      "Epoch: 91 | Batch: 004 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.829500 | 0.622 sec/iter\n",
      "Epoch: 91 | Batch: 005 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.829500 | 0.621 sec/iter\n",
      "Epoch: 91 | Batch: 006 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.794500 | 0.621 sec/iter\n",
      "Epoch: 91 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.821500 | 0.621 sec/iter\n",
      "Epoch: 91 | Batch: 008 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.818000 | 0.62 sec/iter\n",
      "Epoch: 91 | Batch: 009 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.841500 | 0.62 sec/iter\n",
      "Epoch: 91 | Batch: 010 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.849829 | 0.62 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 92 | Batch: 000 / 011 | Total loss: 0.451 | Reg loss: 0.017 | Tree loss: 0.451 | Accuracy: 0.785000 | 0.621 sec/iter\n",
      "Epoch: 92 | Batch: 001 / 011 | Total loss: 0.474 | Reg loss: 0.017 | Tree loss: 0.474 | Accuracy: 0.781000 | 0.621 sec/iter\n",
      "Epoch: 92 | Batch: 002 / 011 | Total loss: 0.455 | Reg loss: 0.017 | Tree loss: 0.455 | Accuracy: 0.785500 | 0.62 sec/iter\n",
      "Epoch: 92 | Batch: 003 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.807500 | 0.62 sec/iter\n",
      "Epoch: 92 | Batch: 004 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.821000 | 0.62 sec/iter\n",
      "Epoch: 92 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.860000 | 0.619 sec/iter\n",
      "Epoch: 92 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.817000 | 0.619 sec/iter\n",
      "Epoch: 92 | Batch: 007 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.813000 | 0.618 sec/iter\n",
      "Epoch: 92 | Batch: 008 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.813500 | 0.618 sec/iter\n",
      "Epoch: 92 | Batch: 009 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.803000 | 0.618 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 | Batch: 010 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.798635 | 0.617 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 93 | Batch: 000 / 011 | Total loss: 0.474 | Reg loss: 0.017 | Tree loss: 0.474 | Accuracy: 0.766000 | 0.619 sec/iter\n",
      "Epoch: 93 | Batch: 001 / 011 | Total loss: 0.459 | Reg loss: 0.017 | Tree loss: 0.459 | Accuracy: 0.791500 | 0.619 sec/iter\n",
      "Epoch: 93 | Batch: 002 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.800000 | 0.619 sec/iter\n",
      "Epoch: 93 | Batch: 003 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.811500 | 0.618 sec/iter\n",
      "Epoch: 93 | Batch: 004 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.823500 | 0.618 sec/iter\n",
      "Epoch: 93 | Batch: 005 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.836500 | 0.617 sec/iter\n",
      "Epoch: 93 | Batch: 006 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.811000 | 0.617 sec/iter\n",
      "Epoch: 93 | Batch: 007 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.799000 | 0.617 sec/iter\n",
      "Epoch: 93 | Batch: 008 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.810500 | 0.616 sec/iter\n",
      "Epoch: 93 | Batch: 009 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.836500 | 0.616 sec/iter\n",
      "Epoch: 93 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.825939 | 0.615 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 94 | Batch: 000 / 011 | Total loss: 0.458 | Reg loss: 0.017 | Tree loss: 0.458 | Accuracy: 0.790000 | 0.616 sec/iter\n",
      "Epoch: 94 | Batch: 001 / 011 | Total loss: 0.466 | Reg loss: 0.017 | Tree loss: 0.466 | Accuracy: 0.774500 | 0.615 sec/iter\n",
      "Epoch: 94 | Batch: 002 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.791000 | 0.615 sec/iter\n",
      "Epoch: 94 | Batch: 003 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.817000 | 0.614 sec/iter\n",
      "Epoch: 94 | Batch: 004 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.834000 | 0.614 sec/iter\n",
      "Epoch: 94 | Batch: 005 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.835500 | 0.614 sec/iter\n",
      "Epoch: 94 | Batch: 006 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.795500 | 0.613 sec/iter\n",
      "Epoch: 94 | Batch: 007 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.806500 | 0.613 sec/iter\n",
      "Epoch: 94 | Batch: 008 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.798500 | 0.613 sec/iter\n",
      "Epoch: 94 | Batch: 009 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.840500 | 0.612 sec/iter\n",
      "Epoch: 94 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.873720 | 0.612 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 95 | Batch: 000 / 011 | Total loss: 0.470 | Reg loss: 0.017 | Tree loss: 0.470 | Accuracy: 0.770500 | 0.614 sec/iter\n",
      "Epoch: 95 | Batch: 001 / 011 | Total loss: 0.459 | Reg loss: 0.017 | Tree loss: 0.459 | Accuracy: 0.776500 | 0.613 sec/iter\n",
      "Epoch: 95 | Batch: 002 / 011 | Total loss: 0.453 | Reg loss: 0.017 | Tree loss: 0.453 | Accuracy: 0.773000 | 0.613 sec/iter\n",
      "Epoch: 95 | Batch: 003 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.811500 | 0.612 sec/iter\n",
      "Epoch: 95 | Batch: 004 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.837500 | 0.612 sec/iter\n",
      "Epoch: 95 | Batch: 005 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.811500 | 0.612 sec/iter\n",
      "Epoch: 95 | Batch: 006 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.820500 | 0.611 sec/iter\n",
      "Epoch: 95 | Batch: 007 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.809000 | 0.611 sec/iter\n",
      "Epoch: 95 | Batch: 008 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.802500 | 0.611 sec/iter\n",
      "Epoch: 95 | Batch: 009 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.837000 | 0.61 sec/iter\n",
      "Epoch: 95 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.860068 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 96 | Batch: 000 / 011 | Total loss: 0.459 | Reg loss: 0.017 | Tree loss: 0.459 | Accuracy: 0.775500 | 0.614 sec/iter\n",
      "Epoch: 96 | Batch: 001 / 011 | Total loss: 0.466 | Reg loss: 0.017 | Tree loss: 0.466 | Accuracy: 0.773000 | 0.614 sec/iter\n",
      "Epoch: 96 | Batch: 002 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.792000 | 0.613 sec/iter\n",
      "Epoch: 96 | Batch: 003 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.808000 | 0.613 sec/iter\n",
      "Epoch: 96 | Batch: 004 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.834000 | 0.613 sec/iter\n",
      "Epoch: 96 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.832000 | 0.612 sec/iter\n",
      "Epoch: 96 | Batch: 006 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.798500 | 0.612 sec/iter\n",
      "Epoch: 96 | Batch: 007 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.802000 | 0.612 sec/iter\n",
      "Epoch: 96 | Batch: 008 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.810000 | 0.611 sec/iter\n",
      "Epoch: 96 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.864500 | 0.611 sec/iter\n",
      "Epoch: 96 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.860068 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 97 | Batch: 000 / 011 | Total loss: 0.466 | Reg loss: 0.017 | Tree loss: 0.466 | Accuracy: 0.785000 | 0.611 sec/iter\n",
      "Epoch: 97 | Batch: 001 / 011 | Total loss: 0.455 | Reg loss: 0.017 | Tree loss: 0.455 | Accuracy: 0.787000 | 0.611 sec/iter\n",
      "Epoch: 97 | Batch: 002 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.781500 | 0.61 sec/iter\n",
      "Epoch: 97 | Batch: 003 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.817000 | 0.61 sec/iter\n",
      "Epoch: 97 | Batch: 004 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.814500 | 0.61 sec/iter\n",
      "Epoch: 97 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.848000 | 0.609 sec/iter\n",
      "Epoch: 97 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.822500 | 0.609 sec/iter\n",
      "Epoch: 97 | Batch: 007 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.819000 | 0.609 sec/iter\n",
      "Epoch: 97 | Batch: 008 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.815500 | 0.608 sec/iter\n",
      "Epoch: 97 | Batch: 009 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.824500 | 0.608 sec/iter\n",
      "Epoch: 97 | Batch: 010 / 011 | Total loss: 0.362 | Reg loss: 0.017 | Tree loss: 0.362 | Accuracy: 0.880546 | 0.608 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 98 | Batch: 000 / 011 | Total loss: 0.467 | Reg loss: 0.017 | Tree loss: 0.467 | Accuracy: 0.766500 | 0.612 sec/iter\n",
      "Epoch: 98 | Batch: 001 / 011 | Total loss: 0.452 | Reg loss: 0.017 | Tree loss: 0.452 | Accuracy: 0.784000 | 0.612 sec/iter\n",
      "Epoch: 98 | Batch: 002 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.793500 | 0.611 sec/iter\n",
      "Epoch: 98 | Batch: 003 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.815500 | 0.611 sec/iter\n",
      "Epoch: 98 | Batch: 004 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.827500 | 0.611 sec/iter\n",
      "Epoch: 98 | Batch: 005 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.834500 | 0.61 sec/iter\n",
      "Epoch: 98 | Batch: 006 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.812000 | 0.61 sec/iter\n",
      "Epoch: 98 | Batch: 007 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.812000 | 0.61 sec/iter\n",
      "Epoch: 98 | Batch: 008 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.817000 | 0.609 sec/iter\n",
      "Epoch: 98 | Batch: 009 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.853000 | 0.609 sec/iter\n",
      "Epoch: 98 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.017 | Tree loss: 0.360 | Accuracy: 0.877133 | 0.609 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 99 | Batch: 000 / 011 | Total loss: 0.467 | Reg loss: 0.017 | Tree loss: 0.467 | Accuracy: 0.770500 | 0.613 sec/iter\n",
      "Epoch: 99 | Batch: 001 / 011 | Total loss: 0.462 | Reg loss: 0.017 | Tree loss: 0.462 | Accuracy: 0.780000 | 0.613 sec/iter\n",
      "Epoch: 99 | Batch: 002 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.804500 | 0.613 sec/iter\n",
      "Epoch: 99 | Batch: 003 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.822500 | 0.612 sec/iter\n",
      "Epoch: 99 | Batch: 004 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.840500 | 0.612 sec/iter\n",
      "Epoch: 99 | Batch: 005 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.831500 | 0.612 sec/iter\n",
      "Epoch: 99 | Batch: 006 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.807500 | 0.611 sec/iter\n",
      "Epoch: 99 | Batch: 007 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.816000 | 0.611 sec/iter\n",
      "Epoch: 99 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.826500 | 0.611 sec/iter\n",
      "Epoch: 99 | Batch: 009 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.848500 | 0.61 sec/iter\n",
      "Epoch: 99 | Batch: 010 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.877133 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 100 | Batch: 000 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.800500 | 0.613 sec/iter\n",
      "Epoch: 100 | Batch: 001 / 011 | Total loss: 0.455 | Reg loss: 0.017 | Tree loss: 0.455 | Accuracy: 0.774500 | 0.613 sec/iter\n",
      "Epoch: 100 | Batch: 002 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.789500 | 0.612 sec/iter\n",
      "Epoch: 100 | Batch: 003 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.822500 | 0.612 sec/iter\n",
      "Epoch: 100 | Batch: 004 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.824000 | 0.612 sec/iter\n",
      "Epoch: 100 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.842000 | 0.612 sec/iter\n",
      "Epoch: 100 | Batch: 006 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.804500 | 0.611 sec/iter\n",
      "Epoch: 100 | Batch: 007 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.799500 | 0.611 sec/iter\n",
      "Epoch: 100 | Batch: 008 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.825500 | 0.611 sec/iter\n",
      "Epoch: 100 | Batch: 009 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.857500 | 0.61 sec/iter\n",
      "Epoch: 100 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.866894 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 101 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.788000 | 0.613 sec/iter\n",
      "Epoch: 101 | Batch: 001 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.776000 | 0.612 sec/iter\n",
      "Epoch: 101 | Batch: 002 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.799000 | 0.612 sec/iter\n",
      "Epoch: 101 | Batch: 003 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.826000 | 0.612 sec/iter\n",
      "Epoch: 101 | Batch: 004 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.826500 | 0.611 sec/iter\n",
      "Epoch: 101 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.838500 | 0.611 sec/iter\n",
      "Epoch: 101 | Batch: 006 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.811000 | 0.611 sec/iter\n",
      "Epoch: 101 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.819000 | 0.611 sec/iter\n",
      "Epoch: 101 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.840500 | 0.61 sec/iter\n",
      "Epoch: 101 | Batch: 009 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.845500 | 0.61 sec/iter\n",
      "Epoch: 101 | Batch: 010 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.887372 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 102 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.790000 | 0.613 sec/iter\n",
      "Epoch: 102 | Batch: 001 / 011 | Total loss: 0.461 | Reg loss: 0.017 | Tree loss: 0.461 | Accuracy: 0.788000 | 0.613 sec/iter\n",
      "Epoch: 102 | Batch: 002 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.806000 | 0.612 sec/iter\n",
      "Epoch: 102 | Batch: 003 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.817000 | 0.612 sec/iter\n",
      "Epoch: 102 | Batch: 004 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.825000 | 0.612 sec/iter\n",
      "Epoch: 102 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.843500 | 0.611 sec/iter\n",
      "Epoch: 102 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.817000 | 0.611 sec/iter\n",
      "Epoch: 102 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.818000 | 0.611 sec/iter\n",
      "Epoch: 102 | Batch: 008 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.821500 | 0.61 sec/iter\n",
      "Epoch: 102 | Batch: 009 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.832500 | 0.61 sec/iter\n",
      "Epoch: 102 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.822526 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 103 | Batch: 000 / 011 | Total loss: 0.452 | Reg loss: 0.017 | Tree loss: 0.452 | Accuracy: 0.785000 | 0.613 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103 | Batch: 001 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.789500 | 0.613 sec/iter\n",
      "Epoch: 103 | Batch: 002 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.809000 | 0.613 sec/iter\n",
      "Epoch: 103 | Batch: 003 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.821000 | 0.612 sec/iter\n",
      "Epoch: 103 | Batch: 004 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.836000 | 0.612 sec/iter\n",
      "Epoch: 103 | Batch: 005 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.822500 | 0.612 sec/iter\n",
      "Epoch: 103 | Batch: 006 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.803500 | 0.611 sec/iter\n",
      "Epoch: 103 | Batch: 007 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.822000 | 0.611 sec/iter\n",
      "Epoch: 103 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.843500 | 0.611 sec/iter\n",
      "Epoch: 103 | Batch: 009 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.845500 | 0.611 sec/iter\n",
      "Epoch: 103 | Batch: 010 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.890785 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 104 | Batch: 000 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.787000 | 0.613 sec/iter\n",
      "Epoch: 104 | Batch: 001 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.804000 | 0.613 sec/iter\n",
      "Epoch: 104 | Batch: 002 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.805000 | 0.613 sec/iter\n",
      "Epoch: 104 | Batch: 003 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.815000 | 0.612 sec/iter\n",
      "Epoch: 104 | Batch: 004 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.835500 | 0.612 sec/iter\n",
      "Epoch: 104 | Batch: 005 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.836000 | 0.612 sec/iter\n",
      "Epoch: 104 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.816500 | 0.611 sec/iter\n",
      "Epoch: 104 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.843000 | 0.611 sec/iter\n",
      "Epoch: 104 | Batch: 008 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.825500 | 0.611 sec/iter\n",
      "Epoch: 104 | Batch: 009 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.838500 | 0.61 sec/iter\n",
      "Epoch: 104 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.836177 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 105 | Batch: 000 / 011 | Total loss: 0.464 | Reg loss: 0.017 | Tree loss: 0.464 | Accuracy: 0.785500 | 0.613 sec/iter\n",
      "Epoch: 105 | Batch: 001 / 011 | Total loss: 0.453 | Reg loss: 0.017 | Tree loss: 0.453 | Accuracy: 0.782000 | 0.612 sec/iter\n",
      "Epoch: 105 | Batch: 002 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.809000 | 0.612 sec/iter\n",
      "Epoch: 105 | Batch: 003 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.815500 | 0.612 sec/iter\n",
      "Epoch: 105 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.839000 | 0.611 sec/iter\n",
      "Epoch: 105 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.830500 | 0.611 sec/iter\n",
      "Epoch: 105 | Batch: 006 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.801000 | 0.611 sec/iter\n",
      "Epoch: 105 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.812000 | 0.611 sec/iter\n",
      "Epoch: 105 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.833500 | 0.61 sec/iter\n",
      "Epoch: 105 | Batch: 009 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.854500 | 0.61 sec/iter\n",
      "Epoch: 105 | Batch: 010 / 011 | Total loss: 0.353 | Reg loss: 0.017 | Tree loss: 0.353 | Accuracy: 0.901024 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 106 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.802500 | 0.613 sec/iter\n",
      "Epoch: 106 | Batch: 001 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.797500 | 0.613 sec/iter\n",
      "Epoch: 106 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.814000 | 0.612 sec/iter\n",
      "Epoch: 106 | Batch: 003 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.811000 | 0.612 sec/iter\n",
      "Epoch: 106 | Batch: 004 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.831000 | 0.612 sec/iter\n",
      "Epoch: 106 | Batch: 005 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.838000 | 0.611 sec/iter\n",
      "Epoch: 106 | Batch: 006 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.806000 | 0.611 sec/iter\n",
      "Epoch: 106 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.831500 | 0.611 sec/iter\n",
      "Epoch: 106 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.822500 | 0.61 sec/iter\n",
      "Epoch: 106 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.853500 | 0.61 sec/iter\n",
      "Epoch: 106 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.877133 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 107 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.790500 | 0.613 sec/iter\n",
      "Epoch: 107 | Batch: 001 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.797000 | 0.613 sec/iter\n",
      "Epoch: 107 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.826000 | 0.613 sec/iter\n",
      "Epoch: 107 | Batch: 003 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.828000 | 0.613 sec/iter\n",
      "Epoch: 107 | Batch: 004 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.833000 | 0.612 sec/iter\n",
      "Epoch: 107 | Batch: 005 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.834000 | 0.612 sec/iter\n",
      "Epoch: 107 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.820000 | 0.612 sec/iter\n",
      "Epoch: 107 | Batch: 007 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.812000 | 0.611 sec/iter\n",
      "Epoch: 107 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.818000 | 0.611 sec/iter\n",
      "Epoch: 107 | Batch: 009 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.841500 | 0.611 sec/iter\n",
      "Epoch: 107 | Batch: 010 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.873720 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 108 | Batch: 000 / 011 | Total loss: 0.463 | Reg loss: 0.017 | Tree loss: 0.463 | Accuracy: 0.774000 | 0.613 sec/iter\n",
      "Epoch: 108 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.807000 | 0.613 sec/iter\n",
      "Epoch: 108 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.810000 | 0.613 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.815500 | 0.612 sec/iter\n",
      "Epoch: 108 | Batch: 004 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.858500 | 0.612 sec/iter\n",
      "Epoch: 108 | Batch: 005 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.805500 | 0.612 sec/iter\n",
      "Epoch: 108 | Batch: 006 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.805000 | 0.611 sec/iter\n",
      "Epoch: 108 | Batch: 007 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.806500 | 0.611 sec/iter\n",
      "Epoch: 108 | Batch: 008 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.848500 | 0.611 sec/iter\n",
      "Epoch: 108 | Batch: 009 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.853000 | 0.611 sec/iter\n",
      "Epoch: 108 | Batch: 010 / 011 | Total loss: 0.329 | Reg loss: 0.017 | Tree loss: 0.329 | Accuracy: 0.880546 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 109 | Batch: 000 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.798000 | 0.613 sec/iter\n",
      "Epoch: 109 | Batch: 001 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.788000 | 0.613 sec/iter\n",
      "Epoch: 109 | Batch: 002 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.815500 | 0.612 sec/iter\n",
      "Epoch: 109 | Batch: 003 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.814500 | 0.612 sec/iter\n",
      "Epoch: 109 | Batch: 004 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.843000 | 0.612 sec/iter\n",
      "Epoch: 109 | Batch: 005 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.835000 | 0.612 sec/iter\n",
      "Epoch: 109 | Batch: 006 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.819500 | 0.611 sec/iter\n",
      "Epoch: 109 | Batch: 007 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.805000 | 0.611 sec/iter\n",
      "Epoch: 109 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.819000 | 0.611 sec/iter\n",
      "Epoch: 109 | Batch: 009 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.845500 | 0.61 sec/iter\n",
      "Epoch: 109 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.880546 | 0.61 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 110 | Batch: 000 / 011 | Total loss: 0.452 | Reg loss: 0.017 | Tree loss: 0.452 | Accuracy: 0.787500 | 0.614 sec/iter\n",
      "Epoch: 110 | Batch: 001 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.806000 | 0.613 sec/iter\n",
      "Epoch: 110 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.812000 | 0.613 sec/iter\n",
      "Epoch: 110 | Batch: 003 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.824500 | 0.613 sec/iter\n",
      "Epoch: 110 | Batch: 004 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.831000 | 0.612 sec/iter\n",
      "Epoch: 110 | Batch: 005 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.826000 | 0.612 sec/iter\n",
      "Epoch: 110 | Batch: 006 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.808000 | 0.612 sec/iter\n",
      "Epoch: 110 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.824000 | 0.612 sec/iter\n",
      "Epoch: 110 | Batch: 008 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.829500 | 0.611 sec/iter\n",
      "Epoch: 110 | Batch: 009 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.842000 | 0.611 sec/iter\n",
      "Epoch: 110 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.870307 | 0.611 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 111 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.801500 | 0.614 sec/iter\n",
      "Epoch: 111 | Batch: 001 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.795000 | 0.614 sec/iter\n",
      "Epoch: 111 | Batch: 002 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.800500 | 0.614 sec/iter\n",
      "Epoch: 111 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.823500 | 0.613 sec/iter\n",
      "Epoch: 111 | Batch: 004 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.837500 | 0.613 sec/iter\n",
      "Epoch: 111 | Batch: 005 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.821500 | 0.613 sec/iter\n",
      "Epoch: 111 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827500 | 0.613 sec/iter\n",
      "Epoch: 111 | Batch: 007 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.806000 | 0.612 sec/iter\n",
      "Epoch: 111 | Batch: 008 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.837500 | 0.612 sec/iter\n",
      "Epoch: 111 | Batch: 009 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.848000 | 0.612 sec/iter\n",
      "Epoch: 111 | Batch: 010 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.839590 | 0.611 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 112 | Batch: 000 / 011 | Total loss: 0.451 | Reg loss: 0.017 | Tree loss: 0.451 | Accuracy: 0.799000 | 0.611 sec/iter\n",
      "Epoch: 112 | Batch: 001 / 011 | Total loss: 0.451 | Reg loss: 0.017 | Tree loss: 0.451 | Accuracy: 0.796000 | 0.611 sec/iter\n",
      "Epoch: 112 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.812500 | 0.611 sec/iter\n",
      "Epoch: 112 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.841500 | 0.61 sec/iter\n",
      "Epoch: 112 | Batch: 004 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.846000 | 0.61 sec/iter\n",
      "Epoch: 112 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.846500 | 0.61 sec/iter\n",
      "Epoch: 112 | Batch: 006 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.815000 | 0.61 sec/iter\n",
      "Epoch: 112 | Batch: 007 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.817500 | 0.609 sec/iter\n",
      "Epoch: 112 | Batch: 008 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.827000 | 0.609 sec/iter\n",
      "Epoch: 112 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.866000 | 0.609 sec/iter\n",
      "Epoch: 112 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.849829 | 0.608 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 113 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.807500 | 0.61 sec/iter\n",
      "Epoch: 113 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.801500 | 0.61 sec/iter\n",
      "Epoch: 113 | Batch: 002 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.812000 | 0.61 sec/iter\n",
      "Epoch: 113 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.830500 | 0.609 sec/iter\n",
      "Epoch: 113 | Batch: 004 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.833500 | 0.609 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.851000 | 0.609 sec/iter\n",
      "Epoch: 113 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.832500 | 0.608 sec/iter\n",
      "Epoch: 113 | Batch: 007 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.805500 | 0.608 sec/iter\n",
      "Epoch: 113 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.819500 | 0.608 sec/iter\n",
      "Epoch: 113 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.853000 | 0.607 sec/iter\n",
      "Epoch: 113 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.856655 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 114 | Batch: 000 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.794000 | 0.609 sec/iter\n",
      "Epoch: 114 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.814000 | 0.609 sec/iter\n",
      "Epoch: 114 | Batch: 002 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.815500 | 0.608 sec/iter\n",
      "Epoch: 114 | Batch: 003 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.820500 | 0.608 sec/iter\n",
      "Epoch: 114 | Batch: 004 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.821000 | 0.608 sec/iter\n",
      "Epoch: 114 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.836000 | 0.607 sec/iter\n",
      "Epoch: 114 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.812000 | 0.607 sec/iter\n",
      "Epoch: 114 | Batch: 007 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.810500 | 0.607 sec/iter\n",
      "Epoch: 114 | Batch: 008 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.827000 | 0.606 sec/iter\n",
      "Epoch: 114 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.852500 | 0.606 sec/iter\n",
      "Epoch: 114 | Batch: 010 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.836177 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 115 | Batch: 000 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.795000 | 0.606 sec/iter\n",
      "Epoch: 115 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.811000 | 0.606 sec/iter\n",
      "Epoch: 115 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 115 | Batch: 003 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.801500 | 0.605 sec/iter\n",
      "Epoch: 115 | Batch: 004 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.842500 | 0.605 sec/iter\n",
      "Epoch: 115 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.824000 | 0.604 sec/iter\n",
      "Epoch: 115 | Batch: 006 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.815000 | 0.604 sec/iter\n",
      "Epoch: 115 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 115 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.836000 | 0.604 sec/iter\n",
      "Epoch: 115 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.854000 | 0.603 sec/iter\n",
      "Epoch: 115 | Batch: 010 / 011 | Total loss: 0.469 | Reg loss: 0.017 | Tree loss: 0.469 | Accuracy: 0.815700 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 116 | Batch: 000 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.800000 | 0.605 sec/iter\n",
      "Epoch: 116 | Batch: 001 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.791500 | 0.604 sec/iter\n",
      "Epoch: 116 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.816000 | 0.604 sec/iter\n",
      "Epoch: 116 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.839000 | 0.604 sec/iter\n",
      "Epoch: 116 | Batch: 004 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.835000 | 0.603 sec/iter\n",
      "Epoch: 116 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.836000 | 0.603 sec/iter\n",
      "Epoch: 116 | Batch: 006 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.808500 | 0.603 sec/iter\n",
      "Epoch: 116 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.831000 | 0.603 sec/iter\n",
      "Epoch: 116 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.846000 | 0.602 sec/iter\n",
      "Epoch: 116 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.863000 | 0.602 sec/iter\n",
      "Epoch: 116 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.866894 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 117 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.806000 | 0.605 sec/iter\n",
      "Epoch: 117 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.820500 | 0.605 sec/iter\n",
      "Epoch: 117 | Batch: 002 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.814000 | 0.605 sec/iter\n",
      "Epoch: 117 | Batch: 003 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 117 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 117 | Batch: 005 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 117 | Batch: 006 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.804500 | 0.604 sec/iter\n",
      "Epoch: 117 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.836500 | 0.603 sec/iter\n",
      "Epoch: 117 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.852000 | 0.603 sec/iter\n",
      "Epoch: 117 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.881500 | 0.603 sec/iter\n",
      "Epoch: 117 | Batch: 010 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.860068 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 118 | Batch: 000 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.793500 | 0.603 sec/iter\n",
      "Epoch: 118 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.816500 | 0.602 sec/iter\n",
      "Epoch: 118 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.805000 | 0.602 sec/iter\n",
      "Epoch: 118 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 118 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.842000 | 0.602 sec/iter\n",
      "Epoch: 118 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 118 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.812000 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118 | Batch: 007 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 118 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.851000 | 0.601 sec/iter\n",
      "Epoch: 118 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.854500 | 0.6 sec/iter\n",
      "Epoch: 118 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.911263 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 119 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.795500 | 0.603 sec/iter\n",
      "Epoch: 119 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.809500 | 0.603 sec/iter\n",
      "Epoch: 119 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.828000 | 0.603 sec/iter\n",
      "Epoch: 119 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.824500 | 0.603 sec/iter\n",
      "Epoch: 119 | Batch: 004 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.840000 | 0.602 sec/iter\n",
      "Epoch: 119 | Batch: 005 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.797500 | 0.602 sec/iter\n",
      "Epoch: 119 | Batch: 006 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 119 | Batch: 007 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 119 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.844500 | 0.601 sec/iter\n",
      "Epoch: 119 | Batch: 009 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.846500 | 0.601 sec/iter\n",
      "Epoch: 119 | Batch: 010 / 011 | Total loss: 0.351 | Reg loss: 0.017 | Tree loss: 0.351 | Accuracy: 0.894198 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 120 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.806500 | 0.606 sec/iter\n",
      "Epoch: 120 | Batch: 001 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.803000 | 0.605 sec/iter\n",
      "Epoch: 120 | Batch: 002 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.808500 | 0.605 sec/iter\n",
      "Epoch: 120 | Batch: 003 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.822000 | 0.605 sec/iter\n",
      "Epoch: 120 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.863500 | 0.605 sec/iter\n",
      "Epoch: 120 | Batch: 005 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 120 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.829000 | 0.604 sec/iter\n",
      "Epoch: 120 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.832500 | 0.604 sec/iter\n",
      "Epoch: 120 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.830500 | 0.604 sec/iter\n",
      "Epoch: 120 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.863500 | 0.603 sec/iter\n",
      "Epoch: 120 | Batch: 010 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.849829 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 121 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.808500 | 0.605 sec/iter\n",
      "Epoch: 121 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.800500 | 0.605 sec/iter\n",
      "Epoch: 121 | Batch: 002 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.847000 | 0.604 sec/iter\n",
      "Epoch: 121 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.828000 | 0.604 sec/iter\n",
      "Epoch: 121 | Batch: 004 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.840000 | 0.604 sec/iter\n",
      "Epoch: 121 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.820000 | 0.604 sec/iter\n",
      "Epoch: 121 | Batch: 006 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.818000 | 0.604 sec/iter\n",
      "Epoch: 121 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.833500 | 0.603 sec/iter\n",
      "Epoch: 121 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.836500 | 0.603 sec/iter\n",
      "Epoch: 121 | Batch: 009 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.844000 | 0.603 sec/iter\n",
      "Epoch: 121 | Batch: 010 / 011 | Total loss: 0.352 | Reg loss: 0.017 | Tree loss: 0.352 | Accuracy: 0.904437 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 122 | Batch: 000 / 011 | Total loss: 0.452 | Reg loss: 0.017 | Tree loss: 0.452 | Accuracy: 0.789000 | 0.607 sec/iter\n",
      "Epoch: 122 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.815000 | 0.607 sec/iter\n",
      "Epoch: 122 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.809500 | 0.607 sec/iter\n",
      "Epoch: 122 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.830500 | 0.607 sec/iter\n",
      "Epoch: 122 | Batch: 004 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.845500 | 0.606 sec/iter\n",
      "Epoch: 122 | Batch: 005 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.824000 | 0.606 sec/iter\n",
      "Epoch: 122 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.825500 | 0.606 sec/iter\n",
      "Epoch: 122 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827000 | 0.606 sec/iter\n",
      "Epoch: 122 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.839000 | 0.605 sec/iter\n",
      "Epoch: 122 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.851500 | 0.605 sec/iter\n",
      "Epoch: 122 | Batch: 010 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.866894 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 123 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.801000 | 0.61 sec/iter\n",
      "Epoch: 123 | Batch: 001 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.794500 | 0.609 sec/iter\n",
      "Epoch: 123 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.830500 | 0.609 sec/iter\n",
      "Epoch: 123 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.833000 | 0.609 sec/iter\n",
      "Epoch: 123 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.829000 | 0.609 sec/iter\n",
      "Epoch: 123 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.816000 | 0.608 sec/iter\n",
      "Epoch: 123 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.806500 | 0.608 sec/iter\n",
      "Epoch: 123 | Batch: 007 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.825500 | 0.608 sec/iter\n",
      "Epoch: 123 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.854000 | 0.608 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.849000 | 0.608 sec/iter\n",
      "Epoch: 123 | Batch: 010 / 011 | Total loss: 0.326 | Reg loss: 0.017 | Tree loss: 0.326 | Accuracy: 0.880546 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 124 | Batch: 000 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.811500 | 0.609 sec/iter\n",
      "Epoch: 124 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.817000 | 0.609 sec/iter\n",
      "Epoch: 124 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.809500 | 0.609 sec/iter\n",
      "Epoch: 124 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.845000 | 0.609 sec/iter\n",
      "Epoch: 124 | Batch: 004 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.828500 | 0.608 sec/iter\n",
      "Epoch: 124 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.807000 | 0.608 sec/iter\n",
      "Epoch: 124 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.822000 | 0.608 sec/iter\n",
      "Epoch: 124 | Batch: 007 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.828000 | 0.608 sec/iter\n",
      "Epoch: 124 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.858500 | 0.608 sec/iter\n",
      "Epoch: 124 | Batch: 009 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.852500 | 0.607 sec/iter\n",
      "Epoch: 124 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.880546 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 125 | Batch: 000 / 011 | Total loss: 0.453 | Reg loss: 0.017 | Tree loss: 0.453 | Accuracy: 0.791000 | 0.61 sec/iter\n",
      "Epoch: 125 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.824000 | 0.61 sec/iter\n",
      "Epoch: 125 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.827000 | 0.609 sec/iter\n",
      "Epoch: 125 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.836000 | 0.609 sec/iter\n",
      "Epoch: 125 | Batch: 004 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.837000 | 0.609 sec/iter\n",
      "Epoch: 125 | Batch: 005 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.800000 | 0.609 sec/iter\n",
      "Epoch: 125 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.819500 | 0.608 sec/iter\n",
      "Epoch: 125 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.832500 | 0.608 sec/iter\n",
      "Epoch: 125 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.856000 | 0.608 sec/iter\n",
      "Epoch: 125 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.865000 | 0.607 sec/iter\n",
      "Epoch: 125 | Batch: 010 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.849829 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 126 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.814500 | 0.61 sec/iter\n",
      "Epoch: 126 | Batch: 001 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.803500 | 0.61 sec/iter\n",
      "Epoch: 126 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.835000 | 0.61 sec/iter\n",
      "Epoch: 126 | Batch: 003 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.826500 | 0.61 sec/iter\n",
      "Epoch: 126 | Batch: 004 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.838000 | 0.609 sec/iter\n",
      "Epoch: 126 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.818000 | 0.609 sec/iter\n",
      "Epoch: 126 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.822000 | 0.609 sec/iter\n",
      "Epoch: 126 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.833500 | 0.609 sec/iter\n",
      "Epoch: 126 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.853000 | 0.608 sec/iter\n",
      "Epoch: 126 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.859500 | 0.608 sec/iter\n",
      "Epoch: 126 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.843003 | 0.608 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 127 | Batch: 000 / 011 | Total loss: 0.457 | Reg loss: 0.017 | Tree loss: 0.457 | Accuracy: 0.787500 | 0.61 sec/iter\n",
      "Epoch: 127 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.807000 | 0.61 sec/iter\n",
      "Epoch: 127 | Batch: 002 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809000 | 0.609 sec/iter\n",
      "Epoch: 127 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821000 | 0.609 sec/iter\n",
      "Epoch: 127 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.854000 | 0.609 sec/iter\n",
      "Epoch: 127 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.809500 | 0.609 sec/iter\n",
      "Epoch: 127 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.834000 | 0.608 sec/iter\n",
      "Epoch: 127 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.821500 | 0.608 sec/iter\n",
      "Epoch: 127 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.861000 | 0.608 sec/iter\n",
      "Epoch: 127 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.866000 | 0.608 sec/iter\n",
      "Epoch: 127 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.849829 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 128 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.790500 | 0.609 sec/iter\n",
      "Epoch: 128 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.809000 | 0.609 sec/iter\n",
      "Epoch: 128 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.820000 | 0.609 sec/iter\n",
      "Epoch: 128 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.839000 | 0.608 sec/iter\n",
      "Epoch: 128 | Batch: 004 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.837000 | 0.608 sec/iter\n",
      "Epoch: 128 | Batch: 005 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.826000 | 0.608 sec/iter\n",
      "Epoch: 128 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.815000 | 0.608 sec/iter\n",
      "Epoch: 128 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.842500 | 0.607 sec/iter\n",
      "Epoch: 128 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.847500 | 0.607 sec/iter\n",
      "Epoch: 128 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.864000 | 0.607 sec/iter\n",
      "Epoch: 128 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.017 | Tree loss: 0.349 | Accuracy: 0.873720 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 129 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.796500 | 0.61 sec/iter\n",
      "Epoch: 129 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.815500 | 0.609 sec/iter\n",
      "Epoch: 129 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.822500 | 0.609 sec/iter\n",
      "Epoch: 129 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.845000 | 0.609 sec/iter\n",
      "Epoch: 129 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.849000 | 0.609 sec/iter\n",
      "Epoch: 129 | Batch: 005 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.832500 | 0.608 sec/iter\n",
      "Epoch: 129 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.830500 | 0.608 sec/iter\n",
      "Epoch: 129 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.827000 | 0.608 sec/iter\n",
      "Epoch: 129 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.846000 | 0.608 sec/iter\n",
      "Epoch: 129 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.857500 | 0.607 sec/iter\n",
      "Epoch: 129 | Batch: 010 / 011 | Total loss: 0.345 | Reg loss: 0.017 | Tree loss: 0.345 | Accuracy: 0.856655 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 130 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.813500 | 0.61 sec/iter\n",
      "Epoch: 130 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.810000 | 0.61 sec/iter\n",
      "Epoch: 130 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.819500 | 0.609 sec/iter\n",
      "Epoch: 130 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.825000 | 0.609 sec/iter\n",
      "Epoch: 130 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.859500 | 0.609 sec/iter\n",
      "Epoch: 130 | Batch: 005 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.817000 | 0.609 sec/iter\n",
      "Epoch: 130 | Batch: 006 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.818000 | 0.608 sec/iter\n",
      "Epoch: 130 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.816000 | 0.608 sec/iter\n",
      "Epoch: 130 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.831500 | 0.608 sec/iter\n",
      "Epoch: 130 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.862000 | 0.608 sec/iter\n",
      "Epoch: 130 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.873720 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 131 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.797500 | 0.608 sec/iter\n",
      "Epoch: 131 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.805500 | 0.608 sec/iter\n",
      "Epoch: 131 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.842000 | 0.608 sec/iter\n",
      "Epoch: 131 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.822500 | 0.607 sec/iter\n",
      "Epoch: 131 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.847500 | 0.607 sec/iter\n",
      "Epoch: 131 | Batch: 005 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.806500 | 0.607 sec/iter\n",
      "Epoch: 131 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.823000 | 0.607 sec/iter\n",
      "Epoch: 131 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.834500 | 0.606 sec/iter\n",
      "Epoch: 131 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.856000 | 0.606 sec/iter\n",
      "Epoch: 131 | Batch: 009 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.860500 | 0.606 sec/iter\n",
      "Epoch: 131 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.829352 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 132 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.792000 | 0.607 sec/iter\n",
      "Epoch: 132 | Batch: 001 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.797000 | 0.607 sec/iter\n",
      "Epoch: 132 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.827500 | 0.607 sec/iter\n",
      "Epoch: 132 | Batch: 003 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.845500 | 0.606 sec/iter\n",
      "Epoch: 132 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.837500 | 0.606 sec/iter\n",
      "Epoch: 132 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.818500 | 0.606 sec/iter\n",
      "Epoch: 132 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.817500 | 0.606 sec/iter\n",
      "Epoch: 132 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.833000 | 0.605 sec/iter\n",
      "Epoch: 132 | Batch: 008 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.841500 | 0.605 sec/iter\n",
      "Epoch: 132 | Batch: 009 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.869500 | 0.605 sec/iter\n",
      "Epoch: 132 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.812287 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 133 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.805500 | 0.608 sec/iter\n",
      "Epoch: 133 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.816500 | 0.607 sec/iter\n",
      "Epoch: 133 | Batch: 002 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.832500 | 0.607 sec/iter\n",
      "Epoch: 133 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.840000 | 0.607 sec/iter\n",
      "Epoch: 133 | Batch: 004 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.805500 | 0.607 sec/iter\n",
      "Epoch: 133 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.812500 | 0.606 sec/iter\n",
      "Epoch: 133 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.818000 | 0.606 sec/iter\n",
      "Epoch: 133 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.843500 | 0.606 sec/iter\n",
      "Epoch: 133 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.857000 | 0.606 sec/iter\n",
      "Epoch: 133 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.853000 | 0.606 sec/iter\n",
      "Epoch: 133 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.836177 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.810500 | 0.606 sec/iter\n",
      "Epoch: 134 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 134 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.839000 | 0.605 sec/iter\n",
      "Epoch: 134 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.835500 | 0.605 sec/iter\n",
      "Epoch: 134 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.851500 | 0.604 sec/iter\n",
      "Epoch: 134 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.812000 | 0.604 sec/iter\n",
      "Epoch: 134 | Batch: 006 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.806000 | 0.604 sec/iter\n",
      "Epoch: 134 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 134 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.844500 | 0.604 sec/iter\n",
      "Epoch: 134 | Batch: 009 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.849000 | 0.603 sec/iter\n",
      "Epoch: 134 | Batch: 010 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.856655 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 135 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.801000 | 0.605 sec/iter\n",
      "Epoch: 135 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.810500 | 0.604 sec/iter\n",
      "Epoch: 135 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 135 | Batch: 003 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.829500 | 0.604 sec/iter\n",
      "Epoch: 135 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 135 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.814500 | 0.603 sec/iter\n",
      "Epoch: 135 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.807500 | 0.603 sec/iter\n",
      "Epoch: 135 | Batch: 007 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 135 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.847500 | 0.603 sec/iter\n",
      "Epoch: 135 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.849000 | 0.602 sec/iter\n",
      "Epoch: 135 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.839590 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 136 | Batch: 000 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.793000 | 0.603 sec/iter\n",
      "Epoch: 136 | Batch: 001 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.812500 | 0.603 sec/iter\n",
      "Epoch: 136 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 136 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.847500 | 0.602 sec/iter\n",
      "Epoch: 136 | Batch: 004 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 136 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 136 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 136 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 136 | Batch: 008 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.863500 | 0.601 sec/iter\n",
      "Epoch: 136 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.854500 | 0.601 sec/iter\n",
      "Epoch: 136 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.018 | Tree loss: 0.442 | Accuracy: 0.819113 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 137 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.808500 | 0.601 sec/iter\n",
      "Epoch: 137 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.807000 | 0.601 sec/iter\n",
      "Epoch: 137 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 137 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.839000 | 0.6 sec/iter\n",
      "Epoch: 137 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 137 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 137 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.827500 | 0.599 sec/iter\n",
      "Epoch: 137 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.820000 | 0.599 sec/iter\n",
      "Epoch: 137 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.849000 | 0.599 sec/iter\n",
      "Epoch: 137 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.873500 | 0.599 sec/iter\n",
      "Epoch: 137 | Batch: 010 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.829352 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 138 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 138 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 138 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 138 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 138 | Batch: 004 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 138 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 138 | Batch: 006 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 138 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.830000 | 0.599 sec/iter\n",
      "Epoch: 138 | Batch: 008 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.865500 | 0.599 sec/iter\n",
      "Epoch: 138 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.848000 | 0.599 sec/iter\n",
      "Epoch: 138 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.839590 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 139 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.797000 | 0.601 sec/iter\n",
      "Epoch: 139 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.813000 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.844500 | 0.6 sec/iter\n",
      "Epoch: 139 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 139 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.849000 | 0.6 sec/iter\n",
      "Epoch: 139 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.810500 | 0.6 sec/iter\n",
      "Epoch: 139 | Batch: 006 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 139 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.831000 | 0.599 sec/iter\n",
      "Epoch: 139 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.853500 | 0.599 sec/iter\n",
      "Epoch: 139 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.859000 | 0.599 sec/iter\n",
      "Epoch: 139 | Batch: 010 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.853242 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 140 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 140 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.823500 | 0.6 sec/iter\n",
      "Epoch: 140 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.813500 | 0.6 sec/iter\n",
      "Epoch: 140 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.851000 | 0.6 sec/iter\n",
      "Epoch: 140 | Batch: 004 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.807500 | 0.6 sec/iter\n",
      "Epoch: 140 | Batch: 005 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.813500 | 0.599 sec/iter\n",
      "Epoch: 140 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.825000 | 0.599 sec/iter\n",
      "Epoch: 140 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.832000 | 0.599 sec/iter\n",
      "Epoch: 140 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.851500 | 0.599 sec/iter\n",
      "Epoch: 140 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.868000 | 0.599 sec/iter\n",
      "Epoch: 140 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.018 | Tree loss: 0.359 | Accuracy: 0.877133 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 141 | Batch: 000 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.791500 | 0.601 sec/iter\n",
      "Epoch: 141 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 141 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 141 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.840000 | 0.6 sec/iter\n",
      "Epoch: 141 | Batch: 004 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 141 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 141 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 141 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 141 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 141 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.853500 | 0.599 sec/iter\n",
      "Epoch: 141 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.883959 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 142 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.810500 | 0.601 sec/iter\n",
      "Epoch: 142 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 142 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 142 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 142 | Batch: 004 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 142 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 142 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 142 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.815000 | 0.6 sec/iter\n",
      "Epoch: 142 | Batch: 008 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.855000 | 0.599 sec/iter\n",
      "Epoch: 142 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.859000 | 0.599 sec/iter\n",
      "Epoch: 142 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.825939 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 143 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.805500 | 0.602 sec/iter\n",
      "Epoch: 143 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 143 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 143 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.816500 | 0.602 sec/iter\n",
      "Epoch: 143 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.857500 | 0.602 sec/iter\n",
      "Epoch: 143 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 143 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 143 | Batch: 007 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 143 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.846000 | 0.601 sec/iter\n",
      "Epoch: 143 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.866500 | 0.601 sec/iter\n",
      "Epoch: 143 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.018 | Tree loss: 0.358 | Accuracy: 0.866894 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 144 | Batch: 000 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.791000 | 0.604 sec/iter\n",
      "Epoch: 144 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.801000 | 0.603 sec/iter\n",
      "Epoch: 144 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.834000 | 0.603 sec/iter\n",
      "Epoch: 144 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.842000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.834000 | 0.603 sec/iter\n",
      "Epoch: 144 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 144 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.807000 | 0.602 sec/iter\n",
      "Epoch: 144 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 144 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.843500 | 0.602 sec/iter\n",
      "Epoch: 144 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.868500 | 0.602 sec/iter\n",
      "Epoch: 144 | Batch: 010 / 011 | Total loss: 0.351 | Reg loss: 0.018 | Tree loss: 0.351 | Accuracy: 0.870307 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 145 | Batch: 000 / 011 | Total loss: 0.451 | Reg loss: 0.017 | Tree loss: 0.451 | Accuracy: 0.785500 | 0.606 sec/iter\n",
      "Epoch: 145 | Batch: 001 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.801500 | 0.606 sec/iter\n",
      "Epoch: 145 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.837500 | 0.605 sec/iter\n",
      "Epoch: 145 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.839000 | 0.605 sec/iter\n",
      "Epoch: 145 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.840500 | 0.605 sec/iter\n",
      "Epoch: 145 | Batch: 005 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 145 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.827500 | 0.604 sec/iter\n",
      "Epoch: 145 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.810500 | 0.604 sec/iter\n",
      "Epoch: 145 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.841000 | 0.604 sec/iter\n",
      "Epoch: 145 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.861000 | 0.604 sec/iter\n",
      "Epoch: 145 | Batch: 010 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.812287 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 146 | Batch: 000 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.801500 | 0.608 sec/iter\n",
      "Epoch: 146 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.810000 | 0.607 sec/iter\n",
      "Epoch: 146 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.827000 | 0.607 sec/iter\n",
      "Epoch: 146 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.856500 | 0.607 sec/iter\n",
      "Epoch: 146 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.811000 | 0.607 sec/iter\n",
      "Epoch: 146 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821500 | 0.607 sec/iter\n",
      "Epoch: 146 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.815000 | 0.606 sec/iter\n",
      "Epoch: 146 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.827500 | 0.606 sec/iter\n",
      "Epoch: 146 | Batch: 008 / 011 | Total loss: 0.363 | Reg loss: 0.018 | Tree loss: 0.363 | Accuracy: 0.872500 | 0.606 sec/iter\n",
      "Epoch: 146 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.864000 | 0.606 sec/iter\n",
      "Epoch: 146 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.822526 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 147 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.808500 | 0.607 sec/iter\n",
      "Epoch: 147 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.817000 | 0.606 sec/iter\n",
      "Epoch: 147 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.826500 | 0.606 sec/iter\n",
      "Epoch: 147 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.850500 | 0.606 sec/iter\n",
      "Epoch: 147 | Batch: 004 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.804000 | 0.606 sec/iter\n",
      "Epoch: 147 | Batch: 005 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.798500 | 0.606 sec/iter\n",
      "Epoch: 147 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.827000 | 0.605 sec/iter\n",
      "Epoch: 147 | Batch: 007 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.847000 | 0.605 sec/iter\n",
      "Epoch: 147 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.854000 | 0.605 sec/iter\n",
      "Epoch: 147 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.863000 | 0.605 sec/iter\n",
      "Epoch: 147 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.863481 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 148 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.807000 | 0.607 sec/iter\n",
      "Epoch: 148 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.802000 | 0.607 sec/iter\n",
      "Epoch: 148 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.824000 | 0.607 sec/iter\n",
      "Epoch: 148 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.857500 | 0.607 sec/iter\n",
      "Epoch: 148 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.820000 | 0.606 sec/iter\n",
      "Epoch: 148 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.820500 | 0.606 sec/iter\n",
      "Epoch: 148 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.823000 | 0.606 sec/iter\n",
      "Epoch: 148 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.824000 | 0.606 sec/iter\n",
      "Epoch: 148 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.860500 | 0.605 sec/iter\n",
      "Epoch: 148 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.853500 | 0.605 sec/iter\n",
      "Epoch: 148 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.018 | Tree loss: 0.349 | Accuracy: 0.860068 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 149 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.816000 | 0.606 sec/iter\n",
      "Epoch: 149 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.811000 | 0.606 sec/iter\n",
      "Epoch: 149 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.823000 | 0.606 sec/iter\n",
      "Epoch: 149 | Batch: 003 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.831000 | 0.606 sec/iter\n",
      "Epoch: 149 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.832000 | 0.605 sec/iter\n",
      "Epoch: 149 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.811000 | 0.605 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 149 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.826000 | 0.605 sec/iter\n",
      "Epoch: 149 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.860500 | 0.604 sec/iter\n",
      "Epoch: 149 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.864500 | 0.604 sec/iter\n",
      "Epoch: 149 | Batch: 010 / 011 | Total loss: 0.330 | Reg loss: 0.018 | Tree loss: 0.330 | Accuracy: 0.856655 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 150 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.822000 | 0.606 sec/iter\n",
      "Epoch: 150 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.824000 | 0.606 sec/iter\n",
      "Epoch: 150 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.820500 | 0.606 sec/iter\n",
      "Epoch: 150 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 150 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.844500 | 0.605 sec/iter\n",
      "Epoch: 150 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.811000 | 0.605 sec/iter\n",
      "Epoch: 150 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.832500 | 0.605 sec/iter\n",
      "Epoch: 150 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 150 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.833500 | 0.604 sec/iter\n",
      "Epoch: 150 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.854000 | 0.604 sec/iter\n",
      "Epoch: 150 | Batch: 010 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.856655 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 151 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.815000 | 0.607 sec/iter\n",
      "Epoch: 151 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.812000 | 0.606 sec/iter\n",
      "Epoch: 151 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.828500 | 0.606 sec/iter\n",
      "Epoch: 151 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.849500 | 0.606 sec/iter\n",
      "Epoch: 151 | Batch: 004 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.815500 | 0.606 sec/iter\n",
      "Epoch: 151 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.816500 | 0.605 sec/iter\n",
      "Epoch: 151 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.812000 | 0.605 sec/iter\n",
      "Epoch: 151 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.833000 | 0.605 sec/iter\n",
      "Epoch: 151 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.852500 | 0.605 sec/iter\n",
      "Epoch: 151 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.854500 | 0.605 sec/iter\n",
      "Epoch: 151 | Batch: 010 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.819113 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 152 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.817000 | 0.606 sec/iter\n",
      "Epoch: 152 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.801000 | 0.606 sec/iter\n",
      "Epoch: 152 | Batch: 002 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.842500 | 0.606 sec/iter\n",
      "Epoch: 152 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.852000 | 0.605 sec/iter\n",
      "Epoch: 152 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.831000 | 0.605 sec/iter\n",
      "Epoch: 152 | Batch: 005 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.813500 | 0.605 sec/iter\n",
      "Epoch: 152 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.832500 | 0.605 sec/iter\n",
      "Epoch: 152 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.840000 | 0.605 sec/iter\n",
      "Epoch: 152 | Batch: 008 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.825500 | 0.604 sec/iter\n",
      "Epoch: 152 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.866000 | 0.604 sec/iter\n",
      "Epoch: 152 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.856655 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 153 | Batch: 000 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.802500 | 0.604 sec/iter\n",
      "Epoch: 153 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.800000 | 0.604 sec/iter\n",
      "Epoch: 153 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.821500 | 0.603 sec/iter\n",
      "Epoch: 153 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 153 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.851000 | 0.603 sec/iter\n",
      "Epoch: 153 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 153 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 153 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 153 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.847000 | 0.602 sec/iter\n",
      "Epoch: 153 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.862500 | 0.602 sec/iter\n",
      "Epoch: 153 | Batch: 010 / 011 | Total loss: 0.343 | Reg loss: 0.018 | Tree loss: 0.343 | Accuracy: 0.873720 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 154 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 154 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.808500 | 0.603 sec/iter\n",
      "Epoch: 154 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 154 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.835500 | 0.602 sec/iter\n",
      "Epoch: 154 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.843500 | 0.602 sec/iter\n",
      "Epoch: 154 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 154 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 154 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.816000 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 154 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.837500 | 0.601 sec/iter\n",
      "Epoch: 154 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.851000 | 0.601 sec/iter\n",
      "Epoch: 154 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.815700 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 155 | Batch: 000 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.788500 | 0.603 sec/iter\n",
      "Epoch: 155 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.810500 | 0.603 sec/iter\n",
      "Epoch: 155 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.828500 | 0.603 sec/iter\n",
      "Epoch: 155 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 155 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.846500 | 0.603 sec/iter\n",
      "Epoch: 155 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 155 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 155 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 155 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.838000 | 0.602 sec/iter\n",
      "Epoch: 155 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.837000 | 0.602 sec/iter\n",
      "Epoch: 155 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.017 | Tree loss: 0.360 | Accuracy: 0.870307 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 156 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.810000 | 0.602 sec/iter\n",
      "Epoch: 156 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 156 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 156 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 156 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.849500 | 0.601 sec/iter\n",
      "Epoch: 156 | Batch: 005 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 156 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.815000 | 0.6 sec/iter\n",
      "Epoch: 156 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 156 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 156 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.860500 | 0.6 sec/iter\n",
      "Epoch: 156 | Batch: 010 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.873720 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 157 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.800000 | 0.602 sec/iter\n",
      "Epoch: 157 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 157 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 157 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 157 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.844500 | 0.601 sec/iter\n",
      "Epoch: 157 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 157 | Batch: 006 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.810500 | 0.601 sec/iter\n",
      "Epoch: 157 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 157 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.844500 | 0.601 sec/iter\n",
      "Epoch: 157 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.858500 | 0.6 sec/iter\n",
      "Epoch: 157 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.890785 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 158 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 158 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.807000 | 0.6 sec/iter\n",
      "Epoch: 158 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 158 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.840000 | 0.6 sec/iter\n",
      "Epoch: 158 | Batch: 004 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.834500 | 0.599 sec/iter\n",
      "Epoch: 158 | Batch: 005 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.809500 | 0.599 sec/iter\n",
      "Epoch: 158 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.832000 | 0.599 sec/iter\n",
      "Epoch: 158 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.812000 | 0.599 sec/iter\n",
      "Epoch: 158 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.819500 | 0.599 sec/iter\n",
      "Epoch: 158 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.862500 | 0.599 sec/iter\n",
      "Epoch: 158 | Batch: 010 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.849829 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 159 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.804000 | 0.601 sec/iter\n",
      "Epoch: 159 | Batch: 001 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.804000 | 0.601 sec/iter\n",
      "Epoch: 159 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.828500 | 0.601 sec/iter\n",
      "Epoch: 159 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 159 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.851000 | 0.6 sec/iter\n",
      "Epoch: 159 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.833500 | 0.6 sec/iter\n",
      "Epoch: 159 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 159 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.825000 | 0.599 sec/iter\n",
      "Epoch: 159 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.833000 | 0.599 sec/iter\n",
      "Epoch: 159 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.847000 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.863481 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 160 | Batch: 000 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.799000 | 0.601 sec/iter\n",
      "Epoch: 160 | Batch: 001 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.797000 | 0.601 sec/iter\n",
      "Epoch: 160 | Batch: 002 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.835500 | 0.601 sec/iter\n",
      "Epoch: 160 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.832000 | 0.601 sec/iter\n",
      "Epoch: 160 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 160 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 160 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 160 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 160 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 160 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.859000 | 0.6 sec/iter\n",
      "Epoch: 160 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.873720 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 161 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 161 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.802500 | 0.6 sec/iter\n",
      "Epoch: 161 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 161 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.849000 | 0.599 sec/iter\n",
      "Epoch: 161 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 161 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 161 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.802500 | 0.599 sec/iter\n",
      "Epoch: 161 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.829000 | 0.599 sec/iter\n",
      "Epoch: 161 | Batch: 008 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.856000 | 0.599 sec/iter\n",
      "Epoch: 161 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.836500 | 0.598 sec/iter\n",
      "Epoch: 161 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.877133 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 162 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.810500 | 0.601 sec/iter\n",
      "Epoch: 162 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 162 | Batch: 002 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 162 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.840000 | 0.6 sec/iter\n",
      "Epoch: 162 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 162 | Batch: 005 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.798000 | 0.6 sec/iter\n",
      "Epoch: 162 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 162 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 162 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.847000 | 0.599 sec/iter\n",
      "Epoch: 162 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.856500 | 0.599 sec/iter\n",
      "Epoch: 162 | Batch: 010 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.856655 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 163 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.800000 | 0.602 sec/iter\n",
      "Epoch: 163 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.815000 | 0.601 sec/iter\n",
      "Epoch: 163 | Batch: 002 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.835500 | 0.601 sec/iter\n",
      "Epoch: 163 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.840000 | 0.601 sec/iter\n",
      "Epoch: 163 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 163 | Batch: 005 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.809000 | 0.601 sec/iter\n",
      "Epoch: 163 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 163 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 163 | Batch: 008 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.853000 | 0.6 sec/iter\n",
      "Epoch: 163 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.858500 | 0.6 sec/iter\n",
      "Epoch: 163 | Batch: 010 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.808874 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 164 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 164 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 164 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 164 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.842000 | 0.602 sec/iter\n",
      "Epoch: 164 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 164 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.832500 | 0.601 sec/iter\n",
      "Epoch: 164 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 164 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 164 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.846500 | 0.601 sec/iter\n",
      "Epoch: 164 | Batch: 009 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 164 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.825939 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.804500 | 0.601 sec/iter\n",
      "Epoch: 165 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 165 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 165 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.846500 | 0.6 sec/iter\n",
      "Epoch: 165 | Batch: 004 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.810000 | 0.6 sec/iter\n",
      "Epoch: 165 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 165 | Batch: 006 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 165 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.823500 | 0.6 sec/iter\n",
      "Epoch: 165 | Batch: 008 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.846000 | 0.6 sec/iter\n",
      "Epoch: 165 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.867500 | 0.599 sec/iter\n",
      "Epoch: 165 | Batch: 010 / 011 | Total loss: 0.454 | Reg loss: 0.017 | Tree loss: 0.454 | Accuracy: 0.812287 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 166 | Batch: 000 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 166 | Batch: 001 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 166 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 166 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.833000 | 0.601 sec/iter\n",
      "Epoch: 166 | Batch: 004 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.828000 | 0.601 sec/iter\n",
      "Epoch: 166 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.816000 | 0.601 sec/iter\n",
      "Epoch: 166 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 166 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 166 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.854000 | 0.601 sec/iter\n",
      "Epoch: 166 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.868500 | 0.6 sec/iter\n",
      "Epoch: 166 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.856655 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 167 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.803500 | 0.604 sec/iter\n",
      "Epoch: 167 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 167 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.843500 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.840000 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.831500 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 006 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.802000 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.841000 | 0.603 sec/iter\n",
      "Epoch: 167 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.851000 | 0.602 sec/iter\n",
      "Epoch: 167 | Batch: 010 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.829352 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 168 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.814000 | 0.605 sec/iter\n",
      "Epoch: 168 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.800000 | 0.605 sec/iter\n",
      "Epoch: 168 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.821000 | 0.605 sec/iter\n",
      "Epoch: 168 | Batch: 003 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.868000 | 0.605 sec/iter\n",
      "Epoch: 168 | Batch: 004 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.806500 | 0.605 sec/iter\n",
      "Epoch: 168 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.812500 | 0.605 sec/iter\n",
      "Epoch: 168 | Batch: 006 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 168 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 168 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.858500 | 0.604 sec/iter\n",
      "Epoch: 168 | Batch: 009 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.848000 | 0.604 sec/iter\n",
      "Epoch: 168 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.846416 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 169 | Batch: 000 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.804500 | 0.607 sec/iter\n",
      "Epoch: 169 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 169 | Batch: 002 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.835000 | 0.606 sec/iter\n",
      "Epoch: 169 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.849000 | 0.606 sec/iter\n",
      "Epoch: 169 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.824500 | 0.606 sec/iter\n",
      "Epoch: 169 | Batch: 005 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.804000 | 0.606 sec/iter\n",
      "Epoch: 169 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.822000 | 0.606 sec/iter\n",
      "Epoch: 169 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 169 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.840000 | 0.605 sec/iter\n",
      "Epoch: 169 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.844000 | 0.605 sec/iter\n",
      "Epoch: 169 | Batch: 010 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.849829 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 170 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.820000 | 0.607 sec/iter\n",
      "Epoch: 170 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.815500 | 0.607 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170 | Batch: 002 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.823500 | 0.606 sec/iter\n",
      "Epoch: 170 | Batch: 003 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.836000 | 0.606 sec/iter\n",
      "Epoch: 170 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.850500 | 0.606 sec/iter\n",
      "Epoch: 170 | Batch: 005 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.816500 | 0.606 sec/iter\n",
      "Epoch: 170 | Batch: 006 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.808000 | 0.606 sec/iter\n",
      "Epoch: 170 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.827000 | 0.605 sec/iter\n",
      "Epoch: 170 | Batch: 008 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.831000 | 0.605 sec/iter\n",
      "Epoch: 170 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.854000 | 0.605 sec/iter\n",
      "Epoch: 170 | Batch: 010 / 011 | Total loss: 0.328 | Reg loss: 0.017 | Tree loss: 0.328 | Accuracy: 0.877133 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 171 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.806500 | 0.607 sec/iter\n",
      "Epoch: 171 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.809000 | 0.607 sec/iter\n",
      "Epoch: 171 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.817500 | 0.607 sec/iter\n",
      "Epoch: 171 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.833500 | 0.607 sec/iter\n",
      "Epoch: 171 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.845000 | 0.606 sec/iter\n",
      "Epoch: 171 | Batch: 005 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.814500 | 0.606 sec/iter\n",
      "Epoch: 171 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.821500 | 0.606 sec/iter\n",
      "Epoch: 171 | Batch: 007 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.817500 | 0.606 sec/iter\n",
      "Epoch: 171 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.820000 | 0.606 sec/iter\n",
      "Epoch: 171 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.859500 | 0.605 sec/iter\n",
      "Epoch: 171 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.843003 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 172 | Batch: 000 / 011 | Total loss: 0.448 | Reg loss: 0.017 | Tree loss: 0.448 | Accuracy: 0.795000 | 0.607 sec/iter\n",
      "Epoch: 172 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.809000 | 0.607 sec/iter\n",
      "Epoch: 172 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.821500 | 0.607 sec/iter\n",
      "Epoch: 172 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.838500 | 0.606 sec/iter\n",
      "Epoch: 172 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.827500 | 0.606 sec/iter\n",
      "Epoch: 172 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.826000 | 0.606 sec/iter\n",
      "Epoch: 172 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.826500 | 0.606 sec/iter\n",
      "Epoch: 172 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.818000 | 0.606 sec/iter\n",
      "Epoch: 172 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.838500 | 0.605 sec/iter\n",
      "Epoch: 172 | Batch: 009 / 011 | Total loss: 0.361 | Reg loss: 0.017 | Tree loss: 0.361 | Accuracy: 0.861500 | 0.605 sec/iter\n",
      "Epoch: 172 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.839590 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 173 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.802000 | 0.606 sec/iter\n",
      "Epoch: 173 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.809000 | 0.606 sec/iter\n",
      "Epoch: 173 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.839000 | 0.606 sec/iter\n",
      "Epoch: 173 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.834500 | 0.606 sec/iter\n",
      "Epoch: 173 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.817000 | 0.605 sec/iter\n",
      "Epoch: 173 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.810500 | 0.605 sec/iter\n",
      "Epoch: 173 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 173 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.821500 | 0.605 sec/iter\n",
      "Epoch: 173 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.838500 | 0.605 sec/iter\n",
      "Epoch: 173 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.840000 | 0.605 sec/iter\n",
      "Epoch: 173 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.860068 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 174 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.813500 | 0.604 sec/iter\n",
      "Epoch: 174 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.805000 | 0.604 sec/iter\n",
      "Epoch: 174 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.824000 | 0.604 sec/iter\n",
      "Epoch: 174 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 174 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.834000 | 0.604 sec/iter\n",
      "Epoch: 174 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.825000 | 0.603 sec/iter\n",
      "Epoch: 174 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.823000 | 0.603 sec/iter\n",
      "Epoch: 174 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.820500 | 0.603 sec/iter\n",
      "Epoch: 174 | Batch: 008 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.863500 | 0.603 sec/iter\n",
      "Epoch: 174 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.872000 | 0.603 sec/iter\n",
      "Epoch: 174 | Batch: 010 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.829352 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 175 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.813000 | 0.603 sec/iter\n",
      "Epoch: 175 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.807000 | 0.603 sec/iter\n",
      "Epoch: 175 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 175 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.845000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 175 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 175 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 175 | Batch: 007 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 175 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.846000 | 0.602 sec/iter\n",
      "Epoch: 175 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.846000 | 0.602 sec/iter\n",
      "Epoch: 175 | Batch: 010 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.815700 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 176 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.808000 | 0.604 sec/iter\n",
      "Epoch: 176 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.813000 | 0.604 sec/iter\n",
      "Epoch: 176 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.837500 | 0.604 sec/iter\n",
      "Epoch: 176 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.844500 | 0.603 sec/iter\n",
      "Epoch: 176 | Batch: 004 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.841000 | 0.603 sec/iter\n",
      "Epoch: 176 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.810500 | 0.603 sec/iter\n",
      "Epoch: 176 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.831000 | 0.603 sec/iter\n",
      "Epoch: 176 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.831500 | 0.603 sec/iter\n",
      "Epoch: 176 | Batch: 008 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 176 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.851500 | 0.602 sec/iter\n",
      "Epoch: 176 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.866894 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 177 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.800000 | 0.602 sec/iter\n",
      "Epoch: 177 | Batch: 001 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 177 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 177 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.835500 | 0.602 sec/iter\n",
      "Epoch: 177 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 177 | Batch: 005 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 177 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.814000 | 0.601 sec/iter\n",
      "Epoch: 177 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.839000 | 0.601 sec/iter\n",
      "Epoch: 177 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.842000 | 0.601 sec/iter\n",
      "Epoch: 177 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.857000 | 0.601 sec/iter\n",
      "Epoch: 177 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.836177 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 178 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 178 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.796000 | 0.604 sec/iter\n",
      "Epoch: 178 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.834500 | 0.604 sec/iter\n",
      "Epoch: 178 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.832500 | 0.604 sec/iter\n",
      "Epoch: 178 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.828000 | 0.603 sec/iter\n",
      "Epoch: 178 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.824500 | 0.603 sec/iter\n",
      "Epoch: 178 | Batch: 006 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.814000 | 0.603 sec/iter\n",
      "Epoch: 178 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.817500 | 0.603 sec/iter\n",
      "Epoch: 178 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833000 | 0.603 sec/iter\n",
      "Epoch: 178 | Batch: 009 / 011 | Total loss: 0.357 | Reg loss: 0.017 | Tree loss: 0.357 | Accuracy: 0.871000 | 0.602 sec/iter\n",
      "Epoch: 178 | Batch: 010 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.819113 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 179 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.809500 | 0.605 sec/iter\n",
      "Epoch: 179 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.791500 | 0.605 sec/iter\n",
      "Epoch: 179 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.822500 | 0.605 sec/iter\n",
      "Epoch: 179 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 179 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.848000 | 0.605 sec/iter\n",
      "Epoch: 179 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.824500 | 0.605 sec/iter\n",
      "Epoch: 179 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.822000 | 0.604 sec/iter\n",
      "Epoch: 179 | Batch: 007 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.801000 | 0.604 sec/iter\n",
      "Epoch: 179 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833000 | 0.604 sec/iter\n",
      "Epoch: 179 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.862000 | 0.604 sec/iter\n",
      "Epoch: 179 | Batch: 010 / 011 | Total loss: 0.362 | Reg loss: 0.017 | Tree loss: 0.362 | Accuracy: 0.849829 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 180 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.816500 | 0.606 sec/iter\n",
      "Epoch: 180 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.811500 | 0.606 sec/iter\n",
      "Epoch: 180 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.828000 | 0.605 sec/iter\n",
      "Epoch: 180 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.835500 | 0.605 sec/iter\n",
      "Epoch: 180 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.849000 | 0.605 sec/iter\n",
      "Epoch: 180 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.825500 | 0.605 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 | Batch: 006 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.819500 | 0.605 sec/iter\n",
      "Epoch: 180 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.824500 | 0.605 sec/iter\n",
      "Epoch: 180 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 180 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.852000 | 0.604 sec/iter\n",
      "Epoch: 180 | Batch: 010 / 011 | Total loss: 0.344 | Reg loss: 0.017 | Tree loss: 0.344 | Accuracy: 0.880546 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 181 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.803000 | 0.606 sec/iter\n",
      "Epoch: 181 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.810000 | 0.606 sec/iter\n",
      "Epoch: 181 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.840500 | 0.606 sec/iter\n",
      "Epoch: 181 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.828500 | 0.606 sec/iter\n",
      "Epoch: 181 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.863000 | 0.605 sec/iter\n",
      "Epoch: 181 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.810000 | 0.605 sec/iter\n",
      "Epoch: 181 | Batch: 006 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.818000 | 0.605 sec/iter\n",
      "Epoch: 181 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.822000 | 0.605 sec/iter\n",
      "Epoch: 181 | Batch: 008 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.834000 | 0.605 sec/iter\n",
      "Epoch: 181 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.838500 | 0.605 sec/iter\n",
      "Epoch: 181 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.839590 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 182 | Batch: 000 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.802000 | 0.607 sec/iter\n",
      "Epoch: 182 | Batch: 001 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.812000 | 0.606 sec/iter\n",
      "Epoch: 182 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.829500 | 0.606 sec/iter\n",
      "Epoch: 182 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.834500 | 0.606 sec/iter\n",
      "Epoch: 182 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.849500 | 0.606 sec/iter\n",
      "Epoch: 182 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.833500 | 0.606 sec/iter\n",
      "Epoch: 182 | Batch: 006 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.800000 | 0.606 sec/iter\n",
      "Epoch: 182 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.823500 | 0.605 sec/iter\n",
      "Epoch: 182 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.831000 | 0.605 sec/iter\n",
      "Epoch: 182 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.862500 | 0.605 sec/iter\n",
      "Epoch: 182 | Batch: 010 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.870307 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 183 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.813000 | 0.605 sec/iter\n",
      "Epoch: 183 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.808000 | 0.605 sec/iter\n",
      "Epoch: 183 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 183 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.825500 | 0.604 sec/iter\n",
      "Epoch: 183 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 183 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.827500 | 0.604 sec/iter\n",
      "Epoch: 183 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.804500 | 0.604 sec/iter\n",
      "Epoch: 183 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.822000 | 0.604 sec/iter\n",
      "Epoch: 183 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.847000 | 0.603 sec/iter\n",
      "Epoch: 183 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.866000 | 0.603 sec/iter\n",
      "Epoch: 183 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.843003 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 184 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.826500 | 0.605 sec/iter\n",
      "Epoch: 184 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.811500 | 0.605 sec/iter\n",
      "Epoch: 184 | Batch: 002 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.808000 | 0.605 sec/iter\n",
      "Epoch: 184 | Batch: 003 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.837000 | 0.605 sec/iter\n",
      "Epoch: 184 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.850000 | 0.605 sec/iter\n",
      "Epoch: 184 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 184 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 184 | Batch: 007 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.808500 | 0.604 sec/iter\n",
      "Epoch: 184 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 184 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.854500 | 0.604 sec/iter\n",
      "Epoch: 184 | Batch: 010 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.860068 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 185 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.825000 | 0.605 sec/iter\n",
      "Epoch: 185 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.803000 | 0.605 sec/iter\n",
      "Epoch: 185 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.828000 | 0.605 sec/iter\n",
      "Epoch: 185 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.830000 | 0.605 sec/iter\n",
      "Epoch: 185 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.833000 | 0.605 sec/iter\n",
      "Epoch: 185 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821000 | 0.605 sec/iter\n",
      "Epoch: 185 | Batch: 006 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.806500 | 0.604 sec/iter\n",
      "Epoch: 185 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.815500 | 0.604 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 185 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.861000 | 0.604 sec/iter\n",
      "Epoch: 185 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.843003 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 186 | Batch: 000 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.803000 | 0.604 sec/iter\n",
      "Epoch: 186 | Batch: 001 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 186 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 186 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.827500 | 0.604 sec/iter\n",
      "Epoch: 186 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.838500 | 0.604 sec/iter\n",
      "Epoch: 186 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.810500 | 0.603 sec/iter\n",
      "Epoch: 186 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 186 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.828000 | 0.603 sec/iter\n",
      "Epoch: 186 | Batch: 008 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.841500 | 0.603 sec/iter\n",
      "Epoch: 186 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.867500 | 0.603 sec/iter\n",
      "Epoch: 186 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.866894 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 187 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.806500 | 0.605 sec/iter\n",
      "Epoch: 187 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.808000 | 0.604 sec/iter\n",
      "Epoch: 187 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.818500 | 0.604 sec/iter\n",
      "Epoch: 187 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 187 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.840500 | 0.604 sec/iter\n",
      "Epoch: 187 | Batch: 005 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 187 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 187 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 187 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.827500 | 0.603 sec/iter\n",
      "Epoch: 187 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.865000 | 0.603 sec/iter\n",
      "Epoch: 187 | Batch: 010 / 011 | Total loss: 0.355 | Reg loss: 0.017 | Tree loss: 0.355 | Accuracy: 0.870307 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 188 | Batch: 000 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.800000 | 0.605 sec/iter\n",
      "Epoch: 188 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.803000 | 0.604 sec/iter\n",
      "Epoch: 188 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 188 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.821000 | 0.604 sec/iter\n",
      "Epoch: 188 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 188 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.829500 | 0.604 sec/iter\n",
      "Epoch: 188 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831000 | 0.604 sec/iter\n",
      "Epoch: 188 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 188 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.843500 | 0.603 sec/iter\n",
      "Epoch: 188 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.844500 | 0.603 sec/iter\n",
      "Epoch: 188 | Batch: 010 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.860068 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 189 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.812000 | 0.604 sec/iter\n",
      "Epoch: 189 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.805000 | 0.604 sec/iter\n",
      "Epoch: 189 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.811000 | 0.603 sec/iter\n",
      "Epoch: 189 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.828000 | 0.603 sec/iter\n",
      "Epoch: 189 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.839500 | 0.603 sec/iter\n",
      "Epoch: 189 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.826500 | 0.603 sec/iter\n",
      "Epoch: 189 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.808000 | 0.603 sec/iter\n",
      "Epoch: 189 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 189 | Batch: 008 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.846000 | 0.602 sec/iter\n",
      "Epoch: 189 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.854500 | 0.602 sec/iter\n",
      "Epoch: 189 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.829352 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 190 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.806000 | 0.605 sec/iter\n",
      "Epoch: 190 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.818500 | 0.605 sec/iter\n",
      "Epoch: 190 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.816500 | 0.605 sec/iter\n",
      "Epoch: 190 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.828500 | 0.605 sec/iter\n",
      "Epoch: 190 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.848000 | 0.605 sec/iter\n",
      "Epoch: 190 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.822500 | 0.605 sec/iter\n",
      "Epoch: 190 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 190 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.815000 | 0.604 sec/iter\n",
      "Epoch: 190 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.816500 | 0.604 sec/iter\n",
      "Epoch: 190 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.847500 | 0.604 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.853242 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 191 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.817500 | 0.604 sec/iter\n",
      "Epoch: 191 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.825000 | 0.604 sec/iter\n",
      "Epoch: 191 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.811500 | 0.604 sec/iter\n",
      "Epoch: 191 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.824500 | 0.603 sec/iter\n",
      "Epoch: 191 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.847500 | 0.603 sec/iter\n",
      "Epoch: 191 | Batch: 005 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 191 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.814000 | 0.603 sec/iter\n",
      "Epoch: 191 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 191 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 191 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.868000 | 0.602 sec/iter\n",
      "Epoch: 191 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.812287 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 192 | Batch: 000 / 011 | Total loss: 0.448 | Reg loss: 0.017 | Tree loss: 0.448 | Accuracy: 0.801000 | 0.604 sec/iter\n",
      "Epoch: 192 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 192 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.838500 | 0.604 sec/iter\n",
      "Epoch: 192 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 192 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.839000 | 0.604 sec/iter\n",
      "Epoch: 192 | Batch: 005 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 192 | Batch: 006 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 192 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 192 | Batch: 008 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.841500 | 0.603 sec/iter\n",
      "Epoch: 192 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.860000 | 0.603 sec/iter\n",
      "Epoch: 192 | Batch: 010 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815700 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 193 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.816000 | 0.604 sec/iter\n",
      "Epoch: 193 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.802000 | 0.604 sec/iter\n",
      "Epoch: 193 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 193 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.843000 | 0.604 sec/iter\n",
      "Epoch: 193 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.831000 | 0.603 sec/iter\n",
      "Epoch: 193 | Batch: 005 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 193 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.823500 | 0.603 sec/iter\n",
      "Epoch: 193 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.817500 | 0.603 sec/iter\n",
      "Epoch: 193 | Batch: 008 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 193 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.864000 | 0.602 sec/iter\n",
      "Epoch: 193 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.017 | Tree loss: 0.360 | Accuracy: 0.853242 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 194 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 194 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.807500 | 0.602 sec/iter\n",
      "Epoch: 194 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 194 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 194 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.840000 | 0.602 sec/iter\n",
      "Epoch: 194 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 194 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 194 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 194 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 194 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.850000 | 0.601 sec/iter\n",
      "Epoch: 194 | Batch: 010 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.863481 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 195 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 195 | Batch: 001 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.795000 | 0.601 sec/iter\n",
      "Epoch: 195 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.806500 | 0.601 sec/iter\n",
      "Epoch: 195 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 195 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.856500 | 0.601 sec/iter\n",
      "Epoch: 195 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 195 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 195 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 195 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 195 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.841000 | 0.6 sec/iter\n",
      "Epoch: 195 | Batch: 010 / 011 | Total loss: 0.313 | Reg loss: 0.017 | Tree loss: 0.313 | Accuracy: 0.911263 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 196 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 196 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.808500 | 0.601 sec/iter\n",
      "Epoch: 196 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.813000 | 0.601 sec/iter\n",
      "Epoch: 196 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 196 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.856500 | 0.6 sec/iter\n",
      "Epoch: 196 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.808000 | 0.6 sec/iter\n",
      "Epoch: 196 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 196 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 196 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 196 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.843000 | 0.599 sec/iter\n",
      "Epoch: 196 | Batch: 010 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.849829 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 197 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.812000 | 0.599 sec/iter\n",
      "Epoch: 197 | Batch: 001 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.794500 | 0.599 sec/iter\n",
      "Epoch: 197 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 197 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.832500 | 0.599 sec/iter\n",
      "Epoch: 197 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.828000 | 0.599 sec/iter\n",
      "Epoch: 197 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.812000 | 0.598 sec/iter\n",
      "Epoch: 197 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.820500 | 0.598 sec/iter\n",
      "Epoch: 197 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.822500 | 0.598 sec/iter\n",
      "Epoch: 197 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.855000 | 0.598 sec/iter\n",
      "Epoch: 197 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.869000 | 0.598 sec/iter\n",
      "Epoch: 197 | Batch: 010 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.839590 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 198 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.802000 | 0.6 sec/iter\n",
      "Epoch: 198 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.822500 | 0.599 sec/iter\n",
      "Epoch: 198 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.827500 | 0.599 sec/iter\n",
      "Epoch: 198 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.825000 | 0.599 sec/iter\n",
      "Epoch: 198 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.853500 | 0.599 sec/iter\n",
      "Epoch: 198 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 198 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.829500 | 0.599 sec/iter\n",
      "Epoch: 198 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.831500 | 0.598 sec/iter\n",
      "Epoch: 198 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.820500 | 0.598 sec/iter\n",
      "Epoch: 198 | Batch: 009 / 011 | Total loss: 0.348 | Reg loss: 0.017 | Tree loss: 0.348 | Accuracy: 0.862500 | 0.598 sec/iter\n",
      "Epoch: 198 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.825939 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 199 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.811000 | 0.6 sec/iter\n",
      "Epoch: 199 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.808500 | 0.6 sec/iter\n",
      "Epoch: 199 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 199 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 199 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.841000 | 0.6 sec/iter\n",
      "Epoch: 199 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.809500 | 0.6 sec/iter\n",
      "Epoch: 199 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 199 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.825000 | 0.599 sec/iter\n",
      "Epoch: 199 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 199 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.866000 | 0.599 sec/iter\n",
      "Epoch: 199 | Batch: 010 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.812287 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 200 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 200 | Batch: 001 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.796500 | 0.601 sec/iter\n",
      "Epoch: 200 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 200 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.829500 | 0.601 sec/iter\n",
      "Epoch: 200 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 200 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.812000 | 0.601 sec/iter\n",
      "Epoch: 200 | Batch: 006 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.809500 | 0.6 sec/iter\n",
      "Epoch: 200 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 200 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.849500 | 0.6 sec/iter\n",
      "Epoch: 200 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.854500 | 0.6 sec/iter\n",
      "Epoch: 200 | Batch: 010 / 011 | Total loss: 0.332 | Reg loss: 0.017 | Tree loss: 0.332 | Accuracy: 0.880546 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 201 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 201 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.814500 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201 | Batch: 002 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.838000 | 0.602 sec/iter\n",
      "Epoch: 201 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 201 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.858000 | 0.602 sec/iter\n",
      "Epoch: 201 | Batch: 005 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 201 | Batch: 006 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.808000 | 0.602 sec/iter\n",
      "Epoch: 201 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.812500 | 0.602 sec/iter\n",
      "Epoch: 201 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 201 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.856500 | 0.601 sec/iter\n",
      "Epoch: 201 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.873720 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 202 | Batch: 000 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.810500 | 0.604 sec/iter\n",
      "Epoch: 202 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.800000 | 0.604 sec/iter\n",
      "Epoch: 202 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 202 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.830000 | 0.604 sec/iter\n",
      "Epoch: 202 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.846000 | 0.603 sec/iter\n",
      "Epoch: 202 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.815500 | 0.603 sec/iter\n",
      "Epoch: 202 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 202 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.823500 | 0.603 sec/iter\n",
      "Epoch: 202 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.839500 | 0.603 sec/iter\n",
      "Epoch: 202 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 202 | Batch: 010 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.812287 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 203 | Batch: 000 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.813500 | 0.605 sec/iter\n",
      "Epoch: 203 | Batch: 001 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.830000 | 0.605 sec/iter\n",
      "Epoch: 203 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 203 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.810000 | 0.605 sec/iter\n",
      "Epoch: 203 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.848000 | 0.605 sec/iter\n",
      "Epoch: 203 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 203 | Batch: 006 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.808500 | 0.604 sec/iter\n",
      "Epoch: 203 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 203 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.833000 | 0.604 sec/iter\n",
      "Epoch: 203 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.851500 | 0.604 sec/iter\n",
      "Epoch: 203 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.860068 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 204 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.815000 | 0.606 sec/iter\n",
      "Epoch: 204 | Batch: 001 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.809000 | 0.606 sec/iter\n",
      "Epoch: 204 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.818500 | 0.606 sec/iter\n",
      "Epoch: 204 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.825000 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.843000 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.808500 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.818500 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.825000 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.852500 | 0.605 sec/iter\n",
      "Epoch: 204 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.863481 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 205 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.823000 | 0.606 sec/iter\n",
      "Epoch: 205 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.814000 | 0.606 sec/iter\n",
      "Epoch: 205 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.819500 | 0.606 sec/iter\n",
      "Epoch: 205 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 205 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.848000 | 0.606 sec/iter\n",
      "Epoch: 205 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 205 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.838000 | 0.605 sec/iter\n",
      "Epoch: 205 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.813000 | 0.605 sec/iter\n",
      "Epoch: 205 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.838500 | 0.605 sec/iter\n",
      "Epoch: 205 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.858500 | 0.605 sec/iter\n",
      "Epoch: 205 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.846416 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 206 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.821000 | 0.606 sec/iter\n",
      "Epoch: 206 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.814000 | 0.606 sec/iter\n",
      "Epoch: 206 | Batch: 002 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.829000 | 0.606 sec/iter\n",
      "Epoch: 206 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.830000 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.843500 | 0.606 sec/iter\n",
      "Epoch: 206 | Batch: 005 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.819500 | 0.606 sec/iter\n",
      "Epoch: 206 | Batch: 006 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.814000 | 0.605 sec/iter\n",
      "Epoch: 206 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.820000 | 0.605 sec/iter\n",
      "Epoch: 206 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.826500 | 0.605 sec/iter\n",
      "Epoch: 206 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.855000 | 0.605 sec/iter\n",
      "Epoch: 206 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.839590 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 207 | Batch: 000 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.805500 | 0.606 sec/iter\n",
      "Epoch: 207 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.814500 | 0.606 sec/iter\n",
      "Epoch: 207 | Batch: 002 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.840500 | 0.606 sec/iter\n",
      "Epoch: 207 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.828000 | 0.606 sec/iter\n",
      "Epoch: 207 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.841500 | 0.605 sec/iter\n",
      "Epoch: 207 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.820000 | 0.605 sec/iter\n",
      "Epoch: 207 | Batch: 006 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.809500 | 0.605 sec/iter\n",
      "Epoch: 207 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 207 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.829500 | 0.605 sec/iter\n",
      "Epoch: 207 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.865500 | 0.605 sec/iter\n",
      "Epoch: 207 | Batch: 010 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.863481 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 208 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.808000 | 0.606 sec/iter\n",
      "Epoch: 208 | Batch: 001 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.827500 | 0.606 sec/iter\n",
      "Epoch: 208 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.831500 | 0.606 sec/iter\n",
      "Epoch: 208 | Batch: 003 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.853500 | 0.605 sec/iter\n",
      "Epoch: 208 | Batch: 004 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.846000 | 0.605 sec/iter\n",
      "Epoch: 208 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 208 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.817000 | 0.605 sec/iter\n",
      "Epoch: 208 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 208 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.829500 | 0.605 sec/iter\n",
      "Epoch: 208 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.833500 | 0.604 sec/iter\n",
      "Epoch: 208 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.836177 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 209 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.813500 | 0.606 sec/iter\n",
      "Epoch: 209 | Batch: 001 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.802500 | 0.606 sec/iter\n",
      "Epoch: 209 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.806000 | 0.606 sec/iter\n",
      "Epoch: 209 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.839500 | 0.606 sec/iter\n",
      "Epoch: 209 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.848500 | 0.606 sec/iter\n",
      "Epoch: 209 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.829000 | 0.605 sec/iter\n",
      "Epoch: 209 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.802000 | 0.605 sec/iter\n",
      "Epoch: 209 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 209 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.828500 | 0.605 sec/iter\n",
      "Epoch: 209 | Batch: 009 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.832000 | 0.605 sec/iter\n",
      "Epoch: 209 | Batch: 010 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.849829 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 210 | Batch: 000 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.797500 | 0.606 sec/iter\n",
      "Epoch: 210 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 210 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.817000 | 0.606 sec/iter\n",
      "Epoch: 210 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.826000 | 0.606 sec/iter\n",
      "Epoch: 210 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.854000 | 0.606 sec/iter\n",
      "Epoch: 210 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.820500 | 0.606 sec/iter\n",
      "Epoch: 210 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.805500 | 0.605 sec/iter\n",
      "Epoch: 210 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 210 | Batch: 008 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.847500 | 0.605 sec/iter\n",
      "Epoch: 210 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.848500 | 0.605 sec/iter\n",
      "Epoch: 210 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.791809 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 211 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.806500 | 0.605 sec/iter\n",
      "Epoch: 211 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 211 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.807500 | 0.605 sec/iter\n",
      "Epoch: 211 | Batch: 003 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.847500 | 0.605 sec/iter\n",
      "Epoch: 211 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.839500 | 0.605 sec/iter\n",
      "Epoch: 211 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.820500 | 0.604 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 211 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.820500 | 0.604 sec/iter\n",
      "Epoch: 211 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.839000 | 0.604 sec/iter\n",
      "Epoch: 211 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.833500 | 0.604 sec/iter\n",
      "Epoch: 211 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.845000 | 0.604 sec/iter\n",
      "Epoch: 211 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.860068 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 212 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.801500 | 0.605 sec/iter\n",
      "Epoch: 212 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 212 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 212 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.834000 | 0.604 sec/iter\n",
      "Epoch: 212 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.844500 | 0.604 sec/iter\n",
      "Epoch: 212 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.818500 | 0.604 sec/iter\n",
      "Epoch: 212 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 212 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.830500 | 0.603 sec/iter\n",
      "Epoch: 212 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.846000 | 0.603 sec/iter\n",
      "Epoch: 212 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.850500 | 0.603 sec/iter\n",
      "Epoch: 212 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.017 | Tree loss: 0.358 | Accuracy: 0.873720 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 213 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.816000 | 0.603 sec/iter\n",
      "Epoch: 213 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.812500 | 0.603 sec/iter\n",
      "Epoch: 213 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 213 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.830500 | 0.603 sec/iter\n",
      "Epoch: 213 | Batch: 004 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 213 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.830000 | 0.602 sec/iter\n",
      "Epoch: 213 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 213 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.810000 | 0.602 sec/iter\n",
      "Epoch: 213 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 213 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.857500 | 0.602 sec/iter\n",
      "Epoch: 213 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.832765 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 214 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.810500 | 0.603 sec/iter\n",
      "Epoch: 214 | Batch: 001 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.796000 | 0.602 sec/iter\n",
      "Epoch: 214 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 214 | Batch: 003 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 214 | Batch: 004 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.862500 | 0.602 sec/iter\n",
      "Epoch: 214 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 214 | Batch: 006 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.796000 | 0.602 sec/iter\n",
      "Epoch: 214 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 214 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.834500 | 0.601 sec/iter\n",
      "Epoch: 214 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.853000 | 0.601 sec/iter\n",
      "Epoch: 214 | Batch: 010 / 011 | Total loss: 0.355 | Reg loss: 0.017 | Tree loss: 0.355 | Accuracy: 0.883959 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 215 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 215 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.819500 | 0.602 sec/iter\n",
      "Epoch: 215 | Batch: 002 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 215 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.814000 | 0.601 sec/iter\n",
      "Epoch: 215 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.855500 | 0.601 sec/iter\n",
      "Epoch: 215 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 215 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 215 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 215 | Batch: 008 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.810500 | 0.601 sec/iter\n",
      "Epoch: 215 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.851500 | 0.6 sec/iter\n",
      "Epoch: 215 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.863481 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 216 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 001 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.801000 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.861500 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 005 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 216 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.819500 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.826000 | 0.599 sec/iter\n",
      "Epoch: 216 | Batch: 009 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.847500 | 0.599 sec/iter\n",
      "Epoch: 216 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.877133 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 217 | Batch: 000 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.814500 | 0.6 sec/iter\n",
      "Epoch: 217 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.808000 | 0.599 sec/iter\n",
      "Epoch: 217 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.836500 | 0.599 sec/iter\n",
      "Epoch: 217 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.835500 | 0.599 sec/iter\n",
      "Epoch: 217 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.845000 | 0.599 sec/iter\n",
      "Epoch: 217 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 217 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.809000 | 0.599 sec/iter\n",
      "Epoch: 217 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833000 | 0.598 sec/iter\n",
      "Epoch: 217 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.808500 | 0.598 sec/iter\n",
      "Epoch: 217 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.860500 | 0.598 sec/iter\n",
      "Epoch: 217 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.846416 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 218 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.808500 | 0.6 sec/iter\n",
      "Epoch: 218 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 218 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 218 | Batch: 003 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.845000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.828000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 006 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.806000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.819000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.865000 | 0.599 sec/iter\n",
      "Epoch: 218 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.877133 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 219 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.812500 | 0.599 sec/iter\n",
      "Epoch: 219 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.803000 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.828000 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.813500 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.836500 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821500 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.831500 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831000 | 0.598 sec/iter\n",
      "Epoch: 219 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.831000 | 0.597 sec/iter\n",
      "Epoch: 219 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.844000 | 0.597 sec/iter\n",
      "Epoch: 219 | Batch: 010 / 011 | Total loss: 0.346 | Reg loss: 0.017 | Tree loss: 0.346 | Accuracy: 0.877133 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 220 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.806500 | 0.6 sec/iter\n",
      "Epoch: 220 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.809000 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 002 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.820500 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.812500 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 004 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.862500 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.814000 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 006 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.804500 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.819000 | 0.599 sec/iter\n",
      "Epoch: 220 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.844000 | 0.598 sec/iter\n",
      "Epoch: 220 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.852000 | 0.598 sec/iter\n",
      "Epoch: 220 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.880546 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 221 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.827500 | 0.601 sec/iter\n",
      "Epoch: 221 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.805000 | 0.601 sec/iter\n",
      "Epoch: 221 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.839000 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 221 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.852500 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 221 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.860068 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 222 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.816500 | 0.602 sec/iter\n",
      "Epoch: 222 | Batch: 001 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.794000 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.814000 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.843000 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 005 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.812000 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.832500 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 008 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 222 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.848000 | 0.6 sec/iter\n",
      "Epoch: 222 | Batch: 010 / 011 | Total loss: 0.343 | Reg loss: 0.017 | Tree loss: 0.343 | Accuracy: 0.890785 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 223 | Batch: 000 / 011 | Total loss: 0.448 | Reg loss: 0.017 | Tree loss: 0.448 | Accuracy: 0.798500 | 0.603 sec/iter\n",
      "Epoch: 223 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.816000 | 0.603 sec/iter\n",
      "Epoch: 223 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.814000 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 004 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.856500 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.812000 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.838500 | 0.602 sec/iter\n",
      "Epoch: 223 | Batch: 010 / 011 | Total loss: 0.340 | Reg loss: 0.017 | Tree loss: 0.340 | Accuracy: 0.890785 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 224 | Batch: 000 / 011 | Total loss: 0.455 | Reg loss: 0.017 | Tree loss: 0.455 | Accuracy: 0.797500 | 0.604 sec/iter\n",
      "Epoch: 224 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 224 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 224 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821000 | 0.604 sec/iter\n",
      "Epoch: 224 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.846500 | 0.603 sec/iter\n",
      "Epoch: 224 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.821500 | 0.603 sec/iter\n",
      "Epoch: 224 | Batch: 006 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.802500 | 0.603 sec/iter\n",
      "Epoch: 224 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.820500 | 0.603 sec/iter\n",
      "Epoch: 224 | Batch: 008 / 011 | Total loss: 0.361 | Reg loss: 0.017 | Tree loss: 0.361 | Accuracy: 0.847000 | 0.603 sec/iter\n",
      "Epoch: 224 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.844500 | 0.603 sec/iter\n",
      "Epoch: 224 | Batch: 010 / 011 | Total loss: 0.326 | Reg loss: 0.017 | Tree loss: 0.326 | Accuracy: 0.890785 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 225 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 225 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.824500 | 0.605 sec/iter\n",
      "Epoch: 225 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.808500 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.822000 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.837000 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.816000 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.816500 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.829500 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.852500 | 0.604 sec/iter\n",
      "Epoch: 225 | Batch: 010 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.860068 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 226 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.798500 | 0.606 sec/iter\n",
      "Epoch: 226 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.808500 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.836500 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 004 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.862000 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.825000 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.820000 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.818500 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.814000 | 0.605 sec/iter\n",
      "Epoch: 226 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.852000 | 0.604 sec/iter\n",
      "Epoch: 226 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.017 | Tree loss: 0.348 | Accuracy: 0.877133 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 227 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.814000 | 0.607 sec/iter\n",
      "Epoch: 227 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.825500 | 0.607 sec/iter\n",
      "Epoch: 227 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.824500 | 0.607 sec/iter\n",
      "Epoch: 227 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.814500 | 0.607 sec/iter\n",
      "Epoch: 227 | Batch: 004 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.840000 | 0.606 sec/iter\n",
      "Epoch: 227 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.826000 | 0.606 sec/iter\n",
      "Epoch: 227 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.826000 | 0.606 sec/iter\n",
      "Epoch: 227 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.818500 | 0.606 sec/iter\n",
      "Epoch: 227 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.831000 | 0.606 sec/iter\n",
      "Epoch: 227 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.837500 | 0.606 sec/iter\n",
      "Epoch: 227 | Batch: 010 / 011 | Total loss: 0.355 | Reg loss: 0.017 | Tree loss: 0.355 | Accuracy: 0.873720 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 228 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.808000 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 001 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.791500 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.820500 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.822000 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.839000 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.843500 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.816500 | 0.607 sec/iter\n",
      "Epoch: 228 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.813000 | 0.606 sec/iter\n",
      "Epoch: 228 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.823500 | 0.606 sec/iter\n",
      "Epoch: 228 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.836500 | 0.606 sec/iter\n",
      "Epoch: 228 | Batch: 010 / 011 | Total loss: 0.357 | Reg loss: 0.017 | Tree loss: 0.357 | Accuracy: 0.890785 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 229 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.823000 | 0.607 sec/iter\n",
      "Epoch: 229 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.806500 | 0.607 sec/iter\n",
      "Epoch: 229 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.820500 | 0.607 sec/iter\n",
      "Epoch: 229 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.813500 | 0.607 sec/iter\n",
      "Epoch: 229 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.838000 | 0.606 sec/iter\n",
      "Epoch: 229 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 229 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.815500 | 0.606 sec/iter\n",
      "Epoch: 229 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.822500 | 0.606 sec/iter\n",
      "Epoch: 229 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.829000 | 0.606 sec/iter\n",
      "Epoch: 229 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.858000 | 0.606 sec/iter\n",
      "Epoch: 229 | Batch: 010 / 011 | Total loss: 0.455 | Reg loss: 0.017 | Tree loss: 0.455 | Accuracy: 0.812287 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 230 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.805500 | 0.607 sec/iter\n",
      "Epoch: 230 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.820500 | 0.607 sec/iter\n",
      "Epoch: 230 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.822500 | 0.607 sec/iter\n",
      "Epoch: 230 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.825000 | 0.607 sec/iter\n",
      "Epoch: 230 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.855500 | 0.607 sec/iter\n",
      "Epoch: 230 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.829000 | 0.606 sec/iter\n",
      "Epoch: 230 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.833500 | 0.606 sec/iter\n",
      "Epoch: 230 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.813500 | 0.606 sec/iter\n",
      "Epoch: 230 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.814500 | 0.606 sec/iter\n",
      "Epoch: 230 | Batch: 009 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.863000 | 0.606 sec/iter\n",
      "Epoch: 230 | Batch: 010 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.870307 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 231 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.804500 | 0.608 sec/iter\n",
      "Epoch: 231 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.815500 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.827000 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.820500 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.847000 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.825500 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.822500 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.825000 | 0.607 sec/iter\n",
      "Epoch: 231 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.821000 | 0.606 sec/iter\n",
      "Epoch: 231 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.852500 | 0.606 sec/iter\n",
      "Epoch: 231 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.832765 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 232 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.814000 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 232 | Batch: 001 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.823000 | 0.606 sec/iter\n",
      "Epoch: 232 | Batch: 002 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.835500 | 0.606 sec/iter\n",
      "Epoch: 232 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.835500 | 0.606 sec/iter\n",
      "Epoch: 232 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.846500 | 0.606 sec/iter\n",
      "Epoch: 232 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.810500 | 0.606 sec/iter\n",
      "Epoch: 232 | Batch: 006 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.842000 | 0.605 sec/iter\n",
      "Epoch: 232 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.810500 | 0.605 sec/iter\n",
      "Epoch: 232 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.822000 | 0.605 sec/iter\n",
      "Epoch: 232 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.857000 | 0.605 sec/iter\n",
      "Epoch: 232 | Batch: 010 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.843003 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 233 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.819500 | 0.606 sec/iter\n",
      "Epoch: 233 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.807000 | 0.605 sec/iter\n",
      "Epoch: 233 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.828000 | 0.605 sec/iter\n",
      "Epoch: 233 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.819000 | 0.605 sec/iter\n",
      "Epoch: 233 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.851500 | 0.605 sec/iter\n",
      "Epoch: 233 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.823500 | 0.605 sec/iter\n",
      "Epoch: 233 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.835500 | 0.605 sec/iter\n",
      "Epoch: 233 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.807000 | 0.604 sec/iter\n",
      "Epoch: 233 | Batch: 008 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.816000 | 0.604 sec/iter\n",
      "Epoch: 233 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.816500 | 0.604 sec/iter\n",
      "Epoch: 233 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.846416 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 234 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.813000 | 0.604 sec/iter\n",
      "Epoch: 234 | Batch: 001 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.797500 | 0.604 sec/iter\n",
      "Epoch: 234 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.825000 | 0.604 sec/iter\n",
      "Epoch: 234 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.828000 | 0.604 sec/iter\n",
      "Epoch: 234 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.824000 | 0.604 sec/iter\n",
      "Epoch: 234 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.859000 | 0.603 sec/iter\n",
      "Epoch: 234 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.832000 | 0.603 sec/iter\n",
      "Epoch: 234 | Batch: 007 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.811000 | 0.603 sec/iter\n",
      "Epoch: 234 | Batch: 008 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.815500 | 0.603 sec/iter\n",
      "Epoch: 234 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.825500 | 0.603 sec/iter\n",
      "Epoch: 234 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.829352 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 235 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 235 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.821500 | 0.603 sec/iter\n",
      "Epoch: 235 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.845500 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 235 | Batch: 009 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 235 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.832765 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 236 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.801000 | 0.602 sec/iter\n",
      "Epoch: 236 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.810000 | 0.602 sec/iter\n",
      "Epoch: 236 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 236 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.836500 | 0.602 sec/iter\n",
      "Epoch: 236 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 236 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.835500 | 0.601 sec/iter\n",
      "Epoch: 236 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 236 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 236 | Batch: 008 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 236 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 236 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.860068 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 237 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 237 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.801500 | 0.601 sec/iter\n",
      "Epoch: 237 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.813500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 237 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 237 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.839000 | 0.601 sec/iter\n",
      "Epoch: 237 | Batch: 005 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.803000 | 0.601 sec/iter\n",
      "Epoch: 237 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 237 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 237 | Batch: 008 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.848500 | 0.6 sec/iter\n",
      "Epoch: 237 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 237 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.017 | Tree loss: 0.347 | Accuracy: 0.866894 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 238 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 238 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.832500 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.851500 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 005 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.816000 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 006 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.818500 | 0.601 sec/iter\n",
      "Epoch: 238 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.841000 | 0.6 sec/iter\n",
      "Epoch: 238 | Batch: 009 / 011 | Total loss: 0.360 | Reg loss: 0.017 | Tree loss: 0.360 | Accuracy: 0.865500 | 0.6 sec/iter\n",
      "Epoch: 238 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.839590 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 239 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.815500 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 001 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.804000 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.815500 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 239 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.819000 | 0.599 sec/iter\n",
      "Epoch: 239 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.838000 | 0.599 sec/iter\n",
      "Epoch: 239 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.833500 | 0.599 sec/iter\n",
      "Epoch: 239 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.866894 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 240 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.803500 | 0.601 sec/iter\n",
      "Epoch: 240 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 240 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 240 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.846500 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 005 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.821000 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.836500 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.854500 | 0.6 sec/iter\n",
      "Epoch: 240 | Batch: 010 / 011 | Total loss: 0.345 | Reg loss: 0.017 | Tree loss: 0.345 | Accuracy: 0.866894 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 241 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.807500 | 0.601 sec/iter\n",
      "Epoch: 241 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.805000 | 0.601 sec/iter\n",
      "Epoch: 241 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 241 | Batch: 003 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.838000 | 0.601 sec/iter\n",
      "Epoch: 241 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.850000 | 0.6 sec/iter\n",
      "Epoch: 241 | Batch: 005 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.815000 | 0.6 sec/iter\n",
      "Epoch: 241 | Batch: 006 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.801500 | 0.6 sec/iter\n",
      "Epoch: 241 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 241 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 241 | Batch: 009 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.847000 | 0.6 sec/iter\n",
      "Epoch: 241 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.017 | Tree loss: 0.349 | Accuracy: 0.870307 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 242 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 242 | Batch: 001 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.799000 | 0.602 sec/iter\n",
      "Epoch: 242 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 242 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 242 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.841500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 242 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 242 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 242 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.813000 | 0.601 sec/iter\n",
      "Epoch: 242 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.836000 | 0.601 sec/iter\n",
      "Epoch: 242 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 242 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.832765 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 243 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.798500 | 0.603 sec/iter\n",
      "Epoch: 243 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.813000 | 0.603 sec/iter\n",
      "Epoch: 243 | Batch: 002 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.812000 | 0.603 sec/iter\n",
      "Epoch: 243 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.832500 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.824000 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 243 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.843003 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 244 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.804000 | 0.604 sec/iter\n",
      "Epoch: 244 | Batch: 001 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.810500 | 0.604 sec/iter\n",
      "Epoch: 244 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 244 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.832000 | 0.604 sec/iter\n",
      "Epoch: 244 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.832500 | 0.603 sec/iter\n",
      "Epoch: 244 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 244 | Batch: 006 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.829000 | 0.603 sec/iter\n",
      "Epoch: 244 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.815000 | 0.603 sec/iter\n",
      "Epoch: 244 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.827500 | 0.603 sec/iter\n",
      "Epoch: 244 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.838500 | 0.603 sec/iter\n",
      "Epoch: 244 | Batch: 010 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.860068 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 245 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.802500 | 0.605 sec/iter\n",
      "Epoch: 245 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 245 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 245 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.834000 | 0.605 sec/iter\n",
      "Epoch: 245 | Batch: 004 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.862000 | 0.605 sec/iter\n",
      "Epoch: 245 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.830500 | 0.604 sec/iter\n",
      "Epoch: 245 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.833500 | 0.604 sec/iter\n",
      "Epoch: 245 | Batch: 007 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 245 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.819000 | 0.604 sec/iter\n",
      "Epoch: 245 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.825000 | 0.604 sec/iter\n",
      "Epoch: 245 | Batch: 010 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.863481 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 246 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.811000 | 0.606 sec/iter\n",
      "Epoch: 246 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.812000 | 0.606 sec/iter\n",
      "Epoch: 246 | Batch: 002 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.816000 | 0.606 sec/iter\n",
      "Epoch: 246 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.827500 | 0.606 sec/iter\n",
      "Epoch: 246 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.856000 | 0.605 sec/iter\n",
      "Epoch: 246 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.820000 | 0.605 sec/iter\n",
      "Epoch: 246 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831500 | 0.605 sec/iter\n",
      "Epoch: 246 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.818500 | 0.605 sec/iter\n",
      "Epoch: 246 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.823000 | 0.605 sec/iter\n",
      "Epoch: 246 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.834000 | 0.605 sec/iter\n",
      "Epoch: 246 | Batch: 010 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.832765 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 247 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.819000 | 0.607 sec/iter\n",
      "Epoch: 247 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.808000 | 0.607 sec/iter\n",
      "Epoch: 247 | Batch: 002 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.782000 | 0.607 sec/iter\n",
      "Epoch: 247 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.837000 | 0.606 sec/iter\n",
      "Epoch: 247 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.835500 | 0.606 sec/iter\n",
      "Epoch: 247 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.833000 | 0.606 sec/iter\n",
      "Epoch: 247 | Batch: 006 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.804500 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.814500 | 0.606 sec/iter\n",
      "Epoch: 247 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.827000 | 0.606 sec/iter\n",
      "Epoch: 247 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.840500 | 0.606 sec/iter\n",
      "Epoch: 247 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.866894 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 248 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.802500 | 0.608 sec/iter\n",
      "Epoch: 248 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.814000 | 0.608 sec/iter\n",
      "Epoch: 248 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.827500 | 0.608 sec/iter\n",
      "Epoch: 248 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.842000 | 0.608 sec/iter\n",
      "Epoch: 248 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.843000 | 0.607 sec/iter\n",
      "Epoch: 248 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.825000 | 0.607 sec/iter\n",
      "Epoch: 248 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.815500 | 0.607 sec/iter\n",
      "Epoch: 248 | Batch: 007 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.811000 | 0.607 sec/iter\n",
      "Epoch: 248 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.816500 | 0.607 sec/iter\n",
      "Epoch: 248 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.842500 | 0.607 sec/iter\n",
      "Epoch: 248 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.860068 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 249 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.810000 | 0.609 sec/iter\n",
      "Epoch: 249 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.806500 | 0.609 sec/iter\n",
      "Epoch: 249 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.822000 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 003 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.834000 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827000 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.830500 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.810500 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821000 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.836500 | 0.608 sec/iter\n",
      "Epoch: 249 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.827000 | 0.607 sec/iter\n",
      "Epoch: 249 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.017 | Tree loss: 0.349 | Accuracy: 0.866894 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 250 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.800500 | 0.609 sec/iter\n",
      "Epoch: 250 | Batch: 001 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.797500 | 0.609 sec/iter\n",
      "Epoch: 250 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.810000 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.836000 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.847500 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.828500 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.827000 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.817000 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.832000 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.855000 | 0.608 sec/iter\n",
      "Epoch: 250 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.839590 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 251 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.799000 | 0.608 sec/iter\n",
      "Epoch: 251 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.797000 | 0.608 sec/iter\n",
      "Epoch: 251 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.820000 | 0.608 sec/iter\n",
      "Epoch: 251 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.835500 | 0.608 sec/iter\n",
      "Epoch: 251 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.838000 | 0.607 sec/iter\n",
      "Epoch: 251 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.815500 | 0.607 sec/iter\n",
      "Epoch: 251 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.822500 | 0.607 sec/iter\n",
      "Epoch: 251 | Batch: 007 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.815000 | 0.607 sec/iter\n",
      "Epoch: 251 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.827500 | 0.607 sec/iter\n",
      "Epoch: 251 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.844500 | 0.607 sec/iter\n",
      "Epoch: 251 | Batch: 010 / 011 | Total loss: 0.342 | Reg loss: 0.017 | Tree loss: 0.342 | Accuracy: 0.907850 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 252 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.803000 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 001 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.827500 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 002 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.819500 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.836000 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.847000 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 005 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.809500 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.824000 | 0.607 sec/iter\n",
      "Epoch: 252 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.828000 | 0.606 sec/iter\n",
      "Epoch: 252 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.825500 | 0.606 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 252 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.848500 | 0.606 sec/iter\n",
      "Epoch: 252 | Batch: 010 / 011 | Total loss: 0.324 | Reg loss: 0.017 | Tree loss: 0.324 | Accuracy: 0.904437 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 253 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.818000 | 0.607 sec/iter\n",
      "Epoch: 253 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.811500 | 0.607 sec/iter\n",
      "Epoch: 253 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.817000 | 0.607 sec/iter\n",
      "Epoch: 253 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.834500 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.845500 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.827000 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 006 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.801500 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.822500 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.831000 | 0.606 sec/iter\n",
      "Epoch: 253 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.832765 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 254 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.803500 | 0.606 sec/iter\n",
      "Epoch: 254 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.808500 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.810500 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.831000 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.836500 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.851000 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.810000 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 007 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.830000 | 0.605 sec/iter\n",
      "Epoch: 254 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.825500 | 0.604 sec/iter\n",
      "Epoch: 254 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 254 | Batch: 010 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.839590 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 255 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.822000 | 0.605 sec/iter\n",
      "Epoch: 255 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.824000 | 0.605 sec/iter\n",
      "Epoch: 255 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.819000 | 0.605 sec/iter\n",
      "Epoch: 255 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 004 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.837500 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.809000 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 007 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.834000 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.839500 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.827500 | 0.604 sec/iter\n",
      "Epoch: 255 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.890785 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 256 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.814500 | 0.605 sec/iter\n",
      "Epoch: 256 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.806000 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.807000 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 003 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.851500 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.841500 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.819000 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.817000 | 0.604 sec/iter\n",
      "Epoch: 256 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 256 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.842000 | 0.603 sec/iter\n",
      "Epoch: 256 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.017 | Tree loss: 0.348 | Accuracy: 0.856655 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 257 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.815500 | 0.603 sec/iter\n",
      "Epoch: 257 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 257 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.808500 | 0.603 sec/iter\n",
      "Epoch: 257 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 257 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.830500 | 0.603 sec/iter\n",
      "Epoch: 257 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.846000 | 0.603 sec/iter\n",
      "Epoch: 257 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 257 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 257 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 257 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.841000 | 0.602 sec/iter\n",
      "Epoch: 257 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.853242 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 258 | Batch: 000 / 011 | Total loss: 0.454 | Reg loss: 0.017 | Tree loss: 0.454 | Accuracy: 0.793000 | 0.604 sec/iter\n",
      "Epoch: 258 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.809500 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.825000 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.823500 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.840000 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.843500 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 006 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.818500 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 258 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.840500 | 0.602 sec/iter\n",
      "Epoch: 258 | Batch: 010 / 011 | Total loss: 0.355 | Reg loss: 0.017 | Tree loss: 0.355 | Accuracy: 0.846416 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 259 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.810000 | 0.604 sec/iter\n",
      "Epoch: 259 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 259 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 259 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.832500 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 004 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.830500 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 006 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.818500 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.823500 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 009 / 011 | Total loss: 0.362 | Reg loss: 0.017 | Tree loss: 0.362 | Accuracy: 0.838500 | 0.603 sec/iter\n",
      "Epoch: 259 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.849829 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 260 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.807500 | 0.603 sec/iter\n",
      "Epoch: 260 | Batch: 001 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.798500 | 0.603 sec/iter\n",
      "Epoch: 260 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.810000 | 0.603 sec/iter\n",
      "Epoch: 260 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.838000 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 260 | Batch: 010 / 011 | Total loss: 0.336 | Reg loss: 0.017 | Tree loss: 0.336 | Accuracy: 0.887372 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 261 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 261 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.825500 | 0.603 sec/iter\n",
      "Epoch: 261 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.817500 | 0.603 sec/iter\n",
      "Epoch: 261 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.820500 | 0.603 sec/iter\n",
      "Epoch: 261 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.840000 | 0.603 sec/iter\n",
      "Epoch: 261 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.844000 | 0.603 sec/iter\n",
      "Epoch: 261 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.819500 | 0.602 sec/iter\n",
      "Epoch: 261 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.830000 | 0.602 sec/iter\n",
      "Epoch: 261 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 261 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.837000 | 0.602 sec/iter\n",
      "Epoch: 261 | Batch: 010 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.846416 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 262 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.017 | Tree loss: 0.443 | Accuracy: 0.801000 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.821500 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.834000 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.823000 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.835500 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.833000 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 006 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.825500 | 0.603 sec/iter\n",
      "Epoch: 262 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 262 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.820000 | 0.602 sec/iter\n",
      "Epoch: 262 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.838500 | 0.602 sec/iter\n",
      "Epoch: 262 | Batch: 010 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.846416 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.804500 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.807500 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.839500 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.844000 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 005 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.834000 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 006 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.834000 | 0.602 sec/iter\n",
      "Epoch: 263 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.827500 | 0.601 sec/iter\n",
      "Epoch: 263 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 263 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.017 | Tree loss: 0.360 | Accuracy: 0.866894 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 264 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.800000 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.812500 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 002 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.805500 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.842000 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.834500 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.833000 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 006 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.834500 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.826000 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.816500 | 0.603 sec/iter\n",
      "Epoch: 264 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.833500 | 0.602 sec/iter\n",
      "Epoch: 264 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.853242 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 265 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.817500 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.806500 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.824000 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.805000 | 0.604 sec/iter\n",
      "Epoch: 265 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.826000 | 0.603 sec/iter\n",
      "Epoch: 265 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 265 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.017 | Tree loss: 0.358 | Accuracy: 0.870307 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 266 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.811500 | 0.605 sec/iter\n",
      "Epoch: 266 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.810500 | 0.605 sec/iter\n",
      "Epoch: 266 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 266 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.834500 | 0.605 sec/iter\n",
      "Epoch: 266 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.835000 | 0.604 sec/iter\n",
      "Epoch: 266 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.836000 | 0.604 sec/iter\n",
      "Epoch: 266 | Batch: 006 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 266 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 266 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.825500 | 0.604 sec/iter\n",
      "Epoch: 266 | Batch: 009 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.853000 | 0.604 sec/iter\n",
      "Epoch: 266 | Batch: 010 / 011 | Total loss: 0.321 | Reg loss: 0.017 | Tree loss: 0.321 | Accuracy: 0.894198 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 267 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.810500 | 0.606 sec/iter\n",
      "Epoch: 267 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.802000 | 0.606 sec/iter\n",
      "Epoch: 267 | Batch: 002 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.838500 | 0.606 sec/iter\n",
      "Epoch: 267 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.840500 | 0.606 sec/iter\n",
      "Epoch: 267 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.832500 | 0.606 sec/iter\n",
      "Epoch: 267 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 267 | Batch: 006 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.829500 | 0.605 sec/iter\n",
      "Epoch: 267 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827500 | 0.605 sec/iter\n",
      "Epoch: 267 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.815500 | 0.605 sec/iter\n",
      "Epoch: 267 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.834000 | 0.605 sec/iter\n",
      "Epoch: 267 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.877133 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 268 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.809000 | 0.607 sec/iter\n",
      "Epoch: 268 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.808000 | 0.607 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.819500 | 0.607 sec/iter\n",
      "Epoch: 268 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.832000 | 0.607 sec/iter\n",
      "Epoch: 268 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.838000 | 0.607 sec/iter\n",
      "Epoch: 268 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.820500 | 0.607 sec/iter\n",
      "Epoch: 268 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.817500 | 0.606 sec/iter\n",
      "Epoch: 268 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.819000 | 0.606 sec/iter\n",
      "Epoch: 268 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.815000 | 0.606 sec/iter\n",
      "Epoch: 268 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.866000 | 0.606 sec/iter\n",
      "Epoch: 268 | Batch: 010 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.839590 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 269 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.805000 | 0.608 sec/iter\n",
      "Epoch: 269 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.821000 | 0.608 sec/iter\n",
      "Epoch: 269 | Batch: 002 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.808500 | 0.608 sec/iter\n",
      "Epoch: 269 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.831000 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.837500 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.827000 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.823500 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.812000 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.821500 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.834500 | 0.607 sec/iter\n",
      "Epoch: 269 | Batch: 010 / 011 | Total loss: 0.323 | Reg loss: 0.017 | Tree loss: 0.323 | Accuracy: 0.901024 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 270 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.801500 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.808000 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.817500 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.836000 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.832000 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.845000 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.826500 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 007 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.824500 | 0.608 sec/iter\n",
      "Epoch: 270 | Batch: 008 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.840000 | 0.607 sec/iter\n",
      "Epoch: 270 | Batch: 009 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.827500 | 0.607 sec/iter\n",
      "Epoch: 270 | Batch: 010 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.849829 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 271 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.813500 | 0.609 sec/iter\n",
      "Epoch: 271 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.819500 | 0.609 sec/iter\n",
      "Epoch: 271 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.813500 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.836000 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.826500 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.860500 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.814500 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.804500 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.826500 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 009 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.826000 | 0.608 sec/iter\n",
      "Epoch: 271 | Batch: 010 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.839590 | 0.607 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 272 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.811500 | 0.608 sec/iter\n",
      "Epoch: 272 | Batch: 001 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.809000 | 0.608 sec/iter\n",
      "Epoch: 272 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.836500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.842500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.834500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.824500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.830500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 007 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.833000 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.819500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 009 / 011 | Total loss: 0.357 | Reg loss: 0.017 | Tree loss: 0.357 | Accuracy: 0.850500 | 0.607 sec/iter\n",
      "Epoch: 272 | Batch: 010 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.860068 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 273 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.807000 | 0.607 sec/iter\n",
      "Epoch: 273 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.813500 | 0.607 sec/iter\n",
      "Epoch: 273 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.812500 | 0.607 sec/iter\n",
      "Epoch: 273 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.830500 | 0.607 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 273 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.828000 | 0.607 sec/iter\n",
      "Epoch: 273 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.856500 | 0.606 sec/iter\n",
      "Epoch: 273 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.818000 | 0.606 sec/iter\n",
      "Epoch: 273 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.823000 | 0.606 sec/iter\n",
      "Epoch: 273 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.827000 | 0.606 sec/iter\n",
      "Epoch: 273 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.826500 | 0.606 sec/iter\n",
      "Epoch: 273 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.846416 | 0.606 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 274 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.797500 | 0.607 sec/iter\n",
      "Epoch: 274 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.818500 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 002 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.837500 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.827500 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.829500 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.841000 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.821500 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.824500 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.838000 | 0.606 sec/iter\n",
      "Epoch: 274 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.839500 | 0.605 sec/iter\n",
      "Epoch: 274 | Batch: 010 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.846416 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 275 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.801500 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.799500 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.821500 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.842000 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.819000 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.821000 | 0.605 sec/iter\n",
      "Epoch: 275 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 275 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 275 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 275 | Batch: 010 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.873720 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 276 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.819000 | 0.605 sec/iter\n",
      "Epoch: 276 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.816500 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 002 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.806000 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.844000 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.850000 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 007 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.835000 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 008 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 276 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.825500 | 0.603 sec/iter\n",
      "Epoch: 276 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.856655 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 277 | Batch: 000 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.827500 | 0.605 sec/iter\n",
      "Epoch: 277 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.810500 | 0.605 sec/iter\n",
      "Epoch: 277 | Batch: 002 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.785000 | 0.605 sec/iter\n",
      "Epoch: 277 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.808000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.858000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 005 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.831000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.831000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.819000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.817000 | 0.604 sec/iter\n",
      "Epoch: 277 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.815700 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 278 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.810000 | 0.604 sec/iter\n",
      "Epoch: 278 | Batch: 001 / 011 | Total loss: 0.446 | Reg loss: 0.017 | Tree loss: 0.446 | Accuracy: 0.803500 | 0.604 sec/iter\n",
      "Epoch: 278 | Batch: 002 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 278 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 278 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 278 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.848000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 278 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.826500 | 0.603 sec/iter\n",
      "Epoch: 278 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 278 | Batch: 008 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.818500 | 0.603 sec/iter\n",
      "Epoch: 278 | Batch: 009 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 278 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.832765 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 279 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.808000 | 0.604 sec/iter\n",
      "Epoch: 279 | Batch: 001 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.802500 | 0.604 sec/iter\n",
      "Epoch: 279 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.820500 | 0.604 sec/iter\n",
      "Epoch: 279 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.831000 | 0.604 sec/iter\n",
      "Epoch: 279 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.830000 | 0.604 sec/iter\n",
      "Epoch: 279 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.846500 | 0.604 sec/iter\n",
      "Epoch: 279 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 279 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 279 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.836000 | 0.603 sec/iter\n",
      "Epoch: 279 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.838500 | 0.603 sec/iter\n",
      "Epoch: 279 | Batch: 010 / 011 | Total loss: 0.330 | Reg loss: 0.017 | Tree loss: 0.330 | Accuracy: 0.877133 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 280 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.816500 | 0.603 sec/iter\n",
      "Epoch: 280 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.812000 | 0.603 sec/iter\n",
      "Epoch: 280 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 280 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 280 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.851500 | 0.603 sec/iter\n",
      "Epoch: 280 | Batch: 005 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 280 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.825000 | 0.602 sec/iter\n",
      "Epoch: 280 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 280 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 280 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.840000 | 0.602 sec/iter\n",
      "Epoch: 280 | Batch: 010 / 011 | Total loss: 0.340 | Reg loss: 0.017 | Tree loss: 0.340 | Accuracy: 0.901024 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 281 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.819000 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 001 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.805500 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.824500 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 004 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.843500 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 281 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 281 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 281 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 281 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.017 | Tree loss: 0.348 | Accuracy: 0.873720 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 282 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.808000 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.817500 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.838000 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 004 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.842000 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.846500 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.820000 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 282 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 282 | Batch: 010 / 011 | Total loss: 0.331 | Reg loss: 0.017 | Tree loss: 0.331 | Accuracy: 0.877133 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 283 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.819500 | 0.603 sec/iter\n",
      "Epoch: 283 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 283 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.837000 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 004 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.826000 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.848000 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 006 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.833500 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 283 | Batch: 008 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.809000 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 009 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 283 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.877133 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 284 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.812500 | 0.603 sec/iter\n",
      "Epoch: 284 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.817500 | 0.603 sec/iter\n",
      "Epoch: 284 | Batch: 002 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.801500 | 0.603 sec/iter\n",
      "Epoch: 284 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.820500 | 0.603 sec/iter\n",
      "Epoch: 284 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 284 | Batch: 005 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.845500 | 0.602 sec/iter\n",
      "Epoch: 284 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 284 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 284 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.812500 | 0.602 sec/iter\n",
      "Epoch: 284 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 284 | Batch: 010 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.866894 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 285 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.844500 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.812500 | 0.602 sec/iter\n",
      "Epoch: 285 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 285 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.854500 | 0.601 sec/iter\n",
      "Epoch: 285 | Batch: 010 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.849829 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 286 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.804000 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.802500 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.819500 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.832500 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.852500 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.814000 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 006 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 286 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 286 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 286 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.853000 | 0.601 sec/iter\n",
      "Epoch: 286 | Batch: 010 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.832765 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 287 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.815500 | 0.603 sec/iter\n",
      "Epoch: 287 | Batch: 001 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.808500 | 0.603 sec/iter\n",
      "Epoch: 287 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 287 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 287 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.842000 | 0.602 sec/iter\n",
      "Epoch: 287 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 287 | Batch: 006 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.798500 | 0.602 sec/iter\n",
      "Epoch: 287 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.812500 | 0.602 sec/iter\n",
      "Epoch: 287 | Batch: 008 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 287 | Batch: 009 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.861500 | 0.602 sec/iter\n",
      "Epoch: 287 | Batch: 010 / 011 | Total loss: 0.316 | Reg loss: 0.017 | Tree loss: 0.316 | Accuracy: 0.901024 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 288 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.818000 | 0.604 sec/iter\n",
      "Epoch: 288 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.814500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.840000 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.825500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.804500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 008 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.856500 | 0.603 sec/iter\n",
      "Epoch: 288 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.853000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 288 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.863481 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 289 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.805500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.803000 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.807500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.830500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.841000 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.826500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 006 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.834500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 007 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.833500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.834500 | 0.604 sec/iter\n",
      "Epoch: 289 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.835500 | 0.603 sec/iter\n",
      "Epoch: 289 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.017 | Tree loss: 0.360 | Accuracy: 0.873720 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 290 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.806500 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.806000 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.823500 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.827500 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.846500 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.822000 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.830000 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.817500 | 0.605 sec/iter\n",
      "Epoch: 290 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.827500 | 0.604 sec/iter\n",
      "Epoch: 290 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.843500 | 0.604 sec/iter\n",
      "Epoch: 290 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.836177 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 291 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.820000 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.826000 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.815500 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.827000 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.838500 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 005 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.833000 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.828500 | 0.606 sec/iter\n",
      "Epoch: 291 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.824500 | 0.605 sec/iter\n",
      "Epoch: 291 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.830500 | 0.605 sec/iter\n",
      "Epoch: 291 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.850000 | 0.605 sec/iter\n",
      "Epoch: 291 | Batch: 010 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.825939 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 292 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.819500 | 0.607 sec/iter\n",
      "Epoch: 292 | Batch: 001 / 011 | Total loss: 0.436 | Reg loss: 0.017 | Tree loss: 0.436 | Accuracy: 0.799500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.813500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.825500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.846500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.860500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 006 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.828000 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.818500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.810500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.837500 | 0.606 sec/iter\n",
      "Epoch: 292 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.017 | Tree loss: 0.358 | Accuracy: 0.856655 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 293 | Batch: 000 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.818500 | 0.607 sec/iter\n",
      "Epoch: 293 | Batch: 001 / 011 | Total loss: 0.451 | Reg loss: 0.017 | Tree loss: 0.451 | Accuracy: 0.798000 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.814500 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.836000 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.829000 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.831500 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.826500 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.828500 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 008 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.811000 | 0.606 sec/iter\n",
      "Epoch: 293 | Batch: 009 / 011 | Total loss: 0.355 | Reg loss: 0.017 | Tree loss: 0.355 | Accuracy: 0.846000 | 0.605 sec/iter\n",
      "Epoch: 293 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.017 | Tree loss: 0.347 | Accuracy: 0.883959 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 294 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.826500 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.830000 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.821500 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.837000 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.832000 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.834000 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.825500 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.822500 | 0.605 sec/iter\n",
      "Epoch: 294 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.822000 | 0.604 sec/iter\n",
      "Epoch: 294 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.835000 | 0.604 sec/iter\n",
      "Epoch: 294 | Batch: 010 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.863481 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 295 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.799000 | 0.605 sec/iter\n",
      "Epoch: 295 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.820500 | 0.605 sec/iter\n",
      "Epoch: 295 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.814500 | 0.605 sec/iter\n",
      "Epoch: 295 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.836000 | 0.605 sec/iter\n",
      "Epoch: 295 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.839000 | 0.604 sec/iter\n",
      "Epoch: 295 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.836000 | 0.604 sec/iter\n",
      "Epoch: 295 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.832000 | 0.604 sec/iter\n",
      "Epoch: 295 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 295 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.830500 | 0.604 sec/iter\n",
      "Epoch: 295 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.839500 | 0.604 sec/iter\n",
      "Epoch: 295 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.017 | Tree loss: 0.347 | Accuracy: 0.866894 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 296 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.805000 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 004 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.820000 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 005 / 011 | Total loss: 0.361 | Reg loss: 0.017 | Tree loss: 0.361 | Accuracy: 0.855500 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 006 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.834000 | 0.604 sec/iter\n",
      "Epoch: 296 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.814000 | 0.603 sec/iter\n",
      "Epoch: 296 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.844000 | 0.603 sec/iter\n",
      "Epoch: 296 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.017 | Tree loss: 0.347 | Accuracy: 0.887372 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 297 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.815500 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.806500 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 003 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.832000 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.843500 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.807500 | 0.603 sec/iter\n",
      "Epoch: 297 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 297 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 297 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.849000 | 0.602 sec/iter\n",
      "Epoch: 297 | Batch: 010 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.829352 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 298 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.801000 | 0.603 sec/iter\n",
      "Epoch: 298 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.823000 | 0.603 sec/iter\n",
      "Epoch: 298 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.839000 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.839500 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.841000 | 0.602 sec/iter\n",
      "Epoch: 298 | Batch: 010 / 011 | Total loss: 0.337 | Reg loss: 0.017 | Tree loss: 0.337 | Accuracy: 0.853242 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 299 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 299 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.811500 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 299 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 299 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.841000 | 0.602 sec/iter\n",
      "Epoch: 299 | Batch: 005 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.855000 | 0.602 sec/iter\n",
      "Epoch: 299 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 299 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 299 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.825000 | 0.602 sec/iter\n",
      "Epoch: 299 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 299 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.825939 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 300 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 300 | Batch: 001 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.800500 | 0.602 sec/iter\n",
      "Epoch: 300 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.833500 | 0.602 sec/iter\n",
      "Epoch: 300 | Batch: 003 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.849000 | 0.602 sec/iter\n",
      "Epoch: 300 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.838500 | 0.602 sec/iter\n",
      "Epoch: 300 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.844000 | 0.601 sec/iter\n",
      "Epoch: 300 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 300 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 300 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 300 | Batch: 009 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815000 | 0.601 sec/iter\n",
      "Epoch: 300 | Batch: 010 / 011 | Total loss: 0.361 | Reg loss: 0.017 | Tree loss: 0.361 | Accuracy: 0.856655 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 301 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.806000 | 0.603 sec/iter\n",
      "Epoch: 301 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 301 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 301 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.825000 | 0.603 sec/iter\n",
      "Epoch: 301 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.825000 | 0.603 sec/iter\n",
      "Epoch: 301 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.838500 | 0.602 sec/iter\n",
      "Epoch: 301 | Batch: 006 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.826000 | 0.602 sec/iter\n",
      "Epoch: 301 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 301 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.819000 | 0.602 sec/iter\n",
      "Epoch: 301 | Batch: 009 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.816500 | 0.602 sec/iter\n",
      "Epoch: 301 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.880546 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 302 | Batch: 000 / 011 | Total loss: 0.438 | Reg loss: 0.017 | Tree loss: 0.438 | Accuracy: 0.794500 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 001 / 011 | Total loss: 0.442 | Reg loss: 0.017 | Tree loss: 0.442 | Accuracy: 0.795500 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.806000 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.826000 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 005 / 011 | Total loss: 0.364 | Reg loss: 0.017 | Tree loss: 0.364 | Accuracy: 0.865000 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.824000 | 0.602 sec/iter\n",
      "Epoch: 302 | Batch: 010 / 011 | Total loss: 0.447 | Reg loss: 0.017 | Tree loss: 0.447 | Accuracy: 0.784983 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 303 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.819500 | 0.603 sec/iter\n",
      "Epoch: 303 | Batch: 001 / 011 | Total loss: 0.450 | Reg loss: 0.017 | Tree loss: 0.450 | Accuracy: 0.794000 | 0.603 sec/iter\n",
      "Epoch: 303 | Batch: 002 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.798500 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.848000 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.837500 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 007 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.810000 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 008 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.805500 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 009 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 303 | Batch: 010 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.839590 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 304 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.800500 | 0.603 sec/iter\n",
      "Epoch: 304 | Batch: 001 / 011 | Total loss: 0.448 | Reg loss: 0.017 | Tree loss: 0.448 | Accuracy: 0.806500 | 0.603 sec/iter\n",
      "Epoch: 304 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.828500 | 0.603 sec/iter\n",
      "Epoch: 304 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.822000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 304 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 304 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.848500 | 0.602 sec/iter\n",
      "Epoch: 304 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.832500 | 0.602 sec/iter\n",
      "Epoch: 304 | Batch: 007 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.798500 | 0.602 sec/iter\n",
      "Epoch: 304 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 304 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 304 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.815700 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 305 | Batch: 000 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.801500 | 0.602 sec/iter\n",
      "Epoch: 305 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 305 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 305 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.850000 | 0.602 sec/iter\n",
      "Epoch: 305 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 305 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.842500 | 0.601 sec/iter\n",
      "Epoch: 305 | Batch: 006 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 305 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 305 | Batch: 008 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 305 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.839000 | 0.601 sec/iter\n",
      "Epoch: 305 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.853242 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 306 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.816500 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 002 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.834000 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 005 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.852500 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 006 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 306 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 306 | Batch: 008 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.838000 | 0.601 sec/iter\n",
      "Epoch: 306 | Batch: 009 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 306 | Batch: 010 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.822526 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 307 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 307 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.812500 | 0.601 sec/iter\n",
      "Epoch: 307 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 307 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.835500 | 0.601 sec/iter\n",
      "Epoch: 307 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.836500 | 0.601 sec/iter\n",
      "Epoch: 307 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.846500 | 0.601 sec/iter\n",
      "Epoch: 307 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 307 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.827500 | 0.6 sec/iter\n",
      "Epoch: 307 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.835500 | 0.6 sec/iter\n",
      "Epoch: 307 | Batch: 009 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 307 | Batch: 010 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.853242 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 308 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.801500 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 003 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.817000 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.838000 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.855500 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.818500 | 0.601 sec/iter\n",
      "Epoch: 308 | Batch: 009 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 308 | Batch: 010 / 011 | Total loss: 0.323 | Reg loss: 0.017 | Tree loss: 0.323 | Accuracy: 0.883959 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 309 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.797000 | 0.602 sec/iter\n",
      "Epoch: 309 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 309 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 309 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 309 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.850500 | 0.602 sec/iter\n",
      "Epoch: 309 | Batch: 005 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.856500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 309 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.817000 | 0.601 sec/iter\n",
      "Epoch: 309 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 309 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 309 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.833000 | 0.601 sec/iter\n",
      "Epoch: 309 | Batch: 010 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.802048 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 310 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.811000 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.807000 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 002 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.824000 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 004 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.859000 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 007 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 009 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.815500 | 0.602 sec/iter\n",
      "Epoch: 310 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.815700 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 311 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.811500 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.807000 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.834000 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.839500 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.849500 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.813000 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 008 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.830500 | 0.603 sec/iter\n",
      "Epoch: 311 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 311 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.017 | Tree loss: 0.347 | Accuracy: 0.853242 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 312 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809500 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.815000 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.808500 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.824000 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.832000 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.844000 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.819000 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 312 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 312 | Batch: 010 / 011 | Total loss: 0.351 | Reg loss: 0.017 | Tree loss: 0.351 | Accuracy: 0.860068 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 313 | Batch: 000 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 313 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.802000 | 0.605 sec/iter\n",
      "Epoch: 313 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.810500 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.825500 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.853500 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.837500 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.819000 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.838500 | 0.604 sec/iter\n",
      "Epoch: 313 | Batch: 010 / 011 | Total loss: 0.313 | Reg loss: 0.017 | Tree loss: 0.313 | Accuracy: 0.911263 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 314 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.821000 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.816000 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.806000 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.828000 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.819500 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.859000 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.830000 | 0.605 sec/iter\n",
      "Epoch: 314 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.808000 | 0.605 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 314 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.835000 | 0.604 sec/iter\n",
      "Epoch: 314 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 314 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.860068 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 315 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.811000 | 0.606 sec/iter\n",
      "Epoch: 315 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.797500 | 0.606 sec/iter\n",
      "Epoch: 315 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.813000 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.819500 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 004 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.832000 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.851000 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 006 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.839000 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 007 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.820500 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.827500 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.853000 | 0.605 sec/iter\n",
      "Epoch: 315 | Batch: 010 / 011 | Total loss: 0.353 | Reg loss: 0.017 | Tree loss: 0.353 | Accuracy: 0.853242 | 0.605 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 316 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.809000 | 0.605 sec/iter\n",
      "Epoch: 316 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.816000 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.845500 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.812000 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.825000 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.831500 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.848500 | 0.604 sec/iter\n",
      "Epoch: 316 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.849829 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 317 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.815000 | 0.604 sec/iter\n",
      "Epoch: 317 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.813000 | 0.604 sec/iter\n",
      "Epoch: 317 | Batch: 002 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.836000 | 0.604 sec/iter\n",
      "Epoch: 317 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.840500 | 0.604 sec/iter\n",
      "Epoch: 317 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.834500 | 0.604 sec/iter\n",
      "Epoch: 317 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 317 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.813500 | 0.603 sec/iter\n",
      "Epoch: 317 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 317 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.815000 | 0.603 sec/iter\n",
      "Epoch: 317 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.840500 | 0.603 sec/iter\n",
      "Epoch: 317 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.832765 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 318 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.017 | Tree loss: 0.439 | Accuracy: 0.799000 | 0.604 sec/iter\n",
      "Epoch: 318 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 318 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.835000 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.838000 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.850500 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.808000 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 008 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 318 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.846416 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 319 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.817500 | 0.603 sec/iter\n",
      "Epoch: 319 | Batch: 001 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.786500 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.835000 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 004 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.805500 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.869500 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 006 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.838000 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.824000 | 0.602 sec/iter\n",
      "Epoch: 319 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.827000 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 319 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.829352 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 320 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 320 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.812500 | 0.602 sec/iter\n",
      "Epoch: 320 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 320 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.836500 | 0.602 sec/iter\n",
      "Epoch: 320 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 320 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.838500 | 0.601 sec/iter\n",
      "Epoch: 320 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.822000 | 0.601 sec/iter\n",
      "Epoch: 320 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 320 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 320 | Batch: 009 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 320 | Batch: 010 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.822526 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 321 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 321 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 321 | Batch: 002 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.807500 | 0.602 sec/iter\n",
      "Epoch: 321 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 321 | Batch: 004 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 321 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.860500 | 0.601 sec/iter\n",
      "Epoch: 321 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 321 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 321 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 321 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 321 | Batch: 010 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.829352 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 322 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.810000 | 0.602 sec/iter\n",
      "Epoch: 322 | Batch: 001 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.805500 | 0.602 sec/iter\n",
      "Epoch: 322 | Batch: 002 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.806500 | 0.602 sec/iter\n",
      "Epoch: 322 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 322 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.855000 | 0.601 sec/iter\n",
      "Epoch: 322 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.844500 | 0.601 sec/iter\n",
      "Epoch: 322 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 322 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 322 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 322 | Batch: 009 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.814000 | 0.601 sec/iter\n",
      "Epoch: 322 | Batch: 010 / 011 | Total loss: 0.362 | Reg loss: 0.017 | Tree loss: 0.362 | Accuracy: 0.863481 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 323 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.816500 | 0.603 sec/iter\n",
      "Epoch: 323 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 002 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.807500 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.840500 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.852000 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 323 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.856655 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 324 | Batch: 000 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 324 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.804000 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.842500 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.834000 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.847000 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.810500 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 008 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.810000 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.814000 | 0.602 sec/iter\n",
      "Epoch: 324 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.843003 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 325 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.808500 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 001 / 011 | Total loss: 0.444 | Reg loss: 0.017 | Tree loss: 0.444 | Accuracy: 0.807500 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.830000 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.851500 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.824000 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 009 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.850000 | 0.602 sec/iter\n",
      "Epoch: 325 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.836177 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 326 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.806500 | 0.603 sec/iter\n",
      "Epoch: 326 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.825000 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.849500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 004 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.855500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 326 | Batch: 010 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.849829 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 327 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.805500 | 0.603 sec/iter\n",
      "Epoch: 327 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 327 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.814000 | 0.603 sec/iter\n",
      "Epoch: 327 | Batch: 003 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.813000 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 004 / 011 | Total loss: 0.365 | Reg loss: 0.017 | Tree loss: 0.365 | Accuracy: 0.840000 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.846000 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.803000 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.843500 | 0.602 sec/iter\n",
      "Epoch: 327 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.017 | Tree loss: 0.358 | Accuracy: 0.856655 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 328 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.801000 | 0.603 sec/iter\n",
      "Epoch: 328 | Batch: 001 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.827500 | 0.603 sec/iter\n",
      "Epoch: 328 | Batch: 002 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 328 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.850000 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.819500 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 009 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 328 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.017 | Tree loss: 0.349 | Accuracy: 0.887372 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 329 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.796000 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 001 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.819000 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 002 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.835000 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.816500 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 004 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.845500 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 329 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 329 | Batch: 009 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.811000 | 0.601 sec/iter\n",
      "Epoch: 329 | Batch: 010 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.863481 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 330 | Batch: 000 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.828500 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330 | Batch: 001 / 011 | Total loss: 0.445 | Reg loss: 0.017 | Tree loss: 0.445 | Accuracy: 0.793500 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.839500 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.813000 | 0.602 sec/iter\n",
      "Epoch: 330 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.863481 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 331 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 331 | Batch: 001 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.801500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.826500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 005 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.858000 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.825000 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.834500 | 0.602 sec/iter\n",
      "Epoch: 331 | Batch: 010 / 011 | Total loss: 0.357 | Reg loss: 0.017 | Tree loss: 0.357 | Accuracy: 0.843003 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 332 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 332 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.814000 | 0.602 sec/iter\n",
      "Epoch: 332 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.820000 | 0.602 sec/iter\n",
      "Epoch: 332 | Batch: 003 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.840000 | 0.602 sec/iter\n",
      "Epoch: 332 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 332 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.839500 | 0.601 sec/iter\n",
      "Epoch: 332 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.813000 | 0.601 sec/iter\n",
      "Epoch: 332 | Batch: 007 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.818500 | 0.601 sec/iter\n",
      "Epoch: 332 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 332 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.847000 | 0.601 sec/iter\n",
      "Epoch: 332 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.877133 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 333 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.803500 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 001 / 011 | Total loss: 0.434 | Reg loss: 0.017 | Tree loss: 0.434 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 002 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.842000 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.856500 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.815500 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.807000 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 333 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.838500 | 0.601 sec/iter\n",
      "Epoch: 333 | Batch: 010 / 011 | Total loss: 0.317 | Reg loss: 0.017 | Tree loss: 0.317 | Accuracy: 0.883959 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 334 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.812000 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.802000 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.820000 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.833500 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 005 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.860500 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.828500 | 0.603 sec/iter\n",
      "Epoch: 334 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 334 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 334 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 334 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.836177 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 335 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.811000 | 0.604 sec/iter\n",
      "Epoch: 335 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.811000 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.800000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 335 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.833000 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.848500 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.871000 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.811500 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 007 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.808500 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.842000 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.835000 | 0.603 sec/iter\n",
      "Epoch: 335 | Batch: 010 / 011 | Total loss: 0.357 | Reg loss: 0.017 | Tree loss: 0.357 | Accuracy: 0.866894 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 336 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.813000 | 0.604 sec/iter\n",
      "Epoch: 336 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.806500 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 002 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.837500 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.826500 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.821000 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.819500 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.832000 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.849500 | 0.603 sec/iter\n",
      "Epoch: 336 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.870307 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 337 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.805000 | 0.603 sec/iter\n",
      "Epoch: 337 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.820000 | 0.603 sec/iter\n",
      "Epoch: 337 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.811000 | 0.603 sec/iter\n",
      "Epoch: 337 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.828500 | 0.603 sec/iter\n",
      "Epoch: 337 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.829000 | 0.602 sec/iter\n",
      "Epoch: 337 | Batch: 005 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.859500 | 0.602 sec/iter\n",
      "Epoch: 337 | Batch: 006 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 337 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.830000 | 0.602 sec/iter\n",
      "Epoch: 337 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 337 | Batch: 009 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 337 | Batch: 010 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.890785 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 338 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.801500 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.826000 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 004 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 005 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.858500 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 007 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.832500 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 009 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 338 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.812287 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 339 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 339 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 339 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.798500 | 0.602 sec/iter\n",
      "Epoch: 339 | Batch: 003 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.848000 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.835000 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.829500 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 009 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 339 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.017 | Tree loss: 0.367 | Accuracy: 0.843003 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 340 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.807000 | 0.601 sec/iter\n",
      "Epoch: 340 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.804500 | 0.601 sec/iter\n",
      "Epoch: 340 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.809000 | 0.601 sec/iter\n",
      "Epoch: 340 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 340 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.840000 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.851000 | 0.6 sec/iter\n",
      "Epoch: 340 | Batch: 006 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 340 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 340 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 340 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 340 | Batch: 010 / 011 | Total loss: 0.324 | Reg loss: 0.017 | Tree loss: 0.324 | Accuracy: 0.887372 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 341 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.807000 | 0.601 sec/iter\n",
      "Epoch: 341 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.865000 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.812500 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 341 | Batch: 010 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.846416 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 342 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 342 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.796500 | 0.601 sec/iter\n",
      "Epoch: 342 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 342 | Batch: 003 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.843000 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.843500 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 342 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.849829 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 343 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.807000 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.838000 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.843000 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 343 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.017 | Tree loss: 0.369 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 343 | Batch: 010 / 011 | Total loss: 0.361 | Reg loss: 0.017 | Tree loss: 0.361 | Accuracy: 0.846416 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 344 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 344 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 344 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.801500 | 0.602 sec/iter\n",
      "Epoch: 344 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 344 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 344 | Batch: 005 / 011 | Total loss: 0.362 | Reg loss: 0.017 | Tree loss: 0.362 | Accuracy: 0.860500 | 0.601 sec/iter\n",
      "Epoch: 344 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 344 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.835000 | 0.601 sec/iter\n",
      "Epoch: 344 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.827500 | 0.601 sec/iter\n",
      "Epoch: 344 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 344 | Batch: 010 / 011 | Total loss: 0.346 | Reg loss: 0.017 | Tree loss: 0.346 | Accuracy: 0.863481 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 345 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 345 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.802500 | 0.603 sec/iter\n",
      "Epoch: 345 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.803500 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.833500 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.845000 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.824500 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 345 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.815500 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 008 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 009 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.840000 | 0.602 sec/iter\n",
      "Epoch: 345 | Batch: 010 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.849829 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 346 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.803500 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.820000 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 002 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.830500 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 003 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.823500 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.847000 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.834500 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833000 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.826000 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 008 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.834000 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.828500 | 0.603 sec/iter\n",
      "Epoch: 346 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.856655 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 347 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.813000 | 0.604 sec/iter\n",
      "Epoch: 347 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.809500 | 0.604 sec/iter\n",
      "Epoch: 347 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.830000 | 0.604 sec/iter\n",
      "Epoch: 347 | Batch: 003 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.833500 | 0.604 sec/iter\n",
      "Epoch: 347 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.837500 | 0.604 sec/iter\n",
      "Epoch: 347 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.844000 | 0.603 sec/iter\n",
      "Epoch: 347 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.828500 | 0.603 sec/iter\n",
      "Epoch: 347 | Batch: 007 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.810000 | 0.603 sec/iter\n",
      "Epoch: 347 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.835500 | 0.603 sec/iter\n",
      "Epoch: 347 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.840500 | 0.603 sec/iter\n",
      "Epoch: 347 | Batch: 010 / 011 | Total loss: 0.343 | Reg loss: 0.017 | Tree loss: 0.343 | Accuracy: 0.863481 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 348 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.809000 | 0.604 sec/iter\n",
      "Epoch: 348 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.810000 | 0.604 sec/iter\n",
      "Epoch: 348 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.805500 | 0.604 sec/iter\n",
      "Epoch: 348 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.805500 | 0.604 sec/iter\n",
      "Epoch: 348 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.838000 | 0.603 sec/iter\n",
      "Epoch: 348 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.850000 | 0.603 sec/iter\n",
      "Epoch: 348 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 348 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 348 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.826000 | 0.603 sec/iter\n",
      "Epoch: 348 | Batch: 009 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.815500 | 0.603 sec/iter\n",
      "Epoch: 348 | Batch: 010 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.822526 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 349 | Batch: 000 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.816000 | 0.604 sec/iter\n",
      "Epoch: 349 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 349 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 349 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.828000 | 0.604 sec/iter\n",
      "Epoch: 349 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.830000 | 0.604 sec/iter\n",
      "Epoch: 349 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.843000 | 0.603 sec/iter\n",
      "Epoch: 349 | Batch: 006 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.834000 | 0.603 sec/iter\n",
      "Epoch: 349 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.824500 | 0.603 sec/iter\n",
      "Epoch: 349 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.823000 | 0.603 sec/iter\n",
      "Epoch: 349 | Batch: 009 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.826500 | 0.603 sec/iter\n",
      "Epoch: 349 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.017 | Tree loss: 0.348 | Accuracy: 0.849829 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 350 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.799500 | 0.604 sec/iter\n",
      "Epoch: 350 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.805500 | 0.604 sec/iter\n",
      "Epoch: 350 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.796000 | 0.604 sec/iter\n",
      "Epoch: 350 | Batch: 003 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 350 | Batch: 004 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.820000 | 0.604 sec/iter\n",
      "Epoch: 350 | Batch: 005 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.852500 | 0.604 sec/iter\n",
      "Epoch: 350 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 350 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.820500 | 0.603 sec/iter\n",
      "Epoch: 350 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.830500 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.835500 | 0.603 sec/iter\n",
      "Epoch: 350 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.017 | Tree loss: 0.359 | Accuracy: 0.870307 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 351 | Batch: 000 / 011 | Total loss: 0.429 | Reg loss: 0.017 | Tree loss: 0.429 | Accuracy: 0.807000 | 0.604 sec/iter\n",
      "Epoch: 351 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 351 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 351 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 351 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.846000 | 0.604 sec/iter\n",
      "Epoch: 351 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.836500 | 0.603 sec/iter\n",
      "Epoch: 351 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 351 | Batch: 007 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.837000 | 0.603 sec/iter\n",
      "Epoch: 351 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.815000 | 0.603 sec/iter\n",
      "Epoch: 351 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.830000 | 0.603 sec/iter\n",
      "Epoch: 351 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.017 | Tree loss: 0.366 | Accuracy: 0.860068 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 352 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.812000 | 0.604 sec/iter\n",
      "Epoch: 352 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.813000 | 0.604 sec/iter\n",
      "Epoch: 352 | Batch: 002 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 352 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 352 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.838000 | 0.604 sec/iter\n",
      "Epoch: 352 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.838500 | 0.603 sec/iter\n",
      "Epoch: 352 | Batch: 006 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.827500 | 0.603 sec/iter\n",
      "Epoch: 352 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.809000 | 0.603 sec/iter\n",
      "Epoch: 352 | Batch: 008 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.816500 | 0.603 sec/iter\n",
      "Epoch: 352 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 352 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.825939 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 353 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.808000 | 0.604 sec/iter\n",
      "Epoch: 353 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 353 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.813500 | 0.604 sec/iter\n",
      "Epoch: 353 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.826000 | 0.604 sec/iter\n",
      "Epoch: 353 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.826000 | 0.603 sec/iter\n",
      "Epoch: 353 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.851500 | 0.603 sec/iter\n",
      "Epoch: 353 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.831500 | 0.603 sec/iter\n",
      "Epoch: 353 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.820500 | 0.603 sec/iter\n",
      "Epoch: 353 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 353 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.826500 | 0.603 sec/iter\n",
      "Epoch: 353 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.829352 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 354 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.820000 | 0.604 sec/iter\n",
      "Epoch: 354 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.815500 | 0.604 sec/iter\n",
      "Epoch: 354 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.811500 | 0.604 sec/iter\n",
      "Epoch: 354 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 004 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.850500 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.831500 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.812500 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.822500 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.836000 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.844000 | 0.603 sec/iter\n",
      "Epoch: 354 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.856655 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 355 | Batch: 000 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 355 | Batch: 001 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.815000 | 0.604 sec/iter\n",
      "Epoch: 355 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.817500 | 0.604 sec/iter\n",
      "Epoch: 355 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 355 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.851500 | 0.604 sec/iter\n",
      "Epoch: 355 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.839500 | 0.603 sec/iter\n",
      "Epoch: 355 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.806000 | 0.603 sec/iter\n",
      "Epoch: 355 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.823500 | 0.603 sec/iter\n",
      "Epoch: 355 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.827000 | 0.603 sec/iter\n",
      "Epoch: 355 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.838000 | 0.603 sec/iter\n",
      "Epoch: 355 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.870307 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 356 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.811500 | 0.603 sec/iter\n",
      "Epoch: 356 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 356 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 356 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.826500 | 0.603 sec/iter\n",
      "Epoch: 356 | Batch: 004 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.839000 | 0.603 sec/iter\n",
      "Epoch: 356 | Batch: 005 / 011 | Total loss: 0.368 | Reg loss: 0.017 | Tree loss: 0.368 | Accuracy: 0.852000 | 0.603 sec/iter\n",
      "Epoch: 356 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 356 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 356 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.835000 | 0.602 sec/iter\n",
      "Epoch: 356 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.840500 | 0.602 sec/iter\n",
      "Epoch: 356 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.863481 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 357 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.807500 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.820000 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.814000 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.842000 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.826000 | 0.602 sec/iter\n",
      "Epoch: 357 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.828000 | 0.601 sec/iter\n",
      "Epoch: 357 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 357 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.842000 | 0.601 sec/iter\n",
      "Epoch: 357 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.018 | Tree loss: 0.348 | Accuracy: 0.880546 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 358 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 358 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.794000 | 0.602 sec/iter\n",
      "Epoch: 358 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 358 | Batch: 003 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.843000 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 005 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.853000 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 007 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.844000 | 0.601 sec/iter\n",
      "Epoch: 358 | Batch: 010 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.836177 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 359 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.809000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.816000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.838000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.844000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 008 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 359 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.845500 | 0.6 sec/iter\n",
      "Epoch: 359 | Batch: 010 / 011 | Total loss: 0.354 | Reg loss: 0.017 | Tree loss: 0.354 | Accuracy: 0.877133 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 360 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 360 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.812500 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.811000 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.839000 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.841500 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 009 / 011 | Total loss: 0.361 | Reg loss: 0.017 | Tree loss: 0.361 | Accuracy: 0.856000 | 0.6 sec/iter\n",
      "Epoch: 360 | Batch: 010 / 011 | Total loss: 0.356 | Reg loss: 0.017 | Tree loss: 0.356 | Accuracy: 0.863481 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 361 | Batch: 000 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.821000 | 0.6 sec/iter\n",
      "Epoch: 361 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 361 | Batch: 002 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.804500 | 0.6 sec/iter\n",
      "Epoch: 361 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 361 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.840500 | 0.599 sec/iter\n",
      "Epoch: 361 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.847000 | 0.599 sec/iter\n",
      "Epoch: 361 | Batch: 006 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.813000 | 0.599 sec/iter\n",
      "Epoch: 361 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 361 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.813000 | 0.599 sec/iter\n",
      "Epoch: 361 | Batch: 009 / 011 | Total loss: 0.342 | Reg loss: 0.017 | Tree loss: 0.342 | Accuracy: 0.869500 | 0.599 sec/iter\n",
      "Epoch: 361 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.863481 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 362 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 362 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.817500 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.825500 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.846000 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.835000 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.853000 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.830000 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.821500 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.826500 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.831000 | 0.599 sec/iter\n",
      "Epoch: 362 | Batch: 010 / 011 | Total loss: 0.334 | Reg loss: 0.018 | Tree loss: 0.334 | Accuracy: 0.866894 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 363 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 363 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 363 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.813500 | 0.6 sec/iter\n",
      "Epoch: 363 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.835500 | 0.6 sec/iter\n",
      "Epoch: 363 | Batch: 004 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 363 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.833500 | 0.599 sec/iter\n",
      "Epoch: 363 | Batch: 006 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.829000 | 0.599 sec/iter\n",
      "Epoch: 363 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.813000 | 0.599 sec/iter\n",
      "Epoch: 363 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.822500 | 0.599 sec/iter\n",
      "Epoch: 363 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.849000 | 0.599 sec/iter\n",
      "Epoch: 363 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.856655 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 364 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 364 | Batch: 001 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.819500 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.843500 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 005 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.847500 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 006 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.800500 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.813500 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.843000 | 0.6 sec/iter\n",
      "Epoch: 364 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.860068 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 365 | Batch: 000 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 004 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.828500 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 005 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.858000 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 365 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.841000 | 0.6 sec/iter\n",
      "Epoch: 365 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.808874 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 366 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.825000 | 0.602 sec/iter\n",
      "Epoch: 366 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.806500 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 366 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 366 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 366 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.841000 | 0.602 sec/iter\n",
      "Epoch: 366 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 366 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 366 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.829500 | 0.601 sec/iter\n",
      "Epoch: 366 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 366 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.845000 | 0.601 sec/iter\n",
      "Epoch: 366 | Batch: 010 / 011 | Total loss: 0.438 | Reg loss: 0.018 | Tree loss: 0.438 | Accuracy: 0.829352 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 367 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.803500 | 0.603 sec/iter\n",
      "Epoch: 367 | Batch: 001 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.806500 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.847000 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.841000 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.813000 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.838000 | 0.602 sec/iter\n",
      "Epoch: 367 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.018 | Tree loss: 0.349 | Accuracy: 0.880546 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 368 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.803000 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 001 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.821500 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.801000 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.843500 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.833500 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 006 / 011 | Total loss: 0.362 | Reg loss: 0.017 | Tree loss: 0.362 | Accuracy: 0.846000 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.814000 | 0.603 sec/iter\n",
      "Epoch: 368 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.017 | Tree loss: 0.400 | Accuracy: 0.809500 | 0.602 sec/iter\n",
      "Epoch: 368 | Batch: 009 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 368 | Batch: 010 / 011 | Total loss: 0.350 | Reg loss: 0.018 | Tree loss: 0.350 | Accuracy: 0.870307 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 369 | Batch: 000 / 011 | Total loss: 0.440 | Reg loss: 0.017 | Tree loss: 0.440 | Accuracy: 0.792500 | 0.604 sec/iter\n",
      "Epoch: 369 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.814500 | 0.604 sec/iter\n",
      "Epoch: 369 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.819500 | 0.604 sec/iter\n",
      "Epoch: 369 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.839500 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.835500 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.850500 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.825500 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.824000 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.829500 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 009 / 011 | Total loss: 0.363 | Reg loss: 0.017 | Tree loss: 0.363 | Accuracy: 0.832000 | 0.603 sec/iter\n",
      "Epoch: 369 | Batch: 010 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.843003 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 370 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.017 | Tree loss: 0.428 | Accuracy: 0.802500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.808500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 002 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.832500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 003 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.826500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.837000 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.846500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 006 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.837000 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.825500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 008 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.818000 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.849500 | 0.604 sec/iter\n",
      "Epoch: 370 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.832765 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 371 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.805500 | 0.605 sec/iter\n",
      "Epoch: 371 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.822500 | 0.605 sec/iter\n",
      "Epoch: 371 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.827000 | 0.605 sec/iter\n",
      "Epoch: 371 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.821000 | 0.604 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 371 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.841000 | 0.604 sec/iter\n",
      "Epoch: 371 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.848000 | 0.604 sec/iter\n",
      "Epoch: 371 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.825000 | 0.604 sec/iter\n",
      "Epoch: 371 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.823000 | 0.604 sec/iter\n",
      "Epoch: 371 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.834000 | 0.604 sec/iter\n",
      "Epoch: 371 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.833000 | 0.604 sec/iter\n",
      "Epoch: 371 | Batch: 010 / 011 | Total loss: 0.339 | Reg loss: 0.018 | Tree loss: 0.339 | Accuracy: 0.880546 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 372 | Batch: 000 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.812500 | 0.605 sec/iter\n",
      "Epoch: 372 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.804500 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.808000 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 003 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.843000 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.836500 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 006 / 011 | Total loss: 0.375 | Reg loss: 0.017 | Tree loss: 0.375 | Accuracy: 0.831000 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 008 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.802500 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.836000 | 0.604 sec/iter\n",
      "Epoch: 372 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.846416 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 373 | Batch: 000 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.826000 | 0.605 sec/iter\n",
      "Epoch: 373 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.819500 | 0.605 sec/iter\n",
      "Epoch: 373 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.805500 | 0.605 sec/iter\n",
      "Epoch: 373 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.836000 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.841500 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.845500 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.817500 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.826500 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.835500 | 0.604 sec/iter\n",
      "Epoch: 373 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.846416 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 374 | Batch: 000 / 011 | Total loss: 0.437 | Reg loss: 0.017 | Tree loss: 0.437 | Accuracy: 0.794000 | 0.605 sec/iter\n",
      "Epoch: 374 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.828500 | 0.605 sec/iter\n",
      "Epoch: 374 | Batch: 002 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.818500 | 0.605 sec/iter\n",
      "Epoch: 374 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.833000 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.840000 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.846000 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.826500 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.823500 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.831500 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.835000 | 0.604 sec/iter\n",
      "Epoch: 374 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.018 | Tree loss: 0.348 | Accuracy: 0.853242 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 375 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.808500 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.821500 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.822500 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.828500 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.849500 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.815000 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.827000 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.817000 | 0.604 sec/iter\n",
      "Epoch: 375 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.833500 | 0.603 sec/iter\n",
      "Epoch: 375 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.832765 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 376 | Batch: 000 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.824500 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.810000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.824000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.804000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.833000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.853000 | 0.604 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 376 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.820000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.814000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 008 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.838000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.841000 | 0.604 sec/iter\n",
      "Epoch: 376 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.853242 | 0.604 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 377 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.810000 | 0.604 sec/iter\n",
      "Epoch: 377 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.802000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.822000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.838000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.849000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.843000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.832500 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.805000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.837000 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.842500 | 0.603 sec/iter\n",
      "Epoch: 377 | Batch: 010 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.846416 | 0.603 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 378 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.820000 | 0.603 sec/iter\n",
      "Epoch: 378 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.817000 | 0.603 sec/iter\n",
      "Epoch: 378 | Batch: 002 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.835000 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 005 / 011 | Total loss: 0.401 | Reg loss: 0.017 | Tree loss: 0.401 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.819000 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.819500 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.820000 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.848000 | 0.602 sec/iter\n",
      "Epoch: 378 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.873720 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 379 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.815500 | 0.602 sec/iter\n",
      "Epoch: 379 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.804000 | 0.602 sec/iter\n",
      "Epoch: 379 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 379 | Batch: 003 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 379 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.845000 | 0.602 sec/iter\n",
      "Epoch: 379 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 379 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 379 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 379 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.833000 | 0.601 sec/iter\n",
      "Epoch: 379 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 379 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.825939 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 380 | Batch: 000 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 002 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.805000 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.837000 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.838500 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.827500 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.833000 | 0.601 sec/iter\n",
      "Epoch: 380 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.840500 | 0.6 sec/iter\n",
      "Epoch: 380 | Batch: 010 / 011 | Total loss: 0.339 | Reg loss: 0.018 | Tree loss: 0.339 | Accuracy: 0.904437 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 381 | Batch: 000 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 381 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.804000 | 0.601 sec/iter\n",
      "Epoch: 381 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 381 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.834500 | 0.601 sec/iter\n",
      "Epoch: 381 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.846000 | 0.601 sec/iter\n",
      "Epoch: 381 | Batch: 005 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 381 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.812500 | 0.6 sec/iter\n",
      "Epoch: 381 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.831000 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 381 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 381 | Batch: 009 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.857000 | 0.6 sec/iter\n",
      "Epoch: 381 | Batch: 010 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.815700 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 382 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.814500 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.807000 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.796000 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.846500 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 009 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.853000 | 0.6 sec/iter\n",
      "Epoch: 382 | Batch: 010 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.870307 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 383 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 383 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 002 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.832500 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.842500 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 004 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.846500 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.819500 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.822000 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.833500 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.853000 | 0.599 sec/iter\n",
      "Epoch: 383 | Batch: 010 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.883959 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 384 | Batch: 000 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 001 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.846000 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.821000 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 384 | Batch: 010 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.802048 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 385 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 385 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.818500 | 0.6 sec/iter\n",
      "Epoch: 385 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 385 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 385 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.830500 | 0.599 sec/iter\n",
      "Epoch: 385 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.852000 | 0.599 sec/iter\n",
      "Epoch: 385 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.830500 | 0.599 sec/iter\n",
      "Epoch: 385 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.834500 | 0.599 sec/iter\n",
      "Epoch: 385 | Batch: 008 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.812000 | 0.599 sec/iter\n",
      "Epoch: 385 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.833500 | 0.599 sec/iter\n",
      "Epoch: 385 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.018 | Tree loss: 0.360 | Accuracy: 0.856655 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 386 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.811000 | 0.601 sec/iter\n",
      "Epoch: 386 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.814000 | 0.601 sec/iter\n",
      "Epoch: 386 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.808000 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.840500 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.836000 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.847500 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 008 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.802500 | 0.6 sec/iter\n",
      "Epoch: 386 | Batch: 009 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.860500 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 386 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.866894 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 387 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 387 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 387 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.818500 | 0.6 sec/iter\n",
      "Epoch: 387 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.017 | Tree loss: 0.394 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 387 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 387 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.017 | Tree loss: 0.385 | Accuracy: 0.843500 | 0.599 sec/iter\n",
      "Epoch: 387 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.823500 | 0.599 sec/iter\n",
      "Epoch: 387 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.814000 | 0.599 sec/iter\n",
      "Epoch: 387 | Batch: 008 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.830000 | 0.599 sec/iter\n",
      "Epoch: 387 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.847000 | 0.599 sec/iter\n",
      "Epoch: 387 | Batch: 010 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.843003 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 388 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 388 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.812500 | 0.601 sec/iter\n",
      "Epoch: 388 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.808500 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 005 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.836000 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 006 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.836000 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 009 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.839000 | 0.6 sec/iter\n",
      "Epoch: 388 | Batch: 010 / 011 | Total loss: 0.337 | Reg loss: 0.018 | Tree loss: 0.337 | Accuracy: 0.870307 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 389 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.809500 | 0.6 sec/iter\n",
      "Epoch: 389 | Batch: 001 / 011 | Total loss: 0.433 | Reg loss: 0.017 | Tree loss: 0.433 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 389 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.814500 | 0.6 sec/iter\n",
      "Epoch: 389 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 389 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.017 | Tree loss: 0.388 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 389 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.843000 | 0.599 sec/iter\n",
      "Epoch: 389 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.823500 | 0.599 sec/iter\n",
      "Epoch: 389 | Batch: 007 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.833500 | 0.599 sec/iter\n",
      "Epoch: 389 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.824500 | 0.599 sec/iter\n",
      "Epoch: 389 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.843000 | 0.599 sec/iter\n",
      "Epoch: 389 | Batch: 010 / 011 | Total loss: 0.348 | Reg loss: 0.018 | Tree loss: 0.348 | Accuracy: 0.860068 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 390 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 390 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.817000 | 0.601 sec/iter\n",
      "Epoch: 390 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.017 | Tree loss: 0.404 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.017 | Tree loss: 0.390 | Accuracy: 0.840000 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 007 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 390 | Batch: 010 / 011 | Total loss: 0.350 | Reg loss: 0.018 | Tree loss: 0.350 | Accuracy: 0.866894 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 391 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 391 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 391 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.017 | Tree loss: 0.415 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 391 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.840500 | 0.6 sec/iter\n",
      "Epoch: 391 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.833500 | 0.6 sec/iter\n",
      "Epoch: 391 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.851500 | 0.599 sec/iter\n",
      "Epoch: 391 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 391 | Batch: 007 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.835500 | 0.599 sec/iter\n",
      "Epoch: 391 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.831500 | 0.599 sec/iter\n",
      "Epoch: 391 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.829000 | 0.599 sec/iter\n",
      "Epoch: 391 | Batch: 010 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.856655 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 392 | Batch: 000 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 392 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 392 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.804500 | 0.601 sec/iter\n",
      "Epoch: 392 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 005 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.853000 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 392 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.846416 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 393 | Batch: 000 / 011 | Total loss: 0.441 | Reg loss: 0.017 | Tree loss: 0.441 | Accuracy: 0.794000 | 0.6 sec/iter\n",
      "Epoch: 393 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.810000 | 0.6 sec/iter\n",
      "Epoch: 393 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.812500 | 0.6 sec/iter\n",
      "Epoch: 393 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.854000 | 0.6 sec/iter\n",
      "Epoch: 393 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.842500 | 0.6 sec/iter\n",
      "Epoch: 393 | Batch: 005 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.852000 | 0.599 sec/iter\n",
      "Epoch: 393 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.816500 | 0.599 sec/iter\n",
      "Epoch: 393 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.820500 | 0.599 sec/iter\n",
      "Epoch: 393 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 393 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.820500 | 0.599 sec/iter\n",
      "Epoch: 393 | Batch: 010 / 011 | Total loss: 0.363 | Reg loss: 0.018 | Tree loss: 0.363 | Accuracy: 0.849829 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 394 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.805000 | 0.601 sec/iter\n",
      "Epoch: 394 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 394 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.810000 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.848000 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 007 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.818500 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.839500 | 0.6 sec/iter\n",
      "Epoch: 394 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.018 | Tree loss: 0.358 | Accuracy: 0.873720 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 395 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.017 | Tree loss: 0.421 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.810000 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 002 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.819500 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 003 / 011 | Total loss: 0.383 | Reg loss: 0.017 | Tree loss: 0.383 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.858000 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 395 | Batch: 010 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.866894 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 396 | Batch: 000 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 396 | Batch: 001 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 396 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.816000 | 0.601 sec/iter\n",
      "Epoch: 396 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.828000 | 0.601 sec/iter\n",
      "Epoch: 396 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 396 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.853000 | 0.6 sec/iter\n",
      "Epoch: 396 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.823500 | 0.6 sec/iter\n",
      "Epoch: 396 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 396 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 396 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.816000 | 0.6 sec/iter\n",
      "Epoch: 396 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.846416 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 397 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.807500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 397 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 003 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.845500 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.017 | Tree loss: 0.376 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.837500 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 397 | Batch: 008 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 397 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 397 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.877133 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 398 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.017 | Tree loss: 0.431 | Accuracy: 0.811500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 002 / 011 | Total loss: 0.413 | Reg loss: 0.017 | Tree loss: 0.413 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.017 | Tree loss: 0.403 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.854000 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 398 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.836177 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 399 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 399 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 399 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 399 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.017 | Tree loss: 0.410 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.848000 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 005 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 007 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.839000 | 0.6 sec/iter\n",
      "Epoch: 399 | Batch: 010 / 011 | Total loss: 0.346 | Reg loss: 0.018 | Tree loss: 0.346 | Accuracy: 0.873720 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 400 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.818500 | 0.601 sec/iter\n",
      "Epoch: 400 | Batch: 001 / 011 | Total loss: 0.398 | Reg loss: 0.017 | Tree loss: 0.398 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 400 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.802500 | 0.601 sec/iter\n",
      "Epoch: 400 | Batch: 003 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.017 | Tree loss: 0.386 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 005 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.853000 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 006 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.840500 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.811500 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 400 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.832765 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 401 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.815000 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.017 | Tree loss: 0.411 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 002 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.017 | Tree loss: 0.402 | Accuracy: 0.833500 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 005 / 011 | Total loss: 0.372 | Reg loss: 0.017 | Tree loss: 0.372 | Accuracy: 0.847500 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 401 | Batch: 010 / 011 | Total loss: 0.334 | Reg loss: 0.018 | Tree loss: 0.334 | Accuracy: 0.873720 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 402 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 402 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 002 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.834000 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.822500 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 402 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.838500 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.846500 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.814000 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.841000 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.842500 | 0.599 sec/iter\n",
      "Epoch: 402 | Batch: 010 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.836177 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 403 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.815000 | 0.599 sec/iter\n",
      "Epoch: 403 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.017 | Tree loss: 0.430 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 403 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.809000 | 0.599 sec/iter\n",
      "Epoch: 403 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.826500 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.823500 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.845500 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.809500 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.824000 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 008 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.829500 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 009 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.807000 | 0.598 sec/iter\n",
      "Epoch: 403 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.832765 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 404 | Batch: 000 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.830500 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.815000 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.804500 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.837500 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.017 | Tree loss: 0.389 | Accuracy: 0.830500 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.017 | Tree loss: 0.374 | Accuracy: 0.853000 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 006 / 011 | Total loss: 0.373 | Reg loss: 0.017 | Tree loss: 0.373 | Accuracy: 0.833500 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 007 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.795000 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.820500 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.830000 | 0.598 sec/iter\n",
      "Epoch: 404 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.822526 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 405 | Batch: 000 / 011 | Total loss: 0.435 | Reg loss: 0.017 | Tree loss: 0.435 | Accuracy: 0.807000 | 0.598 sec/iter\n",
      "Epoch: 405 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.818500 | 0.598 sec/iter\n",
      "Epoch: 405 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.820000 | 0.598 sec/iter\n",
      "Epoch: 405 | Batch: 003 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.817500 | 0.598 sec/iter\n",
      "Epoch: 405 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.017 | Tree loss: 0.381 | Accuracy: 0.831000 | 0.598 sec/iter\n",
      "Epoch: 405 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.017 | Tree loss: 0.371 | Accuracy: 0.850500 | 0.598 sec/iter\n",
      "Epoch: 405 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.017 | Tree loss: 0.382 | Accuracy: 0.824000 | 0.597 sec/iter\n",
      "Epoch: 405 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.830500 | 0.597 sec/iter\n",
      "Epoch: 405 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.819000 | 0.597 sec/iter\n",
      "Epoch: 405 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.833000 | 0.597 sec/iter\n",
      "Epoch: 405 | Batch: 010 / 011 | Total loss: 0.330 | Reg loss: 0.018 | Tree loss: 0.330 | Accuracy: 0.877133 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 406 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.017 | Tree loss: 0.426 | Accuracy: 0.811500 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.815000 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 002 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.834000 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.836000 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.017 | Tree loss: 0.370 | Accuracy: 0.841000 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.017 | Tree loss: 0.391 | Accuracy: 0.842500 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.825500 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.819500 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 008 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.811500 | 0.597 sec/iter\n",
      "Epoch: 406 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.855000 | 0.596 sec/iter\n",
      "Epoch: 406 | Batch: 010 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.836177 | 0.596 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 407 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.818500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 001 / 011 | Total loss: 0.399 | Reg loss: 0.017 | Tree loss: 0.399 | Accuracy: 0.826500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.806000 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.017 | Tree loss: 0.407 | Accuracy: 0.802500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.017 | Tree loss: 0.377 | Accuracy: 0.847000 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.843500 | 0.597 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 407 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.828500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 007 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.809500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 008 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.833500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.829500 | 0.597 sec/iter\n",
      "Epoch: 407 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.018 | Tree loss: 0.347 | Accuracy: 0.843003 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 408 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.017 | Tree loss: 0.406 | Accuracy: 0.829000 | 0.598 sec/iter\n",
      "Epoch: 408 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.825500 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 002 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.829500 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.827000 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.017 | Tree loss: 0.395 | Accuracy: 0.829000 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.841000 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.829500 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.830500 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.831500 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.827500 | 0.597 sec/iter\n",
      "Epoch: 408 | Batch: 010 / 011 | Total loss: 0.356 | Reg loss: 0.018 | Tree loss: 0.356 | Accuracy: 0.863481 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 409 | Batch: 000 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.824000 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.017 | Tree loss: 0.424 | Accuracy: 0.809500 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.017 | Tree loss: 0.419 | Accuracy: 0.807000 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.017 | Tree loss: 0.396 | Accuracy: 0.835500 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.017 | Tree loss: 0.380 | Accuracy: 0.842500 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.835500 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.819500 | 0.598 sec/iter\n",
      "Epoch: 409 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.822500 | 0.597 sec/iter\n",
      "Epoch: 409 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.820500 | 0.597 sec/iter\n",
      "Epoch: 409 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.836000 | 0.597 sec/iter\n",
      "Epoch: 409 | Batch: 010 / 011 | Total loss: 0.353 | Reg loss: 0.018 | Tree loss: 0.353 | Accuracy: 0.877133 | 0.597 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 410 | Batch: 000 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.827500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.821500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.822500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.827000 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.017 | Tree loss: 0.378 | Accuracy: 0.833000 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 005 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.862500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.802500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 007 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.842500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.832500 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.818000 | 0.598 sec/iter\n",
      "Epoch: 410 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.853242 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 411 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.802500 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.017 | Tree loss: 0.414 | Accuracy: 0.811500 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 002 / 011 | Total loss: 0.393 | Reg loss: 0.017 | Tree loss: 0.393 | Accuracy: 0.833000 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.017 | Tree loss: 0.384 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.017 | Tree loss: 0.379 | Accuracy: 0.831000 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.854000 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 006 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.831500 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.815500 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 008 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.835500 | 0.599 sec/iter\n",
      "Epoch: 411 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.845000 | 0.598 sec/iter\n",
      "Epoch: 411 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.866894 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 412 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 412 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.808500 | 0.6 sec/iter\n",
      "Epoch: 412 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.017 | Tree loss: 0.408 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 412 | Batch: 003 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.846500 | 0.599 sec/iter\n",
      "Epoch: 412 | Batch: 004 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.858500 | 0.599 sec/iter\n",
      "Epoch: 412 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 412 | Batch: 006 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.823500 | 0.599 sec/iter\n",
      "Epoch: 412 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.827500 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 412 | Batch: 008 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.806000 | 0.599 sec/iter\n",
      "Epoch: 412 | Batch: 009 / 011 | Total loss: 0.360 | Reg loss: 0.018 | Tree loss: 0.360 | Accuracy: 0.858500 | 0.599 sec/iter\n",
      "Epoch: 412 | Batch: 010 / 011 | Total loss: 0.442 | Reg loss: 0.018 | Tree loss: 0.442 | Accuracy: 0.798635 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 413 | Batch: 000 / 011 | Total loss: 0.453 | Reg loss: 0.017 | Tree loss: 0.453 | Accuracy: 0.785000 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 001 / 011 | Total loss: 0.405 | Reg loss: 0.017 | Tree loss: 0.405 | Accuracy: 0.819500 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 002 / 011 | Total loss: 0.387 | Reg loss: 0.017 | Tree loss: 0.387 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.017 | Tree loss: 0.392 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.841500 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 006 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.838500 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 413 | Batch: 009 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.856500 | 0.599 sec/iter\n",
      "Epoch: 413 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.863481 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 414 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.017 | Tree loss: 0.418 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 414 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.017 | Tree loss: 0.416 | Accuracy: 0.812000 | 0.601 sec/iter\n",
      "Epoch: 414 | Batch: 002 / 011 | Total loss: 0.397 | Reg loss: 0.017 | Tree loss: 0.397 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 414 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.857000 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 005 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.852500 | 0.6 sec/iter\n",
      "Epoch: 414 | Batch: 010 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.860068 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 415 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.017 | Tree loss: 0.425 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.017 | Tree loss: 0.420 | Accuracy: 0.815000 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.017 | Tree loss: 0.423 | Accuracy: 0.811000 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 004 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 005 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.855000 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 007 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 008 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.836000 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.839500 | 0.601 sec/iter\n",
      "Epoch: 415 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.846416 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 416 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.017 | Tree loss: 0.432 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 416 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 416 | Batch: 002 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.833500 | 0.602 sec/iter\n",
      "Epoch: 416 | Batch: 003 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.841000 | 0.602 sec/iter\n",
      "Epoch: 416 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.848000 | 0.602 sec/iter\n",
      "Epoch: 416 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.846500 | 0.601 sec/iter\n",
      "Epoch: 416 | Batch: 006 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 416 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 416 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.814000 | 0.601 sec/iter\n",
      "Epoch: 416 | Batch: 009 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.828500 | 0.601 sec/iter\n",
      "Epoch: 416 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.018 | Tree loss: 0.358 | Accuracy: 0.877133 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 417 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.017 | Tree loss: 0.427 | Accuracy: 0.798500 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.818500 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.831000 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 005 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.857500 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.820000 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.834000 | 0.602 sec/iter\n",
      "Epoch: 417 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.835000 | 0.602 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 417 | Batch: 010 / 011 | Total loss: 0.358 | Reg loss: 0.018 | Tree loss: 0.358 | Accuracy: 0.860068 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 418 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.017 | Tree loss: 0.422 | Accuracy: 0.812000 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.017 | Tree loss: 0.409 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 004 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.848500 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.856500 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.819500 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.814000 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 008 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.846500 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 418 | Batch: 010 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.832765 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 419 | Batch: 000 / 011 | Total loss: 0.433 | Reg loss: 0.018 | Tree loss: 0.433 | Accuracy: 0.807000 | 0.603 sec/iter\n",
      "Epoch: 419 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.018 | Tree loss: 0.431 | Accuracy: 0.812500 | 0.603 sec/iter\n",
      "Epoch: 419 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.816000 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.840500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.843500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.844500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 006 / 011 | Total loss: 0.360 | Reg loss: 0.018 | Tree loss: 0.360 | Accuracy: 0.845500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.846500 | 0.602 sec/iter\n",
      "Epoch: 419 | Batch: 010 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.846416 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 420 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.017 | Tree loss: 0.417 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 420 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 420 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.810500 | 0.602 sec/iter\n",
      "Epoch: 420 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.827500 | 0.602 sec/iter\n",
      "Epoch: 420 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.845000 | 0.602 sec/iter\n",
      "Epoch: 420 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.839000 | 0.601 sec/iter\n",
      "Epoch: 420 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 420 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 420 | Batch: 008 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.838500 | 0.601 sec/iter\n",
      "Epoch: 420 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.834500 | 0.601 sec/iter\n",
      "Epoch: 420 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.843003 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 421 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.821500 | 0.602 sec/iter\n",
      "Epoch: 421 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.818500 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.835000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.844000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.834500 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.822000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 007 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.838000 | 0.601 sec/iter\n",
      "Epoch: 421 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.839590 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 422 | Batch: 000 / 011 | Total loss: 0.430 | Reg loss: 0.018 | Tree loss: 0.430 | Accuracy: 0.811000 | 0.601 sec/iter\n",
      "Epoch: 422 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.018 | Tree loss: 0.429 | Accuracy: 0.803000 | 0.601 sec/iter\n",
      "Epoch: 422 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 422 | Batch: 003 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.845500 | 0.601 sec/iter\n",
      "Epoch: 422 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.828000 | 0.601 sec/iter\n",
      "Epoch: 422 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.840000 | 0.601 sec/iter\n",
      "Epoch: 422 | Batch: 006 / 011 | Total loss: 0.354 | Reg loss: 0.018 | Tree loss: 0.354 | Accuracy: 0.860500 | 0.6 sec/iter\n",
      "Epoch: 422 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 422 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 422 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 422 | Batch: 010 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.825939 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 423 | Batch: 000 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.845500 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 004 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.834500 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.848500 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 006 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.808000 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.805000 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 008 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.844500 | 0.6 sec/iter\n",
      "Epoch: 423 | Batch: 010 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.836177 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 424 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.819500 | 0.6 sec/iter\n",
      "Epoch: 424 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 424 | Batch: 002 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 424 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 424 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 424 | Batch: 005 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.849500 | 0.599 sec/iter\n",
      "Epoch: 424 | Batch: 006 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.836500 | 0.599 sec/iter\n",
      "Epoch: 424 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.813500 | 0.599 sec/iter\n",
      "Epoch: 424 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 424 | Batch: 009 / 011 | Total loss: 0.360 | Reg loss: 0.018 | Tree loss: 0.360 | Accuracy: 0.857500 | 0.599 sec/iter\n",
      "Epoch: 424 | Batch: 010 / 011 | Total loss: 0.344 | Reg loss: 0.018 | Tree loss: 0.344 | Accuracy: 0.849829 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 425 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.803500 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 001 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.815000 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.822500 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 003 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.832000 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 004 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.840500 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 005 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.856000 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 006 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.824500 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.813500 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.824500 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.847000 | 0.599 sec/iter\n",
      "Epoch: 425 | Batch: 010 / 011 | Total loss: 0.353 | Reg loss: 0.018 | Tree loss: 0.353 | Accuracy: 0.883959 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 426 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.813000 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.817500 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 003 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.827500 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.847500 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 005 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.851500 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.820500 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.818500 | 0.599 sec/iter\n",
      "Epoch: 426 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.822000 | 0.598 sec/iter\n",
      "Epoch: 426 | Batch: 010 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.843003 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 427 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.018 | Tree loss: 0.425 | Accuracy: 0.806000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 001 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.823500 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.810000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 003 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.831500 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.825000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 005 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.854000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 006 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.848000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.819000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 008 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.824000 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.828500 | 0.599 sec/iter\n",
      "Epoch: 427 | Batch: 010 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.815700 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 428 | Batch: 000 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.811000 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.821000 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.018 | Tree loss: 0.430 | Accuracy: 0.800000 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.845000 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 005 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.864000 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 006 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.839500 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 007 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.812000 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 008 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.831500 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.830500 | 0.599 sec/iter\n",
      "Epoch: 428 | Batch: 010 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.846416 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 429 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.017 | Tree loss: 0.412 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 001 / 011 | Total loss: 0.447 | Reg loss: 0.018 | Tree loss: 0.447 | Accuracy: 0.805000 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 002 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.807000 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 003 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.852500 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.845000 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 005 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.854500 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.817500 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.825000 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.838500 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.826500 | 0.599 sec/iter\n",
      "Epoch: 429 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.849829 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 430 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.816000 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.812500 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.816500 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.841000 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.831000 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 005 / 011 | Total loss: 0.365 | Reg loss: 0.018 | Tree loss: 0.365 | Accuracy: 0.862000 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.828500 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.810000 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 008 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.826500 | 0.599 sec/iter\n",
      "Epoch: 430 | Batch: 010 / 011 | Total loss: 0.355 | Reg loss: 0.018 | Tree loss: 0.355 | Accuracy: 0.853242 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 431 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.821500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.018 | Tree loss: 0.425 | Accuracy: 0.813500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.796500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 003 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.852500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.840500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 006 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.836500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 007 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.812500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.826500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 009 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.850500 | 0.599 sec/iter\n",
      "Epoch: 431 | Batch: 010 / 011 | Total loss: 0.345 | Reg loss: 0.018 | Tree loss: 0.345 | Accuracy: 0.866894 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 432 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.806500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.825500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.804500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 003 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 004 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.846500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 006 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.819500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.829500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.839500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.833500 | 0.599 sec/iter\n",
      "Epoch: 432 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.863481 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 433 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.826000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.018 | Tree loss: 0.425 | Accuracy: 0.807500 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.818500 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 003 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.840500 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 433 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.829000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 005 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.868000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.822000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.831000 | 0.599 sec/iter\n",
      "Epoch: 433 | Batch: 010 / 011 | Total loss: 0.346 | Reg loss: 0.018 | Tree loss: 0.346 | Accuracy: 0.860068 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 434 | Batch: 000 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 001 / 011 | Total loss: 0.438 | Reg loss: 0.018 | Tree loss: 0.438 | Accuracy: 0.801000 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 002 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 003 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 004 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.845500 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.843500 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 006 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 007 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 434 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 434 | Batch: 009 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.829000 | 0.599 sec/iter\n",
      "Epoch: 434 | Batch: 010 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.883959 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 435 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.818500 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.854000 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 008 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 435 | Batch: 010 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.849829 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 436 | Batch: 000 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.807500 | 0.601 sec/iter\n",
      "Epoch: 436 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.018 | Tree loss: 0.429 | Accuracy: 0.807500 | 0.601 sec/iter\n",
      "Epoch: 436 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.817000 | 0.601 sec/iter\n",
      "Epoch: 436 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 436 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 436 | Batch: 005 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.861000 | 0.6 sec/iter\n",
      "Epoch: 436 | Batch: 006 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.818000 | 0.6 sec/iter\n",
      "Epoch: 436 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 436 | Batch: 008 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 436 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 436 | Batch: 010 / 011 | Total loss: 0.429 | Reg loss: 0.018 | Tree loss: 0.429 | Accuracy: 0.812287 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 437 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 437 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.806500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.832500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.849500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.841000 | 0.601 sec/iter\n",
      "Epoch: 437 | Batch: 010 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.866894 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 438 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.803500 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 002 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.844000 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.842500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 438 | Batch: 006 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.822000 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.837000 | 0.601 sec/iter\n",
      "Epoch: 438 | Batch: 010 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.836177 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 439 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.808500 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 003 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.840000 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 004 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.858000 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 005 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 006 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 007 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.806000 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 008 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.807000 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 009 / 011 | Total loss: 0.359 | Reg loss: 0.018 | Tree loss: 0.359 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 439 | Batch: 010 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.873720 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 440 | Batch: 000 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.816000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.812000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.837000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 005 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.853000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 006 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.801500 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 007 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.847000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 440 | Batch: 010 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.815700 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 441 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 441 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.809000 | 0.601 sec/iter\n",
      "Epoch: 441 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.807500 | 0.601 sec/iter\n",
      "Epoch: 441 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.829500 | 0.601 sec/iter\n",
      "Epoch: 441 | Batch: 004 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.847000 | 0.601 sec/iter\n",
      "Epoch: 441 | Batch: 005 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.851000 | 0.601 sec/iter\n",
      "Epoch: 441 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 441 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.818000 | 0.6 sec/iter\n",
      "Epoch: 441 | Batch: 008 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 441 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.845000 | 0.6 sec/iter\n",
      "Epoch: 441 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.856655 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 442 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.802500 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 002 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 007 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.807000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 008 / 011 | Total loss: 0.363 | Reg loss: 0.018 | Tree loss: 0.363 | Accuracy: 0.833500 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 442 | Batch: 010 / 011 | Total loss: 0.360 | Reg loss: 0.018 | Tree loss: 0.360 | Accuracy: 0.887372 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 443 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 443 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.810000 | 0.6 sec/iter\n",
      "Epoch: 443 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 443 | Batch: 003 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 443 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.844000 | 0.6 sec/iter\n",
      "Epoch: 443 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.839500 | 0.599 sec/iter\n",
      "Epoch: 443 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.835000 | 0.599 sec/iter\n",
      "Epoch: 443 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.816000 | 0.599 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 443 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 443 | Batch: 009 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.851000 | 0.599 sec/iter\n",
      "Epoch: 443 | Batch: 010 / 011 | Total loss: 0.342 | Reg loss: 0.018 | Tree loss: 0.342 | Accuracy: 0.890785 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 444 | Batch: 000 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 001 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.811000 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.807000 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.844000 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.823500 | 0.6 sec/iter\n",
      "Epoch: 444 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.812000 | 0.599 sec/iter\n",
      "Epoch: 444 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 444 | Batch: 009 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.837000 | 0.599 sec/iter\n",
      "Epoch: 444 | Batch: 010 / 011 | Total loss: 0.356 | Reg loss: 0.018 | Tree loss: 0.356 | Accuracy: 0.856655 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 445 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.820000 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.820000 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 002 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.841500 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.849500 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.853000 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.825500 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.810500 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.826000 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.834500 | 0.599 sec/iter\n",
      "Epoch: 445 | Batch: 010 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.836177 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 446 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.818500 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 001 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 002 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.815500 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 003 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.846500 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.853000 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 006 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.798500 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 007 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.821000 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 009 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 446 | Batch: 010 / 011 | Total loss: 0.335 | Reg loss: 0.018 | Tree loss: 0.335 | Accuracy: 0.883959 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 447 | Batch: 000 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 001 / 011 | Total loss: 0.425 | Reg loss: 0.018 | Tree loss: 0.425 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.819500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.836500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.841500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.836500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 006 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 447 | Batch: 010 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.853242 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 448 | Batch: 000 / 011 | Total loss: 0.431 | Reg loss: 0.018 | Tree loss: 0.431 | Accuracy: 0.805000 | 0.601 sec/iter\n",
      "Epoch: 448 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 448 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.805500 | 0.601 sec/iter\n",
      "Epoch: 448 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.836500 | 0.6 sec/iter\n",
      "Epoch: 448 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.839500 | 0.6 sec/iter\n",
      "Epoch: 448 | Batch: 005 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.858000 | 0.6 sec/iter\n",
      "Epoch: 448 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.818000 | 0.6 sec/iter\n",
      "Epoch: 448 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 448 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 448 | Batch: 009 / 011 | Total loss: 0.358 | Reg loss: 0.018 | Tree loss: 0.358 | Accuracy: 0.844000 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448 | Batch: 010 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.839590 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 449 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.828500 | 0.601 sec/iter\n",
      "Epoch: 449 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.812000 | 0.601 sec/iter\n",
      "Epoch: 449 | Batch: 002 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 449 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 449 | Batch: 004 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.845500 | 0.601 sec/iter\n",
      "Epoch: 449 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.840000 | 0.601 sec/iter\n",
      "Epoch: 449 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 449 | Batch: 007 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 449 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 449 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 449 | Batch: 010 / 011 | Total loss: 0.352 | Reg loss: 0.018 | Tree loss: 0.352 | Accuracy: 0.870307 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 450 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.018 | Tree loss: 0.432 | Accuracy: 0.810500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 002 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.813500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.839500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 005 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 006 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.837000 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.814500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 008 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.833500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 450 | Batch: 010 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.849829 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 451 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.827500 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 003 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.836500 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.841000 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 451 | Batch: 010 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.853242 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 452 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.816000 | 0.601 sec/iter\n",
      "Epoch: 452 | Batch: 001 / 011 | Total loss: 0.431 | Reg loss: 0.018 | Tree loss: 0.431 | Accuracy: 0.808000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 002 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.812500 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 003 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.842000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.847000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.818000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 452 | Batch: 010 / 011 | Total loss: 0.335 | Reg loss: 0.018 | Tree loss: 0.335 | Accuracy: 0.883959 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 453 | Batch: 000 / 011 | Total loss: 0.439 | Reg loss: 0.018 | Tree loss: 0.439 | Accuracy: 0.800000 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.018 | Tree loss: 0.426 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 002 / 011 | Total loss: 0.433 | Reg loss: 0.018 | Tree loss: 0.433 | Accuracy: 0.800500 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 003 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.836500 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.843500 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 005 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.863000 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.821500 | 0.6 sec/iter\n",
      "Epoch: 453 | Batch: 008 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.836000 | 0.599 sec/iter\n",
      "Epoch: 453 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.832000 | 0.599 sec/iter\n",
      "Epoch: 453 | Batch: 010 / 011 | Total loss: 0.349 | Reg loss: 0.018 | Tree loss: 0.349 | Accuracy: 0.860068 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 454 | Batch: 000 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.813500 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.856000 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 454 | Batch: 010 / 011 | Total loss: 0.315 | Reg loss: 0.018 | Tree loss: 0.315 | Accuracy: 0.873720 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 455 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.825500 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.824500 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.828000 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 005 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.854000 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.818500 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.825500 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.834000 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.824500 | 0.599 sec/iter\n",
      "Epoch: 455 | Batch: 010 / 011 | Total loss: 0.323 | Reg loss: 0.018 | Tree loss: 0.323 | Accuracy: 0.880546 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 456 | Batch: 000 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.806000 | 0.6 sec/iter\n",
      "Epoch: 456 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 456 | Batch: 002 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.816500 | 0.6 sec/iter\n",
      "Epoch: 456 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 456 | Batch: 004 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.837500 | 0.6 sec/iter\n",
      "Epoch: 456 | Batch: 005 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.844000 | 0.599 sec/iter\n",
      "Epoch: 456 | Batch: 006 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.832500 | 0.599 sec/iter\n",
      "Epoch: 456 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.830000 | 0.599 sec/iter\n",
      "Epoch: 456 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.818000 | 0.599 sec/iter\n",
      "Epoch: 456 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.829000 | 0.599 sec/iter\n",
      "Epoch: 456 | Batch: 010 / 011 | Total loss: 0.363 | Reg loss: 0.018 | Tree loss: 0.363 | Accuracy: 0.873720 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 457 | Batch: 000 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.811000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 002 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.829000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.847000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 006 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.831000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.825500 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 457 | Batch: 010 / 011 | Total loss: 0.350 | Reg loss: 0.018 | Tree loss: 0.350 | Accuracy: 0.856655 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 458 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.808500 | 0.601 sec/iter\n",
      "Epoch: 458 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.806000 | 0.601 sec/iter\n",
      "Epoch: 458 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.810000 | 0.601 sec/iter\n",
      "Epoch: 458 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 458 | Batch: 004 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 458 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.858500 | 0.6 sec/iter\n",
      "Epoch: 458 | Batch: 006 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 458 | Batch: 007 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.813000 | 0.6 sec/iter\n",
      "Epoch: 458 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 458 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.848500 | 0.6 sec/iter\n",
      "Epoch: 458 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.836177 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 459 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 001 / 011 | Total loss: 0.443 | Reg loss: 0.018 | Tree loss: 0.443 | Accuracy: 0.797500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 459 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 004 / 011 | Total loss: 0.365 | Reg loss: 0.018 | Tree loss: 0.365 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 005 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.835000 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 006 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.822000 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 009 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 459 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.846416 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 460 | Batch: 000 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.810500 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 002 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.843000 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.860500 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 008 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.804500 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.831000 | 0.601 sec/iter\n",
      "Epoch: 460 | Batch: 010 / 011 | Total loss: 0.341 | Reg loss: 0.018 | Tree loss: 0.341 | Accuracy: 0.856655 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 461 | Batch: 000 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 001 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 004 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.844500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 005 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.845500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 009 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 461 | Batch: 010 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.822526 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 462 | Batch: 000 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 001 / 011 | Total loss: 0.426 | Reg loss: 0.018 | Tree loss: 0.426 | Accuracy: 0.812500 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 004 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 005 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.861500 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 006 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.841500 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 007 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 462 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.822000 | 0.6 sec/iter\n",
      "Epoch: 462 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 462 | Batch: 010 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.849829 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 463 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 001 / 011 | Total loss: 0.430 | Reg loss: 0.018 | Tree loss: 0.430 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 002 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.819500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 003 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.838000 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 004 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.846000 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 005 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.847500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 006 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.832500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 008 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.811500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 009 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.838500 | 0.6 sec/iter\n",
      "Epoch: 463 | Batch: 010 / 011 | Total loss: 0.338 | Reg loss: 0.018 | Tree loss: 0.338 | Accuracy: 0.849829 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 464 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.824000 | 0.6 sec/iter\n",
      "Epoch: 464 | Batch: 001 / 011 | Total loss: 0.415 | Reg loss: 0.018 | Tree loss: 0.415 | Accuracy: 0.814500 | 0.6 sec/iter\n",
      "Epoch: 464 | Batch: 002 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.811500 | 0.6 sec/iter\n",
      "Epoch: 464 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.831500 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 464 | Batch: 004 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.823500 | 0.6 sec/iter\n",
      "Epoch: 464 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.859000 | 0.6 sec/iter\n",
      "Epoch: 464 | Batch: 006 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.816000 | 0.6 sec/iter\n",
      "Epoch: 464 | Batch: 007 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.817000 | 0.599 sec/iter\n",
      "Epoch: 464 | Batch: 008 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.828500 | 0.599 sec/iter\n",
      "Epoch: 464 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.839500 | 0.599 sec/iter\n",
      "Epoch: 464 | Batch: 010 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.849829 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 465 | Batch: 000 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.827000 | 0.6 sec/iter\n",
      "Epoch: 465 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.819000 | 0.6 sec/iter\n",
      "Epoch: 465 | Batch: 002 / 011 | Total loss: 0.431 | Reg loss: 0.018 | Tree loss: 0.431 | Accuracy: 0.815000 | 0.6 sec/iter\n",
      "Epoch: 465 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.828000 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 004 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.843000 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 005 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.857500 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 006 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.828500 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 007 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.811500 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 008 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 009 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.818500 | 0.599 sec/iter\n",
      "Epoch: 465 | Batch: 010 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.839590 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 466 | Batch: 000 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.817000 | 0.6 sec/iter\n",
      "Epoch: 466 | Batch: 001 / 011 | Total loss: 0.437 | Reg loss: 0.018 | Tree loss: 0.437 | Accuracy: 0.806500 | 0.6 sec/iter\n",
      "Epoch: 466 | Batch: 002 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.812000 | 0.6 sec/iter\n",
      "Epoch: 466 | Batch: 003 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.820000 | 0.6 sec/iter\n",
      "Epoch: 466 | Batch: 004 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.836500 | 0.599 sec/iter\n",
      "Epoch: 466 | Batch: 005 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.844500 | 0.599 sec/iter\n",
      "Epoch: 466 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.825500 | 0.599 sec/iter\n",
      "Epoch: 466 | Batch: 007 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.804000 | 0.599 sec/iter\n",
      "Epoch: 466 | Batch: 008 / 011 | Total loss: 0.399 | Reg loss: 0.018 | Tree loss: 0.399 | Accuracy: 0.813000 | 0.599 sec/iter\n",
      "Epoch: 466 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.817500 | 0.599 sec/iter\n",
      "Epoch: 466 | Batch: 010 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.808874 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 467 | Batch: 000 / 011 | Total loss: 0.443 | Reg loss: 0.018 | Tree loss: 0.443 | Accuracy: 0.793500 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 002 / 011 | Total loss: 0.429 | Reg loss: 0.018 | Tree loss: 0.429 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.830000 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.845000 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 006 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.840500 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.821000 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.823500 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.835000 | 0.6 sec/iter\n",
      "Epoch: 467 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.839590 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 468 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 468 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.805500 | 0.601 sec/iter\n",
      "Epoch: 468 | Batch: 002 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 468 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.828500 | 0.601 sec/iter\n",
      "Epoch: 468 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.836000 | 0.6 sec/iter\n",
      "Epoch: 468 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.846000 | 0.6 sec/iter\n",
      "Epoch: 468 | Batch: 006 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.832000 | 0.6 sec/iter\n",
      "Epoch: 468 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 468 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 468 | Batch: 009 / 011 | Total loss: 0.365 | Reg loss: 0.018 | Tree loss: 0.365 | Accuracy: 0.831500 | 0.6 sec/iter\n",
      "Epoch: 468 | Batch: 010 / 011 | Total loss: 0.343 | Reg loss: 0.018 | Tree loss: 0.343 | Accuracy: 0.863481 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 469 | Batch: 000 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 001 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.820000 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 004 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.834000 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 005 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.852500 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 469 | Batch: 006 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.822500 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 008 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.832500 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.840500 | 0.601 sec/iter\n",
      "Epoch: 469 | Batch: 010 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.822526 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 470 | Batch: 000 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.812000 | 0.602 sec/iter\n",
      "Epoch: 470 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 470 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 470 | Batch: 003 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.818500 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.847000 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 005 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.854000 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 006 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.824000 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 007 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 008 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.828500 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.841500 | 0.601 sec/iter\n",
      "Epoch: 470 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.870307 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 471 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 471 | Batch: 001 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 471 | Batch: 002 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.811000 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.837000 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.845500 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 006 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.806500 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 008 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.840000 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 009 / 011 | Total loss: 0.355 | Reg loss: 0.018 | Tree loss: 0.355 | Accuracy: 0.863000 | 0.601 sec/iter\n",
      "Epoch: 471 | Batch: 010 / 011 | Total loss: 0.329 | Reg loss: 0.018 | Tree loss: 0.329 | Accuracy: 0.897611 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 472 | Batch: 000 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.824000 | 0.602 sec/iter\n",
      "Epoch: 472 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.817500 | 0.602 sec/iter\n",
      "Epoch: 472 | Batch: 002 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.804500 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 003 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.853500 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 009 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 472 | Batch: 010 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.846416 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 473 | Batch: 000 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 473 | Batch: 001 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.826500 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 002 / 011 | Total loss: 0.426 | Reg loss: 0.018 | Tree loss: 0.426 | Accuracy: 0.812000 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 003 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.825000 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 004 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 005 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.839000 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 006 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 007 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.824500 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 008 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.808500 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.835000 | 0.601 sec/iter\n",
      "Epoch: 473 | Batch: 010 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.822526 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 474 | Batch: 000 / 011 | Total loss: 0.419 | Reg loss: 0.018 | Tree loss: 0.419 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 474 | Batch: 001 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 474 | Batch: 002 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.835000 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 004 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 006 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.811500 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 007 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.829000 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 474 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 474 | Batch: 010 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.825939 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 475 | Batch: 000 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 475 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 475 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.802000 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 003 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 005 / 011 | Total loss: 0.359 | Reg loss: 0.018 | Tree loss: 0.359 | Accuracy: 0.861000 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 006 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.832000 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 007 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.815500 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 008 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.821000 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.833500 | 0.601 sec/iter\n",
      "Epoch: 475 | Batch: 010 / 011 | Total loss: 0.410 | Reg loss: 0.018 | Tree loss: 0.410 | Accuracy: 0.832765 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 476 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.812500 | 0.602 sec/iter\n",
      "Epoch: 476 | Batch: 001 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.811500 | 0.602 sec/iter\n",
      "Epoch: 476 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 003 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 004 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.842500 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 005 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.868500 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 006 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.825500 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 009 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 476 | Batch: 010 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.856655 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 477 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.808000 | 0.602 sec/iter\n",
      "Epoch: 477 | Batch: 001 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.830000 | 0.602 sec/iter\n",
      "Epoch: 477 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.809500 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 003 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 004 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.837000 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 005 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.836000 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.819500 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.826000 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 009 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.838500 | 0.601 sec/iter\n",
      "Epoch: 477 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.822526 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 478 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 478 | Batch: 001 / 011 | Total loss: 0.439 | Reg loss: 0.018 | Tree loss: 0.439 | Accuracy: 0.799500 | 0.602 sec/iter\n",
      "Epoch: 478 | Batch: 002 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.811000 | 0.602 sec/iter\n",
      "Epoch: 478 | Batch: 003 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.816500 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.835500 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 005 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.861000 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 007 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.829000 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.823500 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 009 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.843500 | 0.601 sec/iter\n",
      "Epoch: 478 | Batch: 010 / 011 | Total loss: 0.361 | Reg loss: 0.018 | Tree loss: 0.361 | Accuracy: 0.883959 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 479 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.018 | Tree loss: 0.426 | Accuracy: 0.809500 | 0.602 sec/iter\n",
      "Epoch: 479 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.813500 | 0.602 sec/iter\n",
      "Epoch: 479 | Batch: 002 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.831500 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.835500 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.841000 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 005 / 011 | Total loss: 0.362 | Reg loss: 0.018 | Tree loss: 0.362 | Accuracy: 0.860000 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.827500 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 007 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.832000 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 008 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.833000 | 0.601 sec/iter\n",
      "Epoch: 479 | Batch: 009 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.837000 | 0.601 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 479 | Batch: 010 / 011 | Total loss: 0.352 | Reg loss: 0.018 | Tree loss: 0.352 | Accuracy: 0.863481 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 480 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.813000 | 0.601 sec/iter\n",
      "Epoch: 480 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.820500 | 0.601 sec/iter\n",
      "Epoch: 480 | Batch: 002 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.827000 | 0.601 sec/iter\n",
      "Epoch: 480 | Batch: 003 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.837000 | 0.601 sec/iter\n",
      "Epoch: 480 | Batch: 004 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.843000 | 0.601 sec/iter\n",
      "Epoch: 480 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.846500 | 0.601 sec/iter\n",
      "Epoch: 480 | Batch: 006 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.805000 | 0.6 sec/iter\n",
      "Epoch: 480 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 480 | Batch: 008 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.828000 | 0.6 sec/iter\n",
      "Epoch: 480 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 480 | Batch: 010 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.853242 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 481 | Batch: 000 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.813500 | 0.601 sec/iter\n",
      "Epoch: 481 | Batch: 001 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 481 | Batch: 002 / 011 | Total loss: 0.417 | Reg loss: 0.018 | Tree loss: 0.417 | Accuracy: 0.818000 | 0.601 sec/iter\n",
      "Epoch: 481 | Batch: 003 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.839000 | 0.601 sec/iter\n",
      "Epoch: 481 | Batch: 004 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.825000 | 0.6 sec/iter\n",
      "Epoch: 481 | Batch: 005 / 011 | Total loss: 0.373 | Reg loss: 0.018 | Tree loss: 0.373 | Accuracy: 0.846000 | 0.6 sec/iter\n",
      "Epoch: 481 | Batch: 006 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.839500 | 0.6 sec/iter\n",
      "Epoch: 481 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.815500 | 0.6 sec/iter\n",
      "Epoch: 481 | Batch: 008 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.824500 | 0.6 sec/iter\n",
      "Epoch: 481 | Batch: 009 / 011 | Total loss: 0.369 | Reg loss: 0.018 | Tree loss: 0.369 | Accuracy: 0.842500 | 0.6 sec/iter\n",
      "Epoch: 481 | Batch: 010 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.829352 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 482 | Batch: 000 / 011 | Total loss: 0.427 | Reg loss: 0.018 | Tree loss: 0.427 | Accuracy: 0.800500 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.818000 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 002 / 011 | Total loss: 0.428 | Reg loss: 0.018 | Tree loss: 0.428 | Accuracy: 0.807500 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.842000 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 005 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.855000 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 006 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.823000 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 007 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.815500 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.822500 | 0.6 sec/iter\n",
      "Epoch: 482 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.827000 | 0.599 sec/iter\n",
      "Epoch: 482 | Batch: 010 / 011 | Total loss: 0.342 | Reg loss: 0.018 | Tree loss: 0.342 | Accuracy: 0.897611 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 483 | Batch: 000 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.815500 | 0.6 sec/iter\n",
      "Epoch: 483 | Batch: 001 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.806500 | 0.6 sec/iter\n",
      "Epoch: 483 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.820500 | 0.6 sec/iter\n",
      "Epoch: 483 | Batch: 003 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.855000 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 005 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.829500 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.829500 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 007 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 008 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.818500 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.846000 | 0.599 sec/iter\n",
      "Epoch: 483 | Batch: 010 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.843003 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 484 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.808500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 001 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.820500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 002 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.835500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 004 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.842000 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.852500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 006 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.816000 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 007 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.837000 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.823500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 009 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.834500 | 0.599 sec/iter\n",
      "Epoch: 484 | Batch: 010 / 011 | Total loss: 0.350 | Reg loss: 0.018 | Tree loss: 0.350 | Accuracy: 0.894198 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 485 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.810500 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.813000 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 002 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.801500 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 003 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.819500 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.835500 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.850000 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 006 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 007 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 008 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.804000 | 0.599 sec/iter\n",
      "Epoch: 485 | Batch: 009 / 011 | Total loss: 0.377 | Reg loss: 0.018 | Tree loss: 0.377 | Accuracy: 0.819500 | 0.598 sec/iter\n",
      "Epoch: 485 | Batch: 010 / 011 | Total loss: 0.336 | Reg loss: 0.018 | Tree loss: 0.336 | Accuracy: 0.880546 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 486 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.018 | Tree loss: 0.426 | Accuracy: 0.804500 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 001 / 011 | Total loss: 0.429 | Reg loss: 0.018 | Tree loss: 0.429 | Accuracy: 0.819500 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 002 / 011 | Total loss: 0.409 | Reg loss: 0.018 | Tree loss: 0.409 | Accuracy: 0.824000 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.826000 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 004 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.848000 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 005 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.856500 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 006 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.827500 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.831500 | 0.599 sec/iter\n",
      "Epoch: 486 | Batch: 008 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.831500 | 0.598 sec/iter\n",
      "Epoch: 486 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.831000 | 0.598 sec/iter\n",
      "Epoch: 486 | Batch: 010 / 011 | Total loss: 0.315 | Reg loss: 0.018 | Tree loss: 0.315 | Accuracy: 0.901024 | 0.598 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 487 | Batch: 000 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.821000 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 001 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.821500 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 002 / 011 | Total loss: 0.407 | Reg loss: 0.018 | Tree loss: 0.407 | Accuracy: 0.833000 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 003 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.831500 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.840500 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 005 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 006 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.823000 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 008 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.821500 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 009 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.826000 | 0.599 sec/iter\n",
      "Epoch: 487 | Batch: 010 / 011 | Total loss: 0.353 | Reg loss: 0.018 | Tree loss: 0.353 | Accuracy: 0.836177 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 488 | Batch: 000 / 011 | Total loss: 0.426 | Reg loss: 0.018 | Tree loss: 0.426 | Accuracy: 0.817500 | 0.6 sec/iter\n",
      "Epoch: 488 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.808500 | 0.6 sec/iter\n",
      "Epoch: 488 | Batch: 002 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.814000 | 0.6 sec/iter\n",
      "Epoch: 488 | Batch: 003 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 488 | Batch: 004 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.830500 | 0.599 sec/iter\n",
      "Epoch: 488 | Batch: 005 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.840000 | 0.599 sec/iter\n",
      "Epoch: 488 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.817500 | 0.599 sec/iter\n",
      "Epoch: 488 | Batch: 007 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 488 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.837000 | 0.599 sec/iter\n",
      "Epoch: 488 | Batch: 009 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.837500 | 0.599 sec/iter\n",
      "Epoch: 488 | Batch: 010 / 011 | Total loss: 0.365 | Reg loss: 0.018 | Tree loss: 0.365 | Accuracy: 0.863481 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 489 | Batch: 000 / 011 | Total loss: 0.434 | Reg loss: 0.018 | Tree loss: 0.434 | Accuracy: 0.797500 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 001 / 011 | Total loss: 0.424 | Reg loss: 0.018 | Tree loss: 0.424 | Accuracy: 0.809000 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 002 / 011 | Total loss: 0.402 | Reg loss: 0.018 | Tree loss: 0.402 | Accuracy: 0.818500 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 003 / 011 | Total loss: 0.365 | Reg loss: 0.018 | Tree loss: 0.365 | Accuracy: 0.853500 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.830500 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.842000 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 006 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.834000 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 007 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.828500 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 008 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.821000 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 009 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.829500 | 0.6 sec/iter\n",
      "Epoch: 489 | Batch: 010 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.877133 | 0.599 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 490 | Batch: 000 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.808000 | 0.6 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 490 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.811000 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 002 / 011 | Total loss: 0.406 | Reg loss: 0.018 | Tree loss: 0.406 | Accuracy: 0.826500 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 003 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 004 / 011 | Total loss: 0.366 | Reg loss: 0.018 | Tree loss: 0.366 | Accuracy: 0.854000 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 005 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.841500 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.811500 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 007 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.826000 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 008 / 011 | Total loss: 0.370 | Reg loss: 0.018 | Tree loss: 0.370 | Accuracy: 0.833000 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 009 / 011 | Total loss: 0.351 | Reg loss: 0.018 | Tree loss: 0.351 | Accuracy: 0.856000 | 0.6 sec/iter\n",
      "Epoch: 490 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.018 | Tree loss: 0.359 | Accuracy: 0.846416 | 0.6 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 491 | Batch: 000 / 011 | Total loss: 0.425 | Reg loss: 0.018 | Tree loss: 0.425 | Accuracy: 0.809000 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 001 / 011 | Total loss: 0.418 | Reg loss: 0.018 | Tree loss: 0.418 | Accuracy: 0.808500 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 002 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.836500 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 003 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.821500 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 004 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.857000 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 005 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.845000 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 006 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.811000 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 007 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.813000 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 008 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.833000 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.854500 | 0.601 sec/iter\n",
      "Epoch: 491 | Batch: 010 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.839590 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 492 | Batch: 000 / 011 | Total loss: 0.422 | Reg loss: 0.018 | Tree loss: 0.422 | Accuracy: 0.807000 | 0.602 sec/iter\n",
      "Epoch: 492 | Batch: 001 / 011 | Total loss: 0.420 | Reg loss: 0.018 | Tree loss: 0.420 | Accuracy: 0.819000 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 002 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.817500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 003 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.837500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 004 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.849500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 005 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.848000 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 006 / 011 | Total loss: 0.414 | Reg loss: 0.018 | Tree loss: 0.414 | Accuracy: 0.807500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 007 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.814500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 008 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.830500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 009 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.846500 | 0.601 sec/iter\n",
      "Epoch: 492 | Batch: 010 / 011 | Total loss: 0.359 | Reg loss: 0.018 | Tree loss: 0.359 | Accuracy: 0.873720 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 493 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.018 | Tree loss: 0.432 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 493 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 493 | Batch: 002 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.838000 | 0.602 sec/iter\n",
      "Epoch: 493 | Batch: 003 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.844500 | 0.602 sec/iter\n",
      "Epoch: 493 | Batch: 004 / 011 | Total loss: 0.386 | Reg loss: 0.018 | Tree loss: 0.386 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 493 | Batch: 005 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.854500 | 0.602 sec/iter\n",
      "Epoch: 493 | Batch: 006 / 011 | Total loss: 0.394 | Reg loss: 0.018 | Tree loss: 0.394 | Accuracy: 0.812500 | 0.601 sec/iter\n",
      "Epoch: 493 | Batch: 007 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.823000 | 0.601 sec/iter\n",
      "Epoch: 493 | Batch: 008 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.830000 | 0.601 sec/iter\n",
      "Epoch: 493 | Batch: 009 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.841000 | 0.601 sec/iter\n",
      "Epoch: 493 | Batch: 010 / 011 | Total loss: 0.346 | Reg loss: 0.018 | Tree loss: 0.346 | Accuracy: 0.825939 | 0.601 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 494 | Batch: 000 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.818000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.808500 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 002 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.833000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 003 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.821000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 004 / 011 | Total loss: 0.367 | Reg loss: 0.018 | Tree loss: 0.367 | Accuracy: 0.843000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 005 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.856000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 006 / 011 | Total loss: 0.396 | Reg loss: 0.018 | Tree loss: 0.396 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 007 / 011 | Total loss: 0.400 | Reg loss: 0.018 | Tree loss: 0.400 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 008 / 011 | Total loss: 0.375 | Reg loss: 0.018 | Tree loss: 0.375 | Accuracy: 0.835000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 009 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 494 | Batch: 010 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.839590 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 495 | Batch: 000 / 011 | Total loss: 0.436 | Reg loss: 0.018 | Tree loss: 0.436 | Accuracy: 0.807500 | 0.603 sec/iter\n",
      "Epoch: 495 | Batch: 001 / 011 | Total loss: 0.432 | Reg loss: 0.018 | Tree loss: 0.432 | Accuracy: 0.800000 | 0.603 sec/iter\n",
      "Epoch: 495 | Batch: 002 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.832000 | 0.603 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 495 | Batch: 003 / 011 | Total loss: 0.391 | Reg loss: 0.018 | Tree loss: 0.391 | Accuracy: 0.842500 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 004 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 005 / 011 | Total loss: 0.368 | Reg loss: 0.018 | Tree loss: 0.368 | Accuracy: 0.856500 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 006 / 011 | Total loss: 0.378 | Reg loss: 0.018 | Tree loss: 0.378 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 007 / 011 | Total loss: 0.405 | Reg loss: 0.018 | Tree loss: 0.405 | Accuracy: 0.812000 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 008 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.829500 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 009 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.824500 | 0.602 sec/iter\n",
      "Epoch: 495 | Batch: 010 / 011 | Total loss: 0.318 | Reg loss: 0.018 | Tree loss: 0.318 | Accuracy: 0.890785 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 496 | Batch: 000 / 011 | Total loss: 0.432 | Reg loss: 0.018 | Tree loss: 0.432 | Accuracy: 0.802000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 001 / 011 | Total loss: 0.411 | Reg loss: 0.018 | Tree loss: 0.411 | Accuracy: 0.813000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 002 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.805500 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 003 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 004 / 011 | Total loss: 0.376 | Reg loss: 0.018 | Tree loss: 0.376 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 005 / 011 | Total loss: 0.371 | Reg loss: 0.018 | Tree loss: 0.371 | Accuracy: 0.851000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 006 / 011 | Total loss: 0.387 | Reg loss: 0.018 | Tree loss: 0.387 | Accuracy: 0.822000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 007 / 011 | Total loss: 0.385 | Reg loss: 0.018 | Tree loss: 0.385 | Accuracy: 0.839500 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 008 / 011 | Total loss: 0.401 | Reg loss: 0.018 | Tree loss: 0.401 | Accuracy: 0.806000 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 009 / 011 | Total loss: 0.372 | Reg loss: 0.018 | Tree loss: 0.372 | Accuracy: 0.832500 | 0.602 sec/iter\n",
      "Epoch: 496 | Batch: 010 / 011 | Total loss: 0.347 | Reg loss: 0.018 | Tree loss: 0.347 | Accuracy: 0.873720 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 497 | Batch: 000 / 011 | Total loss: 0.412 | Reg loss: 0.018 | Tree loss: 0.412 | Accuracy: 0.814500 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 001 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.817000 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 002 / 011 | Total loss: 0.421 | Reg loss: 0.018 | Tree loss: 0.421 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 003 / 011 | Total loss: 0.398 | Reg loss: 0.018 | Tree loss: 0.398 | Accuracy: 0.830500 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 004 / 011 | Total loss: 0.382 | Reg loss: 0.018 | Tree loss: 0.382 | Accuracy: 0.834000 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 005 / 011 | Total loss: 0.364 | Reg loss: 0.018 | Tree loss: 0.364 | Accuracy: 0.850000 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 006 / 011 | Total loss: 0.397 | Reg loss: 0.018 | Tree loss: 0.397 | Accuracy: 0.811000 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 007 / 011 | Total loss: 0.383 | Reg loss: 0.018 | Tree loss: 0.383 | Accuracy: 0.825500 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 008 / 011 | Total loss: 0.395 | Reg loss: 0.018 | Tree loss: 0.395 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 009 / 011 | Total loss: 0.374 | Reg loss: 0.018 | Tree loss: 0.374 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 497 | Batch: 010 / 011 | Total loss: 0.433 | Reg loss: 0.018 | Tree loss: 0.433 | Accuracy: 0.798635 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 498 | Batch: 000 / 011 | Total loss: 0.416 | Reg loss: 0.018 | Tree loss: 0.416 | Accuracy: 0.818000 | 0.603 sec/iter\n",
      "Epoch: 498 | Batch: 001 / 011 | Total loss: 0.413 | Reg loss: 0.018 | Tree loss: 0.413 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 002 / 011 | Total loss: 0.430 | Reg loss: 0.018 | Tree loss: 0.430 | Accuracy: 0.820500 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 003 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.822500 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 004 / 011 | Total loss: 0.389 | Reg loss: 0.018 | Tree loss: 0.389 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 005 / 011 | Total loss: 0.404 | Reg loss: 0.018 | Tree loss: 0.404 | Accuracy: 0.843500 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 006 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.828000 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 007 / 011 | Total loss: 0.393 | Reg loss: 0.018 | Tree loss: 0.393 | Accuracy: 0.823000 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 008 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.836000 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 009 / 011 | Total loss: 0.381 | Reg loss: 0.018 | Tree loss: 0.381 | Accuracy: 0.823500 | 0.602 sec/iter\n",
      "Epoch: 498 | Batch: 010 / 011 | Total loss: 0.340 | Reg loss: 0.018 | Tree loss: 0.340 | Accuracy: 0.870307 | 0.602 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 499 | Batch: 000 / 011 | Total loss: 0.408 | Reg loss: 0.018 | Tree loss: 0.408 | Accuracy: 0.826000 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 001 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.806500 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 002 / 011 | Total loss: 0.423 | Reg loss: 0.018 | Tree loss: 0.423 | Accuracy: 0.811000 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 003 / 011 | Total loss: 0.403 | Reg loss: 0.018 | Tree loss: 0.403 | Accuracy: 0.831500 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 004 / 011 | Total loss: 0.390 | Reg loss: 0.018 | Tree loss: 0.390 | Accuracy: 0.828500 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 005 / 011 | Total loss: 0.384 | Reg loss: 0.018 | Tree loss: 0.384 | Accuracy: 0.851000 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 006 / 011 | Total loss: 0.380 | Reg loss: 0.018 | Tree loss: 0.380 | Accuracy: 0.833500 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 007 / 011 | Total loss: 0.392 | Reg loss: 0.018 | Tree loss: 0.392 | Accuracy: 0.815000 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 008 / 011 | Total loss: 0.379 | Reg loss: 0.018 | Tree loss: 0.379 | Accuracy: 0.832000 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 009 / 011 | Total loss: 0.388 | Reg loss: 0.018 | Tree loss: 0.388 | Accuracy: 0.827000 | 0.602 sec/iter\n",
      "Epoch: 499 | Batch: 010 / 011 | Total loss: 0.352 | Reg loss: 0.018 | Tree loss: 0.352 | Accuracy: 0.866894 | 0.602 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 5.888888888888889\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'MLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/miniconda3/envs/rambo/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "Average comprehensibility: 53.0\n"
     ]
    }
   ],
   "source": [
    "signal_names = dataset.dataset.all_signals\n",
    "normalizers = torch.tensor([])\n",
    "attr_names = []\n",
    "for signal_name in signal_names:\n",
    "    attr_names += [f\"T{i}.{signal_name}\" for i in range(sampled.shape[-1])]\n",
    "    sensor_norm = torch.tensor([torch.tensor(dataset.dataset.sensor_maxs[signal_name]) for _ in range(sampled.shape[-1])])\n",
    "    normalizers = torch.cat([normalizers, sensor_norm])\n",
    "    \n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    for cond in conds:\n",
    "        cond.weights = cond.weights / normalizers\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    sum_comprehensibility += sum([cond.comprehensibility for cond in conds])\n",
    "    \n",
    "print(f\"Average comprehensibility: {sum_comprehensibility / len(leaves)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8136302828788757\n"
     ]
    }
   ],
   "source": [
    "# prune_tree(tree, factor=1.5)\n",
    "correct = 0\n",
    "tree = tree.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = tree.forward(data)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.view(-1).data).sum()\n",
    "\n",
    "print(f\"Accuracy: {correct / len(tree_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1.0: 0.9723756906077348\n",
      "layer 2.0: 0.9723756906077348\n",
      "layer 3.0: 0.9723756906077348\n",
      "layer 4.0: 0.9723756906077348\n",
      "layer 5.0: 0.9723756906077348\n",
      "layer 6.0: 0.9723756906077349\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sparseness: {sparseness(tree.inner_nodes.weight)}\")\n",
    "layer = 0\n",
    "sps = []\n",
    "for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "    cur_layer = np.floor(np.log2(i+1))\n",
    "    if cur_layer != layer:\n",
    "        print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "        sps = []\n",
    "        layer = cur_layer\n",
    "    \n",
    "    x_ = tree.inner_nodes.weight[i, :]\n",
    "    sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "    sps.append(sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEXCAYAAADr+ZCUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh4UlEQVR4nO3debgdVZ3u8e9LQhIhJAwJUwIEBNHQMkgEbEUiAgavNF6lrwm0BhtFVLQV23tBBm0QBa/XVhSV+CCIIoiobdAwOaQBhyuhFSRCMIQgMQxhSCAhisCv/1jrcCo7ezrJPln77Lyf59nPObtWDWutXVW/GlatUkRgZma2oW1SOgNmZrZxcgAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyIcgMzMrAgHILMOkDRX0tTS+TAbSloGIEmLJT0jaVzN8N9JCkmTBi1360jSJElzJD0h6SFJX5I0vMn4u0n6kaSnJD0q6TM16dMl3SVplaR7JR1cWU5IWln5nFmZTpLOl/RY/nxGkmry+XNJT0u6W9JhNcv9gKT7JD0paZ6k11TStpb0nZzfRyVdLmlMJX2YpE9KWprL9VtJW1bKs0DSCkmPSPpGzbTfkvRgXu49kt5VSRsh6eq8XkTtTlfStTX18Yyk3+e0nWvSVuZ5fKSdMg9UG/U7XtK3JS3P68rl67qs9SFpS0lfz+vqU7nO/0+d+oq8DvZ9P1jSpbmOn8qfOyV9WtLYASz/eEnP1SxraoNxXyLph5KWSXpc0vWS9qwZ58O5LCtyuUZW0mp//+ckfTGnHSTpxjzfZZK+K2mHmnm/QtJNedqHJf1LHr6tpCvy+r5C0i8kHVgzbbPtaWTO65M576e0W2ZJMyXdlqddorSdD6+kN9wfSTqupj6ezr/z/jldWsd9iKSpkp6vmf/M5mtDY4OyrIho+gEWAwuAD1SGvTwPC2BSq3ls6A8wB7gUGAVsD/we+GCDcUcA9wKnAJvnafaupB8O3A8cRArYE4AJOW1SroPhDeb9nlxPE/N0fwBOqqT/Cvgc8CLgrcByYHxOOxBYBewPCHgvsAwYltO/DNwAjAHGAj8BPleZ9yeBnwG75On/DhiV03YCxuX/RwOXAxdUpt0LGJn/fynwELB/pb4+BLwGeBCY2uK3mAuc1SBtV+C5vnWoVZnXYT1oWL85/eacPhbYFNhvPda5ua3qosm0lwBXAVvldeylwDF1xgtg95phlwKfzP+PAl4J/By4E9i8zeUfD9zS5rgHACcAW+c6Owe4u5L+BuDhvA5tlevlvAbz2hxYCbw2fz8S+Me8Tm8GfB24rjL+OOAR4DhgJLAF8LKcthtpG94BGAacCDwKjG5ze/p0Xh+2Al6W1/lpbZb5vcDBpG1jAnAbcOo67o+OJ+2P1IF9yFRgybqu0wPZntZ1We0sdDFwBnBrZdhngdOpBKC8QnwW+FNeAb8KvCinbQX8KP/gT+T/J9ZsvOcAvwCeIu1Yx61HRd0FvLHy/f8CFzUY90Tg5ibz+iVwQoO0STQPQL8ETqx8PwH4df7/JcBfgS0q6Tf3rVzA24Df1GysAeyQv18LvK+S/n7g+kp9rwRe3EZdjQYuA+Y0SN+TFGj+V520JTTZ6eb6eQ7YtUH6x4GfV763KvNY4OKcnz+Tgmzd4NRG/R6R1+11Cm51lje3WV20mPZO4M1tjNc0AFWGbZHr6OQ2l388bQagOtNunfO1Tf7+beBTlfTXAw81mHYmsIi8s62T/grgqcr3TwHfHEDenqT/wKnVuvVn4IhK+jnAle2UuU76KcA1le8D2R/9HPh45fv67EOm0iQodHh7arqsRp927wH9Ghgj6WWShuUf81s145yfM7kvsDspWp+V0zYhHeXtAuwMrAa+VDP9scA7gW1JRxL/2pcg6Q5Jx7aZV4AvANMlbSZpAunI6roG4x4ELFa6dPSo0rX8l+flDgOmAOMlLcyn11+S9KKaedyf0y7Rmpcq9wJur3y/PQ/rS1sUEU81SL8WGCbpwJyPfwZ+RzoyA7gQeJOkrSRtRToiuTanvRx4Fjgmn/LfI+n91QxLeo2kFaSA/1bg8zXpX5b0NHA3aQWd06D+mnkHKbjf1yT9G5Xvrcr8jVyu3YH9SEHkXdTXqn4PIh1ZfiNf2rhV0iEDKVwH/Ro4V9I7Je2xvjPLZb6RdFTed+lzuaSdm0y2X17/75F0pppcsq7xWlKAeSx/r7fObydpmzrTzgQui7wHazDv+ZXvBwGPS/ql0qXjaxqVSdK+pP3Iwjyo4bqVt58d6+R7L+qrLXOrfLe1P5K0S572ssrg9dmHAGyrdKnyPkn/LmnzSlont6dWy6qvjaOIxcBhpLOgTwPTSCv3cPIZEOmUdhWVI27gVcB9Dea5L/BE5ftc4IzK9/dROfUe6Id0Cn1brtwgHSU2Osq6AfgbaaUYAXyUdFQ2grRSBjCPdGo/jnSWdm6edjQpQA0HtgOuJp+F5PTngJdWvu+R5yfg7eQjmUr6ucCl+X8BH8t5e5Z0OeGVlXF3JF12ez5/bgRG5LRj83IuJp0u7006+zy8TvknAJ8AXlInbRjpUtsZwKZ10ludAS0Ejm+QdjDpLG10ZVjDMuf6/Sv5rDoPm0HlDKpm/q3qd1auoxNIl1Wmky4prNOZN+t3BvSiXO7bctkXAkfWGa+tM6A8/DzgxjaXvxvpcugmpIOXPwCntTHdRNKR84zKsHvJl67y902pc6medCDa7Ox4b+Bx4ODKsHvyb/RK0uWsC4Bf1Jl2DOky12mVYc3WrZ1yHkdVxj8cWNxOmWvS35m3i3GVYW3tj4Azgbk1w9ZnH7I9MDn/rrsCN5HPvOj89tRwWc0+A2kF903Sju141ozQAONJ12xvy0day0kRfjxAjvwXSbpf0pM5c1vmI5E+D1X+f5q0c29Ja970Pk7SJsD1wPdJp9njSJekzm8wi9Wkyw/XRsQzpMuI25BWmtV5nC9GxIMR8SjpGugbASJiZUTMi4hnI+Jh4GTgCPXf0F9J2hj6jAFWRvrFatP60vuOMN5FOkrbixQM/wn4kaQdc/p3SRvkFnm6e+k/K+3L99kRsToi7gCu7Mt3VUT8mfRbXVkn7bmIuIW00b137aprTOkG7/akoFzPTOB7EbGyMqxZmXch7cwerKxjF5HOmJE0v7Ie9AW3ZvW7mrSDuTgi/hYRVwIPAK8eSDk7If9Gn4qI/Unr3lXAdyVtvR6znUDagbez/EURcV9EPB8RvwfOBo5pNo2k8aSDty9HxBWVpHrrPPTXe593kLa7tc6OJe1OOmP5l4i4uZK0GvhBRNwaEX8B/g34e1UaXOSrE9eQdpafrkzbbN3qWwdr871GnpuUuS/9zaTAf2TeVzDA/VHtFQFYj31IRDwUEX/Iv+t9wP+m/3ft6PbUYlkNtR2AIuJ+4D7STuz7NcmPklaOvSJiy/wZGxF9QeQjpHsJB0bEGNJpJqQovl4i4siIGJ0/l5Ouz+4EfCki/hrpNPkS6ux8sztIRxT15v0E6Wim0SWCtSbJf/vKNR/Yp5K+D/2n5vOB3SRt0SB9H9J15Hvyj3od6VLY31fSL4qIVXkn/lX6y3hHTX5aGQ68eD3S65kJfL8mwAAv7CT+kbU3tmZlfoB0xDauso6NiYi9ACJir8p6cDOt67fh715SRDxJutexOelIcsAkjSZdtbi51biNskGTbTNfsroBmB0R59Yk11vnH461L1fV29n2XYb6CXBORHyzJrn2N1tje1NqbfcfpDOU99RM23Ddytv5g3Xy/cJltBZlRtI04GvAUTmI92lrfyTp1aSrGrUHbOuzD6lV/V07vT01W1ZjrU6RyJfg8v8vBqbk/1+4BJe/f4F05LZt/j4BeEP+/zOkI5pRpB/kB1Ru3pMuX7yrsszjWcebonn6RcCpOY9b5uVd3mDcPUlnXIeRLjl9mHQ20Xc562zgVtKRwVakjfqcnHZgnn4T0pHrd1jzpvpJpBuQE0gr13zWbMHya9IZ1yjgf7Jmq5KZpDOc3fIPeXjO50tz+s+BL5Iu37yI1CruF5V530Q6ohlJOpt7BHh9TjuOdAlEpCOh/yQFC3I5p5POQIeRWjWtAo6uzHtkzvMS0nXjUVQuKeT8LAcObVDnx5JaFqpmeKsy/5C0no3Jdf5i4JAm60Gz+t2a1CBmZi7nMaQzhhKX4M4kXVYakfN6es7b6Jrxml6Cy7/L/qQd+B9ovxXckcB2+f+XkhpFfLzBuGOA35B2qPXSp5GuZkwmbS8/o6YVHOmAYhWVG9qVfca9wEcbzPvQXC/7ko7e/53cgCh/v4YUgNZqFNTGunUeaTvYKtfBg/S3gmtV5kOBx8it+dZlf0S6JHxZnWnXZx8ylf7tfCfSPuOSyrSd3J6aLqvhPNtYOReTA1DN8NoANIp05LaI1PrkLnJTw1xxc0mncfeQjk7aDkC50o8bwAa9b57nE6Szs+/SHxh3zvnYuTL+W0jX3Z/M0+1VSduUtHNfTtqwLqC/OfMM0lnhKtIKexmwfWVakYLv4/nzGdbcUU/Ky1tNuiF+WM20Z5NaFT6V6/PtlfRdSRvcY3ne1wF71GzM1+WyLgLeU0k7lxQ8VuW/s+hvxTSetCEuz/Xxe+DdddaJqPlMqqTPoE6AqaRfTw7iNcNblXks8JWc5xXAb4HpTdaDhvWb0w/O5VtJus93cKN5tbHOzWXdA9AZpJ3+k/m3nEs6Mq8dr1EAeibX1yrStnI+sGVlnLXW+Zp5fJbUcnVVXlfOpnLPj3Tw+LH8/8ycj1V5nitr501qBfZwLs8l5Cb9lfSLqNOajdQqMmrmu7JmnPeSznCeIK3/O+Xhh+Rpn66Z/uA2162RpGbfT+a8n1JJa1pm0s722Zq0a9vZH1X2ncvJB4h1tol13YeckuvqadIZzxdZsxVbx7anVstq9Olra25m60HSXOATETG3cFbMhgx3xWNmZkU4AJl1xqWkS5Nm1iZfgjMzsyJ8BmTF5GcNppbOh5mV4QC0EVDqXXf3yvd/VertulFXI83mNVXSkk7kK9KzBnPXZx6SJiv1bPxE/vxE0uRK+ick/U1r9tK7W4N5terd/HVKvQGvkLS4zvT7Sro5py+RdFYlbQdJs5V6a16rF/maB/9WSnpW0jU1875NqSfi23JXM9XpG/bortRz+g+UetK+X5Vurdooc9P6U+oVfXUl7YZK2v+QdEt+0PEhSV+rPkei1LPzA0q9SN8v6fSaMs1S6rX9eUnH1/vNbGhzANrISDqD1Jv1IRHR6CGyRtO22z/YhrSU9AzP1qSnzGezdq8O34n+h+pGR8SiFvPcsjLuOZXhq0hNdT/aYLpvk56/2prULPi9kv4hpz1Pahb/1noTRuXBP1LvFn8iNddF0gjSMxvfIj2n8g3gh3l4X/qNpGdutif1XFHtq/FCUlPt7UjPgH2lzsFHozJD6/o7qpJ2RGX4WFIHlzuSnkWbSOqIs8/FpOdwxpCeDTpW0lsq6beTuuX6r3p1ZkOfA9BGRNInSV2SvDYi7snDas+OLs3jvXC2o/RumoeAK0jPhOxYOeLdUeldKp/PR/dL8/8j8zzG5SPz5UrvUrlZqXuSvqPnw/L/B+QzmSeVOjT8XDtliojlEbE40s1MkfrO2r3FZOskIn4T6en8RgFsEukBw+ci4l7gFnJnjRHxcER8mfRQcyuvJT0Q/L38fSrpubvPR3qa/gJSWQ/N6ccDSyPic5F6xvhLpO6XUOoQ8q3AmZG6jrqFFKTfPoCir5OI+HZEXBcRT0fqbeBrVLo6iogFEbGqMsnzVH67iLgwIn4K/GWw82plOABtPM4j9WL+2jbOAKq2Jx3R70LqPuVI0s6u74h3KenJ/YNID9ztQ3p/yhl5+o+QHnQbTzoC/xj1u8D5AvCFfDT8YlKvGkB7vaEr9WX1F9IDcJ+qST4qB7/5ktrp0+5+1e/dvJXPA++QtKnSC8teReqVYKBmAldXds57AXfEmi2G7mDNnr3r9uhO6qH+ub4DjqxeT8/Nytyq/i5XelnbDZL2aVKu2l6ikXSqpJWkdWRz0lmkbSQcgDYeR5B6GP/TAKd7ntQty18jYnWDcY4jdXz6SEQsI3US2XeE/TdST+K7ROr08+aaHSmV8XaXNC4fqf+6LyEi9o6IpjumiNiSdMnnZNIT3X2uIl3+GQ+8GzhL0owGs3mU1CXOLqQubbYgvayvXT8iXQ5cTXqNxcUR0c4ZzwskbZbncWll8GjSk+pVK3L+IF3amk7qpWNH4Mf0X6JrNW2rMreqv+NIZ367kHoEuF75zbs15TqcFFjPqg6PiPPyMl9B6vC4Nq/WwxyANh7TSe8H+rcBTrcsUs/DzexI6nqnz/15GKRr/guBGyQtknRqg3mcQDpav1vp3TxvGmA+yWcMXwUuk7RtHvaHiFiaL4v9knSmVbeX3mjdu3lDSj1XX0fq7mUUqT+sN0h63wCL8RZSlyv/WRnWTs/ejXp0b9WLcdMyt6q/iPhFpN68n47U+/Ry8nuIKnVzEOnM5piaM7G+eURE/DaXY6Drpw1hDkAbj3tIHa6+ryYIPE16lUaf7Wumqz1bqXf2spR0BNxn5zyMiHgqIj4SEbsBRwGnSHp97Qwi4o8RMYN07+N84Gq180KrtW1CKs+EBul994ra0VfWdsbfjXSp67K8M19Cg1dgtDCTtV/SNh/YW1I1H3vTXs/e9wDDteaL7vaheS/G0LjMrepvjXRJ+5HuOf1zvp/TzLr0um5DmAPQRiS3ejsM+KikD+XBvyO1Phqm1KX8IS1m8zCwjSrvYCE1TjhD0vh8/+AscissSW+StHveeT5JaiTwXO1MJf2TpPER8TzpKJp649WZ7nBJ++X8jyG9r+kJUmeTSDpa6a2xknQA8EFSi7J68zpQ0p6SNlF6g+cFpBeErcjpm0gaReqgVpJG9bVEI+3oJenYPN72pHtut1fmP4rU6SXAyPy9uvyJwOtY+zUFc3NdfDA3+Dg5D/9Z/vst4CBJhym9Y+tDpEtrd+Wzwu8DZ0vaXKnb/6NJl7vaKXPD+lN60+qrJY3IdfFR+l/aiKS/I50VfiAiXmhSXqnL99TM+/3ATyvjjMh1JGDTvAzvs3pJrGPvv/4MnQ81vSiT3uL6BKmr9ymko+GnSDulK+jv3n8qdd7zTmqK/BgpUOxI/9spH8yfao/hHyZ1UdPX8/aZlfkspv9VH98ivTJiZc7PmyvjNewNnfReobvzdMtIrw7fu5J+Rc7ryjzeB2umf2HetO7dfCpr9wI+t5J+KKmV2wpSz+lfAzar+R3W+NTk5TTy6wXqlHM/0ls1V5OaJe9Xk96sR/etSa8pWEVq3n1sJa1VmRvWH7lxRJ72MVLwmFJJv4R0D7HaS/T8nLYJKTg9Tn8v+R9jzZ6e59aps6mltyd/OvdxVzxmZlaET2fNzKwIByAzMyvCAcjMzIpwADIzsyK6sXPJtYwbNy4mTZpUOhtmNlgWLEh/99yzbD66SQfq5Lbbbns0IsZ3KEcdNyQC0KRJk5g3b17pbJjZYJk6Nf2dO7dkLrpLB+pE0v2txyrHl+DMzKwIByAzMyvCAcjMzIro6gAk6ShJs1ascA/tZma9pqsDUERcExEnjh07tvXIZmY2pHR1ADIzs97lAGRmZkU4AJmZWREOQGZmVoQDkJmZFeEAZGZmRTgAmZlZEQ5AZmZWhAOQmZkV4QBkZmZFOACZmVkRDkBmZlaEA5CZmRXhAGRmZkU4AJmZWREOQGZmVoQDkJmZFeEAZGZmRTgAmZlZEQ5AZmZWhAOQmZkV4QBkZmZFbPAAJOnNkr4m6YeSjtjQyzczs+7QkQAk6euSHpF0Z83waZIWSFoo6VSAiPiPiHg3cDzwtk4s38zMhp5OnQFdCkyrDpA0DLgQOBKYDMyQNLkyyhk53czMNkIdCUARcRPweM3gA4CFEbEoIp4BrgSOVnI+cG1E/FejeUo6UdI8SfOWLVvWiWyamVkXGcx7QBOAByrfl+RhHwAOA46RdFKjiSNiVkRMiYgp48ePH8RsmplZCcMHcd6qMywi4gLggkFcrpmZDQGDeQa0BNip8n0isHQQl2dmZkPIYAagW4E9JO0qaQQwHZg9kBlIOkrSrBUrVgxKBs3MrJxONcO+AvgVsKekJZJOiIhngZOB64G7gKsiYv5A5hsR10TEiWPHju1ENs3MrIt05B5QRMxoMHwOMKcTyzAzs97irnjMzKyIrg5AvgdkZta7ujoA+R6QmVnv6uoAZGZmvcsByMzMinAAMjOzIro6ALkRgplZ7+rqAORGCGZmvaurA5CZmfUuByAzMyvCAcjMzIpwADIzsyK6OgC5FZyZWe/q6gDkVnBmZr2rqwOQmZn1LgcgMzMrwgHIzMyKcAAyM7MiHIDMzKyIrg5AboZtZta7ujoAuRm2mVnv6uoAZGZmvcsByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiujoA+UFUM7Pe1dUByA+impn1rq4OQGZm1rscgMzMrAgHIDMzK8IByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiujoAuSseM7Pe1dUByF3xmJn1rq4OQGZm1rscgMzMrAgHIDMzK8IByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyK6OgD5dQxmZr2rqwOQX8dgZta7ujoAmZlZ73IAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyIcgMzMrAgHIDMzK8IByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyI2eACStJukiyVdvaGXbWZm3aMjAUjS1yU9IunOmuHTJC2QtFDSqQARsSgiTujEcs3MbOjq1BnQpcC06gBJw4ALgSOBycAMSZM7tDwzMxviOhKAIuIm4PGawQcAC/MZzzPAlcDR7c5T0omS5kmat2zZsk5k08zMushg3gOaADxQ+b4EmCBpG0lfBfaTdFqjiSNiVkRMiYgp48ePH8RsmplZCcMHcd6qMywi4jHgpEFcrpmZDQGDeQa0BNip8n0isHQQl2dmZkPIYAagW4E9JO0qaQQwHZg9kBlIOkrSrBUrVgxKBs3MrJxONcO+AvgVsKekJZJOiIhngZOB64G7gKsiYv5A5hsR10TEiWPHju1ENs3MrIt05B5QRMxoMHwOMKcTyzAzs97irnjMzKyIrg5AvgdkZta7ujoA+R6QmVnv6uoAZGZmvcsByMzMinAAMjOzIhyAzMysiK4OQG4FZ2bWu7o6ALkVnJlZ7+rqAGRmZr3LAcjMzIpwADIzsyK6OgC5EYKZWe/q6gDkRghmZr2rqwOQmZn1LgcgMzMrwgHIzMyKcAAyM7MiHIDMzKyIrg5AboZtZta7ujoAuRm2mVnv6uoAZGZmvcsByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiujoA+UFUM7Pe1dUByA+impn1rq4OQGZm1rscgMzMrAgHIDMzK8IByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiujoAuSseM7Pe1dUByF3xmJn1rq4OQGZm1rscgMzMrAgHIDMzK8IByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyK6OgD5dQxmZr2rqwOQX8dgZta7ujoAmZlZ73IAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyIcgMzMrAgHIDMzK8IByMzMinAAMjOzIhyAzMysCAcgMzMrwgHIzMyKcAAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyKGb+gFStoc+DLwDDA3Ii7f0HkwM7PyOnIGJOnrkh6RdGfN8GmSFkhaKOnUPPgtwNUR8W7gHzqxfDMzG3o6dQnuUmBadYCkYcCFwJHAZGCGpMnAROCBPNpzHVq+mZkNMR0JQBFxE/B4zeADgIURsSgingGuBI4GlpCCUNPlSzpR0jxJ85YtW7bOeZt06o/XedqN1brWmevazAZiMBshTKD/TAdS4JkAfB94q6SvANc0mjgiZkXElIiYMn78+EHMppmZlTCYjRBUZ1hExCrgnYO4XDMzGwIG8wxoCbBT5ftEYOkgLs/MzIaQwQxAtwJ7SNpV0ghgOjB7IDOQdJSkWStWrBiUDJqZWTmdaoZ9BfArYE9JSySdEBHPAicD1wN3AVdFxPyBzDciromIE8eOHduJbJqZWRfpyD2giJjRYPgcYE4nlmFmZr3FXfGYmVkRXR2AfA/IzKx3dXUA8j0gM7PepYgonYeWJC0D7h+EWY8DHh2E+Q5Frot+rot+rot+Q7EudomIrn2Sf0gEoMEiaV5ETCmdj27guujnuujnuujnuui8rr4EZ2ZmvcsByMzMitjYA9Cs0hnoIq6Lfq6Lfq6Lfq6LDtuo7wGZmVk5G/sZkJmZFeIAZGZmRfREAJK0taQbJf0x/92qwXjTJC2QtFDSqe1ML+m0PP4CSW+oM8/Zku4cnJINXIm6kHSdpNslzZf01fw69uI2dF1I2kzSjyXdnevivMEvZfsKrRvnSnpA0srBLV1rjcpVSZekC3L6HZJe0Wra9dl3GBARQ/4DfAY4Nf9/KnB+nXGGAfcCuwEjgNuByc2mBybn8UYCu+bph1Xm+Rbg28CdpeugZF0AY/JfAd8DppeuhxJ1AWwGvC6PMwK4GTiydD0UXjcOAnYAVhYue8NyVcZ5I3BtXo8PAv7/YNSJP5U6L52BDq1cC4Ad8v87AAvqjPMq4PrK99OA05pNXx0nf78eeFX+fzRwS17RuikAbfC6qAzblPSa9beVrofSdZGHfwF4d+l66Ib6oHwAaliuyrCLgBm19TWY68jG/umJS3DAdhHxIED+u22dcSYAD1S+L8nDmk3fbJpzgP8HPN2JAnRQibpA0vXAI8BTwNXrX4yOKFIXAJK2BI4Cfrp+ReioYvXRBdrJY6NxerVOiuvI+4A2BEk/Abavk3R6u7OoM6xVG/S600jaF9g9Ij4saVKby++YbqqLF/6JeIOkUcDlwKHAjW3mZb10Y11IGg5cAVwQEYvazEdHdGN9dIl28thonF6tk+KGTACKiMMapUl6WNIOEfGgpB1IR+K1lgA7Vb5PBJbm/xtN32iaVwH7S1pMqsNtJc2NiKnrULQB67K6qObrL5JmA0ezgQJQl9bFLOCPEfH5gZVm/XVpfXSDdvLYaJwRTaYdynVSXK9cgpsNzMz/zwR+WGecW4E9JO0qaQQwPU/XbPrZwHRJIyXtCuwB/CYivhIRO0bEJOA1wD0bKvi0YYPWhaTRecPrO/J/I3B3h8u0rjZoXQBI+iQwFvhQZ4vSERu8PrpIs3L1mQ28I7eGOwhYkS+r9WqdlFf6JlQnPsA2pGvtf8x/t87DdwTmVMZ7I3APqUXK6a2mz2mn5/EXUKdFEzCJ7mqEsEHrAtiOtIHeAcwHvggML10PhepiIukyy13A7/LnXaXroeR2QmoltgR4Pv/9RMHyr1Uu4CTgpPy/gAtz+u+BKYNRJ/70f9wVj5mZFdErl+DMzGyIcQAyM7MiHIDMzKwIByAzMyvCAcjMzIpwADIzsyIcgMzMrIj/Bn+5M5yFA3t7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = tree.inner_nodes.weight.cpu().detach().numpy()\n",
    "for i in range(0, weights.shape[0], 20):\n",
    "    plt.figure()\n",
    "    weights_layer = weights[i, :]\n",
    "    plt.hist(weights_layer, bins=500)\n",
    "    weights_std = np.std(weights_layer)\n",
    "    weights_mean = np.mean(weights_layer)\n",
    "    plt.axvline(weights_mean + weights_std, color='r')\n",
    "    plt.axvline(weights_mean - weights_std, color='r')\n",
    "    plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\\n Kurtosis: {kurtosis(weights_layer)}\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the accuracy didn't change too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2d39b7a9c923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree_copy' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "tree_copy = tree_copy.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = tree_copy.forward(data)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.view(-1).data).sum()\n",
    "\n",
    "print(f\"Accuracy: {correct / len(tree_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tree_copy.inner_nodes.weight.cpu().detach().numpy()\n",
    "for i in range(0, weights.shape[0], 20):\n",
    "    plt.figure()\n",
    "    weights_layer = weights[i, :]\n",
    "    plt.hist(weights_layer, bins=500)\n",
    "    weights_std = np.std(weights_layer)\n",
    "    weights_mean = np.mean(weights_layer)\n",
    "    plt.axvline(weights_mean + weights_std, color='r')\n",
    "    plt.axvline(weights_mean - weights_std, color='r')\n",
    "    plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stack = LifoQueue()\n",
    "edge_stack = LifoQueue()\n",
    "stack.put(root)\n",
    "rule_counter = 0\n",
    "root.reset()\n",
    "while not stack.empty():\n",
    "    node = stack.get()\n",
    "    if node.is_leaf():\n",
    "        print(f\"============== Rule {rule_counter} ==============\")\n",
    "        for stack_node, cond in zip(stack.queue, edge_stack.queue[1:]):\n",
    "            print(repr(stack_node.get_condition(attr_names)) + cond)\n",
    "            print()\n",
    "        \n",
    "        rule_counter += 1\n",
    "        edge_stack.get()\n",
    "        continue\n",
    "          \n",
    "    if node.left is not None and not node.left.visited:\n",
    "        stack.put(node)\n",
    "        stack.put(node.left)\n",
    "        node.left.visited = True\n",
    "        edge_stack.put(' < 0')\n",
    "        continue\n",
    "        \n",
    "    if node.right is not None and not node.right.visited:\n",
    "        stack.put(node)\n",
    "        stack.put(node.right)\n",
    "        node.right.visited = True\n",
    "        edge_stack.put(' > 0')\n",
    "        continue\n",
    "        \n",
    "    if node is not root:\n",
    "        edge_stack.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
