{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from queue import LifoQueue\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import network.cpc\n",
    "from network.cpc import CDCK2\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from utils.ClassificationUtiols import onehot_coding\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn import tree as tt\n",
    "\n",
    "# IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: /home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_128/models/epoch_40.pt\n",
      "sensor names: (18 total)\n",
      "- speed\n",
      "- steering_angle\n",
      "- wheel_speed_0\n",
      "- wheel_speed_1\n",
      "- wheel_speed_2\n",
      "- wheel_speed_3\n",
      "- accelerometer_0\n",
      "- accelerometer_1\n",
      "- accelerometer_2\n",
      "- gyro_0\n",
      "- gyro_1\n",
      "- gyro_2\n",
      "- gyro_bias_0\n",
      "- gyro_bias_1\n",
      "- gyro_bias_2\n",
      "- gyro_uncalibrated_0\n",
      "- gyro_uncalibrated_1\n",
      "- gyro_uncalibrated_2\n",
      "Multihorizon size of the model: 30\n",
      "Test split ratio: 0.2\n",
      "Total number of windows in the dataset (without splitting): 101465\n"
     ]
    }
   ],
   "source": [
    "model_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_128/models/epoch_40.pt'\n",
    "dataset_path = r'/home/eitan.k/EntangledExplainableClustering/knn_loss_batch_512_k_128/data/test_data_protocol_4.file'\n",
    "\n",
    "print(f\"Load the model from: {model_path}\")\n",
    "model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "with open(dataset_path, 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "all_sensors = dataset.dataset.all_signals    \n",
    "print(f\"sensor names: ({len(all_sensors)} total)\")\n",
    "\n",
    "for s in all_sensors:\n",
    "    print(f\"- {s}\")\n",
    "    \n",
    "print(f\"Multihorizon size of the model: {model.timestep}\")\n",
    "print(f\"Test split ratio: {len(dataset) / len(dataset.dataset)}\")\n",
    "print(f\"Total number of windows in the dataset (without splitting): {len(dataset.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f69e3853ba4b6089c832815d394c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projections = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "device = 'cuda'\n",
    "model = model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(total=len(loader.dataset))\n",
    "    for batch in loader:\n",
    "        hidden = CDCK2.init_hidden(len(batch))\n",
    "        batch = batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        y = model.predict(batch, hidden).detach().cpu()\n",
    "        projections = torch.cat([projections, y.detach().cpu()])\n",
    "        samples = torch.cat([samples, batch.detach().cpu()])\n",
    "        bar.update(y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM and calculate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce615fa16964db4aa9307eefd587325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "best_score = float('inf')\n",
    "clusters = None\n",
    "range_ = list(range(5, 20))\n",
    "for k in tqdm(range_):\n",
    "    y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "    cur_score = davies_bouldin_score(projections, y)\n",
    "    scores.append(cur_score)\n",
    "    \n",
    "    if cur_score < best_score:\n",
    "        best_score = cur_score\n",
    "        clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('DB Score')\n",
    "plt.plot(range_, scores)\n",
    "best_k = range_[np.argmin(scores)]\n",
    "plt.axvline(best_k, color='r')\n",
    "plt.show()\n",
    "\n",
    "labels = set(clusters)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 200\n",
    "\n",
    "p = reduce_dims_and_plot(projections,\n",
    "                         y=clusters,\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnormalized_samples = samples.clone()\n",
    "\n",
    "# for col, sensor in enumerate(tqdm(dataset.dataset.all_signals)):\n",
    "#     denormalizer = dataset.dataset.get_denormalization_for_sensor(sensor)\n",
    "#     unnormalized_samples[:, col, :] = denormalizer(unnormalized_samples[:, col, :])\n",
    "\n",
    "sampled = samples[..., range(0, samples.shape[-1], 200)]\n",
    "\n",
    "samples_f = sampled.flatten(1)\n",
    "tree_dataset = list(zip(samples_f, clusters))\n",
    "batch_size = 2000\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 500\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "tree_depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT accuracy: 0.9326368698566008\n"
     ]
    }
   ],
   "source": [
    "tree = SDT(input_dim=samples_f.shape[1], output_dim=len(labels), depth=tree_depth, lamda=1e-3, use_cuda=True)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)\n",
    "clf = DecisionTreeClassifier(max_depth=tree_depth).fit(samples_f, clusters)\n",
    "print(f\"DT accuracy: {clf.score(samples_f, clusters)}\")\n",
    "tree.initialize_from_decision_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.5817354566135847\n",
      "layer 0: 0.988950276243094\n",
      "layer 1: 0.988950276243094\n",
      "layer 2: 0.988950276243094\n",
      "layer 3: 0.988950276243094\n",
      "layer 4: 0.988950276243094\n",
      "layer 5: 0.8344267955801106\n",
      "layer 6: 0.6335462707182321\n",
      "Epoch: 00 | Batch: 000 / 011 | Total loss: 1.612 | Reg loss: 0.016 | Tree loss: 1.612 | Accuracy: 0.287000 | 1.423 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 011 | Total loss: 1.594 | Reg loss: 0.016 | Tree loss: 1.594 | Accuracy: 0.250500 | 0.818 sec/iter\n",
      "Epoch: 00 | Batch: 002 / 011 | Total loss: 1.578 | Reg loss: 0.016 | Tree loss: 1.578 | Accuracy: 0.319500 | 0.619 sec/iter\n",
      "Epoch: 00 | Batch: 003 / 011 | Total loss: 1.560 | Reg loss: 0.016 | Tree loss: 1.560 | Accuracy: 0.423500 | 0.52 sec/iter\n",
      "Epoch: 00 | Batch: 004 / 011 | Total loss: 1.541 | Reg loss: 0.016 | Tree loss: 1.541 | Accuracy: 0.435500 | 0.459 sec/iter\n",
      "Epoch: 00 | Batch: 005 / 011 | Total loss: 1.535 | Reg loss: 0.016 | Tree loss: 1.535 | Accuracy: 0.404500 | 0.418 sec/iter\n",
      "Epoch: 00 | Batch: 006 / 011 | Total loss: 1.519 | Reg loss: 0.016 | Tree loss: 1.519 | Accuracy: 0.396000 | 0.389 sec/iter\n",
      "Epoch: 00 | Batch: 007 / 011 | Total loss: 1.507 | Reg loss: 0.016 | Tree loss: 1.507 | Accuracy: 0.416000 | 0.367 sec/iter\n",
      "Epoch: 00 | Batch: 008 / 011 | Total loss: 1.512 | Reg loss: 0.016 | Tree loss: 1.512 | Accuracy: 0.393500 | 0.349 sec/iter\n",
      "Epoch: 00 | Batch: 009 / 011 | Total loss: 1.510 | Reg loss: 0.016 | Tree loss: 1.510 | Accuracy: 0.395500 | 0.336 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 011 | Total loss: 1.502 | Reg loss: 0.016 | Tree loss: 1.502 | Accuracy: 0.385666 | 0.325 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 01 | Batch: 000 / 011 | Total loss: 1.590 | Reg loss: 0.015 | Tree loss: 1.590 | Accuracy: 0.360000 | 0.509 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 011 | Total loss: 1.578 | Reg loss: 0.015 | Tree loss: 1.578 | Accuracy: 0.423000 | 0.487 sec/iter\n",
      "Epoch: 01 | Batch: 002 / 011 | Total loss: 1.567 | Reg loss: 0.015 | Tree loss: 1.567 | Accuracy: 0.458000 | 0.468 sec/iter\n",
      "Epoch: 01 | Batch: 003 / 011 | Total loss: 1.552 | Reg loss: 0.015 | Tree loss: 1.552 | Accuracy: 0.483500 | 0.451 sec/iter\n",
      "Epoch: 01 | Batch: 004 / 011 | Total loss: 1.538 | Reg loss: 0.015 | Tree loss: 1.538 | Accuracy: 0.483000 | 0.437 sec/iter\n",
      "Epoch: 01 | Batch: 005 / 011 | Total loss: 1.523 | Reg loss: 0.015 | Tree loss: 1.523 | Accuracy: 0.493500 | 0.424 sec/iter\n",
      "Epoch: 01 | Batch: 006 / 011 | Total loss: 1.513 | Reg loss: 0.015 | Tree loss: 1.513 | Accuracy: 0.471500 | 0.413 sec/iter\n",
      "Epoch: 01 | Batch: 007 / 011 | Total loss: 1.507 | Reg loss: 0.016 | Tree loss: 1.507 | Accuracy: 0.427500 | 0.41 sec/iter\n",
      "Epoch: 01 | Batch: 008 / 011 | Total loss: 1.494 | Reg loss: 0.016 | Tree loss: 1.494 | Accuracy: 0.436500 | 0.401 sec/iter\n",
      "Epoch: 01 | Batch: 009 / 011 | Total loss: 1.484 | Reg loss: 0.016 | Tree loss: 1.484 | Accuracy: 0.421500 | 0.392 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 011 | Total loss: 1.477 | Reg loss: 0.016 | Tree loss: 1.477 | Accuracy: 0.412969 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 02 | Batch: 000 / 011 | Total loss: 1.571 | Reg loss: 0.015 | Tree loss: 1.571 | Accuracy: 0.414000 | 0.478 sec/iter\n",
      "Epoch: 02 | Batch: 001 / 011 | Total loss: 1.560 | Reg loss: 0.015 | Tree loss: 1.560 | Accuracy: 0.430000 | 0.467 sec/iter\n",
      "Epoch: 02 | Batch: 002 / 011 | Total loss: 1.542 | Reg loss: 0.015 | Tree loss: 1.542 | Accuracy: 0.477500 | 0.457 sec/iter\n",
      "Epoch: 02 | Batch: 003 / 011 | Total loss: 1.529 | Reg loss: 0.015 | Tree loss: 1.529 | Accuracy: 0.449000 | 0.448 sec/iter\n",
      "Epoch: 02 | Batch: 004 / 011 | Total loss: 1.520 | Reg loss: 0.015 | Tree loss: 1.520 | Accuracy: 0.419500 | 0.439 sec/iter\n",
      "Epoch: 02 | Batch: 005 / 011 | Total loss: 1.501 | Reg loss: 0.015 | Tree loss: 1.501 | Accuracy: 0.415000 | 0.432 sec/iter\n",
      "Epoch: 02 | Batch: 006 / 011 | Total loss: 1.494 | Reg loss: 0.015 | Tree loss: 1.494 | Accuracy: 0.381500 | 0.424 sec/iter\n",
      "Epoch: 02 | Batch: 007 / 011 | Total loss: 1.478 | Reg loss: 0.016 | Tree loss: 1.478 | Accuracy: 0.411500 | 0.417 sec/iter\n",
      "Epoch: 02 | Batch: 008 / 011 | Total loss: 1.477 | Reg loss: 0.016 | Tree loss: 1.477 | Accuracy: 0.387500 | 0.41 sec/iter\n",
      "Epoch: 02 | Batch: 009 / 011 | Total loss: 1.469 | Reg loss: 0.016 | Tree loss: 1.469 | Accuracy: 0.402000 | 0.404 sec/iter\n",
      "Epoch: 02 | Batch: 010 / 011 | Total loss: 1.461 | Reg loss: 0.016 | Tree loss: 1.461 | Accuracy: 0.416382 | 0.398 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 03 | Batch: 000 / 011 | Total loss: 1.555 | Reg loss: 0.015 | Tree loss: 1.555 | Accuracy: 0.412500 | 0.461 sec/iter\n",
      "Epoch: 03 | Batch: 001 / 011 | Total loss: 1.542 | Reg loss: 0.015 | Tree loss: 1.542 | Accuracy: 0.437000 | 0.454 sec/iter\n",
      "Epoch: 03 | Batch: 002 / 011 | Total loss: 1.529 | Reg loss: 0.015 | Tree loss: 1.529 | Accuracy: 0.446500 | 0.447 sec/iter\n",
      "Epoch: 03 | Batch: 003 / 011 | Total loss: 1.515 | Reg loss: 0.015 | Tree loss: 1.515 | Accuracy: 0.450000 | 0.441 sec/iter\n",
      "Epoch: 03 | Batch: 004 / 011 | Total loss: 1.503 | Reg loss: 0.015 | Tree loss: 1.503 | Accuracy: 0.429500 | 0.435 sec/iter\n",
      "Epoch: 03 | Batch: 005 / 011 | Total loss: 1.478 | Reg loss: 0.015 | Tree loss: 1.478 | Accuracy: 0.432500 | 0.43 sec/iter\n",
      "Epoch: 03 | Batch: 006 / 011 | Total loss: 1.479 | Reg loss: 0.016 | Tree loss: 1.479 | Accuracy: 0.404500 | 0.425 sec/iter\n",
      "Epoch: 03 | Batch: 007 / 011 | Total loss: 1.473 | Reg loss: 0.016 | Tree loss: 1.473 | Accuracy: 0.391000 | 0.42 sec/iter\n",
      "Epoch: 03 | Batch: 008 / 011 | Total loss: 1.451 | Reg loss: 0.016 | Tree loss: 1.451 | Accuracy: 0.422500 | 0.415 sec/iter\n",
      "Epoch: 03 | Batch: 009 / 011 | Total loss: 1.444 | Reg loss: 0.016 | Tree loss: 1.444 | Accuracy: 0.421000 | 0.411 sec/iter\n",
      "Epoch: 03 | Batch: 010 / 011 | Total loss: 1.469 | Reg loss: 0.016 | Tree loss: 1.469 | Accuracy: 0.368601 | 0.406 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 04 | Batch: 000 / 011 | Total loss: 1.537 | Reg loss: 0.015 | Tree loss: 1.537 | Accuracy: 0.421000 | 0.453 sec/iter\n",
      "Epoch: 04 | Batch: 001 / 011 | Total loss: 1.521 | Reg loss: 0.015 | Tree loss: 1.521 | Accuracy: 0.427500 | 0.448 sec/iter\n",
      "Epoch: 04 | Batch: 002 / 011 | Total loss: 1.514 | Reg loss: 0.015 | Tree loss: 1.514 | Accuracy: 0.438000 | 0.443 sec/iter\n",
      "Epoch: 04 | Batch: 003 / 011 | Total loss: 1.497 | Reg loss: 0.015 | Tree loss: 1.497 | Accuracy: 0.444500 | 0.439 sec/iter\n",
      "Epoch: 04 | Batch: 004 / 011 | Total loss: 1.486 | Reg loss: 0.016 | Tree loss: 1.486 | Accuracy: 0.418500 | 0.434 sec/iter\n",
      "Epoch: 04 | Batch: 005 / 011 | Total loss: 1.461 | Reg loss: 0.016 | Tree loss: 1.461 | Accuracy: 0.432500 | 0.429 sec/iter\n",
      "Epoch: 04 | Batch: 006 / 011 | Total loss: 1.457 | Reg loss: 0.016 | Tree loss: 1.457 | Accuracy: 0.412500 | 0.425 sec/iter\n",
      "Epoch: 04 | Batch: 007 / 011 | Total loss: 1.432 | Reg loss: 0.016 | Tree loss: 1.432 | Accuracy: 0.438000 | 0.42 sec/iter\n",
      "Epoch: 04 | Batch: 008 / 011 | Total loss: 1.437 | Reg loss: 0.016 | Tree loss: 1.437 | Accuracy: 0.420000 | 0.416 sec/iter\n",
      "Epoch: 04 | Batch: 009 / 011 | Total loss: 1.439 | Reg loss: 0.017 | Tree loss: 1.439 | Accuracy: 0.405000 | 0.412 sec/iter\n",
      "Epoch: 04 | Batch: 010 / 011 | Total loss: 1.458 | Reg loss: 0.017 | Tree loss: 1.458 | Accuracy: 0.358362 | 0.409 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Batch: 000 / 011 | Total loss: 1.520 | Reg loss: 0.015 | Tree loss: 1.520 | Accuracy: 0.406500 | 0.447 sec/iter\n",
      "Epoch: 05 | Batch: 001 / 011 | Total loss: 1.511 | Reg loss: 0.016 | Tree loss: 1.511 | Accuracy: 0.415000 | 0.443 sec/iter\n",
      "Epoch: 05 | Batch: 002 / 011 | Total loss: 1.486 | Reg loss: 0.016 | Tree loss: 1.486 | Accuracy: 0.447000 | 0.439 sec/iter\n",
      "Epoch: 05 | Batch: 003 / 011 | Total loss: 1.475 | Reg loss: 0.016 | Tree loss: 1.475 | Accuracy: 0.452500 | 0.435 sec/iter\n",
      "Epoch: 05 | Batch: 004 / 011 | Total loss: 1.461 | Reg loss: 0.016 | Tree loss: 1.461 | Accuracy: 0.453500 | 0.431 sec/iter\n",
      "Epoch: 05 | Batch: 005 / 011 | Total loss: 1.456 | Reg loss: 0.016 | Tree loss: 1.456 | Accuracy: 0.419500 | 0.428 sec/iter\n",
      "Epoch: 05 | Batch: 006 / 011 | Total loss: 1.442 | Reg loss: 0.016 | Tree loss: 1.442 | Accuracy: 0.418500 | 0.425 sec/iter\n",
      "Epoch: 05 | Batch: 007 / 011 | Total loss: 1.433 | Reg loss: 0.017 | Tree loss: 1.433 | Accuracy: 0.423000 | 0.421 sec/iter\n",
      "Epoch: 05 | Batch: 008 / 011 | Total loss: 1.410 | Reg loss: 0.017 | Tree loss: 1.410 | Accuracy: 0.437500 | 0.418 sec/iter\n",
      "Epoch: 05 | Batch: 009 / 011 | Total loss: 1.398 | Reg loss: 0.017 | Tree loss: 1.398 | Accuracy: 0.462000 | 0.415 sec/iter\n",
      "Epoch: 05 | Batch: 010 / 011 | Total loss: 1.383 | Reg loss: 0.017 | Tree loss: 1.383 | Accuracy: 0.464164 | 0.412 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 06 | Batch: 000 / 011 | Total loss: 1.505 | Reg loss: 0.016 | Tree loss: 1.505 | Accuracy: 0.416500 | 0.444 sec/iter\n",
      "Epoch: 06 | Batch: 001 / 011 | Total loss: 1.491 | Reg loss: 0.016 | Tree loss: 1.491 | Accuracy: 0.409000 | 0.44 sec/iter\n",
      "Epoch: 06 | Batch: 002 / 011 | Total loss: 1.477 | Reg loss: 0.016 | Tree loss: 1.477 | Accuracy: 0.413000 | 0.437 sec/iter\n",
      "Epoch: 06 | Batch: 003 / 011 | Total loss: 1.452 | Reg loss: 0.016 | Tree loss: 1.452 | Accuracy: 0.449500 | 0.434 sec/iter\n",
      "Epoch: 06 | Batch: 004 / 011 | Total loss: 1.438 | Reg loss: 0.016 | Tree loss: 1.438 | Accuracy: 0.443000 | 0.431 sec/iter\n",
      "Epoch: 06 | Batch: 005 / 011 | Total loss: 1.422 | Reg loss: 0.017 | Tree loss: 1.422 | Accuracy: 0.428000 | 0.428 sec/iter\n",
      "Epoch: 06 | Batch: 006 / 011 | Total loss: 1.399 | Reg loss: 0.017 | Tree loss: 1.399 | Accuracy: 0.451500 | 0.425 sec/iter\n",
      "Epoch: 06 | Batch: 007 / 011 | Total loss: 1.402 | Reg loss: 0.017 | Tree loss: 1.402 | Accuracy: 0.431500 | 0.422 sec/iter\n",
      "Epoch: 06 | Batch: 008 / 011 | Total loss: 1.390 | Reg loss: 0.017 | Tree loss: 1.390 | Accuracy: 0.434500 | 0.419 sec/iter\n",
      "Epoch: 06 | Batch: 009 / 011 | Total loss: 1.375 | Reg loss: 0.018 | Tree loss: 1.375 | Accuracy: 0.441000 | 0.416 sec/iter\n",
      "Epoch: 06 | Batch: 010 / 011 | Total loss: 1.381 | Reg loss: 0.018 | Tree loss: 1.381 | Accuracy: 0.440273 | 0.414 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 07 | Batch: 000 / 011 | Total loss: 1.492 | Reg loss: 0.016 | Tree loss: 1.492 | Accuracy: 0.399500 | 0.424 sec/iter\n",
      "Epoch: 07 | Batch: 001 / 011 | Total loss: 1.471 | Reg loss: 0.016 | Tree loss: 1.471 | Accuracy: 0.402500 | 0.421 sec/iter\n",
      "Epoch: 07 | Batch: 002 / 011 | Total loss: 1.449 | Reg loss: 0.017 | Tree loss: 1.449 | Accuracy: 0.442500 | 0.418 sec/iter\n",
      "Epoch: 07 | Batch: 003 / 011 | Total loss: 1.434 | Reg loss: 0.017 | Tree loss: 1.434 | Accuracy: 0.434500 | 0.416 sec/iter\n",
      "Epoch: 07 | Batch: 004 / 011 | Total loss: 1.416 | Reg loss: 0.017 | Tree loss: 1.416 | Accuracy: 0.447500 | 0.413 sec/iter\n",
      "Epoch: 07 | Batch: 005 / 011 | Total loss: 1.396 | Reg loss: 0.017 | Tree loss: 1.396 | Accuracy: 0.482000 | 0.411 sec/iter\n",
      "Epoch: 07 | Batch: 006 / 011 | Total loss: 1.383 | Reg loss: 0.017 | Tree loss: 1.383 | Accuracy: 0.484000 | 0.408 sec/iter\n",
      "Epoch: 07 | Batch: 007 / 011 | Total loss: 1.369 | Reg loss: 0.018 | Tree loss: 1.369 | Accuracy: 0.496000 | 0.406 sec/iter\n",
      "Epoch: 07 | Batch: 008 / 011 | Total loss: 1.354 | Reg loss: 0.018 | Tree loss: 1.354 | Accuracy: 0.490000 | 0.404 sec/iter\n",
      "Epoch: 07 | Batch: 009 / 011 | Total loss: 1.348 | Reg loss: 0.018 | Tree loss: 1.348 | Accuracy: 0.481500 | 0.402 sec/iter\n",
      "Epoch: 07 | Batch: 010 / 011 | Total loss: 1.364 | Reg loss: 0.018 | Tree loss: 1.364 | Accuracy: 0.477816 | 0.399 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 08 | Batch: 000 / 011 | Total loss: 1.475 | Reg loss: 0.017 | Tree loss: 1.475 | Accuracy: 0.393500 | 0.398 sec/iter\n",
      "Epoch: 08 | Batch: 001 / 011 | Total loss: 1.462 | Reg loss: 0.017 | Tree loss: 1.462 | Accuracy: 0.404000 | 0.396 sec/iter\n",
      "Epoch: 08 | Batch: 002 / 011 | Total loss: 1.431 | Reg loss: 0.017 | Tree loss: 1.431 | Accuracy: 0.441000 | 0.394 sec/iter\n",
      "Epoch: 08 | Batch: 003 / 011 | Total loss: 1.410 | Reg loss: 0.017 | Tree loss: 1.410 | Accuracy: 0.459500 | 0.392 sec/iter\n",
      "Epoch: 08 | Batch: 004 / 011 | Total loss: 1.388 | Reg loss: 0.017 | Tree loss: 1.388 | Accuracy: 0.448000 | 0.39 sec/iter\n",
      "Epoch: 08 | Batch: 005 / 011 | Total loss: 1.365 | Reg loss: 0.018 | Tree loss: 1.365 | Accuracy: 0.490500 | 0.388 sec/iter\n",
      "Epoch: 08 | Batch: 006 / 011 | Total loss: 1.344 | Reg loss: 0.018 | Tree loss: 1.344 | Accuracy: 0.513000 | 0.386 sec/iter\n",
      "Epoch: 08 | Batch: 007 / 011 | Total loss: 1.335 | Reg loss: 0.018 | Tree loss: 1.335 | Accuracy: 0.500000 | 0.385 sec/iter\n",
      "Epoch: 08 | Batch: 008 / 011 | Total loss: 1.323 | Reg loss: 0.018 | Tree loss: 1.323 | Accuracy: 0.510000 | 0.383 sec/iter\n",
      "Epoch: 08 | Batch: 009 / 011 | Total loss: 1.318 | Reg loss: 0.019 | Tree loss: 1.318 | Accuracy: 0.487000 | 0.381 sec/iter\n",
      "Epoch: 08 | Batch: 010 / 011 | Total loss: 1.309 | Reg loss: 0.019 | Tree loss: 1.309 | Accuracy: 0.481229 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 09 | Batch: 000 / 011 | Total loss: 1.457 | Reg loss: 0.017 | Tree loss: 1.457 | Accuracy: 0.402000 | 0.401 sec/iter\n",
      "Epoch: 09 | Batch: 001 / 011 | Total loss: 1.431 | Reg loss: 0.017 | Tree loss: 1.431 | Accuracy: 0.424000 | 0.399 sec/iter\n",
      "Epoch: 09 | Batch: 002 / 011 | Total loss: 1.404 | Reg loss: 0.018 | Tree loss: 1.404 | Accuracy: 0.460000 | 0.397 sec/iter\n",
      "Epoch: 09 | Batch: 003 / 011 | Total loss: 1.385 | Reg loss: 0.018 | Tree loss: 1.385 | Accuracy: 0.480000 | 0.396 sec/iter\n",
      "Epoch: 09 | Batch: 004 / 011 | Total loss: 1.363 | Reg loss: 0.018 | Tree loss: 1.363 | Accuracy: 0.495000 | 0.394 sec/iter\n",
      "Epoch: 09 | Batch: 005 / 011 | Total loss: 1.346 | Reg loss: 0.018 | Tree loss: 1.346 | Accuracy: 0.491000 | 0.392 sec/iter\n",
      "Epoch: 09 | Batch: 006 / 011 | Total loss: 1.320 | Reg loss: 0.018 | Tree loss: 1.320 | Accuracy: 0.537000 | 0.391 sec/iter\n",
      "Epoch: 09 | Batch: 007 / 011 | Total loss: 1.312 | Reg loss: 0.019 | Tree loss: 1.312 | Accuracy: 0.523000 | 0.389 sec/iter\n",
      "Epoch: 09 | Batch: 008 / 011 | Total loss: 1.296 | Reg loss: 0.019 | Tree loss: 1.296 | Accuracy: 0.509000 | 0.387 sec/iter\n",
      "Epoch: 09 | Batch: 009 / 011 | Total loss: 1.299 | Reg loss: 0.019 | Tree loss: 1.299 | Accuracy: 0.492000 | 0.386 sec/iter\n",
      "Epoch: 09 | Batch: 010 / 011 | Total loss: 1.305 | Reg loss: 0.019 | Tree loss: 1.305 | Accuracy: 0.467577 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 10 | Batch: 000 / 011 | Total loss: 1.442 | Reg loss: 0.018 | Tree loss: 1.442 | Accuracy: 0.391500 | 0.401 sec/iter\n",
      "Epoch: 10 | Batch: 001 / 011 | Total loss: 1.414 | Reg loss: 0.018 | Tree loss: 1.414 | Accuracy: 0.436500 | 0.399 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Batch: 002 / 011 | Total loss: 1.380 | Reg loss: 0.018 | Tree loss: 1.380 | Accuracy: 0.487000 | 0.398 sec/iter\n",
      "Epoch: 10 | Batch: 003 / 011 | Total loss: 1.356 | Reg loss: 0.018 | Tree loss: 1.356 | Accuracy: 0.506000 | 0.396 sec/iter\n",
      "Epoch: 10 | Batch: 004 / 011 | Total loss: 1.344 | Reg loss: 0.018 | Tree loss: 1.344 | Accuracy: 0.507000 | 0.394 sec/iter\n",
      "Epoch: 10 | Batch: 005 / 011 | Total loss: 1.315 | Reg loss: 0.019 | Tree loss: 1.315 | Accuracy: 0.556000 | 0.393 sec/iter\n",
      "Epoch: 10 | Batch: 006 / 011 | Total loss: 1.299 | Reg loss: 0.019 | Tree loss: 1.299 | Accuracy: 0.547000 | 0.391 sec/iter\n",
      "Epoch: 10 | Batch: 007 / 011 | Total loss: 1.291 | Reg loss: 0.019 | Tree loss: 1.291 | Accuracy: 0.540500 | 0.389 sec/iter\n",
      "Epoch: 10 | Batch: 008 / 011 | Total loss: 1.278 | Reg loss: 0.019 | Tree loss: 1.278 | Accuracy: 0.547000 | 0.388 sec/iter\n",
      "Epoch: 10 | Batch: 009 / 011 | Total loss: 1.270 | Reg loss: 0.020 | Tree loss: 1.270 | Accuracy: 0.534000 | 0.387 sec/iter\n",
      "Epoch: 10 | Batch: 010 / 011 | Total loss: 1.239 | Reg loss: 0.020 | Tree loss: 1.239 | Accuracy: 0.559727 | 0.385 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 11 | Batch: 000 / 011 | Total loss: 1.420 | Reg loss: 0.018 | Tree loss: 1.420 | Accuracy: 0.437000 | 0.403 sec/iter\n",
      "Epoch: 11 | Batch: 001 / 011 | Total loss: 1.391 | Reg loss: 0.018 | Tree loss: 1.391 | Accuracy: 0.463000 | 0.401 sec/iter\n",
      "Epoch: 11 | Batch: 002 / 011 | Total loss: 1.362 | Reg loss: 0.019 | Tree loss: 1.362 | Accuracy: 0.455500 | 0.4 sec/iter\n",
      "Epoch: 11 | Batch: 003 / 011 | Total loss: 1.337 | Reg loss: 0.019 | Tree loss: 1.337 | Accuracy: 0.471500 | 0.398 sec/iter\n",
      "Epoch: 11 | Batch: 004 / 011 | Total loss: 1.319 | Reg loss: 0.019 | Tree loss: 1.319 | Accuracy: 0.487500 | 0.397 sec/iter\n",
      "Epoch: 11 | Batch: 005 / 011 | Total loss: 1.297 | Reg loss: 0.019 | Tree loss: 1.297 | Accuracy: 0.497000 | 0.395 sec/iter\n",
      "Epoch: 11 | Batch: 006 / 011 | Total loss: 1.268 | Reg loss: 0.019 | Tree loss: 1.268 | Accuracy: 0.528500 | 0.394 sec/iter\n",
      "Epoch: 11 | Batch: 007 / 011 | Total loss: 1.267 | Reg loss: 0.019 | Tree loss: 1.267 | Accuracy: 0.519000 | 0.393 sec/iter\n",
      "Epoch: 11 | Batch: 008 / 011 | Total loss: 1.238 | Reg loss: 0.020 | Tree loss: 1.238 | Accuracy: 0.522500 | 0.391 sec/iter\n",
      "Epoch: 11 | Batch: 009 / 011 | Total loss: 1.239 | Reg loss: 0.020 | Tree loss: 1.239 | Accuracy: 0.521500 | 0.39 sec/iter\n",
      "Epoch: 11 | Batch: 010 / 011 | Total loss: 1.234 | Reg loss: 0.020 | Tree loss: 1.234 | Accuracy: 0.535836 | 0.389 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 12 | Batch: 000 / 011 | Total loss: 1.400 | Reg loss: 0.019 | Tree loss: 1.400 | Accuracy: 0.450000 | 0.404 sec/iter\n",
      "Epoch: 12 | Batch: 001 / 011 | Total loss: 1.379 | Reg loss: 0.019 | Tree loss: 1.379 | Accuracy: 0.467500 | 0.403 sec/iter\n",
      "Epoch: 12 | Batch: 002 / 011 | Total loss: 1.353 | Reg loss: 0.019 | Tree loss: 1.353 | Accuracy: 0.504000 | 0.401 sec/iter\n",
      "Epoch: 12 | Batch: 003 / 011 | Total loss: 1.323 | Reg loss: 0.019 | Tree loss: 1.323 | Accuracy: 0.543000 | 0.4 sec/iter\n",
      "Epoch: 12 | Batch: 004 / 011 | Total loss: 1.299 | Reg loss: 0.019 | Tree loss: 1.299 | Accuracy: 0.536000 | 0.398 sec/iter\n",
      "Epoch: 12 | Batch: 005 / 011 | Total loss: 1.267 | Reg loss: 0.019 | Tree loss: 1.267 | Accuracy: 0.559000 | 0.397 sec/iter\n",
      "Epoch: 12 | Batch: 006 / 011 | Total loss: 1.249 | Reg loss: 0.020 | Tree loss: 1.249 | Accuracy: 0.554500 | 0.396 sec/iter\n",
      "Epoch: 12 | Batch: 007 / 011 | Total loss: 1.250 | Reg loss: 0.020 | Tree loss: 1.250 | Accuracy: 0.540500 | 0.394 sec/iter\n",
      "Epoch: 12 | Batch: 008 / 011 | Total loss: 1.237 | Reg loss: 0.020 | Tree loss: 1.237 | Accuracy: 0.536500 | 0.393 sec/iter\n",
      "Epoch: 12 | Batch: 009 / 011 | Total loss: 1.216 | Reg loss: 0.020 | Tree loss: 1.216 | Accuracy: 0.560000 | 0.392 sec/iter\n",
      "Epoch: 12 | Batch: 010 / 011 | Total loss: 1.240 | Reg loss: 0.020 | Tree loss: 1.240 | Accuracy: 0.532423 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 13 | Batch: 000 / 011 | Total loss: 1.386 | Reg loss: 0.019 | Tree loss: 1.386 | Accuracy: 0.445000 | 0.405 sec/iter\n",
      "Epoch: 13 | Batch: 001 / 011 | Total loss: 1.354 | Reg loss: 0.019 | Tree loss: 1.354 | Accuracy: 0.482500 | 0.404 sec/iter\n",
      "Epoch: 13 | Batch: 002 / 011 | Total loss: 1.327 | Reg loss: 0.019 | Tree loss: 1.327 | Accuracy: 0.484000 | 0.403 sec/iter\n",
      "Epoch: 13 | Batch: 003 / 011 | Total loss: 1.312 | Reg loss: 0.019 | Tree loss: 1.312 | Accuracy: 0.488500 | 0.401 sec/iter\n",
      "Epoch: 13 | Batch: 004 / 011 | Total loss: 1.267 | Reg loss: 0.020 | Tree loss: 1.267 | Accuracy: 0.510000 | 0.4 sec/iter\n",
      "Epoch: 13 | Batch: 005 / 011 | Total loss: 1.240 | Reg loss: 0.020 | Tree loss: 1.240 | Accuracy: 0.514500 | 0.399 sec/iter\n",
      "Epoch: 13 | Batch: 006 / 011 | Total loss: 1.232 | Reg loss: 0.020 | Tree loss: 1.232 | Accuracy: 0.531000 | 0.398 sec/iter\n",
      "Epoch: 13 | Batch: 007 / 011 | Total loss: 1.220 | Reg loss: 0.020 | Tree loss: 1.220 | Accuracy: 0.535500 | 0.397 sec/iter\n",
      "Epoch: 13 | Batch: 008 / 011 | Total loss: 1.203 | Reg loss: 0.020 | Tree loss: 1.203 | Accuracy: 0.533000 | 0.395 sec/iter\n",
      "Epoch: 13 | Batch: 009 / 011 | Total loss: 1.192 | Reg loss: 0.020 | Tree loss: 1.192 | Accuracy: 0.566000 | 0.394 sec/iter\n",
      "Epoch: 13 | Batch: 010 / 011 | Total loss: 1.166 | Reg loss: 0.021 | Tree loss: 1.166 | Accuracy: 0.559727 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 14 | Batch: 000 / 011 | Total loss: 1.353 | Reg loss: 0.020 | Tree loss: 1.353 | Accuracy: 0.520500 | 0.407 sec/iter\n",
      "Epoch: 14 | Batch: 001 / 011 | Total loss: 1.330 | Reg loss: 0.020 | Tree loss: 1.330 | Accuracy: 0.520500 | 0.406 sec/iter\n",
      "Epoch: 14 | Batch: 002 / 011 | Total loss: 1.310 | Reg loss: 0.020 | Tree loss: 1.310 | Accuracy: 0.517500 | 0.404 sec/iter\n",
      "Epoch: 14 | Batch: 003 / 011 | Total loss: 1.288 | Reg loss: 0.020 | Tree loss: 1.288 | Accuracy: 0.502500 | 0.403 sec/iter\n",
      "Epoch: 14 | Batch: 004 / 011 | Total loss: 1.253 | Reg loss: 0.020 | Tree loss: 1.253 | Accuracy: 0.527000 | 0.402 sec/iter\n",
      "Epoch: 14 | Batch: 005 / 011 | Total loss: 1.241 | Reg loss: 0.020 | Tree loss: 1.241 | Accuracy: 0.520500 | 0.401 sec/iter\n",
      "Epoch: 14 | Batch: 006 / 011 | Total loss: 1.239 | Reg loss: 0.020 | Tree loss: 1.239 | Accuracy: 0.510500 | 0.4 sec/iter\n",
      "Epoch: 14 | Batch: 007 / 011 | Total loss: 1.207 | Reg loss: 0.020 | Tree loss: 1.207 | Accuracy: 0.530500 | 0.398 sec/iter\n",
      "Epoch: 14 | Batch: 008 / 011 | Total loss: 1.221 | Reg loss: 0.021 | Tree loss: 1.221 | Accuracy: 0.498500 | 0.397 sec/iter\n",
      "Epoch: 14 | Batch: 009 / 011 | Total loss: 1.204 | Reg loss: 0.021 | Tree loss: 1.204 | Accuracy: 0.518500 | 0.396 sec/iter\n",
      "Epoch: 14 | Batch: 010 / 011 | Total loss: 1.181 | Reg loss: 0.021 | Tree loss: 1.181 | Accuracy: 0.522184 | 0.395 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 15 | Batch: 000 / 011 | Total loss: 1.342 | Reg loss: 0.020 | Tree loss: 1.342 | Accuracy: 0.517000 | 0.408 sec/iter\n",
      "Epoch: 15 | Batch: 001 / 011 | Total loss: 1.311 | Reg loss: 0.020 | Tree loss: 1.311 | Accuracy: 0.529000 | 0.407 sec/iter\n",
      "Epoch: 15 | Batch: 002 / 011 | Total loss: 1.283 | Reg loss: 0.020 | Tree loss: 1.283 | Accuracy: 0.531500 | 0.406 sec/iter\n",
      "Epoch: 15 | Batch: 003 / 011 | Total loss: 1.266 | Reg loss: 0.020 | Tree loss: 1.266 | Accuracy: 0.513000 | 0.405 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Batch: 004 / 011 | Total loss: 1.231 | Reg loss: 0.020 | Tree loss: 1.231 | Accuracy: 0.554500 | 0.403 sec/iter\n",
      "Epoch: 15 | Batch: 005 / 011 | Total loss: 1.204 | Reg loss: 0.020 | Tree loss: 1.204 | Accuracy: 0.546000 | 0.402 sec/iter\n",
      "Epoch: 15 | Batch: 006 / 011 | Total loss: 1.195 | Reg loss: 0.020 | Tree loss: 1.195 | Accuracy: 0.567500 | 0.401 sec/iter\n",
      "Epoch: 15 | Batch: 007 / 011 | Total loss: 1.179 | Reg loss: 0.021 | Tree loss: 1.179 | Accuracy: 0.580000 | 0.4 sec/iter\n",
      "Epoch: 15 | Batch: 008 / 011 | Total loss: 1.187 | Reg loss: 0.021 | Tree loss: 1.187 | Accuracy: 0.562500 | 0.399 sec/iter\n",
      "Epoch: 15 | Batch: 009 / 011 | Total loss: 1.167 | Reg loss: 0.021 | Tree loss: 1.167 | Accuracy: 0.562500 | 0.398 sec/iter\n",
      "Epoch: 15 | Batch: 010 / 011 | Total loss: 1.154 | Reg loss: 0.021 | Tree loss: 1.154 | Accuracy: 0.587031 | 0.397 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 16 | Batch: 000 / 011 | Total loss: 1.318 | Reg loss: 0.020 | Tree loss: 1.318 | Accuracy: 0.533500 | 0.409 sec/iter\n",
      "Epoch: 16 | Batch: 001 / 011 | Total loss: 1.297 | Reg loss: 0.020 | Tree loss: 1.297 | Accuracy: 0.531500 | 0.408 sec/iter\n",
      "Epoch: 16 | Batch: 002 / 011 | Total loss: 1.277 | Reg loss: 0.020 | Tree loss: 1.277 | Accuracy: 0.525000 | 0.407 sec/iter\n",
      "Epoch: 16 | Batch: 003 / 011 | Total loss: 1.250 | Reg loss: 0.020 | Tree loss: 1.250 | Accuracy: 0.520000 | 0.406 sec/iter\n",
      "Epoch: 16 | Batch: 004 / 011 | Total loss: 1.215 | Reg loss: 0.020 | Tree loss: 1.215 | Accuracy: 0.536000 | 0.404 sec/iter\n",
      "Epoch: 16 | Batch: 005 / 011 | Total loss: 1.185 | Reg loss: 0.021 | Tree loss: 1.185 | Accuracy: 0.556000 | 0.403 sec/iter\n",
      "Epoch: 16 | Batch: 006 / 011 | Total loss: 1.199 | Reg loss: 0.021 | Tree loss: 1.199 | Accuracy: 0.522500 | 0.402 sec/iter\n",
      "Epoch: 16 | Batch: 007 / 011 | Total loss: 1.174 | Reg loss: 0.021 | Tree loss: 1.174 | Accuracy: 0.529500 | 0.402 sec/iter\n",
      "Epoch: 16 | Batch: 008 / 011 | Total loss: 1.151 | Reg loss: 0.021 | Tree loss: 1.151 | Accuracy: 0.556500 | 0.401 sec/iter\n",
      "Epoch: 16 | Batch: 009 / 011 | Total loss: 1.136 | Reg loss: 0.021 | Tree loss: 1.136 | Accuracy: 0.573500 | 0.4 sec/iter\n",
      "Epoch: 16 | Batch: 010 / 011 | Total loss: 1.129 | Reg loss: 0.021 | Tree loss: 1.129 | Accuracy: 0.552901 | 0.399 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 17 | Batch: 000 / 011 | Total loss: 1.305 | Reg loss: 0.020 | Tree loss: 1.305 | Accuracy: 0.533000 | 0.41 sec/iter\n",
      "Epoch: 17 | Batch: 001 / 011 | Total loss: 1.275 | Reg loss: 0.020 | Tree loss: 1.275 | Accuracy: 0.546000 | 0.409 sec/iter\n",
      "Epoch: 17 | Batch: 002 / 011 | Total loss: 1.250 | Reg loss: 0.020 | Tree loss: 1.250 | Accuracy: 0.524000 | 0.408 sec/iter\n",
      "Epoch: 17 | Batch: 003 / 011 | Total loss: 1.202 | Reg loss: 0.021 | Tree loss: 1.202 | Accuracy: 0.581500 | 0.407 sec/iter\n",
      "Epoch: 17 | Batch: 004 / 011 | Total loss: 1.192 | Reg loss: 0.021 | Tree loss: 1.192 | Accuracy: 0.563000 | 0.406 sec/iter\n",
      "Epoch: 17 | Batch: 005 / 011 | Total loss: 1.159 | Reg loss: 0.021 | Tree loss: 1.159 | Accuracy: 0.584500 | 0.405 sec/iter\n",
      "Epoch: 17 | Batch: 006 / 011 | Total loss: 1.138 | Reg loss: 0.021 | Tree loss: 1.138 | Accuracy: 0.588500 | 0.404 sec/iter\n",
      "Epoch: 17 | Batch: 007 / 011 | Total loss: 1.142 | Reg loss: 0.021 | Tree loss: 1.142 | Accuracy: 0.570500 | 0.403 sec/iter\n",
      "Epoch: 17 | Batch: 008 / 011 | Total loss: 1.126 | Reg loss: 0.021 | Tree loss: 1.126 | Accuracy: 0.571000 | 0.402 sec/iter\n",
      "Epoch: 17 | Batch: 009 / 011 | Total loss: 1.143 | Reg loss: 0.021 | Tree loss: 1.143 | Accuracy: 0.556000 | 0.401 sec/iter\n",
      "Epoch: 17 | Batch: 010 / 011 | Total loss: 1.108 | Reg loss: 0.021 | Tree loss: 1.108 | Accuracy: 0.556314 | 0.4 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 18 | Batch: 000 / 011 | Total loss: 1.280 | Reg loss: 0.021 | Tree loss: 1.280 | Accuracy: 0.543000 | 0.411 sec/iter\n",
      "Epoch: 18 | Batch: 001 / 011 | Total loss: 1.247 | Reg loss: 0.021 | Tree loss: 1.247 | Accuracy: 0.545500 | 0.41 sec/iter\n",
      "Epoch: 18 | Batch: 002 / 011 | Total loss: 1.239 | Reg loss: 0.021 | Tree loss: 1.239 | Accuracy: 0.514000 | 0.409 sec/iter\n",
      "Epoch: 18 | Batch: 003 / 011 | Total loss: 1.209 | Reg loss: 0.021 | Tree loss: 1.209 | Accuracy: 0.517000 | 0.408 sec/iter\n",
      "Epoch: 18 | Batch: 004 / 011 | Total loss: 1.183 | Reg loss: 0.021 | Tree loss: 1.183 | Accuracy: 0.512000 | 0.407 sec/iter\n",
      "Epoch: 18 | Batch: 005 / 011 | Total loss: 1.157 | Reg loss: 0.021 | Tree loss: 1.157 | Accuracy: 0.519000 | 0.406 sec/iter\n",
      "Epoch: 18 | Batch: 006 / 011 | Total loss: 1.157 | Reg loss: 0.021 | Tree loss: 1.157 | Accuracy: 0.520500 | 0.405 sec/iter\n",
      "Epoch: 18 | Batch: 007 / 011 | Total loss: 1.138 | Reg loss: 0.021 | Tree loss: 1.138 | Accuracy: 0.511500 | 0.404 sec/iter\n",
      "Epoch: 18 | Batch: 008 / 011 | Total loss: 1.135 | Reg loss: 0.021 | Tree loss: 1.135 | Accuracy: 0.525500 | 0.403 sec/iter\n",
      "Epoch: 18 | Batch: 009 / 011 | Total loss: 1.124 | Reg loss: 0.021 | Tree loss: 1.124 | Accuracy: 0.536000 | 0.402 sec/iter\n",
      "Epoch: 18 | Batch: 010 / 011 | Total loss: 1.089 | Reg loss: 0.022 | Tree loss: 1.089 | Accuracy: 0.556314 | 0.401 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 19 | Batch: 000 / 011 | Total loss: 1.260 | Reg loss: 0.021 | Tree loss: 1.260 | Accuracy: 0.549500 | 0.412 sec/iter\n",
      "Epoch: 19 | Batch: 001 / 011 | Total loss: 1.248 | Reg loss: 0.021 | Tree loss: 1.248 | Accuracy: 0.545500 | 0.411 sec/iter\n",
      "Epoch: 19 | Batch: 002 / 011 | Total loss: 1.208 | Reg loss: 0.021 | Tree loss: 1.208 | Accuracy: 0.545500 | 0.41 sec/iter\n",
      "Epoch: 19 | Batch: 003 / 011 | Total loss: 1.194 | Reg loss: 0.021 | Tree loss: 1.194 | Accuracy: 0.559500 | 0.409 sec/iter\n",
      "Epoch: 19 | Batch: 004 / 011 | Total loss: 1.156 | Reg loss: 0.021 | Tree loss: 1.156 | Accuracy: 0.561000 | 0.408 sec/iter\n",
      "Epoch: 19 | Batch: 005 / 011 | Total loss: 1.119 | Reg loss: 0.021 | Tree loss: 1.119 | Accuracy: 0.596000 | 0.407 sec/iter\n",
      "Epoch: 19 | Batch: 006 / 011 | Total loss: 1.102 | Reg loss: 0.021 | Tree loss: 1.102 | Accuracy: 0.594000 | 0.406 sec/iter\n",
      "Epoch: 19 | Batch: 007 / 011 | Total loss: 1.107 | Reg loss: 0.021 | Tree loss: 1.107 | Accuracy: 0.560000 | 0.405 sec/iter\n",
      "Epoch: 19 | Batch: 008 / 011 | Total loss: 1.083 | Reg loss: 0.021 | Tree loss: 1.083 | Accuracy: 0.574000 | 0.404 sec/iter\n",
      "Epoch: 19 | Batch: 009 / 011 | Total loss: 1.075 | Reg loss: 0.022 | Tree loss: 1.075 | Accuracy: 0.583000 | 0.403 sec/iter\n",
      "Epoch: 19 | Batch: 010 / 011 | Total loss: 1.075 | Reg loss: 0.022 | Tree loss: 1.075 | Accuracy: 0.583618 | 0.403 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 20 | Batch: 000 / 011 | Total loss: 1.246 | Reg loss: 0.021 | Tree loss: 1.246 | Accuracy: 0.537500 | 0.411 sec/iter\n",
      "Epoch: 20 | Batch: 001 / 011 | Total loss: 1.234 | Reg loss: 0.021 | Tree loss: 1.234 | Accuracy: 0.511500 | 0.41 sec/iter\n",
      "Epoch: 20 | Batch: 002 / 011 | Total loss: 1.183 | Reg loss: 0.021 | Tree loss: 1.183 | Accuracy: 0.537000 | 0.409 sec/iter\n",
      "Epoch: 20 | Batch: 003 / 011 | Total loss: 1.176 | Reg loss: 0.021 | Tree loss: 1.176 | Accuracy: 0.508500 | 0.408 sec/iter\n",
      "Epoch: 20 | Batch: 004 / 011 | Total loss: 1.154 | Reg loss: 0.021 | Tree loss: 1.154 | Accuracy: 0.506500 | 0.407 sec/iter\n",
      "Epoch: 20 | Batch: 005 / 011 | Total loss: 1.125 | Reg loss: 0.021 | Tree loss: 1.125 | Accuracy: 0.524000 | 0.406 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Batch: 006 / 011 | Total loss: 1.129 | Reg loss: 0.021 | Tree loss: 1.129 | Accuracy: 0.502500 | 0.406 sec/iter\n",
      "Epoch: 20 | Batch: 007 / 011 | Total loss: 1.109 | Reg loss: 0.021 | Tree loss: 1.109 | Accuracy: 0.528000 | 0.405 sec/iter\n",
      "Epoch: 20 | Batch: 008 / 011 | Total loss: 1.106 | Reg loss: 0.021 | Tree loss: 1.106 | Accuracy: 0.526000 | 0.404 sec/iter\n",
      "Epoch: 20 | Batch: 009 / 011 | Total loss: 1.075 | Reg loss: 0.022 | Tree loss: 1.075 | Accuracy: 0.546500 | 0.403 sec/iter\n",
      "Epoch: 20 | Batch: 010 / 011 | Total loss: 1.036 | Reg loss: 0.022 | Tree loss: 1.036 | Accuracy: 0.587031 | 0.402 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 21 | Batch: 000 / 011 | Total loss: 1.239 | Reg loss: 0.021 | Tree loss: 1.239 | Accuracy: 0.505500 | 0.411 sec/iter\n",
      "Epoch: 21 | Batch: 001 / 011 | Total loss: 1.188 | Reg loss: 0.021 | Tree loss: 1.188 | Accuracy: 0.558500 | 0.41 sec/iter\n",
      "Epoch: 21 | Batch: 002 / 011 | Total loss: 1.159 | Reg loss: 0.021 | Tree loss: 1.159 | Accuracy: 0.577500 | 0.41 sec/iter\n",
      "Epoch: 21 | Batch: 003 / 011 | Total loss: 1.136 | Reg loss: 0.021 | Tree loss: 1.136 | Accuracy: 0.563500 | 0.409 sec/iter\n",
      "Epoch: 21 | Batch: 004 / 011 | Total loss: 1.106 | Reg loss: 0.021 | Tree loss: 1.106 | Accuracy: 0.601500 | 0.408 sec/iter\n",
      "Epoch: 21 | Batch: 005 / 011 | Total loss: 1.094 | Reg loss: 0.021 | Tree loss: 1.094 | Accuracy: 0.578000 | 0.407 sec/iter\n",
      "Epoch: 21 | Batch: 006 / 011 | Total loss: 1.063 | Reg loss: 0.021 | Tree loss: 1.063 | Accuracy: 0.573500 | 0.406 sec/iter\n",
      "Epoch: 21 | Batch: 007 / 011 | Total loss: 1.072 | Reg loss: 0.021 | Tree loss: 1.072 | Accuracy: 0.571000 | 0.406 sec/iter\n",
      "Epoch: 21 | Batch: 008 / 011 | Total loss: 1.074 | Reg loss: 0.022 | Tree loss: 1.074 | Accuracy: 0.559500 | 0.405 sec/iter\n",
      "Epoch: 21 | Batch: 009 / 011 | Total loss: 1.081 | Reg loss: 0.022 | Tree loss: 1.081 | Accuracy: 0.564000 | 0.404 sec/iter\n",
      "Epoch: 21 | Batch: 010 / 011 | Total loss: 1.050 | Reg loss: 0.022 | Tree loss: 1.050 | Accuracy: 0.559727 | 0.403 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 22 | Batch: 000 / 011 | Total loss: 1.213 | Reg loss: 0.021 | Tree loss: 1.213 | Accuracy: 0.521000 | 0.412 sec/iter\n",
      "Epoch: 22 | Batch: 001 / 011 | Total loss: 1.198 | Reg loss: 0.021 | Tree loss: 1.198 | Accuracy: 0.508000 | 0.411 sec/iter\n",
      "Epoch: 22 | Batch: 002 / 011 | Total loss: 1.154 | Reg loss: 0.021 | Tree loss: 1.154 | Accuracy: 0.533000 | 0.41 sec/iter\n",
      "Epoch: 22 | Batch: 003 / 011 | Total loss: 1.152 | Reg loss: 0.021 | Tree loss: 1.152 | Accuracy: 0.511000 | 0.409 sec/iter\n",
      "Epoch: 22 | Batch: 004 / 011 | Total loss: 1.114 | Reg loss: 0.021 | Tree loss: 1.114 | Accuracy: 0.516000 | 0.409 sec/iter\n",
      "Epoch: 22 | Batch: 005 / 011 | Total loss: 1.118 | Reg loss: 0.021 | Tree loss: 1.118 | Accuracy: 0.509500 | 0.408 sec/iter\n",
      "Epoch: 22 | Batch: 006 / 011 | Total loss: 1.101 | Reg loss: 0.021 | Tree loss: 1.101 | Accuracy: 0.529000 | 0.407 sec/iter\n",
      "Epoch: 22 | Batch: 007 / 011 | Total loss: 1.089 | Reg loss: 0.021 | Tree loss: 1.089 | Accuracy: 0.529000 | 0.406 sec/iter\n",
      "Epoch: 22 | Batch: 008 / 011 | Total loss: 1.051 | Reg loss: 0.022 | Tree loss: 1.051 | Accuracy: 0.565500 | 0.406 sec/iter\n",
      "Epoch: 22 | Batch: 009 / 011 | Total loss: 1.059 | Reg loss: 0.022 | Tree loss: 1.059 | Accuracy: 0.567000 | 0.405 sec/iter\n",
      "Epoch: 22 | Batch: 010 / 011 | Total loss: 1.015 | Reg loss: 0.022 | Tree loss: 1.015 | Accuracy: 0.634812 | 0.404 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 23 | Batch: 000 / 011 | Total loss: 1.192 | Reg loss: 0.021 | Tree loss: 1.192 | Accuracy: 0.529500 | 0.412 sec/iter\n",
      "Epoch: 23 | Batch: 001 / 011 | Total loss: 1.166 | Reg loss: 0.021 | Tree loss: 1.166 | Accuracy: 0.536500 | 0.412 sec/iter\n",
      "Epoch: 23 | Batch: 002 / 011 | Total loss: 1.144 | Reg loss: 0.021 | Tree loss: 1.144 | Accuracy: 0.546000 | 0.411 sec/iter\n",
      "Epoch: 23 | Batch: 003 / 011 | Total loss: 1.119 | Reg loss: 0.021 | Tree loss: 1.119 | Accuracy: 0.568000 | 0.41 sec/iter\n",
      "Epoch: 23 | Batch: 004 / 011 | Total loss: 1.070 | Reg loss: 0.021 | Tree loss: 1.070 | Accuracy: 0.585500 | 0.409 sec/iter\n",
      "Epoch: 23 | Batch: 005 / 011 | Total loss: 1.058 | Reg loss: 0.021 | Tree loss: 1.058 | Accuracy: 0.604500 | 0.409 sec/iter\n",
      "Epoch: 23 | Batch: 006 / 011 | Total loss: 1.044 | Reg loss: 0.021 | Tree loss: 1.044 | Accuracy: 0.582500 | 0.408 sec/iter\n",
      "Epoch: 23 | Batch: 007 / 011 | Total loss: 1.036 | Reg loss: 0.021 | Tree loss: 1.036 | Accuracy: 0.581000 | 0.407 sec/iter\n",
      "Epoch: 23 | Batch: 008 / 011 | Total loss: 1.058 | Reg loss: 0.022 | Tree loss: 1.058 | Accuracy: 0.543000 | 0.406 sec/iter\n",
      "Epoch: 23 | Batch: 009 / 011 | Total loss: 1.042 | Reg loss: 0.022 | Tree loss: 1.042 | Accuracy: 0.567500 | 0.406 sec/iter\n",
      "Epoch: 23 | Batch: 010 / 011 | Total loss: 1.033 | Reg loss: 0.022 | Tree loss: 1.033 | Accuracy: 0.532423 | 0.405 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 24 | Batch: 000 / 011 | Total loss: 1.181 | Reg loss: 0.021 | Tree loss: 1.181 | Accuracy: 0.526000 | 0.413 sec/iter\n",
      "Epoch: 24 | Batch: 001 / 011 | Total loss: 1.154 | Reg loss: 0.021 | Tree loss: 1.154 | Accuracy: 0.531000 | 0.412 sec/iter\n",
      "Epoch: 24 | Batch: 002 / 011 | Total loss: 1.140 | Reg loss: 0.021 | Tree loss: 1.140 | Accuracy: 0.511000 | 0.411 sec/iter\n",
      "Epoch: 24 | Batch: 003 / 011 | Total loss: 1.144 | Reg loss: 0.021 | Tree loss: 1.144 | Accuracy: 0.514000 | 0.411 sec/iter\n",
      "Epoch: 24 | Batch: 004 / 011 | Total loss: 1.091 | Reg loss: 0.021 | Tree loss: 1.091 | Accuracy: 0.538500 | 0.41 sec/iter\n",
      "Epoch: 24 | Batch: 005 / 011 | Total loss: 1.084 | Reg loss: 0.021 | Tree loss: 1.084 | Accuracy: 0.525500 | 0.409 sec/iter\n",
      "Epoch: 24 | Batch: 006 / 011 | Total loss: 1.083 | Reg loss: 0.021 | Tree loss: 1.083 | Accuracy: 0.533000 | 0.408 sec/iter\n",
      "Epoch: 24 | Batch: 007 / 011 | Total loss: 1.052 | Reg loss: 0.021 | Tree loss: 1.052 | Accuracy: 0.534500 | 0.408 sec/iter\n",
      "Epoch: 24 | Batch: 008 / 011 | Total loss: 1.038 | Reg loss: 0.022 | Tree loss: 1.038 | Accuracy: 0.558000 | 0.407 sec/iter\n",
      "Epoch: 24 | Batch: 009 / 011 | Total loss: 1.006 | Reg loss: 0.022 | Tree loss: 1.006 | Accuracy: 0.588500 | 0.406 sec/iter\n",
      "Epoch: 24 | Batch: 010 / 011 | Total loss: 1.008 | Reg loss: 0.022 | Tree loss: 1.008 | Accuracy: 0.617747 | 0.406 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 25 | Batch: 000 / 011 | Total loss: 1.179 | Reg loss: 0.021 | Tree loss: 1.179 | Accuracy: 0.516500 | 0.413 sec/iter\n",
      "Epoch: 25 | Batch: 001 / 011 | Total loss: 1.136 | Reg loss: 0.021 | Tree loss: 1.136 | Accuracy: 0.549000 | 0.412 sec/iter\n",
      "Epoch: 25 | Batch: 002 / 011 | Total loss: 1.111 | Reg loss: 0.021 | Tree loss: 1.111 | Accuracy: 0.536500 | 0.412 sec/iter\n",
      "Epoch: 25 | Batch: 003 / 011 | Total loss: 1.084 | Reg loss: 0.021 | Tree loss: 1.084 | Accuracy: 0.578000 | 0.411 sec/iter\n",
      "Epoch: 25 | Batch: 004 / 011 | Total loss: 1.051 | Reg loss: 0.021 | Tree loss: 1.051 | Accuracy: 0.600000 | 0.41 sec/iter\n",
      "Epoch: 25 | Batch: 005 / 011 | Total loss: 1.047 | Reg loss: 0.021 | Tree loss: 1.047 | Accuracy: 0.589500 | 0.41 sec/iter\n",
      "Epoch: 25 | Batch: 006 / 011 | Total loss: 1.046 | Reg loss: 0.021 | Tree loss: 1.046 | Accuracy: 0.571500 | 0.409 sec/iter\n",
      "Epoch: 25 | Batch: 007 / 011 | Total loss: 1.033 | Reg loss: 0.021 | Tree loss: 1.033 | Accuracy: 0.554000 | 0.408 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.022 | Tree loss: 1.011 | Accuracy: 0.562500 | 0.408 sec/iter\n",
      "Epoch: 25 | Batch: 009 / 011 | Total loss: 0.991 | Reg loss: 0.022 | Tree loss: 0.991 | Accuracy: 0.582000 | 0.407 sec/iter\n",
      "Epoch: 25 | Batch: 010 / 011 | Total loss: 1.001 | Reg loss: 0.022 | Tree loss: 1.001 | Accuracy: 0.552901 | 0.406 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 26 | Batch: 000 / 011 | Total loss: 1.149 | Reg loss: 0.021 | Tree loss: 1.149 | Accuracy: 0.540000 | 0.414 sec/iter\n",
      "Epoch: 26 | Batch: 001 / 011 | Total loss: 1.136 | Reg loss: 0.021 | Tree loss: 1.136 | Accuracy: 0.512000 | 0.413 sec/iter\n",
      "Epoch: 26 | Batch: 002 / 011 | Total loss: 1.123 | Reg loss: 0.021 | Tree loss: 1.123 | Accuracy: 0.519500 | 0.412 sec/iter\n",
      "Epoch: 26 | Batch: 003 / 011 | Total loss: 1.092 | Reg loss: 0.021 | Tree loss: 1.092 | Accuracy: 0.514500 | 0.412 sec/iter\n",
      "Epoch: 26 | Batch: 004 / 011 | Total loss: 1.097 | Reg loss: 0.021 | Tree loss: 1.097 | Accuracy: 0.505500 | 0.411 sec/iter\n",
      "Epoch: 26 | Batch: 005 / 011 | Total loss: 1.073 | Reg loss: 0.021 | Tree loss: 1.073 | Accuracy: 0.518000 | 0.41 sec/iter\n",
      "Epoch: 26 | Batch: 006 / 011 | Total loss: 1.086 | Reg loss: 0.021 | Tree loss: 1.086 | Accuracy: 0.522500 | 0.41 sec/iter\n",
      "Epoch: 26 | Batch: 007 / 011 | Total loss: 1.039 | Reg loss: 0.021 | Tree loss: 1.039 | Accuracy: 0.547000 | 0.409 sec/iter\n",
      "Epoch: 26 | Batch: 008 / 011 | Total loss: 1.045 | Reg loss: 0.021 | Tree loss: 1.045 | Accuracy: 0.552500 | 0.408 sec/iter\n",
      "Epoch: 26 | Batch: 009 / 011 | Total loss: 0.998 | Reg loss: 0.022 | Tree loss: 0.998 | Accuracy: 0.568000 | 0.407 sec/iter\n",
      "Epoch: 26 | Batch: 010 / 011 | Total loss: 1.003 | Reg loss: 0.022 | Tree loss: 1.003 | Accuracy: 0.556314 | 0.407 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 27 | Batch: 000 / 011 | Total loss: 1.150 | Reg loss: 0.021 | Tree loss: 1.150 | Accuracy: 0.533000 | 0.412 sec/iter\n",
      "Epoch: 27 | Batch: 001 / 011 | Total loss: 1.114 | Reg loss: 0.021 | Tree loss: 1.114 | Accuracy: 0.542500 | 0.412 sec/iter\n",
      "Epoch: 27 | Batch: 002 / 011 | Total loss: 1.077 | Reg loss: 0.021 | Tree loss: 1.077 | Accuracy: 0.579500 | 0.411 sec/iter\n",
      "Epoch: 27 | Batch: 003 / 011 | Total loss: 1.038 | Reg loss: 0.021 | Tree loss: 1.038 | Accuracy: 0.605000 | 0.41 sec/iter\n",
      "Epoch: 27 | Batch: 004 / 011 | Total loss: 1.041 | Reg loss: 0.021 | Tree loss: 1.041 | Accuracy: 0.577500 | 0.41 sec/iter\n",
      "Epoch: 27 | Batch: 005 / 011 | Total loss: 1.037 | Reg loss: 0.021 | Tree loss: 1.037 | Accuracy: 0.563000 | 0.409 sec/iter\n",
      "Epoch: 27 | Batch: 006 / 011 | Total loss: 1.025 | Reg loss: 0.021 | Tree loss: 1.025 | Accuracy: 0.562500 | 0.408 sec/iter\n",
      "Epoch: 27 | Batch: 007 / 011 | Total loss: 1.031 | Reg loss: 0.021 | Tree loss: 1.031 | Accuracy: 0.536500 | 0.408 sec/iter\n",
      "Epoch: 27 | Batch: 008 / 011 | Total loss: 1.033 | Reg loss: 0.021 | Tree loss: 1.033 | Accuracy: 0.537500 | 0.407 sec/iter\n",
      "Epoch: 27 | Batch: 009 / 011 | Total loss: 0.999 | Reg loss: 0.022 | Tree loss: 0.999 | Accuracy: 0.556000 | 0.406 sec/iter\n",
      "Epoch: 27 | Batch: 010 / 011 | Total loss: 1.028 | Reg loss: 0.022 | Tree loss: 1.028 | Accuracy: 0.552901 | 0.406 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 28 | Batch: 000 / 011 | Total loss: 1.148 | Reg loss: 0.021 | Tree loss: 1.148 | Accuracy: 0.528000 | 0.413 sec/iter\n",
      "Epoch: 28 | Batch: 001 / 011 | Total loss: 1.109 | Reg loss: 0.021 | Tree loss: 1.109 | Accuracy: 0.510500 | 0.412 sec/iter\n",
      "Epoch: 28 | Batch: 002 / 011 | Total loss: 1.106 | Reg loss: 0.021 | Tree loss: 1.106 | Accuracy: 0.505000 | 0.411 sec/iter\n",
      "Epoch: 28 | Batch: 003 / 011 | Total loss: 1.086 | Reg loss: 0.021 | Tree loss: 1.086 | Accuracy: 0.530000 | 0.411 sec/iter\n",
      "Epoch: 28 | Batch: 004 / 011 | Total loss: 1.076 | Reg loss: 0.021 | Tree loss: 1.076 | Accuracy: 0.500500 | 0.41 sec/iter\n",
      "Epoch: 28 | Batch: 005 / 011 | Total loss: 1.086 | Reg loss: 0.021 | Tree loss: 1.086 | Accuracy: 0.508500 | 0.41 sec/iter\n",
      "Epoch: 28 | Batch: 006 / 011 | Total loss: 1.090 | Reg loss: 0.021 | Tree loss: 1.090 | Accuracy: 0.495000 | 0.409 sec/iter\n",
      "Epoch: 28 | Batch: 007 / 011 | Total loss: 1.057 | Reg loss: 0.021 | Tree loss: 1.057 | Accuracy: 0.522500 | 0.408 sec/iter\n",
      "Epoch: 28 | Batch: 008 / 011 | Total loss: 1.050 | Reg loss: 0.021 | Tree loss: 1.050 | Accuracy: 0.546500 | 0.408 sec/iter\n",
      "Epoch: 28 | Batch: 009 / 011 | Total loss: 0.991 | Reg loss: 0.021 | Tree loss: 0.991 | Accuracy: 0.558500 | 0.407 sec/iter\n",
      "Epoch: 28 | Batch: 010 / 011 | Total loss: 1.030 | Reg loss: 0.021 | Tree loss: 1.030 | Accuracy: 0.580205 | 0.406 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 29 | Batch: 000 / 011 | Total loss: 1.128 | Reg loss: 0.021 | Tree loss: 1.128 | Accuracy: 0.546000 | 0.406 sec/iter\n",
      "Epoch: 29 | Batch: 001 / 011 | Total loss: 1.097 | Reg loss: 0.021 | Tree loss: 1.097 | Accuracy: 0.531000 | 0.405 sec/iter\n",
      "Epoch: 29 | Batch: 002 / 011 | Total loss: 1.075 | Reg loss: 0.021 | Tree loss: 1.075 | Accuracy: 0.577500 | 0.405 sec/iter\n",
      "Epoch: 29 | Batch: 003 / 011 | Total loss: 1.048 | Reg loss: 0.021 | Tree loss: 1.048 | Accuracy: 0.581500 | 0.404 sec/iter\n",
      "Epoch: 29 | Batch: 004 / 011 | Total loss: 1.030 | Reg loss: 0.021 | Tree loss: 1.030 | Accuracy: 0.576500 | 0.404 sec/iter\n",
      "Epoch: 29 | Batch: 005 / 011 | Total loss: 1.016 | Reg loss: 0.021 | Tree loss: 1.016 | Accuracy: 0.569500 | 0.403 sec/iter\n",
      "Epoch: 29 | Batch: 006 / 011 | Total loss: 1.019 | Reg loss: 0.021 | Tree loss: 1.019 | Accuracy: 0.544000 | 0.403 sec/iter\n",
      "Epoch: 29 | Batch: 007 / 011 | Total loss: 1.028 | Reg loss: 0.021 | Tree loss: 1.028 | Accuracy: 0.530500 | 0.402 sec/iter\n",
      "Epoch: 29 | Batch: 008 / 011 | Total loss: 0.988 | Reg loss: 0.021 | Tree loss: 0.988 | Accuracy: 0.552000 | 0.401 sec/iter\n",
      "Epoch: 29 | Batch: 009 / 011 | Total loss: 0.982 | Reg loss: 0.021 | Tree loss: 0.982 | Accuracy: 0.566500 | 0.401 sec/iter\n",
      "Epoch: 29 | Batch: 010 / 011 | Total loss: 0.946 | Reg loss: 0.021 | Tree loss: 0.946 | Accuracy: 0.590444 | 0.4 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 30 | Batch: 000 / 011 | Total loss: 1.119 | Reg loss: 0.021 | Tree loss: 1.119 | Accuracy: 0.549500 | 0.4 sec/iter\n",
      "Epoch: 30 | Batch: 001 / 011 | Total loss: 1.097 | Reg loss: 0.021 | Tree loss: 1.097 | Accuracy: 0.523000 | 0.4 sec/iter\n",
      "Epoch: 30 | Batch: 002 / 011 | Total loss: 1.114 | Reg loss: 0.021 | Tree loss: 1.114 | Accuracy: 0.508500 | 0.399 sec/iter\n",
      "Epoch: 30 | Batch: 003 / 011 | Total loss: 1.075 | Reg loss: 0.021 | Tree loss: 1.075 | Accuracy: 0.511500 | 0.398 sec/iter\n",
      "Epoch: 30 | Batch: 004 / 011 | Total loss: 1.076 | Reg loss: 0.021 | Tree loss: 1.076 | Accuracy: 0.514000 | 0.398 sec/iter\n",
      "Epoch: 30 | Batch: 005 / 011 | Total loss: 1.051 | Reg loss: 0.021 | Tree loss: 1.051 | Accuracy: 0.531000 | 0.397 sec/iter\n",
      "Epoch: 30 | Batch: 006 / 011 | Total loss: 1.051 | Reg loss: 0.021 | Tree loss: 1.051 | Accuracy: 0.531500 | 0.397 sec/iter\n",
      "Epoch: 30 | Batch: 007 / 011 | Total loss: 1.045 | Reg loss: 0.021 | Tree loss: 1.045 | Accuracy: 0.544000 | 0.396 sec/iter\n",
      "Epoch: 30 | Batch: 008 / 011 | Total loss: 1.016 | Reg loss: 0.021 | Tree loss: 1.016 | Accuracy: 0.550000 | 0.396 sec/iter\n",
      "Epoch: 30 | Batch: 009 / 011 | Total loss: 0.979 | Reg loss: 0.021 | Tree loss: 0.979 | Accuracy: 0.560000 | 0.395 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Batch: 010 / 011 | Total loss: 0.994 | Reg loss: 0.021 | Tree loss: 0.994 | Accuracy: 0.542662 | 0.395 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 31 | Batch: 000 / 011 | Total loss: 1.119 | Reg loss: 0.021 | Tree loss: 1.119 | Accuracy: 0.530000 | 0.394 sec/iter\n",
      "Epoch: 31 | Batch: 001 / 011 | Total loss: 1.086 | Reg loss: 0.021 | Tree loss: 1.086 | Accuracy: 0.541000 | 0.394 sec/iter\n",
      "Epoch: 31 | Batch: 002 / 011 | Total loss: 1.051 | Reg loss: 0.021 | Tree loss: 1.051 | Accuracy: 0.565000 | 0.393 sec/iter\n",
      "Epoch: 31 | Batch: 003 / 011 | Total loss: 1.029 | Reg loss: 0.021 | Tree loss: 1.029 | Accuracy: 0.584500 | 0.393 sec/iter\n",
      "Epoch: 31 | Batch: 004 / 011 | Total loss: 1.001 | Reg loss: 0.021 | Tree loss: 1.001 | Accuracy: 0.606500 | 0.392 sec/iter\n",
      "Epoch: 31 | Batch: 005 / 011 | Total loss: 1.006 | Reg loss: 0.021 | Tree loss: 1.006 | Accuracy: 0.587000 | 0.392 sec/iter\n",
      "Epoch: 31 | Batch: 006 / 011 | Total loss: 1.005 | Reg loss: 0.021 | Tree loss: 1.005 | Accuracy: 0.557000 | 0.391 sec/iter\n",
      "Epoch: 31 | Batch: 007 / 011 | Total loss: 0.981 | Reg loss: 0.021 | Tree loss: 0.981 | Accuracy: 0.554500 | 0.39 sec/iter\n",
      "Epoch: 31 | Batch: 008 / 011 | Total loss: 0.989 | Reg loss: 0.021 | Tree loss: 0.989 | Accuracy: 0.562500 | 0.39 sec/iter\n",
      "Epoch: 31 | Batch: 009 / 011 | Total loss: 0.956 | Reg loss: 0.021 | Tree loss: 0.956 | Accuracy: 0.577500 | 0.389 sec/iter\n",
      "Epoch: 31 | Batch: 010 / 011 | Total loss: 0.989 | Reg loss: 0.021 | Tree loss: 0.989 | Accuracy: 0.556314 | 0.389 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 32 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.021 | Tree loss: 1.085 | Accuracy: 0.590000 | 0.395 sec/iter\n",
      "Epoch: 32 | Batch: 001 / 011 | Total loss: 1.100 | Reg loss: 0.021 | Tree loss: 1.100 | Accuracy: 0.526500 | 0.395 sec/iter\n",
      "Epoch: 32 | Batch: 002 / 011 | Total loss: 1.086 | Reg loss: 0.021 | Tree loss: 1.086 | Accuracy: 0.546000 | 0.394 sec/iter\n",
      "Epoch: 32 | Batch: 003 / 011 | Total loss: 1.047 | Reg loss: 0.021 | Tree loss: 1.047 | Accuracy: 0.545000 | 0.394 sec/iter\n",
      "Epoch: 32 | Batch: 004 / 011 | Total loss: 1.044 | Reg loss: 0.021 | Tree loss: 1.044 | Accuracy: 0.543000 | 0.393 sec/iter\n",
      "Epoch: 32 | Batch: 005 / 011 | Total loss: 1.014 | Reg loss: 0.021 | Tree loss: 1.014 | Accuracy: 0.555000 | 0.392 sec/iter\n",
      "Epoch: 32 | Batch: 006 / 011 | Total loss: 1.026 | Reg loss: 0.021 | Tree loss: 1.026 | Accuracy: 0.528500 | 0.392 sec/iter\n",
      "Epoch: 32 | Batch: 007 / 011 | Total loss: 0.979 | Reg loss: 0.021 | Tree loss: 0.979 | Accuracy: 0.575500 | 0.391 sec/iter\n",
      "Epoch: 32 | Batch: 008 / 011 | Total loss: 1.011 | Reg loss: 0.021 | Tree loss: 1.011 | Accuracy: 0.566000 | 0.391 sec/iter\n",
      "Epoch: 32 | Batch: 009 / 011 | Total loss: 0.946 | Reg loss: 0.021 | Tree loss: 0.946 | Accuracy: 0.594500 | 0.39 sec/iter\n",
      "Epoch: 32 | Batch: 010 / 011 | Total loss: 0.937 | Reg loss: 0.021 | Tree loss: 0.937 | Accuracy: 0.645051 | 0.39 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 33 | Batch: 000 / 011 | Total loss: 1.085 | Reg loss: 0.021 | Tree loss: 1.085 | Accuracy: 0.591500 | 0.395 sec/iter\n",
      "Epoch: 33 | Batch: 001 / 011 | Total loss: 1.055 | Reg loss: 0.021 | Tree loss: 1.055 | Accuracy: 0.556500 | 0.394 sec/iter\n",
      "Epoch: 33 | Batch: 002 / 011 | Total loss: 1.046 | Reg loss: 0.021 | Tree loss: 1.046 | Accuracy: 0.561500 | 0.394 sec/iter\n",
      "Epoch: 33 | Batch: 003 / 011 | Total loss: 0.989 | Reg loss: 0.021 | Tree loss: 0.989 | Accuracy: 0.611000 | 0.393 sec/iter\n",
      "Epoch: 33 | Batch: 004 / 011 | Total loss: 1.012 | Reg loss: 0.021 | Tree loss: 1.012 | Accuracy: 0.582000 | 0.393 sec/iter\n",
      "Epoch: 33 | Batch: 005 / 011 | Total loss: 1.001 | Reg loss: 0.021 | Tree loss: 1.001 | Accuracy: 0.563000 | 0.392 sec/iter\n",
      "Epoch: 33 | Batch: 006 / 011 | Total loss: 0.963 | Reg loss: 0.021 | Tree loss: 0.963 | Accuracy: 0.593000 | 0.392 sec/iter\n",
      "Epoch: 33 | Batch: 007 / 011 | Total loss: 0.987 | Reg loss: 0.021 | Tree loss: 0.987 | Accuracy: 0.557500 | 0.391 sec/iter\n",
      "Epoch: 33 | Batch: 008 / 011 | Total loss: 0.987 | Reg loss: 0.021 | Tree loss: 0.987 | Accuracy: 0.542000 | 0.391 sec/iter\n",
      "Epoch: 33 | Batch: 009 / 011 | Total loss: 0.965 | Reg loss: 0.021 | Tree loss: 0.965 | Accuracy: 0.571500 | 0.39 sec/iter\n",
      "Epoch: 33 | Batch: 010 / 011 | Total loss: 0.945 | Reg loss: 0.021 | Tree loss: 0.945 | Accuracy: 0.576792 | 0.39 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 34 | Batch: 000 / 011 | Total loss: 1.065 | Reg loss: 0.021 | Tree loss: 1.065 | Accuracy: 0.592000 | 0.395 sec/iter\n",
      "Epoch: 34 | Batch: 001 / 011 | Total loss: 1.065 | Reg loss: 0.021 | Tree loss: 1.065 | Accuracy: 0.587000 | 0.395 sec/iter\n",
      "Epoch: 34 | Batch: 002 / 011 | Total loss: 1.064 | Reg loss: 0.021 | Tree loss: 1.064 | Accuracy: 0.566000 | 0.395 sec/iter\n",
      "Epoch: 34 | Batch: 003 / 011 | Total loss: 1.050 | Reg loss: 0.021 | Tree loss: 1.050 | Accuracy: 0.555500 | 0.394 sec/iter\n",
      "Epoch: 34 | Batch: 004 / 011 | Total loss: 1.059 | Reg loss: 0.021 | Tree loss: 1.059 | Accuracy: 0.531500 | 0.394 sec/iter\n",
      "Epoch: 34 | Batch: 005 / 011 | Total loss: 1.018 | Reg loss: 0.021 | Tree loss: 1.018 | Accuracy: 0.573500 | 0.393 sec/iter\n",
      "Epoch: 34 | Batch: 006 / 011 | Total loss: 1.013 | Reg loss: 0.021 | Tree loss: 1.013 | Accuracy: 0.552500 | 0.393 sec/iter\n",
      "Epoch: 34 | Batch: 007 / 011 | Total loss: 0.985 | Reg loss: 0.021 | Tree loss: 0.985 | Accuracy: 0.578000 | 0.392 sec/iter\n",
      "Epoch: 34 | Batch: 008 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.587500 | 0.392 sec/iter\n",
      "Epoch: 34 | Batch: 009 / 011 | Total loss: 0.956 | Reg loss: 0.021 | Tree loss: 0.956 | Accuracy: 0.586000 | 0.391 sec/iter\n",
      "Epoch: 34 | Batch: 010 / 011 | Total loss: 0.991 | Reg loss: 0.021 | Tree loss: 0.991 | Accuracy: 0.573379 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 35 | Batch: 000 / 011 | Total loss: 1.059 | Reg loss: 0.021 | Tree loss: 1.059 | Accuracy: 0.587500 | 0.396 sec/iter\n",
      "Epoch: 35 | Batch: 001 / 011 | Total loss: 1.049 | Reg loss: 0.021 | Tree loss: 1.049 | Accuracy: 0.584000 | 0.396 sec/iter\n",
      "Epoch: 35 | Batch: 002 / 011 | Total loss: 1.024 | Reg loss: 0.021 | Tree loss: 1.024 | Accuracy: 0.578500 | 0.395 sec/iter\n",
      "Epoch: 35 | Batch: 003 / 011 | Total loss: 0.997 | Reg loss: 0.021 | Tree loss: 0.997 | Accuracy: 0.591500 | 0.395 sec/iter\n",
      "Epoch: 35 | Batch: 004 / 011 | Total loss: 0.978 | Reg loss: 0.021 | Tree loss: 0.978 | Accuracy: 0.603500 | 0.394 sec/iter\n",
      "Epoch: 35 | Batch: 005 / 011 | Total loss: 0.967 | Reg loss: 0.021 | Tree loss: 0.967 | Accuracy: 0.616500 | 0.394 sec/iter\n",
      "Epoch: 35 | Batch: 006 / 011 | Total loss: 0.980 | Reg loss: 0.021 | Tree loss: 0.980 | Accuracy: 0.556000 | 0.393 sec/iter\n",
      "Epoch: 35 | Batch: 007 / 011 | Total loss: 0.975 | Reg loss: 0.021 | Tree loss: 0.975 | Accuracy: 0.567000 | 0.393 sec/iter\n",
      "Epoch: 35 | Batch: 008 / 011 | Total loss: 0.965 | Reg loss: 0.021 | Tree loss: 0.965 | Accuracy: 0.563000 | 0.392 sec/iter\n",
      "Epoch: 35 | Batch: 009 / 011 | Total loss: 0.979 | Reg loss: 0.021 | Tree loss: 0.979 | Accuracy: 0.566500 | 0.392 sec/iter\n",
      "Epoch: 35 | Batch: 010 / 011 | Total loss: 0.972 | Reg loss: 0.021 | Tree loss: 0.972 | Accuracy: 0.580205 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 36 | Batch: 000 / 011 | Total loss: 1.060 | Reg loss: 0.021 | Tree loss: 1.060 | Accuracy: 0.587000 | 0.397 sec/iter\n",
      "Epoch: 36 | Batch: 001 / 011 | Total loss: 1.062 | Reg loss: 0.021 | Tree loss: 1.062 | Accuracy: 0.586000 | 0.396 sec/iter\n",
      "Epoch: 36 | Batch: 002 / 011 | Total loss: 1.054 | Reg loss: 0.021 | Tree loss: 1.054 | Accuracy: 0.573500 | 0.396 sec/iter\n",
      "Epoch: 36 | Batch: 003 / 011 | Total loss: 1.051 | Reg loss: 0.021 | Tree loss: 1.051 | Accuracy: 0.573500 | 0.396 sec/iter\n",
      "Epoch: 36 | Batch: 004 / 011 | Total loss: 1.014 | Reg loss: 0.021 | Tree loss: 1.014 | Accuracy: 0.572500 | 0.395 sec/iter\n",
      "Epoch: 36 | Batch: 005 / 011 | Total loss: 0.980 | Reg loss: 0.021 | Tree loss: 0.980 | Accuracy: 0.590000 | 0.395 sec/iter\n",
      "Epoch: 36 | Batch: 006 / 011 | Total loss: 0.990 | Reg loss: 0.021 | Tree loss: 0.990 | Accuracy: 0.572000 | 0.394 sec/iter\n",
      "Epoch: 36 | Batch: 007 / 011 | Total loss: 0.953 | Reg loss: 0.021 | Tree loss: 0.953 | Accuracy: 0.604500 | 0.394 sec/iter\n",
      "Epoch: 36 | Batch: 008 / 011 | Total loss: 0.950 | Reg loss: 0.021 | Tree loss: 0.950 | Accuracy: 0.603500 | 0.393 sec/iter\n",
      "Epoch: 36 | Batch: 009 / 011 | Total loss: 0.942 | Reg loss: 0.021 | Tree loss: 0.942 | Accuracy: 0.613500 | 0.393 sec/iter\n",
      "Epoch: 36 | Batch: 010 / 011 | Total loss: 0.962 | Reg loss: 0.021 | Tree loss: 0.962 | Accuracy: 0.621160 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 37 | Batch: 000 / 011 | Total loss: 1.064 | Reg loss: 0.021 | Tree loss: 1.064 | Accuracy: 0.585500 | 0.398 sec/iter\n",
      "Epoch: 37 | Batch: 001 / 011 | Total loss: 1.041 | Reg loss: 0.021 | Tree loss: 1.041 | Accuracy: 0.594500 | 0.397 sec/iter\n",
      "Epoch: 37 | Batch: 002 / 011 | Total loss: 1.012 | Reg loss: 0.021 | Tree loss: 1.012 | Accuracy: 0.568500 | 0.397 sec/iter\n",
      "Epoch: 37 | Batch: 003 / 011 | Total loss: 0.993 | Reg loss: 0.021 | Tree loss: 0.993 | Accuracy: 0.580000 | 0.396 sec/iter\n",
      "Epoch: 37 | Batch: 004 / 011 | Total loss: 0.978 | Reg loss: 0.021 | Tree loss: 0.978 | Accuracy: 0.603500 | 0.396 sec/iter\n",
      "Epoch: 37 | Batch: 005 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.591500 | 0.395 sec/iter\n",
      "Epoch: 37 | Batch: 006 / 011 | Total loss: 0.962 | Reg loss: 0.021 | Tree loss: 0.962 | Accuracy: 0.584500 | 0.395 sec/iter\n",
      "Epoch: 37 | Batch: 007 / 011 | Total loss: 0.963 | Reg loss: 0.021 | Tree loss: 0.963 | Accuracy: 0.575500 | 0.394 sec/iter\n",
      "Epoch: 37 | Batch: 008 / 011 | Total loss: 0.958 | Reg loss: 0.021 | Tree loss: 0.958 | Accuracy: 0.582500 | 0.394 sec/iter\n",
      "Epoch: 37 | Batch: 009 / 011 | Total loss: 0.939 | Reg loss: 0.021 | Tree loss: 0.939 | Accuracy: 0.580000 | 0.394 sec/iter\n",
      "Epoch: 37 | Batch: 010 / 011 | Total loss: 1.008 | Reg loss: 0.021 | Tree loss: 1.008 | Accuracy: 0.532423 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 38 | Batch: 000 / 011 | Total loss: 1.050 | Reg loss: 0.021 | Tree loss: 1.050 | Accuracy: 0.579000 | 0.398 sec/iter\n",
      "Epoch: 38 | Batch: 001 / 011 | Total loss: 1.022 | Reg loss: 0.021 | Tree loss: 1.022 | Accuracy: 0.599500 | 0.398 sec/iter\n",
      "Epoch: 38 | Batch: 002 / 011 | Total loss: 1.036 | Reg loss: 0.021 | Tree loss: 1.036 | Accuracy: 0.571000 | 0.397 sec/iter\n",
      "Epoch: 38 | Batch: 003 / 011 | Total loss: 1.019 | Reg loss: 0.021 | Tree loss: 1.019 | Accuracy: 0.582000 | 0.397 sec/iter\n",
      "Epoch: 38 | Batch: 004 / 011 | Total loss: 1.009 | Reg loss: 0.021 | Tree loss: 1.009 | Accuracy: 0.571500 | 0.396 sec/iter\n",
      "Epoch: 38 | Batch: 005 / 011 | Total loss: 0.999 | Reg loss: 0.021 | Tree loss: 0.999 | Accuracy: 0.577000 | 0.396 sec/iter\n",
      "Epoch: 38 | Batch: 006 / 011 | Total loss: 0.982 | Reg loss: 0.021 | Tree loss: 0.982 | Accuracy: 0.589000 | 0.396 sec/iter\n",
      "Epoch: 38 | Batch: 007 / 011 | Total loss: 0.952 | Reg loss: 0.021 | Tree loss: 0.952 | Accuracy: 0.600500 | 0.395 sec/iter\n",
      "Epoch: 38 | Batch: 008 / 011 | Total loss: 0.961 | Reg loss: 0.021 | Tree loss: 0.961 | Accuracy: 0.596500 | 0.395 sec/iter\n",
      "Epoch: 38 | Batch: 009 / 011 | Total loss: 0.958 | Reg loss: 0.021 | Tree loss: 0.958 | Accuracy: 0.585500 | 0.394 sec/iter\n",
      "Epoch: 38 | Batch: 010 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.614334 | 0.394 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 39 | Batch: 000 / 011 | Total loss: 1.041 | Reg loss: 0.021 | Tree loss: 1.041 | Accuracy: 0.587000 | 0.399 sec/iter\n",
      "Epoch: 39 | Batch: 001 / 011 | Total loss: 1.018 | Reg loss: 0.021 | Tree loss: 1.018 | Accuracy: 0.585500 | 0.398 sec/iter\n",
      "Epoch: 39 | Batch: 002 / 011 | Total loss: 0.977 | Reg loss: 0.021 | Tree loss: 0.977 | Accuracy: 0.587000 | 0.398 sec/iter\n",
      "Epoch: 39 | Batch: 003 / 011 | Total loss: 0.980 | Reg loss: 0.021 | Tree loss: 0.980 | Accuracy: 0.577500 | 0.398 sec/iter\n",
      "Epoch: 39 | Batch: 004 / 011 | Total loss: 0.951 | Reg loss: 0.021 | Tree loss: 0.951 | Accuracy: 0.623000 | 0.397 sec/iter\n",
      "Epoch: 39 | Batch: 005 / 011 | Total loss: 0.959 | Reg loss: 0.021 | Tree loss: 0.959 | Accuracy: 0.602000 | 0.397 sec/iter\n",
      "Epoch: 39 | Batch: 006 / 011 | Total loss: 0.953 | Reg loss: 0.021 | Tree loss: 0.953 | Accuracy: 0.587500 | 0.396 sec/iter\n",
      "Epoch: 39 | Batch: 007 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.582500 | 0.396 sec/iter\n",
      "Epoch: 39 | Batch: 008 / 011 | Total loss: 0.967 | Reg loss: 0.021 | Tree loss: 0.967 | Accuracy: 0.574000 | 0.395 sec/iter\n",
      "Epoch: 39 | Batch: 009 / 011 | Total loss: 0.935 | Reg loss: 0.021 | Tree loss: 0.935 | Accuracy: 0.586500 | 0.395 sec/iter\n",
      "Epoch: 39 | Batch: 010 / 011 | Total loss: 0.930 | Reg loss: 0.021 | Tree loss: 0.930 | Accuracy: 0.593857 | 0.395 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 40 | Batch: 000 / 011 | Total loss: 1.052 | Reg loss: 0.021 | Tree loss: 1.052 | Accuracy: 0.572500 | 0.399 sec/iter\n",
      "Epoch: 40 | Batch: 001 / 011 | Total loss: 1.025 | Reg loss: 0.021 | Tree loss: 1.025 | Accuracy: 0.580500 | 0.399 sec/iter\n",
      "Epoch: 40 | Batch: 002 / 011 | Total loss: 1.013 | Reg loss: 0.021 | Tree loss: 1.013 | Accuracy: 0.585000 | 0.399 sec/iter\n",
      "Epoch: 40 | Batch: 003 / 011 | Total loss: 0.999 | Reg loss: 0.021 | Tree loss: 0.999 | Accuracy: 0.600000 | 0.398 sec/iter\n",
      "Epoch: 40 | Batch: 004 / 011 | Total loss: 0.992 | Reg loss: 0.021 | Tree loss: 0.992 | Accuracy: 0.580000 | 0.398 sec/iter\n",
      "Epoch: 40 | Batch: 005 / 011 | Total loss: 0.967 | Reg loss: 0.021 | Tree loss: 0.967 | Accuracy: 0.600000 | 0.397 sec/iter\n",
      "Epoch: 40 | Batch: 006 / 011 | Total loss: 0.948 | Reg loss: 0.021 | Tree loss: 0.948 | Accuracy: 0.609000 | 0.397 sec/iter\n",
      "Epoch: 40 | Batch: 007 / 011 | Total loss: 0.943 | Reg loss: 0.021 | Tree loss: 0.943 | Accuracy: 0.609500 | 0.397 sec/iter\n",
      "Epoch: 40 | Batch: 008 / 011 | Total loss: 0.922 | Reg loss: 0.021 | Tree loss: 0.922 | Accuracy: 0.628500 | 0.396 sec/iter\n",
      "Epoch: 40 | Batch: 009 / 011 | Total loss: 0.926 | Reg loss: 0.021 | Tree loss: 0.926 | Accuracy: 0.605500 | 0.396 sec/iter\n",
      "Epoch: 40 | Batch: 010 / 011 | Total loss: 0.943 | Reg loss: 0.021 | Tree loss: 0.943 | Accuracy: 0.600683 | 0.395 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 41 | Batch: 000 / 011 | Total loss: 1.038 | Reg loss: 0.021 | Tree loss: 1.038 | Accuracy: 0.587000 | 0.4 sec/iter\n",
      "Epoch: 41 | Batch: 001 / 011 | Total loss: 1.008 | Reg loss: 0.021 | Tree loss: 1.008 | Accuracy: 0.598500 | 0.4 sec/iter\n",
      "Epoch: 41 | Batch: 002 / 011 | Total loss: 0.988 | Reg loss: 0.021 | Tree loss: 0.988 | Accuracy: 0.565500 | 0.399 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Batch: 003 / 011 | Total loss: 0.970 | Reg loss: 0.021 | Tree loss: 0.970 | Accuracy: 0.588500 | 0.399 sec/iter\n",
      "Epoch: 41 | Batch: 004 / 011 | Total loss: 0.936 | Reg loss: 0.021 | Tree loss: 0.936 | Accuracy: 0.625500 | 0.398 sec/iter\n",
      "Epoch: 41 | Batch: 005 / 011 | Total loss: 0.941 | Reg loss: 0.021 | Tree loss: 0.941 | Accuracy: 0.606000 | 0.398 sec/iter\n",
      "Epoch: 41 | Batch: 006 / 011 | Total loss: 0.953 | Reg loss: 0.021 | Tree loss: 0.953 | Accuracy: 0.581000 | 0.398 sec/iter\n",
      "Epoch: 41 | Batch: 007 / 011 | Total loss: 0.940 | Reg loss: 0.021 | Tree loss: 0.940 | Accuracy: 0.584500 | 0.397 sec/iter\n",
      "Epoch: 41 | Batch: 008 / 011 | Total loss: 0.964 | Reg loss: 0.021 | Tree loss: 0.964 | Accuracy: 0.556000 | 0.397 sec/iter\n",
      "Epoch: 41 | Batch: 009 / 011 | Total loss: 0.958 | Reg loss: 0.021 | Tree loss: 0.958 | Accuracy: 0.573500 | 0.396 sec/iter\n",
      "Epoch: 41 | Batch: 010 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.546075 | 0.396 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 42 | Batch: 000 / 011 | Total loss: 1.018 | Reg loss: 0.021 | Tree loss: 1.018 | Accuracy: 0.581000 | 0.401 sec/iter\n",
      "Epoch: 42 | Batch: 001 / 011 | Total loss: 1.049 | Reg loss: 0.021 | Tree loss: 1.049 | Accuracy: 0.557000 | 0.4 sec/iter\n",
      "Epoch: 42 | Batch: 002 / 011 | Total loss: 1.006 | Reg loss: 0.021 | Tree loss: 1.006 | Accuracy: 0.583500 | 0.4 sec/iter\n",
      "Epoch: 42 | Batch: 003 / 011 | Total loss: 0.984 | Reg loss: 0.021 | Tree loss: 0.984 | Accuracy: 0.590500 | 0.399 sec/iter\n",
      "Epoch: 42 | Batch: 004 / 011 | Total loss: 0.983 | Reg loss: 0.021 | Tree loss: 0.983 | Accuracy: 0.602500 | 0.399 sec/iter\n",
      "Epoch: 42 | Batch: 005 / 011 | Total loss: 0.966 | Reg loss: 0.021 | Tree loss: 0.966 | Accuracy: 0.597000 | 0.399 sec/iter\n",
      "Epoch: 42 | Batch: 006 / 011 | Total loss: 0.937 | Reg loss: 0.021 | Tree loss: 0.937 | Accuracy: 0.609000 | 0.398 sec/iter\n",
      "Epoch: 42 | Batch: 007 / 011 | Total loss: 0.942 | Reg loss: 0.021 | Tree loss: 0.942 | Accuracy: 0.602000 | 0.398 sec/iter\n",
      "Epoch: 42 | Batch: 008 / 011 | Total loss: 0.902 | Reg loss: 0.021 | Tree loss: 0.902 | Accuracy: 0.628500 | 0.397 sec/iter\n",
      "Epoch: 42 | Batch: 009 / 011 | Total loss: 0.941 | Reg loss: 0.021 | Tree loss: 0.941 | Accuracy: 0.573500 | 0.397 sec/iter\n",
      "Epoch: 42 | Batch: 010 / 011 | Total loss: 0.994 | Reg loss: 0.021 | Tree loss: 0.994 | Accuracy: 0.587031 | 0.396 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 43 | Batch: 000 / 011 | Total loss: 1.038 | Reg loss: 0.021 | Tree loss: 1.038 | Accuracy: 0.577500 | 0.401 sec/iter\n",
      "Epoch: 43 | Batch: 001 / 011 | Total loss: 1.015 | Reg loss: 0.021 | Tree loss: 1.015 | Accuracy: 0.569500 | 0.401 sec/iter\n",
      "Epoch: 43 | Batch: 002 / 011 | Total loss: 0.984 | Reg loss: 0.021 | Tree loss: 0.984 | Accuracy: 0.588500 | 0.4 sec/iter\n",
      "Epoch: 43 | Batch: 003 / 011 | Total loss: 0.980 | Reg loss: 0.021 | Tree loss: 0.980 | Accuracy: 0.569000 | 0.4 sec/iter\n",
      "Epoch: 43 | Batch: 004 / 011 | Total loss: 0.918 | Reg loss: 0.021 | Tree loss: 0.918 | Accuracy: 0.636000 | 0.399 sec/iter\n",
      "Epoch: 43 | Batch: 005 / 011 | Total loss: 0.916 | Reg loss: 0.021 | Tree loss: 0.916 | Accuracy: 0.625500 | 0.399 sec/iter\n",
      "Epoch: 43 | Batch: 006 / 011 | Total loss: 0.927 | Reg loss: 0.021 | Tree loss: 0.927 | Accuracy: 0.592500 | 0.398 sec/iter\n",
      "Epoch: 43 | Batch: 007 / 011 | Total loss: 0.944 | Reg loss: 0.021 | Tree loss: 0.944 | Accuracy: 0.578500 | 0.398 sec/iter\n",
      "Epoch: 43 | Batch: 008 / 011 | Total loss: 0.939 | Reg loss: 0.021 | Tree loss: 0.939 | Accuracy: 0.563500 | 0.398 sec/iter\n",
      "Epoch: 43 | Batch: 009 / 011 | Total loss: 0.939 | Reg loss: 0.021 | Tree loss: 0.939 | Accuracy: 0.568000 | 0.397 sec/iter\n",
      "Epoch: 43 | Batch: 010 / 011 | Total loss: 0.955 | Reg loss: 0.021 | Tree loss: 0.955 | Accuracy: 0.573379 | 0.397 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 44 | Batch: 000 / 011 | Total loss: 1.028 | Reg loss: 0.021 | Tree loss: 1.028 | Accuracy: 0.573500 | 0.401 sec/iter\n",
      "Epoch: 44 | Batch: 001 / 011 | Total loss: 1.009 | Reg loss: 0.021 | Tree loss: 1.009 | Accuracy: 0.595000 | 0.401 sec/iter\n",
      "Epoch: 44 | Batch: 002 / 011 | Total loss: 1.010 | Reg loss: 0.021 | Tree loss: 1.010 | Accuracy: 0.580500 | 0.4 sec/iter\n",
      "Epoch: 44 | Batch: 003 / 011 | Total loss: 0.974 | Reg loss: 0.021 | Tree loss: 0.974 | Accuracy: 0.585000 | 0.4 sec/iter\n",
      "Epoch: 44 | Batch: 004 / 011 | Total loss: 0.993 | Reg loss: 0.021 | Tree loss: 0.993 | Accuracy: 0.579000 | 0.4 sec/iter\n",
      "Epoch: 44 | Batch: 005 / 011 | Total loss: 0.949 | Reg loss: 0.021 | Tree loss: 0.949 | Accuracy: 0.599000 | 0.399 sec/iter\n",
      "Epoch: 44 | Batch: 006 / 011 | Total loss: 0.938 | Reg loss: 0.021 | Tree loss: 0.938 | Accuracy: 0.614500 | 0.399 sec/iter\n",
      "Epoch: 44 | Batch: 007 / 011 | Total loss: 0.916 | Reg loss: 0.021 | Tree loss: 0.916 | Accuracy: 0.605000 | 0.398 sec/iter\n",
      "Epoch: 44 | Batch: 008 / 011 | Total loss: 0.936 | Reg loss: 0.021 | Tree loss: 0.936 | Accuracy: 0.595000 | 0.398 sec/iter\n",
      "Epoch: 44 | Batch: 009 / 011 | Total loss: 0.916 | Reg loss: 0.021 | Tree loss: 0.916 | Accuracy: 0.607500 | 0.398 sec/iter\n",
      "Epoch: 44 | Batch: 010 / 011 | Total loss: 0.925 | Reg loss: 0.021 | Tree loss: 0.925 | Accuracy: 0.604096 | 0.397 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 45 | Batch: 000 / 011 | Total loss: 1.031 | Reg loss: 0.021 | Tree loss: 1.031 | Accuracy: 0.564000 | 0.401 sec/iter\n",
      "Epoch: 45 | Batch: 001 / 011 | Total loss: 0.978 | Reg loss: 0.021 | Tree loss: 0.978 | Accuracy: 0.609500 | 0.401 sec/iter\n",
      "Epoch: 45 | Batch: 002 / 011 | Total loss: 0.948 | Reg loss: 0.021 | Tree loss: 0.948 | Accuracy: 0.627500 | 0.401 sec/iter\n",
      "Epoch: 45 | Batch: 003 / 011 | Total loss: 0.949 | Reg loss: 0.021 | Tree loss: 0.949 | Accuracy: 0.606500 | 0.4 sec/iter\n",
      "Epoch: 45 | Batch: 004 / 011 | Total loss: 0.951 | Reg loss: 0.021 | Tree loss: 0.951 | Accuracy: 0.631000 | 0.4 sec/iter\n",
      "Epoch: 45 | Batch: 005 / 011 | Total loss: 0.934 | Reg loss: 0.021 | Tree loss: 0.934 | Accuracy: 0.608500 | 0.4 sec/iter\n",
      "Epoch: 45 | Batch: 006 / 011 | Total loss: 0.936 | Reg loss: 0.021 | Tree loss: 0.936 | Accuracy: 0.581000 | 0.399 sec/iter\n",
      "Epoch: 45 | Batch: 007 / 011 | Total loss: 0.911 | Reg loss: 0.021 | Tree loss: 0.911 | Accuracy: 0.588000 | 0.399 sec/iter\n",
      "Epoch: 45 | Batch: 008 / 011 | Total loss: 0.933 | Reg loss: 0.021 | Tree loss: 0.933 | Accuracy: 0.579000 | 0.398 sec/iter\n",
      "Epoch: 45 | Batch: 009 / 011 | Total loss: 0.933 | Reg loss: 0.021 | Tree loss: 0.933 | Accuracy: 0.577500 | 0.398 sec/iter\n",
      "Epoch: 45 | Batch: 010 / 011 | Total loss: 0.919 | Reg loss: 0.021 | Tree loss: 0.919 | Accuracy: 0.580205 | 0.397 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 46 | Batch: 000 / 011 | Total loss: 1.002 | Reg loss: 0.021 | Tree loss: 1.002 | Accuracy: 0.589000 | 0.4 sec/iter\n",
      "Epoch: 46 | Batch: 001 / 011 | Total loss: 0.991 | Reg loss: 0.021 | Tree loss: 0.991 | Accuracy: 0.585500 | 0.399 sec/iter\n",
      "Epoch: 46 | Batch: 002 / 011 | Total loss: 1.008 | Reg loss: 0.021 | Tree loss: 1.008 | Accuracy: 0.574500 | 0.399 sec/iter\n",
      "Epoch: 46 | Batch: 003 / 011 | Total loss: 0.962 | Reg loss: 0.021 | Tree loss: 0.962 | Accuracy: 0.601500 | 0.398 sec/iter\n",
      "Epoch: 46 | Batch: 004 / 011 | Total loss: 0.957 | Reg loss: 0.021 | Tree loss: 0.957 | Accuracy: 0.600000 | 0.398 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Batch: 005 / 011 | Total loss: 0.948 | Reg loss: 0.021 | Tree loss: 0.948 | Accuracy: 0.595500 | 0.398 sec/iter\n",
      "Epoch: 46 | Batch: 006 / 011 | Total loss: 0.930 | Reg loss: 0.021 | Tree loss: 0.930 | Accuracy: 0.619000 | 0.397 sec/iter\n",
      "Epoch: 46 | Batch: 007 / 011 | Total loss: 0.929 | Reg loss: 0.021 | Tree loss: 0.929 | Accuracy: 0.613000 | 0.397 sec/iter\n",
      "Epoch: 46 | Batch: 008 / 011 | Total loss: 0.912 | Reg loss: 0.021 | Tree loss: 0.912 | Accuracy: 0.608000 | 0.397 sec/iter\n",
      "Epoch: 46 | Batch: 009 / 011 | Total loss: 0.904 | Reg loss: 0.021 | Tree loss: 0.904 | Accuracy: 0.594000 | 0.396 sec/iter\n",
      "Epoch: 46 | Batch: 010 / 011 | Total loss: 0.915 | Reg loss: 0.021 | Tree loss: 0.915 | Accuracy: 0.569966 | 0.396 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 47 | Batch: 000 / 011 | Total loss: 0.977 | Reg loss: 0.021 | Tree loss: 0.977 | Accuracy: 0.603500 | 0.4 sec/iter\n",
      "Epoch: 47 | Batch: 001 / 011 | Total loss: 0.992 | Reg loss: 0.021 | Tree loss: 0.992 | Accuracy: 0.574000 | 0.4 sec/iter\n",
      "Epoch: 47 | Batch: 002 / 011 | Total loss: 1.005 | Reg loss: 0.021 | Tree loss: 1.005 | Accuracy: 0.557500 | 0.399 sec/iter\n",
      "Epoch: 47 | Batch: 003 / 011 | Total loss: 0.948 | Reg loss: 0.021 | Tree loss: 0.948 | Accuracy: 0.607500 | 0.399 sec/iter\n",
      "Epoch: 47 | Batch: 004 / 011 | Total loss: 0.922 | Reg loss: 0.021 | Tree loss: 0.922 | Accuracy: 0.619000 | 0.399 sec/iter\n",
      "Epoch: 47 | Batch: 005 / 011 | Total loss: 0.929 | Reg loss: 0.021 | Tree loss: 0.929 | Accuracy: 0.601500 | 0.398 sec/iter\n",
      "Epoch: 47 | Batch: 006 / 011 | Total loss: 0.905 | Reg loss: 0.021 | Tree loss: 0.905 | Accuracy: 0.602000 | 0.398 sec/iter\n",
      "Epoch: 47 | Batch: 007 / 011 | Total loss: 0.939 | Reg loss: 0.021 | Tree loss: 0.939 | Accuracy: 0.572500 | 0.397 sec/iter\n",
      "Epoch: 47 | Batch: 008 / 011 | Total loss: 0.941 | Reg loss: 0.021 | Tree loss: 0.941 | Accuracy: 0.575000 | 0.397 sec/iter\n",
      "Epoch: 47 | Batch: 009 / 011 | Total loss: 0.927 | Reg loss: 0.021 | Tree loss: 0.927 | Accuracy: 0.575500 | 0.397 sec/iter\n",
      "Epoch: 47 | Batch: 010 / 011 | Total loss: 0.953 | Reg loss: 0.021 | Tree loss: 0.953 | Accuracy: 0.566553 | 0.396 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 48 | Batch: 000 / 011 | Total loss: 1.016 | Reg loss: 0.021 | Tree loss: 1.016 | Accuracy: 0.575500 | 0.397 sec/iter\n",
      "Epoch: 48 | Batch: 001 / 011 | Total loss: 1.018 | Reg loss: 0.021 | Tree loss: 1.018 | Accuracy: 0.578000 | 0.396 sec/iter\n",
      "Epoch: 48 | Batch: 002 / 011 | Total loss: 0.988 | Reg loss: 0.021 | Tree loss: 0.988 | Accuracy: 0.573000 | 0.396 sec/iter\n",
      "Epoch: 48 | Batch: 003 / 011 | Total loss: 0.950 | Reg loss: 0.021 | Tree loss: 0.950 | Accuracy: 0.603500 | 0.396 sec/iter\n",
      "Epoch: 48 | Batch: 004 / 011 | Total loss: 0.975 | Reg loss: 0.021 | Tree loss: 0.975 | Accuracy: 0.579000 | 0.395 sec/iter\n",
      "Epoch: 48 | Batch: 005 / 011 | Total loss: 0.923 | Reg loss: 0.021 | Tree loss: 0.923 | Accuracy: 0.621000 | 0.395 sec/iter\n",
      "Epoch: 48 | Batch: 006 / 011 | Total loss: 0.907 | Reg loss: 0.021 | Tree loss: 0.907 | Accuracy: 0.623000 | 0.394 sec/iter\n",
      "Epoch: 48 | Batch: 007 / 011 | Total loss: 0.912 | Reg loss: 0.021 | Tree loss: 0.912 | Accuracy: 0.615500 | 0.394 sec/iter\n",
      "Epoch: 48 | Batch: 008 / 011 | Total loss: 0.889 | Reg loss: 0.021 | Tree loss: 0.889 | Accuracy: 0.616000 | 0.394 sec/iter\n",
      "Epoch: 48 | Batch: 009 / 011 | Total loss: 0.925 | Reg loss: 0.021 | Tree loss: 0.925 | Accuracy: 0.579000 | 0.393 sec/iter\n",
      "Epoch: 48 | Batch: 010 / 011 | Total loss: 0.943 | Reg loss: 0.021 | Tree loss: 0.943 | Accuracy: 0.559727 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 49 | Batch: 000 / 011 | Total loss: 1.011 | Reg loss: 0.021 | Tree loss: 1.011 | Accuracy: 0.571500 | 0.397 sec/iter\n",
      "Epoch: 49 | Batch: 001 / 011 | Total loss: 0.995 | Reg loss: 0.021 | Tree loss: 0.995 | Accuracy: 0.582500 | 0.397 sec/iter\n",
      "Epoch: 49 | Batch: 002 / 011 | Total loss: 0.946 | Reg loss: 0.021 | Tree loss: 0.946 | Accuracy: 0.596500 | 0.396 sec/iter\n",
      "Epoch: 49 | Batch: 003 / 011 | Total loss: 0.967 | Reg loss: 0.021 | Tree loss: 0.967 | Accuracy: 0.592000 | 0.396 sec/iter\n",
      "Epoch: 49 | Batch: 004 / 011 | Total loss: 0.914 | Reg loss: 0.021 | Tree loss: 0.914 | Accuracy: 0.634500 | 0.396 sec/iter\n",
      "Epoch: 49 | Batch: 005 / 011 | Total loss: 0.906 | Reg loss: 0.021 | Tree loss: 0.906 | Accuracy: 0.624500 | 0.395 sec/iter\n",
      "Epoch: 49 | Batch: 006 / 011 | Total loss: 0.929 | Reg loss: 0.021 | Tree loss: 0.929 | Accuracy: 0.592500 | 0.395 sec/iter\n",
      "Epoch: 49 | Batch: 007 / 011 | Total loss: 0.914 | Reg loss: 0.021 | Tree loss: 0.914 | Accuracy: 0.582000 | 0.395 sec/iter\n",
      "Epoch: 49 | Batch: 008 / 011 | Total loss: 0.898 | Reg loss: 0.021 | Tree loss: 0.898 | Accuracy: 0.598000 | 0.394 sec/iter\n",
      "Epoch: 49 | Batch: 009 / 011 | Total loss: 0.905 | Reg loss: 0.021 | Tree loss: 0.905 | Accuracy: 0.580500 | 0.394 sec/iter\n",
      "Epoch: 49 | Batch: 010 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.569966 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 50 | Batch: 000 / 011 | Total loss: 1.003 | Reg loss: 0.021 | Tree loss: 1.003 | Accuracy: 0.575500 | 0.397 sec/iter\n",
      "Epoch: 50 | Batch: 001 / 011 | Total loss: 0.984 | Reg loss: 0.021 | Tree loss: 0.984 | Accuracy: 0.593000 | 0.397 sec/iter\n",
      "Epoch: 50 | Batch: 002 / 011 | Total loss: 0.982 | Reg loss: 0.021 | Tree loss: 0.982 | Accuracy: 0.577500 | 0.397 sec/iter\n",
      "Epoch: 50 | Batch: 003 / 011 | Total loss: 0.975 | Reg loss: 0.021 | Tree loss: 0.975 | Accuracy: 0.583000 | 0.396 sec/iter\n",
      "Epoch: 50 | Batch: 004 / 011 | Total loss: 0.952 | Reg loss: 0.021 | Tree loss: 0.952 | Accuracy: 0.590500 | 0.396 sec/iter\n",
      "Epoch: 50 | Batch: 005 / 011 | Total loss: 0.915 | Reg loss: 0.021 | Tree loss: 0.915 | Accuracy: 0.609500 | 0.395 sec/iter\n",
      "Epoch: 50 | Batch: 006 / 011 | Total loss: 0.902 | Reg loss: 0.021 | Tree loss: 0.902 | Accuracy: 0.636000 | 0.395 sec/iter\n",
      "Epoch: 50 | Batch: 007 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.606000 | 0.395 sec/iter\n",
      "Epoch: 50 | Batch: 008 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.608000 | 0.394 sec/iter\n",
      "Epoch: 50 | Batch: 009 / 011 | Total loss: 0.924 | Reg loss: 0.021 | Tree loss: 0.924 | Accuracy: 0.581500 | 0.394 sec/iter\n",
      "Epoch: 50 | Batch: 010 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.624573 | 0.394 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 51 | Batch: 000 / 011 | Total loss: 0.994 | Reg loss: 0.021 | Tree loss: 0.994 | Accuracy: 0.602500 | 0.398 sec/iter\n",
      "Epoch: 51 | Batch: 001 / 011 | Total loss: 0.982 | Reg loss: 0.021 | Tree loss: 0.982 | Accuracy: 0.599000 | 0.397 sec/iter\n",
      "Epoch: 51 | Batch: 002 / 011 | Total loss: 0.937 | Reg loss: 0.021 | Tree loss: 0.937 | Accuracy: 0.611500 | 0.397 sec/iter\n",
      "Epoch: 51 | Batch: 003 / 011 | Total loss: 0.940 | Reg loss: 0.021 | Tree loss: 0.940 | Accuracy: 0.600000 | 0.397 sec/iter\n",
      "Epoch: 51 | Batch: 004 / 011 | Total loss: 0.919 | Reg loss: 0.021 | Tree loss: 0.919 | Accuracy: 0.599000 | 0.396 sec/iter\n",
      "Epoch: 51 | Batch: 005 / 011 | Total loss: 0.926 | Reg loss: 0.021 | Tree loss: 0.926 | Accuracy: 0.608500 | 0.396 sec/iter\n",
      "Epoch: 51 | Batch: 006 / 011 | Total loss: 0.896 | Reg loss: 0.021 | Tree loss: 0.896 | Accuracy: 0.608000 | 0.396 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | Batch: 007 / 011 | Total loss: 0.906 | Reg loss: 0.021 | Tree loss: 0.906 | Accuracy: 0.594000 | 0.395 sec/iter\n",
      "Epoch: 51 | Batch: 008 / 011 | Total loss: 0.900 | Reg loss: 0.021 | Tree loss: 0.900 | Accuracy: 0.589000 | 0.395 sec/iter\n",
      "Epoch: 51 | Batch: 009 / 011 | Total loss: 0.926 | Reg loss: 0.021 | Tree loss: 0.926 | Accuracy: 0.573500 | 0.395 sec/iter\n",
      "Epoch: 51 | Batch: 010 / 011 | Total loss: 0.900 | Reg loss: 0.021 | Tree loss: 0.900 | Accuracy: 0.566553 | 0.394 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 52 | Batch: 000 / 011 | Total loss: 0.996 | Reg loss: 0.021 | Tree loss: 0.996 | Accuracy: 0.575000 | 0.398 sec/iter\n",
      "Epoch: 52 | Batch: 001 / 011 | Total loss: 0.999 | Reg loss: 0.021 | Tree loss: 0.999 | Accuracy: 0.572500 | 0.398 sec/iter\n",
      "Epoch: 52 | Batch: 002 / 011 | Total loss: 0.973 | Reg loss: 0.021 | Tree loss: 0.973 | Accuracy: 0.588500 | 0.397 sec/iter\n",
      "Epoch: 52 | Batch: 003 / 011 | Total loss: 0.966 | Reg loss: 0.021 | Tree loss: 0.966 | Accuracy: 0.594500 | 0.397 sec/iter\n",
      "Epoch: 52 | Batch: 004 / 011 | Total loss: 0.921 | Reg loss: 0.021 | Tree loss: 0.921 | Accuracy: 0.628500 | 0.397 sec/iter\n",
      "Epoch: 52 | Batch: 005 / 011 | Total loss: 0.907 | Reg loss: 0.021 | Tree loss: 0.907 | Accuracy: 0.622000 | 0.396 sec/iter\n",
      "Epoch: 52 | Batch: 006 / 011 | Total loss: 0.907 | Reg loss: 0.021 | Tree loss: 0.907 | Accuracy: 0.622000 | 0.396 sec/iter\n",
      "Epoch: 52 | Batch: 007 / 011 | Total loss: 0.907 | Reg loss: 0.021 | Tree loss: 0.907 | Accuracy: 0.605000 | 0.396 sec/iter\n",
      "Epoch: 52 | Batch: 008 / 011 | Total loss: 0.924 | Reg loss: 0.021 | Tree loss: 0.924 | Accuracy: 0.585500 | 0.395 sec/iter\n",
      "Epoch: 52 | Batch: 009 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.598000 | 0.395 sec/iter\n",
      "Epoch: 52 | Batch: 010 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.624573 | 0.395 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 53 | Batch: 000 / 011 | Total loss: 0.984 | Reg loss: 0.021 | Tree loss: 0.984 | Accuracy: 0.581000 | 0.396 sec/iter\n",
      "Epoch: 53 | Batch: 001 / 011 | Total loss: 0.986 | Reg loss: 0.021 | Tree loss: 0.986 | Accuracy: 0.573500 | 0.396 sec/iter\n",
      "Epoch: 53 | Batch: 002 / 011 | Total loss: 0.953 | Reg loss: 0.021 | Tree loss: 0.953 | Accuracy: 0.602500 | 0.395 sec/iter\n",
      "Epoch: 53 | Batch: 003 / 011 | Total loss: 0.917 | Reg loss: 0.021 | Tree loss: 0.917 | Accuracy: 0.593000 | 0.395 sec/iter\n",
      "Epoch: 53 | Batch: 004 / 011 | Total loss: 0.927 | Reg loss: 0.021 | Tree loss: 0.927 | Accuracy: 0.607000 | 0.395 sec/iter\n",
      "Epoch: 53 | Batch: 005 / 011 | Total loss: 0.896 | Reg loss: 0.021 | Tree loss: 0.896 | Accuracy: 0.652000 | 0.394 sec/iter\n",
      "Epoch: 53 | Batch: 006 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.600500 | 0.394 sec/iter\n",
      "Epoch: 53 | Batch: 007 / 011 | Total loss: 0.907 | Reg loss: 0.021 | Tree loss: 0.907 | Accuracy: 0.583500 | 0.393 sec/iter\n",
      "Epoch: 53 | Batch: 008 / 011 | Total loss: 0.921 | Reg loss: 0.021 | Tree loss: 0.921 | Accuracy: 0.586500 | 0.393 sec/iter\n",
      "Epoch: 53 | Batch: 009 / 011 | Total loss: 0.919 | Reg loss: 0.021 | Tree loss: 0.919 | Accuracy: 0.568000 | 0.393 sec/iter\n",
      "Epoch: 53 | Batch: 010 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.610922 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 54 | Batch: 000 / 011 | Total loss: 1.000 | Reg loss: 0.021 | Tree loss: 1.000 | Accuracy: 0.580000 | 0.392 sec/iter\n",
      "Epoch: 54 | Batch: 001 / 011 | Total loss: 0.998 | Reg loss: 0.021 | Tree loss: 0.998 | Accuracy: 0.568000 | 0.392 sec/iter\n",
      "Epoch: 54 | Batch: 002 / 011 | Total loss: 0.958 | Reg loss: 0.021 | Tree loss: 0.958 | Accuracy: 0.594500 | 0.392 sec/iter\n",
      "Epoch: 54 | Batch: 003 / 011 | Total loss: 0.979 | Reg loss: 0.021 | Tree loss: 0.979 | Accuracy: 0.576500 | 0.391 sec/iter\n",
      "Epoch: 54 | Batch: 004 / 011 | Total loss: 0.904 | Reg loss: 0.021 | Tree loss: 0.904 | Accuracy: 0.627000 | 0.391 sec/iter\n",
      "Epoch: 54 | Batch: 005 / 011 | Total loss: 0.890 | Reg loss: 0.021 | Tree loss: 0.890 | Accuracy: 0.638000 | 0.391 sec/iter\n",
      "Epoch: 54 | Batch: 006 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.636500 | 0.39 sec/iter\n",
      "Epoch: 54 | Batch: 007 / 011 | Total loss: 0.888 | Reg loss: 0.021 | Tree loss: 0.888 | Accuracy: 0.625500 | 0.39 sec/iter\n",
      "Epoch: 54 | Batch: 008 / 011 | Total loss: 0.900 | Reg loss: 0.021 | Tree loss: 0.900 | Accuracy: 0.592500 | 0.39 sec/iter\n",
      "Epoch: 54 | Batch: 009 / 011 | Total loss: 0.924 | Reg loss: 0.021 | Tree loss: 0.924 | Accuracy: 0.554000 | 0.389 sec/iter\n",
      "Epoch: 54 | Batch: 010 / 011 | Total loss: 0.914 | Reg loss: 0.021 | Tree loss: 0.914 | Accuracy: 0.559727 | 0.389 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 55 | Batch: 000 / 011 | Total loss: 0.998 | Reg loss: 0.021 | Tree loss: 0.998 | Accuracy: 0.582500 | 0.393 sec/iter\n",
      "Epoch: 55 | Batch: 001 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.583500 | 0.392 sec/iter\n",
      "Epoch: 55 | Batch: 002 / 011 | Total loss: 0.949 | Reg loss: 0.021 | Tree loss: 0.949 | Accuracy: 0.600500 | 0.392 sec/iter\n",
      "Epoch: 55 | Batch: 003 / 011 | Total loss: 0.979 | Reg loss: 0.021 | Tree loss: 0.979 | Accuracy: 0.587000 | 0.392 sec/iter\n",
      "Epoch: 55 | Batch: 004 / 011 | Total loss: 0.945 | Reg loss: 0.021 | Tree loss: 0.945 | Accuracy: 0.610000 | 0.391 sec/iter\n",
      "Epoch: 55 | Batch: 005 / 011 | Total loss: 0.899 | Reg loss: 0.021 | Tree loss: 0.899 | Accuracy: 0.637500 | 0.391 sec/iter\n",
      "Epoch: 55 | Batch: 006 / 011 | Total loss: 0.886 | Reg loss: 0.021 | Tree loss: 0.886 | Accuracy: 0.616000 | 0.391 sec/iter\n",
      "Epoch: 55 | Batch: 007 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.610500 | 0.391 sec/iter\n",
      "Epoch: 55 | Batch: 008 / 011 | Total loss: 0.887 | Reg loss: 0.021 | Tree loss: 0.887 | Accuracy: 0.612000 | 0.39 sec/iter\n",
      "Epoch: 55 | Batch: 009 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.603000 | 0.39 sec/iter\n",
      "Epoch: 55 | Batch: 010 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.583618 | 0.39 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 56 | Batch: 000 / 011 | Total loss: 1.015 | Reg loss: 0.021 | Tree loss: 1.015 | Accuracy: 0.571500 | 0.393 sec/iter\n",
      "Epoch: 56 | Batch: 001 / 011 | Total loss: 0.973 | Reg loss: 0.021 | Tree loss: 0.973 | Accuracy: 0.587500 | 0.393 sec/iter\n",
      "Epoch: 56 | Batch: 002 / 011 | Total loss: 0.955 | Reg loss: 0.021 | Tree loss: 0.955 | Accuracy: 0.598500 | 0.392 sec/iter\n",
      "Epoch: 56 | Batch: 003 / 011 | Total loss: 0.926 | Reg loss: 0.021 | Tree loss: 0.926 | Accuracy: 0.603500 | 0.392 sec/iter\n",
      "Epoch: 56 | Batch: 004 / 011 | Total loss: 0.914 | Reg loss: 0.021 | Tree loss: 0.914 | Accuracy: 0.630000 | 0.392 sec/iter\n",
      "Epoch: 56 | Batch: 005 / 011 | Total loss: 0.905 | Reg loss: 0.021 | Tree loss: 0.905 | Accuracy: 0.636000 | 0.391 sec/iter\n",
      "Epoch: 56 | Batch: 006 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.598000 | 0.391 sec/iter\n",
      "Epoch: 56 | Batch: 007 / 011 | Total loss: 0.892 | Reg loss: 0.021 | Tree loss: 0.892 | Accuracy: 0.597500 | 0.391 sec/iter\n",
      "Epoch: 56 | Batch: 008 / 011 | Total loss: 0.898 | Reg loss: 0.021 | Tree loss: 0.898 | Accuracy: 0.586000 | 0.391 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | Batch: 009 / 011 | Total loss: 0.898 | Reg loss: 0.021 | Tree loss: 0.898 | Accuracy: 0.592500 | 0.39 sec/iter\n",
      "Epoch: 56 | Batch: 010 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.614334 | 0.39 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 57 | Batch: 000 / 011 | Total loss: 0.999 | Reg loss: 0.021 | Tree loss: 0.999 | Accuracy: 0.578000 | 0.393 sec/iter\n",
      "Epoch: 57 | Batch: 001 / 011 | Total loss: 0.970 | Reg loss: 0.021 | Tree loss: 0.970 | Accuracy: 0.582500 | 0.393 sec/iter\n",
      "Epoch: 57 | Batch: 002 / 011 | Total loss: 0.939 | Reg loss: 0.021 | Tree loss: 0.939 | Accuracy: 0.594500 | 0.393 sec/iter\n",
      "Epoch: 57 | Batch: 003 / 011 | Total loss: 0.951 | Reg loss: 0.021 | Tree loss: 0.951 | Accuracy: 0.589500 | 0.393 sec/iter\n",
      "Epoch: 57 | Batch: 004 / 011 | Total loss: 0.901 | Reg loss: 0.021 | Tree loss: 0.901 | Accuracy: 0.614000 | 0.392 sec/iter\n",
      "Epoch: 57 | Batch: 005 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.647000 | 0.392 sec/iter\n",
      "Epoch: 57 | Batch: 006 / 011 | Total loss: 0.906 | Reg loss: 0.021 | Tree loss: 0.906 | Accuracy: 0.611500 | 0.392 sec/iter\n",
      "Epoch: 57 | Batch: 007 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.627500 | 0.391 sec/iter\n",
      "Epoch: 57 | Batch: 008 / 011 | Total loss: 0.905 | Reg loss: 0.021 | Tree loss: 0.905 | Accuracy: 0.588000 | 0.391 sec/iter\n",
      "Epoch: 57 | Batch: 009 / 011 | Total loss: 0.886 | Reg loss: 0.021 | Tree loss: 0.886 | Accuracy: 0.591000 | 0.391 sec/iter\n",
      "Epoch: 57 | Batch: 010 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.617747 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 58 | Batch: 000 / 011 | Total loss: 1.000 | Reg loss: 0.021 | Tree loss: 1.000 | Accuracy: 0.581000 | 0.394 sec/iter\n",
      "Epoch: 58 | Batch: 001 / 011 | Total loss: 0.956 | Reg loss: 0.021 | Tree loss: 0.956 | Accuracy: 0.606500 | 0.394 sec/iter\n",
      "Epoch: 58 | Batch: 002 / 011 | Total loss: 0.942 | Reg loss: 0.021 | Tree loss: 0.942 | Accuracy: 0.590500 | 0.393 sec/iter\n",
      "Epoch: 58 | Batch: 003 / 011 | Total loss: 0.941 | Reg loss: 0.021 | Tree loss: 0.941 | Accuracy: 0.586000 | 0.393 sec/iter\n",
      "Epoch: 58 | Batch: 004 / 011 | Total loss: 0.899 | Reg loss: 0.021 | Tree loss: 0.899 | Accuracy: 0.633500 | 0.393 sec/iter\n",
      "Epoch: 58 | Batch: 005 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.633000 | 0.392 sec/iter\n",
      "Epoch: 58 | Batch: 006 / 011 | Total loss: 0.909 | Reg loss: 0.021 | Tree loss: 0.909 | Accuracy: 0.602000 | 0.392 sec/iter\n",
      "Epoch: 58 | Batch: 007 / 011 | Total loss: 0.885 | Reg loss: 0.021 | Tree loss: 0.885 | Accuracy: 0.617500 | 0.392 sec/iter\n",
      "Epoch: 58 | Batch: 008 / 011 | Total loss: 0.885 | Reg loss: 0.021 | Tree loss: 0.885 | Accuracy: 0.588000 | 0.391 sec/iter\n",
      "Epoch: 58 | Batch: 009 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.593000 | 0.391 sec/iter\n",
      "Epoch: 58 | Batch: 010 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.621160 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 59 | Batch: 000 / 011 | Total loss: 0.976 | Reg loss: 0.021 | Tree loss: 0.976 | Accuracy: 0.580500 | 0.394 sec/iter\n",
      "Epoch: 59 | Batch: 001 / 011 | Total loss: 0.967 | Reg loss: 0.021 | Tree loss: 0.967 | Accuracy: 0.595500 | 0.394 sec/iter\n",
      "Epoch: 59 | Batch: 002 / 011 | Total loss: 0.952 | Reg loss: 0.021 | Tree loss: 0.952 | Accuracy: 0.593000 | 0.394 sec/iter\n",
      "Epoch: 59 | Batch: 003 / 011 | Total loss: 0.927 | Reg loss: 0.021 | Tree loss: 0.927 | Accuracy: 0.600000 | 0.393 sec/iter\n",
      "Epoch: 59 | Batch: 004 / 011 | Total loss: 0.914 | Reg loss: 0.021 | Tree loss: 0.914 | Accuracy: 0.608000 | 0.393 sec/iter\n",
      "Epoch: 59 | Batch: 005 / 011 | Total loss: 0.916 | Reg loss: 0.021 | Tree loss: 0.916 | Accuracy: 0.626000 | 0.393 sec/iter\n",
      "Epoch: 59 | Batch: 006 / 011 | Total loss: 0.884 | Reg loss: 0.021 | Tree loss: 0.884 | Accuracy: 0.646500 | 0.393 sec/iter\n",
      "Epoch: 59 | Batch: 007 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.620000 | 0.392 sec/iter\n",
      "Epoch: 59 | Batch: 008 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.609500 | 0.392 sec/iter\n",
      "Epoch: 59 | Batch: 009 / 011 | Total loss: 0.908 | Reg loss: 0.021 | Tree loss: 0.908 | Accuracy: 0.570000 | 0.392 sec/iter\n",
      "Epoch: 59 | Batch: 010 / 011 | Total loss: 0.922 | Reg loss: 0.021 | Tree loss: 0.922 | Accuracy: 0.600683 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 60 | Batch: 000 / 011 | Total loss: 0.988 | Reg loss: 0.021 | Tree loss: 0.988 | Accuracy: 0.586500 | 0.395 sec/iter\n",
      "Epoch: 60 | Batch: 001 / 011 | Total loss: 0.940 | Reg loss: 0.021 | Tree loss: 0.940 | Accuracy: 0.599500 | 0.394 sec/iter\n",
      "Epoch: 60 | Batch: 002 / 011 | Total loss: 0.909 | Reg loss: 0.021 | Tree loss: 0.909 | Accuracy: 0.628500 | 0.394 sec/iter\n",
      "Epoch: 60 | Batch: 003 / 011 | Total loss: 0.902 | Reg loss: 0.021 | Tree loss: 0.902 | Accuracy: 0.623000 | 0.394 sec/iter\n",
      "Epoch: 60 | Batch: 004 / 011 | Total loss: 0.929 | Reg loss: 0.021 | Tree loss: 0.929 | Accuracy: 0.623500 | 0.393 sec/iter\n",
      "Epoch: 60 | Batch: 005 / 011 | Total loss: 0.912 | Reg loss: 0.021 | Tree loss: 0.912 | Accuracy: 0.598000 | 0.393 sec/iter\n",
      "Epoch: 60 | Batch: 006 / 011 | Total loss: 0.908 | Reg loss: 0.021 | Tree loss: 0.908 | Accuracy: 0.596500 | 0.393 sec/iter\n",
      "Epoch: 60 | Batch: 007 / 011 | Total loss: 0.889 | Reg loss: 0.021 | Tree loss: 0.889 | Accuracy: 0.592000 | 0.392 sec/iter\n",
      "Epoch: 60 | Batch: 008 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.604000 | 0.392 sec/iter\n",
      "Epoch: 60 | Batch: 009 / 011 | Total loss: 0.884 | Reg loss: 0.021 | Tree loss: 0.884 | Accuracy: 0.602000 | 0.392 sec/iter\n",
      "Epoch: 60 | Batch: 010 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.587031 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 61 | Batch: 000 / 011 | Total loss: 0.953 | Reg loss: 0.021 | Tree loss: 0.953 | Accuracy: 0.596000 | 0.395 sec/iter\n",
      "Epoch: 61 | Batch: 001 / 011 | Total loss: 0.972 | Reg loss: 0.021 | Tree loss: 0.972 | Accuracy: 0.582500 | 0.395 sec/iter\n",
      "Epoch: 61 | Batch: 002 / 011 | Total loss: 0.977 | Reg loss: 0.021 | Tree loss: 0.977 | Accuracy: 0.573500 | 0.394 sec/iter\n",
      "Epoch: 61 | Batch: 003 / 011 | Total loss: 0.921 | Reg loss: 0.021 | Tree loss: 0.921 | Accuracy: 0.609000 | 0.394 sec/iter\n",
      "Epoch: 61 | Batch: 004 / 011 | Total loss: 0.905 | Reg loss: 0.021 | Tree loss: 0.905 | Accuracy: 0.624000 | 0.394 sec/iter\n",
      "Epoch: 61 | Batch: 005 / 011 | Total loss: 0.885 | Reg loss: 0.021 | Tree loss: 0.885 | Accuracy: 0.656500 | 0.393 sec/iter\n",
      "Epoch: 61 | Batch: 006 / 011 | Total loss: 0.899 | Reg loss: 0.021 | Tree loss: 0.899 | Accuracy: 0.611000 | 0.393 sec/iter\n",
      "Epoch: 61 | Batch: 007 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.596500 | 0.393 sec/iter\n",
      "Epoch: 61 | Batch: 008 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.606500 | 0.393 sec/iter\n",
      "Epoch: 61 | Batch: 009 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.588000 | 0.392 sec/iter\n",
      "Epoch: 61 | Batch: 010 / 011 | Total loss: 0.946 | Reg loss: 0.021 | Tree loss: 0.946 | Accuracy: 0.552901 | 0.392 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 62 | Batch: 000 / 011 | Total loss: 0.956 | Reg loss: 0.021 | Tree loss: 0.956 | Accuracy: 0.586000 | 0.395 sec/iter\n",
      "Epoch: 62 | Batch: 001 / 011 | Total loss: 0.982 | Reg loss: 0.021 | Tree loss: 0.982 | Accuracy: 0.579000 | 0.395 sec/iter\n",
      "Epoch: 62 | Batch: 002 / 011 | Total loss: 0.947 | Reg loss: 0.021 | Tree loss: 0.947 | Accuracy: 0.595500 | 0.395 sec/iter\n",
      "Epoch: 62 | Batch: 003 / 011 | Total loss: 0.904 | Reg loss: 0.021 | Tree loss: 0.904 | Accuracy: 0.613500 | 0.394 sec/iter\n",
      "Epoch: 62 | Batch: 004 / 011 | Total loss: 0.900 | Reg loss: 0.021 | Tree loss: 0.900 | Accuracy: 0.641500 | 0.394 sec/iter\n",
      "Epoch: 62 | Batch: 005 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.639500 | 0.394 sec/iter\n",
      "Epoch: 62 | Batch: 006 / 011 | Total loss: 0.906 | Reg loss: 0.021 | Tree loss: 0.906 | Accuracy: 0.599500 | 0.394 sec/iter\n",
      "Epoch: 62 | Batch: 007 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.626000 | 0.393 sec/iter\n",
      "Epoch: 62 | Batch: 008 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.602000 | 0.393 sec/iter\n",
      "Epoch: 62 | Batch: 009 / 011 | Total loss: 0.897 | Reg loss: 0.021 | Tree loss: 0.897 | Accuracy: 0.579500 | 0.393 sec/iter\n",
      "Epoch: 62 | Batch: 010 / 011 | Total loss: 0.945 | Reg loss: 0.021 | Tree loss: 0.945 | Accuracy: 0.583618 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 63 | Batch: 000 / 011 | Total loss: 0.958 | Reg loss: 0.021 | Tree loss: 0.958 | Accuracy: 0.604500 | 0.395 sec/iter\n",
      "Epoch: 63 | Batch: 001 / 011 | Total loss: 0.932 | Reg loss: 0.021 | Tree loss: 0.932 | Accuracy: 0.605000 | 0.395 sec/iter\n",
      "Epoch: 63 | Batch: 002 / 011 | Total loss: 0.936 | Reg loss: 0.021 | Tree loss: 0.936 | Accuracy: 0.597000 | 0.395 sec/iter\n",
      "Epoch: 63 | Batch: 003 / 011 | Total loss: 0.904 | Reg loss: 0.021 | Tree loss: 0.904 | Accuracy: 0.620500 | 0.395 sec/iter\n",
      "Epoch: 63 | Batch: 004 / 011 | Total loss: 0.912 | Reg loss: 0.021 | Tree loss: 0.912 | Accuracy: 0.613500 | 0.394 sec/iter\n",
      "Epoch: 63 | Batch: 005 / 011 | Total loss: 0.899 | Reg loss: 0.021 | Tree loss: 0.899 | Accuracy: 0.636500 | 0.394 sec/iter\n",
      "Epoch: 63 | Batch: 006 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.610000 | 0.394 sec/iter\n",
      "Epoch: 63 | Batch: 007 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.617500 | 0.394 sec/iter\n",
      "Epoch: 63 | Batch: 008 / 011 | Total loss: 0.903 | Reg loss: 0.021 | Tree loss: 0.903 | Accuracy: 0.586500 | 0.393 sec/iter\n",
      "Epoch: 63 | Batch: 009 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.597500 | 0.393 sec/iter\n",
      "Epoch: 63 | Batch: 010 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.621160 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 64 | Batch: 000 / 011 | Total loss: 0.982 | Reg loss: 0.021 | Tree loss: 0.982 | Accuracy: 0.594500 | 0.396 sec/iter\n",
      "Epoch: 64 | Batch: 001 / 011 | Total loss: 0.958 | Reg loss: 0.021 | Tree loss: 0.958 | Accuracy: 0.587000 | 0.396 sec/iter\n",
      "Epoch: 64 | Batch: 002 / 011 | Total loss: 0.966 | Reg loss: 0.021 | Tree loss: 0.966 | Accuracy: 0.579000 | 0.395 sec/iter\n",
      "Epoch: 64 | Batch: 003 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.635000 | 0.395 sec/iter\n",
      "Epoch: 64 | Batch: 004 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.627500 | 0.395 sec/iter\n",
      "Epoch: 64 | Batch: 005 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.640500 | 0.395 sec/iter\n",
      "Epoch: 64 | Batch: 006 / 011 | Total loss: 0.887 | Reg loss: 0.021 | Tree loss: 0.887 | Accuracy: 0.620500 | 0.394 sec/iter\n",
      "Epoch: 64 | Batch: 007 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.602000 | 0.394 sec/iter\n",
      "Epoch: 64 | Batch: 008 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.604500 | 0.394 sec/iter\n",
      "Epoch: 64 | Batch: 009 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.598000 | 0.393 sec/iter\n",
      "Epoch: 64 | Batch: 010 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.604096 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 65 | Batch: 000 / 011 | Total loss: 0.969 | Reg loss: 0.021 | Tree loss: 0.969 | Accuracy: 0.590000 | 0.396 sec/iter\n",
      "Epoch: 65 | Batch: 001 / 011 | Total loss: 0.930 | Reg loss: 0.021 | Tree loss: 0.930 | Accuracy: 0.601000 | 0.396 sec/iter\n",
      "Epoch: 65 | Batch: 002 / 011 | Total loss: 0.937 | Reg loss: 0.021 | Tree loss: 0.937 | Accuracy: 0.591000 | 0.396 sec/iter\n",
      "Epoch: 65 | Batch: 003 / 011 | Total loss: 0.913 | Reg loss: 0.021 | Tree loss: 0.913 | Accuracy: 0.621000 | 0.395 sec/iter\n",
      "Epoch: 65 | Batch: 004 / 011 | Total loss: 0.889 | Reg loss: 0.021 | Tree loss: 0.889 | Accuracy: 0.639500 | 0.395 sec/iter\n",
      "Epoch: 65 | Batch: 005 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.645500 | 0.395 sec/iter\n",
      "Epoch: 65 | Batch: 006 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.617500 | 0.394 sec/iter\n",
      "Epoch: 65 | Batch: 007 / 011 | Total loss: 0.889 | Reg loss: 0.021 | Tree loss: 0.889 | Accuracy: 0.582000 | 0.394 sec/iter\n",
      "Epoch: 65 | Batch: 008 / 011 | Total loss: 0.887 | Reg loss: 0.021 | Tree loss: 0.887 | Accuracy: 0.602000 | 0.394 sec/iter\n",
      "Epoch: 65 | Batch: 009 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.581000 | 0.394 sec/iter\n",
      "Epoch: 65 | Batch: 010 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.614334 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 66 | Batch: 000 / 011 | Total loss: 0.952 | Reg loss: 0.021 | Tree loss: 0.952 | Accuracy: 0.595000 | 0.396 sec/iter\n",
      "Epoch: 66 | Batch: 001 / 011 | Total loss: 0.933 | Reg loss: 0.021 | Tree loss: 0.933 | Accuracy: 0.601000 | 0.396 sec/iter\n",
      "Epoch: 66 | Batch: 002 / 011 | Total loss: 0.928 | Reg loss: 0.021 | Tree loss: 0.928 | Accuracy: 0.594000 | 0.396 sec/iter\n",
      "Epoch: 66 | Batch: 003 / 011 | Total loss: 0.934 | Reg loss: 0.021 | Tree loss: 0.934 | Accuracy: 0.591000 | 0.396 sec/iter\n",
      "Epoch: 66 | Batch: 004 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.641500 | 0.395 sec/iter\n",
      "Epoch: 66 | Batch: 005 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.681500 | 0.395 sec/iter\n",
      "Epoch: 66 | Batch: 006 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.618000 | 0.395 sec/iter\n",
      "Epoch: 66 | Batch: 007 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.617500 | 0.395 sec/iter\n",
      "Epoch: 66 | Batch: 008 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.591000 | 0.394 sec/iter\n",
      "Epoch: 66 | Batch: 009 / 011 | Total loss: 0.890 | Reg loss: 0.021 | Tree loss: 0.890 | Accuracy: 0.586000 | 0.394 sec/iter\n",
      "Epoch: 66 | Batch: 010 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.580205 | 0.394 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 | Batch: 000 / 011 | Total loss: 0.935 | Reg loss: 0.021 | Tree loss: 0.935 | Accuracy: 0.606500 | 0.394 sec/iter\n",
      "Epoch: 67 | Batch: 001 / 011 | Total loss: 0.959 | Reg loss: 0.021 | Tree loss: 0.959 | Accuracy: 0.574500 | 0.393 sec/iter\n",
      "Epoch: 67 | Batch: 002 / 011 | Total loss: 0.950 | Reg loss: 0.021 | Tree loss: 0.950 | Accuracy: 0.597500 | 0.393 sec/iter\n",
      "Epoch: 67 | Batch: 003 / 011 | Total loss: 0.916 | Reg loss: 0.021 | Tree loss: 0.916 | Accuracy: 0.599000 | 0.393 sec/iter\n",
      "Epoch: 67 | Batch: 004 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.623000 | 0.393 sec/iter\n",
      "Epoch: 67 | Batch: 005 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.659500 | 0.392 sec/iter\n",
      "Epoch: 67 | Batch: 006 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.612500 | 0.392 sec/iter\n",
      "Epoch: 67 | Batch: 007 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.608500 | 0.392 sec/iter\n",
      "Epoch: 67 | Batch: 008 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.603500 | 0.392 sec/iter\n",
      "Epoch: 67 | Batch: 009 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.597000 | 0.391 sec/iter\n",
      "Epoch: 67 | Batch: 010 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.566553 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 68 | Batch: 000 / 011 | Total loss: 0.941 | Reg loss: 0.021 | Tree loss: 0.941 | Accuracy: 0.606500 | 0.394 sec/iter\n",
      "Epoch: 68 | Batch: 001 / 011 | Total loss: 0.940 | Reg loss: 0.021 | Tree loss: 0.940 | Accuracy: 0.589000 | 0.394 sec/iter\n",
      "Epoch: 68 | Batch: 002 / 011 | Total loss: 0.943 | Reg loss: 0.021 | Tree loss: 0.943 | Accuracy: 0.611000 | 0.393 sec/iter\n",
      "Epoch: 68 | Batch: 003 / 011 | Total loss: 0.911 | Reg loss: 0.021 | Tree loss: 0.911 | Accuracy: 0.620500 | 0.393 sec/iter\n",
      "Epoch: 68 | Batch: 004 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.633500 | 0.393 sec/iter\n",
      "Epoch: 68 | Batch: 005 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.626000 | 0.393 sec/iter\n",
      "Epoch: 68 | Batch: 006 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.610500 | 0.392 sec/iter\n",
      "Epoch: 68 | Batch: 007 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.591500 | 0.392 sec/iter\n",
      "Epoch: 68 | Batch: 008 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.591000 | 0.392 sec/iter\n",
      "Epoch: 68 | Batch: 009 / 011 | Total loss: 0.898 | Reg loss: 0.021 | Tree loss: 0.898 | Accuracy: 0.588500 | 0.392 sec/iter\n",
      "Epoch: 68 | Batch: 010 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.662116 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 69 | Batch: 000 / 011 | Total loss: 0.957 | Reg loss: 0.021 | Tree loss: 0.957 | Accuracy: 0.588500 | 0.394 sec/iter\n",
      "Epoch: 69 | Batch: 001 / 011 | Total loss: 0.933 | Reg loss: 0.021 | Tree loss: 0.933 | Accuracy: 0.590500 | 0.393 sec/iter\n",
      "Epoch: 69 | Batch: 002 / 011 | Total loss: 0.943 | Reg loss: 0.021 | Tree loss: 0.943 | Accuracy: 0.596000 | 0.393 sec/iter\n",
      "Epoch: 69 | Batch: 003 / 011 | Total loss: 0.909 | Reg loss: 0.021 | Tree loss: 0.909 | Accuracy: 0.617000 | 0.393 sec/iter\n",
      "Epoch: 69 | Batch: 004 / 011 | Total loss: 0.886 | Reg loss: 0.021 | Tree loss: 0.886 | Accuracy: 0.641000 | 0.392 sec/iter\n",
      "Epoch: 69 | Batch: 005 / 011 | Total loss: 0.884 | Reg loss: 0.021 | Tree loss: 0.884 | Accuracy: 0.629000 | 0.392 sec/iter\n",
      "Epoch: 69 | Batch: 006 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.641500 | 0.392 sec/iter\n",
      "Epoch: 69 | Batch: 007 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.588500 | 0.392 sec/iter\n",
      "Epoch: 69 | Batch: 008 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.594500 | 0.391 sec/iter\n",
      "Epoch: 69 | Batch: 009 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.601500 | 0.391 sec/iter\n",
      "Epoch: 69 | Batch: 010 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.569966 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 70 | Batch: 000 / 011 | Total loss: 0.949 | Reg loss: 0.021 | Tree loss: 0.949 | Accuracy: 0.594000 | 0.394 sec/iter\n",
      "Epoch: 70 | Batch: 001 / 011 | Total loss: 0.952 | Reg loss: 0.021 | Tree loss: 0.952 | Accuracy: 0.593000 | 0.394 sec/iter\n",
      "Epoch: 70 | Batch: 002 / 011 | Total loss: 0.946 | Reg loss: 0.021 | Tree loss: 0.946 | Accuracy: 0.586000 | 0.393 sec/iter\n",
      "Epoch: 70 | Batch: 003 / 011 | Total loss: 0.905 | Reg loss: 0.021 | Tree loss: 0.905 | Accuracy: 0.615000 | 0.393 sec/iter\n",
      "Epoch: 70 | Batch: 004 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.630000 | 0.393 sec/iter\n",
      "Epoch: 70 | Batch: 005 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.649500 | 0.393 sec/iter\n",
      "Epoch: 70 | Batch: 006 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.618000 | 0.392 sec/iter\n",
      "Epoch: 70 | Batch: 007 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.630000 | 0.392 sec/iter\n",
      "Epoch: 70 | Batch: 008 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.609500 | 0.392 sec/iter\n",
      "Epoch: 70 | Batch: 009 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.593000 | 0.392 sec/iter\n",
      "Epoch: 70 | Batch: 010 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.597270 | 0.391 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 71 | Batch: 000 / 011 | Total loss: 0.954 | Reg loss: 0.021 | Tree loss: 0.954 | Accuracy: 0.585500 | 0.394 sec/iter\n",
      "Epoch: 71 | Batch: 001 / 011 | Total loss: 0.935 | Reg loss: 0.021 | Tree loss: 0.935 | Accuracy: 0.584000 | 0.394 sec/iter\n",
      "Epoch: 71 | Batch: 002 / 011 | Total loss: 0.906 | Reg loss: 0.021 | Tree loss: 0.906 | Accuracy: 0.627500 | 0.394 sec/iter\n",
      "Epoch: 71 | Batch: 003 / 011 | Total loss: 0.923 | Reg loss: 0.021 | Tree loss: 0.923 | Accuracy: 0.613000 | 0.393 sec/iter\n",
      "Epoch: 71 | Batch: 004 / 011 | Total loss: 0.884 | Reg loss: 0.021 | Tree loss: 0.884 | Accuracy: 0.645000 | 0.393 sec/iter\n",
      "Epoch: 71 | Batch: 005 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.640000 | 0.393 sec/iter\n",
      "Epoch: 71 | Batch: 006 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.620500 | 0.393 sec/iter\n",
      "Epoch: 71 | Batch: 007 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.599000 | 0.392 sec/iter\n",
      "Epoch: 71 | Batch: 008 / 011 | Total loss: 0.886 | Reg loss: 0.021 | Tree loss: 0.886 | Accuracy: 0.586500 | 0.392 sec/iter\n",
      "Epoch: 71 | Batch: 009 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.589000 | 0.392 sec/iter\n",
      "Epoch: 71 | Batch: 010 / 011 | Total loss: 0.889 | Reg loss: 0.021 | Tree loss: 0.889 | Accuracy: 0.566553 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 72 | Batch: 000 / 011 | Total loss: 0.944 | Reg loss: 0.021 | Tree loss: 0.944 | Accuracy: 0.589500 | 0.394 sec/iter\n",
      "Epoch: 72 | Batch: 001 / 011 | Total loss: 0.942 | Reg loss: 0.021 | Tree loss: 0.942 | Accuracy: 0.592000 | 0.394 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 | Batch: 002 / 011 | Total loss: 0.910 | Reg loss: 0.021 | Tree loss: 0.910 | Accuracy: 0.603000 | 0.394 sec/iter\n",
      "Epoch: 72 | Batch: 003 / 011 | Total loss: 0.920 | Reg loss: 0.021 | Tree loss: 0.920 | Accuracy: 0.611000 | 0.394 sec/iter\n",
      "Epoch: 72 | Batch: 004 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.620500 | 0.393 sec/iter\n",
      "Epoch: 72 | Batch: 005 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.644000 | 0.393 sec/iter\n",
      "Epoch: 72 | Batch: 006 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.641000 | 0.393 sec/iter\n",
      "Epoch: 72 | Batch: 007 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.619000 | 0.393 sec/iter\n",
      "Epoch: 72 | Batch: 008 / 011 | Total loss: 0.888 | Reg loss: 0.021 | Tree loss: 0.888 | Accuracy: 0.595500 | 0.392 sec/iter\n",
      "Epoch: 72 | Batch: 009 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.594500 | 0.392 sec/iter\n",
      "Epoch: 72 | Batch: 010 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.590444 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 73 | Batch: 000 / 011 | Total loss: 0.924 | Reg loss: 0.021 | Tree loss: 0.924 | Accuracy: 0.596500 | 0.395 sec/iter\n",
      "Epoch: 73 | Batch: 001 / 011 | Total loss: 0.913 | Reg loss: 0.021 | Tree loss: 0.913 | Accuracy: 0.612000 | 0.394 sec/iter\n",
      "Epoch: 73 | Batch: 002 / 011 | Total loss: 0.909 | Reg loss: 0.021 | Tree loss: 0.909 | Accuracy: 0.608000 | 0.394 sec/iter\n",
      "Epoch: 73 | Batch: 003 / 011 | Total loss: 0.914 | Reg loss: 0.021 | Tree loss: 0.914 | Accuracy: 0.602000 | 0.394 sec/iter\n",
      "Epoch: 73 | Batch: 004 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.641000 | 0.394 sec/iter\n",
      "Epoch: 73 | Batch: 005 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.650000 | 0.393 sec/iter\n",
      "Epoch: 73 | Batch: 006 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.617500 | 0.393 sec/iter\n",
      "Epoch: 73 | Batch: 007 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.597000 | 0.393 sec/iter\n",
      "Epoch: 73 | Batch: 008 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.591500 | 0.393 sec/iter\n",
      "Epoch: 73 | Batch: 009 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.595000 | 0.392 sec/iter\n",
      "Epoch: 73 | Batch: 010 / 011 | Total loss: 0.991 | Reg loss: 0.021 | Tree loss: 0.991 | Accuracy: 0.511945 | 0.392 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 74 | Batch: 000 / 011 | Total loss: 0.930 | Reg loss: 0.021 | Tree loss: 0.930 | Accuracy: 0.594500 | 0.395 sec/iter\n",
      "Epoch: 74 | Batch: 001 / 011 | Total loss: 0.961 | Reg loss: 0.021 | Tree loss: 0.961 | Accuracy: 0.583000 | 0.395 sec/iter\n",
      "Epoch: 74 | Batch: 002 / 011 | Total loss: 0.898 | Reg loss: 0.021 | Tree loss: 0.898 | Accuracy: 0.618500 | 0.394 sec/iter\n",
      "Epoch: 74 | Batch: 003 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.631500 | 0.394 sec/iter\n",
      "Epoch: 74 | Batch: 004 / 011 | Total loss: 0.904 | Reg loss: 0.021 | Tree loss: 0.904 | Accuracy: 0.621000 | 0.394 sec/iter\n",
      "Epoch: 74 | Batch: 005 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.663000 | 0.394 sec/iter\n",
      "Epoch: 74 | Batch: 006 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.623000 | 0.393 sec/iter\n",
      "Epoch: 74 | Batch: 007 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.600500 | 0.393 sec/iter\n",
      "Epoch: 74 | Batch: 008 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.595000 | 0.393 sec/iter\n",
      "Epoch: 74 | Batch: 009 / 011 | Total loss: 0.886 | Reg loss: 0.021 | Tree loss: 0.886 | Accuracy: 0.577000 | 0.393 sec/iter\n",
      "Epoch: 74 | Batch: 010 / 011 | Total loss: 0.910 | Reg loss: 0.021 | Tree loss: 0.910 | Accuracy: 0.576792 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 75 | Batch: 000 / 011 | Total loss: 0.944 | Reg loss: 0.021 | Tree loss: 0.944 | Accuracy: 0.601000 | 0.395 sec/iter\n",
      "Epoch: 75 | Batch: 001 / 011 | Total loss: 0.908 | Reg loss: 0.021 | Tree loss: 0.908 | Accuracy: 0.622500 | 0.395 sec/iter\n",
      "Epoch: 75 | Batch: 002 / 011 | Total loss: 0.897 | Reg loss: 0.021 | Tree loss: 0.897 | Accuracy: 0.620500 | 0.395 sec/iter\n",
      "Epoch: 75 | Batch: 003 / 011 | Total loss: 0.904 | Reg loss: 0.021 | Tree loss: 0.904 | Accuracy: 0.629000 | 0.394 sec/iter\n",
      "Epoch: 75 | Batch: 004 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.650500 | 0.394 sec/iter\n",
      "Epoch: 75 | Batch: 005 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.631500 | 0.394 sec/iter\n",
      "Epoch: 75 | Batch: 006 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.598500 | 0.394 sec/iter\n",
      "Epoch: 75 | Batch: 007 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.605000 | 0.393 sec/iter\n",
      "Epoch: 75 | Batch: 008 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.590500 | 0.393 sec/iter\n",
      "Epoch: 75 | Batch: 009 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.585000 | 0.393 sec/iter\n",
      "Epoch: 75 | Batch: 010 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.573379 | 0.393 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 76 | Batch: 000 / 011 | Total loss: 0.935 | Reg loss: 0.021 | Tree loss: 0.935 | Accuracy: 0.591500 | 0.393 sec/iter\n",
      "Epoch: 76 | Batch: 001 / 011 | Total loss: 0.898 | Reg loss: 0.021 | Tree loss: 0.898 | Accuracy: 0.618000 | 0.392 sec/iter\n",
      "Epoch: 76 | Batch: 002 / 011 | Total loss: 0.927 | Reg loss: 0.021 | Tree loss: 0.927 | Accuracy: 0.580000 | 0.392 sec/iter\n",
      "Epoch: 76 | Batch: 003 / 011 | Total loss: 0.890 | Reg loss: 0.021 | Tree loss: 0.890 | Accuracy: 0.615500 | 0.392 sec/iter\n",
      "Epoch: 76 | Batch: 004 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.629500 | 0.392 sec/iter\n",
      "Epoch: 76 | Batch: 005 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.679500 | 0.391 sec/iter\n",
      "Epoch: 76 | Batch: 006 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.636000 | 0.391 sec/iter\n",
      "Epoch: 76 | Batch: 007 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.606000 | 0.391 sec/iter\n",
      "Epoch: 76 | Batch: 008 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.602500 | 0.391 sec/iter\n",
      "Epoch: 76 | Batch: 009 / 011 | Total loss: 0.892 | Reg loss: 0.022 | Tree loss: 0.892 | Accuracy: 0.570000 | 0.391 sec/iter\n",
      "Epoch: 76 | Batch: 010 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.587031 | 0.39 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 77 | Batch: 000 / 011 | Total loss: 0.924 | Reg loss: 0.021 | Tree loss: 0.924 | Accuracy: 0.606500 | 0.39 sec/iter\n",
      "Epoch: 77 | Batch: 001 / 011 | Total loss: 0.909 | Reg loss: 0.021 | Tree loss: 0.909 | Accuracy: 0.610000 | 0.39 sec/iter\n",
      "Epoch: 77 | Batch: 002 / 011 | Total loss: 0.918 | Reg loss: 0.021 | Tree loss: 0.918 | Accuracy: 0.604500 | 0.39 sec/iter\n",
      "Epoch: 77 | Batch: 003 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.626000 | 0.39 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 | Batch: 004 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.640000 | 0.389 sec/iter\n",
      "Epoch: 77 | Batch: 005 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.637500 | 0.389 sec/iter\n",
      "Epoch: 77 | Batch: 006 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.616500 | 0.389 sec/iter\n",
      "Epoch: 77 | Batch: 007 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.591000 | 0.389 sec/iter\n",
      "Epoch: 77 | Batch: 008 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.596000 | 0.388 sec/iter\n",
      "Epoch: 77 | Batch: 009 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.605500 | 0.388 sec/iter\n",
      "Epoch: 77 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.597270 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 78 | Batch: 000 / 011 | Total loss: 0.934 | Reg loss: 0.022 | Tree loss: 0.934 | Accuracy: 0.614000 | 0.388 sec/iter\n",
      "Epoch: 78 | Batch: 001 / 011 | Total loss: 0.923 | Reg loss: 0.022 | Tree loss: 0.923 | Accuracy: 0.599500 | 0.388 sec/iter\n",
      "Epoch: 78 | Batch: 002 / 011 | Total loss: 0.915 | Reg loss: 0.022 | Tree loss: 0.915 | Accuracy: 0.600500 | 0.387 sec/iter\n",
      "Epoch: 78 | Batch: 003 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.625500 | 0.387 sec/iter\n",
      "Epoch: 78 | Batch: 004 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.644500 | 0.387 sec/iter\n",
      "Epoch: 78 | Batch: 005 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.625000 | 0.387 sec/iter\n",
      "Epoch: 78 | Batch: 006 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.622500 | 0.387 sec/iter\n",
      "Epoch: 78 | Batch: 007 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.601500 | 0.386 sec/iter\n",
      "Epoch: 78 | Batch: 008 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.595000 | 0.386 sec/iter\n",
      "Epoch: 78 | Batch: 009 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.626500 | 0.386 sec/iter\n",
      "Epoch: 78 | Batch: 010 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.607509 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 79 | Batch: 000 / 011 | Total loss: 0.923 | Reg loss: 0.022 | Tree loss: 0.923 | Accuracy: 0.606000 | 0.388 sec/iter\n",
      "Epoch: 79 | Batch: 001 / 011 | Total loss: 0.917 | Reg loss: 0.022 | Tree loss: 0.917 | Accuracy: 0.608000 | 0.388 sec/iter\n",
      "Epoch: 79 | Batch: 002 / 011 | Total loss: 0.921 | Reg loss: 0.022 | Tree loss: 0.921 | Accuracy: 0.594000 | 0.388 sec/iter\n",
      "Epoch: 79 | Batch: 003 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.610500 | 0.388 sec/iter\n",
      "Epoch: 79 | Batch: 004 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.634000 | 0.387 sec/iter\n",
      "Epoch: 79 | Batch: 005 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.645000 | 0.387 sec/iter\n",
      "Epoch: 79 | Batch: 006 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.631000 | 0.387 sec/iter\n",
      "Epoch: 79 | Batch: 007 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.617000 | 0.387 sec/iter\n",
      "Epoch: 79 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.608500 | 0.386 sec/iter\n",
      "Epoch: 79 | Batch: 009 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.604000 | 0.386 sec/iter\n",
      "Epoch: 79 | Batch: 010 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.593857 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 80 | Batch: 000 / 011 | Total loss: 0.913 | Reg loss: 0.022 | Tree loss: 0.913 | Accuracy: 0.603500 | 0.388 sec/iter\n",
      "Epoch: 80 | Batch: 001 / 011 | Total loss: 0.929 | Reg loss: 0.022 | Tree loss: 0.929 | Accuracy: 0.590500 | 0.388 sec/iter\n",
      "Epoch: 80 | Batch: 002 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.616000 | 0.388 sec/iter\n",
      "Epoch: 80 | Batch: 003 / 011 | Total loss: 0.916 | Reg loss: 0.022 | Tree loss: 0.916 | Accuracy: 0.605500 | 0.387 sec/iter\n",
      "Epoch: 80 | Batch: 004 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.646500 | 0.387 sec/iter\n",
      "Epoch: 80 | Batch: 005 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.680000 | 0.387 sec/iter\n",
      "Epoch: 80 | Batch: 006 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.653000 | 0.387 sec/iter\n",
      "Epoch: 80 | Batch: 007 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.614000 | 0.387 sec/iter\n",
      "Epoch: 80 | Batch: 008 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.577000 | 0.386 sec/iter\n",
      "Epoch: 80 | Batch: 009 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.593500 | 0.386 sec/iter\n",
      "Epoch: 80 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.576792 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 81 | Batch: 000 / 011 | Total loss: 0.915 | Reg loss: 0.022 | Tree loss: 0.915 | Accuracy: 0.616000 | 0.388 sec/iter\n",
      "Epoch: 81 | Batch: 001 / 011 | Total loss: 0.910 | Reg loss: 0.022 | Tree loss: 0.910 | Accuracy: 0.614500 | 0.388 sec/iter\n",
      "Epoch: 81 | Batch: 002 / 011 | Total loss: 0.912 | Reg loss: 0.022 | Tree loss: 0.912 | Accuracy: 0.609500 | 0.388 sec/iter\n",
      "Epoch: 81 | Batch: 003 / 011 | Total loss: 0.900 | Reg loss: 0.022 | Tree loss: 0.900 | Accuracy: 0.614500 | 0.388 sec/iter\n",
      "Epoch: 81 | Batch: 004 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.675000 | 0.388 sec/iter\n",
      "Epoch: 81 | Batch: 005 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.651000 | 0.387 sec/iter\n",
      "Epoch: 81 | Batch: 006 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.624500 | 0.387 sec/iter\n",
      "Epoch: 81 | Batch: 007 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.598500 | 0.387 sec/iter\n",
      "Epoch: 81 | Batch: 008 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.586000 | 0.387 sec/iter\n",
      "Epoch: 81 | Batch: 009 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.590000 | 0.387 sec/iter\n",
      "Epoch: 81 | Batch: 010 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.587031 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 82 | Batch: 000 / 011 | Total loss: 0.928 | Reg loss: 0.022 | Tree loss: 0.928 | Accuracy: 0.604000 | 0.389 sec/iter\n",
      "Epoch: 82 | Batch: 001 / 011 | Total loss: 0.902 | Reg loss: 0.022 | Tree loss: 0.902 | Accuracy: 0.614500 | 0.388 sec/iter\n",
      "Epoch: 82 | Batch: 002 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.610000 | 0.388 sec/iter\n",
      "Epoch: 82 | Batch: 003 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.620500 | 0.388 sec/iter\n",
      "Epoch: 82 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.653000 | 0.388 sec/iter\n",
      "Epoch: 82 | Batch: 005 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.652000 | 0.388 sec/iter\n",
      "Epoch: 82 | Batch: 006 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.633000 | 0.387 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 | Batch: 007 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.593500 | 0.387 sec/iter\n",
      "Epoch: 82 | Batch: 008 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.612000 | 0.387 sec/iter\n",
      "Epoch: 82 | Batch: 009 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.605500 | 0.387 sec/iter\n",
      "Epoch: 82 | Batch: 010 / 011 | Total loss: 0.908 | Reg loss: 0.022 | Tree loss: 0.908 | Accuracy: 0.563140 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 83 | Batch: 000 / 011 | Total loss: 0.935 | Reg loss: 0.022 | Tree loss: 0.935 | Accuracy: 0.578000 | 0.389 sec/iter\n",
      "Epoch: 83 | Batch: 001 / 011 | Total loss: 0.944 | Reg loss: 0.022 | Tree loss: 0.944 | Accuracy: 0.589000 | 0.389 sec/iter\n",
      "Epoch: 83 | Batch: 002 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.598000 | 0.389 sec/iter\n",
      "Epoch: 83 | Batch: 003 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.657500 | 0.388 sec/iter\n",
      "Epoch: 83 | Batch: 004 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.631000 | 0.388 sec/iter\n",
      "Epoch: 83 | Batch: 005 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.638500 | 0.388 sec/iter\n",
      "Epoch: 83 | Batch: 006 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.637500 | 0.388 sec/iter\n",
      "Epoch: 83 | Batch: 007 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.626500 | 0.388 sec/iter\n",
      "Epoch: 83 | Batch: 008 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.616000 | 0.387 sec/iter\n",
      "Epoch: 83 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.600000 | 0.387 sec/iter\n",
      "Epoch: 83 | Batch: 010 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.576792 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 84 | Batch: 000 / 011 | Total loss: 0.937 | Reg loss: 0.022 | Tree loss: 0.937 | Accuracy: 0.591000 | 0.389 sec/iter\n",
      "Epoch: 84 | Batch: 001 / 011 | Total loss: 0.922 | Reg loss: 0.022 | Tree loss: 0.922 | Accuracy: 0.604000 | 0.389 sec/iter\n",
      "Epoch: 84 | Batch: 002 / 011 | Total loss: 0.917 | Reg loss: 0.022 | Tree loss: 0.917 | Accuracy: 0.590500 | 0.389 sec/iter\n",
      "Epoch: 84 | Batch: 003 / 011 | Total loss: 0.897 | Reg loss: 0.022 | Tree loss: 0.897 | Accuracy: 0.620000 | 0.389 sec/iter\n",
      "Epoch: 84 | Batch: 004 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.644500 | 0.388 sec/iter\n",
      "Epoch: 84 | Batch: 005 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.648000 | 0.388 sec/iter\n",
      "Epoch: 84 | Batch: 006 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.639500 | 0.388 sec/iter\n",
      "Epoch: 84 | Batch: 007 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.619000 | 0.388 sec/iter\n",
      "Epoch: 84 | Batch: 008 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.599000 | 0.388 sec/iter\n",
      "Epoch: 84 | Batch: 009 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.594500 | 0.387 sec/iter\n",
      "Epoch: 84 | Batch: 010 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.624573 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 85 | Batch: 000 / 011 | Total loss: 0.936 | Reg loss: 0.022 | Tree loss: 0.936 | Accuracy: 0.600500 | 0.39 sec/iter\n",
      "Epoch: 85 | Batch: 001 / 011 | Total loss: 0.916 | Reg loss: 0.022 | Tree loss: 0.916 | Accuracy: 0.596500 | 0.389 sec/iter\n",
      "Epoch: 85 | Batch: 002 / 011 | Total loss: 0.904 | Reg loss: 0.022 | Tree loss: 0.904 | Accuracy: 0.605500 | 0.389 sec/iter\n",
      "Epoch: 85 | Batch: 003 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.627500 | 0.389 sec/iter\n",
      "Epoch: 85 | Batch: 004 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.668500 | 0.389 sec/iter\n",
      "Epoch: 85 | Batch: 005 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.617500 | 0.389 sec/iter\n",
      "Epoch: 85 | Batch: 006 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.611000 | 0.388 sec/iter\n",
      "Epoch: 85 | Batch: 007 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.622000 | 0.388 sec/iter\n",
      "Epoch: 85 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.642500 | 0.388 sec/iter\n",
      "Epoch: 85 | Batch: 009 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.610500 | 0.388 sec/iter\n",
      "Epoch: 85 | Batch: 010 / 011 | Total loss: 0.783 | Reg loss: 0.022 | Tree loss: 0.783 | Accuracy: 0.617747 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 86 | Batch: 000 / 011 | Total loss: 0.921 | Reg loss: 0.022 | Tree loss: 0.921 | Accuracy: 0.590500 | 0.39 sec/iter\n",
      "Epoch: 86 | Batch: 001 / 011 | Total loss: 0.928 | Reg loss: 0.022 | Tree loss: 0.928 | Accuracy: 0.588500 | 0.39 sec/iter\n",
      "Epoch: 86 | Batch: 002 / 011 | Total loss: 0.931 | Reg loss: 0.022 | Tree loss: 0.931 | Accuracy: 0.596000 | 0.389 sec/iter\n",
      "Epoch: 86 | Batch: 003 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.598000 | 0.389 sec/iter\n",
      "Epoch: 86 | Batch: 004 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.646500 | 0.389 sec/iter\n",
      "Epoch: 86 | Batch: 005 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.655000 | 0.389 sec/iter\n",
      "Epoch: 86 | Batch: 006 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.653000 | 0.389 sec/iter\n",
      "Epoch: 86 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.629500 | 0.388 sec/iter\n",
      "Epoch: 86 | Batch: 008 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.606000 | 0.388 sec/iter\n",
      "Epoch: 86 | Batch: 009 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.589500 | 0.388 sec/iter\n",
      "Epoch: 86 | Batch: 010 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.621160 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 87 | Batch: 000 / 011 | Total loss: 0.919 | Reg loss: 0.022 | Tree loss: 0.919 | Accuracy: 0.595000 | 0.39 sec/iter\n",
      "Epoch: 87 | Batch: 001 / 011 | Total loss: 0.938 | Reg loss: 0.022 | Tree loss: 0.938 | Accuracy: 0.595500 | 0.39 sec/iter\n",
      "Epoch: 87 | Batch: 002 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.608500 | 0.39 sec/iter\n",
      "Epoch: 87 | Batch: 003 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.641500 | 0.389 sec/iter\n",
      "Epoch: 87 | Batch: 004 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.639500 | 0.389 sec/iter\n",
      "Epoch: 87 | Batch: 005 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.645500 | 0.389 sec/iter\n",
      "Epoch: 87 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.633500 | 0.389 sec/iter\n",
      "Epoch: 87 | Batch: 007 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.620000 | 0.389 sec/iter\n",
      "Epoch: 87 | Batch: 008 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.593500 | 0.388 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 | Batch: 009 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.599500 | 0.388 sec/iter\n",
      "Epoch: 87 | Batch: 010 / 011 | Total loss: 0.914 | Reg loss: 0.022 | Tree loss: 0.914 | Accuracy: 0.556314 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 88 | Batch: 000 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.597500 | 0.39 sec/iter\n",
      "Epoch: 88 | Batch: 001 / 011 | Total loss: 0.899 | Reg loss: 0.022 | Tree loss: 0.899 | Accuracy: 0.616500 | 0.39 sec/iter\n",
      "Epoch: 88 | Batch: 002 / 011 | Total loss: 0.910 | Reg loss: 0.022 | Tree loss: 0.910 | Accuracy: 0.589500 | 0.39 sec/iter\n",
      "Epoch: 88 | Batch: 003 / 011 | Total loss: 0.894 | Reg loss: 0.022 | Tree loss: 0.894 | Accuracy: 0.604000 | 0.39 sec/iter\n",
      "Epoch: 88 | Batch: 004 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.671500 | 0.39 sec/iter\n",
      "Epoch: 88 | Batch: 005 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.653500 | 0.389 sec/iter\n",
      "Epoch: 88 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.637000 | 0.389 sec/iter\n",
      "Epoch: 88 | Batch: 007 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.610000 | 0.389 sec/iter\n",
      "Epoch: 88 | Batch: 008 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.603500 | 0.389 sec/iter\n",
      "Epoch: 88 | Batch: 009 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.606000 | 0.389 sec/iter\n",
      "Epoch: 88 | Batch: 010 / 011 | Total loss: 0.921 | Reg loss: 0.022 | Tree loss: 0.921 | Accuracy: 0.573379 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 89 | Batch: 000 / 011 | Total loss: 0.908 | Reg loss: 0.022 | Tree loss: 0.908 | Accuracy: 0.615000 | 0.388 sec/iter\n",
      "Epoch: 89 | Batch: 001 / 011 | Total loss: 0.902 | Reg loss: 0.022 | Tree loss: 0.902 | Accuracy: 0.605500 | 0.388 sec/iter\n",
      "Epoch: 89 | Batch: 002 / 011 | Total loss: 0.894 | Reg loss: 0.022 | Tree loss: 0.894 | Accuracy: 0.605000 | 0.388 sec/iter\n",
      "Epoch: 89 | Batch: 003 / 011 | Total loss: 0.882 | Reg loss: 0.022 | Tree loss: 0.882 | Accuracy: 0.641000 | 0.388 sec/iter\n",
      "Epoch: 89 | Batch: 004 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.661000 | 0.387 sec/iter\n",
      "Epoch: 89 | Batch: 005 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.635000 | 0.387 sec/iter\n",
      "Epoch: 89 | Batch: 006 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.658500 | 0.387 sec/iter\n",
      "Epoch: 89 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.627500 | 0.387 sec/iter\n",
      "Epoch: 89 | Batch: 008 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.574000 | 0.387 sec/iter\n",
      "Epoch: 89 | Batch: 009 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.588000 | 0.387 sec/iter\n",
      "Epoch: 89 | Batch: 010 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.593857 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 90 | Batch: 000 / 011 | Total loss: 0.894 | Reg loss: 0.022 | Tree loss: 0.894 | Accuracy: 0.621500 | 0.388 sec/iter\n",
      "Epoch: 90 | Batch: 001 / 011 | Total loss: 0.911 | Reg loss: 0.022 | Tree loss: 0.911 | Accuracy: 0.599500 | 0.388 sec/iter\n",
      "Epoch: 90 | Batch: 002 / 011 | Total loss: 0.899 | Reg loss: 0.022 | Tree loss: 0.899 | Accuracy: 0.601500 | 0.388 sec/iter\n",
      "Epoch: 90 | Batch: 003 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.619500 | 0.388 sec/iter\n",
      "Epoch: 90 | Batch: 004 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.650500 | 0.388 sec/iter\n",
      "Epoch: 90 | Batch: 005 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.652500 | 0.388 sec/iter\n",
      "Epoch: 90 | Batch: 006 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.628500 | 0.387 sec/iter\n",
      "Epoch: 90 | Batch: 007 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.603500 | 0.387 sec/iter\n",
      "Epoch: 90 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.617000 | 0.387 sec/iter\n",
      "Epoch: 90 | Batch: 009 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.604500 | 0.387 sec/iter\n",
      "Epoch: 90 | Batch: 010 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.583618 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 91 | Batch: 000 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.619000 | 0.388 sec/iter\n",
      "Epoch: 91 | Batch: 001 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.612000 | 0.388 sec/iter\n",
      "Epoch: 91 | Batch: 002 / 011 | Total loss: 0.894 | Reg loss: 0.022 | Tree loss: 0.894 | Accuracy: 0.633000 | 0.388 sec/iter\n",
      "Epoch: 91 | Batch: 003 / 011 | Total loss: 0.899 | Reg loss: 0.022 | Tree loss: 0.899 | Accuracy: 0.616500 | 0.388 sec/iter\n",
      "Epoch: 91 | Batch: 004 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.656000 | 0.388 sec/iter\n",
      "Epoch: 91 | Batch: 005 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.627000 | 0.387 sec/iter\n",
      "Epoch: 91 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.649500 | 0.387 sec/iter\n",
      "Epoch: 91 | Batch: 007 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.624500 | 0.387 sec/iter\n",
      "Epoch: 91 | Batch: 008 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.588000 | 0.387 sec/iter\n",
      "Epoch: 91 | Batch: 009 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.599500 | 0.387 sec/iter\n",
      "Epoch: 91 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.559727 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 92 | Batch: 000 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.619000 | 0.389 sec/iter\n",
      "Epoch: 92 | Batch: 001 / 011 | Total loss: 0.917 | Reg loss: 0.022 | Tree loss: 0.917 | Accuracy: 0.605000 | 0.388 sec/iter\n",
      "Epoch: 92 | Batch: 002 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.610000 | 0.388 sec/iter\n",
      "Epoch: 92 | Batch: 003 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.601500 | 0.388 sec/iter\n",
      "Epoch: 92 | Batch: 004 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.649500 | 0.388 sec/iter\n",
      "Epoch: 92 | Batch: 005 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.653500 | 0.388 sec/iter\n",
      "Epoch: 92 | Batch: 006 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.641500 | 0.387 sec/iter\n",
      "Epoch: 92 | Batch: 007 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.618000 | 0.387 sec/iter\n",
      "Epoch: 92 | Batch: 008 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.602000 | 0.387 sec/iter\n",
      "Epoch: 92 | Batch: 009 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.600000 | 0.387 sec/iter\n",
      "Epoch: 92 | Batch: 010 / 011 | Total loss: 0.778 | Reg loss: 0.022 | Tree loss: 0.778 | Accuracy: 0.665529 | 0.387 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 93 | Batch: 000 / 011 | Total loss: 0.901 | Reg loss: 0.022 | Tree loss: 0.901 | Accuracy: 0.617500 | 0.389 sec/iter\n",
      "Epoch: 93 | Batch: 001 / 011 | Total loss: 0.923 | Reg loss: 0.022 | Tree loss: 0.923 | Accuracy: 0.596000 | 0.389 sec/iter\n",
      "Epoch: 93 | Batch: 002 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.615000 | 0.388 sec/iter\n",
      "Epoch: 93 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.648500 | 0.388 sec/iter\n",
      "Epoch: 93 | Batch: 004 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.657000 | 0.388 sec/iter\n",
      "Epoch: 93 | Batch: 005 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.636000 | 0.388 sec/iter\n",
      "Epoch: 93 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.022 | Tree loss: 0.818 | Accuracy: 0.647000 | 0.388 sec/iter\n",
      "Epoch: 93 | Batch: 007 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.610000 | 0.388 sec/iter\n",
      "Epoch: 93 | Batch: 008 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.600500 | 0.387 sec/iter\n",
      "Epoch: 93 | Batch: 009 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.608000 | 0.387 sec/iter\n",
      "Epoch: 93 | Batch: 010 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.621160 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 94 | Batch: 000 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.607000 | 0.389 sec/iter\n",
      "Epoch: 94 | Batch: 001 / 011 | Total loss: 0.917 | Reg loss: 0.022 | Tree loss: 0.917 | Accuracy: 0.596500 | 0.389 sec/iter\n",
      "Epoch: 94 | Batch: 002 / 011 | Total loss: 0.902 | Reg loss: 0.022 | Tree loss: 0.902 | Accuracy: 0.601500 | 0.389 sec/iter\n",
      "Epoch: 94 | Batch: 003 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.624000 | 0.389 sec/iter\n",
      "Epoch: 94 | Batch: 004 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.638000 | 0.388 sec/iter\n",
      "Epoch: 94 | Batch: 005 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.653000 | 0.388 sec/iter\n",
      "Epoch: 94 | Batch: 006 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.632000 | 0.388 sec/iter\n",
      "Epoch: 94 | Batch: 007 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.623000 | 0.388 sec/iter\n",
      "Epoch: 94 | Batch: 008 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.616500 | 0.388 sec/iter\n",
      "Epoch: 94 | Batch: 009 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.607500 | 0.387 sec/iter\n",
      "Epoch: 94 | Batch: 010 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.610922 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 95 | Batch: 000 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.614000 | 0.389 sec/iter\n",
      "Epoch: 95 | Batch: 001 / 011 | Total loss: 0.904 | Reg loss: 0.022 | Tree loss: 0.904 | Accuracy: 0.591500 | 0.389 sec/iter\n",
      "Epoch: 95 | Batch: 002 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.612500 | 0.389 sec/iter\n",
      "Epoch: 95 | Batch: 003 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.629000 | 0.389 sec/iter\n",
      "Epoch: 95 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.632000 | 0.389 sec/iter\n",
      "Epoch: 95 | Batch: 005 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.614500 | 0.388 sec/iter\n",
      "Epoch: 95 | Batch: 006 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.635000 | 0.388 sec/iter\n",
      "Epoch: 95 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.622000 | 0.388 sec/iter\n",
      "Epoch: 95 | Batch: 008 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.597500 | 0.388 sec/iter\n",
      "Epoch: 95 | Batch: 009 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.599000 | 0.388 sec/iter\n",
      "Epoch: 95 | Batch: 010 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.580205 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 96 | Batch: 000 / 011 | Total loss: 0.918 | Reg loss: 0.022 | Tree loss: 0.918 | Accuracy: 0.608000 | 0.39 sec/iter\n",
      "Epoch: 96 | Batch: 001 / 011 | Total loss: 0.911 | Reg loss: 0.022 | Tree loss: 0.911 | Accuracy: 0.606000 | 0.389 sec/iter\n",
      "Epoch: 96 | Batch: 002 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.613500 | 0.389 sec/iter\n",
      "Epoch: 96 | Batch: 003 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.607000 | 0.389 sec/iter\n",
      "Epoch: 96 | Batch: 004 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.635000 | 0.389 sec/iter\n",
      "Epoch: 96 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.660000 | 0.389 sec/iter\n",
      "Epoch: 96 | Batch: 006 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.624500 | 0.389 sec/iter\n",
      "Epoch: 96 | Batch: 007 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.636000 | 0.388 sec/iter\n",
      "Epoch: 96 | Batch: 008 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.590000 | 0.388 sec/iter\n",
      "Epoch: 96 | Batch: 009 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.608000 | 0.388 sec/iter\n",
      "Epoch: 96 | Batch: 010 / 011 | Total loss: 0.803 | Reg loss: 0.022 | Tree loss: 0.803 | Accuracy: 0.631399 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 97 | Batch: 000 / 011 | Total loss: 0.905 | Reg loss: 0.022 | Tree loss: 0.905 | Accuracy: 0.596000 | 0.39 sec/iter\n",
      "Epoch: 97 | Batch: 001 / 011 | Total loss: 0.899 | Reg loss: 0.022 | Tree loss: 0.899 | Accuracy: 0.609000 | 0.39 sec/iter\n",
      "Epoch: 97 | Batch: 002 / 011 | Total loss: 0.901 | Reg loss: 0.022 | Tree loss: 0.901 | Accuracy: 0.600500 | 0.39 sec/iter\n",
      "Epoch: 97 | Batch: 003 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.634500 | 0.389 sec/iter\n",
      "Epoch: 97 | Batch: 004 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.639000 | 0.389 sec/iter\n",
      "Epoch: 97 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.628000 | 0.389 sec/iter\n",
      "Epoch: 97 | Batch: 006 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.637000 | 0.389 sec/iter\n",
      "Epoch: 97 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.627000 | 0.389 sec/iter\n",
      "Epoch: 97 | Batch: 008 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.598000 | 0.388 sec/iter\n",
      "Epoch: 97 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.620000 | 0.388 sec/iter\n",
      "Epoch: 97 | Batch: 010 / 011 | Total loss: 0.802 | Reg loss: 0.022 | Tree loss: 0.802 | Accuracy: 0.651877 | 0.388 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 | Batch: 000 / 011 | Total loss: 0.921 | Reg loss: 0.022 | Tree loss: 0.921 | Accuracy: 0.605000 | 0.388 sec/iter\n",
      "Epoch: 98 | Batch: 001 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.618000 | 0.388 sec/iter\n",
      "Epoch: 98 | Batch: 002 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.619000 | 0.388 sec/iter\n",
      "Epoch: 98 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.650000 | 0.387 sec/iter\n",
      "Epoch: 98 | Batch: 004 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.656000 | 0.387 sec/iter\n",
      "Epoch: 98 | Batch: 005 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.648000 | 0.387 sec/iter\n",
      "Epoch: 98 | Batch: 006 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.620500 | 0.387 sec/iter\n",
      "Epoch: 98 | Batch: 007 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.597000 | 0.387 sec/iter\n",
      "Epoch: 98 | Batch: 008 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.609000 | 0.387 sec/iter\n",
      "Epoch: 98 | Batch: 009 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.600500 | 0.386 sec/iter\n",
      "Epoch: 98 | Batch: 010 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.614334 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 99 | Batch: 000 / 011 | Total loss: 0.903 | Reg loss: 0.022 | Tree loss: 0.903 | Accuracy: 0.597500 | 0.388 sec/iter\n",
      "Epoch: 99 | Batch: 001 / 011 | Total loss: 0.900 | Reg loss: 0.022 | Tree loss: 0.900 | Accuracy: 0.602000 | 0.388 sec/iter\n",
      "Epoch: 99 | Batch: 002 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.613000 | 0.388 sec/iter\n",
      "Epoch: 99 | Batch: 003 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.623500 | 0.388 sec/iter\n",
      "Epoch: 99 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.670000 | 0.388 sec/iter\n",
      "Epoch: 99 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.631500 | 0.387 sec/iter\n",
      "Epoch: 99 | Batch: 006 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.643000 | 0.387 sec/iter\n",
      "Epoch: 99 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.618500 | 0.387 sec/iter\n",
      "Epoch: 99 | Batch: 008 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.611000 | 0.387 sec/iter\n",
      "Epoch: 99 | Batch: 009 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.590000 | 0.387 sec/iter\n",
      "Epoch: 99 | Batch: 010 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.604096 | 0.387 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 100 | Batch: 000 / 011 | Total loss: 0.901 | Reg loss: 0.022 | Tree loss: 0.901 | Accuracy: 0.607500 | 0.388 sec/iter\n",
      "Epoch: 100 | Batch: 001 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.613000 | 0.388 sec/iter\n",
      "Epoch: 100 | Batch: 002 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.607000 | 0.388 sec/iter\n",
      "Epoch: 100 | Batch: 003 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.621500 | 0.387 sec/iter\n",
      "Epoch: 100 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.647500 | 0.387 sec/iter\n",
      "Epoch: 100 | Batch: 005 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.646000 | 0.387 sec/iter\n",
      "Epoch: 100 | Batch: 006 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.645500 | 0.387 sec/iter\n",
      "Epoch: 100 | Batch: 007 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.641500 | 0.387 sec/iter\n",
      "Epoch: 100 | Batch: 008 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.610500 | 0.387 sec/iter\n",
      "Epoch: 100 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.630000 | 0.386 sec/iter\n",
      "Epoch: 100 | Batch: 010 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.621160 | 0.386 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 101 | Batch: 000 / 011 | Total loss: 0.893 | Reg loss: 0.022 | Tree loss: 0.893 | Accuracy: 0.607500 | 0.387 sec/iter\n",
      "Epoch: 101 | Batch: 001 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.612500 | 0.386 sec/iter\n",
      "Epoch: 101 | Batch: 002 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.601000 | 0.386 sec/iter\n",
      "Epoch: 101 | Batch: 003 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.635000 | 0.386 sec/iter\n",
      "Epoch: 101 | Batch: 004 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.659000 | 0.386 sec/iter\n",
      "Epoch: 101 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.652500 | 0.386 sec/iter\n",
      "Epoch: 101 | Batch: 006 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.639000 | 0.385 sec/iter\n",
      "Epoch: 101 | Batch: 007 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.600000 | 0.385 sec/iter\n",
      "Epoch: 101 | Batch: 008 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.610000 | 0.385 sec/iter\n",
      "Epoch: 101 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.629000 | 0.385 sec/iter\n",
      "Epoch: 101 | Batch: 010 / 011 | Total loss: 0.903 | Reg loss: 0.022 | Tree loss: 0.903 | Accuracy: 0.569966 | 0.385 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 102 | Batch: 000 / 011 | Total loss: 0.916 | Reg loss: 0.022 | Tree loss: 0.916 | Accuracy: 0.611500 | 0.385 sec/iter\n",
      "Epoch: 102 | Batch: 001 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.617000 | 0.385 sec/iter\n",
      "Epoch: 102 | Batch: 002 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.606500 | 0.384 sec/iter\n",
      "Epoch: 102 | Batch: 003 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.622500 | 0.384 sec/iter\n",
      "Epoch: 102 | Batch: 004 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.629500 | 0.384 sec/iter\n",
      "Epoch: 102 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.639500 | 0.384 sec/iter\n",
      "Epoch: 102 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.637500 | 0.384 sec/iter\n",
      "Epoch: 102 | Batch: 007 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.616000 | 0.384 sec/iter\n",
      "Epoch: 102 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.619500 | 0.383 sec/iter\n",
      "Epoch: 102 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.631500 | 0.383 sec/iter\n",
      "Epoch: 102 | Batch: 010 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.607509 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 103 | Batch: 000 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.607000 | 0.385 sec/iter\n",
      "Epoch: 103 | Batch: 001 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.611000 | 0.385 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103 | Batch: 002 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.606500 | 0.385 sec/iter\n",
      "Epoch: 103 | Batch: 003 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.619500 | 0.384 sec/iter\n",
      "Epoch: 103 | Batch: 004 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.641000 | 0.384 sec/iter\n",
      "Epoch: 103 | Batch: 005 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.650500 | 0.384 sec/iter\n",
      "Epoch: 103 | Batch: 006 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.649500 | 0.384 sec/iter\n",
      "Epoch: 103 | Batch: 007 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.606500 | 0.384 sec/iter\n",
      "Epoch: 103 | Batch: 008 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.622000 | 0.384 sec/iter\n",
      "Epoch: 103 | Batch: 009 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.621000 | 0.383 sec/iter\n",
      "Epoch: 103 | Batch: 010 / 011 | Total loss: 0.796 | Reg loss: 0.022 | Tree loss: 0.796 | Accuracy: 0.624573 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 104 | Batch: 000 / 011 | Total loss: 0.903 | Reg loss: 0.022 | Tree loss: 0.903 | Accuracy: 0.604500 | 0.385 sec/iter\n",
      "Epoch: 104 | Batch: 001 / 011 | Total loss: 0.890 | Reg loss: 0.022 | Tree loss: 0.890 | Accuracy: 0.611500 | 0.385 sec/iter\n",
      "Epoch: 104 | Batch: 002 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.603000 | 0.385 sec/iter\n",
      "Epoch: 104 | Batch: 003 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.620500 | 0.385 sec/iter\n",
      "Epoch: 104 | Batch: 004 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.620000 | 0.384 sec/iter\n",
      "Epoch: 104 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.656000 | 0.384 sec/iter\n",
      "Epoch: 104 | Batch: 006 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.628500 | 0.384 sec/iter\n",
      "Epoch: 104 | Batch: 007 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.600000 | 0.384 sec/iter\n",
      "Epoch: 104 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.632500 | 0.384 sec/iter\n",
      "Epoch: 104 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.638000 | 0.384 sec/iter\n",
      "Epoch: 104 | Batch: 010 / 011 | Total loss: 0.790 | Reg loss: 0.022 | Tree loss: 0.790 | Accuracy: 0.648464 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 105 | Batch: 000 / 011 | Total loss: 0.905 | Reg loss: 0.022 | Tree loss: 0.905 | Accuracy: 0.597000 | 0.385 sec/iter\n",
      "Epoch: 105 | Batch: 001 / 011 | Total loss: 0.894 | Reg loss: 0.022 | Tree loss: 0.894 | Accuracy: 0.599000 | 0.385 sec/iter\n",
      "Epoch: 105 | Batch: 002 / 011 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.618000 | 0.385 sec/iter\n",
      "Epoch: 105 | Batch: 003 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.636500 | 0.385 sec/iter\n",
      "Epoch: 105 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.640000 | 0.385 sec/iter\n",
      "Epoch: 105 | Batch: 005 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.648500 | 0.385 sec/iter\n",
      "Epoch: 105 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.637500 | 0.384 sec/iter\n",
      "Epoch: 105 | Batch: 007 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.621000 | 0.384 sec/iter\n",
      "Epoch: 105 | Batch: 008 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.603500 | 0.384 sec/iter\n",
      "Epoch: 105 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.624500 | 0.384 sec/iter\n",
      "Epoch: 105 | Batch: 010 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.617747 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 106 | Batch: 000 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.619500 | 0.386 sec/iter\n",
      "Epoch: 106 | Batch: 001 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.600500 | 0.385 sec/iter\n",
      "Epoch: 106 | Batch: 002 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.615500 | 0.385 sec/iter\n",
      "Epoch: 106 | Batch: 003 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.630500 | 0.385 sec/iter\n",
      "Epoch: 106 | Batch: 004 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.645000 | 0.385 sec/iter\n",
      "Epoch: 106 | Batch: 005 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.656000 | 0.385 sec/iter\n",
      "Epoch: 106 | Batch: 006 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.625500 | 0.385 sec/iter\n",
      "Epoch: 106 | Batch: 007 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.624500 | 0.384 sec/iter\n",
      "Epoch: 106 | Batch: 008 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.601000 | 0.384 sec/iter\n",
      "Epoch: 106 | Batch: 009 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.602000 | 0.384 sec/iter\n",
      "Epoch: 106 | Batch: 010 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.604096 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 107 | Batch: 000 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.591500 | 0.386 sec/iter\n",
      "Epoch: 107 | Batch: 001 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.609000 | 0.386 sec/iter\n",
      "Epoch: 107 | Batch: 002 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.611500 | 0.386 sec/iter\n",
      "Epoch: 107 | Batch: 003 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.623500 | 0.385 sec/iter\n",
      "Epoch: 107 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.635000 | 0.385 sec/iter\n",
      "Epoch: 107 | Batch: 005 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.661500 | 0.385 sec/iter\n",
      "Epoch: 107 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.639000 | 0.385 sec/iter\n",
      "Epoch: 107 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.623000 | 0.385 sec/iter\n",
      "Epoch: 107 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.621500 | 0.385 sec/iter\n",
      "Epoch: 107 | Batch: 009 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.596500 | 0.384 sec/iter\n",
      "Epoch: 107 | Batch: 010 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.610922 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 108 | Batch: 000 / 011 | Total loss: 0.901 | Reg loss: 0.022 | Tree loss: 0.901 | Accuracy: 0.605000 | 0.386 sec/iter\n",
      "Epoch: 108 | Batch: 001 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.613000 | 0.386 sec/iter\n",
      "Epoch: 108 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.628000 | 0.386 sec/iter\n",
      "Epoch: 108 | Batch: 003 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.617500 | 0.386 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108 | Batch: 004 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.643000 | 0.385 sec/iter\n",
      "Epoch: 108 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.657000 | 0.385 sec/iter\n",
      "Epoch: 108 | Batch: 006 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.629500 | 0.385 sec/iter\n",
      "Epoch: 108 | Batch: 007 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.613000 | 0.385 sec/iter\n",
      "Epoch: 108 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.620000 | 0.385 sec/iter\n",
      "Epoch: 108 | Batch: 009 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.617000 | 0.385 sec/iter\n",
      "Epoch: 108 | Batch: 010 / 011 | Total loss: 0.900 | Reg loss: 0.022 | Tree loss: 0.900 | Accuracy: 0.610922 | 0.385 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 109 | Batch: 000 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.612500 | 0.386 sec/iter\n",
      "Epoch: 109 | Batch: 001 / 011 | Total loss: 0.905 | Reg loss: 0.022 | Tree loss: 0.905 | Accuracy: 0.598500 | 0.386 sec/iter\n",
      "Epoch: 109 | Batch: 002 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.639000 | 0.386 sec/iter\n",
      "Epoch: 109 | Batch: 003 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.629500 | 0.386 sec/iter\n",
      "Epoch: 109 | Batch: 004 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.638000 | 0.386 sec/iter\n",
      "Epoch: 109 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.625000 | 0.386 sec/iter\n",
      "Epoch: 109 | Batch: 006 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.632000 | 0.385 sec/iter\n",
      "Epoch: 109 | Batch: 007 / 011 | Total loss: 0.804 | Reg loss: 0.022 | Tree loss: 0.804 | Accuracy: 0.640500 | 0.385 sec/iter\n",
      "Epoch: 109 | Batch: 008 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.601000 | 0.385 sec/iter\n",
      "Epoch: 109 | Batch: 009 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.612500 | 0.385 sec/iter\n",
      "Epoch: 109 | Batch: 010 / 011 | Total loss: 0.882 | Reg loss: 0.022 | Tree loss: 0.882 | Accuracy: 0.556314 | 0.385 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 110 | Batch: 000 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.607500 | 0.387 sec/iter\n",
      "Epoch: 110 | Batch: 001 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.611000 | 0.386 sec/iter\n",
      "Epoch: 110 | Batch: 002 / 011 | Total loss: 0.908 | Reg loss: 0.022 | Tree loss: 0.908 | Accuracy: 0.582500 | 0.386 sec/iter\n",
      "Epoch: 110 | Batch: 003 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.629500 | 0.386 sec/iter\n",
      "Epoch: 110 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.667500 | 0.386 sec/iter\n",
      "Epoch: 110 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.680500 | 0.386 sec/iter\n",
      "Epoch: 110 | Batch: 006 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.620000 | 0.386 sec/iter\n",
      "Epoch: 110 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.626500 | 0.385 sec/iter\n",
      "Epoch: 110 | Batch: 008 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.618000 | 0.385 sec/iter\n",
      "Epoch: 110 | Batch: 009 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.594500 | 0.385 sec/iter\n",
      "Epoch: 110 | Batch: 010 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.610922 | 0.385 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 111 | Batch: 000 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.618500 | 0.385 sec/iter\n",
      "Epoch: 111 | Batch: 001 / 011 | Total loss: 0.892 | Reg loss: 0.022 | Tree loss: 0.892 | Accuracy: 0.621500 | 0.385 sec/iter\n",
      "Epoch: 111 | Batch: 002 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.632000 | 0.385 sec/iter\n",
      "Epoch: 111 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.661000 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.648500 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 005 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.603500 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 006 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.617000 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.625500 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 008 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.605500 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.629000 | 0.384 sec/iter\n",
      "Epoch: 111 | Batch: 010 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.638225 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 112 | Batch: 000 / 011 | Total loss: 0.893 | Reg loss: 0.022 | Tree loss: 0.893 | Accuracy: 0.619000 | 0.385 sec/iter\n",
      "Epoch: 112 | Batch: 001 / 011 | Total loss: 0.891 | Reg loss: 0.022 | Tree loss: 0.891 | Accuracy: 0.614000 | 0.385 sec/iter\n",
      "Epoch: 112 | Batch: 002 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.607000 | 0.385 sec/iter\n",
      "Epoch: 112 | Batch: 003 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.632000 | 0.385 sec/iter\n",
      "Epoch: 112 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.663500 | 0.385 sec/iter\n",
      "Epoch: 112 | Batch: 005 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.649500 | 0.384 sec/iter\n",
      "Epoch: 112 | Batch: 006 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.629500 | 0.384 sec/iter\n",
      "Epoch: 112 | Batch: 007 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.607500 | 0.384 sec/iter\n",
      "Epoch: 112 | Batch: 008 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.620000 | 0.384 sec/iter\n",
      "Epoch: 112 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.608000 | 0.384 sec/iter\n",
      "Epoch: 112 | Batch: 010 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.600683 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 113 | Batch: 000 / 011 | Total loss: 0.890 | Reg loss: 0.022 | Tree loss: 0.890 | Accuracy: 0.613000 | 0.385 sec/iter\n",
      "Epoch: 113 | Batch: 001 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.608500 | 0.385 sec/iter\n",
      "Epoch: 113 | Batch: 002 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.625500 | 0.385 sec/iter\n",
      "Epoch: 113 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.617500 | 0.385 sec/iter\n",
      "Epoch: 113 | Batch: 004 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.652500 | 0.384 sec/iter\n",
      "Epoch: 113 | Batch: 005 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.659000 | 0.384 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113 | Batch: 006 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.625000 | 0.384 sec/iter\n",
      "Epoch: 113 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.621500 | 0.384 sec/iter\n",
      "Epoch: 113 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.635500 | 0.384 sec/iter\n",
      "Epoch: 113 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.622500 | 0.384 sec/iter\n",
      "Epoch: 113 | Batch: 010 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.624573 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 114 | Batch: 000 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.618500 | 0.385 sec/iter\n",
      "Epoch: 114 | Batch: 001 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.608000 | 0.385 sec/iter\n",
      "Epoch: 114 | Batch: 002 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.636500 | 0.385 sec/iter\n",
      "Epoch: 114 | Batch: 003 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.630000 | 0.385 sec/iter\n",
      "Epoch: 114 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.652000 | 0.385 sec/iter\n",
      "Epoch: 114 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.654000 | 0.384 sec/iter\n",
      "Epoch: 114 | Batch: 006 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.633500 | 0.384 sec/iter\n",
      "Epoch: 114 | Batch: 007 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.619000 | 0.384 sec/iter\n",
      "Epoch: 114 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.627000 | 0.384 sec/iter\n",
      "Epoch: 114 | Batch: 009 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.604000 | 0.384 sec/iter\n",
      "Epoch: 114 | Batch: 010 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.600683 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 115 | Batch: 000 / 011 | Total loss: 0.893 | Reg loss: 0.022 | Tree loss: 0.893 | Accuracy: 0.600500 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.628000 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 002 / 011 | Total loss: 0.882 | Reg loss: 0.022 | Tree loss: 0.882 | Accuracy: 0.613500 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.630000 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.657000 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.660000 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.639500 | 0.385 sec/iter\n",
      "Epoch: 115 | Batch: 007 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.628500 | 0.384 sec/iter\n",
      "Epoch: 115 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.618000 | 0.384 sec/iter\n",
      "Epoch: 115 | Batch: 009 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.605500 | 0.384 sec/iter\n",
      "Epoch: 115 | Batch: 010 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.587031 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 116 | Batch: 000 / 011 | Total loss: 0.908 | Reg loss: 0.022 | Tree loss: 0.908 | Accuracy: 0.595500 | 0.386 sec/iter\n",
      "Epoch: 116 | Batch: 001 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.624500 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.648000 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.636500 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.643500 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 005 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.641000 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.634000 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.609500 | 0.385 sec/iter\n",
      "Epoch: 116 | Batch: 008 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.610500 | 0.384 sec/iter\n",
      "Epoch: 116 | Batch: 009 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.604000 | 0.384 sec/iter\n",
      "Epoch: 116 | Batch: 010 / 011 | Total loss: 0.795 | Reg loss: 0.022 | Tree loss: 0.795 | Accuracy: 0.631399 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 117 | Batch: 000 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.596500 | 0.386 sec/iter\n",
      "Epoch: 117 | Batch: 001 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.610500 | 0.386 sec/iter\n",
      "Epoch: 117 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.628500 | 0.386 sec/iter\n",
      "Epoch: 117 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.637000 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 004 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.650500 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.643500 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 006 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.623500 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 007 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.613000 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.639000 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 009 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.610500 | 0.385 sec/iter\n",
      "Epoch: 117 | Batch: 010 / 011 | Total loss: 0.791 | Reg loss: 0.022 | Tree loss: 0.791 | Accuracy: 0.621160 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 118 | Batch: 000 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.604500 | 0.384 sec/iter\n",
      "Epoch: 118 | Batch: 001 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.620000 | 0.384 sec/iter\n",
      "Epoch: 118 | Batch: 002 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.621500 | 0.384 sec/iter\n",
      "Epoch: 118 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.625500 | 0.384 sec/iter\n",
      "Epoch: 118 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.651500 | 0.384 sec/iter\n",
      "Epoch: 118 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.653000 | 0.384 sec/iter\n",
      "Epoch: 118 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.639000 | 0.383 sec/iter\n",
      "Epoch: 118 | Batch: 007 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.617500 | 0.383 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.633000 | 0.383 sec/iter\n",
      "Epoch: 118 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.629000 | 0.383 sec/iter\n",
      "Epoch: 118 | Batch: 010 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.583618 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 119 | Batch: 000 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.609000 | 0.385 sec/iter\n",
      "Epoch: 119 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.619000 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 002 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.620500 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 003 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.631000 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 004 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.640500 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.631500 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.632000 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.644500 | 0.384 sec/iter\n",
      "Epoch: 119 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.604500 | 0.383 sec/iter\n",
      "Epoch: 119 | Batch: 009 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.606000 | 0.383 sec/iter\n",
      "Epoch: 119 | Batch: 010 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.590444 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 120 | Batch: 000 / 011 | Total loss: 0.888 | Reg loss: 0.022 | Tree loss: 0.888 | Accuracy: 0.609000 | 0.384 sec/iter\n",
      "Epoch: 120 | Batch: 001 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.610500 | 0.384 sec/iter\n",
      "Epoch: 120 | Batch: 002 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.615500 | 0.384 sec/iter\n",
      "Epoch: 120 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.645000 | 0.384 sec/iter\n",
      "Epoch: 120 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.654500 | 0.384 sec/iter\n",
      "Epoch: 120 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.644500 | 0.384 sec/iter\n",
      "Epoch: 120 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.619500 | 0.383 sec/iter\n",
      "Epoch: 120 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.636000 | 0.383 sec/iter\n",
      "Epoch: 120 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.602000 | 0.383 sec/iter\n",
      "Epoch: 120 | Batch: 009 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.586500 | 0.383 sec/iter\n",
      "Epoch: 120 | Batch: 010 / 011 | Total loss: 0.779 | Reg loss: 0.022 | Tree loss: 0.779 | Accuracy: 0.627986 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 121 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.627000 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 001 / 011 | Total loss: 0.892 | Reg loss: 0.022 | Tree loss: 0.892 | Accuracy: 0.596500 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 002 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.586500 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 003 / 011 | Total loss: 0.888 | Reg loss: 0.022 | Tree loss: 0.888 | Accuracy: 0.611500 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 004 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.660000 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.677500 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.651000 | 0.384 sec/iter\n",
      "Epoch: 121 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.638000 | 0.383 sec/iter\n",
      "Epoch: 121 | Batch: 008 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.598500 | 0.383 sec/iter\n",
      "Epoch: 121 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.613000 | 0.383 sec/iter\n",
      "Epoch: 121 | Batch: 010 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.590444 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 122 | Batch: 000 / 011 | Total loss: 0.910 | Reg loss: 0.022 | Tree loss: 0.910 | Accuracy: 0.601000 | 0.385 sec/iter\n",
      "Epoch: 122 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.620000 | 0.385 sec/iter\n",
      "Epoch: 122 | Batch: 002 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.608500 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.649500 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 004 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.642000 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.650500 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.638500 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.622000 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.625000 | 0.384 sec/iter\n",
      "Epoch: 122 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.630000 | 0.383 sec/iter\n",
      "Epoch: 122 | Batch: 010 / 011 | Total loss: 0.818 | Reg loss: 0.022 | Tree loss: 0.818 | Accuracy: 0.621160 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 123 | Batch: 000 / 011 | Total loss: 0.882 | Reg loss: 0.022 | Tree loss: 0.882 | Accuracy: 0.617500 | 0.385 sec/iter\n",
      "Epoch: 123 | Batch: 001 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.616000 | 0.385 sec/iter\n",
      "Epoch: 123 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.629000 | 0.385 sec/iter\n",
      "Epoch: 123 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.633500 | 0.384 sec/iter\n",
      "Epoch: 123 | Batch: 004 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.662500 | 0.384 sec/iter\n",
      "Epoch: 123 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.644000 | 0.384 sec/iter\n",
      "Epoch: 123 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.637000 | 0.384 sec/iter\n",
      "Epoch: 123 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.628500 | 0.384 sec/iter\n",
      "Epoch: 123 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.635000 | 0.384 sec/iter\n",
      "Epoch: 123 | Batch: 009 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.614000 | 0.384 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123 | Batch: 010 / 011 | Total loss: 0.906 | Reg loss: 0.022 | Tree loss: 0.906 | Accuracy: 0.539249 | 0.383 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 124 | Batch: 000 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.612000 | 0.385 sec/iter\n",
      "Epoch: 124 | Batch: 001 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.611500 | 0.385 sec/iter\n",
      "Epoch: 124 | Batch: 002 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.628500 | 0.385 sec/iter\n",
      "Epoch: 124 | Batch: 003 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.630000 | 0.385 sec/iter\n",
      "Epoch: 124 | Batch: 004 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.634500 | 0.385 sec/iter\n",
      "Epoch: 124 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.676000 | 0.384 sec/iter\n",
      "Epoch: 124 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.636500 | 0.384 sec/iter\n",
      "Epoch: 124 | Batch: 007 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.616500 | 0.384 sec/iter\n",
      "Epoch: 124 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.616500 | 0.384 sec/iter\n",
      "Epoch: 124 | Batch: 009 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.602000 | 0.384 sec/iter\n",
      "Epoch: 124 | Batch: 010 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.587031 | 0.384 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 125 | Batch: 000 / 011 | Total loss: 0.892 | Reg loss: 0.022 | Tree loss: 0.892 | Accuracy: 0.614500 | 0.384 sec/iter\n",
      "Epoch: 125 | Batch: 001 / 011 | Total loss: 0.893 | Reg loss: 0.022 | Tree loss: 0.893 | Accuracy: 0.605500 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 002 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.607500 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.635500 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.655000 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.650000 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 006 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.634000 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.637000 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.616500 | 0.383 sec/iter\n",
      "Epoch: 125 | Batch: 009 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.619500 | 0.382 sec/iter\n",
      "Epoch: 125 | Batch: 010 / 011 | Total loss: 0.759 | Reg loss: 0.022 | Tree loss: 0.759 | Accuracy: 0.641638 | 0.382 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 126 | Batch: 000 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.612500 | 0.382 sec/iter\n",
      "Epoch: 126 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.610000 | 0.382 sec/iter\n",
      "Epoch: 126 | Batch: 002 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.627000 | 0.382 sec/iter\n",
      "Epoch: 126 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.638000 | 0.382 sec/iter\n",
      "Epoch: 126 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.669500 | 0.382 sec/iter\n",
      "Epoch: 126 | Batch: 005 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 126 | Batch: 006 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 126 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 126 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 126 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 126 | Batch: 010 / 011 | Total loss: 0.766 | Reg loss: 0.022 | Tree loss: 0.766 | Accuracy: 0.662116 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 127 | Batch: 000 / 011 | Total loss: 0.890 | Reg loss: 0.022 | Tree loss: 0.890 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 127 | Batch: 001 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 127 | Batch: 002 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 005 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.608000 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 127 | Batch: 010 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.607509 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 128 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 128 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 128 | Batch: 002 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.607500 | 0.381 sec/iter\n",
      "Epoch: 128 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 128 | Batch: 004 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 128 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 128 | Batch: 006 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 128 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 128 | Batch: 008 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 128 | Batch: 009 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.600000 | 0.38 sec/iter\n",
      "Epoch: 128 | Batch: 010 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.607509 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 129 | Batch: 000 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 129 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 129 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 129 | Batch: 003 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 129 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.672000 | 0.38 sec/iter\n",
      "Epoch: 129 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 129 | Batch: 006 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 129 | Batch: 007 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 129 | Batch: 008 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.597500 | 0.38 sec/iter\n",
      "Epoch: 129 | Batch: 009 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.607000 | 0.38 sec/iter\n",
      "Epoch: 129 | Batch: 010 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 130 | Batch: 000 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 130 | Batch: 001 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 130 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 130 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 130 | Batch: 004 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 130 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 130 | Batch: 006 / 011 | Total loss: 0.798 | Reg loss: 0.022 | Tree loss: 0.798 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 130 | Batch: 007 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 130 | Batch: 008 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 130 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 130 | Batch: 010 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 131 | Batch: 000 / 011 | Total loss: 0.882 | Reg loss: 0.022 | Tree loss: 0.882 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.667500 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 006 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 007 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 131 | Batch: 008 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.602000 | 0.38 sec/iter\n",
      "Epoch: 131 | Batch: 009 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.602000 | 0.38 sec/iter\n",
      "Epoch: 131 | Batch: 010 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 132 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.636500 | 0.382 sec/iter\n",
      "Epoch: 132 | Batch: 001 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.623000 | 0.382 sec/iter\n",
      "Epoch: 132 | Batch: 002 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 007 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.596500 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 008 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 009 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 132 | Batch: 010 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 133 | Batch: 000 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.631500 | 0.382 sec/iter\n",
      "Epoch: 133 | Batch: 001 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.606000 | 0.382 sec/iter\n",
      "Epoch: 133 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.626500 | 0.382 sec/iter\n",
      "Epoch: 133 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.641500 | 0.382 sec/iter\n",
      "Epoch: 133 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 133 | Batch: 005 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 133 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 133 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 133 | Batch: 008 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.600000 | 0.381 sec/iter\n",
      "Epoch: 133 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 133 | Batch: 010 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.645051 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 134 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.632000 | 0.382 sec/iter\n",
      "Epoch: 134 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.620500 | 0.382 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134 | Batch: 002 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.628500 | 0.382 sec/iter\n",
      "Epoch: 134 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.645500 | 0.382 sec/iter\n",
      "Epoch: 134 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.653000 | 0.382 sec/iter\n",
      "Epoch: 134 | Batch: 005 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.649000 | 0.382 sec/iter\n",
      "Epoch: 134 | Batch: 006 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 134 | Batch: 007 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.605500 | 0.381 sec/iter\n",
      "Epoch: 134 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 134 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 134 | Batch: 010 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 135 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.616500 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 001 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.620000 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.641000 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 003 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.607500 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.653500 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 005 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.627000 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.647000 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.631500 | 0.382 sec/iter\n",
      "Epoch: 135 | Batch: 008 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 135 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 135 | Batch: 010 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 136 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.615000 | 0.383 sec/iter\n",
      "Epoch: 136 | Batch: 001 / 011 | Total loss: 0.895 | Reg loss: 0.022 | Tree loss: 0.895 | Accuracy: 0.599000 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.638000 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.627000 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.671500 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 005 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.636000 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.640000 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 007 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.625500 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.621500 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.612500 | 0.382 sec/iter\n",
      "Epoch: 136 | Batch: 010 / 011 | Total loss: 0.795 | Reg loss: 0.022 | Tree loss: 0.795 | Accuracy: 0.621160 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 137 | Batch: 000 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.628000 | 0.383 sec/iter\n",
      "Epoch: 137 | Batch: 001 / 011 | Total loss: 0.890 | Reg loss: 0.022 | Tree loss: 0.890 | Accuracy: 0.607000 | 0.383 sec/iter\n",
      "Epoch: 137 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.634500 | 0.383 sec/iter\n",
      "Epoch: 137 | Batch: 003 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.626500 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.654500 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.626500 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 006 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.624000 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.622500 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.640000 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 009 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.615500 | 0.382 sec/iter\n",
      "Epoch: 137 | Batch: 010 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.590444 | 0.382 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 138 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.633000 | 0.382 sec/iter\n",
      "Epoch: 138 | Batch: 001 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.664000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 008 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 138 | Batch: 009 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.614000 | 0.38 sec/iter\n",
      "Epoch: 138 | Batch: 010 / 011 | Total loss: 0.809 | Reg loss: 0.022 | Tree loss: 0.809 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 139 | Batch: 000 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.633000 | 0.382 sec/iter\n",
      "Epoch: 139 | Batch: 001 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.616000 | 0.382 sec/iter\n",
      "Epoch: 139 | Batch: 002 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.628500 | 0.382 sec/iter\n",
      "Epoch: 139 | Batch: 003 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.629500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139 | Batch: 004 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 139 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 139 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 139 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 139 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.614500 | 0.381 sec/iter\n",
      "Epoch: 139 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 139 | Batch: 010 / 011 | Total loss: 0.795 | Reg loss: 0.022 | Tree loss: 0.795 | Accuracy: 0.621160 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 140 | Batch: 000 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.606000 | 0.382 sec/iter\n",
      "Epoch: 140 | Batch: 001 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.632000 | 0.382 sec/iter\n",
      "Epoch: 140 | Batch: 002 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.656500 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 005 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 006 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 008 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.608000 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 140 | Batch: 010 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.607509 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 141 | Batch: 000 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.614500 | 0.382 sec/iter\n",
      "Epoch: 141 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.624500 | 0.382 sec/iter\n",
      "Epoch: 141 | Batch: 002 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.612500 | 0.382 sec/iter\n",
      "Epoch: 141 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.641500 | 0.382 sec/iter\n",
      "Epoch: 141 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.667500 | 0.381 sec/iter\n",
      "Epoch: 141 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 141 | Batch: 006 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 141 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.022 | Tree loss: 0.806 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 141 | Batch: 008 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.611000 | 0.381 sec/iter\n",
      "Epoch: 141 | Batch: 009 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 141 | Batch: 010 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.600683 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 142 | Batch: 000 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.617500 | 0.382 sec/iter\n",
      "Epoch: 142 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.627500 | 0.382 sec/iter\n",
      "Epoch: 142 | Batch: 002 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.618500 | 0.382 sec/iter\n",
      "Epoch: 142 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.636500 | 0.382 sec/iter\n",
      "Epoch: 142 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.647500 | 0.382 sec/iter\n",
      "Epoch: 142 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.022 | Tree loss: 0.818 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 142 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 142 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 142 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.022 | Tree loss: 0.807 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 142 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 142 | Batch: 010 / 011 | Total loss: 0.887 | Reg loss: 0.022 | Tree loss: 0.887 | Accuracy: 0.583618 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 143 | Batch: 000 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.631000 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 001 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.614500 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 002 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.625000 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.632000 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 004 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.642500 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.667000 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 006 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.640000 | 0.382 sec/iter\n",
      "Epoch: 143 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 143 | Batch: 008 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.606500 | 0.381 sec/iter\n",
      "Epoch: 143 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 143 | Batch: 010 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 144 | Batch: 000 / 011 | Total loss: 0.889 | Reg loss: 0.022 | Tree loss: 0.889 | Accuracy: 0.611500 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 001 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.621000 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.633500 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.664000 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.663000 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.637500 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 006 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.631500 | 0.382 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.633000 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 008 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.607000 | 0.382 sec/iter\n",
      "Epoch: 144 | Batch: 009 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.589000 | 0.381 sec/iter\n",
      "Epoch: 144 | Batch: 010 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.587031 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 145 | Batch: 000 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 145 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 145 | Batch: 010 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 146 | Batch: 000 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.609000 | 0.382 sec/iter\n",
      "Epoch: 146 | Batch: 001 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.608500 | 0.382 sec/iter\n",
      "Epoch: 146 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.658000 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.653500 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.614500 | 0.381 sec/iter\n",
      "Epoch: 146 | Batch: 010 / 011 | Total loss: 0.789 | Reg loss: 0.022 | Tree loss: 0.789 | Accuracy: 0.631399 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 147 | Batch: 000 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.613500 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 003 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 004 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 005 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 147 | Batch: 007 / 011 | Total loss: 0.804 | Reg loss: 0.022 | Tree loss: 0.804 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 147 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 147 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 147 | Batch: 010 / 011 | Total loss: 0.802 | Reg loss: 0.022 | Tree loss: 0.802 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 148 | Batch: 000 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 001 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 004 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.665000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.610000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 148 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 148 | Batch: 010 / 011 | Total loss: 0.878 | Reg loss: 0.022 | Tree loss: 0.878 | Accuracy: 0.590444 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 149 | Batch: 000 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.619000 | 0.382 sec/iter\n",
      "Epoch: 149 | Batch: 001 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.628500 | 0.382 sec/iter\n",
      "Epoch: 149 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.672000 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 005 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 006 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.612500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.022 | Tree loss: 0.804 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 149 | Batch: 010 / 011 | Total loss: 0.796 | Reg loss: 0.022 | Tree loss: 0.796 | Accuracy: 0.675768 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 150 | Batch: 000 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 150 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 150 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 150 | Batch: 003 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 150 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.680500 | 0.38 sec/iter\n",
      "Epoch: 150 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 150 | Batch: 006 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 150 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 150 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 150 | Batch: 009 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 150 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 151 | Batch: 000 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 151 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 151 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.641500 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.653000 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.637000 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.613500 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.621500 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 007 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.613000 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.630500 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 009 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.625000 | 0.379 sec/iter\n",
      "Epoch: 151 | Batch: 010 / 011 | Total loss: 0.800 | Reg loss: 0.022 | Tree loss: 0.800 | Accuracy: 0.655290 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 152 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.611500 | 0.38 sec/iter\n",
      "Epoch: 152 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 152 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 152 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 152 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.642500 | 0.379 sec/iter\n",
      "Epoch: 152 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 152 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 152 | Batch: 007 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.617500 | 0.379 sec/iter\n",
      "Epoch: 152 | Batch: 008 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.637000 | 0.379 sec/iter\n",
      "Epoch: 152 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.644000 | 0.379 sec/iter\n",
      "Epoch: 152 | Batch: 010 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.614334 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 153 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.611000 | 0.38 sec/iter\n",
      "Epoch: 153 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 153 | Batch: 002 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.600500 | 0.38 sec/iter\n",
      "Epoch: 153 | Batch: 003 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 153 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.669000 | 0.38 sec/iter\n",
      "Epoch: 153 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 153 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.648000 | 0.379 sec/iter\n",
      "Epoch: 153 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.647000 | 0.379 sec/iter\n",
      "Epoch: 153 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.626000 | 0.379 sec/iter\n",
      "Epoch: 153 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 153 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.621160 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 154 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 001 / 011 | Total loss: 0.874 | Reg loss: 0.022 | Tree loss: 0.874 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 002 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 003 / 011 | Total loss: 0.859 | Reg loss: 0.022 | Tree loss: 0.859 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 005 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.022 | Tree loss: 0.818 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.022 | Tree loss: 0.809 | Accuracy: 0.656000 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.022 | Tree loss: 0.807 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 154 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.022 | Tree loss: 0.804 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 154 | Batch: 010 / 011 | Total loss: 0.793 | Reg loss: 0.022 | Tree loss: 0.793 | Accuracy: 0.675768 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 155 | Batch: 000 / 011 | Total loss: 0.884 | Reg loss: 0.022 | Tree loss: 0.884 | Accuracy: 0.609500 | 0.381 sec/iter\n",
      "Epoch: 155 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.658500 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 155 | Batch: 010 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 156 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 156 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.613500 | 0.381 sec/iter\n",
      "Epoch: 156 | Batch: 002 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 156 | Batch: 003 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 006 / 011 | Total loss: 0.800 | Reg loss: 0.022 | Tree loss: 0.800 | Accuracy: 0.662000 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 009 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.610000 | 0.38 sec/iter\n",
      "Epoch: 156 | Batch: 010 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.590444 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 157 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 157 | Batch: 001 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 157 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 157 | Batch: 003 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 157 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 157 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.656000 | 0.38 sec/iter\n",
      "Epoch: 157 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 157 | Batch: 007 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.609000 | 0.38 sec/iter\n",
      "Epoch: 157 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 157 | Batch: 009 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 157 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 158 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 003 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 158 | Batch: 007 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 158 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 158 | Batch: 009 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 158 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.648464 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 159 | Batch: 000 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.022 | Tree loss: 0.883 | Accuracy: 0.599000 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 004 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 005 / 011 | Total loss: 0.795 | Reg loss: 0.022 | Tree loss: 0.795 | Accuracy: 0.667500 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.022 | Tree loss: 0.803 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.022 | Tree loss: 0.836 | Accuracy: 0.609000 | 0.381 sec/iter\n",
      "Epoch: 159 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 159 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 159 | Batch: 010 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 160 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.633000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 | Batch: 001 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 002 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.657500 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 007 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 160 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 160 | Batch: 009 / 011 | Total loss: 0.841 | Reg loss: 0.022 | Tree loss: 0.841 | Accuracy: 0.601000 | 0.379 sec/iter\n",
      "Epoch: 160 | Batch: 010 / 011 | Total loss: 0.745 | Reg loss: 0.022 | Tree loss: 0.745 | Accuracy: 0.662116 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 161 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 001 / 011 | Total loss: 0.892 | Reg loss: 0.022 | Tree loss: 0.892 | Accuracy: 0.601500 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 009 / 011 | Total loss: 0.851 | Reg loss: 0.022 | Tree loss: 0.851 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 161 | Batch: 010 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.621160 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 162 | Batch: 000 / 011 | Total loss: 0.897 | Reg loss: 0.022 | Tree loss: 0.897 | Accuracy: 0.606000 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.608000 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 002 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.611000 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 162 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 162 | Batch: 009 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.614500 | 0.379 sec/iter\n",
      "Epoch: 162 | Batch: 010 / 011 | Total loss: 0.754 | Reg loss: 0.022 | Tree loss: 0.754 | Accuracy: 0.651877 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 163 | Batch: 000 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 005 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 163 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.607509 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 164 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 164 | Batch: 001 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.593500 | 0.381 sec/iter\n",
      "Epoch: 164 | Batch: 002 / 011 | Total loss: 0.881 | Reg loss: 0.022 | Tree loss: 0.881 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.658500 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.669500 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.646500 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 008 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 164 | Batch: 010 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.610922 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 165 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 165 | Batch: 001 / 011 | Total loss: 0.891 | Reg loss: 0.022 | Tree loss: 0.891 | Accuracy: 0.608500 | 0.381 sec/iter\n",
      "Epoch: 165 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.642500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 165 | Batch: 004 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 165 | Batch: 005 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 165 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 165 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.611500 | 0.38 sec/iter\n",
      "Epoch: 165 | Batch: 008 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 165 | Batch: 009 / 011 | Total loss: 0.800 | Reg loss: 0.022 | Tree loss: 0.800 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 165 | Batch: 010 / 011 | Total loss: 0.779 | Reg loss: 0.022 | Tree loss: 0.779 | Accuracy: 0.648464 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 166 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 166 | Batch: 001 / 011 | Total loss: 0.886 | Reg loss: 0.022 | Tree loss: 0.886 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 166 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 166 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 166 | Batch: 004 / 011 | Total loss: 0.788 | Reg loss: 0.022 | Tree loss: 0.788 | Accuracy: 0.673500 | 0.381 sec/iter\n",
      "Epoch: 166 | Batch: 005 / 011 | Total loss: 0.815 | Reg loss: 0.022 | Tree loss: 0.815 | Accuracy: 0.671500 | 0.381 sec/iter\n",
      "Epoch: 166 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 166 | Batch: 007 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.598000 | 0.38 sec/iter\n",
      "Epoch: 166 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.605500 | 0.38 sec/iter\n",
      "Epoch: 166 | Batch: 009 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 166 | Batch: 010 / 011 | Total loss: 0.780 | Reg loss: 0.022 | Tree loss: 0.780 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 167 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.022 | Tree loss: 0.864 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.659500 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 005 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 167 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.022 | Tree loss: 0.808 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 167 | Batch: 009 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 167 | Batch: 010 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.600683 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 168 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.604000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.656000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 005 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 006 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 168 | Batch: 010 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 169 | Batch: 000 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.022 | Tree loss: 0.862 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 004 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 169 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.587031 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 170 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 170 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 170 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 003 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.649000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 170 | Batch: 010 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 171 | Batch: 000 / 011 | Total loss: 0.873 | Reg loss: 0.022 | Tree loss: 0.873 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.022 | Tree loss: 0.875 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 004 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.022 | Tree loss: 0.806 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 008 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 171 | Batch: 010 / 011 | Total loss: 0.790 | Reg loss: 0.022 | Tree loss: 0.790 | Accuracy: 0.638225 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 172 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 172 | Batch: 001 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.648000 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 003 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.022 | Tree loss: 0.806 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 008 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 009 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.600500 | 0.38 sec/iter\n",
      "Epoch: 172 | Batch: 010 / 011 | Total loss: 0.854 | Reg loss: 0.022 | Tree loss: 0.854 | Accuracy: 0.580205 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 173 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.022 | Tree loss: 0.858 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 173 | Batch: 001 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.614500 | 0.381 sec/iter\n",
      "Epoch: 173 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 173 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 005 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.609500 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 173 | Batch: 010 / 011 | Total loss: 0.791 | Reg loss: 0.022 | Tree loss: 0.791 | Accuracy: 0.638225 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 174 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.022 | Tree loss: 0.872 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 003 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.022 | Tree loss: 0.808 | Accuracy: 0.661500 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 006 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.022 | Tree loss: 0.801 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 174 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.602000 | 0.379 sec/iter\n",
      "Epoch: 174 | Batch: 009 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.617000 | 0.379 sec/iter\n",
      "Epoch: 174 | Batch: 010 / 011 | Total loss: 0.920 | Reg loss: 0.022 | Tree loss: 0.920 | Accuracy: 0.573379 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 175 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.635000 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.657500 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.646500 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.659000 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 006 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 175 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.627500 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175 | Batch: 008 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.610000 | 0.378 sec/iter\n",
      "Epoch: 175 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.628000 | 0.378 sec/iter\n",
      "Epoch: 175 | Batch: 010 / 011 | Total loss: 0.807 | Reg loss: 0.022 | Tree loss: 0.807 | Accuracy: 0.638225 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 176 | Batch: 000 / 011 | Total loss: 0.892 | Reg loss: 0.022 | Tree loss: 0.892 | Accuracy: 0.621500 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 003 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.655500 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.628000 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 005 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.626000 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.022 | Tree loss: 0.806 | Accuracy: 0.635000 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.620000 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.616000 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.609500 | 0.379 sec/iter\n",
      "Epoch: 176 | Batch: 010 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.624573 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 177 | Batch: 000 / 011 | Total loss: 0.879 | Reg loss: 0.022 | Tree loss: 0.879 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 177 | Batch: 001 / 011 | Total loss: 0.865 | Reg loss: 0.022 | Tree loss: 0.865 | Accuracy: 0.622500 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.644000 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.022 | Tree loss: 0.850 | Accuracy: 0.644500 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.656000 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.022 | Tree loss: 0.813 | Accuracy: 0.643500 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 007 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.636500 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.635000 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.626000 | 0.379 sec/iter\n",
      "Epoch: 177 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.627986 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 178 | Batch: 000 / 011 | Total loss: 0.833 | Reg loss: 0.022 | Tree loss: 0.833 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 178 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.022 | Tree loss: 0.869 | Accuracy: 0.600000 | 0.38 sec/iter\n",
      "Epoch: 178 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.022 | Tree loss: 0.834 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 178 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.022 | Tree loss: 0.852 | Accuracy: 0.638000 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.022 | Tree loss: 0.821 | Accuracy: 0.630500 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 005 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.617500 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.022 | Tree loss: 0.828 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.022 | Tree loss: 0.812 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.633000 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.022 | Tree loss: 0.823 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 178 | Batch: 010 / 011 | Total loss: 0.799 | Reg loss: 0.022 | Tree loss: 0.799 | Accuracy: 0.679181 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 179 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 179 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 179 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 179 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 179 | Batch: 004 / 011 | Total loss: 0.838 | Reg loss: 0.022 | Tree loss: 0.838 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 179 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.629500 | 0.379 sec/iter\n",
      "Epoch: 179 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.623000 | 0.379 sec/iter\n",
      "Epoch: 179 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 179 | Batch: 008 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.613000 | 0.379 sec/iter\n",
      "Epoch: 179 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.619000 | 0.379 sec/iter\n",
      "Epoch: 179 | Batch: 010 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.617747 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 180 | Batch: 000 / 011 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.022 | Tree loss: 0.839 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 002 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.022 | Tree loss: 0.856 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.022 | Tree loss: 0.819 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.022 | Tree loss: 0.827 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 180 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.624000 | 0.379 sec/iter\n",
      "Epoch: 180 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.619500 | 0.379 sec/iter\n",
      "Epoch: 180 | Batch: 010 / 011 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.607509 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 181 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.022 | Tree loss: 0.868 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.022 | Tree loss: 0.861 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.022 | Tree loss: 0.829 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.022 | Tree loss: 0.843 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 004 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.022 | Tree loss: 0.835 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.022 | Tree loss: 0.826 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 181 | Batch: 010 / 011 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.576792 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 182 | Batch: 000 / 011 | Total loss: 0.855 | Reg loss: 0.022 | Tree loss: 0.855 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 182 | Batch: 001 / 011 | Total loss: 0.885 | Reg loss: 0.022 | Tree loss: 0.885 | Accuracy: 0.606000 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 002 / 011 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 003 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.022 | Tree loss: 0.816 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.022 | Tree loss: 0.840 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 006 / 011 | Total loss: 0.793 | Reg loss: 0.022 | Tree loss: 0.793 | Accuracy: 0.665500 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.022 | Tree loss: 0.804 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 182 | Batch: 010 / 011 | Total loss: 0.790 | Reg loss: 0.022 | Tree loss: 0.790 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 183 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.022 | Tree loss: 0.860 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 183 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.022 | Tree loss: 0.853 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 183 | Batch: 002 / 011 | Total loss: 0.871 | Reg loss: 0.022 | Tree loss: 0.871 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 183 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.022 | Tree loss: 0.842 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.022 | Tree loss: 0.831 | Accuracy: 0.603000 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 008 / 011 | Total loss: 0.844 | Reg loss: 0.022 | Tree loss: 0.844 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 009 / 011 | Total loss: 0.807 | Reg loss: 0.022 | Tree loss: 0.807 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 183 | Batch: 010 / 011 | Total loss: 0.867 | Reg loss: 0.022 | Tree loss: 0.867 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 184 | Batch: 000 / 011 | Total loss: 0.866 | Reg loss: 0.022 | Tree loss: 0.866 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 184 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.022 | Tree loss: 0.876 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 184 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.022 | Tree loss: 0.845 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 184 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.022 | Tree loss: 0.857 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 184 | Batch: 004 / 011 | Total loss: 0.804 | Reg loss: 0.022 | Tree loss: 0.804 | Accuracy: 0.665500 | 0.381 sec/iter\n",
      "Epoch: 184 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 184 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.022 | Tree loss: 0.830 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 184 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.022 | Tree loss: 0.811 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 184 | Batch: 008 / 011 | Total loss: 0.849 | Reg loss: 0.022 | Tree loss: 0.849 | Accuracy: 0.600000 | 0.38 sec/iter\n",
      "Epoch: 184 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 184 | Batch: 010 / 011 | Total loss: 0.848 | Reg loss: 0.022 | Tree loss: 0.848 | Accuracy: 0.610922 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 185 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 002 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.654500 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.022 | Tree loss: 0.824 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 005 / 011 | Total loss: 0.846 | Reg loss: 0.022 | Tree loss: 0.846 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 006 / 011 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 185 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.022 | Tree loss: 0.810 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 185 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 185 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.022 | Tree loss: 0.818 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 185 | Batch: 010 / 011 | Total loss: 0.863 | Reg loss: 0.022 | Tree loss: 0.863 | Accuracy: 0.576792 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 186 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.627000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186 | Batch: 001 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 002 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 003 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.660000 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 007 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 186 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.022 | Tree loss: 0.822 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 186 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.022 | Tree loss: 0.832 | Accuracy: 0.617000 | 0.379 sec/iter\n",
      "Epoch: 186 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.022 | Tree loss: 0.847 | Accuracy: 0.627986 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 187 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 001 / 011 | Total loss: 0.893 | Reg loss: 0.021 | Tree loss: 0.893 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 006 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 009 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 187 | Batch: 010 / 011 | Total loss: 0.794 | Reg loss: 0.022 | Tree loss: 0.794 | Accuracy: 0.627986 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 188 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 001 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 003 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.654500 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 006 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 008 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 188 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 188 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.604096 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 189 | Batch: 000 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 189 | Batch: 010 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.621160 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 190 | Batch: 000 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 190 | Batch: 001 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.648000 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 006 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 007 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 190 | Batch: 010 / 011 | Total loss: 0.776 | Reg loss: 0.021 | Tree loss: 0.776 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 191 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 191 | Batch: 001 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 191 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.640000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.658000 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 005 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 006 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 191 | Batch: 010 / 011 | Total loss: 0.900 | Reg loss: 0.021 | Tree loss: 0.900 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 192 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 192 | Batch: 001 / 011 | Total loss: 0.885 | Reg loss: 0.021 | Tree loss: 0.885 | Accuracy: 0.607500 | 0.381 sec/iter\n",
      "Epoch: 192 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 192 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.676000 | 0.381 sec/iter\n",
      "Epoch: 192 | Batch: 004 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.672500 | 0.381 sec/iter\n",
      "Epoch: 192 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 192 | Batch: 006 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.661000 | 0.38 sec/iter\n",
      "Epoch: 192 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 192 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 192 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.611500 | 0.38 sec/iter\n",
      "Epoch: 192 | Batch: 010 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.569966 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 193 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 004 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.669500 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 007 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.605500 | 0.381 sec/iter\n",
      "Epoch: 193 | Batch: 008 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 193 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 193 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.600683 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 194 | Batch: 000 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 003 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 007 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.601000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 008 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 194 | Batch: 010 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 195 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 195 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 005 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 008 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.603000 | 0.38 sec/iter\n",
      "Epoch: 195 | Batch: 010 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.573379 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 196 | Batch: 000 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.658000 | 0.381 sec/iter\n",
      "Epoch: 196 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.610500 | 0.381 sec/iter\n",
      "Epoch: 196 | Batch: 002 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.610500 | 0.381 sec/iter\n",
      "Epoch: 196 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 196 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.638500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 196 | Batch: 005 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 196 | Batch: 006 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 196 | Batch: 007 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 196 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 196 | Batch: 009 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.593500 | 0.38 sec/iter\n",
      "Epoch: 196 | Batch: 010 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 197 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 002 / 011 | Total loss: 0.884 | Reg loss: 0.021 | Tree loss: 0.884 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 006 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 197 | Batch: 010 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.600683 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 198 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 198 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 198 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 198 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.647000 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.644500 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 005 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.644000 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.623000 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 198 | Batch: 010 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.593857 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 199 | Batch: 000 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.648000 | 0.379 sec/iter\n",
      "Epoch: 199 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 199 | Batch: 002 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.615000 | 0.379 sec/iter\n",
      "Epoch: 199 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.640000 | 0.379 sec/iter\n",
      "Epoch: 199 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.644500 | 0.378 sec/iter\n",
      "Epoch: 199 | Batch: 005 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.663000 | 0.378 sec/iter\n",
      "Epoch: 199 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.640000 | 0.378 sec/iter\n",
      "Epoch: 199 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.628500 | 0.378 sec/iter\n",
      "Epoch: 199 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 199 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 199 | Batch: 010 / 011 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.638225 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 200 | Batch: 000 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 001 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 004 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.643000 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.631000 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 200 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.632500 | 0.378 sec/iter\n",
      "Epoch: 200 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.630500 | 0.378 sec/iter\n",
      "Epoch: 200 | Batch: 009 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.628000 | 0.378 sec/iter\n",
      "Epoch: 200 | Batch: 010 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.610922 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 201 | Batch: 000 / 011 | Total loss: 0.897 | Reg loss: 0.021 | Tree loss: 0.897 | Accuracy: 0.603500 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.652500 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 002 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 004 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.658000 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 005 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.630500 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.625000 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.625000 | 0.379 sec/iter\n",
      "Epoch: 201 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.632000 | 0.378 sec/iter\n",
      "Epoch: 201 | Batch: 010 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.627986 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 202 | Batch: 000 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.647500 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 002 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.600500 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 003 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.627000 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.646000 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.637500 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.641500 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.628000 | 0.379 sec/iter\n",
      "Epoch: 202 | Batch: 010 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.597270 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 203 | Batch: 000 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 203 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.609000 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 003 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.644000 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.641500 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.644000 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.637000 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.604500 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.621500 | 0.379 sec/iter\n",
      "Epoch: 203 | Batch: 010 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.614334 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 204 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 204 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 204 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 204 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 204 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.660000 | 0.379 sec/iter\n",
      "Epoch: 204 | Batch: 005 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 204 | Batch: 006 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.652500 | 0.379 sec/iter\n",
      "Epoch: 204 | Batch: 007 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.605500 | 0.379 sec/iter\n",
      "Epoch: 204 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 204 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.613500 | 0.379 sec/iter\n",
      "Epoch: 204 | Batch: 010 / 011 | Total loss: 0.742 | Reg loss: 0.021 | Tree loss: 0.742 | Accuracy: 0.675768 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 205 | Batch: 000 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 205 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 205 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 205 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 205 | Batch: 004 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 205 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 205 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.638000 | 0.379 sec/iter\n",
      "Epoch: 205 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.649000 | 0.379 sec/iter\n",
      "Epoch: 205 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.631000 | 0.379 sec/iter\n",
      "Epoch: 205 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.606000 | 0.379 sec/iter\n",
      "Epoch: 205 | Batch: 010 / 011 | Total loss: 0.747 | Reg loss: 0.021 | Tree loss: 0.747 | Accuracy: 0.645051 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 206 | Batch: 000 / 011 | Total loss: 0.886 | Reg loss: 0.021 | Tree loss: 0.886 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.658000 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 004 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 006 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 206 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.620000 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206 | Batch: 009 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.634000 | 0.379 sec/iter\n",
      "Epoch: 206 | Batch: 010 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.645051 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 207 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 001 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 002 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.611500 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 004 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 005 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.659500 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 008 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.602000 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 207 | Batch: 010 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 208 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 001 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 002 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.664000 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.663000 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 007 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.613000 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 208 | Batch: 010 / 011 | Total loss: 0.786 | Reg loss: 0.021 | Tree loss: 0.786 | Accuracy: 0.689420 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 209 | Batch: 000 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 209 | Batch: 001 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 209 | Batch: 002 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 006 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 209 | Batch: 010 / 011 | Total loss: 0.776 | Reg loss: 0.021 | Tree loss: 0.776 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 210 | Batch: 000 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 210 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 210 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 210 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.652500 | 0.381 sec/iter\n",
      "Epoch: 210 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 210 | Batch: 005 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 210 | Batch: 006 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 210 | Batch: 007 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 210 | Batch: 008 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 210 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 210 | Batch: 010 / 011 | Total loss: 0.770 | Reg loss: 0.021 | Tree loss: 0.770 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 211 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 211 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 211 | Batch: 002 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 211 | Batch: 003 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 211 | Batch: 004 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.659500 | 0.381 sec/iter\n",
      "Epoch: 211 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 211 | Batch: 006 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 211 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 211 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 211 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 211 | Batch: 010 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 212 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.613500 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 003 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.665000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 212 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.621000 | 0.379 sec/iter\n",
      "Epoch: 212 | Batch: 009 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 212 | Batch: 010 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.648464 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 213 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 002 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 006 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 213 | Batch: 010 / 011 | Total loss: 0.734 | Reg loss: 0.021 | Tree loss: 0.734 | Accuracy: 0.675768 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 214 | Batch: 000 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 001 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.656000 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 005 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 214 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.620000 | 0.379 sec/iter\n",
      "Epoch: 214 | Batch: 010 / 011 | Total loss: 0.771 | Reg loss: 0.021 | Tree loss: 0.771 | Accuracy: 0.655290 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 215 | Batch: 000 / 011 | Total loss: 0.895 | Reg loss: 0.021 | Tree loss: 0.895 | Accuracy: 0.604500 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 007 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 008 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 215 | Batch: 010 / 011 | Total loss: 0.777 | Reg loss: 0.021 | Tree loss: 0.777 | Accuracy: 0.665529 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 216 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 006 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 216 | Batch: 010 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 217 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 217 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.631000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 217 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 006 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 008 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 217 | Batch: 010 / 011 | Total loss: 0.785 | Reg loss: 0.021 | Tree loss: 0.785 | Accuracy: 0.679181 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 218 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 218 | Batch: 001 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 218 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 218 | Batch: 003 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 218 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 218 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 218 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 218 | Batch: 007 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 218 | Batch: 008 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 218 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 218 | Batch: 010 / 011 | Total loss: 0.787 | Reg loss: 0.021 | Tree loss: 0.787 | Accuracy: 0.675768 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 219 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 219 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 219 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 219 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 219 | Batch: 004 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 219 | Batch: 005 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 219 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 219 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 219 | Batch: 008 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 219 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 219 | Batch: 010 / 011 | Total loss: 0.903 | Reg loss: 0.021 | Tree loss: 0.903 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 220 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 004 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.653000 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 006 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 220 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 220 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 220 | Batch: 010 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 221 | Batch: 000 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.656000 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 001 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 006 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 221 | Batch: 010 / 011 | Total loss: 0.778 | Reg loss: 0.021 | Tree loss: 0.778 | Accuracy: 0.682594 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 222 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 001 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 002 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.642000 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 222 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.653000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.622500 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.633000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 009 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 222 | Batch: 010 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.631399 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 223 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.621000 | 0.379 sec/iter\n",
      "Epoch: 223 | Batch: 001 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.664000 | 0.379 sec/iter\n",
      "Epoch: 223 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 223 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.653500 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.663500 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.632500 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.631500 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.615000 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.618500 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.615500 | 0.378 sec/iter\n",
      "Epoch: 223 | Batch: 010 / 011 | Total loss: 0.894 | Reg loss: 0.021 | Tree loss: 0.894 | Accuracy: 0.552901 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 224 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 224 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 224 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 224 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.647000 | 0.379 sec/iter\n",
      "Epoch: 224 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.644500 | 0.379 sec/iter\n",
      "Epoch: 224 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.646000 | 0.378 sec/iter\n",
      "Epoch: 224 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.642500 | 0.378 sec/iter\n",
      "Epoch: 224 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.616000 | 0.378 sec/iter\n",
      "Epoch: 224 | Batch: 008 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.624000 | 0.378 sec/iter\n",
      "Epoch: 224 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.631500 | 0.378 sec/iter\n",
      "Epoch: 224 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.600683 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 225 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.618000 | 0.379 sec/iter\n",
      "Epoch: 225 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 225 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 225 | Batch: 003 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 225 | Batch: 004 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.666000 | 0.379 sec/iter\n",
      "Epoch: 225 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.635000 | 0.378 sec/iter\n",
      "Epoch: 225 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.610500 | 0.378 sec/iter\n",
      "Epoch: 225 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.636000 | 0.378 sec/iter\n",
      "Epoch: 225 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.621000 | 0.378 sec/iter\n",
      "Epoch: 225 | Batch: 009 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.614500 | 0.378 sec/iter\n",
      "Epoch: 225 | Batch: 010 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.651877 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 226 | Batch: 000 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.643000 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 001 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.628000 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.654500 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 004 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.632500 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 005 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.649500 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 226 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.627500 | 0.378 sec/iter\n",
      "Epoch: 226 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 226 | Batch: 010 / 011 | Total loss: 0.733 | Reg loss: 0.021 | Tree loss: 0.733 | Accuracy: 0.692833 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 227 | Batch: 000 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.625000 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 003 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.666000 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.643500 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.627000 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.626500 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 227 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 008 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.615500 | 0.379 sec/iter\n",
      "Epoch: 227 | Batch: 010 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.651877 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 228 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.633000 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.647500 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.641500 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.646500 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 005 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.643000 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.645000 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.613000 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.618500 | 0.379 sec/iter\n",
      "Epoch: 228 | Batch: 010 / 011 | Total loss: 0.770 | Reg loss: 0.021 | Tree loss: 0.770 | Accuracy: 0.631399 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 229 | Batch: 000 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.618500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 002 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.607000 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.630500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.646000 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 007 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 009 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.611500 | 0.379 sec/iter\n",
      "Epoch: 229 | Batch: 010 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.621160 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 230 | Batch: 000 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 230 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.603500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.647500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 003 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.670000 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.658500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.653500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.629500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.620000 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.623500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 009 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 230 | Batch: 010 / 011 | Total loss: 0.790 | Reg loss: 0.021 | Tree loss: 0.790 | Accuracy: 0.624573 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 231 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 231 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 231 | Batch: 002 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.648000 | 0.38 sec/iter\n",
      "Epoch: 231 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.657500 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.649500 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.636500 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.636500 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.611500 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 009 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.600500 | 0.379 sec/iter\n",
      "Epoch: 231 | Batch: 010 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.634812 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 232 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.617500 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 003 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.628000 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.666500 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 232 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.634500 | 0.378 sec/iter\n",
      "Epoch: 232 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.625500 | 0.378 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 232 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.628500 | 0.378 sec/iter\n",
      "Epoch: 232 | Batch: 010 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.634812 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 233 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 001 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.616000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.643000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.656500 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.638000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.643000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.627000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.633000 | 0.379 sec/iter\n",
      "Epoch: 233 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.613500 | 0.378 sec/iter\n",
      "Epoch: 233 | Batch: 010 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.638225 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 234 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.642500 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 002 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.616500 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.648000 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 004 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.637500 | 0.379 sec/iter\n",
      "Epoch: 234 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.632000 | 0.378 sec/iter\n",
      "Epoch: 234 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 234 | Batch: 010 / 011 | Total loss: 0.765 | Reg loss: 0.021 | Tree loss: 0.765 | Accuracy: 0.689420 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 235 | Batch: 000 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.607000 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.634000 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.631000 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 003 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.655500 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.652000 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.643500 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 007 / 011 | Total loss: 0.784 | Reg loss: 0.021 | Tree loss: 0.784 | Accuracy: 0.632500 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 009 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.608000 | 0.379 sec/iter\n",
      "Epoch: 235 | Batch: 010 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.552901 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 236 | Batch: 000 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.638000 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.627000 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 002 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.637500 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 003 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.659500 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.636500 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 005 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 006 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.615500 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 007 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 008 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 009 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 236 | Batch: 010 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.624573 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 237 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.621500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 001 / 011 | Total loss: 0.885 | Reg loss: 0.021 | Tree loss: 0.885 | Accuracy: 0.601500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 003 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.663500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.659000 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.637000 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 008 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.605000 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 237 | Batch: 010 / 011 | Total loss: 0.758 | Reg loss: 0.021 | Tree loss: 0.758 | Accuracy: 0.658703 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 238 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 238 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.625000 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 002 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.616500 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 006 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.635000 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.615000 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 008 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.609000 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 009 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.605500 | 0.379 sec/iter\n",
      "Epoch: 238 | Batch: 010 / 011 | Total loss: 0.773 | Reg loss: 0.021 | Tree loss: 0.773 | Accuracy: 0.668942 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 239 | Batch: 000 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 239 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 239 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 239 | Batch: 003 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 239 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.652000 | 0.378 sec/iter\n",
      "Epoch: 239 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.652500 | 0.378 sec/iter\n",
      "Epoch: 239 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 239 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.620500 | 0.378 sec/iter\n",
      "Epoch: 239 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.609000 | 0.378 sec/iter\n",
      "Epoch: 239 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.638000 | 0.378 sec/iter\n",
      "Epoch: 239 | Batch: 010 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.617747 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 240 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.626500 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 001 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.658500 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.656500 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.629500 | 0.379 sec/iter\n",
      "Epoch: 240 | Batch: 007 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.611500 | 0.378 sec/iter\n",
      "Epoch: 240 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 240 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.642000 | 0.378 sec/iter\n",
      "Epoch: 240 | Batch: 010 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.624573 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 241 | Batch: 000 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 241 | Batch: 001 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 241 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.648500 | 0.379 sec/iter\n",
      "Epoch: 241 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.654500 | 0.379 sec/iter\n",
      "Epoch: 241 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.654500 | 0.379 sec/iter\n",
      "Epoch: 241 | Batch: 005 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.634500 | 0.378 sec/iter\n",
      "Epoch: 241 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.605500 | 0.378 sec/iter\n",
      "Epoch: 241 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.603500 | 0.378 sec/iter\n",
      "Epoch: 241 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.624500 | 0.378 sec/iter\n",
      "Epoch: 241 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.623500 | 0.378 sec/iter\n",
      "Epoch: 241 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.617747 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 242 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 001 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.650000 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.641500 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.651000 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 242 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.625500 | 0.378 sec/iter\n",
      "Epoch: 242 | Batch: 009 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.626000 | 0.378 sec/iter\n",
      "Epoch: 242 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.590444 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 243 | Batch: 000 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.638000 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 001 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.624000 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.664500 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 006 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 243 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.629000 | 0.378 sec/iter\n",
      "Epoch: 243 | Batch: 010 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.641638 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 244 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.637000 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.622500 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.612000 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 009 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.658000 | 0.379 sec/iter\n",
      "Epoch: 244 | Batch: 010 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.580205 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 245 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 001 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.648500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.651500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.649500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 006 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 007 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.614000 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.633500 | 0.379 sec/iter\n",
      "Epoch: 245 | Batch: 010 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.587031 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 246 | Batch: 000 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.651500 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.619000 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.649000 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 005 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.656000 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 006 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.637500 | 0.379 sec/iter\n",
      "Epoch: 246 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.621500 | 0.378 sec/iter\n",
      "Epoch: 246 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.623000 | 0.378 sec/iter\n",
      "Epoch: 246 | Batch: 010 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.627986 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 247 | Batch: 000 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.628500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 001 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.616500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.646500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.651500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.646500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.642000 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.631500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 007 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.614000 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.639500 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 009 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.633000 | 0.378 sec/iter\n",
      "Epoch: 247 | Batch: 010 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.617747 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 248 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.638000 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 001 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.625000 | 0.378 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 248 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.621000 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.641000 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.641500 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.634000 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.615500 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.620500 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 008 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.644000 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.630500 | 0.378 sec/iter\n",
      "Epoch: 248 | Batch: 010 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.621160 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 249 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 249 | Batch: 001 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.640000 | 0.379 sec/iter\n",
      "Epoch: 249 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.631500 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 003 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.630500 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 004 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.650000 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.631000 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.642500 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.646000 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.626500 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.616000 | 0.378 sec/iter\n",
      "Epoch: 249 | Batch: 010 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.597270 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 250 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.646000 | 0.379 sec/iter\n",
      "Epoch: 250 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.636500 | 0.379 sec/iter\n",
      "Epoch: 250 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 250 | Batch: 003 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.655000 | 0.379 sec/iter\n",
      "Epoch: 250 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.632000 | 0.378 sec/iter\n",
      "Epoch: 250 | Batch: 005 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.650000 | 0.378 sec/iter\n",
      "Epoch: 250 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.641500 | 0.378 sec/iter\n",
      "Epoch: 250 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.625500 | 0.378 sec/iter\n",
      "Epoch: 250 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.630500 | 0.378 sec/iter\n",
      "Epoch: 250 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.623500 | 0.378 sec/iter\n",
      "Epoch: 250 | Batch: 010 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.593857 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 251 | Batch: 000 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.643500 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.021 | Tree loss: 0.883 | Accuracy: 0.609000 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.650500 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.655000 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.647500 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 251 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.622000 | 0.378 sec/iter\n",
      "Epoch: 251 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.623500 | 0.378 sec/iter\n",
      "Epoch: 251 | Batch: 009 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.617500 | 0.378 sec/iter\n",
      "Epoch: 251 | Batch: 010 / 011 | Total loss: 0.766 | Reg loss: 0.021 | Tree loss: 0.766 | Accuracy: 0.648464 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 252 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 001 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.649000 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.614500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 003 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.660500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.656500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.662500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 007 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.607500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 008 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.615500 | 0.379 sec/iter\n",
      "Epoch: 252 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.629500 | 0.378 sec/iter\n",
      "Epoch: 252 | Batch: 010 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.590444 | 0.378 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 253 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.623000 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.644500 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 253 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.642500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.639500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.639500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 008 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.649500 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.617000 | 0.379 sec/iter\n",
      "Epoch: 253 | Batch: 010 / 011 | Total loss: 0.759 | Reg loss: 0.021 | Tree loss: 0.759 | Accuracy: 0.658703 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 254 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 001 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.650000 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.639500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 005 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.647500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.644500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 007 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.622500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 254 | Batch: 010 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.638225 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 255 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.624000 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.622000 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.623000 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.632500 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.633000 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.639500 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.617000 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.634500 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.619500 | 0.379 sec/iter\n",
      "Epoch: 255 | Batch: 010 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.655290 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 256 | Batch: 000 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 256 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 256 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.633000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.657000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 004 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.649000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.662000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.643000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.631500 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 008 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.618000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 009 / 011 | Total loss: 0.786 | Reg loss: 0.021 | Tree loss: 0.786 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 256 | Batch: 010 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.590444 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 257 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 257 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 257 | Batch: 002 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 257 | Batch: 003 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 257 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 257 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 257 | Batch: 006 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 257 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.642500 | 0.379 sec/iter\n",
      "Epoch: 257 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.644500 | 0.379 sec/iter\n",
      "Epoch: 257 | Batch: 009 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.642000 | 0.379 sec/iter\n",
      "Epoch: 257 | Batch: 010 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.617747 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 258 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 258 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 258 | Batch: 002 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 258 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 258 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 258 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.658500 | 0.38 sec/iter\n",
      "Epoch: 258 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.628000 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 258 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.614000 | 0.379 sec/iter\n",
      "Epoch: 258 | Batch: 009 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 258 | Batch: 010 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.631399 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 259 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.610500 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 007 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 259 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.615000 | 0.379 sec/iter\n",
      "Epoch: 259 | Batch: 009 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.626000 | 0.379 sec/iter\n",
      "Epoch: 259 | Batch: 010 / 011 | Total loss: 0.765 | Reg loss: 0.021 | Tree loss: 0.765 | Accuracy: 0.668942 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 260 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.647000 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.621000 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.646500 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.655000 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.628000 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.627000 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.632500 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.628500 | 0.379 sec/iter\n",
      "Epoch: 260 | Batch: 010 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.631399 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 261 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.649500 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.637500 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 002 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.629000 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 003 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.637500 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.653000 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 006 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.646500 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.624000 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 008 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.611500 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.621000 | 0.379 sec/iter\n",
      "Epoch: 261 | Batch: 010 / 011 | Total loss: 0.775 | Reg loss: 0.021 | Tree loss: 0.775 | Accuracy: 0.614334 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 262 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.621000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.637000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 003 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.635000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.664500 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.638500 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.627000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.621500 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 262 | Batch: 010 / 011 | Total loss: 0.744 | Reg loss: 0.021 | Tree loss: 0.744 | Accuracy: 0.662116 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 263 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 263 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 263 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.632000 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 003 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.651500 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 004 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.630000 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 005 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.658500 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.622500 | 0.379 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 263 | Batch: 010 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.648464 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 264 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 264 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.021 | Tree loss: 0.883 | Accuracy: 0.605500 | 0.38 sec/iter\n",
      "Epoch: 264 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 264 | Batch: 003 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 264 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.652500 | 0.379 sec/iter\n",
      "Epoch: 264 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.645000 | 0.379 sec/iter\n",
      "Epoch: 264 | Batch: 006 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.655000 | 0.379 sec/iter\n",
      "Epoch: 264 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.634000 | 0.379 sec/iter\n",
      "Epoch: 264 | Batch: 008 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 264 | Batch: 009 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.617500 | 0.379 sec/iter\n",
      "Epoch: 264 | Batch: 010 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.614334 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 265 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 004 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 265 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.641000 | 0.379 sec/iter\n",
      "Epoch: 265 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.614000 | 0.379 sec/iter\n",
      "Epoch: 265 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 265 | Batch: 010 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.631399 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 266 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 001 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 004 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.674500 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.669500 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 266 | Batch: 009 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.606500 | 0.379 sec/iter\n",
      "Epoch: 266 | Batch: 010 / 011 | Total loss: 0.727 | Reg loss: 0.021 | Tree loss: 0.727 | Accuracy: 0.686007 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 267 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 001 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 002 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.660000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.605000 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 267 | Batch: 010 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.641638 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 268 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 002 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.664000 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 005 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 008 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.604000 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 009 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 268 | Batch: 010 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.624573 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 269 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 006 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.614000 | 0.38 sec/iter\n",
      "Epoch: 269 | Batch: 008 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.603000 | 0.379 sec/iter\n",
      "Epoch: 269 | Batch: 009 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.646500 | 0.379 sec/iter\n",
      "Epoch: 269 | Batch: 010 / 011 | Total loss: 0.767 | Reg loss: 0.021 | Tree loss: 0.767 | Accuracy: 0.672355 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 270 | Batch: 000 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.653500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.630500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 003 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.608500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 004 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.635500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.647500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 006 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.648500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 007 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.626500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.624500 | 0.379 sec/iter\n",
      "Epoch: 270 | Batch: 010 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.610922 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 271 | Batch: 000 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.659000 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.614000 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.639000 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.642500 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 004 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.645500 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.644500 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.617000 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.615500 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.610500 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.622500 | 0.379 sec/iter\n",
      "Epoch: 271 | Batch: 010 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.641638 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 272 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 272 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 272 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.608500 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.642500 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.668000 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.655000 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.640500 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 007 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.643500 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 008 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.604500 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 009 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.625000 | 0.379 sec/iter\n",
      "Epoch: 272 | Batch: 010 / 011 | Total loss: 0.897 | Reg loss: 0.021 | Tree loss: 0.897 | Accuracy: 0.583618 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 273 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 273 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 273 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 273 | Batch: 003 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 273 | Batch: 004 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.625500 | 0.379 sec/iter\n",
      "Epoch: 273 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.662000 | 0.379 sec/iter\n",
      "Epoch: 273 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.640000 | 0.379 sec/iter\n",
      "Epoch: 273 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.622500 | 0.379 sec/iter\n",
      "Epoch: 273 | Batch: 008 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.636000 | 0.379 sec/iter\n",
      "Epoch: 273 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.626500 | 0.379 sec/iter\n",
      "Epoch: 273 | Batch: 010 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.610922 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 274 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 274 | Batch: 001 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 274 | Batch: 002 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 274 | Batch: 003 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 274 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 274 | Batch: 005 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.665500 | 0.38 sec/iter\n",
      "Epoch: 274 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.646000 | 0.379 sec/iter\n",
      "Epoch: 274 | Batch: 007 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.607000 | 0.379 sec/iter\n",
      "Epoch: 274 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.623000 | 0.379 sec/iter\n",
      "Epoch: 274 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.627500 | 0.379 sec/iter\n",
      "Epoch: 274 | Batch: 010 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.617747 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 275 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 001 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 003 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.667000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.662000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 007 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.601000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.613000 | 0.38 sec/iter\n",
      "Epoch: 275 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.620500 | 0.379 sec/iter\n",
      "Epoch: 275 | Batch: 010 / 011 | Total loss: 0.787 | Reg loss: 0.021 | Tree loss: 0.787 | Accuracy: 0.624573 | 0.379 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 276 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 001 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 004 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 276 | Batch: 010 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.641638 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 277 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 001 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 002 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 004 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 005 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 277 | Batch: 010 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.593857 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 278 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 001 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 002 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.664000 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 007 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 278 | Batch: 010 / 011 | Total loss: 0.785 | Reg loss: 0.021 | Tree loss: 0.785 | Accuracy: 0.638225 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 279 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 279 | Batch: 001 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.658500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 279 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 004 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 279 | Batch: 010 / 011 | Total loss: 0.770 | Reg loss: 0.021 | Tree loss: 0.770 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 280 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 280 | Batch: 001 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 280 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 280 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 004 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 006 / 011 | Total loss: 0.782 | Reg loss: 0.021 | Tree loss: 0.782 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 280 | Batch: 010 / 011 | Total loss: 0.742 | Reg loss: 0.021 | Tree loss: 0.742 | Accuracy: 0.703072 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 281 | Batch: 000 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 281 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 281 | Batch: 002 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 281 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 281 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.666500 | 0.381 sec/iter\n",
      "Epoch: 281 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 281 | Batch: 006 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 281 | Batch: 007 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 281 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 281 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 281 | Batch: 010 / 011 | Total loss: 0.768 | Reg loss: 0.021 | Tree loss: 0.768 | Accuracy: 0.610922 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 282 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.654500 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 005 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 282 | Batch: 008 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 282 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 282 | Batch: 010 / 011 | Total loss: 0.786 | Reg loss: 0.021 | Tree loss: 0.786 | Accuracy: 0.648464 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 283 | Batch: 000 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 001 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 004 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.664000 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 005 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.656000 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 009 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 283 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 284 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 001 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 002 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.648500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 284 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 006 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 284 | Batch: 010 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 285 | Batch: 000 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 004 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.667500 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 005 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.669000 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.609000 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 285 | Batch: 010 / 011 | Total loss: 0.770 | Reg loss: 0.021 | Tree loss: 0.770 | Accuracy: 0.672355 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 286 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 001 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 006 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 008 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 286 | Batch: 010 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.641638 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 287 | Batch: 000 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 287 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 287 | Batch: 002 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 287 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 006 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.614000 | 0.38 sec/iter\n",
      "Epoch: 287 | Batch: 010 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 288 | Batch: 000 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 288 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 288 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 288 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.670500 | 0.381 sec/iter\n",
      "Epoch: 288 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 288 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 288 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 288 | Batch: 007 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 288 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 288 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 288 | Batch: 010 / 011 | Total loss: 0.761 | Reg loss: 0.021 | Tree loss: 0.761 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 289 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 289 | Batch: 001 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 289 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 289 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 289 | Batch: 004 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 289 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 289 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.645500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 289 | Batch: 007 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 289 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 289 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 289 | Batch: 010 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.641638 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 290 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 001 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 004 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 005 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 006 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 290 | Batch: 009 / 011 | Total loss: 0.780 | Reg loss: 0.021 | Tree loss: 0.780 | Accuracy: 0.661500 | 0.38 sec/iter\n",
      "Epoch: 290 | Batch: 010 / 011 | Total loss: 0.780 | Reg loss: 0.021 | Tree loss: 0.780 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 291 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 002 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 009 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 291 | Batch: 010 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 292 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 292 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 292 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 292 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 292 | Batch: 004 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 292 | Batch: 005 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 292 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 292 | Batch: 007 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 292 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.604000 | 0.38 sec/iter\n",
      "Epoch: 292 | Batch: 009 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 292 | Batch: 010 / 011 | Total loss: 0.767 | Reg loss: 0.021 | Tree loss: 0.767 | Accuracy: 0.648464 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 293 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 003 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 005 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.673000 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 293 | Batch: 010 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 294 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.612000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 294 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 294 | Batch: 010 / 011 | Total loss: 0.776 | Reg loss: 0.021 | Tree loss: 0.776 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 295 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 002 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.608500 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 006 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.658000 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 007 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 009 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 295 | Batch: 010 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 296 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 296 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.675500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.648000 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.610500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.607000 | 0.38 sec/iter\n",
      "Epoch: 296 | Batch: 010 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 297 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 297 | Batch: 001 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 297 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 297 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 297 | Batch: 004 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 297 | Batch: 005 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 297 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 297 | Batch: 007 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 297 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 297 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 297 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 298 | Batch: 000 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 004 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 006 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 298 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 298 | Batch: 008 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 298 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 298 | Batch: 010 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.621160 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 299 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.654500 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.652500 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 006 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 299 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 299 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 299 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 299 | Batch: 010 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.587031 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 300 | Batch: 000 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 001 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 003 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 004 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 005 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.663000 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.599500 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 007 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 008 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 009 / 011 | Total loss: 0.774 | Reg loss: 0.021 | Tree loss: 0.774 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 300 | Batch: 010 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.593857 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 301 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 001 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 003 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.652500 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 004 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 005 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.659000 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 301 | Batch: 010 / 011 | Total loss: 0.783 | Reg loss: 0.021 | Tree loss: 0.783 | Accuracy: 0.614334 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 302 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.666000 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 009 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 302 | Batch: 010 / 011 | Total loss: 0.894 | Reg loss: 0.021 | Tree loss: 0.894 | Accuracy: 0.621160 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 303 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 001 / 011 | Total loss: 0.882 | Reg loss: 0.021 | Tree loss: 0.882 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 003 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.662000 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.669500 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 006 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 303 | Batch: 010 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.631399 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 304 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.635000 | 0.382 sec/iter\n",
      "Epoch: 304 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 002 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.610000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 004 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 008 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 304 | Batch: 010 / 011 | Total loss: 0.767 | Reg loss: 0.021 | Tree loss: 0.767 | Accuracy: 0.668942 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 305 | Batch: 000 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.638000 | 0.382 sec/iter\n",
      "Epoch: 305 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.620000 | 0.382 sec/iter\n",
      "Epoch: 305 | Batch: 002 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.630000 | 0.382 sec/iter\n",
      "Epoch: 305 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 004 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 005 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 006 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 305 | Batch: 010 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 306 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.609500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 001 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 008 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 306 | Batch: 010 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 307 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 001 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.602000 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 307 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 308 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 003 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.670500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 004 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.609500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 008 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.598500 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 009 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.598000 | 0.381 sec/iter\n",
      "Epoch: 308 | Batch: 010 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.634812 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 309 | Batch: 000 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 004 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 007 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 309 | Batch: 010 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.590444 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 310 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.611000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 008 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.609000 | 0.381 sec/iter\n",
      "Epoch: 310 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 311 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.654000 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 005 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 311 | Batch: 010 / 011 | Total loss: 0.779 | Reg loss: 0.021 | Tree loss: 0.779 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 312 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.634000 | 0.382 sec/iter\n",
      "Epoch: 312 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 006 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 008 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 009 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.606500 | 0.381 sec/iter\n",
      "Epoch: 312 | Batch: 010 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.604096 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 313 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.634000 | 0.382 sec/iter\n",
      "Epoch: 313 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.634000 | 0.382 sec/iter\n",
      "Epoch: 313 | Batch: 002 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.625500 | 0.382 sec/iter\n",
      "Epoch: 313 | Batch: 003 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.666500 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 005 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.670000 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.611000 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 313 | Batch: 010 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.600683 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 314 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.634000 | 0.382 sec/iter\n",
      "Epoch: 314 | Batch: 001 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.648500 | 0.382 sec/iter\n",
      "Epoch: 314 | Batch: 002 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.625500 | 0.382 sec/iter\n",
      "Epoch: 314 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.631000 | 0.382 sec/iter\n",
      "Epoch: 314 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.647500 | 0.382 sec/iter\n",
      "Epoch: 314 | Batch: 005 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.665500 | 0.382 sec/iter\n",
      "Epoch: 314 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.654500 | 0.381 sec/iter\n",
      "Epoch: 314 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 314 | Batch: 008 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 314 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 314 | Batch: 010 / 011 | Total loss: 0.778 | Reg loss: 0.021 | Tree loss: 0.778 | Accuracy: 0.634812 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 315 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.649000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 315 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 007 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.598000 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 315 | Batch: 010 / 011 | Total loss: 0.790 | Reg loss: 0.021 | Tree loss: 0.790 | Accuracy: 0.655290 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 316 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.654000 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 316 | Batch: 007 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 316 | Batch: 008 / 011 | Total loss: 0.785 | Reg loss: 0.021 | Tree loss: 0.785 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 316 | Batch: 009 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 316 | Batch: 010 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 317 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 001 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 008 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.610000 | 0.381 sec/iter\n",
      "Epoch: 317 | Batch: 010 / 011 | Total loss: 0.737 | Reg loss: 0.021 | Tree loss: 0.737 | Accuracy: 0.675768 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 318 | Batch: 000 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.658000 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 005 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 009 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 318 | Batch: 010 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 319 | Batch: 000 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 004 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 005 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.665000 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 009 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.609000 | 0.381 sec/iter\n",
      "Epoch: 319 | Batch: 010 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.597270 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 320 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 001 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.614500 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.666000 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.663000 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.625500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 008 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 320 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.634812 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 321 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 002 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 005 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 009 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 321 | Batch: 010 / 011 | Total loss: 0.744 | Reg loss: 0.021 | Tree loss: 0.744 | Accuracy: 0.668942 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 322 | Batch: 000 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 005 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.669500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 006 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 322 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.624573 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 323 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.647500 | 0.382 sec/iter\n",
      "Epoch: 323 | Batch: 001 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.636000 | 0.382 sec/iter\n",
      "Epoch: 323 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 004 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 006 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 008 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 323 | Batch: 010 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 324 | Batch: 000 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.621000 | 0.382 sec/iter\n",
      "Epoch: 324 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.617500 | 0.382 sec/iter\n",
      "Epoch: 324 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.623500 | 0.382 sec/iter\n",
      "Epoch: 324 | Batch: 003 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.614000 | 0.382 sec/iter\n",
      "Epoch: 324 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 324 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 324 | Batch: 006 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 324 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 324 | Batch: 008 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 324 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 324 | Batch: 010 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 325 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 001 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 002 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 004 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.669500 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.627000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 325 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 325 | Batch: 010 / 011 | Total loss: 0.917 | Reg loss: 0.021 | Tree loss: 0.917 | Accuracy: 0.580205 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 326 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 001 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 003 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 008 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 009 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.613500 | 0.381 sec/iter\n",
      "Epoch: 326 | Batch: 010 / 011 | Total loss: 0.703 | Reg loss: 0.021 | Tree loss: 0.703 | Accuracy: 0.672355 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 327 | Batch: 000 / 011 | Total loss: 0.887 | Reg loss: 0.021 | Tree loss: 0.887 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 002 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 004 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 008 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 327 | Batch: 010 / 011 | Total loss: 0.755 | Reg loss: 0.021 | Tree loss: 0.755 | Accuracy: 0.696246 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 328 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.659000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 005 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 007 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 328 | Batch: 010 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.641638 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 329 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 003 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 004 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.656500 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 005 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 006 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 329 | Batch: 010 / 011 | Total loss: 0.762 | Reg loss: 0.021 | Tree loss: 0.762 | Accuracy: 0.672355 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 330 | Batch: 000 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 001 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 003 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.669000 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 330 | Batch: 010 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.607509 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 331 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.626500 | 0.382 sec/iter\n",
      "Epoch: 331 | Batch: 001 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 003 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.662500 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 007 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 331 | Batch: 010 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.590444 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 332 | Batch: 000 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.635000 | 0.382 sec/iter\n",
      "Epoch: 332 | Batch: 001 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.653000 | 0.382 sec/iter\n",
      "Epoch: 332 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 005 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 006 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 007 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 332 | Batch: 010 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 333 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.638500 | 0.382 sec/iter\n",
      "Epoch: 333 | Batch: 001 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.626000 | 0.382 sec/iter\n",
      "Epoch: 333 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.615500 | 0.382 sec/iter\n",
      "Epoch: 333 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.647500 | 0.382 sec/iter\n",
      "Epoch: 333 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.656000 | 0.381 sec/iter\n",
      "Epoch: 333 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 333 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 333 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 333 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.606500 | 0.381 sec/iter\n",
      "Epoch: 333 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 333 | Batch: 010 / 011 | Total loss: 0.746 | Reg loss: 0.021 | Tree loss: 0.746 | Accuracy: 0.658703 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 334 | Batch: 000 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 001 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.653500 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 005 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.654000 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 006 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 007 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 008 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 009 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.607500 | 0.381 sec/iter\n",
      "Epoch: 334 | Batch: 010 / 011 | Total loss: 0.762 | Reg loss: 0.021 | Tree loss: 0.762 | Accuracy: 0.634812 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 335 | Batch: 000 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.653000 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 005 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.660000 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 335 | Batch: 010 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.590444 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 336 | Batch: 000 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 006 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 009 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 336 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.590444 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 337 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 003 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.652500 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 004 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.652500 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 006 / 011 | Total loss: 0.782 | Reg loss: 0.021 | Tree loss: 0.782 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 007 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 009 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.600000 | 0.381 sec/iter\n",
      "Epoch: 337 | Batch: 010 / 011 | Total loss: 0.740 | Reg loss: 0.021 | Tree loss: 0.740 | Accuracy: 0.651877 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 338 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 001 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.653500 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.605500 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 009 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.609000 | 0.381 sec/iter\n",
      "Epoch: 338 | Batch: 010 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.634812 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 339 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 005 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 339 | Batch: 010 / 011 | Total loss: 0.778 | Reg loss: 0.021 | Tree loss: 0.778 | Accuracy: 0.638225 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 340 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 340 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.657500 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 006 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 009 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 340 | Batch: 010 / 011 | Total loss: 0.778 | Reg loss: 0.021 | Tree loss: 0.778 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 341 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 341 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.640500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 341 | Batch: 002 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 341 | Batch: 003 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.658000 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 341 | Batch: 010 / 011 | Total loss: 0.770 | Reg loss: 0.021 | Tree loss: 0.770 | Accuracy: 0.668942 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 342 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 342 | Batch: 001 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 342 | Batch: 002 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 342 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 342 | Batch: 004 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 342 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 342 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 342 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 342 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 342 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 342 | Batch: 010 / 011 | Total loss: 0.765 | Reg loss: 0.021 | Tree loss: 0.765 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 343 | Batch: 000 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.614500 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 002 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 003 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.672000 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 006 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.667000 | 0.381 sec/iter\n",
      "Epoch: 343 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 343 | Batch: 008 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 343 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 343 | Batch: 010 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 344 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 001 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 004 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 344 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 344 | Batch: 010 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 345 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 004 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.683500 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.653000 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 009 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.607000 | 0.381 sec/iter\n",
      "Epoch: 345 | Batch: 010 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.590444 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 346 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 001 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.640000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 346 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.665000 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 008 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 009 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 346 | Batch: 010 / 011 | Total loss: 0.784 | Reg loss: 0.021 | Tree loss: 0.784 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 347 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 002 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 003 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.660000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 005 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 006 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 009 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 347 | Batch: 010 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 348 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 003 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.676500 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 348 | Batch: 010 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 349 | Batch: 000 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 003 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 004 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 008 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 349 | Batch: 010 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 350 | Batch: 000 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 001 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 004 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 007 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 350 | Batch: 010 / 011 | Total loss: 0.751 | Reg loss: 0.021 | Tree loss: 0.751 | Accuracy: 0.679181 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 351 | Batch: 000 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.665000 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 005 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.654500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 351 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 009 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 351 | Batch: 010 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 352 | Batch: 000 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 001 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.608500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 007 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.607500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 008 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.608500 | 0.381 sec/iter\n",
      "Epoch: 352 | Batch: 010 / 011 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 353 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 004 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.659000 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.659500 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 006 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 009 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 353 | Batch: 010 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 354 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 003 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 004 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 005 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 008 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 009 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 354 | Batch: 010 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 355 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 001 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 003 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 004 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 007 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 009 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 355 | Batch: 010 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 356 | Batch: 000 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 004 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.663500 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 005 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 006 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.630000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 356 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 009 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 356 | Batch: 010 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.604096 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 357 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 009 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 357 | Batch: 010 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.634812 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 358 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 358 | Batch: 010 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 359 | Batch: 000 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.642500 | 0.382 sec/iter\n",
      "Epoch: 359 | Batch: 001 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.622500 | 0.382 sec/iter\n",
      "Epoch: 359 | Batch: 002 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 004 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 005 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.667000 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 007 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.598500 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.609000 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 009 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 359 | Batch: 010 / 011 | Total loss: 0.761 | Reg loss: 0.021 | Tree loss: 0.761 | Accuracy: 0.658703 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 360 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 001 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 002 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 008 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 360 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 361 | Batch: 000 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 003 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 005 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 006 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 007 / 011 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 361 | Batch: 010 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.597270 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 362 | Batch: 000 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 002 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 003 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.659000 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 006 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 009 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.609500 | 0.381 sec/iter\n",
      "Epoch: 362 | Batch: 010 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.624573 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 363 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 363 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.614500 | 0.381 sec/iter\n",
      "Epoch: 363 | Batch: 002 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 363 | Batch: 003 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 363 | Batch: 004 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 363 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 363 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 363 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 363 | Batch: 008 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.601500 | 0.38 sec/iter\n",
      "Epoch: 363 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 363 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 364 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 002 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 006 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 007 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 009 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 364 | Batch: 010 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 365 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 002 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.660000 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 004 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 008 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.610500 | 0.38 sec/iter\n",
      "Epoch: 365 | Batch: 010 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 366 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 001 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 003 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.661500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 005 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 006 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.610000 | 0.38 sec/iter\n",
      "Epoch: 366 | Batch: 010 / 011 | Total loss: 0.768 | Reg loss: 0.021 | Tree loss: 0.768 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 367 | Batch: 000 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.664500 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 005 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 007 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.611000 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 367 | Batch: 010 / 011 | Total loss: 0.761 | Reg loss: 0.021 | Tree loss: 0.761 | Accuracy: 0.665529 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 368 | Batch: 000 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 368 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 368 | Batch: 002 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.657500 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 006 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 007 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 368 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.590444 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 369 | Batch: 000 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 369 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 369 | Batch: 002 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 369 | Batch: 003 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 369 | Batch: 004 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 369 | Batch: 005 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 369 | Batch: 006 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 369 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 369 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 369 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 369 | Batch: 010 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.607509 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 370 | Batch: 000 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 370 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 370 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 370 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 370 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 370 | Batch: 005 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 370 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 370 | Batch: 007 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 370 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 370 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.602500 | 0.38 sec/iter\n",
      "Epoch: 370 | Batch: 010 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.593857 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 371 | Batch: 000 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 001 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 002 / 011 | Total loss: 0.881 | Reg loss: 0.021 | Tree loss: 0.881 | Accuracy: 0.620000 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 003 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 006 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 007 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 371 | Batch: 009 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.605500 | 0.38 sec/iter\n",
      "Epoch: 371 | Batch: 010 / 011 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.655290 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 372 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 001 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.613500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 372 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.665500 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 006 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 007 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 009 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.610000 | 0.381 sec/iter\n",
      "Epoch: 372 | Batch: 010 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.638225 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 373 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 003 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 006 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 008 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 373 | Batch: 010 / 011 | Total loss: 0.778 | Reg loss: 0.021 | Tree loss: 0.778 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 374 | Batch: 000 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 001 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 003 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 006 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 007 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.607500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 008 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 009 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 374 | Batch: 010 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.624573 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 375 | Batch: 000 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.654000 | 0.381 sec/iter\n",
      "Epoch: 375 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 375 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 375 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 375 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 375 | Batch: 005 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 375 | Batch: 006 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 375 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 375 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 375 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 375 | Batch: 010 / 011 | Total loss: 0.784 | Reg loss: 0.021 | Tree loss: 0.784 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 376 | Batch: 000 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 376 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 376 | Batch: 002 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 376 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 376 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.667000 | 0.381 sec/iter\n",
      "Epoch: 376 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 376 | Batch: 006 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.659000 | 0.38 sec/iter\n",
      "Epoch: 376 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 376 | Batch: 008 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 376 | Batch: 009 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 376 | Batch: 010 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 377 | Batch: 000 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 377 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 377 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 377 | Batch: 003 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.671500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 377 | Batch: 004 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 377 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 377 | Batch: 006 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.608000 | 0.38 sec/iter\n",
      "Epoch: 377 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 377 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 377 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 377 | Batch: 010 / 011 | Total loss: 0.771 | Reg loss: 0.021 | Tree loss: 0.771 | Accuracy: 0.648464 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 378 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 001 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 004 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.664000 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 005 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 378 | Batch: 007 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 378 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 378 | Batch: 009 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 378 | Batch: 010 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 379 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 001 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 003 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.659000 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 006 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 379 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 379 | Batch: 009 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 379 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 380 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.654000 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 005 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 007 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 380 | Batch: 010 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 381 | Batch: 000 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 004 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 005 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 007 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 381 | Batch: 010 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 382 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 003 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.646000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 382 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.607000 | 0.381 sec/iter\n",
      "Epoch: 382 | Batch: 010 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.645051 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 383 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 001 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 002 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 003 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.659000 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 383 | Batch: 010 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.641638 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 384 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 002 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.663000 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 005 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 384 | Batch: 007 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 384 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 384 | Batch: 009 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 384 | Batch: 010 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 385 | Batch: 000 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 003 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 004 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 385 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 385 | Batch: 010 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 386 | Batch: 000 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 386 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 386 | Batch: 002 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 386 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 386 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 386 | Batch: 005 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 386 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 386 | Batch: 007 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 386 | Batch: 008 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 386 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.611500 | 0.38 sec/iter\n",
      "Epoch: 386 | Batch: 010 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.607509 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 387 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 001 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 002 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.613500 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 003 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.656000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 005 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 007 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.642000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 387 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 387 | Batch: 010 / 011 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 388 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 002 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 006 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 388 | Batch: 010 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 389 | Batch: 000 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.605500 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 009 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 389 | Batch: 010 / 011 | Total loss: 0.761 | Reg loss: 0.021 | Tree loss: 0.761 | Accuracy: 0.709898 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 390 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 001 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.673500 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 006 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 007 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 008 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.613000 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 390 | Batch: 010 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.583618 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 391 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 001 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 004 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.654500 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 007 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 391 | Batch: 010 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 392 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 002 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.657500 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.646500 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 392 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.626500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 392 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 393 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.613000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 003 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.665000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 004 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 007 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.613500 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 393 | Batch: 010 / 011 | Total loss: 0.768 | Reg loss: 0.021 | Tree loss: 0.768 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 394 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 394 | Batch: 001 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 394 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 003 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.664500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.646500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 005 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 394 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.621160 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 395 | Batch: 000 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 395 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 395 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 395 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 395 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.654500 | 0.381 sec/iter\n",
      "Epoch: 395 | Batch: 005 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 395 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 395 | Batch: 007 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 395 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 395 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 395 | Batch: 010 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.607509 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 396 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 002 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 003 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.610500 | 0.381 sec/iter\n",
      "Epoch: 396 | Batch: 008 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 396 | Batch: 009 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 396 | Batch: 010 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 397 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 005 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 397 | Batch: 010 / 011 | Total loss: 0.780 | Reg loss: 0.021 | Tree loss: 0.780 | Accuracy: 0.593857 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 398 | Batch: 000 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 002 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 005 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 007 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 008 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 009 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 398 | Batch: 010 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 399 | Batch: 000 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 003 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 005 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 007 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.610500 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 008 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 009 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 399 | Batch: 010 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 400 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 001 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 003 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.665500 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 008 / 011 | Total loss: 0.790 | Reg loss: 0.021 | Tree loss: 0.790 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 400 | Batch: 010 / 011 | Total loss: 0.786 | Reg loss: 0.021 | Tree loss: 0.786 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 401 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 001 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 003 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 006 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 007 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.613500 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 401 | Batch: 010 / 011 | Total loss: 0.777 | Reg loss: 0.021 | Tree loss: 0.777 | Accuracy: 0.624573 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 402 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.602500 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 002 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 003 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 005 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.668500 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 007 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 402 | Batch: 010 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.597270 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 403 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.623000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 403 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 008 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 009 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 403 | Batch: 010 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 404 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.647000 | 0.382 sec/iter\n",
      "Epoch: 404 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.640500 | 0.382 sec/iter\n",
      "Epoch: 404 | Batch: 002 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 004 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.658000 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.663000 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 007 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.608500 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 008 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 404 | Batch: 010 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.597270 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 405 | Batch: 000 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 003 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 008 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.610000 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 405 | Batch: 010 / 011 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.655290 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 406 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.650000 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 007 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 406 | Batch: 010 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.590444 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 407 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 001 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 005 / 011 | Total loss: 0.774 | Reg loss: 0.021 | Tree loss: 0.774 | Accuracy: 0.672500 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 006 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 008 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 009 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.601500 | 0.381 sec/iter\n",
      "Epoch: 407 | Batch: 010 / 011 | Total loss: 0.785 | Reg loss: 0.021 | Tree loss: 0.785 | Accuracy: 0.645051 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 408 | Batch: 000 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 003 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.633000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 408 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.655500 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.658000 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 006 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.615500 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 008 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 009 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 408 | Batch: 010 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.645051 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 409 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 001 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 002 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 004 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 008 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.605500 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 409 | Batch: 010 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 410 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 001 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 002 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 005 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 410 | Batch: 010 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 411 | Batch: 000 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 411 | Batch: 001 / 011 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.609500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 004 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 006 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.659000 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 008 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.648000 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 009 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 411 | Batch: 010 / 011 | Total loss: 0.743 | Reg loss: 0.021 | Tree loss: 0.743 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 412 | Batch: 000 / 011 | Total loss: 0.873 | Reg loss: 0.021 | Tree loss: 0.873 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 412 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 412 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 412 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 008 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 412 | Batch: 010 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 413 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 413 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 413 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 413 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 413 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 413 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.655500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 413 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 413 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 413 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 413 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 413 | Batch: 010 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.590444 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 414 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 004 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 005 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.653000 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 414 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 414 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.611000 | 0.38 sec/iter\n",
      "Epoch: 414 | Batch: 010 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.600683 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 415 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 001 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 003 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 006 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 415 | Batch: 009 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 415 | Batch: 010 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 416 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.637000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.634000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 004 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 005 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 006 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 009 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 416 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.627986 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 417 | Batch: 000 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 002 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 003 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.659500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 004 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 005 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 009 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 417 | Batch: 010 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.651877 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 418 | Batch: 000 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 004 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.653000 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 006 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 007 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.628500 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 418 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 009 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 418 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.597270 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 419 | Batch: 000 / 011 | Total loss: 0.876 | Reg loss: 0.021 | Tree loss: 0.876 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 001 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 002 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 003 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.651000 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 004 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.656500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.654000 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 006 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.617500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 008 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.598500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 009 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 419 | Batch: 010 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 420 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.605000 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 001 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.655000 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 005 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 006 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.618000 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 009 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.613500 | 0.381 sec/iter\n",
      "Epoch: 420 | Batch: 010 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.641638 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 421 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 001 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 003 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 004 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 005 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 007 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 421 | Batch: 010 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.617747 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 422 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 001 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 005 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.652500 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 006 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 007 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 009 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 422 | Batch: 010 / 011 | Total loss: 0.751 | Reg loss: 0.021 | Tree loss: 0.751 | Accuracy: 0.692833 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 423 | Batch: 000 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.645000 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 002 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 003 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 005 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 006 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 008 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 009 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.614000 | 0.381 sec/iter\n",
      "Epoch: 423 | Batch: 010 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.597270 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 424 | Batch: 000 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 001 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 002 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.616500 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 005 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 006 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 008 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.611000 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 009 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 424 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.655290 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 425 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 002 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 003 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.653500 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 007 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 425 | Batch: 010 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.607509 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 426 | Batch: 000 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 003 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 008 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 009 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 426 | Batch: 010 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 427 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 003 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.648000 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 006 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.623000 | 0.381 sec/iter\n",
      "Epoch: 427 | Batch: 010 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.597270 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 428 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 004 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 006 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.619000 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 428 | Batch: 010 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.621160 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 429 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 002 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 003 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.656000 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.653500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 006 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 008 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 009 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 429 | Batch: 010 / 011 | Total loss: 0.751 | Reg loss: 0.021 | Tree loss: 0.751 | Accuracy: 0.658703 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 430 | Batch: 000 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.622500 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 005 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 009 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 430 | Batch: 010 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.610922 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 431 | Batch: 000 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 001 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 002 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 003 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.661000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 005 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 007 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 008 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 009 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 431 | Batch: 010 / 011 | Total loss: 0.771 | Reg loss: 0.021 | Tree loss: 0.771 | Accuracy: 0.641638 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 432 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 001 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 002 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 006 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 007 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 008 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 009 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 432 | Batch: 010 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.668942 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 433 | Batch: 000 / 011 | Total loss: 0.891 | Reg loss: 0.021 | Tree loss: 0.891 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 001 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 003 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 005 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 007 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 008 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 009 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 433 | Batch: 010 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.624573 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 434 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 434 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.610000 | 0.381 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 434 | Batch: 002 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 434 | Batch: 003 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 434 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.660000 | 0.381 sec/iter\n",
      "Epoch: 434 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.665500 | 0.38 sec/iter\n",
      "Epoch: 434 | Batch: 006 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 434 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 434 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 434 | Batch: 009 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 434 | Batch: 010 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.593857 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 435 | Batch: 000 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 004 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.655500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.606500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.610500 | 0.38 sec/iter\n",
      "Epoch: 435 | Batch: 010 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.655290 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 436 | Batch: 000 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 001 / 011 | Total loss: 0.880 | Reg loss: 0.021 | Tree loss: 0.880 | Accuracy: 0.611000 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 003 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.664500 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 436 | Batch: 010 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.668942 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 437 | Batch: 000 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.613000 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.646500 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 004 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.613000 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 005 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 007 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.614000 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 009 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 437 | Batch: 010 / 011 | Total loss: 0.787 | Reg loss: 0.021 | Tree loss: 0.787 | Accuracy: 0.682594 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 438 | Batch: 000 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 001 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 002 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.652000 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 006 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 008 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 009 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.600500 | 0.38 sec/iter\n",
      "Epoch: 438 | Batch: 010 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.621160 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 439 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 439 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 439 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.666500 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 004 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.653500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 439 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 006 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 007 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 009 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 439 | Batch: 010 / 011 | Total loss: 0.771 | Reg loss: 0.021 | Tree loss: 0.771 | Accuracy: 0.672355 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 440 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 440 | Batch: 001 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 440 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 440 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 440 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 440 | Batch: 005 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 440 | Batch: 006 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.600000 | 0.38 sec/iter\n",
      "Epoch: 440 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 440 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 440 | Batch: 009 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 440 | Batch: 010 / 011 | Total loss: 0.747 | Reg loss: 0.021 | Tree loss: 0.747 | Accuracy: 0.655290 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 441 | Batch: 000 / 011 | Total loss: 0.863 | Reg loss: 0.021 | Tree loss: 0.863 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 441 | Batch: 001 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.660500 | 0.381 sec/iter\n",
      "Epoch: 441 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 441 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 441 | Batch: 004 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 441 | Batch: 005 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.658500 | 0.381 sec/iter\n",
      "Epoch: 441 | Batch: 006 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 441 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 441 | Batch: 008 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.607500 | 0.38 sec/iter\n",
      "Epoch: 441 | Batch: 009 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.604000 | 0.38 sec/iter\n",
      "Epoch: 441 | Batch: 010 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.600683 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 442 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.613000 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 002 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 005 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.643000 | 0.381 sec/iter\n",
      "Epoch: 442 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 442 | Batch: 009 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 442 | Batch: 010 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 443 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.636000 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 001 / 011 | Total loss: 0.884 | Reg loss: 0.021 | Tree loss: 0.884 | Accuracy: 0.610500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 003 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.646000 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 007 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 009 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 443 | Batch: 010 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 444 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 001 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.662500 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 006 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.637000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 444 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 008 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 009 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 444 | Batch: 010 / 011 | Total loss: 0.772 | Reg loss: 0.021 | Tree loss: 0.772 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 445 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 445 | Batch: 001 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.630000 | 0.381 sec/iter\n",
      "Epoch: 445 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.654500 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 006 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 007 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 445 | Batch: 010 / 011 | Total loss: 0.791 | Reg loss: 0.021 | Tree loss: 0.791 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 446 | Batch: 000 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.613500 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 002 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.654000 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 003 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.646500 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.654500 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 007 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.605500 | 0.38 sec/iter\n",
      "Epoch: 446 | Batch: 010 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 447 | Batch: 000 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 447 | Batch: 001 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.617000 | 0.381 sec/iter\n",
      "Epoch: 447 | Batch: 002 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.667500 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 003 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.659000 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 447 | Batch: 010 / 011 | Total loss: 0.728 | Reg loss: 0.021 | Tree loss: 0.728 | Accuracy: 0.665529 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 448 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 448 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 448 | Batch: 002 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.612500 | 0.381 sec/iter\n",
      "Epoch: 448 | Batch: 003 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.649500 | 0.381 sec/iter\n",
      "Epoch: 448 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 448 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 448 | Batch: 006 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 448 | Batch: 007 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 448 | Batch: 008 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 448 | Batch: 009 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 448 | Batch: 010 / 011 | Total loss: 0.783 | Reg loss: 0.021 | Tree loss: 0.783 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 449 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.631500 | 0.381 sec/iter\n",
      "Epoch: 449 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 449 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 449 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 449 | Batch: 004 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.663000 | 0.381 sec/iter\n",
      "Epoch: 449 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 449 | Batch: 006 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.662500 | 0.38 sec/iter\n",
      "Epoch: 449 | Batch: 007 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 449 | Batch: 008 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.613500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 449 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 449 | Batch: 010 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 450 | Batch: 000 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 001 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 002 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.647500 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 003 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 005 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 006 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.604500 | 0.381 sec/iter\n",
      "Epoch: 450 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 450 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 450 | Batch: 010 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.624573 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 451 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.635500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 001 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.650500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.632500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.637500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.630500 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 009 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.615000 | 0.381 sec/iter\n",
      "Epoch: 451 | Batch: 010 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 452 | Batch: 000 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.616000 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 002 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.662500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 006 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 007 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 452 | Batch: 010 / 011 | Total loss: 0.752 | Reg loss: 0.021 | Tree loss: 0.752 | Accuracy: 0.648464 | 0.381 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 453 | Batch: 000 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.625000 | 0.381 sec/iter\n",
      "Epoch: 453 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 003 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 006 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 008 / 011 | Total loss: 0.787 | Reg loss: 0.021 | Tree loss: 0.787 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 009 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 453 | Batch: 010 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 454 | Batch: 000 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.656000 | 0.381 sec/iter\n",
      "Epoch: 454 | Batch: 001 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 454 | Batch: 002 / 011 | Total loss: 0.858 | Reg loss: 0.021 | Tree loss: 0.858 | Accuracy: 0.621000 | 0.381 sec/iter\n",
      "Epoch: 454 | Batch: 003 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.671500 | 0.381 sec/iter\n",
      "Epoch: 454 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.663500 | 0.38 sec/iter\n",
      "Epoch: 454 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 454 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 454 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 454 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 454 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 454 | Batch: 010 / 011 | Total loss: 0.892 | Reg loss: 0.021 | Tree loss: 0.892 | Accuracy: 0.593857 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 455 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 455 | Batch: 001 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.649000 | 0.381 sec/iter\n",
      "Epoch: 455 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 003 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 004 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 006 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 008 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 009 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.620000 | 0.38 sec/iter\n",
      "Epoch: 455 | Batch: 010 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 456 | Batch: 000 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.636500 | 0.381 sec/iter\n",
      "Epoch: 456 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.633000 | 0.381 sec/iter\n",
      "Epoch: 456 | Batch: 002 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 456 | Batch: 003 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 456 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.658000 | 0.38 sec/iter\n",
      "Epoch: 456 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 456 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 456 | Batch: 007 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 456 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 456 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 456 | Batch: 010 / 011 | Total loss: 0.743 | Reg loss: 0.021 | Tree loss: 0.743 | Accuracy: 0.665529 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 457 | Batch: 000 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.620500 | 0.381 sec/iter\n",
      "Epoch: 457 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 457 | Batch: 002 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.640500 | 0.381 sec/iter\n",
      "Epoch: 457 | Batch: 003 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.626500 | 0.381 sec/iter\n",
      "Epoch: 457 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 457 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.667500 | 0.381 sec/iter\n",
      "Epoch: 457 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 457 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 457 | Batch: 008 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 457 | Batch: 009 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 457 | Batch: 010 / 011 | Total loss: 0.724 | Reg loss: 0.021 | Tree loss: 0.724 | Accuracy: 0.675768 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 458 | Batch: 000 / 011 | Total loss: 0.871 | Reg loss: 0.021 | Tree loss: 0.871 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 001 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 002 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 003 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 005 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 007 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 008 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 458 | Batch: 010 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.621160 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 459 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 001 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 002 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 003 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 005 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 006 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 007 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.611500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 459 | Batch: 010 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 460 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 001 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.606000 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 002 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 004 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 005 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 006 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.607000 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 009 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.641500 | 0.38 sec/iter\n",
      "Epoch: 460 | Batch: 010 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 461 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 001 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 002 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 003 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 004 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 006 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 007 / 011 | Total loss: 0.786 | Reg loss: 0.021 | Tree loss: 0.786 | Accuracy: 0.651500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 008 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 461 | Batch: 010 / 011 | Total loss: 0.883 | Reg loss: 0.021 | Tree loss: 0.883 | Accuracy: 0.593857 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 462 | Batch: 000 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 001 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.661000 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 002 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 003 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 004 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.654500 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 005 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.651000 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 006 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.606500 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 007 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 009 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.604000 | 0.38 sec/iter\n",
      "Epoch: 462 | Batch: 010 / 011 | Total loss: 0.754 | Reg loss: 0.021 | Tree loss: 0.754 | Accuracy: 0.662116 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 463 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.659500 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 006 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 007 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 463 | Batch: 010 / 011 | Total loss: 0.783 | Reg loss: 0.021 | Tree loss: 0.783 | Accuracy: 0.672355 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 464 | Batch: 000 / 011 | Total loss: 0.849 | Reg loss: 0.021 | Tree loss: 0.849 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 001 / 011 | Total loss: 0.883 | Reg loss: 0.021 | Tree loss: 0.883 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 002 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 003 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.649500 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 005 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.610000 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 007 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 009 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 464 | Batch: 010 / 011 | Total loss: 0.768 | Reg loss: 0.021 | Tree loss: 0.768 | Accuracy: 0.641638 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 465 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.638500 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 001 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.612000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 465 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 004 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.673500 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.629500 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 007 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 008 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 465 | Batch: 010 / 011 | Total loss: 0.740 | Reg loss: 0.021 | Tree loss: 0.740 | Accuracy: 0.689420 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 466 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 466 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.628000 | 0.381 sec/iter\n",
      "Epoch: 466 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 003 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.665000 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 005 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 006 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.614000 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 007 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.610000 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 009 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 466 | Batch: 010 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.614334 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 467 | Batch: 000 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.618500 | 0.381 sec/iter\n",
      "Epoch: 467 | Batch: 001 / 011 | Total loss: 0.864 | Reg loss: 0.021 | Tree loss: 0.864 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 467 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.629000 | 0.381 sec/iter\n",
      "Epoch: 467 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 467 | Batch: 004 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 467 | Batch: 005 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.664500 | 0.38 sec/iter\n",
      "Epoch: 467 | Batch: 006 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 467 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 467 | Batch: 008 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 467 | Batch: 009 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 467 | Batch: 010 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.638225 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 468 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.643500 | 0.381 sec/iter\n",
      "Epoch: 468 | Batch: 001 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 468 | Batch: 002 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.628500 | 0.381 sec/iter\n",
      "Epoch: 468 | Batch: 003 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.647000 | 0.381 sec/iter\n",
      "Epoch: 468 | Batch: 004 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.658000 | 0.381 sec/iter\n",
      "Epoch: 468 | Batch: 005 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.639000 | 0.381 sec/iter\n",
      "Epoch: 468 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 468 | Batch: 007 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 468 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 468 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 468 | Batch: 010 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.600683 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 469 | Batch: 000 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.624000 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 001 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.626000 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 002 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 003 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.644000 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.652000 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.645500 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 007 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.624500 | 0.381 sec/iter\n",
      "Epoch: 469 | Batch: 008 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 469 | Batch: 009 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 469 | Batch: 010 / 011 | Total loss: 0.782 | Reg loss: 0.021 | Tree loss: 0.782 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 470 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 002 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 003 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.667500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470 | Batch: 004 / 011 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 009 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 470 | Batch: 010 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 471 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 001 / 011 | Total loss: 0.874 | Reg loss: 0.021 | Tree loss: 0.874 | Accuracy: 0.616000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 002 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.659000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.665000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 005 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 006 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 007 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.618500 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 008 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 471 | Batch: 010 / 011 | Total loss: 0.720 | Reg loss: 0.021 | Tree loss: 0.720 | Accuracy: 0.689420 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 472 | Batch: 000 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 001 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.625500 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 004 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.655000 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.648000 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 006 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.628000 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 008 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 472 | Batch: 010 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 473 | Batch: 000 / 011 | Total loss: 0.875 | Reg loss: 0.021 | Tree loss: 0.875 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 001 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 002 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 003 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.675000 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 005 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 006 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 007 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.616500 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 473 | Batch: 010 / 011 | Total loss: 0.758 | Reg loss: 0.021 | Tree loss: 0.758 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 474 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 474 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 474 | Batch: 002 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.637500 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 004 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.659000 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.650000 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 006 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 008 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 009 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 474 | Batch: 010 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.641638 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 475 | Batch: 000 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.631000 | 0.381 sec/iter\n",
      "Epoch: 475 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.639500 | 0.381 sec/iter\n",
      "Epoch: 475 | Batch: 002 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.656000 | 0.381 sec/iter\n",
      "Epoch: 475 | Batch: 003 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 475 | Batch: 004 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 475 | Batch: 005 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.637500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 475 | Batch: 006 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 475 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 475 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 475 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 475 | Batch: 010 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.604096 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 476 | Batch: 000 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.640000 | 0.381 sec/iter\n",
      "Epoch: 476 | Batch: 001 / 011 | Total loss: 0.870 | Reg loss: 0.021 | Tree loss: 0.870 | Accuracy: 0.627500 | 0.381 sec/iter\n",
      "Epoch: 476 | Batch: 002 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.653500 | 0.381 sec/iter\n",
      "Epoch: 476 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.648500 | 0.381 sec/iter\n",
      "Epoch: 476 | Batch: 004 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.651500 | 0.381 sec/iter\n",
      "Epoch: 476 | Batch: 005 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 476 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 476 | Batch: 007 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 476 | Batch: 008 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 476 | Batch: 009 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 476 | Batch: 010 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.587031 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 477 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.627000 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 002 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.623500 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 003 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.661500 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 004 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.657000 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 006 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.622000 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 007 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.642000 | 0.381 sec/iter\n",
      "Epoch: 477 | Batch: 008 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 477 | Batch: 009 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 477 | Batch: 010 / 011 | Total loss: 0.795 | Reg loss: 0.021 | Tree loss: 0.795 | Accuracy: 0.645051 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 478 | Batch: 000 / 011 | Total loss: 0.852 | Reg loss: 0.021 | Tree loss: 0.852 | Accuracy: 0.625500 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.644500 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 002 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.662000 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 003 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.638500 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.619500 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 006 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.629500 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 007 / 011 | Total loss: 0.819 | Reg loss: 0.021 | Tree loss: 0.819 | Accuracy: 0.633500 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 008 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.632000 | 0.381 sec/iter\n",
      "Epoch: 478 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 478 | Batch: 010 / 011 | Total loss: 0.877 | Reg loss: 0.021 | Tree loss: 0.877 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 479 | Batch: 000 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 001 / 011 | Total loss: 0.847 | Reg loss: 0.021 | Tree loss: 0.847 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 002 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 003 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 004 / 011 | Total loss: 0.833 | Reg loss: 0.021 | Tree loss: 0.833 | Accuracy: 0.652500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 005 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.648500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 006 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 007 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.613500 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 009 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.609000 | 0.38 sec/iter\n",
      "Epoch: 479 | Batch: 010 / 011 | Total loss: 0.767 | Reg loss: 0.021 | Tree loss: 0.767 | Accuracy: 0.617747 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 480 | Batch: 000 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 480 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.618000 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 002 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 003 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.661000 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 005 / 011 | Total loss: 0.793 | Reg loss: 0.021 | Tree loss: 0.793 | Accuracy: 0.669500 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 006 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 007 / 011 | Total loss: 0.842 | Reg loss: 0.021 | Tree loss: 0.842 | Accuracy: 0.615000 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480 | Batch: 008 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.606500 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 009 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 480 | Batch: 010 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.552901 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 481 | Batch: 000 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 001 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 003 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.664000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 004 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 006 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 007 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 009 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 481 | Batch: 010 / 011 | Total loss: 0.784 | Reg loss: 0.021 | Tree loss: 0.784 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 482 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.624500 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 002 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 004 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 005 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 006 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 007 / 011 | Total loss: 0.816 | Reg loss: 0.021 | Tree loss: 0.816 | Accuracy: 0.629000 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 008 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 009 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.621500 | 0.38 sec/iter\n",
      "Epoch: 482 | Batch: 010 / 011 | Total loss: 0.770 | Reg loss: 0.021 | Tree loss: 0.770 | Accuracy: 0.662116 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 483 | Batch: 000 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 002 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 003 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.661000 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 005 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 006 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 007 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.612500 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 009 / 011 | Total loss: 0.794 | Reg loss: 0.021 | Tree loss: 0.794 | Accuracy: 0.644500 | 0.38 sec/iter\n",
      "Epoch: 483 | Batch: 010 / 011 | Total loss: 0.869 | Reg loss: 0.021 | Tree loss: 0.869 | Accuracy: 0.597270 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 484 | Batch: 000 / 011 | Total loss: 0.845 | Reg loss: 0.021 | Tree loss: 0.845 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 001 / 011 | Total loss: 0.860 | Reg loss: 0.021 | Tree loss: 0.860 | Accuracy: 0.635000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 002 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 004 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 005 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 007 / 011 | Total loss: 0.800 | Reg loss: 0.021 | Tree loss: 0.800 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 008 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 009 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 484 | Batch: 010 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.665529 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 485 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.630500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 001 / 011 | Total loss: 0.862 | Reg loss: 0.021 | Tree loss: 0.862 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 002 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 003 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.644000 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 004 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 005 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 006 / 011 | Total loss: 0.797 | Reg loss: 0.021 | Tree loss: 0.797 | Accuracy: 0.646500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 008 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 485 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.634500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 485 | Batch: 010 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.638225 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 486 | Batch: 000 / 011 | Total loss: 0.856 | Reg loss: 0.021 | Tree loss: 0.856 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 001 / 011 | Total loss: 0.846 | Reg loss: 0.021 | Tree loss: 0.846 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.634500 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.643000 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 004 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.642500 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 005 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 006 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 007 / 011 | Total loss: 0.792 | Reg loss: 0.021 | Tree loss: 0.792 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 008 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 009 / 011 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 486 | Batch: 010 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.651877 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 487 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 001 / 011 | Total loss: 0.879 | Reg loss: 0.021 | Tree loss: 0.879 | Accuracy: 0.615500 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 002 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 003 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 004 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.666000 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 005 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 006 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 007 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 008 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 487 | Batch: 010 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.610922 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 488 | Batch: 000 / 011 | Total loss: 0.896 | Reg loss: 0.021 | Tree loss: 0.896 | Accuracy: 0.603000 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 001 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.650500 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 002 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 003 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.662500 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 004 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.645500 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 005 / 011 | Total loss: 0.821 | Reg loss: 0.021 | Tree loss: 0.821 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 006 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 007 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 008 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 009 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.619500 | 0.38 sec/iter\n",
      "Epoch: 488 | Batch: 010 / 011 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.580205 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 489 | Batch: 000 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 001 / 011 | Total loss: 0.857 | Reg loss: 0.021 | Tree loss: 0.857 | Accuracy: 0.617500 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 002 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 003 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 004 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.639500 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 005 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 007 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 008 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.615000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 009 / 011 | Total loss: 0.789 | Reg loss: 0.021 | Tree loss: 0.789 | Accuracy: 0.640000 | 0.38 sec/iter\n",
      "Epoch: 489 | Batch: 010 / 011 | Total loss: 0.725 | Reg loss: 0.021 | Tree loss: 0.725 | Accuracy: 0.679181 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 490 | Batch: 000 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.632500 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 001 / 011 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 002 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 003 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 004 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.658500 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 005 / 011 | Total loss: 0.829 | Reg loss: 0.021 | Tree loss: 0.829 | Accuracy: 0.638000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 006 / 011 | Total loss: 0.790 | Reg loss: 0.021 | Tree loss: 0.790 | Accuracy: 0.660500 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 007 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 008 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.619000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 009 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.607000 | 0.38 sec/iter\n",
      "Epoch: 490 | Batch: 010 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.607509 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9723756906077349\n",
      "Epoch: 491 | Batch: 000 / 011 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 001 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 002 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 003 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 004 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.656500 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 005 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 006 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 007 / 011 | Total loss: 0.803 | Reg loss: 0.021 | Tree loss: 0.803 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 008 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.622000 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 009 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.639000 | 0.38 sec/iter\n",
      "Epoch: 491 | Batch: 010 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 492 | Batch: 000 / 011 | Total loss: 0.859 | Reg loss: 0.021 | Tree loss: 0.859 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 001 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.657500 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 002 / 011 | Total loss: 0.848 | Reg loss: 0.021 | Tree loss: 0.848 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 003 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 004 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 005 / 011 | Total loss: 0.812 | Reg loss: 0.021 | Tree loss: 0.812 | Accuracy: 0.647000 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 006 / 011 | Total loss: 0.796 | Reg loss: 0.021 | Tree loss: 0.796 | Accuracy: 0.657000 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 007 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 008 / 011 | Total loss: 0.841 | Reg loss: 0.021 | Tree loss: 0.841 | Accuracy: 0.605000 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 009 / 011 | Total loss: 0.825 | Reg loss: 0.021 | Tree loss: 0.825 | Accuracy: 0.610500 | 0.38 sec/iter\n",
      "Epoch: 492 | Batch: 010 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 493 | Batch: 000 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.635000 | 0.381 sec/iter\n",
      "Epoch: 493 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.605000 | 0.381 sec/iter\n",
      "Epoch: 493 | Batch: 002 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.660000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 003 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 004 / 011 | Total loss: 0.822 | Reg loss: 0.021 | Tree loss: 0.822 | Accuracy: 0.664500 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.649000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 006 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.634000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 007 / 011 | Total loss: 0.832 | Reg loss: 0.021 | Tree loss: 0.832 | Accuracy: 0.617000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 008 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.625000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 009 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.632000 | 0.38 sec/iter\n",
      "Epoch: 493 | Batch: 010 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.638225 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 494 | Batch: 000 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.634500 | 0.381 sec/iter\n",
      "Epoch: 494 | Batch: 001 / 011 | Total loss: 0.854 | Reg loss: 0.021 | Tree loss: 0.854 | Accuracy: 0.612000 | 0.381 sec/iter\n",
      "Epoch: 494 | Batch: 002 / 011 | Total loss: 0.851 | Reg loss: 0.021 | Tree loss: 0.851 | Accuracy: 0.621500 | 0.381 sec/iter\n",
      "Epoch: 494 | Batch: 003 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.641000 | 0.381 sec/iter\n",
      "Epoch: 494 | Batch: 004 / 011 | Total loss: 0.835 | Reg loss: 0.021 | Tree loss: 0.835 | Accuracy: 0.657500 | 0.381 sec/iter\n",
      "Epoch: 494 | Batch: 005 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.673500 | 0.38 sec/iter\n",
      "Epoch: 494 | Batch: 006 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 494 | Batch: 007 / 011 | Total loss: 0.827 | Reg loss: 0.021 | Tree loss: 0.827 | Accuracy: 0.640500 | 0.38 sec/iter\n",
      "Epoch: 494 | Batch: 008 / 011 | Total loss: 0.806 | Reg loss: 0.021 | Tree loss: 0.806 | Accuracy: 0.626500 | 0.38 sec/iter\n",
      "Epoch: 494 | Batch: 009 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.627500 | 0.38 sec/iter\n",
      "Epoch: 494 | Batch: 010 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.634812 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 495 | Batch: 000 / 011 | Total loss: 0.878 | Reg loss: 0.021 | Tree loss: 0.878 | Accuracy: 0.611500 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 001 / 011 | Total loss: 0.805 | Reg loss: 0.021 | Tree loss: 0.805 | Accuracy: 0.659500 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 002 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.638000 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 003 / 011 | Total loss: 0.807 | Reg loss: 0.021 | Tree loss: 0.807 | Accuracy: 0.646500 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 004 / 011 | Total loss: 0.817 | Reg loss: 0.021 | Tree loss: 0.817 | Accuracy: 0.656500 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 005 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.642500 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 006 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.641500 | 0.381 sec/iter\n",
      "Epoch: 495 | Batch: 007 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.626000 | 0.38 sec/iter\n",
      "Epoch: 495 | Batch: 008 / 011 | Total loss: 0.818 | Reg loss: 0.021 | Tree loss: 0.818 | Accuracy: 0.622500 | 0.38 sec/iter\n",
      "Epoch: 495 | Batch: 009 / 011 | Total loss: 0.813 | Reg loss: 0.021 | Tree loss: 0.813 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 495 | Batch: 010 / 011 | Total loss: 0.814 | Reg loss: 0.021 | Tree loss: 0.814 | Accuracy: 0.631399 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 496 | Batch: 000 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.630000 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 001 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.637500 | 0.38 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 496 | Batch: 002 / 011 | Total loss: 0.868 | Reg loss: 0.021 | Tree loss: 0.868 | Accuracy: 0.621000 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 003 / 011 | Total loss: 0.823 | Reg loss: 0.021 | Tree loss: 0.823 | Accuracy: 0.643500 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 004 / 011 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.646000 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 005 / 011 | Total loss: 0.788 | Reg loss: 0.021 | Tree loss: 0.788 | Accuracy: 0.672500 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 006 / 011 | Total loss: 0.834 | Reg loss: 0.021 | Tree loss: 0.834 | Accuracy: 0.628500 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 007 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 008 / 011 | Total loss: 0.826 | Reg loss: 0.021 | Tree loss: 0.826 | Accuracy: 0.620500 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 009 / 011 | Total loss: 0.804 | Reg loss: 0.021 | Tree loss: 0.804 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 496 | Batch: 010 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.627986 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 497 | Batch: 000 / 011 | Total loss: 0.867 | Reg loss: 0.021 | Tree loss: 0.867 | Accuracy: 0.631500 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 001 / 011 | Total loss: 0.843 | Reg loss: 0.021 | Tree loss: 0.843 | Accuracy: 0.633500 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 002 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.624000 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 003 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.633000 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 004 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.667500 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 005 / 011 | Total loss: 0.808 | Reg loss: 0.021 | Tree loss: 0.808 | Accuracy: 0.663500 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 006 / 011 | Total loss: 0.801 | Reg loss: 0.021 | Tree loss: 0.801 | Accuracy: 0.645000 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 007 / 011 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.636000 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 008 / 011 | Total loss: 0.837 | Reg loss: 0.021 | Tree loss: 0.837 | Accuracy: 0.601000 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 009 / 011 | Total loss: 0.866 | Reg loss: 0.021 | Tree loss: 0.866 | Accuracy: 0.586500 | 0.38 sec/iter\n",
      "Epoch: 497 | Batch: 010 / 011 | Total loss: 0.772 | Reg loss: 0.021 | Tree loss: 0.772 | Accuracy: 0.658703 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 498 | Batch: 000 / 011 | Total loss: 0.861 | Reg loss: 0.021 | Tree loss: 0.861 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.612000 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 002 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 003 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.636500 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 004 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.659500 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 005 / 011 | Total loss: 0.828 | Reg loss: 0.021 | Tree loss: 0.828 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 006 / 011 | Total loss: 0.811 | Reg loss: 0.021 | Tree loss: 0.811 | Accuracy: 0.653500 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.623500 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 008 / 011 | Total loss: 0.831 | Reg loss: 0.021 | Tree loss: 0.831 | Accuracy: 0.623000 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 009 / 011 | Total loss: 0.799 | Reg loss: 0.021 | Tree loss: 0.799 | Accuracy: 0.641000 | 0.38 sec/iter\n",
      "Epoch: 498 | Batch: 010 / 011 | Total loss: 0.809 | Reg loss: 0.021 | Tree loss: 0.809 | Accuracy: 0.621160 | 0.38 sec/iter\n",
      "Average sparseness: 0.9723756906077348\n",
      "layer 0: 0.9723756906077348\n",
      "layer 1: 0.9723756906077348\n",
      "layer 2: 0.9723756906077348\n",
      "layer 3: 0.9723756906077348\n",
      "layer 4: 0.9723756906077348\n",
      "layer 5: 0.9723756906077348\n",
      "layer 6: 0.9723756906077349\n",
      "Epoch: 499 | Batch: 000 / 011 | Total loss: 0.824 | Reg loss: 0.021 | Tree loss: 0.824 | Accuracy: 0.647500 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 001 / 011 | Total loss: 0.853 | Reg loss: 0.021 | Tree loss: 0.853 | Accuracy: 0.627000 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 002 / 011 | Total loss: 0.844 | Reg loss: 0.021 | Tree loss: 0.844 | Accuracy: 0.637000 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 003 / 011 | Total loss: 0.840 | Reg loss: 0.021 | Tree loss: 0.840 | Accuracy: 0.635500 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 004 / 011 | Total loss: 0.820 | Reg loss: 0.021 | Tree loss: 0.820 | Accuracy: 0.655500 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 005 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.653000 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 006 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.631000 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 007 / 011 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.610500 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 008 / 011 | Total loss: 0.836 | Reg loss: 0.021 | Tree loss: 0.836 | Accuracy: 0.614500 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 009 / 011 | Total loss: 0.810 | Reg loss: 0.021 | Tree loss: 0.810 | Accuracy: 0.642000 | 0.38 sec/iter\n",
      "Epoch: 499 | Batch: 010 / 011 | Total loss: 0.855 | Reg loss: 0.021 | Tree loss: 0.855 | Accuracy: 0.600683 | 0.38 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 6.754098360655738\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 61\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'MLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "20293\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "============== Pattern 19 ==============\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "============== Pattern 25 ==============\n",
      "============== Pattern 26 ==============\n",
      "============== Pattern 27 ==============\n",
      "============== Pattern 28 ==============\n",
      "============== Pattern 29 ==============\n",
      "============== Pattern 30 ==============\n",
      "============== Pattern 31 ==============\n",
      "============== Pattern 32 ==============\n",
      "============== Pattern 33 ==============\n",
      "============== Pattern 34 ==============\n",
      "============== Pattern 35 ==============\n",
      "============== Pattern 36 ==============\n",
      "============== Pattern 37 ==============\n",
      "============== Pattern 38 ==============\n",
      "============== Pattern 39 ==============\n",
      "============== Pattern 40 ==============\n",
      "============== Pattern 41 ==============\n",
      "============== Pattern 42 ==============\n",
      "============== Pattern 43 ==============\n",
      "============== Pattern 44 ==============\n",
      "============== Pattern 45 ==============\n",
      "============== Pattern 46 ==============\n",
      "============== Pattern 47 ==============\n",
      "============== Pattern 48 ==============\n",
      "============== Pattern 49 ==============\n",
      "============== Pattern 50 ==============\n",
      "============== Pattern 51 ==============\n",
      "============== Pattern 52 ==============\n",
      "============== Pattern 53 ==============\n",
      "============== Pattern 54 ==============\n",
      "============== Pattern 55 ==============\n",
      "============== Pattern 56 ==============\n",
      "============== Pattern 57 ==============\n",
      "============== Pattern 58 ==============\n",
      "============== Pattern 59 ==============\n",
      "============== Pattern 60 ==============\n",
      "============== Pattern 61 ==============\n",
      "Average comprehensibility: 64.0327868852459\n",
      "std comprehensibility: 14.667871897578136\n",
      "var comprehensibility: 215.1464660037624\n",
      "minimum comprehensibility: 24\n",
      "maximum comprehensibility: 78\n"
     ]
    }
   ],
   "source": [
    "signal_names = dataset.dataset.all_signals\n",
    "normalizers = torch.tensor([])\n",
    "attr_names = []\n",
    "for signal_name in signal_names:\n",
    "    attr_names += [f\"T{i}.{signal_name}\" for i in range(sampled.shape[-1])]\n",
    "    sensor_norm = torch.tensor([torch.tensor(dataset.dataset.sensor_maxs[signal_name]) for _ in range(sampled.shape[-1])])\n",
    "    normalizers = torch.cat([normalizers, sensor_norm])\n",
    "    \n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    for cond in conds:\n",
    "        cond.weights = cond.weights / normalizers\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
