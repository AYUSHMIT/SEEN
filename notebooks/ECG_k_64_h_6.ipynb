{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 64\n",
    "tree_depth = 6\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.303014755249023 | KNN Loss: 5.731903553009033 | CLS Loss: 1.5711109638214111\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 5.449155807495117 | KNN Loss: 4.73738956451416 | CLS Loss: 0.7117664813995361\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 5.2877278327941895 | KNN Loss: 4.609186172485352 | CLS Loss: 0.6785417795181274\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 5.199596405029297 | KNN Loss: 4.553031921386719 | CLS Loss: 0.6465644836425781\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 5.04219388961792 | KNN Loss: 4.514331340789795 | CLS Loss: 0.5278626084327698\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 5.134302616119385 | KNN Loss: 4.567552089691162 | CLS Loss: 0.5667505860328674\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 5.0261921882629395 | KNN Loss: 4.5067338943481445 | CLS Loss: 0.5194582939147949\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.983083724975586 | KNN Loss: 4.485644817352295 | CLS Loss: 0.4974391460418701\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.822225570678711 | KNN Loss: 4.462758541107178 | CLS Loss: 0.3594670593738556\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.880746841430664 | KNN Loss: 4.418784141540527 | CLS Loss: 0.4619625508785248\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.900815486907959 | KNN Loss: 4.418549537658691 | CLS Loss: 0.48226606845855713\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.727579593658447 | KNN Loss: 4.3720550537109375 | CLS Loss: 0.35552462935447693\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.724827766418457 | KNN Loss: 4.415557861328125 | CLS Loss: 0.3092696964740753\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.671380043029785 | KNN Loss: 4.357109546661377 | CLS Loss: 0.31427037715911865\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.780028343200684 | KNN Loss: 4.428051471710205 | CLS Loss: 0.35197675228118896\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.7273406982421875 | KNN Loss: 4.405120372772217 | CLS Loss: 0.3222202956676483\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.620558738708496 | KNN Loss: 4.345426559448242 | CLS Loss: 0.27513211965560913\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.595983982086182 | KNN Loss: 4.339775085449219 | CLS Loss: 0.25620895624160767\n",
      "Epoch: 001, Loss: 4.9988, Train: 0.9324, Valid: 0.9328, Best: 0.9328\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.692935943603516 | KNN Loss: 4.341916561126709 | CLS Loss: 0.3510194420814514\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.622734069824219 | KNN Loss: 4.374478340148926 | CLS Loss: 0.24825584888458252\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.566370487213135 | KNN Loss: 4.333676338195801 | CLS Loss: 0.2326940894126892\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 4.668000221252441 | KNN Loss: 4.3934197425842285 | CLS Loss: 0.27458029985427856\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 4.59631872177124 | KNN Loss: 4.326944351196289 | CLS Loss: 0.26937443017959595\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 4.699987888336182 | KNN Loss: 4.418390274047852 | CLS Loss: 0.28159773349761963\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 4.55706787109375 | KNN Loss: 4.354773998260498 | CLS Loss: 0.20229390263557434\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 4.571453094482422 | KNN Loss: 4.343774318695068 | CLS Loss: 0.22767861187458038\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 4.615169525146484 | KNN Loss: 4.343868255615234 | CLS Loss: 0.2713013291358948\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 4.665790557861328 | KNN Loss: 4.360330581665039 | CLS Loss: 0.30545997619628906\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 4.569613456726074 | KNN Loss: 4.323210716247559 | CLS Loss: 0.24640265107154846\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 4.631088733673096 | KNN Loss: 4.3496413230896 | CLS Loss: 0.2814474105834961\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 4.576292037963867 | KNN Loss: 4.376305103302002 | CLS Loss: 0.19998709857463837\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 4.564415454864502 | KNN Loss: 4.344381809234619 | CLS Loss: 0.22003380954265594\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 4.567758560180664 | KNN Loss: 4.341564178466797 | CLS Loss: 0.22619418799877167\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 4.53521728515625 | KNN Loss: 4.319014072418213 | CLS Loss: 0.2162032425403595\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 4.58465576171875 | KNN Loss: 4.31699275970459 | CLS Loss: 0.26766276359558105\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 4.490262985229492 | KNN Loss: 4.313310146331787 | CLS Loss: 0.1769530177116394\n",
      "Epoch: 002, Loss: 4.5959, Train: 0.9470, Valid: 0.9473, Best: 0.9473\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 4.512904167175293 | KNN Loss: 4.328122615814209 | CLS Loss: 0.18478159606456757\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 4.515027046203613 | KNN Loss: 4.321355819702148 | CLS Loss: 0.1936710625886917\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 4.5947113037109375 | KNN Loss: 4.391077041625977 | CLS Loss: 0.20363444089889526\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 4.486320972442627 | KNN Loss: 4.303920269012451 | CLS Loss: 0.18240053951740265\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 4.493992805480957 | KNN Loss: 4.339068412780762 | CLS Loss: 0.1549243927001953\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 4.491260051727295 | KNN Loss: 4.3014068603515625 | CLS Loss: 0.18985314667224884\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 4.507312774658203 | KNN Loss: 4.287348747253418 | CLS Loss: 0.21996401250362396\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 4.593361854553223 | KNN Loss: 4.3377685546875 | CLS Loss: 0.25559353828430176\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 4.496921062469482 | KNN Loss: 4.277721405029297 | CLS Loss: 0.2191997915506363\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 4.497067451477051 | KNN Loss: 4.334606170654297 | CLS Loss: 0.16246117651462555\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 4.512143611907959 | KNN Loss: 4.332306385040283 | CLS Loss: 0.17983706295490265\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 4.476863384246826 | KNN Loss: 4.3218488693237305 | CLS Loss: 0.15501435101032257\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 4.530744552612305 | KNN Loss: 4.305783748626709 | CLS Loss: 0.22496093809604645\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 4.549559116363525 | KNN Loss: 4.354465961456299 | CLS Loss: 0.19509312510490417\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 4.4973578453063965 | KNN Loss: 4.289187908172607 | CLS Loss: 0.2081698775291443\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 4.47994327545166 | KNN Loss: 4.294799327850342 | CLS Loss: 0.18514378368854523\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 4.420714378356934 | KNN Loss: 4.276360988616943 | CLS Loss: 0.14435343444347382\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 4.464265823364258 | KNN Loss: 4.299624919891357 | CLS Loss: 0.16464069485664368\n",
      "Epoch: 003, Loss: 4.5091, Train: 0.9526, Valid: 0.9520, Best: 0.9520\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 4.4854230880737305 | KNN Loss: 4.295263290405273 | CLS Loss: 0.19015958905220032\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 4.496158123016357 | KNN Loss: 4.3193159103393555 | CLS Loss: 0.1768423169851303\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 4.4474263191223145 | KNN Loss: 4.27347469329834 | CLS Loss: 0.17395175993442535\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 4.451951503753662 | KNN Loss: 4.301894664764404 | CLS Loss: 0.15005682408809662\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 4.492161273956299 | KNN Loss: 4.286376953125 | CLS Loss: 0.2057843804359436\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 4.36663293838501 | KNN Loss: 4.224485874176025 | CLS Loss: 0.1421472132205963\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 4.54197359085083 | KNN Loss: 4.277700901031494 | CLS Loss: 0.26427289843559265\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 4.460843563079834 | KNN Loss: 4.310069561004639 | CLS Loss: 0.15077418088912964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 4.453580856323242 | KNN Loss: 4.280031204223633 | CLS Loss: 0.17354948818683624\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 4.456829071044922 | KNN Loss: 4.278853893280029 | CLS Loss: 0.1779753863811493\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 4.422021389007568 | KNN Loss: 4.252720832824707 | CLS Loss: 0.169300377368927\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 4.439184665679932 | KNN Loss: 4.2957000732421875 | CLS Loss: 0.14348460733890533\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 4.44588041305542 | KNN Loss: 4.277695178985596 | CLS Loss: 0.16818521916866302\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 4.444919109344482 | KNN Loss: 4.2993974685668945 | CLS Loss: 0.1455218642950058\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 4.41594123840332 | KNN Loss: 4.2986297607421875 | CLS Loss: 0.11731164157390594\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 4.403146743774414 | KNN Loss: 4.288595676422119 | CLS Loss: 0.1145508736371994\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 4.446214199066162 | KNN Loss: 4.27496862411499 | CLS Loss: 0.1712454855442047\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 4.385624408721924 | KNN Loss: 4.284814834594727 | CLS Loss: 0.100809745490551\n",
      "Epoch: 004, Loss: 4.4500, Train: 0.9634, Valid: 0.9622, Best: 0.9622\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 4.37226676940918 | KNN Loss: 4.251922130584717 | CLS Loss: 0.12034469097852707\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 4.385055065155029 | KNN Loss: 4.278078079223633 | CLS Loss: 0.10697683691978455\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 4.379448413848877 | KNN Loss: 4.2678046226501465 | CLS Loss: 0.11164357513189316\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 4.400436878204346 | KNN Loss: 4.228359699249268 | CLS Loss: 0.17207734286785126\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 4.379693984985352 | KNN Loss: 4.25601863861084 | CLS Loss: 0.12367519736289978\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 4.353026866912842 | KNN Loss: 4.280000686645508 | CLS Loss: 0.07302609086036682\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 4.407726764678955 | KNN Loss: 4.312803268432617 | CLS Loss: 0.09492358565330505\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 4.398771286010742 | KNN Loss: 4.309509754180908 | CLS Loss: 0.0892617404460907\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 4.364543437957764 | KNN Loss: 4.282378196716309 | CLS Loss: 0.08216524124145508\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 4.361400604248047 | KNN Loss: 4.226688385009766 | CLS Loss: 0.13471239805221558\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 4.380341053009033 | KNN Loss: 4.285616874694824 | CLS Loss: 0.09472395479679108\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 4.441356182098389 | KNN Loss: 4.311046123504639 | CLS Loss: 0.13031020760536194\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 4.45948600769043 | KNN Loss: 4.301511287689209 | CLS Loss: 0.1579744815826416\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 4.411581993103027 | KNN Loss: 4.2882609367370605 | CLS Loss: 0.12332084774971008\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 4.42018461227417 | KNN Loss: 4.289124488830566 | CLS Loss: 0.13106025755405426\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 4.407782077789307 | KNN Loss: 4.2631120681762695 | CLS Loss: 0.1446700543165207\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 4.39321756362915 | KNN Loss: 4.303592681884766 | CLS Loss: 0.08962500840425491\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 4.44317626953125 | KNN Loss: 4.296880722045898 | CLS Loss: 0.14629577100276947\n",
      "Epoch: 005, Loss: 4.3983, Train: 0.9735, Valid: 0.9718, Best: 0.9718\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 4.335608005523682 | KNN Loss: 4.257888317108154 | CLS Loss: 0.07771964371204376\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 4.398468971252441 | KNN Loss: 4.293289661407471 | CLS Loss: 0.10517940670251846\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 4.352837562561035 | KNN Loss: 4.247531414031982 | CLS Loss: 0.10530620813369751\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 4.418179512023926 | KNN Loss: 4.280318737030029 | CLS Loss: 0.13786087930202484\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 4.427526950836182 | KNN Loss: 4.268429279327393 | CLS Loss: 0.1590975522994995\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 4.403155326843262 | KNN Loss: 4.274508476257324 | CLS Loss: 0.12864695489406586\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 4.390800476074219 | KNN Loss: 4.267198085784912 | CLS Loss: 0.12360230088233948\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 4.345126152038574 | KNN Loss: 4.253328323364258 | CLS Loss: 0.0917978510260582\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 4.333038330078125 | KNN Loss: 4.260618209838867 | CLS Loss: 0.07241994887590408\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 4.3696112632751465 | KNN Loss: 4.276307582855225 | CLS Loss: 0.09330353140830994\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 4.395654678344727 | KNN Loss: 4.303194999694824 | CLS Loss: 0.09245990216732025\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 4.3587422370910645 | KNN Loss: 4.283611297607422 | CLS Loss: 0.07513115555047989\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 4.33650541305542 | KNN Loss: 4.258454322814941 | CLS Loss: 0.07805117219686508\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 4.363231182098389 | KNN Loss: 4.28228235244751 | CLS Loss: 0.08094899356365204\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 4.390444755554199 | KNN Loss: 4.303208351135254 | CLS Loss: 0.0872361958026886\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 4.354078769683838 | KNN Loss: 4.261462688446045 | CLS Loss: 0.09261620789766312\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 4.357231140136719 | KNN Loss: 4.226693630218506 | CLS Loss: 0.13053752481937408\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 4.370307922363281 | KNN Loss: 4.270161151885986 | CLS Loss: 0.10014665126800537\n",
      "Epoch: 006, Loss: 4.3692, Train: 0.9773, Valid: 0.9753, Best: 0.9753\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 4.321225643157959 | KNN Loss: 4.226861476898193 | CLS Loss: 0.09436395019292831\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 4.3353118896484375 | KNN Loss: 4.261106967926025 | CLS Loss: 0.07420496642589569\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 4.341083526611328 | KNN Loss: 4.254240989685059 | CLS Loss: 0.08684247732162476\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 4.363754749298096 | KNN Loss: 4.285254001617432 | CLS Loss: 0.07850051671266556\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 4.359442234039307 | KNN Loss: 4.293490886688232 | CLS Loss: 0.0659513995051384\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 4.326114654541016 | KNN Loss: 4.257915019989014 | CLS Loss: 0.06819985806941986\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 4.368539810180664 | KNN Loss: 4.265825271606445 | CLS Loss: 0.10271468758583069\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 4.336554527282715 | KNN Loss: 4.231147766113281 | CLS Loss: 0.10540666431188583\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 4.345058441162109 | KNN Loss: 4.262645244598389 | CLS Loss: 0.08241298794746399\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 4.355255603790283 | KNN Loss: 4.266066074371338 | CLS Loss: 0.08918976038694382\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 4.376423358917236 | KNN Loss: 4.291700839996338 | CLS Loss: 0.08472269028425217\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 4.354942321777344 | KNN Loss: 4.2469682693481445 | CLS Loss: 0.10797394067049026\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 4.334362506866455 | KNN Loss: 4.240971088409424 | CLS Loss: 0.09339120239019394\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 4.3076300621032715 | KNN Loss: 4.240925312042236 | CLS Loss: 0.0667048841714859\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 4.287379264831543 | KNN Loss: 4.219457149505615 | CLS Loss: 0.06792192906141281\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 4.378657341003418 | KNN Loss: 4.270001411437988 | CLS Loss: 0.10865593701601028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 4.271496772766113 | KNN Loss: 4.237403869628906 | CLS Loss: 0.03409278392791748\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 4.4215545654296875 | KNN Loss: 4.311953544616699 | CLS Loss: 0.10960079729557037\n",
      "Epoch: 007, Loss: 4.3496, Train: 0.9781, Valid: 0.9762, Best: 0.9762\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 4.328602313995361 | KNN Loss: 4.25540018081665 | CLS Loss: 0.07320191711187363\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 4.354703426361084 | KNN Loss: 4.2576446533203125 | CLS Loss: 0.09705885499715805\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 4.363182544708252 | KNN Loss: 4.277888774871826 | CLS Loss: 0.08529369533061981\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 4.294840335845947 | KNN Loss: 4.2391510009765625 | CLS Loss: 0.05568942427635193\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 4.3226799964904785 | KNN Loss: 4.238986492156982 | CLS Loss: 0.08369331061840057\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 4.343766212463379 | KNN Loss: 4.264186382293701 | CLS Loss: 0.079579658806324\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 4.307332515716553 | KNN Loss: 4.252284526824951 | CLS Loss: 0.055048100650310516\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 4.316009521484375 | KNN Loss: 4.258149147033691 | CLS Loss: 0.05786031484603882\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 4.325863361358643 | KNN Loss: 4.2618560791015625 | CLS Loss: 0.06400716304779053\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 4.307553291320801 | KNN Loss: 4.2560834884643555 | CLS Loss: 0.05146969109773636\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 4.2886528968811035 | KNN Loss: 4.235530376434326 | CLS Loss: 0.05312275514006615\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 4.39354133605957 | KNN Loss: 4.262009620666504 | CLS Loss: 0.13153192400932312\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 4.286179065704346 | KNN Loss: 4.2271199226379395 | CLS Loss: 0.059059374034404755\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 4.3447794914245605 | KNN Loss: 4.26641321182251 | CLS Loss: 0.07836636900901794\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 4.296406269073486 | KNN Loss: 4.22779655456543 | CLS Loss: 0.06860970705747604\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 4.340223789215088 | KNN Loss: 4.249167442321777 | CLS Loss: 0.091056227684021\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 4.348062992095947 | KNN Loss: 4.2505011558532715 | CLS Loss: 0.09756182134151459\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 4.34735107421875 | KNN Loss: 4.244546413421631 | CLS Loss: 0.10280446708202362\n",
      "Epoch: 008, Loss: 4.3311, Train: 0.9799, Valid: 0.9772, Best: 0.9772\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 4.337162494659424 | KNN Loss: 4.252368927001953 | CLS Loss: 0.08479375392198563\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 4.319007873535156 | KNN Loss: 4.255263328552246 | CLS Loss: 0.06374435126781464\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 4.281088829040527 | KNN Loss: 4.190730094909668 | CLS Loss: 0.09035862237215042\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 4.302770137786865 | KNN Loss: 4.247549533843994 | CLS Loss: 0.05522046238183975\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 4.2996745109558105 | KNN Loss: 4.234983921051025 | CLS Loss: 0.06469038873910904\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 4.294185638427734 | KNN Loss: 4.205125331878662 | CLS Loss: 0.08906027674674988\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 4.313713073730469 | KNN Loss: 4.213541030883789 | CLS Loss: 0.10017211735248566\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 4.294916152954102 | KNN Loss: 4.19606351852417 | CLS Loss: 0.09885270148515701\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 4.378347396850586 | KNN Loss: 4.26940393447876 | CLS Loss: 0.10894346982240677\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 4.310978889465332 | KNN Loss: 4.2594990730285645 | CLS Loss: 0.051479972898960114\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 4.302731990814209 | KNN Loss: 4.228389739990234 | CLS Loss: 0.07434247434139252\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 4.246212482452393 | KNN Loss: 4.204207897186279 | CLS Loss: 0.042004525661468506\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 4.262792587280273 | KNN Loss: 4.216753959655762 | CLS Loss: 0.04603862017393112\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 4.283864974975586 | KNN Loss: 4.22499418258667 | CLS Loss: 0.058870960026979446\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 4.3588972091674805 | KNN Loss: 4.257540225982666 | CLS Loss: 0.10135698318481445\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 4.322752952575684 | KNN Loss: 4.250810146331787 | CLS Loss: 0.07194292545318604\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 4.31610107421875 | KNN Loss: 4.259458541870117 | CLS Loss: 0.05664230138063431\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 4.318001747131348 | KNN Loss: 4.250827312469482 | CLS Loss: 0.06717437505722046\n",
      "Epoch: 009, Loss: 4.3150, Train: 0.9811, Valid: 0.9786, Best: 0.9786\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 4.310710430145264 | KNN Loss: 4.23529577255249 | CLS Loss: 0.07541488111019135\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 4.329373359680176 | KNN Loss: 4.264593601226807 | CLS Loss: 0.06477990746498108\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 4.288515090942383 | KNN Loss: 4.22406005859375 | CLS Loss: 0.0644548088312149\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 4.3075714111328125 | KNN Loss: 4.228660583496094 | CLS Loss: 0.07891106605529785\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 4.322882652282715 | KNN Loss: 4.245631217956543 | CLS Loss: 0.07725122570991516\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 4.415169715881348 | KNN Loss: 4.32119083404541 | CLS Loss: 0.0939788818359375\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 4.362856864929199 | KNN Loss: 4.297478675842285 | CLS Loss: 0.06537831574678421\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 4.2716569900512695 | KNN Loss: 4.217554569244385 | CLS Loss: 0.054102249443531036\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 4.337768077850342 | KNN Loss: 4.27317476272583 | CLS Loss: 0.06459315866231918\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 4.307835102081299 | KNN Loss: 4.2348198890686035 | CLS Loss: 0.07301542162895203\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 4.305729389190674 | KNN Loss: 4.244847297668457 | CLS Loss: 0.060882169753313065\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 4.378188610076904 | KNN Loss: 4.268738269805908 | CLS Loss: 0.10945029556751251\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 4.303032875061035 | KNN Loss: 4.228626251220703 | CLS Loss: 0.07440638542175293\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 4.359853267669678 | KNN Loss: 4.265048980712891 | CLS Loss: 0.09480451047420502\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 4.3068623542785645 | KNN Loss: 4.228238582611084 | CLS Loss: 0.07862373441457748\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 4.270930767059326 | KNN Loss: 4.221412181854248 | CLS Loss: 0.049518413841724396\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 4.321329116821289 | KNN Loss: 4.24310302734375 | CLS Loss: 0.07822602987289429\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 4.348568916320801 | KNN Loss: 4.262516498565674 | CLS Loss: 0.08605219423770905\n",
      "Epoch: 010, Loss: 4.3095, Train: 0.9832, Valid: 0.9795, Best: 0.9795\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 4.28935432434082 | KNN Loss: 4.2310895919799805 | CLS Loss: 0.05826487019658089\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 4.259880542755127 | KNN Loss: 4.223616600036621 | CLS Loss: 0.036263931542634964\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 4.257923126220703 | KNN Loss: 4.212137222290039 | CLS Loss: 0.04578595608472824\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 4.293931007385254 | KNN Loss: 4.239909648895264 | CLS Loss: 0.0540214367210865\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 4.357726573944092 | KNN Loss: 4.265573024749756 | CLS Loss: 0.09215351194143295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 4.319055080413818 | KNN Loss: 4.250992298126221 | CLS Loss: 0.06806281954050064\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 4.287293910980225 | KNN Loss: 4.216714859008789 | CLS Loss: 0.0705791637301445\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 4.3196024894714355 | KNN Loss: 4.24448823928833 | CLS Loss: 0.07511436194181442\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 4.336727142333984 | KNN Loss: 4.268614768981934 | CLS Loss: 0.06811220943927765\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 4.2627034187316895 | KNN Loss: 4.196775913238525 | CLS Loss: 0.06592747569084167\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 4.307506561279297 | KNN Loss: 4.2461066246032715 | CLS Loss: 0.061399850994348526\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 4.333591938018799 | KNN Loss: 4.2286481857299805 | CLS Loss: 0.10494387149810791\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 4.277791500091553 | KNN Loss: 4.230057716369629 | CLS Loss: 0.04773376137018204\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 4.342279434204102 | KNN Loss: 4.2507643699646 | CLS Loss: 0.09151506423950195\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 4.247053623199463 | KNN Loss: 4.213812351226807 | CLS Loss: 0.033241499215364456\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 4.31581974029541 | KNN Loss: 4.240088939666748 | CLS Loss: 0.07573069632053375\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 4.350049018859863 | KNN Loss: 4.275498867034912 | CLS Loss: 0.07455003261566162\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 4.297404766082764 | KNN Loss: 4.22611665725708 | CLS Loss: 0.07128807157278061\n",
      "Epoch: 011, Loss: 4.3023, Train: 0.9835, Valid: 0.9810, Best: 0.9810\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 4.288158893585205 | KNN Loss: 4.229374885559082 | CLS Loss: 0.05878394842147827\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 4.251783847808838 | KNN Loss: 4.211694240570068 | CLS Loss: 0.04008952155709267\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 4.334216117858887 | KNN Loss: 4.278279781341553 | CLS Loss: 0.05593650043010712\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 4.34562349319458 | KNN Loss: 4.257525444030762 | CLS Loss: 0.08809801191091537\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 4.309895038604736 | KNN Loss: 4.225228786468506 | CLS Loss: 0.08466602116823196\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 4.2942376136779785 | KNN Loss: 4.2174201011657715 | CLS Loss: 0.07681732624769211\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 4.274234771728516 | KNN Loss: 4.224253177642822 | CLS Loss: 0.049981728196144104\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 4.320179462432861 | KNN Loss: 4.2425031661987305 | CLS Loss: 0.07767632603645325\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 4.272956371307373 | KNN Loss: 4.200414180755615 | CLS Loss: 0.07254226505756378\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 4.375065803527832 | KNN Loss: 4.3061442375183105 | CLS Loss: 0.0689217746257782\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 4.295323848724365 | KNN Loss: 4.2426276206970215 | CLS Loss: 0.05269601196050644\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 4.3550872802734375 | KNN Loss: 4.262670993804932 | CLS Loss: 0.09241613745689392\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 4.291930198669434 | KNN Loss: 4.248876571655273 | CLS Loss: 0.04305371642112732\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 4.326662063598633 | KNN Loss: 4.274238109588623 | CLS Loss: 0.05242413654923439\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 4.267332553863525 | KNN Loss: 4.215295791625977 | CLS Loss: 0.05203670635819435\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 4.314253807067871 | KNN Loss: 4.242215156555176 | CLS Loss: 0.072038434445858\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 4.285303592681885 | KNN Loss: 4.210441589355469 | CLS Loss: 0.07486181706190109\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 4.32081937789917 | KNN Loss: 4.256894588470459 | CLS Loss: 0.06392496079206467\n",
      "Epoch: 012, Loss: 4.2905, Train: 0.9851, Valid: 0.9818, Best: 0.9818\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 4.252326488494873 | KNN Loss: 4.203999042510986 | CLS Loss: 0.04832742363214493\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 4.2603440284729 | KNN Loss: 4.221033573150635 | CLS Loss: 0.03931029140949249\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 4.275030612945557 | KNN Loss: 4.208583354949951 | CLS Loss: 0.06644707173109055\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 4.2739667892456055 | KNN Loss: 4.221493721008301 | CLS Loss: 0.052473265677690506\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 4.2577128410339355 | KNN Loss: 4.216465473175049 | CLS Loss: 0.041247304528951645\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 4.290420055389404 | KNN Loss: 4.237595558166504 | CLS Loss: 0.05282468721270561\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 4.312285900115967 | KNN Loss: 4.256324768066406 | CLS Loss: 0.05596092715859413\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 4.274969577789307 | KNN Loss: 4.235604286193848 | CLS Loss: 0.039365384727716446\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 4.307216167449951 | KNN Loss: 4.252776622772217 | CLS Loss: 0.05443938076496124\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 4.295909404754639 | KNN Loss: 4.235807418823242 | CLS Loss: 0.060101915150880814\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 4.279927730560303 | KNN Loss: 4.233880996704102 | CLS Loss: 0.04604673385620117\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 4.285984039306641 | KNN Loss: 4.247039794921875 | CLS Loss: 0.038944028317928314\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 4.2654523849487305 | KNN Loss: 4.212749481201172 | CLS Loss: 0.05270269140601158\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 4.372955799102783 | KNN Loss: 4.2271623611450195 | CLS Loss: 0.14579349756240845\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 4.312160968780518 | KNN Loss: 4.24456262588501 | CLS Loss: 0.06759817898273468\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 4.2440409660339355 | KNN Loss: 4.214793682098389 | CLS Loss: 0.02924746461212635\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 4.282743453979492 | KNN Loss: 4.215782642364502 | CLS Loss: 0.06696061044931412\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 4.319957256317139 | KNN Loss: 4.252196311950684 | CLS Loss: 0.06776092201471329\n",
      "Epoch: 013, Loss: 4.2885, Train: 0.9851, Valid: 0.9816, Best: 0.9818\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 4.269031524658203 | KNN Loss: 4.217026710510254 | CLS Loss: 0.05200495943427086\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 4.275376796722412 | KNN Loss: 4.212575912475586 | CLS Loss: 0.06280100345611572\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 4.2525787353515625 | KNN Loss: 4.224621295928955 | CLS Loss: 0.02795722894370556\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 4.313669681549072 | KNN Loss: 4.258332252502441 | CLS Loss: 0.05533721670508385\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 4.337815761566162 | KNN Loss: 4.270282745361328 | CLS Loss: 0.06753301620483398\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 4.310584545135498 | KNN Loss: 4.24605131149292 | CLS Loss: 0.06453323364257812\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 4.277381896972656 | KNN Loss: 4.224081993103027 | CLS Loss: 0.05330003425478935\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 4.291672229766846 | KNN Loss: 4.226101875305176 | CLS Loss: 0.065570168197155\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 4.278740406036377 | KNN Loss: 4.209131240844727 | CLS Loss: 0.06960925459861755\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 4.346019744873047 | KNN Loss: 4.267478942871094 | CLS Loss: 0.07854080200195312\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 4.2772135734558105 | KNN Loss: 4.2163825035095215 | CLS Loss: 0.0608309730887413\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 4.254654884338379 | KNN Loss: 4.213926792144775 | CLS Loss: 0.04072796553373337\n",
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 4.2519402503967285 | KNN Loss: 4.204023361206055 | CLS Loss: 0.04791683331131935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 4.287924289703369 | KNN Loss: 4.241753578186035 | CLS Loss: 0.04617079719901085\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 4.2644243240356445 | KNN Loss: 4.207264423370361 | CLS Loss: 0.057159729301929474\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 4.306877136230469 | KNN Loss: 4.237769603729248 | CLS Loss: 0.06910748034715652\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 4.267545700073242 | KNN Loss: 4.225411415100098 | CLS Loss: 0.04213442653417587\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 4.248343467712402 | KNN Loss: 4.228784561157227 | CLS Loss: 0.019559090957045555\n",
      "Epoch: 014, Loss: 4.2794, Train: 0.9854, Valid: 0.9820, Best: 0.9820\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 4.325794219970703 | KNN Loss: 4.262497425079346 | CLS Loss: 0.06329665333032608\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 4.276278972625732 | KNN Loss: 4.239833354949951 | CLS Loss: 0.0364457443356514\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 4.3032050132751465 | KNN Loss: 4.241669178009033 | CLS Loss: 0.06153560057282448\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 4.274662971496582 | KNN Loss: 4.219981670379639 | CLS Loss: 0.05468123033642769\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 4.23516845703125 | KNN Loss: 4.193406581878662 | CLS Loss: 0.041762031614780426\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 4.327524185180664 | KNN Loss: 4.242616653442383 | CLS Loss: 0.08490768074989319\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 4.271228790283203 | KNN Loss: 4.212742805480957 | CLS Loss: 0.05848578363656998\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 4.287466049194336 | KNN Loss: 4.215232849121094 | CLS Loss: 0.0722331777215004\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 4.268727779388428 | KNN Loss: 4.200064182281494 | CLS Loss: 0.06866345554590225\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 4.265634059906006 | KNN Loss: 4.186956405639648 | CLS Loss: 0.07867784053087234\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 4.282611846923828 | KNN Loss: 4.244265556335449 | CLS Loss: 0.038346465677022934\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 4.2977399826049805 | KNN Loss: 4.2529425621032715 | CLS Loss: 0.04479734227061272\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 4.253211498260498 | KNN Loss: 4.202448844909668 | CLS Loss: 0.05076254531741142\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 4.318792343139648 | KNN Loss: 4.229543685913086 | CLS Loss: 0.08924844115972519\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 4.241602420806885 | KNN Loss: 4.186033725738525 | CLS Loss: 0.05556854233145714\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 4.263670921325684 | KNN Loss: 4.214260578155518 | CLS Loss: 0.04941055551171303\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 4.254408836364746 | KNN Loss: 4.219934463500977 | CLS Loss: 0.03447447344660759\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 4.272351264953613 | KNN Loss: 4.211286544799805 | CLS Loss: 0.06106463074684143\n",
      "Epoch: 015, Loss: 4.2763, Train: 0.9873, Valid: 0.9828, Best: 0.9828\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 4.2825212478637695 | KNN Loss: 4.264659881591797 | CLS Loss: 0.017861586064100266\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 4.283971786499023 | KNN Loss: 4.232239723205566 | CLS Loss: 0.05173223465681076\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 4.278346061706543 | KNN Loss: 4.243297100067139 | CLS Loss: 0.0350491926074028\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 4.313230514526367 | KNN Loss: 4.246068000793457 | CLS Loss: 0.0671624019742012\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 4.25537633895874 | KNN Loss: 4.222850799560547 | CLS Loss: 0.03252536803483963\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 4.285006999969482 | KNN Loss: 4.225320339202881 | CLS Loss: 0.059686750173568726\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 4.2829909324646 | KNN Loss: 4.2215166091918945 | CLS Loss: 0.061474502086639404\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 4.226901531219482 | KNN Loss: 4.18865442276001 | CLS Loss: 0.03824695944786072\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 4.245882987976074 | KNN Loss: 4.193605899810791 | CLS Loss: 0.05227703973650932\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 4.2918267250061035 | KNN Loss: 4.234570026397705 | CLS Loss: 0.057256463915109634\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 4.2873077392578125 | KNN Loss: 4.248394966125488 | CLS Loss: 0.03891276940703392\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 4.2992048263549805 | KNN Loss: 4.206996917724609 | CLS Loss: 0.09220804274082184\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 4.281314849853516 | KNN Loss: 4.208917617797852 | CLS Loss: 0.07239722460508347\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 4.345771312713623 | KNN Loss: 4.266372203826904 | CLS Loss: 0.07939890027046204\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 4.27329158782959 | KNN Loss: 4.203043460845947 | CLS Loss: 0.07024834305047989\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 4.297311305999756 | KNN Loss: 4.261656761169434 | CLS Loss: 0.035654641687870026\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 4.266654014587402 | KNN Loss: 4.20258092880249 | CLS Loss: 0.0640728622674942\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 4.297793388366699 | KNN Loss: 4.242414474487305 | CLS Loss: 0.05537901446223259\n",
      "Epoch: 016, Loss: 4.2717, Train: 0.9877, Valid: 0.9827, Best: 0.9828\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 4.320013523101807 | KNN Loss: 4.250495910644531 | CLS Loss: 0.06951764225959778\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 4.253784656524658 | KNN Loss: 4.209648132324219 | CLS Loss: 0.044136691838502884\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 4.254150390625 | KNN Loss: 4.187052249908447 | CLS Loss: 0.06709831207990646\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 4.269178867340088 | KNN Loss: 4.221508979797363 | CLS Loss: 0.04767007380723953\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 4.254748344421387 | KNN Loss: 4.219134330749512 | CLS Loss: 0.03561397269368172\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 4.2364606857299805 | KNN Loss: 4.201522350311279 | CLS Loss: 0.03493813797831535\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 4.21679162979126 | KNN Loss: 4.193119525909424 | CLS Loss: 0.023672213777899742\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 4.2752366065979 | KNN Loss: 4.211948394775391 | CLS Loss: 0.06328806281089783\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 4.258005142211914 | KNN Loss: 4.22141695022583 | CLS Loss: 0.03658803552389145\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 4.2344069480896 | KNN Loss: 4.195039749145508 | CLS Loss: 0.03936712443828583\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 4.267901420593262 | KNN Loss: 4.208272457122803 | CLS Loss: 0.059629201889038086\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 4.244203567504883 | KNN Loss: 4.215091705322266 | CLS Loss: 0.02911205030977726\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 4.28261661529541 | KNN Loss: 4.2293291091918945 | CLS Loss: 0.05328742042183876\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 4.295003414154053 | KNN Loss: 4.226351261138916 | CLS Loss: 0.06865228712558746\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 4.296730995178223 | KNN Loss: 4.237945079803467 | CLS Loss: 0.058786001056432724\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 4.326335906982422 | KNN Loss: 4.240088939666748 | CLS Loss: 0.08624681830406189\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 4.239222049713135 | KNN Loss: 4.2188310623168945 | CLS Loss: 0.02039092406630516\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 4.282956123352051 | KNN Loss: 4.23043966293335 | CLS Loss: 0.052516475319862366\n",
      "Epoch: 017, Loss: 4.2671, Train: 0.9874, Valid: 0.9824, Best: 0.9828\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 4.253523349761963 | KNN Loss: 4.186094284057617 | CLS Loss: 0.06742921471595764\n",
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 4.251976490020752 | KNN Loss: 4.197628021240234 | CLS Loss: 0.054348599165678024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 4.303857803344727 | KNN Loss: 4.226426124572754 | CLS Loss: 0.07743176817893982\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 4.239066123962402 | KNN Loss: 4.17639684677124 | CLS Loss: 0.06266903877258301\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 4.26939058303833 | KNN Loss: 4.226423263549805 | CLS Loss: 0.04296719282865524\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 4.297374725341797 | KNN Loss: 4.213367462158203 | CLS Loss: 0.08400703966617584\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 4.271676540374756 | KNN Loss: 4.241681098937988 | CLS Loss: 0.02999560534954071\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 4.251960754394531 | KNN Loss: 4.231335639953613 | CLS Loss: 0.020625127479434013\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 4.242746353149414 | KNN Loss: 4.223612308502197 | CLS Loss: 0.019134126603603363\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 4.2283406257629395 | KNN Loss: 4.18551778793335 | CLS Loss: 0.042822692543268204\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 4.25616979598999 | KNN Loss: 4.214877128601074 | CLS Loss: 0.04129274562001228\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 4.289101600646973 | KNN Loss: 4.234160423278809 | CLS Loss: 0.05494120344519615\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 4.246072769165039 | KNN Loss: 4.206423759460449 | CLS Loss: 0.03964913636445999\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 4.258713245391846 | KNN Loss: 4.17808723449707 | CLS Loss: 0.0806259736418724\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 4.301905632019043 | KNN Loss: 4.225554466247559 | CLS Loss: 0.0763513371348381\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 4.251494884490967 | KNN Loss: 4.229053497314453 | CLS Loss: 0.022441409528255463\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 4.249829292297363 | KNN Loss: 4.202629089355469 | CLS Loss: 0.047200340777635574\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 4.241430282592773 | KNN Loss: 4.186627388000488 | CLS Loss: 0.05480287969112396\n",
      "Epoch: 018, Loss: 4.2621, Train: 0.9884, Valid: 0.9836, Best: 0.9836\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 4.2216949462890625 | KNN Loss: 4.186976432800293 | CLS Loss: 0.03471831977367401\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 4.240072727203369 | KNN Loss: 4.218364238739014 | CLS Loss: 0.02170846424996853\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 4.250646114349365 | KNN Loss: 4.21525239944458 | CLS Loss: 0.035393670201301575\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 4.2314300537109375 | KNN Loss: 4.195818901062012 | CLS Loss: 0.03561098873615265\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 4.228666305541992 | KNN Loss: 4.211548805236816 | CLS Loss: 0.017117420211434364\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 4.274559497833252 | KNN Loss: 4.217037200927734 | CLS Loss: 0.05752246454358101\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 4.261913776397705 | KNN Loss: 4.237067699432373 | CLS Loss: 0.024845942854881287\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 4.268951416015625 | KNN Loss: 4.205253601074219 | CLS Loss: 0.06369795650243759\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 4.235235691070557 | KNN Loss: 4.212899684906006 | CLS Loss: 0.022335773333907127\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 4.255836486816406 | KNN Loss: 4.202581882476807 | CLS Loss: 0.05325471609830856\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 4.237296104431152 | KNN Loss: 4.204753875732422 | CLS Loss: 0.032542187720537186\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 4.204029083251953 | KNN Loss: 4.184709072113037 | CLS Loss: 0.01931985281407833\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 4.202364921569824 | KNN Loss: 4.17183780670166 | CLS Loss: 0.03052699752151966\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 4.256235599517822 | KNN Loss: 4.208996772766113 | CLS Loss: 0.047238823026418686\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 4.208785533905029 | KNN Loss: 4.188211441040039 | CLS Loss: 0.020574163645505905\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 4.2721266746521 | KNN Loss: 4.197616100311279 | CLS Loss: 0.07451078295707703\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 4.255075931549072 | KNN Loss: 4.206202030181885 | CLS Loss: 0.048873864114284515\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 4.2827935218811035 | KNN Loss: 4.227510452270508 | CLS Loss: 0.055283088237047195\n",
      "Epoch: 019, Loss: 4.2543, Train: 0.9852, Valid: 0.9815, Best: 0.9836\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 4.331035137176514 | KNN Loss: 4.228299140930176 | CLS Loss: 0.10273600369691849\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 4.299703121185303 | KNN Loss: 4.222803592681885 | CLS Loss: 0.07689972221851349\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 4.228664875030518 | KNN Loss: 4.1815338134765625 | CLS Loss: 0.04713103920221329\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 4.299994945526123 | KNN Loss: 4.230976581573486 | CLS Loss: 0.06901843100786209\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 4.247851848602295 | KNN Loss: 4.215337753295898 | CLS Loss: 0.03251388669013977\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 4.274163246154785 | KNN Loss: 4.225634574890137 | CLS Loss: 0.048528652638196945\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 4.227720260620117 | KNN Loss: 4.194893836975098 | CLS Loss: 0.03282633796334267\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 4.2942938804626465 | KNN Loss: 4.23776388168335 | CLS Loss: 0.05652986466884613\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 4.214879035949707 | KNN Loss: 4.176788806915283 | CLS Loss: 0.03809018433094025\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 4.2670512199401855 | KNN Loss: 4.224826335906982 | CLS Loss: 0.04222501069307327\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 4.303231716156006 | KNN Loss: 4.216519832611084 | CLS Loss: 0.08671176433563232\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 4.258169651031494 | KNN Loss: 4.225979328155518 | CLS Loss: 0.0321902297437191\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 4.222823619842529 | KNN Loss: 4.197859287261963 | CLS Loss: 0.024964408949017525\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 4.2616143226623535 | KNN Loss: 4.226276874542236 | CLS Loss: 0.0353374145925045\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 4.284913539886475 | KNN Loss: 4.266122817993164 | CLS Loss: 0.01879083178937435\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 4.253394603729248 | KNN Loss: 4.221404075622559 | CLS Loss: 0.031990423798561096\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 4.2703986167907715 | KNN Loss: 4.215547561645508 | CLS Loss: 0.05485110357403755\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 4.225647926330566 | KNN Loss: 4.190401554107666 | CLS Loss: 0.035246215760707855\n",
      "Epoch: 020, Loss: 4.2597, Train: 0.9888, Valid: 0.9838, Best: 0.9838\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 4.258875846862793 | KNN Loss: 4.218377590179443 | CLS Loss: 0.04049842432141304\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 4.262322902679443 | KNN Loss: 4.198833465576172 | CLS Loss: 0.06348955631256104\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 4.234791278839111 | KNN Loss: 4.19998836517334 | CLS Loss: 0.03480271250009537\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 4.27598237991333 | KNN Loss: 4.205866813659668 | CLS Loss: 0.07011555880308151\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 4.229947566986084 | KNN Loss: 4.201915740966797 | CLS Loss: 0.028031708672642708\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 4.295852184295654 | KNN Loss: 4.23016357421875 | CLS Loss: 0.06568857282400131\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 4.286153316497803 | KNN Loss: 4.228769302368164 | CLS Loss: 0.057383980602025986\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 4.198602676391602 | KNN Loss: 4.1682257652282715 | CLS Loss: 0.030376777052879333\n",
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 4.276921272277832 | KNN Loss: 4.23076868057251 | CLS Loss: 0.046152569353580475\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 4.272282123565674 | KNN Loss: 4.221740245819092 | CLS Loss: 0.050541773438453674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 4.259561538696289 | KNN Loss: 4.207320690155029 | CLS Loss: 0.052240628749132156\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 4.250393390655518 | KNN Loss: 4.197073936462402 | CLS Loss: 0.053319595754146576\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 4.259017467498779 | KNN Loss: 4.217649936676025 | CLS Loss: 0.041367728263139725\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 4.250395774841309 | KNN Loss: 4.1975555419921875 | CLS Loss: 0.05284019187092781\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 4.186774730682373 | KNN Loss: 4.170956611633301 | CLS Loss: 0.015817929059267044\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 4.233867168426514 | KNN Loss: 4.186148166656494 | CLS Loss: 0.04771913215517998\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 4.241882801055908 | KNN Loss: 4.191761493682861 | CLS Loss: 0.0501212440431118\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 4.277629852294922 | KNN Loss: 4.232100963592529 | CLS Loss: 0.04552900418639183\n",
      "Epoch: 021, Loss: 4.2489, Train: 0.9902, Valid: 0.9848, Best: 0.9848\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 4.250068664550781 | KNN Loss: 4.172281265258789 | CLS Loss: 0.07778757065534592\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 4.251753807067871 | KNN Loss: 4.228021144866943 | CLS Loss: 0.023732725530862808\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 4.295654773712158 | KNN Loss: 4.238722324371338 | CLS Loss: 0.05693242698907852\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 4.2510666847229 | KNN Loss: 4.220368385314941 | CLS Loss: 0.030698120594024658\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 4.297425270080566 | KNN Loss: 4.234644889831543 | CLS Loss: 0.06278055161237717\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 4.270768165588379 | KNN Loss: 4.228744983673096 | CLS Loss: 0.0420231819152832\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 4.227379322052002 | KNN Loss: 4.203805446624756 | CLS Loss: 0.02357405237853527\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 4.242979049682617 | KNN Loss: 4.209258079528809 | CLS Loss: 0.03372117877006531\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 4.225507736206055 | KNN Loss: 4.172271251678467 | CLS Loss: 0.05323630943894386\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 4.217650413513184 | KNN Loss: 4.194058418273926 | CLS Loss: 0.023591989651322365\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 4.250540733337402 | KNN Loss: 4.221598148345947 | CLS Loss: 0.028942503035068512\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 4.2555928230285645 | KNN Loss: 4.218032360076904 | CLS Loss: 0.03756045550107956\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 4.254837989807129 | KNN Loss: 4.201726913452148 | CLS Loss: 0.05311104655265808\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 4.263791561126709 | KNN Loss: 4.226749420166016 | CLS Loss: 0.03704197332262993\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 4.258815765380859 | KNN Loss: 4.204404830932617 | CLS Loss: 0.054411083459854126\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 4.235722064971924 | KNN Loss: 4.189619064331055 | CLS Loss: 0.04610290750861168\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 4.21738862991333 | KNN Loss: 4.186598300933838 | CLS Loss: 0.030790284276008606\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 4.264017105102539 | KNN Loss: 4.218303680419922 | CLS Loss: 0.045713189989328384\n",
      "Epoch: 022, Loss: 4.2480, Train: 0.9898, Valid: 0.9838, Best: 0.9848\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 4.21018648147583 | KNN Loss: 4.187124729156494 | CLS Loss: 0.023061661049723625\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 4.227526664733887 | KNN Loss: 4.199708461761475 | CLS Loss: 0.02781800366938114\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 4.262063503265381 | KNN Loss: 4.222349166870117 | CLS Loss: 0.03971412405371666\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 4.249453067779541 | KNN Loss: 4.230800151824951 | CLS Loss: 0.0186529029160738\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 4.240106105804443 | KNN Loss: 4.208496570587158 | CLS Loss: 0.03160938248038292\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 4.275143623352051 | KNN Loss: 4.218674182891846 | CLS Loss: 0.05646935850381851\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 4.2287797927856445 | KNN Loss: 4.185035705566406 | CLS Loss: 0.04374408721923828\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 4.285009860992432 | KNN Loss: 4.24881649017334 | CLS Loss: 0.03619343042373657\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 4.254176616668701 | KNN Loss: 4.205610275268555 | CLS Loss: 0.048566509038209915\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 4.271644115447998 | KNN Loss: 4.237758636474609 | CLS Loss: 0.03388566896319389\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 4.282222747802734 | KNN Loss: 4.237936019897461 | CLS Loss: 0.04428655281662941\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 4.202406883239746 | KNN Loss: 4.165465354919434 | CLS Loss: 0.03694162145256996\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 4.253562927246094 | KNN Loss: 4.226682186126709 | CLS Loss: 0.026880957186222076\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 4.236137390136719 | KNN Loss: 4.174229621887207 | CLS Loss: 0.061907701194286346\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 4.221398830413818 | KNN Loss: 4.211559295654297 | CLS Loss: 0.009839688427746296\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 4.243689060211182 | KNN Loss: 4.203072547912598 | CLS Loss: 0.04061643406748772\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 4.255873680114746 | KNN Loss: 4.216855525970459 | CLS Loss: 0.03901800513267517\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 4.25380277633667 | KNN Loss: 4.218988418579102 | CLS Loss: 0.03481438383460045\n",
      "Epoch: 023, Loss: 4.2496, Train: 0.9883, Valid: 0.9823, Best: 0.9848\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 4.261878490447998 | KNN Loss: 4.20166015625 | CLS Loss: 0.06021825224161148\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 4.226091384887695 | KNN Loss: 4.209625244140625 | CLS Loss: 0.016466308385133743\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 4.19814920425415 | KNN Loss: 4.176408767700195 | CLS Loss: 0.021740257740020752\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 4.226062297821045 | KNN Loss: 4.193108558654785 | CLS Loss: 0.032953597605228424\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 4.232868671417236 | KNN Loss: 4.207519054412842 | CLS Loss: 0.02534961700439453\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 4.2333903312683105 | KNN Loss: 4.195723533630371 | CLS Loss: 0.03766687586903572\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 4.261663913726807 | KNN Loss: 4.198727607727051 | CLS Loss: 0.06293641775846481\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 4.24940824508667 | KNN Loss: 4.197469711303711 | CLS Loss: 0.05193866044282913\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 4.222164630889893 | KNN Loss: 4.196344375610352 | CLS Loss: 0.025820111855864525\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 4.211374282836914 | KNN Loss: 4.178181171417236 | CLS Loss: 0.0331929549574852\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 4.251784324645996 | KNN Loss: 4.225840091705322 | CLS Loss: 0.025944184511899948\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 4.237175941467285 | KNN Loss: 4.204505443572998 | CLS Loss: 0.03267037868499756\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 4.322859764099121 | KNN Loss: 4.223090648651123 | CLS Loss: 0.09976919740438461\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 4.234837532043457 | KNN Loss: 4.20140266418457 | CLS Loss: 0.033434778451919556\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 4.301214694976807 | KNN Loss: 4.250209808349609 | CLS Loss: 0.05100508779287338\n",
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 4.206593990325928 | KNN Loss: 4.178808689117432 | CLS Loss: 0.027785420417785645\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 4.2397003173828125 | KNN Loss: 4.182971477508545 | CLS Loss: 0.05672898516058922\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 4.238361835479736 | KNN Loss: 4.189783096313477 | CLS Loss: 0.04857875034213066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss: 4.2390, Train: 0.9909, Valid: 0.9854, Best: 0.9854\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 4.265495300292969 | KNN Loss: 4.238539218902588 | CLS Loss: 0.02695620246231556\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 4.219695091247559 | KNN Loss: 4.180814743041992 | CLS Loss: 0.03888051211833954\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 4.232290744781494 | KNN Loss: 4.200233459472656 | CLS Loss: 0.032057516276836395\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 4.259670734405518 | KNN Loss: 4.225083827972412 | CLS Loss: 0.034587111324071884\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 4.251523017883301 | KNN Loss: 4.226673126220703 | CLS Loss: 0.024849819019436836\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 4.218588352203369 | KNN Loss: 4.196338653564453 | CLS Loss: 0.022249750792980194\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 4.233736515045166 | KNN Loss: 4.207286834716797 | CLS Loss: 0.02644953317940235\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 4.2492265701293945 | KNN Loss: 4.217988014221191 | CLS Loss: 0.031238414347171783\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 4.266417503356934 | KNN Loss: 4.207190036773682 | CLS Loss: 0.05922743305563927\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 4.252819538116455 | KNN Loss: 4.2074761390686035 | CLS Loss: 0.045343272387981415\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 4.21483850479126 | KNN Loss: 4.184965133666992 | CLS Loss: 0.029873229563236237\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 4.2692461013793945 | KNN Loss: 4.223791599273682 | CLS Loss: 0.0454547293484211\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 4.223237037658691 | KNN Loss: 4.186558246612549 | CLS Loss: 0.0366789884865284\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 4.2616376876831055 | KNN Loss: 4.213806629180908 | CLS Loss: 0.04783129692077637\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 4.263386249542236 | KNN Loss: 4.217089653015137 | CLS Loss: 0.04629642516374588\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 4.232057094573975 | KNN Loss: 4.19171667098999 | CLS Loss: 0.04034026339650154\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 4.266920566558838 | KNN Loss: 4.21495246887207 | CLS Loss: 0.05196818336844444\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 4.285027980804443 | KNN Loss: 4.22920560836792 | CLS Loss: 0.05582231655716896\n",
      "Epoch: 025, Loss: 4.2384, Train: 0.9899, Valid: 0.9848, Best: 0.9854\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 4.251325607299805 | KNN Loss: 4.204461574554443 | CLS Loss: 0.04686414822936058\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 4.219026565551758 | KNN Loss: 4.187685012817383 | CLS Loss: 0.03134150058031082\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 4.203920841217041 | KNN Loss: 4.187310695648193 | CLS Loss: 0.016610300168395042\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 4.214272975921631 | KNN Loss: 4.1866021156311035 | CLS Loss: 0.02767099253833294\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 4.208147048950195 | KNN Loss: 4.183663368225098 | CLS Loss: 0.024483608081936836\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 4.2142767906188965 | KNN Loss: 4.194276809692383 | CLS Loss: 0.01999981701374054\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 4.243304252624512 | KNN Loss: 4.212854862213135 | CLS Loss: 0.03044934757053852\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 4.274799346923828 | KNN Loss: 4.232661724090576 | CLS Loss: 0.04213773086667061\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 4.222052097320557 | KNN Loss: 4.1769843101501465 | CLS Loss: 0.045067645609378815\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 4.28305196762085 | KNN Loss: 4.186529159545898 | CLS Loss: 0.09652283787727356\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 4.213113307952881 | KNN Loss: 4.1822309494018555 | CLS Loss: 0.030882524326443672\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 4.227965831756592 | KNN Loss: 4.2000250816345215 | CLS Loss: 0.027940982952713966\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 4.212033748626709 | KNN Loss: 4.195338249206543 | CLS Loss: 0.016695568338036537\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 4.266389846801758 | KNN Loss: 4.225860118865967 | CLS Loss: 0.040529754012823105\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 4.241871356964111 | KNN Loss: 4.188888072967529 | CLS Loss: 0.052983514964580536\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 4.265113830566406 | KNN Loss: 4.238674640655518 | CLS Loss: 0.026439422741532326\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 4.184279441833496 | KNN Loss: 4.166487693786621 | CLS Loss: 0.01779153198003769\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 4.187841415405273 | KNN Loss: 4.150993824005127 | CLS Loss: 0.03684772551059723\n",
      "Epoch: 026, Loss: 4.2361, Train: 0.9908, Valid: 0.9856, Best: 0.9856\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 4.252105236053467 | KNN Loss: 4.1844072341918945 | CLS Loss: 0.06769822537899017\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 4.218749046325684 | KNN Loss: 4.187963008880615 | CLS Loss: 0.03078615479171276\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 4.2674384117126465 | KNN Loss: 4.216571807861328 | CLS Loss: 0.05086648836731911\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 4.2241129875183105 | KNN Loss: 4.196303844451904 | CLS Loss: 0.02780933678150177\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 4.211053371429443 | KNN Loss: 4.192888259887695 | CLS Loss: 0.018165215849876404\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 4.270581245422363 | KNN Loss: 4.240804672241211 | CLS Loss: 0.02977670170366764\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 4.278476715087891 | KNN Loss: 4.217138290405273 | CLS Loss: 0.06133823096752167\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 4.188866138458252 | KNN Loss: 4.1725993156433105 | CLS Loss: 0.016266772523522377\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 4.194770812988281 | KNN Loss: 4.162871360778809 | CLS Loss: 0.031899333000183105\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 4.214621067047119 | KNN Loss: 4.199199676513672 | CLS Loss: 0.015421519987285137\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 4.209836959838867 | KNN Loss: 4.187599182128906 | CLS Loss: 0.022237805649638176\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 4.219498157501221 | KNN Loss: 4.195162773132324 | CLS Loss: 0.024335553869605064\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 4.229556083679199 | KNN Loss: 4.197524547576904 | CLS Loss: 0.03203153237700462\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 4.280827522277832 | KNN Loss: 4.22462272644043 | CLS Loss: 0.056204844266176224\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 4.252660274505615 | KNN Loss: 4.20957088470459 | CLS Loss: 0.04308925196528435\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 4.26121711730957 | KNN Loss: 4.188325881958008 | CLS Loss: 0.07289137691259384\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 4.235755920410156 | KNN Loss: 4.203683853149414 | CLS Loss: 0.03207230567932129\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 4.250436782836914 | KNN Loss: 4.203000545501709 | CLS Loss: 0.047436103224754333\n",
      "Epoch: 027, Loss: 4.2338, Train: 0.9892, Valid: 0.9824, Best: 0.9856\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 4.299891948699951 | KNN Loss: 4.2343010902404785 | CLS Loss: 0.0655910074710846\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 4.220666885375977 | KNN Loss: 4.193973064422607 | CLS Loss: 0.026693765074014664\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 4.181515693664551 | KNN Loss: 4.15965461730957 | CLS Loss: 0.021861158311367035\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 4.219599723815918 | KNN Loss: 4.180010795593262 | CLS Loss: 0.039588913321495056\n",
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 4.248940944671631 | KNN Loss: 4.199404239654541 | CLS Loss: 0.04953671246767044\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 4.197627544403076 | KNN Loss: 4.159452438354492 | CLS Loss: 0.03817509859800339\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 4.224468231201172 | KNN Loss: 4.193991661071777 | CLS Loss: 0.03047649934887886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 4.275606155395508 | KNN Loss: 4.237156867980957 | CLS Loss: 0.03844938054680824\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 4.209798812866211 | KNN Loss: 4.193807601928711 | CLS Loss: 0.015991419553756714\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 4.20304536819458 | KNN Loss: 4.172657012939453 | CLS Loss: 0.03038826398551464\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 4.267799377441406 | KNN Loss: 4.218329906463623 | CLS Loss: 0.04946959391236305\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 4.239386558532715 | KNN Loss: 4.214444160461426 | CLS Loss: 0.024942200630903244\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 4.184256076812744 | KNN Loss: 4.156450271606445 | CLS Loss: 0.027805667370557785\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 4.254861831665039 | KNN Loss: 4.222545623779297 | CLS Loss: 0.032315973192453384\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 4.228485107421875 | KNN Loss: 4.176639556884766 | CLS Loss: 0.051845770329236984\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 4.1940155029296875 | KNN Loss: 4.1713786125183105 | CLS Loss: 0.02263689786195755\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 4.197505950927734 | KNN Loss: 4.173363208770752 | CLS Loss: 0.02414284646511078\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 4.221912860870361 | KNN Loss: 4.185169219970703 | CLS Loss: 0.03674344718456268\n",
      "Epoch: 028, Loss: 4.2295, Train: 0.9905, Valid: 0.9853, Best: 0.9856\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 4.231966972351074 | KNN Loss: 4.200469970703125 | CLS Loss: 0.0314970463514328\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 4.245031356811523 | KNN Loss: 4.211313247680664 | CLS Loss: 0.03371809422969818\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 4.1899542808532715 | KNN Loss: 4.166292190551758 | CLS Loss: 0.023662099614739418\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 4.2078680992126465 | KNN Loss: 4.192835330963135 | CLS Loss: 0.015032750554382801\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 4.2479166984558105 | KNN Loss: 4.2279157638549805 | CLS Loss: 0.02000095322728157\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 4.210402965545654 | KNN Loss: 4.185183525085449 | CLS Loss: 0.025219406932592392\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 4.215366840362549 | KNN Loss: 4.1795525550842285 | CLS Loss: 0.035814255475997925\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 4.235289096832275 | KNN Loss: 4.192209243774414 | CLS Loss: 0.04307985678315163\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 4.214179039001465 | KNN Loss: 4.195398807525635 | CLS Loss: 0.018780166283249855\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 4.199059009552002 | KNN Loss: 4.188188552856445 | CLS Loss: 0.010870624333620071\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 4.228123664855957 | KNN Loss: 4.187553882598877 | CLS Loss: 0.04056982323527336\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 4.289095401763916 | KNN Loss: 4.228348731994629 | CLS Loss: 0.060746461153030396\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 4.251412391662598 | KNN Loss: 4.206307411193848 | CLS Loss: 0.04510478675365448\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 4.230990886688232 | KNN Loss: 4.1882100105285645 | CLS Loss: 0.04278098791837692\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 4.231603622436523 | KNN Loss: 4.205193042755127 | CLS Loss: 0.02641049399971962\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 4.189242362976074 | KNN Loss: 4.168245792388916 | CLS Loss: 0.02099660225212574\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 4.295879364013672 | KNN Loss: 4.239243507385254 | CLS Loss: 0.056636057794094086\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 4.223880290985107 | KNN Loss: 4.206209659576416 | CLS Loss: 0.017670566216111183\n",
      "Epoch: 029, Loss: 4.2293, Train: 0.9911, Valid: 0.9837, Best: 0.9856\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 4.2311787605285645 | KNN Loss: 4.19776725769043 | CLS Loss: 0.03341158106923103\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 4.241630554199219 | KNN Loss: 4.2019476890563965 | CLS Loss: 0.03968281298875809\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 4.223554611206055 | KNN Loss: 4.183115005493164 | CLS Loss: 0.04043978080153465\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 4.188487529754639 | KNN Loss: 4.16664981842041 | CLS Loss: 0.021837588399648666\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 4.216121673583984 | KNN Loss: 4.195652008056641 | CLS Loss: 0.020469719544053078\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 4.253000259399414 | KNN Loss: 4.226670265197754 | CLS Loss: 0.0263301320374012\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 4.254159450531006 | KNN Loss: 4.197479724884033 | CLS Loss: 0.05667978897690773\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 4.211840629577637 | KNN Loss: 4.190933704376221 | CLS Loss: 0.02090677246451378\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 4.221433162689209 | KNN Loss: 4.192389011383057 | CLS Loss: 0.029044127091765404\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 4.20969820022583 | KNN Loss: 4.173086643218994 | CLS Loss: 0.036611367017030716\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 4.187717437744141 | KNN Loss: 4.154101848602295 | CLS Loss: 0.03361565247178078\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 4.223985195159912 | KNN Loss: 4.183226108551025 | CLS Loss: 0.0407588817179203\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 4.221014022827148 | KNN Loss: 4.191911220550537 | CLS Loss: 0.029102878645062447\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 4.2132248878479 | KNN Loss: 4.175264358520508 | CLS Loss: 0.03796031326055527\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 4.219824314117432 | KNN Loss: 4.197226047515869 | CLS Loss: 0.02259814366698265\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 4.2231221199035645 | KNN Loss: 4.180332183837891 | CLS Loss: 0.042790088802576065\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 4.221446990966797 | KNN Loss: 4.187013626098633 | CLS Loss: 0.0344332791864872\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 4.237885475158691 | KNN Loss: 4.205171585083008 | CLS Loss: 0.032713767141103745\n",
      "Epoch: 030, Loss: 4.2253, Train: 0.9921, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 4.201195240020752 | KNN Loss: 4.180237293243408 | CLS Loss: 0.020957790315151215\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 4.228719711303711 | KNN Loss: 4.18105411529541 | CLS Loss: 0.04766570404171944\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 4.1911702156066895 | KNN Loss: 4.155381202697754 | CLS Loss: 0.0357888862490654\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 4.157013893127441 | KNN Loss: 4.144191265106201 | CLS Loss: 0.012822522781789303\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 4.2550554275512695 | KNN Loss: 4.193337440490723 | CLS Loss: 0.06171804293990135\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 4.211691379547119 | KNN Loss: 4.191201686859131 | CLS Loss: 0.02048986405134201\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 4.194186687469482 | KNN Loss: 4.171597957611084 | CLS Loss: 0.0225885808467865\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 4.238214015960693 | KNN Loss: 4.219130039215088 | CLS Loss: 0.019083797931671143\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 4.2365336418151855 | KNN Loss: 4.199977874755859 | CLS Loss: 0.036555662751197815\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 4.199844837188721 | KNN Loss: 4.160585403442383 | CLS Loss: 0.03925960510969162\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 4.184700965881348 | KNN Loss: 4.159362316131592 | CLS Loss: 0.025338608771562576\n",
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 4.191658020019531 | KNN Loss: 4.170419692993164 | CLS Loss: 0.021238243207335472\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 4.193929672241211 | KNN Loss: 4.1748175621032715 | CLS Loss: 0.01911216601729393\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 4.240921974182129 | KNN Loss: 4.205450057983398 | CLS Loss: 0.03547174856066704\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 4.221508979797363 | KNN Loss: 4.183967113494873 | CLS Loss: 0.03754206746816635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 4.229220390319824 | KNN Loss: 4.211800575256348 | CLS Loss: 0.017419731244444847\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 4.192266464233398 | KNN Loss: 4.172729969024658 | CLS Loss: 0.0195364598184824\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 4.243007659912109 | KNN Loss: 4.205879211425781 | CLS Loss: 0.03712835535407066\n",
      "Epoch: 031, Loss: 4.2213, Train: 0.9923, Valid: 0.9853, Best: 0.9860\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 4.189051151275635 | KNN Loss: 4.1735639572143555 | CLS Loss: 0.015487393364310265\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 4.225273609161377 | KNN Loss: 4.191262722015381 | CLS Loss: 0.034010663628578186\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 4.220917701721191 | KNN Loss: 4.197173118591309 | CLS Loss: 0.02374441921710968\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 4.222548961639404 | KNN Loss: 4.196850299835205 | CLS Loss: 0.025698574259877205\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 4.264047145843506 | KNN Loss: 4.20931339263916 | CLS Loss: 0.05473380908370018\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 4.224193096160889 | KNN Loss: 4.185343265533447 | CLS Loss: 0.03884997218847275\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 4.217889785766602 | KNN Loss: 4.203401565551758 | CLS Loss: 0.014488354325294495\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 4.23001766204834 | KNN Loss: 4.197346210479736 | CLS Loss: 0.032671283930540085\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 4.187466144561768 | KNN Loss: 4.154268264770508 | CLS Loss: 0.03319775313138962\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 4.239106178283691 | KNN Loss: 4.208245277404785 | CLS Loss: 0.030860712751746178\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 4.2309746742248535 | KNN Loss: 4.196812152862549 | CLS Loss: 0.03416264057159424\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 4.247771263122559 | KNN Loss: 4.194882392883301 | CLS Loss: 0.052889108657836914\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 4.2014923095703125 | KNN Loss: 4.180399417877197 | CLS Loss: 0.021093063056468964\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 4.193838596343994 | KNN Loss: 4.174745559692383 | CLS Loss: 0.01909303292632103\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 4.2379302978515625 | KNN Loss: 4.213953018188477 | CLS Loss: 0.023977456614375114\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 4.243497848510742 | KNN Loss: 4.20642614364624 | CLS Loss: 0.037071604281663895\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 4.243021011352539 | KNN Loss: 4.202747344970703 | CLS Loss: 0.040273670107126236\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 4.247272968292236 | KNN Loss: 4.210111618041992 | CLS Loss: 0.037161462008953094\n",
      "Epoch: 032, Loss: 4.2198, Train: 0.9927, Valid: 0.9857, Best: 0.9860\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 4.229454040527344 | KNN Loss: 4.21084451675415 | CLS Loss: 0.018609317019581795\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 4.19378662109375 | KNN Loss: 4.157492637634277 | CLS Loss: 0.036294158548116684\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 4.2098541259765625 | KNN Loss: 4.1424055099487305 | CLS Loss: 0.06744883954524994\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 4.191234111785889 | KNN Loss: 4.170675754547119 | CLS Loss: 0.02055823989212513\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 4.194606781005859 | KNN Loss: 4.172504425048828 | CLS Loss: 0.022102488204836845\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 4.241878032684326 | KNN Loss: 4.2063164710998535 | CLS Loss: 0.03556135669350624\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 4.216800212860107 | KNN Loss: 4.205779552459717 | CLS Loss: 0.011020760983228683\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 4.18856143951416 | KNN Loss: 4.167444229125977 | CLS Loss: 0.02111707255244255\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 4.247620105743408 | KNN Loss: 4.205637454986572 | CLS Loss: 0.04198277369141579\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 4.2203850746154785 | KNN Loss: 4.19083309173584 | CLS Loss: 0.02955193631350994\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 4.197385787963867 | KNN Loss: 4.175185680389404 | CLS Loss: 0.022200146690011024\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 4.21903657913208 | KNN Loss: 4.176628112792969 | CLS Loss: 0.04240827262401581\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 4.203173637390137 | KNN Loss: 4.192592144012451 | CLS Loss: 0.010581478476524353\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 4.17281436920166 | KNN Loss: 4.14930534362793 | CLS Loss: 0.023509208112955093\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 4.259448528289795 | KNN Loss: 4.2124762535095215 | CLS Loss: 0.04697246104478836\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 4.222159385681152 | KNN Loss: 4.197532653808594 | CLS Loss: 0.024626560509204865\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 4.24234676361084 | KNN Loss: 4.209096431732178 | CLS Loss: 0.03325015679001808\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 4.217576026916504 | KNN Loss: 4.1899638175964355 | CLS Loss: 0.02761233225464821\n",
      "Epoch: 033, Loss: 4.2162, Train: 0.9925, Valid: 0.9858, Best: 0.9860\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 4.195364952087402 | KNN Loss: 4.18083381652832 | CLS Loss: 0.014531024731695652\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 4.217348098754883 | KNN Loss: 4.1971893310546875 | CLS Loss: 0.02015857584774494\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 4.207679271697998 | KNN Loss: 4.187971115112305 | CLS Loss: 0.019708093255758286\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 4.206719398498535 | KNN Loss: 4.181100845336914 | CLS Loss: 0.02561875618994236\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 4.209280490875244 | KNN Loss: 4.188432693481445 | CLS Loss: 0.020847881212830544\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 4.235565662384033 | KNN Loss: 4.196556568145752 | CLS Loss: 0.039009299129247665\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 4.179759502410889 | KNN Loss: 4.150469779968262 | CLS Loss: 0.029289796948432922\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 4.218094348907471 | KNN Loss: 4.194674491882324 | CLS Loss: 0.023419644683599472\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 4.21740198135376 | KNN Loss: 4.189485549926758 | CLS Loss: 0.027916651219129562\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 4.250144004821777 | KNN Loss: 4.211368083953857 | CLS Loss: 0.038776006549596786\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 4.231729507446289 | KNN Loss: 4.188359260559082 | CLS Loss: 0.043370235711336136\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 4.200868606567383 | KNN Loss: 4.1904168128967285 | CLS Loss: 0.01045198179781437\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 4.222850799560547 | KNN Loss: 4.199549198150635 | CLS Loss: 0.023301400244235992\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 4.206369876861572 | KNN Loss: 4.184521198272705 | CLS Loss: 0.02184879407286644\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 4.229311943054199 | KNN Loss: 4.197768688201904 | CLS Loss: 0.03154311701655388\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 4.253121852874756 | KNN Loss: 4.222902297973633 | CLS Loss: 0.03021973930299282\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 4.168692111968994 | KNN Loss: 4.151196002960205 | CLS Loss: 0.017496122047305107\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 4.216568470001221 | KNN Loss: 4.194651126861572 | CLS Loss: 0.021917186677455902\n",
      "Epoch: 034, Loss: 4.2166, Train: 0.9927, Valid: 0.9849, Best: 0.9860\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 4.20521879196167 | KNN Loss: 4.180727958679199 | CLS Loss: 0.024490930140018463\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 4.269962310791016 | KNN Loss: 4.225386619567871 | CLS Loss: 0.044575922191143036\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 4.238717555999756 | KNN Loss: 4.218960285186768 | CLS Loss: 0.01975722424685955\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 4.194509983062744 | KNN Loss: 4.1771769523620605 | CLS Loss: 0.017333023250102997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 4.229077339172363 | KNN Loss: 4.195725917816162 | CLS Loss: 0.03335139527916908\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 4.223647594451904 | KNN Loss: 4.196990966796875 | CLS Loss: 0.02665676362812519\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 4.197102069854736 | KNN Loss: 4.175550937652588 | CLS Loss: 0.02155124582350254\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 4.214033126831055 | KNN Loss: 4.189996242523193 | CLS Loss: 0.024036716669797897\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 4.235169887542725 | KNN Loss: 4.202627182006836 | CLS Loss: 0.032542772591114044\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 4.245207786560059 | KNN Loss: 4.1876983642578125 | CLS Loss: 0.05750952288508415\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 4.187944412231445 | KNN Loss: 4.153622150421143 | CLS Loss: 0.0343221016228199\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 4.234807014465332 | KNN Loss: 4.186310291290283 | CLS Loss: 0.04849689453840256\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 4.22358512878418 | KNN Loss: 4.196140289306641 | CLS Loss: 0.027445049956440926\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 4.194206237792969 | KNN Loss: 4.162620544433594 | CLS Loss: 0.03158555179834366\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 4.2270121574401855 | KNN Loss: 4.199886322021484 | CLS Loss: 0.027126045897603035\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 4.2582926750183105 | KNN Loss: 4.245429992675781 | CLS Loss: 0.012862741947174072\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 4.218529224395752 | KNN Loss: 4.186933994293213 | CLS Loss: 0.03159504756331444\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 4.223231315612793 | KNN Loss: 4.202216625213623 | CLS Loss: 0.021014796569943428\n",
      "Epoch: 035, Loss: 4.2181, Train: 0.9929, Valid: 0.9858, Best: 0.9860\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 4.24452543258667 | KNN Loss: 4.196224212646484 | CLS Loss: 0.048301223665475845\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 4.192006587982178 | KNN Loss: 4.186628818511963 | CLS Loss: 0.005377673078328371\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 4.230497360229492 | KNN Loss: 4.188449382781982 | CLS Loss: 0.04204821586608887\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 4.221479892730713 | KNN Loss: 4.202937126159668 | CLS Loss: 0.018542751669883728\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 4.191051959991455 | KNN Loss: 4.184905052185059 | CLS Loss: 0.006147068925201893\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 4.245951175689697 | KNN Loss: 4.214476585388184 | CLS Loss: 0.03147459030151367\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 4.22965145111084 | KNN Loss: 4.205459117889404 | CLS Loss: 0.024192186072468758\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 4.182241439819336 | KNN Loss: 4.166006565093994 | CLS Loss: 0.0162349846214056\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 4.212545871734619 | KNN Loss: 4.196372985839844 | CLS Loss: 0.01617291010916233\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 4.1815314292907715 | KNN Loss: 4.1693949699401855 | CLS Loss: 0.01213656086474657\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 4.188266754150391 | KNN Loss: 4.17077112197876 | CLS Loss: 0.01749582588672638\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 4.237633228302002 | KNN Loss: 4.203495979309082 | CLS Loss: 0.034137338399887085\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 4.200331687927246 | KNN Loss: 4.1743316650390625 | CLS Loss: 0.025999844074249268\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 4.202746868133545 | KNN Loss: 4.181027412414551 | CLS Loss: 0.021719571202993393\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 4.215539932250977 | KNN Loss: 4.1896162033081055 | CLS Loss: 0.025923823937773705\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 4.208852291107178 | KNN Loss: 4.193861961364746 | CLS Loss: 0.014990397728979588\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 4.200983047485352 | KNN Loss: 4.158677577972412 | CLS Loss: 0.04230562224984169\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 4.227785587310791 | KNN Loss: 4.201479434967041 | CLS Loss: 0.02630636841058731\n",
      "Epoch: 036, Loss: 4.2068, Train: 0.9926, Valid: 0.9855, Best: 0.9860\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 4.182365894317627 | KNN Loss: 4.171778202056885 | CLS Loss: 0.01058748085051775\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 4.197867393493652 | KNN Loss: 4.17623233795166 | CLS Loss: 0.021635010838508606\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 4.195868015289307 | KNN Loss: 4.172025680541992 | CLS Loss: 0.0238420981913805\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 4.243321418762207 | KNN Loss: 4.197839736938477 | CLS Loss: 0.04548174887895584\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 4.226945877075195 | KNN Loss: 4.196040153503418 | CLS Loss: 0.030905574560165405\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 4.1683573722839355 | KNN Loss: 4.14651346206665 | CLS Loss: 0.021843673661351204\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 4.165615558624268 | KNN Loss: 4.161298751831055 | CLS Loss: 0.004316812846809626\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 4.195076942443848 | KNN Loss: 4.183282852172852 | CLS Loss: 0.011794214136898518\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 4.243047714233398 | KNN Loss: 4.208829879760742 | CLS Loss: 0.034217823296785355\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 4.204465866088867 | KNN Loss: 4.163378715515137 | CLS Loss: 0.041087210178375244\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 4.206691265106201 | KNN Loss: 4.181225299835205 | CLS Loss: 0.02546585537493229\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 4.210785388946533 | KNN Loss: 4.194170951843262 | CLS Loss: 0.016614332795143127\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 4.18648624420166 | KNN Loss: 4.174610614776611 | CLS Loss: 0.011875410564243793\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 4.188613414764404 | KNN Loss: 4.174125671386719 | CLS Loss: 0.014487829059362411\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 4.235230922698975 | KNN Loss: 4.207151889801025 | CLS Loss: 0.028079228475689888\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 4.206774711608887 | KNN Loss: 4.174009799957275 | CLS Loss: 0.032765015959739685\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 4.233295440673828 | KNN Loss: 4.21753454208374 | CLS Loss: 0.01576068438589573\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 4.238668918609619 | KNN Loss: 4.190054893493652 | CLS Loss: 0.048613958060741425\n",
      "Epoch: 037, Loss: 4.2104, Train: 0.9911, Valid: 0.9847, Best: 0.9860\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 4.1974778175354 | KNN Loss: 4.17964506149292 | CLS Loss: 0.01783282682299614\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 4.188989162445068 | KNN Loss: 4.173192501068115 | CLS Loss: 0.01579689234495163\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 4.184380531311035 | KNN Loss: 4.145155429840088 | CLS Loss: 0.03922507166862488\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 4.197133541107178 | KNN Loss: 4.1735076904296875 | CLS Loss: 0.02362574264407158\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 4.206583023071289 | KNN Loss: 4.180802822113037 | CLS Loss: 0.025780079886317253\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 4.2251362800598145 | KNN Loss: 4.193143367767334 | CLS Loss: 0.03199268877506256\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 4.202780246734619 | KNN Loss: 4.1823649406433105 | CLS Loss: 0.020415378734469414\n",
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 4.187076568603516 | KNN Loss: 4.17816162109375 | CLS Loss: 0.008914724923670292\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 4.1899542808532715 | KNN Loss: 4.173786163330078 | CLS Loss: 0.01616826467216015\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 4.215790748596191 | KNN Loss: 4.16990327835083 | CLS Loss: 0.04588732868432999\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 4.209150791168213 | KNN Loss: 4.1853790283203125 | CLS Loss: 0.023771710693836212\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 4.191348075866699 | KNN Loss: 4.154999732971191 | CLS Loss: 0.036348115652799606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 4.225594520568848 | KNN Loss: 4.195630073547363 | CLS Loss: 0.029964551329612732\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 4.187765121459961 | KNN Loss: 4.166758060455322 | CLS Loss: 0.021006902679800987\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 4.200759410858154 | KNN Loss: 4.188342571258545 | CLS Loss: 0.012416871264576912\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 4.227649211883545 | KNN Loss: 4.194164276123047 | CLS Loss: 0.03348511457443237\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 4.270568370819092 | KNN Loss: 4.220340251922607 | CLS Loss: 0.05022818222641945\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 4.2346367835998535 | KNN Loss: 4.2113447189331055 | CLS Loss: 0.02329188585281372\n",
      "Epoch: 038, Loss: 4.2077, Train: 0.9912, Valid: 0.9844, Best: 0.9860\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 4.251513481140137 | KNN Loss: 4.220104217529297 | CLS Loss: 0.03140903264284134\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 4.2326555252075195 | KNN Loss: 4.193683624267578 | CLS Loss: 0.038971852511167526\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 4.179063320159912 | KNN Loss: 4.166586875915527 | CLS Loss: 0.01247643493115902\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 4.195731163024902 | KNN Loss: 4.170513153076172 | CLS Loss: 0.02521786093711853\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 4.206264019012451 | KNN Loss: 4.194141387939453 | CLS Loss: 0.01212250255048275\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 4.18252420425415 | KNN Loss: 4.162737846374512 | CLS Loss: 0.01978634111583233\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 4.197977066040039 | KNN Loss: 4.164301872253418 | CLS Loss: 0.033675417304039\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 4.213644504547119 | KNN Loss: 4.203157424926758 | CLS Loss: 0.010487310588359833\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 4.2156572341918945 | KNN Loss: 4.210903167724609 | CLS Loss: 0.004754116293042898\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 4.1942009925842285 | KNN Loss: 4.159965991973877 | CLS Loss: 0.03423522785305977\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 4.199461460113525 | KNN Loss: 4.155009746551514 | CLS Loss: 0.0444517508149147\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 4.198465824127197 | KNN Loss: 4.176275730133057 | CLS Loss: 0.022189954295754433\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 4.204185485839844 | KNN Loss: 4.190230846405029 | CLS Loss: 0.013954426161944866\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 4.2112040519714355 | KNN Loss: 4.172880172729492 | CLS Loss: 0.038323912769556046\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 4.200712203979492 | KNN Loss: 4.189337253570557 | CLS Loss: 0.011374859139323235\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 4.246676921844482 | KNN Loss: 4.2313313484191895 | CLS Loss: 0.015345696359872818\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 4.197383403778076 | KNN Loss: 4.161867618560791 | CLS Loss: 0.03551590442657471\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 4.212184429168701 | KNN Loss: 4.174275875091553 | CLS Loss: 0.03790853172540665\n",
      "Epoch: 039, Loss: 4.2097, Train: 0.9938, Valid: 0.9857, Best: 0.9860\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 4.189136505126953 | KNN Loss: 4.179266452789307 | CLS Loss: 0.009869925677776337\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 4.244431018829346 | KNN Loss: 4.195152759552002 | CLS Loss: 0.04927842691540718\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 4.262000560760498 | KNN Loss: 4.235904216766357 | CLS Loss: 0.026096466928720474\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 4.1940178871154785 | KNN Loss: 4.178595542907715 | CLS Loss: 0.0154222771525383\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 4.212309837341309 | KNN Loss: 4.180955410003662 | CLS Loss: 0.03135451301932335\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 4.185784816741943 | KNN Loss: 4.182159423828125 | CLS Loss: 0.0036255880258977413\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 4.184004306793213 | KNN Loss: 4.161116600036621 | CLS Loss: 0.02288779988884926\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 4.201785087585449 | KNN Loss: 4.17724084854126 | CLS Loss: 0.024544458836317062\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 4.227101802825928 | KNN Loss: 4.209723949432373 | CLS Loss: 0.017377732321619987\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 4.220954895019531 | KNN Loss: 4.20111083984375 | CLS Loss: 0.019844088703393936\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 4.146017551422119 | KNN Loss: 4.139091491699219 | CLS Loss: 0.00692588509991765\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 4.200680255889893 | KNN Loss: 4.181654930114746 | CLS Loss: 0.019025402143597603\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 4.150696754455566 | KNN Loss: 4.1437273025512695 | CLS Loss: 0.00696937832981348\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 4.164852619171143 | KNN Loss: 4.144252777099609 | CLS Loss: 0.020599642768502235\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 4.209608554840088 | KNN Loss: 4.175693035125732 | CLS Loss: 0.03391551971435547\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 4.236997604370117 | KNN Loss: 4.215256690979004 | CLS Loss: 0.02174113318324089\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 4.226190090179443 | KNN Loss: 4.18446159362793 | CLS Loss: 0.0417286679148674\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 4.157059669494629 | KNN Loss: 4.141096591949463 | CLS Loss: 0.015963194891810417\n",
      "Epoch: 040, Loss: 4.2017, Train: 0.9938, Valid: 0.9868, Best: 0.9868\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 4.160349369049072 | KNN Loss: 4.1527276039123535 | CLS Loss: 0.0076219188049435616\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 4.193455696105957 | KNN Loss: 4.1814045906066895 | CLS Loss: 0.01205117255449295\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 4.19587516784668 | KNN Loss: 4.187536716461182 | CLS Loss: 0.00833827629685402\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 4.176074981689453 | KNN Loss: 4.167856216430664 | CLS Loss: 0.00821882113814354\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 4.170176029205322 | KNN Loss: 4.160262107849121 | CLS Loss: 0.0099137332290411\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 4.193395614624023 | KNN Loss: 4.170035362243652 | CLS Loss: 0.02336045913398266\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 4.22054386138916 | KNN Loss: 4.1881303787231445 | CLS Loss: 0.03241328150033951\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 4.191493511199951 | KNN Loss: 4.1785359382629395 | CLS Loss: 0.01295741368085146\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 4.19486141204834 | KNN Loss: 4.167008876800537 | CLS Loss: 0.02785256877541542\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 4.2316999435424805 | KNN Loss: 4.192934989929199 | CLS Loss: 0.03876512497663498\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 4.20734167098999 | KNN Loss: 4.174236297607422 | CLS Loss: 0.03310547396540642\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 4.214964389801025 | KNN Loss: 4.189462661743164 | CLS Loss: 0.02550172619521618\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 4.195089817047119 | KNN Loss: 4.190135478973389 | CLS Loss: 0.004954474046826363\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 4.209777355194092 | KNN Loss: 4.171315670013428 | CLS Loss: 0.038461796939373016\n",
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 4.2355828285217285 | KNN Loss: 4.189440727233887 | CLS Loss: 0.04614194110035896\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 4.1999616622924805 | KNN Loss: 4.175922870635986 | CLS Loss: 0.024038977921009064\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 4.1850104331970215 | KNN Loss: 4.149648189544678 | CLS Loss: 0.0353621169924736\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 4.2036919593811035 | KNN Loss: 4.176445007324219 | CLS Loss: 0.027246862649917603\n",
      "Epoch: 041, Loss: 4.2068, Train: 0.9915, Valid: 0.9857, Best: 0.9868\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 4.212025165557861 | KNN Loss: 4.186009883880615 | CLS Loss: 0.026015115901827812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 4.178593158721924 | KNN Loss: 4.17196798324585 | CLS Loss: 0.006625153124332428\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 4.2046895027160645 | KNN Loss: 4.1780524253845215 | CLS Loss: 0.02663695067167282\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 4.174792766571045 | KNN Loss: 4.166518211364746 | CLS Loss: 0.008274378255009651\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 4.287055492401123 | KNN Loss: 4.255039691925049 | CLS Loss: 0.03201565518975258\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 4.218233585357666 | KNN Loss: 4.1948676109313965 | CLS Loss: 0.023365966975688934\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 4.211311340332031 | KNN Loss: 4.18679141998291 | CLS Loss: 0.02451995015144348\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 4.191420555114746 | KNN Loss: 4.151583671569824 | CLS Loss: 0.03983696922659874\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 4.273916721343994 | KNN Loss: 4.230209827423096 | CLS Loss: 0.043707117438316345\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 4.220102310180664 | KNN Loss: 4.202602863311768 | CLS Loss: 0.017499355599284172\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 4.195613384246826 | KNN Loss: 4.166893005371094 | CLS Loss: 0.028720583766698837\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 4.2173542976379395 | KNN Loss: 4.180830478668213 | CLS Loss: 0.03652377426624298\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 4.1740827560424805 | KNN Loss: 4.155406475067139 | CLS Loss: 0.018676307052373886\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 4.190695285797119 | KNN Loss: 4.173926830291748 | CLS Loss: 0.01676824875175953\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 4.223289489746094 | KNN Loss: 4.1889543533325195 | CLS Loss: 0.034335147589445114\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 4.189715385437012 | KNN Loss: 4.160943508148193 | CLS Loss: 0.028771642595529556\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 4.212423801422119 | KNN Loss: 4.19814395904541 | CLS Loss: 0.014280005358159542\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 4.185815334320068 | KNN Loss: 4.169171333312988 | CLS Loss: 0.016643844544887543\n",
      "Epoch: 042, Loss: 4.2062, Train: 0.9939, Valid: 0.9853, Best: 0.9868\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 4.195977687835693 | KNN Loss: 4.164560317993164 | CLS Loss: 0.031417153775691986\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 4.201529502868652 | KNN Loss: 4.188882827758789 | CLS Loss: 0.012646655552089214\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 4.219240188598633 | KNN Loss: 4.190286636352539 | CLS Loss: 0.02895355224609375\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 4.224311828613281 | KNN Loss: 4.181884765625 | CLS Loss: 0.0424269400537014\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 4.238871097564697 | KNN Loss: 4.2067108154296875 | CLS Loss: 0.03216024860739708\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 4.1861066818237305 | KNN Loss: 4.165303707122803 | CLS Loss: 0.02080298401415348\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 4.191495418548584 | KNN Loss: 4.183960437774658 | CLS Loss: 0.007534977048635483\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 4.186695575714111 | KNN Loss: 4.172177791595459 | CLS Loss: 0.014517869800329208\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 4.203575134277344 | KNN Loss: 4.194509029388428 | CLS Loss: 0.009066279046237469\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 4.166460990905762 | KNN Loss: 4.1518073081970215 | CLS Loss: 0.014653544872999191\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 4.203615188598633 | KNN Loss: 4.1818671226501465 | CLS Loss: 0.021748298779129982\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 4.169527530670166 | KNN Loss: 4.158590316772461 | CLS Loss: 0.010937327519059181\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 4.190110683441162 | KNN Loss: 4.16038179397583 | CLS Loss: 0.029728740453720093\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 4.225623607635498 | KNN Loss: 4.1952738761901855 | CLS Loss: 0.030349956825375557\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 4.209837913513184 | KNN Loss: 4.1928205490112305 | CLS Loss: 0.017017340287566185\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 4.191954135894775 | KNN Loss: 4.171169757843018 | CLS Loss: 0.020784316584467888\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 4.179251194000244 | KNN Loss: 4.151986122131348 | CLS Loss: 0.02726520225405693\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 4.1996965408325195 | KNN Loss: 4.187111854553223 | CLS Loss: 0.012584815733134747\n",
      "Epoch: 043, Loss: 4.2007, Train: 0.9939, Valid: 0.9861, Best: 0.9868\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 4.25785493850708 | KNN Loss: 4.2328338623046875 | CLS Loss: 0.025020912289619446\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 4.20809268951416 | KNN Loss: 4.180485725402832 | CLS Loss: 0.027606794610619545\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 4.184823989868164 | KNN Loss: 4.170588970184326 | CLS Loss: 0.01423521339893341\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 4.210537910461426 | KNN Loss: 4.196132183074951 | CLS Loss: 0.014405717141926289\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 4.220526218414307 | KNN Loss: 4.183002471923828 | CLS Loss: 0.03752398118376732\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 4.220452785491943 | KNN Loss: 4.21036434173584 | CLS Loss: 0.010088568553328514\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 4.228451728820801 | KNN Loss: 4.197158336639404 | CLS Loss: 0.03129316493868828\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 4.210536003112793 | KNN Loss: 4.17685604095459 | CLS Loss: 0.03368004411458969\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 4.188255310058594 | KNN Loss: 4.177235126495361 | CLS Loss: 0.01102014072239399\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 4.19363260269165 | KNN Loss: 4.155709743499756 | CLS Loss: 0.03792287036776543\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 4.172011375427246 | KNN Loss: 4.1548686027526855 | CLS Loss: 0.017142893746495247\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 4.195164203643799 | KNN Loss: 4.180932521820068 | CLS Loss: 0.014231566339731216\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 4.217436790466309 | KNN Loss: 4.199679374694824 | CLS Loss: 0.017757469788193703\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 4.213067531585693 | KNN Loss: 4.199239253997803 | CLS Loss: 0.013828111812472343\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 4.206387996673584 | KNN Loss: 4.179233551025391 | CLS Loss: 0.027154672890901566\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 4.184737205505371 | KNN Loss: 4.1669392585754395 | CLS Loss: 0.017797794193029404\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 4.207710266113281 | KNN Loss: 4.182801723480225 | CLS Loss: 0.02490854263305664\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 4.19697380065918 | KNN Loss: 4.187990665435791 | CLS Loss: 0.008983279578387737\n",
      "Epoch: 044, Loss: 4.1971, Train: 0.9939, Valid: 0.9869, Best: 0.9869\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 4.204085350036621 | KNN Loss: 4.180772304534912 | CLS Loss: 0.023312926292419434\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 4.175992488861084 | KNN Loss: 4.163400650024414 | CLS Loss: 0.012591968290507793\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 4.170784950256348 | KNN Loss: 4.152363300323486 | CLS Loss: 0.018421422690153122\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 4.216982841491699 | KNN Loss: 4.194876670837402 | CLS Loss: 0.022106382995843887\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 4.24452018737793 | KNN Loss: 4.21630334854126 | CLS Loss: 0.02821706235408783\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 4.209571838378906 | KNN Loss: 4.182824611663818 | CLS Loss: 0.026747336611151695\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 4.195662021636963 | KNN Loss: 4.153786659240723 | CLS Loss: 0.04187522456049919\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 4.199655055999756 | KNN Loss: 4.1697773933410645 | CLS Loss: 0.029877707362174988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 4.2150163650512695 | KNN Loss: 4.199432373046875 | CLS Loss: 0.015583793632686138\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 4.2043633460998535 | KNN Loss: 4.1850738525390625 | CLS Loss: 0.01928948424756527\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 4.213202476501465 | KNN Loss: 4.193416595458984 | CLS Loss: 0.019785992801189423\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 4.189053058624268 | KNN Loss: 4.167591571807861 | CLS Loss: 0.021461494266986847\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 4.203876495361328 | KNN Loss: 4.184410095214844 | CLS Loss: 0.019466590136289597\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 4.207544803619385 | KNN Loss: 4.178778648376465 | CLS Loss: 0.02876628190279007\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 4.223671913146973 | KNN Loss: 4.192754745483398 | CLS Loss: 0.030917160212993622\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 4.210974216461182 | KNN Loss: 4.174140930175781 | CLS Loss: 0.036833472549915314\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 4.1739068031311035 | KNN Loss: 4.167418956756592 | CLS Loss: 0.006488021928817034\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 4.2266526222229 | KNN Loss: 4.19287633895874 | CLS Loss: 0.03377607837319374\n",
      "Epoch: 045, Loss: 4.1986, Train: 0.9950, Valid: 0.9860, Best: 0.9869\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 4.204358100891113 | KNN Loss: 4.179437637329102 | CLS Loss: 0.024920452386140823\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 4.15355110168457 | KNN Loss: 4.14401912689209 | CLS Loss: 0.00953205768018961\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 4.182133197784424 | KNN Loss: 4.155734539031982 | CLS Loss: 0.026398485526442528\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 4.189082622528076 | KNN Loss: 4.171329021453857 | CLS Loss: 0.017753547057509422\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 4.202401638031006 | KNN Loss: 4.185234069824219 | CLS Loss: 0.01716766133904457\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 4.191256523132324 | KNN Loss: 4.1705522537231445 | CLS Loss: 0.020704053342342377\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 4.17602014541626 | KNN Loss: 4.162651538848877 | CLS Loss: 0.013368595391511917\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 4.178183555603027 | KNN Loss: 4.165025234222412 | CLS Loss: 0.013158217072486877\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 4.169361114501953 | KNN Loss: 4.162484169006348 | CLS Loss: 0.00687706982716918\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 4.239406108856201 | KNN Loss: 4.217508792877197 | CLS Loss: 0.021897349506616592\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 4.214151859283447 | KNN Loss: 4.170231342315674 | CLS Loss: 0.043920353055000305\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 4.179041385650635 | KNN Loss: 4.160693645477295 | CLS Loss: 0.018347764387726784\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 4.182572841644287 | KNN Loss: 4.163818359375 | CLS Loss: 0.018754269927740097\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 4.19502067565918 | KNN Loss: 4.17003870010376 | CLS Loss: 0.024982037022709846\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 4.184298515319824 | KNN Loss: 4.1742167472839355 | CLS Loss: 0.01008161436766386\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 4.240451812744141 | KNN Loss: 4.19146203994751 | CLS Loss: 0.04898976907134056\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 4.196624279022217 | KNN Loss: 4.180678367614746 | CLS Loss: 0.01594572141766548\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 4.199508190155029 | KNN Loss: 4.178945541381836 | CLS Loss: 0.020562777295708656\n",
      "Epoch: 046, Loss: 4.1960, Train: 0.9948, Valid: 0.9859, Best: 0.9869\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 4.166454792022705 | KNN Loss: 4.145724773406982 | CLS Loss: 0.020729919895529747\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 4.164517402648926 | KNN Loss: 4.152342319488525 | CLS Loss: 0.012175198644399643\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 4.1994147300720215 | KNN Loss: 4.178013801574707 | CLS Loss: 0.021400747820734978\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 4.182967662811279 | KNN Loss: 4.171773910522461 | CLS Loss: 0.01119394600391388\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 4.1769118309021 | KNN Loss: 4.155463218688965 | CLS Loss: 0.021448584273457527\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 4.214486122131348 | KNN Loss: 4.189789295196533 | CLS Loss: 0.024696873500943184\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 4.230566024780273 | KNN Loss: 4.201609134674072 | CLS Loss: 0.02895684540271759\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 4.204869747161865 | KNN Loss: 4.192754745483398 | CLS Loss: 0.012114995159208775\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 4.262033939361572 | KNN Loss: 4.2273478507995605 | CLS Loss: 0.03468593209981918\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 4.215130805969238 | KNN Loss: 4.183504581451416 | CLS Loss: 0.03162630274891853\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 4.171586990356445 | KNN Loss: 4.141666889190674 | CLS Loss: 0.029919888824224472\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 4.18705415725708 | KNN Loss: 4.159756183624268 | CLS Loss: 0.02729788050055504\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 4.183041095733643 | KNN Loss: 4.163703918457031 | CLS Loss: 0.019337095320224762\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 4.201131343841553 | KNN Loss: 4.1795830726623535 | CLS Loss: 0.021548157557845116\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 4.193127155303955 | KNN Loss: 4.1825737953186035 | CLS Loss: 0.010553308762609959\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 4.198739528656006 | KNN Loss: 4.182491302490234 | CLS Loss: 0.016248386353254318\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 4.1689629554748535 | KNN Loss: 4.154789924621582 | CLS Loss: 0.014172871597111225\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 4.2444233894348145 | KNN Loss: 4.18199348449707 | CLS Loss: 0.062429916113615036\n",
      "Epoch: 047, Loss: 4.1961, Train: 0.9957, Valid: 0.9877, Best: 0.9877\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 4.183649063110352 | KNN Loss: 4.157551288604736 | CLS Loss: 0.026097692549228668\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 4.176508903503418 | KNN Loss: 4.126302719116211 | CLS Loss: 0.05020629242062569\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 4.1751017570495605 | KNN Loss: 4.165640830993652 | CLS Loss: 0.009460920467972755\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 4.185816287994385 | KNN Loss: 4.175631999969482 | CLS Loss: 0.01018428336828947\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 4.2292962074279785 | KNN Loss: 4.202830791473389 | CLS Loss: 0.026465609669685364\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 4.185205459594727 | KNN Loss: 4.161445617675781 | CLS Loss: 0.023759733885526657\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 4.188150405883789 | KNN Loss: 4.1667022705078125 | CLS Loss: 0.021447936072945595\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 4.19634485244751 | KNN Loss: 4.167145729064941 | CLS Loss: 0.029199354350566864\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 4.215764045715332 | KNN Loss: 4.1847028732299805 | CLS Loss: 0.03106093592941761\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 4.175046920776367 | KNN Loss: 4.139489650726318 | CLS Loss: 0.03555721789598465\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 4.195395469665527 | KNN Loss: 4.165696620941162 | CLS Loss: 0.029698804020881653\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 4.175937652587891 | KNN Loss: 4.151942253112793 | CLS Loss: 0.023995403200387955\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 4.184849739074707 | KNN Loss: 4.172281265258789 | CLS Loss: 0.01256867777556181\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 4.231572151184082 | KNN Loss: 4.194605350494385 | CLS Loss: 0.036966919898986816\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 4.184235572814941 | KNN Loss: 4.164338111877441 | CLS Loss: 0.01989755406975746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 4.202439785003662 | KNN Loss: 4.172946929931641 | CLS Loss: 0.02949298359453678\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 4.217105865478516 | KNN Loss: 4.204037189483643 | CLS Loss: 0.013068810105323792\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 4.218495845794678 | KNN Loss: 4.19435453414917 | CLS Loss: 0.02414124459028244\n",
      "Epoch: 048, Loss: 4.1964, Train: 0.9943, Valid: 0.9858, Best: 0.9877\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 4.174630165100098 | KNN Loss: 4.161332130432129 | CLS Loss: 0.01329818181693554\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 4.209981441497803 | KNN Loss: 4.201780796051025 | CLS Loss: 0.008200523443520069\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 4.175197124481201 | KNN Loss: 4.1686320304870605 | CLS Loss: 0.006565262097865343\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 4.208946228027344 | KNN Loss: 4.193747520446777 | CLS Loss: 0.015198523178696632\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 4.1861066818237305 | KNN Loss: 4.176388740539551 | CLS Loss: 0.009718172252178192\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 4.265081882476807 | KNN Loss: 4.217670917510986 | CLS Loss: 0.047411173582077026\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 4.202476501464844 | KNN Loss: 4.17832088470459 | CLS Loss: 0.02415557950735092\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 4.1767120361328125 | KNN Loss: 4.166411876678467 | CLS Loss: 0.010300075635313988\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 4.209331035614014 | KNN Loss: 4.161514759063721 | CLS Loss: 0.047816067934036255\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 4.1766862869262695 | KNN Loss: 4.151636123657227 | CLS Loss: 0.02505004219710827\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 4.200244426727295 | KNN Loss: 4.176714897155762 | CLS Loss: 0.02352961152791977\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 4.176370143890381 | KNN Loss: 4.162383079528809 | CLS Loss: 0.01398723479360342\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 4.246304035186768 | KNN Loss: 4.236668586730957 | CLS Loss: 0.009635346941649914\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 4.258408546447754 | KNN Loss: 4.1667022705078125 | CLS Loss: 0.09170626103878021\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 4.234044551849365 | KNN Loss: 4.195174694061279 | CLS Loss: 0.03886999562382698\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 4.1945271492004395 | KNN Loss: 4.174160003662109 | CLS Loss: 0.020367072895169258\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 4.190567970275879 | KNN Loss: 4.155357837677002 | CLS Loss: 0.035209983587265015\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 4.211367130279541 | KNN Loss: 4.174187183380127 | CLS Loss: 0.037179868668317795\n",
      "Epoch: 049, Loss: 4.2042, Train: 0.9954, Valid: 0.9870, Best: 0.9877\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 4.1729655265808105 | KNN Loss: 4.161123752593994 | CLS Loss: 0.011841555126011372\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 4.195057392120361 | KNN Loss: 4.145755290985107 | CLS Loss: 0.04930223524570465\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 4.175429821014404 | KNN Loss: 4.159156322479248 | CLS Loss: 0.016273459419608116\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 4.219444274902344 | KNN Loss: 4.173607349395752 | CLS Loss: 0.045836903154850006\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 4.1822099685668945 | KNN Loss: 4.163977146148682 | CLS Loss: 0.018232664093375206\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 4.221290111541748 | KNN Loss: 4.203875541687012 | CLS Loss: 0.017414715141057968\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 4.19268274307251 | KNN Loss: 4.166651725769043 | CLS Loss: 0.0260311271995306\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 4.222149848937988 | KNN Loss: 4.187933921813965 | CLS Loss: 0.03421570360660553\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 4.190452575683594 | KNN Loss: 4.174038887023926 | CLS Loss: 0.016413681209087372\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 4.180287837982178 | KNN Loss: 4.162320613861084 | CLS Loss: 0.01796703413128853\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 4.203284740447998 | KNN Loss: 4.147146701812744 | CLS Loss: 0.05613822862505913\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 4.210058689117432 | KNN Loss: 4.1748151779174805 | CLS Loss: 0.03524370864033699\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 4.191634178161621 | KNN Loss: 4.168959617614746 | CLS Loss: 0.022674458101391792\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 4.162441730499268 | KNN Loss: 4.1568145751953125 | CLS Loss: 0.005626960191875696\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 4.196415901184082 | KNN Loss: 4.166978359222412 | CLS Loss: 0.029437413439154625\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 4.1725172996521 | KNN Loss: 4.152430057525635 | CLS Loss: 0.0200872253626585\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 4.2331061363220215 | KNN Loss: 4.203064441680908 | CLS Loss: 0.030041906982660294\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 4.219943523406982 | KNN Loss: 4.199551105499268 | CLS Loss: 0.020392470061779022\n",
      "Epoch: 050, Loss: 4.1930, Train: 0.9945, Valid: 0.9859, Best: 0.9877\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 4.163461685180664 | KNN Loss: 4.149448871612549 | CLS Loss: 0.014013009145855904\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 4.20368766784668 | KNN Loss: 4.173403263092041 | CLS Loss: 0.030284250155091286\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 4.185276985168457 | KNN Loss: 4.171422481536865 | CLS Loss: 0.013854486867785454\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 4.200986862182617 | KNN Loss: 4.181859493255615 | CLS Loss: 0.019127320498228073\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 4.1932830810546875 | KNN Loss: 4.184010028839111 | CLS Loss: 0.009273017756640911\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 4.1470947265625 | KNN Loss: 4.133242130279541 | CLS Loss: 0.013852725736796856\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 4.17837381362915 | KNN Loss: 4.167112350463867 | CLS Loss: 0.011261684820055962\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 4.183236122131348 | KNN Loss: 4.155823230743408 | CLS Loss: 0.027412710711359978\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 4.203627109527588 | KNN Loss: 4.156520843505859 | CLS Loss: 0.04710615798830986\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 4.234025478363037 | KNN Loss: 4.193531036376953 | CLS Loss: 0.04049423336982727\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 4.20263671875 | KNN Loss: 4.187188148498535 | CLS Loss: 0.015448673628270626\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 4.1644697189331055 | KNN Loss: 4.160810470581055 | CLS Loss: 0.003659082343801856\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 4.173097610473633 | KNN Loss: 4.156417369842529 | CLS Loss: 0.016680117696523666\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 4.1813764572143555 | KNN Loss: 4.166853427886963 | CLS Loss: 0.014522950164973736\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 4.2408647537231445 | KNN Loss: 4.2193217277526855 | CLS Loss: 0.02154320850968361\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 4.161197185516357 | KNN Loss: 4.158260822296143 | CLS Loss: 0.0029363995417952538\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 4.216034412384033 | KNN Loss: 4.192706108093262 | CLS Loss: 0.02332816645503044\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 4.1814069747924805 | KNN Loss: 4.144802093505859 | CLS Loss: 0.036604780703783035\n",
      "Epoch: 051, Loss: 4.1899, Train: 0.9957, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 4.17133092880249 | KNN Loss: 4.151634216308594 | CLS Loss: 0.01969689317047596\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 4.1533918380737305 | KNN Loss: 4.13978910446167 | CLS Loss: 0.013602907769382\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 4.160888195037842 | KNN Loss: 4.154993534088135 | CLS Loss: 0.005894836504012346\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 4.206767559051514 | KNN Loss: 4.179776668548584 | CLS Loss: 0.026990853250026703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 4.1946821212768555 | KNN Loss: 4.176973819732666 | CLS Loss: 0.017708133906126022\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 4.202315807342529 | KNN Loss: 4.189834117889404 | CLS Loss: 0.012481702491641045\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 4.20235013961792 | KNN Loss: 4.175153732299805 | CLS Loss: 0.02719629369676113\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 4.306292533874512 | KNN Loss: 4.272714614868164 | CLS Loss: 0.03357803821563721\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 4.217885971069336 | KNN Loss: 4.194332122802734 | CLS Loss: 0.023553909733891487\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 4.210465908050537 | KNN Loss: 4.188170433044434 | CLS Loss: 0.022295527160167694\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 4.2572150230407715 | KNN Loss: 4.216191291809082 | CLS Loss: 0.041023626923561096\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 4.2148590087890625 | KNN Loss: 4.1752824783325195 | CLS Loss: 0.03957630321383476\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 4.217155456542969 | KNN Loss: 4.178476810455322 | CLS Loss: 0.038678836077451706\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 4.206447124481201 | KNN Loss: 4.173908233642578 | CLS Loss: 0.03253881633281708\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 4.228703022003174 | KNN Loss: 4.1962385177612305 | CLS Loss: 0.032464466989040375\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 4.21415376663208 | KNN Loss: 4.1988325119018555 | CLS Loss: 0.015321183949708939\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 4.156657695770264 | KNN Loss: 4.134454727172852 | CLS Loss: 0.022202979773283005\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 4.160546779632568 | KNN Loss: 4.134192943572998 | CLS Loss: 0.02635382115840912\n",
      "Epoch: 052, Loss: 4.1946, Train: 0.9938, Valid: 0.9849, Best: 0.9877\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 4.15569543838501 | KNN Loss: 4.14953088760376 | CLS Loss: 0.006164603866636753\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 4.221404552459717 | KNN Loss: 4.181436538696289 | CLS Loss: 0.03996815159916878\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 4.197814464569092 | KNN Loss: 4.17595100402832 | CLS Loss: 0.021863514557480812\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 4.182140827178955 | KNN Loss: 4.167317867279053 | CLS Loss: 0.014822996221482754\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 4.2113823890686035 | KNN Loss: 4.187038898468018 | CLS Loss: 0.024343350902199745\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 4.200143337249756 | KNN Loss: 4.179953575134277 | CLS Loss: 0.020189788192510605\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 4.22184419631958 | KNN Loss: 4.199351787567139 | CLS Loss: 0.022492505609989166\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 4.236414432525635 | KNN Loss: 4.169044494628906 | CLS Loss: 0.06736976653337479\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 4.193349361419678 | KNN Loss: 4.174281120300293 | CLS Loss: 0.01906834915280342\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 4.177212715148926 | KNN Loss: 4.167109489440918 | CLS Loss: 0.010103239677846432\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 4.190049171447754 | KNN Loss: 4.178314208984375 | CLS Loss: 0.011735196225345135\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 4.292734146118164 | KNN Loss: 4.249789237976074 | CLS Loss: 0.04294471815228462\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 4.1764960289001465 | KNN Loss: 4.162383556365967 | CLS Loss: 0.014112349599599838\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 4.186647415161133 | KNN Loss: 4.158596992492676 | CLS Loss: 0.028050661087036133\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 4.175267219543457 | KNN Loss: 4.157101631164551 | CLS Loss: 0.01816549338400364\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 4.169312953948975 | KNN Loss: 4.152370452880859 | CLS Loss: 0.016942456364631653\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 4.191418170928955 | KNN Loss: 4.163364887237549 | CLS Loss: 0.028053443878889084\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 4.220963001251221 | KNN Loss: 4.187360763549805 | CLS Loss: 0.03360200673341751\n",
      "Epoch: 053, Loss: 4.1944, Train: 0.9957, Valid: 0.9876, Best: 0.9877\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 4.1538591384887695 | KNN Loss: 4.148444652557373 | CLS Loss: 0.0054146177135407925\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 4.230650424957275 | KNN Loss: 4.2073140144348145 | CLS Loss: 0.02333620935678482\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 4.17724084854126 | KNN Loss: 4.156526565551758 | CLS Loss: 0.020714057609438896\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 4.2025957107543945 | KNN Loss: 4.1786370277404785 | CLS Loss: 0.02395862527191639\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 4.1670684814453125 | KNN Loss: 4.150359153747559 | CLS Loss: 0.016709335148334503\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 4.157742500305176 | KNN Loss: 4.1475372314453125 | CLS Loss: 0.010205278173089027\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 4.181238651275635 | KNN Loss: 4.156988620758057 | CLS Loss: 0.024250175803899765\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 4.192037105560303 | KNN Loss: 4.16537618637085 | CLS Loss: 0.026660699397325516\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 4.241939544677734 | KNN Loss: 4.210652828216553 | CLS Loss: 0.03128684684634209\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 4.141291618347168 | KNN Loss: 4.109841823577881 | CLS Loss: 0.03144996613264084\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 4.190823554992676 | KNN Loss: 4.167544841766357 | CLS Loss: 0.02327866107225418\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 4.187634468078613 | KNN Loss: 4.15515661239624 | CLS Loss: 0.0324777252972126\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 4.183910846710205 | KNN Loss: 4.1744513511657715 | CLS Loss: 0.009459310211241245\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 4.207942485809326 | KNN Loss: 4.194711208343506 | CLS Loss: 0.013231487013399601\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 4.152684688568115 | KNN Loss: 4.149089813232422 | CLS Loss: 0.003594911191612482\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 4.187401294708252 | KNN Loss: 4.176386833190918 | CLS Loss: 0.011014627292752266\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 4.19587516784668 | KNN Loss: 4.160421371459961 | CLS Loss: 0.035453904420137405\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 4.194023132324219 | KNN Loss: 4.166614055633545 | CLS Loss: 0.027408991008996964\n",
      "Epoch: 054, Loss: 4.1881, Train: 0.9950, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 4.188843727111816 | KNN Loss: 4.1704864501953125 | CLS Loss: 0.018357468768954277\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 4.171178340911865 | KNN Loss: 4.155740737915039 | CLS Loss: 0.01543780043721199\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 4.187386512756348 | KNN Loss: 4.167938232421875 | CLS Loss: 0.019448280334472656\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 4.1927809715271 | KNN Loss: 4.177872180938721 | CLS Loss: 0.014908628538250923\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 4.146735191345215 | KNN Loss: 4.134877681732178 | CLS Loss: 0.011857394129037857\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 4.148321151733398 | KNN Loss: 4.137840270996094 | CLS Loss: 0.01048066932708025\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 4.197994709014893 | KNN Loss: 4.188391208648682 | CLS Loss: 0.009603346697986126\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 4.216485977172852 | KNN Loss: 4.205857276916504 | CLS Loss: 0.010628537274897099\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 4.209875106811523 | KNN Loss: 4.18130350112915 | CLS Loss: 0.028571557253599167\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 4.179111957550049 | KNN Loss: 4.173495769500732 | CLS Loss: 0.005616228561848402\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 4.167266368865967 | KNN Loss: 4.151647567749023 | CLS Loss: 0.015618802979588509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 4.283218860626221 | KNN Loss: 4.244460582733154 | CLS Loss: 0.038758207112550735\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 4.160972595214844 | KNN Loss: 4.155418872833252 | CLS Loss: 0.005553707480430603\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 4.201815605163574 | KNN Loss: 4.174366474151611 | CLS Loss: 0.02744893543422222\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 4.202620506286621 | KNN Loss: 4.1774773597717285 | CLS Loss: 0.025143008679151535\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 4.160615921020508 | KNN Loss: 4.144134521484375 | CLS Loss: 0.016481172293424606\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 4.17690372467041 | KNN Loss: 4.168121337890625 | CLS Loss: 0.00878248829394579\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 4.2019243240356445 | KNN Loss: 4.184511661529541 | CLS Loss: 0.017412450164556503\n",
      "Epoch: 055, Loss: 4.1892, Train: 0.9947, Valid: 0.9854, Best: 0.9877\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 4.174366474151611 | KNN Loss: 4.158445835113525 | CLS Loss: 0.015920840203762054\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 4.197088241577148 | KNN Loss: 4.187653064727783 | CLS Loss: 0.009435242041945457\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 4.164981365203857 | KNN Loss: 4.141678333282471 | CLS Loss: 0.023302879184484482\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 4.168210983276367 | KNN Loss: 4.159496307373047 | CLS Loss: 0.008714558556675911\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 4.155797481536865 | KNN Loss: 4.142934322357178 | CLS Loss: 0.012863105162978172\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 4.217653274536133 | KNN Loss: 4.207963943481445 | CLS Loss: 0.009689219295978546\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 4.220933437347412 | KNN Loss: 4.177765846252441 | CLS Loss: 0.043167416006326675\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 4.195696830749512 | KNN Loss: 4.188261985778809 | CLS Loss: 0.007435052189975977\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 4.1576714515686035 | KNN Loss: 4.136754035949707 | CLS Loss: 0.020917387679219246\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 4.177483558654785 | KNN Loss: 4.157865047454834 | CLS Loss: 0.019618676975369453\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 4.195064067840576 | KNN Loss: 4.172776222229004 | CLS Loss: 0.022287661209702492\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 4.187705993652344 | KNN Loss: 4.1687912940979 | CLS Loss: 0.018914658576250076\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 4.17784309387207 | KNN Loss: 4.173099517822266 | CLS Loss: 0.004743762314319611\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 4.164274215698242 | KNN Loss: 4.158516883850098 | CLS Loss: 0.005757556296885014\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 4.176257133483887 | KNN Loss: 4.140575885772705 | CLS Loss: 0.035681188106536865\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 4.215977668762207 | KNN Loss: 4.188068866729736 | CLS Loss: 0.027908626943826675\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 4.195369720458984 | KNN Loss: 4.170719146728516 | CLS Loss: 0.02465045265853405\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 4.22122859954834 | KNN Loss: 4.196397304534912 | CLS Loss: 0.024831369519233704\n",
      "Epoch: 056, Loss: 4.1920, Train: 0.9941, Valid: 0.9856, Best: 0.9877\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 4.271069526672363 | KNN Loss: 4.223259449005127 | CLS Loss: 0.047810111194849014\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 4.178898811340332 | KNN Loss: 4.162998676300049 | CLS Loss: 0.01590009033679962\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 4.18686580657959 | KNN Loss: 4.159111022949219 | CLS Loss: 0.02775471843779087\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 4.188411235809326 | KNN Loss: 4.153407096862793 | CLS Loss: 0.035003986209630966\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 4.146536827087402 | KNN Loss: 4.134840965270996 | CLS Loss: 0.01169571653008461\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 4.183973789215088 | KNN Loss: 4.162751197814941 | CLS Loss: 0.021222742274403572\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 4.184130668640137 | KNN Loss: 4.167799472808838 | CLS Loss: 0.016331234946846962\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 4.275938034057617 | KNN Loss: 4.249277591705322 | CLS Loss: 0.02666023001074791\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 4.204413890838623 | KNN Loss: 4.178882122039795 | CLS Loss: 0.025531893596053123\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 4.204036712646484 | KNN Loss: 4.178550720214844 | CLS Loss: 0.025486061349511147\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 4.195117950439453 | KNN Loss: 4.184289932250977 | CLS Loss: 0.010828020982444286\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 4.1591572761535645 | KNN Loss: 4.1368608474731445 | CLS Loss: 0.022296518087387085\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 4.153077125549316 | KNN Loss: 4.1470441818237305 | CLS Loss: 0.006032917648553848\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 4.153826713562012 | KNN Loss: 4.131156921386719 | CLS Loss: 0.022669559344649315\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 4.182433128356934 | KNN Loss: 4.168216705322266 | CLS Loss: 0.014216538518667221\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 4.195130348205566 | KNN Loss: 4.182866096496582 | CLS Loss: 0.012264149263501167\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 4.187394142150879 | KNN Loss: 4.170163631439209 | CLS Loss: 0.01723073609173298\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 4.145096778869629 | KNN Loss: 4.125833034515381 | CLS Loss: 0.019263586029410362\n",
      "Epoch: 057, Loss: 4.1861, Train: 0.9947, Valid: 0.9861, Best: 0.9877\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 4.20922327041626 | KNN Loss: 4.193386077880859 | CLS Loss: 0.01583734154701233\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 4.187291145324707 | KNN Loss: 4.169250965118408 | CLS Loss: 0.018040034919977188\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 4.175755023956299 | KNN Loss: 4.158952236175537 | CLS Loss: 0.016802940517663956\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 4.194173812866211 | KNN Loss: 4.17372465133667 | CLS Loss: 0.020449189469218254\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 4.229572296142578 | KNN Loss: 4.206111431121826 | CLS Loss: 0.023460784927010536\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 4.14766263961792 | KNN Loss: 4.132922172546387 | CLS Loss: 0.014740393497049809\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 4.209327697753906 | KNN Loss: 4.185959339141846 | CLS Loss: 0.02336813323199749\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 4.146594524383545 | KNN Loss: 4.143551349639893 | CLS Loss: 0.00304333190433681\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 4.144277572631836 | KNN Loss: 4.137383460998535 | CLS Loss: 0.006894091609865427\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 4.158014297485352 | KNN Loss: 4.143691062927246 | CLS Loss: 0.01432342454791069\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 4.1993608474731445 | KNN Loss: 4.1508564949035645 | CLS Loss: 0.0485043004155159\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 4.175408840179443 | KNN Loss: 4.145971298217773 | CLS Loss: 0.029437346383929253\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 4.138322353363037 | KNN Loss: 4.134052753448486 | CLS Loss: 0.004269629716873169\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 4.182605266571045 | KNN Loss: 4.159867763519287 | CLS Loss: 0.022737659513950348\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 4.225786209106445 | KNN Loss: 4.195443153381348 | CLS Loss: 0.0303429514169693\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 4.188277721405029 | KNN Loss: 4.174738883972168 | CLS Loss: 0.013538972474634647\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 4.203320026397705 | KNN Loss: 4.150591850280762 | CLS Loss: 0.052728381007909775\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 4.197310924530029 | KNN Loss: 4.175058841705322 | CLS Loss: 0.022252099588513374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 058, Loss: 4.1864, Train: 0.9949, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 4.1580610275268555 | KNN Loss: 4.152759552001953 | CLS Loss: 0.005301548633724451\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 4.188549995422363 | KNN Loss: 4.148524284362793 | CLS Loss: 0.040025655180215836\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 4.178872108459473 | KNN Loss: 4.157114505767822 | CLS Loss: 0.021757641807198524\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 4.163790225982666 | KNN Loss: 4.147476673126221 | CLS Loss: 0.016313612461090088\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 4.23149299621582 | KNN Loss: 4.222084045410156 | CLS Loss: 0.009408792480826378\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 4.192058563232422 | KNN Loss: 4.184995174407959 | CLS Loss: 0.007063187193125486\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 4.179533004760742 | KNN Loss: 4.176252365112305 | CLS Loss: 0.003280709031969309\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 4.22612190246582 | KNN Loss: 4.197593688964844 | CLS Loss: 0.02852826565504074\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 4.159022808074951 | KNN Loss: 4.1337361335754395 | CLS Loss: 0.025286784395575523\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 4.195673942565918 | KNN Loss: 4.186011791229248 | CLS Loss: 0.009662026539444923\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 4.148355484008789 | KNN Loss: 4.128079414367676 | CLS Loss: 0.020276112481951714\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 4.190517902374268 | KNN Loss: 4.176209926605225 | CLS Loss: 0.014308036305010319\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 4.155712604522705 | KNN Loss: 4.147670745849609 | CLS Loss: 0.008041994646191597\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 4.184357643127441 | KNN Loss: 4.156216144561768 | CLS Loss: 0.028141550719738007\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 4.188663005828857 | KNN Loss: 4.168036937713623 | CLS Loss: 0.02062586322426796\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 4.2102131843566895 | KNN Loss: 4.182629585266113 | CLS Loss: 0.02758382074534893\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 4.188268661499023 | KNN Loss: 4.162322044372559 | CLS Loss: 0.025946855545043945\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 4.192691326141357 | KNN Loss: 4.161137104034424 | CLS Loss: 0.031554367393255234\n",
      "Epoch: 059, Loss: 4.1871, Train: 0.9950, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 4.190289497375488 | KNN Loss: 4.1788225173950195 | CLS Loss: 0.01146703027188778\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 4.18634033203125 | KNN Loss: 4.149582386016846 | CLS Loss: 0.03675808385014534\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 4.169499397277832 | KNN Loss: 4.16159725189209 | CLS Loss: 0.007902324199676514\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 4.173172473907471 | KNN Loss: 4.162556171417236 | CLS Loss: 0.010616219602525234\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 4.178328990936279 | KNN Loss: 4.162808418273926 | CLS Loss: 0.015520397573709488\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 4.200328350067139 | KNN Loss: 4.18943977355957 | CLS Loss: 0.010888406075537205\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 4.242382049560547 | KNN Loss: 4.210780620574951 | CLS Loss: 0.03160126879811287\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 4.150717258453369 | KNN Loss: 4.145615100860596 | CLS Loss: 0.0051023890264332294\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 4.170252799987793 | KNN Loss: 4.160851955413818 | CLS Loss: 0.009400920942425728\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 4.183624744415283 | KNN Loss: 4.16433048248291 | CLS Loss: 0.019294217228889465\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 4.166468620300293 | KNN Loss: 4.1514058113098145 | CLS Loss: 0.015062869526445866\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 4.160887241363525 | KNN Loss: 4.130575656890869 | CLS Loss: 0.030311524868011475\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 4.222324371337891 | KNN Loss: 4.203080177307129 | CLS Loss: 0.019244195893406868\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 4.171751976013184 | KNN Loss: 4.163360118865967 | CLS Loss: 0.008391986601054668\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 4.194356918334961 | KNN Loss: 4.1643571853637695 | CLS Loss: 0.02999967336654663\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 4.19920015335083 | KNN Loss: 4.169564247131348 | CLS Loss: 0.029635854065418243\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 4.1885762214660645 | KNN Loss: 4.176789283752441 | CLS Loss: 0.011787078343331814\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 4.198350429534912 | KNN Loss: 4.17657995223999 | CLS Loss: 0.021770358085632324\n",
      "Epoch: 060, Loss: 4.1832, Train: 0.9960, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 4.152155876159668 | KNN Loss: 4.1464104652404785 | CLS Loss: 0.005745557602494955\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 4.160512924194336 | KNN Loss: 4.154390335083008 | CLS Loss: 0.006122480146586895\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 4.174169063568115 | KNN Loss: 4.167585849761963 | CLS Loss: 0.006583177484571934\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 4.188695430755615 | KNN Loss: 4.168550968170166 | CLS Loss: 0.020144423469901085\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 4.192633628845215 | KNN Loss: 4.170688152313232 | CLS Loss: 0.021945472806692123\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 4.215027332305908 | KNN Loss: 4.1998610496521 | CLS Loss: 0.015166162513196468\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 4.193521976470947 | KNN Loss: 4.185551166534424 | CLS Loss: 0.007970866747200489\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 4.193424224853516 | KNN Loss: 4.159579277038574 | CLS Loss: 0.03384483978152275\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 4.191830635070801 | KNN Loss: 4.172145366668701 | CLS Loss: 0.01968546025454998\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 4.193990230560303 | KNN Loss: 4.176139831542969 | CLS Loss: 0.017850441858172417\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 4.182857036590576 | KNN Loss: 4.159542083740234 | CLS Loss: 0.023314932361245155\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 4.188109397888184 | KNN Loss: 4.17280387878418 | CLS Loss: 0.01530572958290577\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 4.1730875968933105 | KNN Loss: 4.163440704345703 | CLS Loss: 0.00964692234992981\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 4.166763782501221 | KNN Loss: 4.155246257781982 | CLS Loss: 0.011517385020852089\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 4.170893669128418 | KNN Loss: 4.164095401763916 | CLS Loss: 0.006798442918807268\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 4.182436943054199 | KNN Loss: 4.174325942993164 | CLS Loss: 0.008111168630421162\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 4.1404948234558105 | KNN Loss: 4.11480712890625 | CLS Loss: 0.025687485933303833\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 4.193625450134277 | KNN Loss: 4.164515018463135 | CLS Loss: 0.0291102547198534\n",
      "Epoch: 061, Loss: 4.1860, Train: 0.9953, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 4.214906692504883 | KNN Loss: 4.197138786315918 | CLS Loss: 0.017767788842320442\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 4.201409339904785 | KNN Loss: 4.195317268371582 | CLS Loss: 0.006092037074267864\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 4.189330577850342 | KNN Loss: 4.1673431396484375 | CLS Loss: 0.02198743261396885\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 4.180302619934082 | KNN Loss: 4.173332691192627 | CLS Loss: 0.006970059592276812\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 4.2009053230285645 | KNN Loss: 4.1834564208984375 | CLS Loss: 0.017448948696255684\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 4.210848331451416 | KNN Loss: 4.190005302429199 | CLS Loss: 0.020842984318733215\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 4.186984062194824 | KNN Loss: 4.171144008636475 | CLS Loss: 0.015839867293834686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 4.202852249145508 | KNN Loss: 4.180104732513428 | CLS Loss: 0.02274765633046627\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 4.186528205871582 | KNN Loss: 4.161948204040527 | CLS Loss: 0.024579916149377823\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 4.224067687988281 | KNN Loss: 4.204464435577393 | CLS Loss: 0.019603334367275238\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 4.140321254730225 | KNN Loss: 4.1305155754089355 | CLS Loss: 0.009805455803871155\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 4.218142032623291 | KNN Loss: 4.1864471435546875 | CLS Loss: 0.031695082783699036\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 4.177969932556152 | KNN Loss: 4.159965991973877 | CLS Loss: 0.018004121258854866\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 4.169165134429932 | KNN Loss: 4.156026363372803 | CLS Loss: 0.0131387235596776\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 4.2020158767700195 | KNN Loss: 4.177320957183838 | CLS Loss: 0.024694839492440224\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 4.171797752380371 | KNN Loss: 4.15643310546875 | CLS Loss: 0.015364660881459713\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 4.186367988586426 | KNN Loss: 4.154431343078613 | CLS Loss: 0.03193652257323265\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 4.155806541442871 | KNN Loss: 4.152590751647949 | CLS Loss: 0.0032159059774130583\n",
      "Epoch: 062, Loss: 4.1900, Train: 0.9931, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 4.202555179595947 | KNN Loss: 4.190117359161377 | CLS Loss: 0.012437662109732628\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 4.208451271057129 | KNN Loss: 4.201002597808838 | CLS Loss: 0.007448798511177301\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 4.210043430328369 | KNN Loss: 4.185326099395752 | CLS Loss: 0.024717243388295174\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 4.137921333312988 | KNN Loss: 4.133312225341797 | CLS Loss: 0.004609128925949335\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 4.170688629150391 | KNN Loss: 4.162235736846924 | CLS Loss: 0.008452978916466236\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 4.222733020782471 | KNN Loss: 4.1930928230285645 | CLS Loss: 0.02964015305042267\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 4.169138431549072 | KNN Loss: 4.162961483001709 | CLS Loss: 0.0061768582090735435\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 4.16104793548584 | KNN Loss: 4.153441429138184 | CLS Loss: 0.007606486324220896\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 4.153920650482178 | KNN Loss: 4.14501953125 | CLS Loss: 0.008901086635887623\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 4.186702728271484 | KNN Loss: 4.174489974975586 | CLS Loss: 0.012212890200316906\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 4.169755458831787 | KNN Loss: 4.161862373352051 | CLS Loss: 0.007892969995737076\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 4.1777753829956055 | KNN Loss: 4.162795543670654 | CLS Loss: 0.014979809522628784\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 4.166971683502197 | KNN Loss: 4.123122692108154 | CLS Loss: 0.043848827481269836\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 4.190537929534912 | KNN Loss: 4.1591620445251465 | CLS Loss: 0.03137601912021637\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 4.242883205413818 | KNN Loss: 4.202382564544678 | CLS Loss: 0.040500424802303314\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 4.192423343658447 | KNN Loss: 4.176150321960449 | CLS Loss: 0.01627296768128872\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 4.1854705810546875 | KNN Loss: 4.177093029022217 | CLS Loss: 0.008377321995794773\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 4.215199947357178 | KNN Loss: 4.165999412536621 | CLS Loss: 0.049200352281332016\n",
      "Epoch: 063, Loss: 4.1922, Train: 0.9945, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 4.162527084350586 | KNN Loss: 4.15480375289917 | CLS Loss: 0.007723491173237562\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 4.197299003601074 | KNN Loss: 4.177958965301514 | CLS Loss: 0.019339878112077713\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 4.20522403717041 | KNN Loss: 4.177889823913574 | CLS Loss: 0.027334151789546013\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 4.189571380615234 | KNN Loss: 4.136044979095459 | CLS Loss: 0.05352652445435524\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 4.179740905761719 | KNN Loss: 4.166107654571533 | CLS Loss: 0.013633474707603455\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 4.179077625274658 | KNN Loss: 4.160269260406494 | CLS Loss: 0.018808307126164436\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 4.189944744110107 | KNN Loss: 4.179205894470215 | CLS Loss: 0.010738823562860489\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 4.219489574432373 | KNN Loss: 4.211067199707031 | CLS Loss: 0.008422507904469967\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 4.188959121704102 | KNN Loss: 4.170352458953857 | CLS Loss: 0.01860671117901802\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 4.167389869689941 | KNN Loss: 4.15418004989624 | CLS Loss: 0.013209795579314232\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 4.179009437561035 | KNN Loss: 4.150783538818359 | CLS Loss: 0.0282260961830616\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 4.171849250793457 | KNN Loss: 4.143321514129639 | CLS Loss: 0.028527548536658287\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 4.144495487213135 | KNN Loss: 4.141034126281738 | CLS Loss: 0.0034614386968314648\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 4.177862644195557 | KNN Loss: 4.153165817260742 | CLS Loss: 0.024696635082364082\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 4.1577067375183105 | KNN Loss: 4.154171466827393 | CLS Loss: 0.003535086289048195\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 4.1933722496032715 | KNN Loss: 4.163733959197998 | CLS Loss: 0.029638325795531273\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 4.193981170654297 | KNN Loss: 4.169260501861572 | CLS Loss: 0.024720551446080208\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 4.176357746124268 | KNN Loss: 4.156928539276123 | CLS Loss: 0.019429096952080727\n",
      "Epoch: 064, Loss: 4.1836, Train: 0.9935, Valid: 0.9854, Best: 0.9877\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 4.180519104003906 | KNN Loss: 4.156240940093994 | CLS Loss: 0.02427821420133114\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 4.1568603515625 | KNN Loss: 4.149448871612549 | CLS Loss: 0.007411439437419176\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 4.199382305145264 | KNN Loss: 4.178462505340576 | CLS Loss: 0.020919783040881157\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 4.161691188812256 | KNN Loss: 4.155282497406006 | CLS Loss: 0.006408785469830036\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 4.128109455108643 | KNN Loss: 4.110257148742676 | CLS Loss: 0.017852406948804855\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 4.145929336547852 | KNN Loss: 4.122074604034424 | CLS Loss: 0.023854592815041542\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 4.222799777984619 | KNN Loss: 4.197614669799805 | CLS Loss: 0.025184927508234978\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 4.15179967880249 | KNN Loss: 4.149442195892334 | CLS Loss: 0.0023574044462293386\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 4.1536335945129395 | KNN Loss: 4.148128509521484 | CLS Loss: 0.0055050114169716835\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 4.191843032836914 | KNN Loss: 4.172643661499023 | CLS Loss: 0.01919923909008503\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 4.172246932983398 | KNN Loss: 4.167236328125 | CLS Loss: 0.005010519176721573\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 4.178384304046631 | KNN Loss: 4.163044452667236 | CLS Loss: 0.015339751727879047\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 4.147440433502197 | KNN Loss: 4.1334404945373535 | CLS Loss: 0.013999813236296177\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 4.2476677894592285 | KNN Loss: 4.214787483215332 | CLS Loss: 0.032880157232284546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 4.149967193603516 | KNN Loss: 4.126682758331299 | CLS Loss: 0.023284204304218292\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 4.1950812339782715 | KNN Loss: 4.183898448944092 | CLS Loss: 0.01118288841098547\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 4.1710052490234375 | KNN Loss: 4.163559436798096 | CLS Loss: 0.007445796392858028\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 4.160733699798584 | KNN Loss: 4.144943714141846 | CLS Loss: 0.015789829194545746\n",
      "Epoch: 065, Loss: 4.1793, Train: 0.9953, Valid: 0.9852, Best: 0.9877\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 4.219118118286133 | KNN Loss: 4.183114528656006 | CLS Loss: 0.03600335121154785\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 4.160523891448975 | KNN Loss: 4.146389961242676 | CLS Loss: 0.01413408201187849\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 4.176066875457764 | KNN Loss: 4.167725563049316 | CLS Loss: 0.008341513574123383\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 4.182732105255127 | KNN Loss: 4.147710800170898 | CLS Loss: 0.03502140939235687\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 4.1841349601745605 | KNN Loss: 4.178525924682617 | CLS Loss: 0.005609115120023489\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 4.171126842498779 | KNN Loss: 4.1519646644592285 | CLS Loss: 0.019162237644195557\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 4.1773505210876465 | KNN Loss: 4.172310829162598 | CLS Loss: 0.005039859097450972\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 4.172236919403076 | KNN Loss: 4.131618976593018 | CLS Loss: 0.04061798006296158\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 4.209178447723389 | KNN Loss: 4.19867467880249 | CLS Loss: 0.010503792203962803\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 4.167263031005859 | KNN Loss: 4.159352779388428 | CLS Loss: 0.007910214364528656\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 4.170059680938721 | KNN Loss: 4.145280838012695 | CLS Loss: 0.024778900668025017\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 4.2094597816467285 | KNN Loss: 4.198851585388184 | CLS Loss: 0.010608173906803131\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 4.161638259887695 | KNN Loss: 4.158752918243408 | CLS Loss: 0.0028853490948677063\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 4.185323715209961 | KNN Loss: 4.177604675292969 | CLS Loss: 0.00771910697221756\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 4.176724433898926 | KNN Loss: 4.151027679443359 | CLS Loss: 0.02569691278040409\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 4.157661437988281 | KNN Loss: 4.131130695343018 | CLS Loss: 0.026530928909778595\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 4.222017288208008 | KNN Loss: 4.208633899688721 | CLS Loss: 0.013383482582867146\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 4.157837390899658 | KNN Loss: 4.145650386810303 | CLS Loss: 0.012187075801193714\n",
      "Epoch: 066, Loss: 4.1826, Train: 0.9960, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 4.231837749481201 | KNN Loss: 4.19941520690918 | CLS Loss: 0.032422490417957306\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 4.193704128265381 | KNN Loss: 4.174973487854004 | CLS Loss: 0.01873060129582882\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 4.183823108673096 | KNN Loss: 4.172351837158203 | CLS Loss: 0.011471201665699482\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 4.205478191375732 | KNN Loss: 4.188162326812744 | CLS Loss: 0.01731574907898903\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 4.174054145812988 | KNN Loss: 4.167616367340088 | CLS Loss: 0.006437606643885374\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 4.159465789794922 | KNN Loss: 4.133650779724121 | CLS Loss: 0.02581513486802578\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 4.1790313720703125 | KNN Loss: 4.15092134475708 | CLS Loss: 0.028109829872846603\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 4.182360649108887 | KNN Loss: 4.1728291511535645 | CLS Loss: 0.009531619027256966\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 4.167611122131348 | KNN Loss: 4.159175395965576 | CLS Loss: 0.00843551941215992\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 4.192787170410156 | KNN Loss: 4.166912078857422 | CLS Loss: 0.025875095278024673\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 4.179800510406494 | KNN Loss: 4.165910720825195 | CLS Loss: 0.013889659196138382\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 4.211494445800781 | KNN Loss: 4.19594144821167 | CLS Loss: 0.015552868135273457\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 4.166876316070557 | KNN Loss: 4.157533645629883 | CLS Loss: 0.00934260431677103\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 4.210312843322754 | KNN Loss: 4.170645713806152 | CLS Loss: 0.039666928350925446\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 4.186127185821533 | KNN Loss: 4.1780619621276855 | CLS Loss: 0.008065053261816502\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 4.174736976623535 | KNN Loss: 4.159698963165283 | CLS Loss: 0.015037977136671543\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 4.159631729125977 | KNN Loss: 4.151113033294678 | CLS Loss: 0.00851889792829752\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 4.220822811126709 | KNN Loss: 4.196662425994873 | CLS Loss: 0.02416016161441803\n",
      "Epoch: 067, Loss: 4.1818, Train: 0.9964, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 4.167754650115967 | KNN Loss: 4.150136470794678 | CLS Loss: 0.01761798746883869\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 4.150201320648193 | KNN Loss: 4.141645908355713 | CLS Loss: 0.008555488660931587\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 4.20172643661499 | KNN Loss: 4.195560932159424 | CLS Loss: 0.006165544036775827\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 4.157908916473389 | KNN Loss: 4.151841163635254 | CLS Loss: 0.006067752372473478\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 4.17024564743042 | KNN Loss: 4.1649675369262695 | CLS Loss: 0.0052780574187636375\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 4.1734490394592285 | KNN Loss: 4.149567604064941 | CLS Loss: 0.02388131432235241\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 4.193099021911621 | KNN Loss: 4.164592266082764 | CLS Loss: 0.028506852686405182\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 4.164700984954834 | KNN Loss: 4.15596342086792 | CLS Loss: 0.008737416006624699\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 4.196006774902344 | KNN Loss: 4.181838035583496 | CLS Loss: 0.014168698340654373\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 4.211807727813721 | KNN Loss: 4.1943278312683105 | CLS Loss: 0.01748008280992508\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 4.151956081390381 | KNN Loss: 4.142825126647949 | CLS Loss: 0.0091310515999794\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 4.205252170562744 | KNN Loss: 4.201743125915527 | CLS Loss: 0.0035092735197395086\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 4.182815074920654 | KNN Loss: 4.1727423667907715 | CLS Loss: 0.010072614066302776\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 4.184753894805908 | KNN Loss: 4.166159629821777 | CLS Loss: 0.018594248220324516\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 4.230354309082031 | KNN Loss: 4.211423397064209 | CLS Loss: 0.018930824473500252\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 4.203771114349365 | KNN Loss: 4.17689847946167 | CLS Loss: 0.026872407644987106\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 4.263893127441406 | KNN Loss: 4.166635990142822 | CLS Loss: 0.09725715219974518\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 4.166374683380127 | KNN Loss: 4.139469146728516 | CLS Loss: 0.026905491948127747\n",
      "Epoch: 068, Loss: 4.1800, Train: 0.9945, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 4.171289443969727 | KNN Loss: 4.160757064819336 | CLS Loss: 0.010532421991229057\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 4.1612420082092285 | KNN Loss: 4.153985500335693 | CLS Loss: 0.0072566308081150055\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 4.245773792266846 | KNN Loss: 4.2283453941345215 | CLS Loss: 0.017428554594516754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 4.161281585693359 | KNN Loss: 4.155218601226807 | CLS Loss: 0.006062796339392662\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 4.206069469451904 | KNN Loss: 4.188847541809082 | CLS Loss: 0.017221912741661072\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 4.157599925994873 | KNN Loss: 4.15139102935791 | CLS Loss: 0.00620880164206028\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 4.141510963439941 | KNN Loss: 4.135335445404053 | CLS Loss: 0.006175358314067125\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 4.170724868774414 | KNN Loss: 4.14848518371582 | CLS Loss: 0.02223968505859375\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 4.239158630371094 | KNN Loss: 4.203597545623779 | CLS Loss: 0.03556087985634804\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 4.225435733795166 | KNN Loss: 4.179186820983887 | CLS Loss: 0.04624883085489273\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 4.150387763977051 | KNN Loss: 4.144852161407471 | CLS Loss: 0.005535645876079798\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 4.161396503448486 | KNN Loss: 4.144098281860352 | CLS Loss: 0.017297986894845963\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 4.17037296295166 | KNN Loss: 4.155343532562256 | CLS Loss: 0.015029655769467354\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 4.196665287017822 | KNN Loss: 4.181464195251465 | CLS Loss: 0.01520126685500145\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 4.165807723999023 | KNN Loss: 4.157211780548096 | CLS Loss: 0.008596151135861874\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 4.155028820037842 | KNN Loss: 4.147309303283691 | CLS Loss: 0.007719546556472778\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 4.164587020874023 | KNN Loss: 4.147572040557861 | CLS Loss: 0.017014943063259125\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 4.184034824371338 | KNN Loss: 4.169610500335693 | CLS Loss: 0.014424150809645653\n",
      "Epoch: 069, Loss: 4.1805, Train: 0.9955, Valid: 0.9850, Best: 0.9877\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 4.187837600708008 | KNN Loss: 4.1678619384765625 | CLS Loss: 0.019975794479250908\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 4.151243209838867 | KNN Loss: 4.142723560333252 | CLS Loss: 0.008519493974745274\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 4.165775299072266 | KNN Loss: 4.144067764282227 | CLS Loss: 0.021707702428102493\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 4.183548927307129 | KNN Loss: 4.170566558837891 | CLS Loss: 0.012982139363884926\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 4.156222343444824 | KNN Loss: 4.147678852081299 | CLS Loss: 0.008543711155653\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 4.174514293670654 | KNN Loss: 4.171353816986084 | CLS Loss: 0.0031604431569576263\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 4.145087242126465 | KNN Loss: 4.1391282081604 | CLS Loss: 0.005959258880466223\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 4.1935834884643555 | KNN Loss: 4.179771423339844 | CLS Loss: 0.01381201483309269\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 4.169347286224365 | KNN Loss: 4.143106937408447 | CLS Loss: 0.026240302249789238\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 4.21146821975708 | KNN Loss: 4.204212665557861 | CLS Loss: 0.0072553884238004684\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 4.213930130004883 | KNN Loss: 4.194669246673584 | CLS Loss: 0.019260985776782036\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 4.159182548522949 | KNN Loss: 4.156078815460205 | CLS Loss: 0.0031037291046231985\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 4.204433917999268 | KNN Loss: 4.172985553741455 | CLS Loss: 0.03144844248890877\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 4.170777797698975 | KNN Loss: 4.155932903289795 | CLS Loss: 0.014844832941889763\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 4.208544731140137 | KNN Loss: 4.169693470001221 | CLS Loss: 0.03885109722614288\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 4.165184020996094 | KNN Loss: 4.15303373336792 | CLS Loss: 0.012150416150689125\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 4.1963396072387695 | KNN Loss: 4.167211055755615 | CLS Loss: 0.02912864275276661\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 4.1809234619140625 | KNN Loss: 4.1582417488098145 | CLS Loss: 0.022681618109345436\n",
      "Epoch: 070, Loss: 4.1766, Train: 0.9957, Valid: 0.9865, Best: 0.9877\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 4.170158386230469 | KNN Loss: 4.167078971862793 | CLS Loss: 0.0030795305501669645\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 4.206162929534912 | KNN Loss: 4.150888442993164 | CLS Loss: 0.05527466908097267\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 4.16791296005249 | KNN Loss: 4.15611457824707 | CLS Loss: 0.011798599734902382\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 4.165423393249512 | KNN Loss: 4.1565399169921875 | CLS Loss: 0.008883274160325527\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 4.171961784362793 | KNN Loss: 4.163576602935791 | CLS Loss: 0.008385074324905872\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 4.173121452331543 | KNN Loss: 4.1596760749816895 | CLS Loss: 0.013445567339658737\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 4.2128190994262695 | KNN Loss: 4.168182849884033 | CLS Loss: 0.04463639855384827\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 4.214569091796875 | KNN Loss: 4.173384189605713 | CLS Loss: 0.04118511453270912\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 4.163692474365234 | KNN Loss: 4.148853302001953 | CLS Loss: 0.014839223586022854\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 4.199971675872803 | KNN Loss: 4.185338497161865 | CLS Loss: 0.01463338267058134\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 4.167294502258301 | KNN Loss: 4.165405750274658 | CLS Loss: 0.0018886149628087878\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 4.241740703582764 | KNN Loss: 4.226922988891602 | CLS Loss: 0.014817558228969574\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 4.1218485832214355 | KNN Loss: 4.117952346801758 | CLS Loss: 0.003896167501807213\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 4.16344690322876 | KNN Loss: 4.157317638397217 | CLS Loss: 0.006129369605332613\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 4.17965841293335 | KNN Loss: 4.150880813598633 | CLS Loss: 0.028777657076716423\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 4.176329612731934 | KNN Loss: 4.162956714630127 | CLS Loss: 0.013373107649385929\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 4.179160118103027 | KNN Loss: 4.167644500732422 | CLS Loss: 0.011515527032315731\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 4.226656436920166 | KNN Loss: 4.219691276550293 | CLS Loss: 0.006964998785406351\n",
      "Epoch: 071, Loss: 4.1766, Train: 0.9958, Valid: 0.9874, Best: 0.9877\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 4.2381415367126465 | KNN Loss: 4.225121021270752 | CLS Loss: 0.013020490296185017\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 4.154847621917725 | KNN Loss: 4.147446155548096 | CLS Loss: 0.00740147614851594\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 4.219912528991699 | KNN Loss: 4.200375556945801 | CLS Loss: 0.019536837935447693\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 4.180099010467529 | KNN Loss: 4.150279998779297 | CLS Loss: 0.029818903654813766\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 4.207136631011963 | KNN Loss: 4.193516254425049 | CLS Loss: 0.013620196841657162\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 4.2066569328308105 | KNN Loss: 4.178406715393066 | CLS Loss: 0.028250327333807945\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 4.199223518371582 | KNN Loss: 4.159883975982666 | CLS Loss: 0.03933975473046303\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 4.215082168579102 | KNN Loss: 4.1904754638671875 | CLS Loss: 0.024606915190815926\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 4.16453742980957 | KNN Loss: 4.151551723480225 | CLS Loss: 0.012985597364604473\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 4.157801151275635 | KNN Loss: 4.132411956787109 | CLS Loss: 0.0253891684114933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 4.170676231384277 | KNN Loss: 4.148681640625 | CLS Loss: 0.02199462056159973\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 4.2044477462768555 | KNN Loss: 4.183150291442871 | CLS Loss: 0.021297693252563477\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 4.215217113494873 | KNN Loss: 4.193902969360352 | CLS Loss: 0.021314125508069992\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 4.149684906005859 | KNN Loss: 4.13804817199707 | CLS Loss: 0.011636967770755291\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 4.20574426651001 | KNN Loss: 4.187355041503906 | CLS Loss: 0.01838923618197441\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 4.197363376617432 | KNN Loss: 4.1769843101501465 | CLS Loss: 0.0203792005777359\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 4.219241619110107 | KNN Loss: 4.185904502868652 | CLS Loss: 0.03333720564842224\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 4.235894203186035 | KNN Loss: 4.218753337860107 | CLS Loss: 0.01714097335934639\n",
      "Epoch: 072, Loss: 4.1804, Train: 0.9944, Valid: 0.9841, Best: 0.9877\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 4.208772659301758 | KNN Loss: 4.196898460388184 | CLS Loss: 0.011874042451381683\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 4.182821750640869 | KNN Loss: 4.165198802947998 | CLS Loss: 0.017623163759708405\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 4.150142669677734 | KNN Loss: 4.140549659729004 | CLS Loss: 0.00959315337240696\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 4.174214839935303 | KNN Loss: 4.144075870513916 | CLS Loss: 0.03013891540467739\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 4.200753688812256 | KNN Loss: 4.186898708343506 | CLS Loss: 0.013854864984750748\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 4.139793872833252 | KNN Loss: 4.1293625831604 | CLS Loss: 0.010431398637592793\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 4.130931854248047 | KNN Loss: 4.124027252197266 | CLS Loss: 0.006904568988829851\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 4.206811904907227 | KNN Loss: 4.197904586791992 | CLS Loss: 0.008907382376492023\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 4.184333801269531 | KNN Loss: 4.155919551849365 | CLS Loss: 0.028414122760295868\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 4.161161422729492 | KNN Loss: 4.143783092498779 | CLS Loss: 0.017378151416778564\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 4.183229923248291 | KNN Loss: 4.177558898925781 | CLS Loss: 0.005671198945492506\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 4.185021877288818 | KNN Loss: 4.173288345336914 | CLS Loss: 0.011733656749129295\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 4.220908164978027 | KNN Loss: 4.19686222076416 | CLS Loss: 0.02404613606631756\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 4.136571407318115 | KNN Loss: 4.12255859375 | CLS Loss: 0.014012686908245087\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 4.23292875289917 | KNN Loss: 4.19175386428833 | CLS Loss: 0.0411747582256794\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 4.16949987411499 | KNN Loss: 4.156106948852539 | CLS Loss: 0.013393014669418335\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 4.170571327209473 | KNN Loss: 4.146082878112793 | CLS Loss: 0.02448825165629387\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 4.173799514770508 | KNN Loss: 4.159095287322998 | CLS Loss: 0.014704038389027119\n",
      "Epoch: 073, Loss: 4.1777, Train: 0.9953, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 4.176216125488281 | KNN Loss: 4.167000770568848 | CLS Loss: 0.009215512312948704\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 4.155704975128174 | KNN Loss: 4.134768009185791 | CLS Loss: 0.020936783403158188\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 4.189949035644531 | KNN Loss: 4.1813836097717285 | CLS Loss: 0.00856554415076971\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 4.181241512298584 | KNN Loss: 4.17094087600708 | CLS Loss: 0.010300647467374802\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 4.191871166229248 | KNN Loss: 4.16889762878418 | CLS Loss: 0.02297365479171276\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 4.194440841674805 | KNN Loss: 4.182281017303467 | CLS Loss: 0.012159794569015503\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 4.187269687652588 | KNN Loss: 4.176556587219238 | CLS Loss: 0.010712976567447186\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 4.180051803588867 | KNN Loss: 4.16275691986084 | CLS Loss: 0.017294764518737793\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 4.152035713195801 | KNN Loss: 4.136088848114014 | CLS Loss: 0.015946924686431885\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 4.172590732574463 | KNN Loss: 4.157774448394775 | CLS Loss: 0.014816435985267162\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 4.164289474487305 | KNN Loss: 4.147979259490967 | CLS Loss: 0.01631033420562744\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 4.185530185699463 | KNN Loss: 4.175896167755127 | CLS Loss: 0.009634084068238735\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 4.218377113342285 | KNN Loss: 4.199061870574951 | CLS Loss: 0.019315460696816444\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 4.154009819030762 | KNN Loss: 4.1466169357299805 | CLS Loss: 0.0073928795754909515\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 4.184183597564697 | KNN Loss: 4.172980308532715 | CLS Loss: 0.011203211732208729\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 4.196458339691162 | KNN Loss: 4.179955005645752 | CLS Loss: 0.01650330424308777\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 4.184362411499023 | KNN Loss: 4.166133880615234 | CLS Loss: 0.01822858490049839\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 4.158277988433838 | KNN Loss: 4.145635604858398 | CLS Loss: 0.012642279267311096\n",
      "Epoch: 074, Loss: 4.1778, Train: 0.9961, Valid: 0.9852, Best: 0.9877\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 4.143581867218018 | KNN Loss: 4.13757848739624 | CLS Loss: 0.0060036019422113895\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 4.162570953369141 | KNN Loss: 4.139172554016113 | CLS Loss: 0.023398486897349358\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 4.182397365570068 | KNN Loss: 4.1725544929504395 | CLS Loss: 0.009842860512435436\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 4.186518669128418 | KNN Loss: 4.170416831970215 | CLS Loss: 0.01610167883336544\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 4.201295375823975 | KNN Loss: 4.194589138031006 | CLS Loss: 0.006706175394356251\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 4.173399448394775 | KNN Loss: 4.149832248687744 | CLS Loss: 0.023567426949739456\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 4.137907028198242 | KNN Loss: 4.130557060241699 | CLS Loss: 0.007349739782512188\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 4.170384883880615 | KNN Loss: 4.1624250411987305 | CLS Loss: 0.00795987993478775\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 4.181382179260254 | KNN Loss: 4.16827917098999 | CLS Loss: 0.013103088364005089\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 4.20677375793457 | KNN Loss: 4.194046497344971 | CLS Loss: 0.012727346271276474\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 4.181722164154053 | KNN Loss: 4.172894477844238 | CLS Loss: 0.008827734738588333\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 4.1730875968933105 | KNN Loss: 4.165979385375977 | CLS Loss: 0.007108372636139393\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 4.177255153656006 | KNN Loss: 4.163214206695557 | CLS Loss: 0.014041159301996231\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 4.18131685256958 | KNN Loss: 4.167166709899902 | CLS Loss: 0.014150016941130161\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 4.226101875305176 | KNN Loss: 4.203927516937256 | CLS Loss: 0.022174354642629623\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 4.174103260040283 | KNN Loss: 4.144429683685303 | CLS Loss: 0.029673470184206963\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 4.193955421447754 | KNN Loss: 4.1692962646484375 | CLS Loss: 0.02465907670557499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 4.165290355682373 | KNN Loss: 4.154426574707031 | CLS Loss: 0.010863877832889557\n",
      "Epoch: 075, Loss: 4.1779, Train: 0.9956, Valid: 0.9850, Best: 0.9877\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 4.209721088409424 | KNN Loss: 4.195563793182373 | CLS Loss: 0.014157470315694809\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 4.16067361831665 | KNN Loss: 4.154938697814941 | CLS Loss: 0.005734800361096859\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 4.171138763427734 | KNN Loss: 4.147661209106445 | CLS Loss: 0.023477718234062195\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 4.242914199829102 | KNN Loss: 4.216883659362793 | CLS Loss: 0.026030760258436203\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 4.16958475112915 | KNN Loss: 4.156491279602051 | CLS Loss: 0.013093606568872929\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 4.16823148727417 | KNN Loss: 4.158453464508057 | CLS Loss: 0.009778019040822983\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 4.176153182983398 | KNN Loss: 4.1627888679504395 | CLS Loss: 0.013364270329475403\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 4.201756477355957 | KNN Loss: 4.193305015563965 | CLS Loss: 0.008451616391539574\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 4.144165992736816 | KNN Loss: 4.120063781738281 | CLS Loss: 0.024102360010147095\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 4.195085048675537 | KNN Loss: 4.183490753173828 | CLS Loss: 0.011594315059483051\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 4.195036888122559 | KNN Loss: 4.1587934494018555 | CLS Loss: 0.036243487149477005\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 4.236033916473389 | KNN Loss: 4.202251434326172 | CLS Loss: 0.0337827131152153\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 4.193355083465576 | KNN Loss: 4.1895623207092285 | CLS Loss: 0.003792561125010252\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 4.145547389984131 | KNN Loss: 4.135390281677246 | CLS Loss: 0.010157101787626743\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 4.1723480224609375 | KNN Loss: 4.150391578674316 | CLS Loss: 0.02195627987384796\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 4.19710111618042 | KNN Loss: 4.186020851135254 | CLS Loss: 0.01108038704842329\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 4.184582710266113 | KNN Loss: 4.1665358543396 | CLS Loss: 0.018046870827674866\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 4.210596561431885 | KNN Loss: 4.189473628997803 | CLS Loss: 0.02112315036356449\n",
      "Epoch: 076, Loss: 4.1821, Train: 0.9955, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 4.161868095397949 | KNN Loss: 4.15441370010376 | CLS Loss: 0.00745451869443059\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 4.1838059425354 | KNN Loss: 4.17821741104126 | CLS Loss: 0.0055885943584144115\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 4.153075218200684 | KNN Loss: 4.14494514465332 | CLS Loss: 0.0081302709877491\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 4.171784400939941 | KNN Loss: 4.159066677093506 | CLS Loss: 0.012717503122985363\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 4.161023139953613 | KNN Loss: 4.1558756828308105 | CLS Loss: 0.005147439427673817\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 4.175129413604736 | KNN Loss: 4.169060707092285 | CLS Loss: 0.006068678572773933\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 4.181051731109619 | KNN Loss: 4.165167331695557 | CLS Loss: 0.015884315595030785\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 4.168356418609619 | KNN Loss: 4.145086765289307 | CLS Loss: 0.023269420489668846\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 4.204336166381836 | KNN Loss: 4.197872638702393 | CLS Loss: 0.006463333498686552\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 4.15413236618042 | KNN Loss: 4.145902633666992 | CLS Loss: 0.008229645900428295\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 4.196852684020996 | KNN Loss: 4.177908420562744 | CLS Loss: 0.018944257870316505\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 4.191620826721191 | KNN Loss: 4.176413059234619 | CLS Loss: 0.015207621268928051\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 4.167291164398193 | KNN Loss: 4.147816181182861 | CLS Loss: 0.019474875181913376\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 4.163484573364258 | KNN Loss: 4.150543212890625 | CLS Loss: 0.012941312976181507\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 4.187547206878662 | KNN Loss: 4.15699577331543 | CLS Loss: 0.030551252886652946\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 4.187646865844727 | KNN Loss: 4.1732306480407715 | CLS Loss: 0.014416428282856941\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 4.188479423522949 | KNN Loss: 4.172924995422363 | CLS Loss: 0.015554322861135006\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 4.176396369934082 | KNN Loss: 4.160902500152588 | CLS Loss: 0.015494059771299362\n",
      "Epoch: 077, Loss: 4.1786, Train: 0.9955, Valid: 0.9849, Best: 0.9877\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 4.178187370300293 | KNN Loss: 4.172600746154785 | CLS Loss: 0.005586632993072271\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 4.198708534240723 | KNN Loss: 4.191030502319336 | CLS Loss: 0.007677936460822821\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 4.203131198883057 | KNN Loss: 4.17355489730835 | CLS Loss: 0.029576502740383148\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 4.252958297729492 | KNN Loss: 4.2198309898376465 | CLS Loss: 0.033127132803201675\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 4.1679534912109375 | KNN Loss: 4.159599304199219 | CLS Loss: 0.008354012854397297\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 4.159792900085449 | KNN Loss: 4.147709369659424 | CLS Loss: 0.01208345964550972\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 4.179369926452637 | KNN Loss: 4.169665336608887 | CLS Loss: 0.00970480591058731\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 4.161451816558838 | KNN Loss: 4.141105651855469 | CLS Loss: 0.020346328616142273\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 4.153707504272461 | KNN Loss: 4.140512943267822 | CLS Loss: 0.013194586150348186\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 4.223719596862793 | KNN Loss: 4.205204963684082 | CLS Loss: 0.018514424562454224\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 4.182529449462891 | KNN Loss: 4.159502029418945 | CLS Loss: 0.023027192801237106\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 4.1720404624938965 | KNN Loss: 4.13924503326416 | CLS Loss: 0.03279520198702812\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 4.186882495880127 | KNN Loss: 4.174535274505615 | CLS Loss: 0.012347218580543995\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 4.141887187957764 | KNN Loss: 4.139145851135254 | CLS Loss: 0.0027411310002207756\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 4.179330825805664 | KNN Loss: 4.163630485534668 | CLS Loss: 0.015700198709964752\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 4.177751064300537 | KNN Loss: 4.164331436157227 | CLS Loss: 0.013419696129858494\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 4.170572280883789 | KNN Loss: 4.161056995391846 | CLS Loss: 0.009515369310975075\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 4.17949104309082 | KNN Loss: 4.16062593460083 | CLS Loss: 0.018864979967474937\n",
      "Epoch: 078, Loss: 4.1825, Train: 0.9969, Valid: 0.9878, Best: 0.9878\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 4.15908670425415 | KNN Loss: 4.154188632965088 | CLS Loss: 0.004898142535239458\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 4.186744689941406 | KNN Loss: 4.177713394165039 | CLS Loss: 0.00903141126036644\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 4.207042694091797 | KNN Loss: 4.189197063446045 | CLS Loss: 0.017845574766397476\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 4.170248508453369 | KNN Loss: 4.157418251037598 | CLS Loss: 0.01283029094338417\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 4.164660930633545 | KNN Loss: 4.159849166870117 | CLS Loss: 0.004811678547412157\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 4.1951165199279785 | KNN Loss: 4.161731719970703 | CLS Loss: 0.03338490054011345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 4.166930198669434 | KNN Loss: 4.16139030456543 | CLS Loss: 0.005539972335100174\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 4.169836044311523 | KNN Loss: 4.141866207122803 | CLS Loss: 0.027969712391495705\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 4.2296037673950195 | KNN Loss: 4.2214484214782715 | CLS Loss: 0.008155218325555325\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 4.1908769607543945 | KNN Loss: 4.160884857177734 | CLS Loss: 0.029992029070854187\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 4.188178062438965 | KNN Loss: 4.1837286949157715 | CLS Loss: 0.004449509549885988\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 4.142493724822998 | KNN Loss: 4.134003162384033 | CLS Loss: 0.008490631356835365\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 4.185122489929199 | KNN Loss: 4.175537109375 | CLS Loss: 0.009585217572748661\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 4.192245006561279 | KNN Loss: 4.182685375213623 | CLS Loss: 0.009559745900332928\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 4.223074436187744 | KNN Loss: 4.212996959686279 | CLS Loss: 0.010077692568302155\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 4.19175386428833 | KNN Loss: 4.159964561462402 | CLS Loss: 0.031789328902959824\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 4.151710510253906 | KNN Loss: 4.13653039932251 | CLS Loss: 0.015180084854364395\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 4.169646739959717 | KNN Loss: 4.162167549133301 | CLS Loss: 0.007479346357285976\n",
      "Epoch: 079, Loss: 4.1838, Train: 0.9964, Valid: 0.9874, Best: 0.9878\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 4.12962007522583 | KNN Loss: 4.120359420776367 | CLS Loss: 0.009260665625333786\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 4.197901248931885 | KNN Loss: 4.181757926940918 | CLS Loss: 0.01614346355199814\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 4.1768107414245605 | KNN Loss: 4.1688432693481445 | CLS Loss: 0.00796751119196415\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 4.223877429962158 | KNN Loss: 4.210057258605957 | CLS Loss: 0.013820325024425983\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 4.184234142303467 | KNN Loss: 4.170432090759277 | CLS Loss: 0.01380210556089878\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 4.191662311553955 | KNN Loss: 4.15938138961792 | CLS Loss: 0.032280877232551575\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 4.155916213989258 | KNN Loss: 4.139425277709961 | CLS Loss: 0.016490701586008072\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 4.228704929351807 | KNN Loss: 4.201555252075195 | CLS Loss: 0.02714962512254715\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 4.159491062164307 | KNN Loss: 4.1474175453186035 | CLS Loss: 0.01207373384386301\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 4.165961742401123 | KNN Loss: 4.159073829650879 | CLS Loss: 0.006888070609420538\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 4.191854953765869 | KNN Loss: 4.160642147064209 | CLS Loss: 0.031212925910949707\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 4.225229740142822 | KNN Loss: 4.198160171508789 | CLS Loss: 0.027069738134741783\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 4.206549167633057 | KNN Loss: 4.182945728302002 | CLS Loss: 0.02360360696911812\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 4.230119228363037 | KNN Loss: 4.166800498962402 | CLS Loss: 0.06331872195005417\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 4.194962978363037 | KNN Loss: 4.184878349304199 | CLS Loss: 0.010084769688546658\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 4.189581871032715 | KNN Loss: 4.180243968963623 | CLS Loss: 0.009337837807834148\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 4.158136367797852 | KNN Loss: 4.148576736450195 | CLS Loss: 0.009559531696140766\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 4.175725936889648 | KNN Loss: 4.162307262420654 | CLS Loss: 0.013418524526059628\n",
      "Epoch: 080, Loss: 4.1840, Train: 0.9952, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 4.1590681076049805 | KNN Loss: 4.146656513214111 | CLS Loss: 0.012411530129611492\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 4.165151119232178 | KNN Loss: 4.158769607543945 | CLS Loss: 0.0063814944587647915\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 4.149521350860596 | KNN Loss: 4.142034530639648 | CLS Loss: 0.007486902642995119\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 4.15257453918457 | KNN Loss: 4.141861438751221 | CLS Loss: 0.01071323174983263\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 4.166594982147217 | KNN Loss: 4.157659530639648 | CLS Loss: 0.008935446850955486\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 4.140980243682861 | KNN Loss: 4.133781433105469 | CLS Loss: 0.007198842242360115\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 4.168479919433594 | KNN Loss: 4.1601691246032715 | CLS Loss: 0.00831094104796648\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 4.172027587890625 | KNN Loss: 4.153079986572266 | CLS Loss: 0.01894744113087654\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 4.197789669036865 | KNN Loss: 4.186452388763428 | CLS Loss: 0.011337102390825748\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 4.168424606323242 | KNN Loss: 4.154244422912598 | CLS Loss: 0.014180203899741173\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 4.163232803344727 | KNN Loss: 4.156899929046631 | CLS Loss: 0.006332960445433855\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 4.1729888916015625 | KNN Loss: 4.152504920959473 | CLS Loss: 0.020483803004026413\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 4.129970073699951 | KNN Loss: 4.127333164215088 | CLS Loss: 0.0026367525570094585\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 4.170549392700195 | KNN Loss: 4.153589248657227 | CLS Loss: 0.016959993168711662\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 4.187359809875488 | KNN Loss: 4.162325382232666 | CLS Loss: 0.025034258142113686\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 4.186398029327393 | KNN Loss: 4.168292045593262 | CLS Loss: 0.018106084316968918\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 4.199158191680908 | KNN Loss: 4.156116008758545 | CLS Loss: 0.04304198548197746\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 4.195005893707275 | KNN Loss: 4.174354076385498 | CLS Loss: 0.020651981234550476\n",
      "Epoch: 081, Loss: 4.1793, Train: 0.9954, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 4.153435230255127 | KNN Loss: 4.134059906005859 | CLS Loss: 0.01937546581029892\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 4.168667316436768 | KNN Loss: 4.156847953796387 | CLS Loss: 0.01181945763528347\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 4.200275897979736 | KNN Loss: 4.16276741027832 | CLS Loss: 0.03750857338309288\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 4.156221389770508 | KNN Loss: 4.1505608558654785 | CLS Loss: 0.005660550203174353\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 4.266817569732666 | KNN Loss: 4.248661041259766 | CLS Loss: 0.01815634034574032\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 4.2222771644592285 | KNN Loss: 4.210926532745361 | CLS Loss: 0.011350497603416443\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 4.152029037475586 | KNN Loss: 4.133529186248779 | CLS Loss: 0.01849980093538761\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 4.160923004150391 | KNN Loss: 4.149087905883789 | CLS Loss: 0.011834928765892982\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 4.191843509674072 | KNN Loss: 4.178515434265137 | CLS Loss: 0.013328171335160732\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 4.201108932495117 | KNN Loss: 4.16576623916626 | CLS Loss: 0.03534283488988876\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 4.166797637939453 | KNN Loss: 4.161895751953125 | CLS Loss: 0.0049019670113921165\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 4.170715808868408 | KNN Loss: 4.1675615310668945 | CLS Loss: 0.0031542556826025248\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 4.211050033569336 | KNN Loss: 4.206447601318359 | CLS Loss: 0.004602397326380014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 4.155994415283203 | KNN Loss: 4.132330417633057 | CLS Loss: 0.023664116859436035\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 4.1669535636901855 | KNN Loss: 4.163586616516113 | CLS Loss: 0.0033669774420559406\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 4.171258926391602 | KNN Loss: 4.163424015045166 | CLS Loss: 0.00783504731953144\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 4.204437732696533 | KNN Loss: 4.1814751625061035 | CLS Loss: 0.02296256273984909\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 4.179472923278809 | KNN Loss: 4.148589611053467 | CLS Loss: 0.03088338114321232\n",
      "Epoch: 082, Loss: 4.1793, Train: 0.9959, Valid: 0.9866, Best: 0.9878\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 4.178383827209473 | KNN Loss: 4.163675785064697 | CLS Loss: 0.014707834459841251\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 4.192801475524902 | KNN Loss: 4.166308879852295 | CLS Loss: 0.02649264968931675\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 4.185253620147705 | KNN Loss: 4.173760414123535 | CLS Loss: 0.011492997407913208\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 4.177699565887451 | KNN Loss: 4.152550220489502 | CLS Loss: 0.025149403139948845\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 4.180536270141602 | KNN Loss: 4.168869972229004 | CLS Loss: 0.011666360311210155\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 4.152684211730957 | KNN Loss: 4.144905090332031 | CLS Loss: 0.0077789039351046085\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 4.156444549560547 | KNN Loss: 4.146544456481934 | CLS Loss: 0.009899899363517761\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 4.130496978759766 | KNN Loss: 4.129680156707764 | CLS Loss: 0.0008168086060322821\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 4.1628642082214355 | KNN Loss: 4.155555248260498 | CLS Loss: 0.007308863569051027\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 4.178264141082764 | KNN Loss: 4.167250633239746 | CLS Loss: 0.011013389565050602\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 4.199706077575684 | KNN Loss: 4.184779644012451 | CLS Loss: 0.014926441945135593\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 4.185074806213379 | KNN Loss: 4.178433418273926 | CLS Loss: 0.00664123659953475\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 4.198305606842041 | KNN Loss: 4.158435821533203 | CLS Loss: 0.03986961767077446\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 4.188807964324951 | KNN Loss: 4.169614315032959 | CLS Loss: 0.019193625077605247\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 4.143266677856445 | KNN Loss: 4.1245341300964355 | CLS Loss: 0.018732711672782898\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 4.193303108215332 | KNN Loss: 4.1797332763671875 | CLS Loss: 0.013569695875048637\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 4.245274066925049 | KNN Loss: 4.227949142456055 | CLS Loss: 0.01732480712234974\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 4.167366981506348 | KNN Loss: 4.158875942230225 | CLS Loss: 0.008491192944347858\n",
      "Epoch: 083, Loss: 4.1791, Train: 0.9966, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 4.208160400390625 | KNN Loss: 4.200193881988525 | CLS Loss: 0.007966414093971252\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 4.1750993728637695 | KNN Loss: 4.1688079833984375 | CLS Loss: 0.006291389465332031\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 4.199196815490723 | KNN Loss: 4.168063640594482 | CLS Loss: 0.031133221462368965\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 4.186878681182861 | KNN Loss: 4.177953243255615 | CLS Loss: 0.00892532430589199\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 4.169229030609131 | KNN Loss: 4.157440662384033 | CLS Loss: 0.011788303032517433\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 4.215410232543945 | KNN Loss: 4.207673072814941 | CLS Loss: 0.0077369422651827335\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 4.18629264831543 | KNN Loss: 4.164737701416016 | CLS Loss: 0.021555162966251373\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 4.156375408172607 | KNN Loss: 4.142085552215576 | CLS Loss: 0.01428991463035345\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 4.149376392364502 | KNN Loss: 4.139701843261719 | CLS Loss: 0.009674682281911373\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 4.218171119689941 | KNN Loss: 4.213734149932861 | CLS Loss: 0.00443715276196599\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 4.206173419952393 | KNN Loss: 4.183952808380127 | CLS Loss: 0.022220568731427193\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 4.222309112548828 | KNN Loss: 4.204389572143555 | CLS Loss: 0.01791965216398239\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 4.191226959228516 | KNN Loss: 4.169990062713623 | CLS Loss: 0.021236862987279892\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 4.244627475738525 | KNN Loss: 4.2268548011779785 | CLS Loss: 0.017772449180483818\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 4.201031684875488 | KNN Loss: 4.169785976409912 | CLS Loss: 0.03124581277370453\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 4.157548427581787 | KNN Loss: 4.152623176574707 | CLS Loss: 0.004925297573208809\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 4.202309608459473 | KNN Loss: 4.185976505279541 | CLS Loss: 0.01633314974606037\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 4.1992669105529785 | KNN Loss: 4.17183780670166 | CLS Loss: 0.02742896042764187\n",
      "Epoch: 084, Loss: 4.1805, Train: 0.9968, Valid: 0.9875, Best: 0.9878\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 4.194999694824219 | KNN Loss: 4.181896209716797 | CLS Loss: 0.013103647157549858\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 4.147675037384033 | KNN Loss: 4.142064571380615 | CLS Loss: 0.005610386375337839\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 4.170497417449951 | KNN Loss: 4.164799690246582 | CLS Loss: 0.005697732791304588\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 4.182676792144775 | KNN Loss: 4.178676605224609 | CLS Loss: 0.0040003517642617226\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 4.170291423797607 | KNN Loss: 4.152902126312256 | CLS Loss: 0.017389493063092232\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 4.190389633178711 | KNN Loss: 4.1770782470703125 | CLS Loss: 0.013311169110238552\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 4.167426586151123 | KNN Loss: 4.137857913970947 | CLS Loss: 0.02956889383494854\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 4.165163516998291 | KNN Loss: 4.155222415924072 | CLS Loss: 0.009941126219928265\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 4.224169731140137 | KNN Loss: 4.202430248260498 | CLS Loss: 0.021739356219768524\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 4.22349214553833 | KNN Loss: 4.182008266448975 | CLS Loss: 0.04148368537425995\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 4.18834924697876 | KNN Loss: 4.168163776397705 | CLS Loss: 0.020185498520731926\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 4.176428318023682 | KNN Loss: 4.162036418914795 | CLS Loss: 0.014391849748790264\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 4.216803550720215 | KNN Loss: 4.17242956161499 | CLS Loss: 0.044374048709869385\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 4.156102657318115 | KNN Loss: 4.152792930603027 | CLS Loss: 0.0033095686230808496\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 4.16155481338501 | KNN Loss: 4.15447998046875 | CLS Loss: 0.007074874825775623\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 4.149419784545898 | KNN Loss: 4.143124580383301 | CLS Loss: 0.006294978316873312\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 4.169740676879883 | KNN Loss: 4.149325847625732 | CLS Loss: 0.02041495591402054\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 4.18450403213501 | KNN Loss: 4.174252986907959 | CLS Loss: 0.01025120448321104\n",
      "Epoch: 085, Loss: 4.1788, Train: 0.9967, Valid: 0.9875, Best: 0.9878\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 4.184994220733643 | KNN Loss: 4.173877239227295 | CLS Loss: 0.011116822250187397\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 4.1671624183654785 | KNN Loss: 4.1591033935546875 | CLS Loss: 0.008059064857661724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 4.153111457824707 | KNN Loss: 4.150784969329834 | CLS Loss: 0.0023263453040271997\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 4.211200714111328 | KNN Loss: 4.2052083015441895 | CLS Loss: 0.005992430727928877\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 4.188557147979736 | KNN Loss: 4.170945644378662 | CLS Loss: 0.017611712217330933\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 4.149726867675781 | KNN Loss: 4.135758399963379 | CLS Loss: 0.013968263752758503\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 4.198293685913086 | KNN Loss: 4.182538032531738 | CLS Loss: 0.015755776315927505\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 4.164061069488525 | KNN Loss: 4.139739036560059 | CLS Loss: 0.02432223968207836\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 4.149442672729492 | KNN Loss: 4.140484809875488 | CLS Loss: 0.008958091959357262\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 4.155911445617676 | KNN Loss: 4.146936893463135 | CLS Loss: 0.008974441327154636\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 4.17742395401001 | KNN Loss: 4.163337707519531 | CLS Loss: 0.014086154289543629\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 4.190559387207031 | KNN Loss: 4.165095806121826 | CLS Loss: 0.025463415309786797\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 4.186779022216797 | KNN Loss: 4.18192720413208 | CLS Loss: 0.00485198013484478\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 4.170151233673096 | KNN Loss: 4.159946918487549 | CLS Loss: 0.010204318910837173\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 4.195965766906738 | KNN Loss: 4.181880474090576 | CLS Loss: 0.014085416682064533\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 4.171440601348877 | KNN Loss: 4.163841247558594 | CLS Loss: 0.007599234580993652\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 4.148266792297363 | KNN Loss: 4.140342712402344 | CLS Loss: 0.007923928089439869\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 4.172053337097168 | KNN Loss: 4.154528617858887 | CLS Loss: 0.017524829134345055\n",
      "Epoch: 086, Loss: 4.1780, Train: 0.9963, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 4.1932244300842285 | KNN Loss: 4.186839580535889 | CLS Loss: 0.006384895648807287\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 4.128680229187012 | KNN Loss: 4.125175476074219 | CLS Loss: 0.003504558000713587\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 4.220898628234863 | KNN Loss: 4.205389499664307 | CLS Loss: 0.015509325079619884\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 4.187190055847168 | KNN Loss: 4.153357982635498 | CLS Loss: 0.0338318757712841\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 4.132153034210205 | KNN Loss: 4.127317428588867 | CLS Loss: 0.0048356386832892895\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 4.1748456954956055 | KNN Loss: 4.168214797973633 | CLS Loss: 0.0066307708621025085\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 4.187983989715576 | KNN Loss: 4.184523582458496 | CLS Loss: 0.0034603329841047525\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 4.135838985443115 | KNN Loss: 4.13095760345459 | CLS Loss: 0.004881191998720169\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 4.175736427307129 | KNN Loss: 4.152895450592041 | CLS Loss: 0.022840755060315132\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 4.207329273223877 | KNN Loss: 4.184647083282471 | CLS Loss: 0.022682340815663338\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 4.217637538909912 | KNN Loss: 4.213039398193359 | CLS Loss: 0.00459813280031085\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 4.1956892013549805 | KNN Loss: 4.167177200317383 | CLS Loss: 0.028512049466371536\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 4.1828155517578125 | KNN Loss: 4.171455383300781 | CLS Loss: 0.011360053904354572\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 4.12867546081543 | KNN Loss: 4.125711917877197 | CLS Loss: 0.002963748760521412\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 4.170193195343018 | KNN Loss: 4.159775257110596 | CLS Loss: 0.010418010875582695\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 4.208191394805908 | KNN Loss: 4.182064533233643 | CLS Loss: 0.0261269249022007\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 4.178725242614746 | KNN Loss: 4.162474632263184 | CLS Loss: 0.016250479966402054\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 4.222171783447266 | KNN Loss: 4.208720684051514 | CLS Loss: 0.013450881466269493\n",
      "Epoch: 087, Loss: 4.1761, Train: 0.9966, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 4.1663408279418945 | KNN Loss: 4.1513285636901855 | CLS Loss: 0.015012246556580067\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 4.136226177215576 | KNN Loss: 4.132049083709717 | CLS Loss: 0.004177005961537361\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 4.1424102783203125 | KNN Loss: 4.134203910827637 | CLS Loss: 0.008206598460674286\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 4.136504650115967 | KNN Loss: 4.1346964836120605 | CLS Loss: 0.0018083625473082066\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 4.139909267425537 | KNN Loss: 4.1249680519104 | CLS Loss: 0.014941273257136345\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 4.195226192474365 | KNN Loss: 4.186803817749023 | CLS Loss: 0.008422142826020718\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 4.1500091552734375 | KNN Loss: 4.129913330078125 | CLS Loss: 0.02009568177163601\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 4.191749095916748 | KNN Loss: 4.168130397796631 | CLS Loss: 0.02361890859901905\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 4.1978840827941895 | KNN Loss: 4.178332805633545 | CLS Loss: 0.019551508128643036\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 4.18227481842041 | KNN Loss: 4.165390968322754 | CLS Loss: 0.01688387617468834\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 4.180987358093262 | KNN Loss: 4.166604995727539 | CLS Loss: 0.01438238937407732\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 4.222291946411133 | KNN Loss: 4.218182563781738 | CLS Loss: 0.00410958519205451\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 4.167695999145508 | KNN Loss: 4.15336799621582 | CLS Loss: 0.014327946119010448\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 4.173290729522705 | KNN Loss: 4.1695075035095215 | CLS Loss: 0.0037833082024008036\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 4.169389724731445 | KNN Loss: 4.162833213806152 | CLS Loss: 0.00655630836263299\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 4.194468975067139 | KNN Loss: 4.18222188949585 | CLS Loss: 0.012247303500771523\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 4.220010280609131 | KNN Loss: 4.214594841003418 | CLS Loss: 0.005415407940745354\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 4.1876935958862305 | KNN Loss: 4.183859825134277 | CLS Loss: 0.0038339458405971527\n",
      "Epoch: 088, Loss: 4.1782, Train: 0.9970, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 4.159397602081299 | KNN Loss: 4.156277656555176 | CLS Loss: 0.0031197676435112953\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 4.171903610229492 | KNN Loss: 4.151054382324219 | CLS Loss: 0.020849447697401047\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 4.135075569152832 | KNN Loss: 4.118734359741211 | CLS Loss: 0.01634136028587818\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 4.160885810852051 | KNN Loss: 4.150867938995361 | CLS Loss: 0.010017793625593185\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 4.244046688079834 | KNN Loss: 4.218906402587891 | CLS Loss: 0.025140132755041122\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 4.152180194854736 | KNN Loss: 4.145652770996094 | CLS Loss: 0.006527386140078306\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 4.205212116241455 | KNN Loss: 4.187859535217285 | CLS Loss: 0.017352454364299774\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 4.163094520568848 | KNN Loss: 4.1595988273620605 | CLS Loss: 0.0034958277828991413\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 4.221331596374512 | KNN Loss: 4.213691711425781 | CLS Loss: 0.00763977924361825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 4.1525468826293945 | KNN Loss: 4.1374945640563965 | CLS Loss: 0.015052217990159988\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 4.18501091003418 | KNN Loss: 4.164855003356934 | CLS Loss: 0.020155927166342735\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 4.166687488555908 | KNN Loss: 4.149980545043945 | CLS Loss: 0.01670677773654461\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 4.208606719970703 | KNN Loss: 4.180209159851074 | CLS Loss: 0.028397560119628906\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 4.2185540199279785 | KNN Loss: 4.210280418395996 | CLS Loss: 0.008273464627563953\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 4.214430809020996 | KNN Loss: 4.202151298522949 | CLS Loss: 0.012279417365789413\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 4.182023048400879 | KNN Loss: 4.167685031890869 | CLS Loss: 0.014338172972202301\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 4.17145299911499 | KNN Loss: 4.143521785736084 | CLS Loss: 0.02793111652135849\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 4.160270690917969 | KNN Loss: 4.154552459716797 | CLS Loss: 0.00571801932528615\n",
      "Epoch: 089, Loss: 4.1784, Train: 0.9970, Valid: 0.9875, Best: 0.9878\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 4.154632091522217 | KNN Loss: 4.148737907409668 | CLS Loss: 0.005894151516258717\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 4.174392223358154 | KNN Loss: 4.169342517852783 | CLS Loss: 0.005049918312579393\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 4.190350532531738 | KNN Loss: 4.168203353881836 | CLS Loss: 0.02214733324944973\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 4.140889644622803 | KNN Loss: 4.137548446655273 | CLS Loss: 0.0033414247445762157\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 4.189310550689697 | KNN Loss: 4.162335395812988 | CLS Loss: 0.026975180953741074\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 4.183482646942139 | KNN Loss: 4.169567584991455 | CLS Loss: 0.013915170915424824\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 4.150699615478516 | KNN Loss: 4.147353649139404 | CLS Loss: 0.0033458545804023743\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 4.136463642120361 | KNN Loss: 4.130498886108398 | CLS Loss: 0.005964776035398245\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 4.146946430206299 | KNN Loss: 4.130858898162842 | CLS Loss: 0.016087641939520836\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 4.165049076080322 | KNN Loss: 4.1444196701049805 | CLS Loss: 0.020629171282052994\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 4.178002834320068 | KNN Loss: 4.172195911407471 | CLS Loss: 0.0058068931102752686\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 4.173453330993652 | KNN Loss: 4.161689281463623 | CLS Loss: 0.011763918213546276\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 4.166114807128906 | KNN Loss: 4.15049409866333 | CLS Loss: 0.015620660036802292\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 4.138000965118408 | KNN Loss: 4.134454727172852 | CLS Loss: 0.003546444233506918\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 4.168557643890381 | KNN Loss: 4.144507884979248 | CLS Loss: 0.02404962107539177\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 4.18446159362793 | KNN Loss: 4.1487627029418945 | CLS Loss: 0.03569898381829262\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 4.184220790863037 | KNN Loss: 4.170618534088135 | CLS Loss: 0.013602212071418762\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 4.215275764465332 | KNN Loss: 4.198873519897461 | CLS Loss: 0.01640211045742035\n",
      "Epoch: 090, Loss: 4.1748, Train: 0.9944, Valid: 0.9858, Best: 0.9878\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 4.196054458618164 | KNN Loss: 4.187758922576904 | CLS Loss: 0.00829559750854969\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 4.182688236236572 | KNN Loss: 4.166046142578125 | CLS Loss: 0.01664193905889988\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 4.160012722015381 | KNN Loss: 4.149559497833252 | CLS Loss: 0.010453400202095509\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 4.16206169128418 | KNN Loss: 4.153542995452881 | CLS Loss: 0.00851851049810648\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 4.188148021697998 | KNN Loss: 4.180838584899902 | CLS Loss: 0.0073094177059829235\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 4.208874702453613 | KNN Loss: 4.192360877990723 | CLS Loss: 0.016513876616954803\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 4.16013240814209 | KNN Loss: 4.153782367706299 | CLS Loss: 0.006350107956677675\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 4.160359859466553 | KNN Loss: 4.144375324249268 | CLS Loss: 0.015984388068318367\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 4.170640468597412 | KNN Loss: 4.160149574279785 | CLS Loss: 0.010490940883755684\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 4.13536262512207 | KNN Loss: 4.1312384605407715 | CLS Loss: 0.004124166909605265\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 4.181225299835205 | KNN Loss: 4.158551216125488 | CLS Loss: 0.022673912346363068\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 4.204772472381592 | KNN Loss: 4.186130523681641 | CLS Loss: 0.018641969189047813\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 4.2342658042907715 | KNN Loss: 4.211865425109863 | CLS Loss: 0.02240016497671604\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 4.152974605560303 | KNN Loss: 4.151005744934082 | CLS Loss: 0.0019688487518578768\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 4.135554313659668 | KNN Loss: 4.130601406097412 | CLS Loss: 0.004953053779900074\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 4.142655372619629 | KNN Loss: 4.139456748962402 | CLS Loss: 0.0031984003726392984\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 4.131426811218262 | KNN Loss: 4.128182888031006 | CLS Loss: 0.003244068007916212\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 4.159820556640625 | KNN Loss: 4.144188404083252 | CLS Loss: 0.015632042661309242\n",
      "Epoch: 091, Loss: 4.1741, Train: 0.9975, Valid: 0.9873, Best: 0.9878\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 4.15037202835083 | KNN Loss: 4.148196220397949 | CLS Loss: 0.0021760377567261457\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 4.145885467529297 | KNN Loss: 4.1389360427856445 | CLS Loss: 0.006949212867766619\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 4.135226249694824 | KNN Loss: 4.126610279083252 | CLS Loss: 0.008615751750767231\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 4.145832061767578 | KNN Loss: 4.132987022399902 | CLS Loss: 0.012844965793192387\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 4.1897292137146 | KNN Loss: 4.165089130401611 | CLS Loss: 0.024640027433633804\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 4.136330604553223 | KNN Loss: 4.134823799133301 | CLS Loss: 0.0015065745683386922\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 4.192056179046631 | KNN Loss: 4.166966438293457 | CLS Loss: 0.02508985623717308\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 4.1676249504089355 | KNN Loss: 4.1550188064575195 | CLS Loss: 0.01260637491941452\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 4.198703765869141 | KNN Loss: 4.176377296447754 | CLS Loss: 0.02232654206454754\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 4.22766637802124 | KNN Loss: 4.200456142425537 | CLS Loss: 0.027210261672735214\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 4.153274059295654 | KNN Loss: 4.140314102172852 | CLS Loss: 0.012960151769220829\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 4.175403594970703 | KNN Loss: 4.157240390777588 | CLS Loss: 0.01816306635737419\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 4.146319389343262 | KNN Loss: 4.142425060272217 | CLS Loss: 0.0038945642299950123\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 4.205864429473877 | KNN Loss: 4.183237552642822 | CLS Loss: 0.022626791149377823\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 4.149368762969971 | KNN Loss: 4.14162015914917 | CLS Loss: 0.007748735602945089\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 4.170450210571289 | KNN Loss: 4.14707088470459 | CLS Loss: 0.0233791321516037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 4.180145740509033 | KNN Loss: 4.1617536544799805 | CLS Loss: 0.01839185319840908\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 4.194956302642822 | KNN Loss: 4.1919379234313965 | CLS Loss: 0.0030185317154973745\n",
      "Epoch: 092, Loss: 4.1729, Train: 0.9963, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 4.200282573699951 | KNN Loss: 4.175217628479004 | CLS Loss: 0.025065094232559204\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 4.13863468170166 | KNN Loss: 4.134592533111572 | CLS Loss: 0.0040422710590064526\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 4.167498588562012 | KNN Loss: 4.149827003479004 | CLS Loss: 0.017671680077910423\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 4.143689155578613 | KNN Loss: 4.1400861740112305 | CLS Loss: 0.0036030588671565056\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 4.132369041442871 | KNN Loss: 4.126833915710449 | CLS Loss: 0.005535160191357136\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 4.158443450927734 | KNN Loss: 4.150720119476318 | CLS Loss: 0.007723317015916109\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 4.137667655944824 | KNN Loss: 4.131059646606445 | CLS Loss: 0.006607881281524897\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 4.177826881408691 | KNN Loss: 4.164150238037109 | CLS Loss: 0.013676508329808712\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 4.184001922607422 | KNN Loss: 4.174532890319824 | CLS Loss: 0.009469130076467991\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 4.197732925415039 | KNN Loss: 4.152334690093994 | CLS Loss: 0.045398466289043427\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 4.172608375549316 | KNN Loss: 4.165862560272217 | CLS Loss: 0.006745670456439257\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 4.196243762969971 | KNN Loss: 4.183614253997803 | CLS Loss: 0.012629613280296326\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 4.154326438903809 | KNN Loss: 4.134781837463379 | CLS Loss: 0.01954447291791439\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 4.183219909667969 | KNN Loss: 4.169793605804443 | CLS Loss: 0.013426242396235466\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 4.168991565704346 | KNN Loss: 4.159210205078125 | CLS Loss: 0.009781251661479473\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 4.188932418823242 | KNN Loss: 4.165553569793701 | CLS Loss: 0.02337903156876564\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 4.181258201599121 | KNN Loss: 4.1617536544799805 | CLS Loss: 0.01950431615114212\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 4.191627502441406 | KNN Loss: 4.175380706787109 | CLS Loss: 0.016246914863586426\n",
      "Epoch: 093, Loss: 4.1714, Train: 0.9965, Valid: 0.9866, Best: 0.9878\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 4.140284538269043 | KNN Loss: 4.136935234069824 | CLS Loss: 0.0033494301605969667\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 4.158339977264404 | KNN Loss: 4.152195453643799 | CLS Loss: 0.006144437938928604\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 4.152693748474121 | KNN Loss: 4.148836135864258 | CLS Loss: 0.003857484320178628\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 4.168338775634766 | KNN Loss: 4.141453742980957 | CLS Loss: 0.026885032653808594\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 4.182682037353516 | KNN Loss: 4.17325496673584 | CLS Loss: 0.009426849894225597\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 4.198927402496338 | KNN Loss: 4.184854030609131 | CLS Loss: 0.014073532074689865\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 4.18773889541626 | KNN Loss: 4.171475410461426 | CLS Loss: 0.01626358926296234\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 4.237812519073486 | KNN Loss: 4.205992221832275 | CLS Loss: 0.03182027116417885\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 4.170400619506836 | KNN Loss: 4.1334686279296875 | CLS Loss: 0.0369318388402462\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 4.174459934234619 | KNN Loss: 4.160362243652344 | CLS Loss: 0.014097736217081547\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 4.178137302398682 | KNN Loss: 4.172126293182373 | CLS Loss: 0.006011071149259806\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 4.192749500274658 | KNN Loss: 4.1676177978515625 | CLS Loss: 0.025131583213806152\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 4.154879093170166 | KNN Loss: 4.144773006439209 | CLS Loss: 0.010105947032570839\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 4.163738250732422 | KNN Loss: 4.152572154998779 | CLS Loss: 0.011166073381900787\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 4.165780544281006 | KNN Loss: 4.156317710876465 | CLS Loss: 0.009462953545153141\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 4.136083126068115 | KNN Loss: 4.132871627807617 | CLS Loss: 0.0032113229390233755\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 4.195590496063232 | KNN Loss: 4.183718681335449 | CLS Loss: 0.011871959082782269\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 4.173067092895508 | KNN Loss: 4.157431125640869 | CLS Loss: 0.01563594490289688\n",
      "Epoch: 094, Loss: 4.1735, Train: 0.9951, Valid: 0.9846, Best: 0.9878\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 4.166945457458496 | KNN Loss: 4.15759801864624 | CLS Loss: 0.009347348473966122\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 4.166837215423584 | KNN Loss: 4.1591901779174805 | CLS Loss: 0.007646952290087938\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 4.168759346008301 | KNN Loss: 4.163774490356445 | CLS Loss: 0.004984977189451456\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 4.160672187805176 | KNN Loss: 4.141238212585449 | CLS Loss: 0.01943378336727619\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 4.168867111206055 | KNN Loss: 4.159939765930176 | CLS Loss: 0.00892723724246025\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 4.227948188781738 | KNN Loss: 4.217955589294434 | CLS Loss: 0.00999260600656271\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 4.1823625564575195 | KNN Loss: 4.16064453125 | CLS Loss: 0.021718250587582588\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 4.193857669830322 | KNN Loss: 4.185059070587158 | CLS Loss: 0.008798486553132534\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 4.202523708343506 | KNN Loss: 4.1872735023498535 | CLS Loss: 0.015250402502715588\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 4.137632369995117 | KNN Loss: 4.134857654571533 | CLS Loss: 0.0027746856212615967\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 4.138493537902832 | KNN Loss: 4.12988805770874 | CLS Loss: 0.008605645969510078\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 4.168591022491455 | KNN Loss: 4.156987190246582 | CLS Loss: 0.011603723280131817\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 4.148024082183838 | KNN Loss: 4.143584728240967 | CLS Loss: 0.004439348354935646\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 4.1550116539001465 | KNN Loss: 4.1417717933654785 | CLS Loss: 0.013240017928183079\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 4.182775497436523 | KNN Loss: 4.1799750328063965 | CLS Loss: 0.002800465328618884\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 4.1693949699401855 | KNN Loss: 4.166738986968994 | CLS Loss: 0.0026560616679489613\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 4.131930351257324 | KNN Loss: 4.125296115875244 | CLS Loss: 0.006634376011788845\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 4.141206741333008 | KNN Loss: 4.137670516967773 | CLS Loss: 0.003536290256306529\n",
      "Epoch: 095, Loss: 4.1742, Train: 0.9971, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 4.199728965759277 | KNN Loss: 4.1791815757751465 | CLS Loss: 0.02054738625884056\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 4.162211894989014 | KNN Loss: 4.1573028564453125 | CLS Loss: 0.004909177776426077\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 4.143337726593018 | KNN Loss: 4.13460111618042 | CLS Loss: 0.00873645767569542\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 4.147456169128418 | KNN Loss: 4.146128177642822 | CLS Loss: 0.0013278218684718013\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 4.186278820037842 | KNN Loss: 4.183380126953125 | CLS Loss: 0.0028984902892261744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 4.188086986541748 | KNN Loss: 4.171458721160889 | CLS Loss: 0.01662849821150303\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 4.154277324676514 | KNN Loss: 4.1363911628723145 | CLS Loss: 0.017885973677039146\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 4.154818534851074 | KNN Loss: 4.14848518371582 | CLS Loss: 0.006333326920866966\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 4.169034481048584 | KNN Loss: 4.16160249710083 | CLS Loss: 0.007432049140334129\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 4.147444248199463 | KNN Loss: 4.139397144317627 | CLS Loss: 0.008047022856771946\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 4.214555740356445 | KNN Loss: 4.159028053283691 | CLS Loss: 0.05552755668759346\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 4.18003511428833 | KNN Loss: 4.1660075187683105 | CLS Loss: 0.014027445577085018\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 4.181146144866943 | KNN Loss: 4.16917610168457 | CLS Loss: 0.011970017105340958\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 4.158448696136475 | KNN Loss: 4.142028331756592 | CLS Loss: 0.016420338302850723\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 4.157132625579834 | KNN Loss: 4.145318031311035 | CLS Loss: 0.011814367026090622\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 4.16439151763916 | KNN Loss: 4.148606300354004 | CLS Loss: 0.015785112977027893\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 4.2019147872924805 | KNN Loss: 4.180360317230225 | CLS Loss: 0.021554624661803246\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 4.1891937255859375 | KNN Loss: 4.172304630279541 | CLS Loss: 0.0168891791254282\n",
      "Epoch: 096, Loss: 4.1678, Train: 0.9969, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 4.151857376098633 | KNN Loss: 4.146420001983643 | CLS Loss: 0.005437610205262899\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 4.189200401306152 | KNN Loss: 4.167440414428711 | CLS Loss: 0.02176002226769924\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 4.173271179199219 | KNN Loss: 4.165506362915039 | CLS Loss: 0.007764898240566254\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 4.1714253425598145 | KNN Loss: 4.163195610046387 | CLS Loss: 0.008229900151491165\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 4.174449920654297 | KNN Loss: 4.168009281158447 | CLS Loss: 0.006440723780542612\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 4.154344081878662 | KNN Loss: 4.140151023864746 | CLS Loss: 0.014192989096045494\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 4.207475185394287 | KNN Loss: 4.201487064361572 | CLS Loss: 0.005987920798361301\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 4.147433280944824 | KNN Loss: 4.136519908905029 | CLS Loss: 0.010913415811955929\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 4.151521682739258 | KNN Loss: 4.144383430480957 | CLS Loss: 0.007138200104236603\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 4.185174942016602 | KNN Loss: 4.174465179443359 | CLS Loss: 0.010709647089242935\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 4.1862006187438965 | KNN Loss: 4.168557167053223 | CLS Loss: 0.017643222585320473\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 4.174319744110107 | KNN Loss: 4.162379264831543 | CLS Loss: 0.011940348893404007\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 4.18256950378418 | KNN Loss: 4.16276216506958 | CLS Loss: 0.019807152450084686\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 4.144580841064453 | KNN Loss: 4.131566047668457 | CLS Loss: 0.013014917261898518\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 4.186473846435547 | KNN Loss: 4.176584243774414 | CLS Loss: 0.009889720007777214\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 4.185082912445068 | KNN Loss: 4.17193603515625 | CLS Loss: 0.013146826066076756\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 4.157001495361328 | KNN Loss: 4.149495601654053 | CLS Loss: 0.007505707908421755\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 4.169189453125 | KNN Loss: 4.158507347106934 | CLS Loss: 0.010682312771677971\n",
      "Epoch: 097, Loss: 4.1683, Train: 0.9962, Valid: 0.9852, Best: 0.9878\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 4.181336402893066 | KNN Loss: 4.171402454376221 | CLS Loss: 0.00993412733078003\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 4.167256832122803 | KNN Loss: 4.1636810302734375 | CLS Loss: 0.003576017217710614\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 4.1796064376831055 | KNN Loss: 4.1735334396362305 | CLS Loss: 0.006072901654988527\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 4.158479690551758 | KNN Loss: 4.1489691734313965 | CLS Loss: 0.009510302916169167\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 4.195868492126465 | KNN Loss: 4.182300090789795 | CLS Loss: 0.013568543829023838\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 4.173130989074707 | KNN Loss: 4.164309978485107 | CLS Loss: 0.008820963092148304\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 4.163674354553223 | KNN Loss: 4.153247833251953 | CLS Loss: 0.010426490567624569\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 4.113823890686035 | KNN Loss: 4.108546733856201 | CLS Loss: 0.005277133546769619\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 4.172277927398682 | KNN Loss: 4.15951681137085 | CLS Loss: 0.012761161662638187\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 4.1591596603393555 | KNN Loss: 4.150171756744385 | CLS Loss: 0.00898777600377798\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 4.121213436126709 | KNN Loss: 4.120363712310791 | CLS Loss: 0.000849753268994391\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 4.159709453582764 | KNN Loss: 4.148205757141113 | CLS Loss: 0.011503569781780243\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 4.197445869445801 | KNN Loss: 4.194850921630859 | CLS Loss: 0.002594954101368785\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 4.138115406036377 | KNN Loss: 4.131247520446777 | CLS Loss: 0.006868122611194849\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 4.183228492736816 | KNN Loss: 4.171149730682373 | CLS Loss: 0.012078625150024891\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 4.18364953994751 | KNN Loss: 4.166165351867676 | CLS Loss: 0.017484234645962715\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 4.169824123382568 | KNN Loss: 4.148412227630615 | CLS Loss: 0.02141173556447029\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 4.193515777587891 | KNN Loss: 4.17921257019043 | CLS Loss: 0.014303280040621758\n",
      "Epoch: 098, Loss: 4.1694, Train: 0.9959, Valid: 0.9874, Best: 0.9878\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 4.227753162384033 | KNN Loss: 4.209374904632568 | CLS Loss: 0.01837816834449768\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 4.166040897369385 | KNN Loss: 4.154370307922363 | CLS Loss: 0.011670640669763088\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 4.157907962799072 | KNN Loss: 4.150381565093994 | CLS Loss: 0.00752658536657691\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 4.164126396179199 | KNN Loss: 4.139498233795166 | CLS Loss: 0.02462804690003395\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 4.145505428314209 | KNN Loss: 4.137720584869385 | CLS Loss: 0.007785051129758358\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 4.1740899085998535 | KNN Loss: 4.148983001708984 | CLS Loss: 0.02510697953402996\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 4.1649489402771 | KNN Loss: 4.161239147186279 | CLS Loss: 0.0037100124172866344\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 4.191843032836914 | KNN Loss: 4.167238235473633 | CLS Loss: 0.02460472658276558\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 4.167166709899902 | KNN Loss: 4.152698040008545 | CLS Loss: 0.01446868572384119\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 4.181460380554199 | KNN Loss: 4.163299083709717 | CLS Loss: 0.0181612316519022\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 4.179050445556641 | KNN Loss: 4.145328998565674 | CLS Loss: 0.03372139856219292\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 4.188873767852783 | KNN Loss: 4.175118446350098 | CLS Loss: 0.01375550962984562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 4.182658672332764 | KNN Loss: 4.172940254211426 | CLS Loss: 0.009718348272144794\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 4.150428295135498 | KNN Loss: 4.142909049987793 | CLS Loss: 0.007519348058849573\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 4.1450347900390625 | KNN Loss: 4.140814781188965 | CLS Loss: 0.004220094531774521\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 4.186178207397461 | KNN Loss: 4.180509090423584 | CLS Loss: 0.00566928181797266\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 4.161584854125977 | KNN Loss: 4.156813621520996 | CLS Loss: 0.0047710672952234745\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 4.174562931060791 | KNN Loss: 4.171230316162109 | CLS Loss: 0.0033327247947454453\n",
      "Epoch: 099, Loss: 4.1704, Train: 0.9962, Valid: 0.9871, Best: 0.9878\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 4.171031475067139 | KNN Loss: 4.1543288230896 | CLS Loss: 0.01670273393392563\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 4.183075904846191 | KNN Loss: 4.17228364944458 | CLS Loss: 0.010792387649416924\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 4.162484645843506 | KNN Loss: 4.158630847930908 | CLS Loss: 0.003853669622913003\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 4.134145736694336 | KNN Loss: 4.129727840423584 | CLS Loss: 0.004418037366122007\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 4.164580345153809 | KNN Loss: 4.161870956420898 | CLS Loss: 0.002709375461563468\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 4.188117980957031 | KNN Loss: 4.1774582862854 | CLS Loss: 0.010659714229404926\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 4.167538166046143 | KNN Loss: 4.153055191040039 | CLS Loss: 0.014482839033007622\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 4.129312038421631 | KNN Loss: 4.127440929412842 | CLS Loss: 0.001871265354566276\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 4.222724437713623 | KNN Loss: 4.198300838470459 | CLS Loss: 0.0244233887642622\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 4.175475120544434 | KNN Loss: 4.131746768951416 | CLS Loss: 0.043728116899728775\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 4.214911460876465 | KNN Loss: 4.2045087814331055 | CLS Loss: 0.010402826592326164\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 4.186712741851807 | KNN Loss: 4.159259796142578 | CLS Loss: 0.027452794834971428\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 4.17632532119751 | KNN Loss: 4.156905651092529 | CLS Loss: 0.019419550895690918\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 4.151647090911865 | KNN Loss: 4.141692638397217 | CLS Loss: 0.009954432025551796\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 4.1723856925964355 | KNN Loss: 4.145079135894775 | CLS Loss: 0.027306631207466125\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 4.188704013824463 | KNN Loss: 4.169511318206787 | CLS Loss: 0.019192755222320557\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 4.182382106781006 | KNN Loss: 4.170726776123047 | CLS Loss: 0.011655124835669994\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 4.195488452911377 | KNN Loss: 4.1790080070495605 | CLS Loss: 0.01648050546646118\n",
      "Epoch: 100, Loss: 4.1740, Train: 0.9968, Valid: 0.9870, Best: 0.9878\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 4.1625285148620605 | KNN Loss: 4.139948844909668 | CLS Loss: 0.022579891607165337\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 4.1886210441589355 | KNN Loss: 4.178282737731934 | CLS Loss: 0.01033839862793684\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 4.1778564453125 | KNN Loss: 4.175000190734863 | CLS Loss: 0.002856374252587557\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 4.188891410827637 | KNN Loss: 4.169743061065674 | CLS Loss: 0.019148414954543114\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 4.198932647705078 | KNN Loss: 4.172610282897949 | CLS Loss: 0.026322271674871445\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 4.177754878997803 | KNN Loss: 4.1541571617126465 | CLS Loss: 0.02359790913760662\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 4.163851737976074 | KNN Loss: 4.154909610748291 | CLS Loss: 0.008942041546106339\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 4.1644287109375 | KNN Loss: 4.159038066864014 | CLS Loss: 0.005390849430114031\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 4.156468391418457 | KNN Loss: 4.1514410972595215 | CLS Loss: 0.0050272331573069096\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 4.202508926391602 | KNN Loss: 4.18951416015625 | CLS Loss: 0.012994862161576748\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 4.177207946777344 | KNN Loss: 4.173884868621826 | CLS Loss: 0.0033229191321879625\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 4.188437461853027 | KNN Loss: 4.16872501373291 | CLS Loss: 0.019712258130311966\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 4.151055335998535 | KNN Loss: 4.142941474914551 | CLS Loss: 0.008113681338727474\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 4.167396068572998 | KNN Loss: 4.162851810455322 | CLS Loss: 0.00454446068033576\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 4.162392616271973 | KNN Loss: 4.158740043640137 | CLS Loss: 0.003652637591585517\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 4.169486045837402 | KNN Loss: 4.159351348876953 | CLS Loss: 0.01013448741286993\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 4.175125598907471 | KNN Loss: 4.167341232299805 | CLS Loss: 0.007784194778650999\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 4.14634370803833 | KNN Loss: 4.130734443664551 | CLS Loss: 0.015609199181199074\n",
      "Epoch: 101, Loss: 4.1738, Train: 0.9969, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 4.181778907775879 | KNN Loss: 4.176619529724121 | CLS Loss: 0.005159367807209492\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 4.190735816955566 | KNN Loss: 4.1798224449157715 | CLS Loss: 0.01091340184211731\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 4.16740608215332 | KNN Loss: 4.158050060272217 | CLS Loss: 0.009356122463941574\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 4.165302276611328 | KNN Loss: 4.155357837677002 | CLS Loss: 0.009944483637809753\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 4.1559224128723145 | KNN Loss: 4.1497626304626465 | CLS Loss: 0.0061597684398293495\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 4.14654016494751 | KNN Loss: 4.142849922180176 | CLS Loss: 0.0036900262348353863\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 4.169404983520508 | KNN Loss: 4.14100980758667 | CLS Loss: 0.028395377099514008\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 4.148522853851318 | KNN Loss: 4.142653465270996 | CLS Loss: 0.005869427230209112\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 4.188172340393066 | KNN Loss: 4.176693916320801 | CLS Loss: 0.011478392407298088\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 4.176272869110107 | KNN Loss: 4.1676764488220215 | CLS Loss: 0.008596374653279781\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 4.153069019317627 | KNN Loss: 4.1477155685424805 | CLS Loss: 0.005353326443582773\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 4.172876358032227 | KNN Loss: 4.1572723388671875 | CLS Loss: 0.015604089014232159\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 4.13810396194458 | KNN Loss: 4.134093284606934 | CLS Loss: 0.00401077838614583\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 4.181797027587891 | KNN Loss: 4.160994052886963 | CLS Loss: 0.020803069695830345\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 4.129210948944092 | KNN Loss: 4.127437591552734 | CLS Loss: 0.0017732378328219056\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 4.197361469268799 | KNN Loss: 4.169590473175049 | CLS Loss: 0.027770917862653732\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 4.1785759925842285 | KNN Loss: 4.165340423583984 | CLS Loss: 0.013235410675406456\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 4.152034759521484 | KNN Loss: 4.148393630981445 | CLS Loss: 0.003640916431322694\n",
      "Epoch: 102, Loss: 4.1684, Train: 0.9958, Valid: 0.9867, Best: 0.9878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 4.172691345214844 | KNN Loss: 4.165294170379639 | CLS Loss: 0.007397236302495003\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 4.156515121459961 | KNN Loss: 4.151280403137207 | CLS Loss: 0.005234846379607916\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 4.1643967628479 | KNN Loss: 4.157748222351074 | CLS Loss: 0.006648611277341843\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 4.1371684074401855 | KNN Loss: 4.1332855224609375 | CLS Loss: 0.0038827117532491684\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 4.189187049865723 | KNN Loss: 4.182706832885742 | CLS Loss: 0.006480189971625805\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 4.200575351715088 | KNN Loss: 4.194869518280029 | CLS Loss: 0.005705840419977903\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 4.1659345626831055 | KNN Loss: 4.159405708312988 | CLS Loss: 0.006528736092150211\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 4.186144828796387 | KNN Loss: 4.177495956420898 | CLS Loss: 0.00864891055971384\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 4.159814834594727 | KNN Loss: 4.153444766998291 | CLS Loss: 0.0063702878542244434\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 4.189204216003418 | KNN Loss: 4.178410053253174 | CLS Loss: 0.010793977417051792\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 4.173006057739258 | KNN Loss: 4.140128135681152 | CLS Loss: 0.03287788853049278\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 4.1403093338012695 | KNN Loss: 4.1348042488098145 | CLS Loss: 0.005505197215825319\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 4.209115028381348 | KNN Loss: 4.200133800506592 | CLS Loss: 0.008981205523014069\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 4.156996726989746 | KNN Loss: 4.131980895996094 | CLS Loss: 0.025015829131007195\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 4.182093620300293 | KNN Loss: 4.1667561531066895 | CLS Loss: 0.015337442979216576\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 4.17720365524292 | KNN Loss: 4.162518501281738 | CLS Loss: 0.014685133472084999\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 4.165013790130615 | KNN Loss: 4.163090229034424 | CLS Loss: 0.001923740142956376\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 4.162350177764893 | KNN Loss: 4.149652481079102 | CLS Loss: 0.012697571888566017\n",
      "Epoch: 103, Loss: 4.1783, Train: 0.9967, Valid: 0.9873, Best: 0.9878\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 4.158728122711182 | KNN Loss: 4.156845569610596 | CLS Loss: 0.001882671844214201\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 4.171478748321533 | KNN Loss: 4.157070159912109 | CLS Loss: 0.014408464543521404\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 4.192291736602783 | KNN Loss: 4.17816162109375 | CLS Loss: 0.01413013692945242\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 4.2037811279296875 | KNN Loss: 4.190732002258301 | CLS Loss: 0.013049027882516384\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 4.2002668380737305 | KNN Loss: 4.185103416442871 | CLS Loss: 0.015163223259150982\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 4.214405536651611 | KNN Loss: 4.200911045074463 | CLS Loss: 0.013494262471795082\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 4.195974349975586 | KNN Loss: 4.166247844696045 | CLS Loss: 0.029726477339863777\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 4.148006916046143 | KNN Loss: 4.121830940246582 | CLS Loss: 0.026175785809755325\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 4.173137664794922 | KNN Loss: 4.159570693969727 | CLS Loss: 0.013567056506872177\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 4.188289165496826 | KNN Loss: 4.177971839904785 | CLS Loss: 0.010317323729395866\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 4.154343605041504 | KNN Loss: 4.145900726318359 | CLS Loss: 0.008442909456789494\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 4.147625923156738 | KNN Loss: 4.143162250518799 | CLS Loss: 0.00446350546553731\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9879, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5cc284e7714aa0bad5651c3f9a3ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb5a5dbc5c247a794e1fdba6d1f55f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940b1dc5a4fc41608df4f29e158a2764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0074980b76a84dc396f5061f06246fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3457738d8e3d40dd9f6b66813875a7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9344022657713216\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291593615ddf43d7bc03ee3babc97fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "Epoch: 00 | Batch: 000 / 040 | Total loss: 1.575 | Reg loss: 0.007 | Tree loss: 1.575 | Accuracy: 0.066406 | 0.07 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 01 | Batch: 000 / 040 | Total loss: 1.395 | Reg loss: 0.004 | Tree loss: 1.395 | Accuracy: 0.689453 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 02 | Batch: 000 / 040 | Total loss: 1.311 | Reg loss: 0.006 | Tree loss: 1.311 | Accuracy: 0.636719 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 03 | Batch: 000 / 040 | Total loss: 1.215 | Reg loss: 0.008 | Tree loss: 1.215 | Accuracy: 0.656250 | 0.045 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 04 | Batch: 000 / 040 | Total loss: 1.130 | Reg loss: 0.010 | Tree loss: 1.130 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 05 | Batch: 000 / 040 | Total loss: 1.153 | Reg loss: 0.012 | Tree loss: 1.153 | Accuracy: 0.640625 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 06 | Batch: 000 / 040 | Total loss: 1.044 | Reg loss: 0.013 | Tree loss: 1.044 | Accuracy: 0.689453 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 07 | Batch: 000 / 040 | Total loss: 1.033 | Reg loss: 0.014 | Tree loss: 1.033 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 08 | Batch: 000 / 040 | Total loss: 1.019 | Reg loss: 0.015 | Tree loss: 1.019 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 09 | Batch: 000 / 040 | Total loss: 0.948 | Reg loss: 0.016 | Tree loss: 0.948 | Accuracy: 0.703125 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 10 | Batch: 000 / 040 | Total loss: 1.022 | Reg loss: 0.017 | Tree loss: 1.022 | Accuracy: 0.652344 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 11 | Batch: 000 / 040 | Total loss: 0.963 | Reg loss: 0.017 | Tree loss: 0.963 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 12 | Batch: 000 / 040 | Total loss: 0.984 | Reg loss: 0.018 | Tree loss: 0.984 | Accuracy: 0.650391 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 13 | Batch: 000 / 040 | Total loss: 0.960 | Reg loss: 0.018 | Tree loss: 0.960 | Accuracy: 0.662109 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 14 | Batch: 000 / 040 | Total loss: 0.947 | Reg loss: 0.019 | Tree loss: 0.947 | Accuracy: 0.666016 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 15 | Batch: 000 / 040 | Total loss: 0.920 | Reg loss: 0.019 | Tree loss: 0.920 | Accuracy: 0.671875 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 16 | Batch: 000 / 040 | Total loss: 0.888 | Reg loss: 0.019 | Tree loss: 0.888 | Accuracy: 0.691406 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 17 | Batch: 000 / 040 | Total loss: 0.930 | Reg loss: 0.020 | Tree loss: 0.930 | Accuracy: 0.662109 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 18 | Batch: 000 / 040 | Total loss: 0.880 | Reg loss: 0.020 | Tree loss: 0.880 | Accuracy: 0.691406 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 19 | Batch: 000 / 040 | Total loss: 0.896 | Reg loss: 0.020 | Tree loss: 0.896 | Accuracy: 0.675781 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 20 | Batch: 000 / 040 | Total loss: 0.850 | Reg loss: 0.020 | Tree loss: 0.850 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 21 | Batch: 000 / 040 | Total loss: 0.833 | Reg loss: 0.020 | Tree loss: 0.833 | Accuracy: 0.695312 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 22 | Batch: 000 / 040 | Total loss: 0.839 | Reg loss: 0.020 | Tree loss: 0.839 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 23 | Batch: 000 / 040 | Total loss: 0.893 | Reg loss: 0.020 | Tree loss: 0.893 | Accuracy: 0.656250 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 24 | Batch: 000 / 040 | Total loss: 0.867 | Reg loss: 0.020 | Tree loss: 0.867 | Accuracy: 0.654297 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 25 | Batch: 000 / 040 | Total loss: 0.829 | Reg loss: 0.020 | Tree loss: 0.829 | Accuracy: 0.695312 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 26 | Batch: 000 / 040 | Total loss: 0.822 | Reg loss: 0.020 | Tree loss: 0.822 | Accuracy: 0.673828 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 27 | Batch: 000 / 040 | Total loss: 0.722 | Reg loss: 0.021 | Tree loss: 0.722 | Accuracy: 0.720703 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 28 | Batch: 000 / 040 | Total loss: 0.815 | Reg loss: 0.021 | Tree loss: 0.815 | Accuracy: 0.660156 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 29 | Batch: 000 / 040 | Total loss: 0.802 | Reg loss: 0.021 | Tree loss: 0.802 | Accuracy: 0.669922 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 30 | Batch: 000 / 040 | Total loss: 0.781 | Reg loss: 0.021 | Tree loss: 0.781 | Accuracy: 0.675781 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 31 | Batch: 000 / 040 | Total loss: 0.699 | Reg loss: 0.021 | Tree loss: 0.699 | Accuracy: 0.699219 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 32 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.021 | Tree loss: 0.678 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 33 | Batch: 000 / 040 | Total loss: 0.774 | Reg loss: 0.021 | Tree loss: 0.774 | Accuracy: 0.664062 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 34 | Batch: 000 / 040 | Total loss: 0.765 | Reg loss: 0.021 | Tree loss: 0.765 | Accuracy: 0.671875 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 35 | Batch: 000 / 040 | Total loss: 0.798 | Reg loss: 0.021 | Tree loss: 0.798 | Accuracy: 0.648438 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 36 | Batch: 000 / 040 | Total loss: 0.693 | Reg loss: 0.020 | Tree loss: 0.693 | Accuracy: 0.689453 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 37 | Batch: 000 / 040 | Total loss: 0.860 | Reg loss: 0.020 | Tree loss: 0.860 | Accuracy: 0.630859 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 38 | Batch: 000 / 040 | Total loss: 0.612 | Reg loss: 0.020 | Tree loss: 0.612 | Accuracy: 0.763672 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 39 | Batch: 000 / 040 | Total loss: 0.749 | Reg loss: 0.020 | Tree loss: 0.749 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 40 | Batch: 000 / 040 | Total loss: 0.684 | Reg loss: 0.020 | Tree loss: 0.684 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 41 | Batch: 000 / 040 | Total loss: 0.712 | Reg loss: 0.020 | Tree loss: 0.712 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 42 | Batch: 000 / 040 | Total loss: 0.719 | Reg loss: 0.020 | Tree loss: 0.719 | Accuracy: 0.687500 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 43 | Batch: 000 / 040 | Total loss: 0.669 | Reg loss: 0.020 | Tree loss: 0.669 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 44 | Batch: 000 / 040 | Total loss: 0.769 | Reg loss: 0.020 | Tree loss: 0.769 | Accuracy: 0.654297 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 45 | Batch: 000 / 040 | Total loss: 0.731 | Reg loss: 0.020 | Tree loss: 0.731 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 46 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.693359 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 47 | Batch: 000 / 040 | Total loss: 0.676 | Reg loss: 0.020 | Tree loss: 0.676 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 48 | Batch: 000 / 040 | Total loss: 0.716 | Reg loss: 0.020 | Tree loss: 0.716 | Accuracy: 0.671875 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 49 | Batch: 000 / 040 | Total loss: 0.735 | Reg loss: 0.020 | Tree loss: 0.735 | Accuracy: 0.687500 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 50 | Batch: 000 / 040 | Total loss: 0.672 | Reg loss: 0.020 | Tree loss: 0.672 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 51 | Batch: 000 / 040 | Total loss: 0.668 | Reg loss: 0.020 | Tree loss: 0.668 | Accuracy: 0.703125 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 52 | Batch: 000 / 040 | Total loss: 0.692 | Reg loss: 0.020 | Tree loss: 0.692 | Accuracy: 0.703125 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 53 | Batch: 000 / 040 | Total loss: 0.649 | Reg loss: 0.020 | Tree loss: 0.649 | Accuracy: 0.699219 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 54 | Batch: 000 / 040 | Total loss: 0.724 | Reg loss: 0.020 | Tree loss: 0.724 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 55 | Batch: 000 / 040 | Total loss: 0.700 | Reg loss: 0.020 | Tree loss: 0.700 | Accuracy: 0.679688 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 56 | Batch: 000 / 040 | Total loss: 0.692 | Reg loss: 0.020 | Tree loss: 0.692 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 57 | Batch: 000 / 040 | Total loss: 0.701 | Reg loss: 0.020 | Tree loss: 0.701 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 58 | Batch: 000 / 040 | Total loss: 0.640 | Reg loss: 0.020 | Tree loss: 0.640 | Accuracy: 0.718750 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 59 | Batch: 000 / 040 | Total loss: 0.709 | Reg loss: 0.020 | Tree loss: 0.709 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 60 | Batch: 000 / 040 | Total loss: 0.703 | Reg loss: 0.020 | Tree loss: 0.703 | Accuracy: 0.675781 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 61 | Batch: 000 / 040 | Total loss: 0.644 | Reg loss: 0.020 | Tree loss: 0.644 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 62 | Batch: 000 / 040 | Total loss: 0.689 | Reg loss: 0.020 | Tree loss: 0.689 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 63 | Batch: 000 / 040 | Total loss: 0.701 | Reg loss: 0.020 | Tree loss: 0.701 | Accuracy: 0.707031 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 64 | Batch: 000 / 040 | Total loss: 0.698 | Reg loss: 0.020 | Tree loss: 0.698 | Accuracy: 0.703125 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 65 | Batch: 000 / 040 | Total loss: 0.696 | Reg loss: 0.020 | Tree loss: 0.696 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 66 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.020 | Tree loss: 0.678 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 67 | Batch: 000 / 040 | Total loss: 0.718 | Reg loss: 0.020 | Tree loss: 0.718 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 68 | Batch: 000 / 040 | Total loss: 0.568 | Reg loss: 0.020 | Tree loss: 0.568 | Accuracy: 0.755859 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 69 | Batch: 000 / 040 | Total loss: 0.607 | Reg loss: 0.020 | Tree loss: 0.607 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 70 | Batch: 000 / 040 | Total loss: 0.708 | Reg loss: 0.020 | Tree loss: 0.708 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 71 | Batch: 000 / 040 | Total loss: 0.700 | Reg loss: 0.020 | Tree loss: 0.700 | Accuracy: 0.671875 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 72 | Batch: 000 / 040 | Total loss: 0.671 | Reg loss: 0.020 | Tree loss: 0.671 | Accuracy: 0.695312 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 73 | Batch: 000 / 040 | Total loss: 0.785 | Reg loss: 0.020 | Tree loss: 0.785 | Accuracy: 0.667969 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 74 | Batch: 000 / 040 | Total loss: 0.689 | Reg loss: 0.020 | Tree loss: 0.689 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 75 | Batch: 000 / 040 | Total loss: 0.664 | Reg loss: 0.020 | Tree loss: 0.664 | Accuracy: 0.712891 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 76 | Batch: 000 / 040 | Total loss: 0.623 | Reg loss: 0.020 | Tree loss: 0.623 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 77 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.695312 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 78 | Batch: 000 / 040 | Total loss: 0.653 | Reg loss: 0.020 | Tree loss: 0.653 | Accuracy: 0.707031 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 79 | Batch: 000 / 040 | Total loss: 0.780 | Reg loss: 0.020 | Tree loss: 0.780 | Accuracy: 0.667969 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 80 | Batch: 000 / 040 | Total loss: 0.717 | Reg loss: 0.020 | Tree loss: 0.717 | Accuracy: 0.695312 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 81 | Batch: 000 / 040 | Total loss: 0.698 | Reg loss: 0.020 | Tree loss: 0.698 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 82 | Batch: 000 / 040 | Total loss: 0.699 | Reg loss: 0.020 | Tree loss: 0.699 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 83 | Batch: 000 / 040 | Total loss: 0.644 | Reg loss: 0.020 | Tree loss: 0.644 | Accuracy: 0.720703 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 84 | Batch: 000 / 040 | Total loss: 0.692 | Reg loss: 0.020 | Tree loss: 0.692 | Accuracy: 0.681641 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 85 | Batch: 000 / 040 | Total loss: 0.701 | Reg loss: 0.020 | Tree loss: 0.701 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 86 | Batch: 000 / 040 | Total loss: 0.623 | Reg loss: 0.020 | Tree loss: 0.623 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 87 | Batch: 000 / 040 | Total loss: 0.652 | Reg loss: 0.020 | Tree loss: 0.652 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 88 | Batch: 000 / 040 | Total loss: 0.742 | Reg loss: 0.020 | Tree loss: 0.742 | Accuracy: 0.662109 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 89 | Batch: 000 / 040 | Total loss: 0.737 | Reg loss: 0.020 | Tree loss: 0.737 | Accuracy: 0.677734 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 90 | Batch: 000 / 040 | Total loss: 0.719 | Reg loss: 0.020 | Tree loss: 0.719 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 91 | Batch: 000 / 040 | Total loss: 0.704 | Reg loss: 0.020 | Tree loss: 0.704 | Accuracy: 0.699219 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 92 | Batch: 000 / 040 | Total loss: 0.701 | Reg loss: 0.020 | Tree loss: 0.701 | Accuracy: 0.693359 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 93 | Batch: 000 / 040 | Total loss: 0.693 | Reg loss: 0.020 | Tree loss: 0.693 | Accuracy: 0.687500 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 94 | Batch: 000 / 040 | Total loss: 0.706 | Reg loss: 0.020 | Tree loss: 0.706 | Accuracy: 0.691406 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 95 | Batch: 000 / 040 | Total loss: 0.698 | Reg loss: 0.020 | Tree loss: 0.698 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 96 | Batch: 000 / 040 | Total loss: 0.661 | Reg loss: 0.020 | Tree loss: 0.661 | Accuracy: 0.703125 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 97 | Batch: 000 / 040 | Total loss: 0.721 | Reg loss: 0.020 | Tree loss: 0.721 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 98 | Batch: 000 / 040 | Total loss: 0.686 | Reg loss: 0.020 | Tree loss: 0.686 | Accuracy: 0.708984 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 99 | Batch: 000 / 040 | Total loss: 0.704 | Reg loss: 0.020 | Tree loss: 0.704 | Accuracy: 0.710938 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 100 | Batch: 000 / 040 | Total loss: 0.657 | Reg loss: 0.020 | Tree loss: 0.657 | Accuracy: 0.710938 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 101 | Batch: 000 / 040 | Total loss: 0.672 | Reg loss: 0.020 | Tree loss: 0.672 | Accuracy: 0.718750 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 102 | Batch: 000 / 040 | Total loss: 0.608 | Reg loss: 0.020 | Tree loss: 0.608 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 103 | Batch: 000 / 040 | Total loss: 0.637 | Reg loss: 0.020 | Tree loss: 0.637 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 104 | Batch: 000 / 040 | Total loss: 0.621 | Reg loss: 0.020 | Tree loss: 0.621 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 105 | Batch: 000 / 040 | Total loss: 0.711 | Reg loss: 0.020 | Tree loss: 0.711 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 106 | Batch: 000 / 040 | Total loss: 0.669 | Reg loss: 0.020 | Tree loss: 0.669 | Accuracy: 0.687500 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 107 | Batch: 000 / 040 | Total loss: 0.614 | Reg loss: 0.020 | Tree loss: 0.614 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 108 | Batch: 000 / 040 | Total loss: 0.618 | Reg loss: 0.020 | Tree loss: 0.618 | Accuracy: 0.738281 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 109 | Batch: 000 / 040 | Total loss: 0.710 | Reg loss: 0.020 | Tree loss: 0.710 | Accuracy: 0.681641 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 110 | Batch: 000 / 040 | Total loss: 0.619 | Reg loss: 0.020 | Tree loss: 0.619 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 111 | Batch: 000 / 040 | Total loss: 0.668 | Reg loss: 0.020 | Tree loss: 0.668 | Accuracy: 0.695312 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 112 | Batch: 000 / 040 | Total loss: 0.749 | Reg loss: 0.020 | Tree loss: 0.749 | Accuracy: 0.666016 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 113 | Batch: 000 / 040 | Total loss: 0.666 | Reg loss: 0.020 | Tree loss: 0.666 | Accuracy: 0.691406 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 114 | Batch: 000 / 040 | Total loss: 0.646 | Reg loss: 0.020 | Tree loss: 0.646 | Accuracy: 0.707031 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 115 | Batch: 000 / 040 | Total loss: 0.684 | Reg loss: 0.020 | Tree loss: 0.684 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 116 | Batch: 000 / 040 | Total loss: 0.596 | Reg loss: 0.020 | Tree loss: 0.596 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 117 | Batch: 000 / 040 | Total loss: 0.715 | Reg loss: 0.020 | Tree loss: 0.715 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 118 | Batch: 000 / 040 | Total loss: 0.736 | Reg loss: 0.020 | Tree loss: 0.736 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 119 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 120 | Batch: 000 / 040 | Total loss: 0.712 | Reg loss: 0.020 | Tree loss: 0.712 | Accuracy: 0.687500 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 121 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.020 | Tree loss: 0.678 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 122 | Batch: 000 / 040 | Total loss: 0.725 | Reg loss: 0.020 | Tree loss: 0.725 | Accuracy: 0.687500 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 123 | Batch: 000 / 040 | Total loss: 0.702 | Reg loss: 0.020 | Tree loss: 0.702 | Accuracy: 0.689453 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 124 | Batch: 000 / 040 | Total loss: 0.696 | Reg loss: 0.020 | Tree loss: 0.696 | Accuracy: 0.714844 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 125 | Batch: 000 / 040 | Total loss: 0.636 | Reg loss: 0.020 | Tree loss: 0.636 | Accuracy: 0.699219 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 126 | Batch: 000 / 040 | Total loss: 0.705 | Reg loss: 0.020 | Tree loss: 0.705 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 127 | Batch: 000 / 040 | Total loss: 0.661 | Reg loss: 0.020 | Tree loss: 0.661 | Accuracy: 0.714844 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 128 | Batch: 000 / 040 | Total loss: 0.675 | Reg loss: 0.020 | Tree loss: 0.675 | Accuracy: 0.707031 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 129 | Batch: 000 / 040 | Total loss: 0.692 | Reg loss: 0.020 | Tree loss: 0.692 | Accuracy: 0.701172 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 130 | Batch: 000 / 040 | Total loss: 0.676 | Reg loss: 0.020 | Tree loss: 0.676 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 131 | Batch: 000 / 040 | Total loss: 0.694 | Reg loss: 0.020 | Tree loss: 0.694 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 132 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 133 | Batch: 000 / 040 | Total loss: 0.608 | Reg loss: 0.020 | Tree loss: 0.608 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 134 | Batch: 000 / 040 | Total loss: 0.711 | Reg loss: 0.020 | Tree loss: 0.711 | Accuracy: 0.693359 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 135 | Batch: 000 / 040 | Total loss: 0.609 | Reg loss: 0.020 | Tree loss: 0.609 | Accuracy: 0.744141 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 136 | Batch: 000 / 040 | Total loss: 0.744 | Reg loss: 0.020 | Tree loss: 0.744 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 137 | Batch: 000 / 040 | Total loss: 0.778 | Reg loss: 0.020 | Tree loss: 0.778 | Accuracy: 0.666016 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 138 | Batch: 000 / 040 | Total loss: 0.694 | Reg loss: 0.020 | Tree loss: 0.694 | Accuracy: 0.695312 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 139 | Batch: 000 / 040 | Total loss: 0.680 | Reg loss: 0.020 | Tree loss: 0.680 | Accuracy: 0.699219 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 140 | Batch: 000 / 040 | Total loss: 0.671 | Reg loss: 0.020 | Tree loss: 0.671 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 141 | Batch: 000 / 040 | Total loss: 0.702 | Reg loss: 0.020 | Tree loss: 0.702 | Accuracy: 0.712891 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 142 | Batch: 000 / 040 | Total loss: 0.726 | Reg loss: 0.020 | Tree loss: 0.726 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 143 | Batch: 000 / 040 | Total loss: 0.630 | Reg loss: 0.020 | Tree loss: 0.630 | Accuracy: 0.701172 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 144 | Batch: 000 / 040 | Total loss: 0.687 | Reg loss: 0.020 | Tree loss: 0.687 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 145 | Batch: 000 / 040 | Total loss: 0.684 | Reg loss: 0.020 | Tree loss: 0.684 | Accuracy: 0.667969 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 146 | Batch: 000 / 040 | Total loss: 0.614 | Reg loss: 0.020 | Tree loss: 0.614 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 147 | Batch: 000 / 040 | Total loss: 0.608 | Reg loss: 0.020 | Tree loss: 0.608 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 148 | Batch: 000 / 040 | Total loss: 0.695 | Reg loss: 0.020 | Tree loss: 0.695 | Accuracy: 0.683594 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 149 | Batch: 000 / 040 | Total loss: 0.626 | Reg loss: 0.020 | Tree loss: 0.626 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 150 | Batch: 000 / 040 | Total loss: 0.700 | Reg loss: 0.020 | Tree loss: 0.700 | Accuracy: 0.701172 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 151 | Batch: 000 / 040 | Total loss: 0.667 | Reg loss: 0.020 | Tree loss: 0.667 | Accuracy: 0.701172 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 152 | Batch: 000 / 040 | Total loss: 0.682 | Reg loss: 0.020 | Tree loss: 0.682 | Accuracy: 0.699219 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 153 | Batch: 000 / 040 | Total loss: 0.660 | Reg loss: 0.020 | Tree loss: 0.660 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 154 | Batch: 000 / 040 | Total loss: 0.685 | Reg loss: 0.020 | Tree loss: 0.685 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 155 | Batch: 000 / 040 | Total loss: 0.710 | Reg loss: 0.020 | Tree loss: 0.710 | Accuracy: 0.685547 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 156 | Batch: 000 / 040 | Total loss: 0.664 | Reg loss: 0.020 | Tree loss: 0.664 | Accuracy: 0.708984 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 157 | Batch: 000 / 040 | Total loss: 0.617 | Reg loss: 0.020 | Tree loss: 0.617 | Accuracy: 0.718750 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 158 | Batch: 000 / 040 | Total loss: 0.773 | Reg loss: 0.020 | Tree loss: 0.773 | Accuracy: 0.654297 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 159 | Batch: 000 / 040 | Total loss: 0.692 | Reg loss: 0.020 | Tree loss: 0.692 | Accuracy: 0.691406 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 160 | Batch: 000 / 040 | Total loss: 0.731 | Reg loss: 0.020 | Tree loss: 0.731 | Accuracy: 0.681641 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 161 | Batch: 000 / 040 | Total loss: 0.640 | Reg loss: 0.020 | Tree loss: 0.640 | Accuracy: 0.705078 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 162 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 163 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 164 | Batch: 000 / 040 | Total loss: 0.598 | Reg loss: 0.020 | Tree loss: 0.598 | Accuracy: 0.738281 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 165 | Batch: 000 / 040 | Total loss: 0.613 | Reg loss: 0.020 | Tree loss: 0.613 | Accuracy: 0.744141 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 166 | Batch: 000 / 040 | Total loss: 0.651 | Reg loss: 0.020 | Tree loss: 0.651 | Accuracy: 0.712891 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 167 | Batch: 000 / 040 | Total loss: 0.635 | Reg loss: 0.020 | Tree loss: 0.635 | Accuracy: 0.736328 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 168 | Batch: 000 / 040 | Total loss: 0.593 | Reg loss: 0.020 | Tree loss: 0.593 | Accuracy: 0.742188 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 169 | Batch: 000 / 040 | Total loss: 0.672 | Reg loss: 0.020 | Tree loss: 0.672 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 170 | Batch: 000 / 040 | Total loss: 0.652 | Reg loss: 0.020 | Tree loss: 0.652 | Accuracy: 0.718750 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 171 | Batch: 000 / 040 | Total loss: 0.669 | Reg loss: 0.020 | Tree loss: 0.669 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 172 | Batch: 000 / 040 | Total loss: 0.709 | Reg loss: 0.020 | Tree loss: 0.709 | Accuracy: 0.679688 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 173 | Batch: 000 / 040 | Total loss: 0.682 | Reg loss: 0.020 | Tree loss: 0.682 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 174 | Batch: 000 / 040 | Total loss: 0.648 | Reg loss: 0.020 | Tree loss: 0.648 | Accuracy: 0.740234 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 175 | Batch: 000 / 040 | Total loss: 0.658 | Reg loss: 0.020 | Tree loss: 0.658 | Accuracy: 0.730469 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 176 | Batch: 000 / 040 | Total loss: 0.573 | Reg loss: 0.020 | Tree loss: 0.573 | Accuracy: 0.765625 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 177 | Batch: 000 / 040 | Total loss: 0.593 | Reg loss: 0.020 | Tree loss: 0.593 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 178 | Batch: 000 / 040 | Total loss: 0.660 | Reg loss: 0.020 | Tree loss: 0.660 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 179 | Batch: 000 / 040 | Total loss: 0.683 | Reg loss: 0.020 | Tree loss: 0.683 | Accuracy: 0.708984 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 180 | Batch: 000 / 040 | Total loss: 0.616 | Reg loss: 0.020 | Tree loss: 0.616 | Accuracy: 0.744141 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 181 | Batch: 000 / 040 | Total loss: 0.722 | Reg loss: 0.020 | Tree loss: 0.722 | Accuracy: 0.710938 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 182 | Batch: 000 / 040 | Total loss: 0.708 | Reg loss: 0.020 | Tree loss: 0.708 | Accuracy: 0.707031 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 183 | Batch: 000 / 040 | Total loss: 0.686 | Reg loss: 0.020 | Tree loss: 0.686 | Accuracy: 0.730469 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 184 | Batch: 000 / 040 | Total loss: 0.636 | Reg loss: 0.020 | Tree loss: 0.636 | Accuracy: 0.748047 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 185 | Batch: 000 / 040 | Total loss: 0.575 | Reg loss: 0.020 | Tree loss: 0.575 | Accuracy: 0.750000 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 186 | Batch: 000 / 040 | Total loss: 0.666 | Reg loss: 0.020 | Tree loss: 0.666 | Accuracy: 0.710938 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 187 | Batch: 000 / 040 | Total loss: 0.614 | Reg loss: 0.020 | Tree loss: 0.614 | Accuracy: 0.763672 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 188 | Batch: 000 / 040 | Total loss: 0.655 | Reg loss: 0.020 | Tree loss: 0.655 | Accuracy: 0.728516 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 189 | Batch: 000 / 040 | Total loss: 0.628 | Reg loss: 0.020 | Tree loss: 0.628 | Accuracy: 0.746094 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 190 | Batch: 000 / 040 | Total loss: 0.605 | Reg loss: 0.020 | Tree loss: 0.605 | Accuracy: 0.755859 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 191 | Batch: 000 / 040 | Total loss: 0.645 | Reg loss: 0.020 | Tree loss: 0.645 | Accuracy: 0.744141 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 192 | Batch: 000 / 040 | Total loss: 0.652 | Reg loss: 0.020 | Tree loss: 0.652 | Accuracy: 0.740234 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 193 | Batch: 000 / 040 | Total loss: 0.557 | Reg loss: 0.020 | Tree loss: 0.557 | Accuracy: 0.783203 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 194 | Batch: 000 / 040 | Total loss: 0.560 | Reg loss: 0.020 | Tree loss: 0.560 | Accuracy: 0.783203 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 195 | Batch: 000 / 040 | Total loss: 0.668 | Reg loss: 0.020 | Tree loss: 0.668 | Accuracy: 0.728516 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 196 | Batch: 000 / 040 | Total loss: 0.645 | Reg loss: 0.020 | Tree loss: 0.645 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 197 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.755859 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 198 | Batch: 000 / 040 | Total loss: 0.641 | Reg loss: 0.020 | Tree loss: 0.641 | Accuracy: 0.742188 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 199 | Batch: 000 / 040 | Total loss: 0.593 | Reg loss: 0.020 | Tree loss: 0.593 | Accuracy: 0.771484 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 200 | Batch: 000 / 040 | Total loss: 0.669 | Reg loss: 0.020 | Tree loss: 0.669 | Accuracy: 0.730469 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 201 | Batch: 000 / 040 | Total loss: 0.611 | Reg loss: 0.020 | Tree loss: 0.611 | Accuracy: 0.763672 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 202 | Batch: 000 / 040 | Total loss: 0.606 | Reg loss: 0.020 | Tree loss: 0.606 | Accuracy: 0.777344 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 203 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.742188 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 204 | Batch: 000 / 040 | Total loss: 0.571 | Reg loss: 0.020 | Tree loss: 0.571 | Accuracy: 0.763672 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 205 | Batch: 000 / 040 | Total loss: 0.747 | Reg loss: 0.020 | Tree loss: 0.747 | Accuracy: 0.697266 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 206 | Batch: 000 / 040 | Total loss: 0.563 | Reg loss: 0.020 | Tree loss: 0.563 | Accuracy: 0.779297 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 207 | Batch: 000 / 040 | Total loss: 0.615 | Reg loss: 0.020 | Tree loss: 0.615 | Accuracy: 0.763672 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 208 | Batch: 000 / 040 | Total loss: 0.643 | Reg loss: 0.020 | Tree loss: 0.643 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 209 | Batch: 000 / 040 | Total loss: 0.635 | Reg loss: 0.020 | Tree loss: 0.635 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 210 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 211 | Batch: 000 / 040 | Total loss: 0.608 | Reg loss: 0.020 | Tree loss: 0.608 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 212 | Batch: 000 / 040 | Total loss: 0.677 | Reg loss: 0.020 | Tree loss: 0.677 | Accuracy: 0.708984 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 213 | Batch: 000 / 040 | Total loss: 0.658 | Reg loss: 0.020 | Tree loss: 0.658 | Accuracy: 0.746094 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 214 | Batch: 000 / 040 | Total loss: 0.664 | Reg loss: 0.020 | Tree loss: 0.664 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 215 | Batch: 000 / 040 | Total loss: 0.611 | Reg loss: 0.020 | Tree loss: 0.611 | Accuracy: 0.750000 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 216 | Batch: 000 / 040 | Total loss: 0.614 | Reg loss: 0.020 | Tree loss: 0.614 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 217 | Batch: 000 / 040 | Total loss: 0.616 | Reg loss: 0.020 | Tree loss: 0.616 | Accuracy: 0.750000 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 218 | Batch: 000 / 040 | Total loss: 0.661 | Reg loss: 0.020 | Tree loss: 0.661 | Accuracy: 0.712891 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 219 | Batch: 000 / 040 | Total loss: 0.601 | Reg loss: 0.020 | Tree loss: 0.601 | Accuracy: 0.748047 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 220 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 221 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 222 | Batch: 000 / 040 | Total loss: 0.681 | Reg loss: 0.020 | Tree loss: 0.681 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 223 | Batch: 000 / 040 | Total loss: 0.626 | Reg loss: 0.020 | Tree loss: 0.626 | Accuracy: 0.744141 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 224 | Batch: 000 / 040 | Total loss: 0.614 | Reg loss: 0.020 | Tree loss: 0.614 | Accuracy: 0.769531 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 225 | Batch: 000 / 040 | Total loss: 0.582 | Reg loss: 0.020 | Tree loss: 0.582 | Accuracy: 0.775391 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 226 | Batch: 000 / 040 | Total loss: 0.684 | Reg loss: 0.020 | Tree loss: 0.684 | Accuracy: 0.691406 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 227 | Batch: 000 / 040 | Total loss: 0.601 | Reg loss: 0.020 | Tree loss: 0.601 | Accuracy: 0.753906 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 228 | Batch: 000 / 040 | Total loss: 0.577 | Reg loss: 0.020 | Tree loss: 0.577 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 229 | Batch: 000 / 040 | Total loss: 0.669 | Reg loss: 0.020 | Tree loss: 0.669 | Accuracy: 0.742188 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 230 | Batch: 000 / 040 | Total loss: 0.636 | Reg loss: 0.020 | Tree loss: 0.636 | Accuracy: 0.750000 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 231 | Batch: 000 / 040 | Total loss: 0.660 | Reg loss: 0.020 | Tree loss: 0.660 | Accuracy: 0.740234 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 232 | Batch: 000 / 040 | Total loss: 0.581 | Reg loss: 0.020 | Tree loss: 0.581 | Accuracy: 0.759766 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 233 | Batch: 000 / 040 | Total loss: 0.622 | Reg loss: 0.020 | Tree loss: 0.622 | Accuracy: 0.738281 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 234 | Batch: 000 / 040 | Total loss: 0.615 | Reg loss: 0.020 | Tree loss: 0.615 | Accuracy: 0.738281 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 235 | Batch: 000 / 040 | Total loss: 0.671 | Reg loss: 0.020 | Tree loss: 0.671 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 236 | Batch: 000 / 040 | Total loss: 0.646 | Reg loss: 0.020 | Tree loss: 0.646 | Accuracy: 0.761719 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 237 | Batch: 000 / 040 | Total loss: 0.643 | Reg loss: 0.020 | Tree loss: 0.643 | Accuracy: 0.757812 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 238 | Batch: 000 / 040 | Total loss: 0.672 | Reg loss: 0.020 | Tree loss: 0.672 | Accuracy: 0.728516 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 239 | Batch: 000 / 040 | Total loss: 0.684 | Reg loss: 0.020 | Tree loss: 0.684 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 240 | Batch: 000 / 040 | Total loss: 0.558 | Reg loss: 0.020 | Tree loss: 0.558 | Accuracy: 0.769531 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 241 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 242 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 243 | Batch: 000 / 040 | Total loss: 0.593 | Reg loss: 0.020 | Tree loss: 0.593 | Accuracy: 0.750000 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 244 | Batch: 000 / 040 | Total loss: 0.682 | Reg loss: 0.020 | Tree loss: 0.682 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 245 | Batch: 000 / 040 | Total loss: 0.698 | Reg loss: 0.020 | Tree loss: 0.698 | Accuracy: 0.708984 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 246 | Batch: 000 / 040 | Total loss: 0.589 | Reg loss: 0.020 | Tree loss: 0.589 | Accuracy: 0.777344 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 247 | Batch: 000 / 040 | Total loss: 0.658 | Reg loss: 0.020 | Tree loss: 0.658 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 248 | Batch: 000 / 040 | Total loss: 0.641 | Reg loss: 0.020 | Tree loss: 0.641 | Accuracy: 0.742188 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 249 | Batch: 000 / 040 | Total loss: 0.606 | Reg loss: 0.020 | Tree loss: 0.606 | Accuracy: 0.767578 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 250 | Batch: 000 / 040 | Total loss: 0.643 | Reg loss: 0.020 | Tree loss: 0.643 | Accuracy: 0.738281 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 251 | Batch: 000 / 040 | Total loss: 0.703 | Reg loss: 0.020 | Tree loss: 0.703 | Accuracy: 0.720703 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 252 | Batch: 000 / 040 | Total loss: 0.660 | Reg loss: 0.020 | Tree loss: 0.660 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 253 | Batch: 000 / 040 | Total loss: 0.657 | Reg loss: 0.020 | Tree loss: 0.657 | Accuracy: 0.718750 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 254 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.708984 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 255 | Batch: 000 / 040 | Total loss: 0.584 | Reg loss: 0.020 | Tree loss: 0.584 | Accuracy: 0.767578 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 256 | Batch: 000 / 040 | Total loss: 0.638 | Reg loss: 0.020 | Tree loss: 0.638 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 257 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.744141 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 258 | Batch: 000 / 040 | Total loss: 0.646 | Reg loss: 0.020 | Tree loss: 0.646 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 259 | Batch: 000 / 040 | Total loss: 0.659 | Reg loss: 0.020 | Tree loss: 0.659 | Accuracy: 0.732422 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 260 | Batch: 000 / 040 | Total loss: 0.659 | Reg loss: 0.020 | Tree loss: 0.659 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 261 | Batch: 000 / 040 | Total loss: 0.615 | Reg loss: 0.020 | Tree loss: 0.615 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 262 | Batch: 000 / 040 | Total loss: 0.516 | Reg loss: 0.020 | Tree loss: 0.516 | Accuracy: 0.787109 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 263 | Batch: 000 / 040 | Total loss: 0.628 | Reg loss: 0.020 | Tree loss: 0.628 | Accuracy: 0.748047 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 264 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 265 | Batch: 000 / 040 | Total loss: 0.650 | Reg loss: 0.020 | Tree loss: 0.650 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 266 | Batch: 000 / 040 | Total loss: 0.634 | Reg loss: 0.020 | Tree loss: 0.634 | Accuracy: 0.714844 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 267 | Batch: 000 / 040 | Total loss: 0.621 | Reg loss: 0.020 | Tree loss: 0.621 | Accuracy: 0.748047 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 268 | Batch: 000 / 040 | Total loss: 0.646 | Reg loss: 0.020 | Tree loss: 0.646 | Accuracy: 0.716797 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 269 | Batch: 000 / 040 | Total loss: 0.700 | Reg loss: 0.020 | Tree loss: 0.700 | Accuracy: 0.703125 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 270 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.020 | Tree loss: 0.678 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 271 | Batch: 000 / 040 | Total loss: 0.638 | Reg loss: 0.020 | Tree loss: 0.638 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 272 | Batch: 000 / 040 | Total loss: 0.638 | Reg loss: 0.020 | Tree loss: 0.638 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 273 | Batch: 000 / 040 | Total loss: 0.655 | Reg loss: 0.020 | Tree loss: 0.655 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 274 | Batch: 000 / 040 | Total loss: 0.591 | Reg loss: 0.020 | Tree loss: 0.591 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 275 | Batch: 000 / 040 | Total loss: 0.619 | Reg loss: 0.020 | Tree loss: 0.619 | Accuracy: 0.763672 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 276 | Batch: 000 / 040 | Total loss: 0.646 | Reg loss: 0.020 | Tree loss: 0.646 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 277 | Batch: 000 / 040 | Total loss: 0.628 | Reg loss: 0.020 | Tree loss: 0.628 | Accuracy: 0.728516 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 278 | Batch: 000 / 040 | Total loss: 0.645 | Reg loss: 0.020 | Tree loss: 0.645 | Accuracy: 0.722656 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 279 | Batch: 000 / 040 | Total loss: 0.616 | Reg loss: 0.020 | Tree loss: 0.616 | Accuracy: 0.759766 | 0.046 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 280 | Batch: 000 / 040 | Total loss: 0.635 | Reg loss: 0.020 | Tree loss: 0.635 | Accuracy: 0.755859 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 281 | Batch: 000 / 040 | Total loss: 0.616 | Reg loss: 0.020 | Tree loss: 0.616 | Accuracy: 0.748047 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 282 | Batch: 000 / 040 | Total loss: 0.619 | Reg loss: 0.020 | Tree loss: 0.619 | Accuracy: 0.746094 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 283 | Batch: 000 / 040 | Total loss: 0.588 | Reg loss: 0.020 | Tree loss: 0.588 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 284 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.020 | Tree loss: 0.678 | Accuracy: 0.701172 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 285 | Batch: 000 / 040 | Total loss: 0.687 | Reg loss: 0.020 | Tree loss: 0.687 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 286 | Batch: 000 / 040 | Total loss: 0.616 | Reg loss: 0.020 | Tree loss: 0.616 | Accuracy: 0.751953 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 287 | Batch: 000 / 040 | Total loss: 0.647 | Reg loss: 0.020 | Tree loss: 0.647 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 288 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 289 | Batch: 000 / 040 | Total loss: 0.664 | Reg loss: 0.020 | Tree loss: 0.664 | Accuracy: 0.712891 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 290 | Batch: 000 / 040 | Total loss: 0.629 | Reg loss: 0.020 | Tree loss: 0.629 | Accuracy: 0.714844 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 291 | Batch: 000 / 040 | Total loss: 0.626 | Reg loss: 0.020 | Tree loss: 0.626 | Accuracy: 0.736328 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 292 | Batch: 000 / 040 | Total loss: 0.647 | Reg loss: 0.020 | Tree loss: 0.647 | Accuracy: 0.734375 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 293 | Batch: 000 / 040 | Total loss: 0.641 | Reg loss: 0.020 | Tree loss: 0.641 | Accuracy: 0.728516 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 294 | Batch: 000 / 040 | Total loss: 0.666 | Reg loss: 0.020 | Tree loss: 0.666 | Accuracy: 0.724609 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 295 | Batch: 000 / 040 | Total loss: 0.721 | Reg loss: 0.020 | Tree loss: 0.721 | Accuracy: 0.726562 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 296 | Batch: 000 / 040 | Total loss: 0.634 | Reg loss: 0.020 | Tree loss: 0.634 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 297 | Batch: 000 / 040 | Total loss: 0.644 | Reg loss: 0.020 | Tree loss: 0.644 | Accuracy: 0.720703 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 298 | Batch: 000 / 040 | Total loss: 0.599 | Reg loss: 0.020 | Tree loss: 0.599 | Accuracy: 0.746094 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 299 | Batch: 000 / 040 | Total loss: 0.643 | Reg loss: 0.020 | Tree loss: 0.643 | Accuracy: 0.738281 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 300 | Batch: 000 / 040 | Total loss: 0.541 | Reg loss: 0.020 | Tree loss: 0.541 | Accuracy: 0.781250 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 301 | Batch: 000 / 040 | Total loss: 0.600 | Reg loss: 0.020 | Tree loss: 0.600 | Accuracy: 0.767578 | 0.046 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 302 | Batch: 000 / 040 | Total loss: 0.578 | Reg loss: 0.020 | Tree loss: 0.578 | Accuracy: 0.761719 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 303 | Batch: 000 / 040 | Total loss: 0.609 | Reg loss: 0.020 | Tree loss: 0.609 | Accuracy: 0.728516 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 304 | Batch: 000 / 040 | Total loss: 0.706 | Reg loss: 0.020 | Tree loss: 0.706 | Accuracy: 0.708984 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 305 | Batch: 000 / 040 | Total loss: 0.652 | Reg loss: 0.020 | Tree loss: 0.652 | Accuracy: 0.750000 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 306 | Batch: 000 / 040 | Total loss: 0.655 | Reg loss: 0.020 | Tree loss: 0.655 | Accuracy: 0.746094 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 307 | Batch: 000 / 040 | Total loss: 0.539 | Reg loss: 0.020 | Tree loss: 0.539 | Accuracy: 0.769531 | 0.047 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 308 | Batch: 000 / 040 | Total loss: 0.633 | Reg loss: 0.020 | Tree loss: 0.633 | Accuracy: 0.753906 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 309 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.751953 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 310 | Batch: 000 / 040 | Total loss: 0.637 | Reg loss: 0.020 | Tree loss: 0.637 | Accuracy: 0.750000 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 311 | Batch: 000 / 040 | Total loss: 0.633 | Reg loss: 0.020 | Tree loss: 0.633 | Accuracy: 0.730469 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 312 | Batch: 000 / 040 | Total loss: 0.673 | Reg loss: 0.020 | Tree loss: 0.673 | Accuracy: 0.724609 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 313 | Batch: 000 / 040 | Total loss: 0.576 | Reg loss: 0.020 | Tree loss: 0.576 | Accuracy: 0.771484 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 314 | Batch: 000 / 040 | Total loss: 0.642 | Reg loss: 0.020 | Tree loss: 0.642 | Accuracy: 0.746094 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 315 | Batch: 000 / 040 | Total loss: 0.632 | Reg loss: 0.020 | Tree loss: 0.632 | Accuracy: 0.740234 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 316 | Batch: 000 / 040 | Total loss: 0.579 | Reg loss: 0.020 | Tree loss: 0.579 | Accuracy: 0.773438 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 317 | Batch: 000 / 040 | Total loss: 0.595 | Reg loss: 0.020 | Tree loss: 0.595 | Accuracy: 0.769531 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 318 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.020 | Tree loss: 0.678 | Accuracy: 0.730469 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 319 | Batch: 000 / 040 | Total loss: 0.589 | Reg loss: 0.020 | Tree loss: 0.589 | Accuracy: 0.779297 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 320 | Batch: 000 / 040 | Total loss: 0.659 | Reg loss: 0.020 | Tree loss: 0.659 | Accuracy: 0.728516 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 321 | Batch: 000 / 040 | Total loss: 0.603 | Reg loss: 0.020 | Tree loss: 0.603 | Accuracy: 0.751953 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 322 | Batch: 000 / 040 | Total loss: 0.632 | Reg loss: 0.020 | Tree loss: 0.632 | Accuracy: 0.750000 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 323 | Batch: 000 / 040 | Total loss: 0.629 | Reg loss: 0.020 | Tree loss: 0.629 | Accuracy: 0.718750 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 324 | Batch: 000 / 040 | Total loss: 0.687 | Reg loss: 0.020 | Tree loss: 0.687 | Accuracy: 0.712891 | 0.047 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 325 | Batch: 000 / 040 | Total loss: 0.573 | Reg loss: 0.020 | Tree loss: 0.573 | Accuracy: 0.765625 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 326 | Batch: 000 / 040 | Total loss: 0.671 | Reg loss: 0.020 | Tree loss: 0.671 | Accuracy: 0.718750 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 327 | Batch: 000 / 040 | Total loss: 0.589 | Reg loss: 0.020 | Tree loss: 0.589 | Accuracy: 0.761719 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 328 | Batch: 000 / 040 | Total loss: 0.678 | Reg loss: 0.020 | Tree loss: 0.678 | Accuracy: 0.740234 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 329 | Batch: 000 / 040 | Total loss: 0.590 | Reg loss: 0.020 | Tree loss: 0.590 | Accuracy: 0.761719 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 330 | Batch: 000 / 040 | Total loss: 0.665 | Reg loss: 0.020 | Tree loss: 0.665 | Accuracy: 0.722656 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 331 | Batch: 000 / 040 | Total loss: 0.581 | Reg loss: 0.020 | Tree loss: 0.581 | Accuracy: 0.757812 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 332 | Batch: 000 / 040 | Total loss: 0.621 | Reg loss: 0.020 | Tree loss: 0.621 | Accuracy: 0.726562 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 333 | Batch: 000 / 040 | Total loss: 0.609 | Reg loss: 0.020 | Tree loss: 0.609 | Accuracy: 0.750000 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 334 | Batch: 000 / 040 | Total loss: 0.635 | Reg loss: 0.020 | Tree loss: 0.635 | Accuracy: 0.744141 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 335 | Batch: 000 / 040 | Total loss: 0.653 | Reg loss: 0.020 | Tree loss: 0.653 | Accuracy: 0.755859 | 0.048 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 336 | Batch: 000 / 040 | Total loss: 0.558 | Reg loss: 0.020 | Tree loss: 0.558 | Accuracy: 0.765625 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 337 | Batch: 000 / 040 | Total loss: 0.576 | Reg loss: 0.020 | Tree loss: 0.576 | Accuracy: 0.767578 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 338 | Batch: 000 / 040 | Total loss: 0.640 | Reg loss: 0.020 | Tree loss: 0.640 | Accuracy: 0.753906 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 339 | Batch: 000 / 040 | Total loss: 0.649 | Reg loss: 0.020 | Tree loss: 0.649 | Accuracy: 0.726562 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 340 | Batch: 000 / 040 | Total loss: 0.573 | Reg loss: 0.020 | Tree loss: 0.573 | Accuracy: 0.761719 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 341 | Batch: 000 / 040 | Total loss: 0.720 | Reg loss: 0.020 | Tree loss: 0.720 | Accuracy: 0.685547 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 342 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.755859 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 343 | Batch: 000 / 040 | Total loss: 0.646 | Reg loss: 0.020 | Tree loss: 0.646 | Accuracy: 0.736328 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 344 | Batch: 000 / 040 | Total loss: 0.674 | Reg loss: 0.020 | Tree loss: 0.674 | Accuracy: 0.738281 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 345 | Batch: 000 / 040 | Total loss: 0.626 | Reg loss: 0.020 | Tree loss: 0.626 | Accuracy: 0.742188 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 346 | Batch: 000 / 040 | Total loss: 0.666 | Reg loss: 0.020 | Tree loss: 0.666 | Accuracy: 0.714844 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 347 | Batch: 000 / 040 | Total loss: 0.612 | Reg loss: 0.020 | Tree loss: 0.612 | Accuracy: 0.765625 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 348 | Batch: 000 / 040 | Total loss: 0.649 | Reg loss: 0.020 | Tree loss: 0.649 | Accuracy: 0.724609 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 349 | Batch: 000 / 040 | Total loss: 0.638 | Reg loss: 0.020 | Tree loss: 0.638 | Accuracy: 0.753906 | 0.048 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 350 | Batch: 000 / 040 | Total loss: 0.633 | Reg loss: 0.020 | Tree loss: 0.633 | Accuracy: 0.740234 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 351 | Batch: 000 / 040 | Total loss: 0.609 | Reg loss: 0.020 | Tree loss: 0.609 | Accuracy: 0.759766 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 352 | Batch: 000 / 040 | Total loss: 0.591 | Reg loss: 0.020 | Tree loss: 0.591 | Accuracy: 0.763672 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 353 | Batch: 000 / 040 | Total loss: 0.699 | Reg loss: 0.020 | Tree loss: 0.699 | Accuracy: 0.708984 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 354 | Batch: 000 / 040 | Total loss: 0.645 | Reg loss: 0.020 | Tree loss: 0.645 | Accuracy: 0.742188 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 355 | Batch: 000 / 040 | Total loss: 0.684 | Reg loss: 0.020 | Tree loss: 0.684 | Accuracy: 0.705078 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 356 | Batch: 000 / 040 | Total loss: 0.613 | Reg loss: 0.020 | Tree loss: 0.613 | Accuracy: 0.748047 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 357 | Batch: 000 / 040 | Total loss: 0.623 | Reg loss: 0.020 | Tree loss: 0.623 | Accuracy: 0.750000 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 358 | Batch: 000 / 040 | Total loss: 0.642 | Reg loss: 0.020 | Tree loss: 0.642 | Accuracy: 0.734375 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 359 | Batch: 000 / 040 | Total loss: 0.597 | Reg loss: 0.020 | Tree loss: 0.597 | Accuracy: 0.759766 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 360 | Batch: 000 / 040 | Total loss: 0.589 | Reg loss: 0.020 | Tree loss: 0.589 | Accuracy: 0.753906 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 361 | Batch: 000 / 040 | Total loss: 0.644 | Reg loss: 0.020 | Tree loss: 0.644 | Accuracy: 0.734375 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 362 | Batch: 000 / 040 | Total loss: 0.640 | Reg loss: 0.020 | Tree loss: 0.640 | Accuracy: 0.734375 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 363 | Batch: 000 / 040 | Total loss: 0.645 | Reg loss: 0.020 | Tree loss: 0.645 | Accuracy: 0.736328 | 0.049 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 364 | Batch: 000 / 040 | Total loss: 0.681 | Reg loss: 0.020 | Tree loss: 0.681 | Accuracy: 0.720703 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 365 | Batch: 000 / 040 | Total loss: 0.655 | Reg loss: 0.020 | Tree loss: 0.655 | Accuracy: 0.742188 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 366 | Batch: 000 / 040 | Total loss: 0.617 | Reg loss: 0.020 | Tree loss: 0.617 | Accuracy: 0.738281 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 367 | Batch: 000 / 040 | Total loss: 0.700 | Reg loss: 0.020 | Tree loss: 0.700 | Accuracy: 0.707031 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 368 | Batch: 000 / 040 | Total loss: 0.585 | Reg loss: 0.020 | Tree loss: 0.585 | Accuracy: 0.738281 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 369 | Batch: 000 / 040 | Total loss: 0.627 | Reg loss: 0.020 | Tree loss: 0.627 | Accuracy: 0.732422 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 370 | Batch: 000 / 040 | Total loss: 0.656 | Reg loss: 0.020 | Tree loss: 0.656 | Accuracy: 0.746094 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 371 | Batch: 000 / 040 | Total loss: 0.620 | Reg loss: 0.020 | Tree loss: 0.620 | Accuracy: 0.763672 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 372 | Batch: 000 / 040 | Total loss: 0.666 | Reg loss: 0.020 | Tree loss: 0.666 | Accuracy: 0.726562 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 373 | Batch: 000 / 040 | Total loss: 0.627 | Reg loss: 0.020 | Tree loss: 0.627 | Accuracy: 0.757812 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 374 | Batch: 000 / 040 | Total loss: 0.630 | Reg loss: 0.020 | Tree loss: 0.630 | Accuracy: 0.738281 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 375 | Batch: 000 / 040 | Total loss: 0.676 | Reg loss: 0.020 | Tree loss: 0.676 | Accuracy: 0.720703 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 376 | Batch: 000 / 040 | Total loss: 0.602 | Reg loss: 0.020 | Tree loss: 0.602 | Accuracy: 0.748047 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 377 | Batch: 000 / 040 | Total loss: 0.626 | Reg loss: 0.020 | Tree loss: 0.626 | Accuracy: 0.742188 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 378 | Batch: 000 / 040 | Total loss: 0.594 | Reg loss: 0.020 | Tree loss: 0.594 | Accuracy: 0.769531 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 379 | Batch: 000 / 040 | Total loss: 0.672 | Reg loss: 0.020 | Tree loss: 0.672 | Accuracy: 0.710938 | 0.049 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 380 | Batch: 000 / 040 | Total loss: 0.634 | Reg loss: 0.020 | Tree loss: 0.634 | Accuracy: 0.753906 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 381 | Batch: 000 / 040 | Total loss: 0.655 | Reg loss: 0.020 | Tree loss: 0.655 | Accuracy: 0.724609 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 382 | Batch: 000 / 040 | Total loss: 0.617 | Reg loss: 0.020 | Tree loss: 0.617 | Accuracy: 0.750000 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 383 | Batch: 000 / 040 | Total loss: 0.653 | Reg loss: 0.020 | Tree loss: 0.653 | Accuracy: 0.753906 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 384 | Batch: 000 / 040 | Total loss: 0.680 | Reg loss: 0.020 | Tree loss: 0.680 | Accuracy: 0.722656 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 385 | Batch: 000 / 040 | Total loss: 0.638 | Reg loss: 0.020 | Tree loss: 0.638 | Accuracy: 0.761719 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 386 | Batch: 000 / 040 | Total loss: 0.611 | Reg loss: 0.020 | Tree loss: 0.611 | Accuracy: 0.746094 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 387 | Batch: 000 / 040 | Total loss: 0.623 | Reg loss: 0.020 | Tree loss: 0.623 | Accuracy: 0.742188 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 388 | Batch: 000 / 040 | Total loss: 0.605 | Reg loss: 0.020 | Tree loss: 0.605 | Accuracy: 0.750000 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 389 | Batch: 000 / 040 | Total loss: 0.673 | Reg loss: 0.020 | Tree loss: 0.673 | Accuracy: 0.728516 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 390 | Batch: 000 / 040 | Total loss: 0.634 | Reg loss: 0.020 | Tree loss: 0.634 | Accuracy: 0.724609 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 391 | Batch: 000 / 040 | Total loss: 0.670 | Reg loss: 0.020 | Tree loss: 0.670 | Accuracy: 0.726562 | 0.05 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 392 | Batch: 000 / 040 | Total loss: 0.668 | Reg loss: 0.020 | Tree loss: 0.668 | Accuracy: 0.734375 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 393 | Batch: 000 / 040 | Total loss: 0.648 | Reg loss: 0.020 | Tree loss: 0.648 | Accuracy: 0.708984 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 394 | Batch: 000 / 040 | Total loss: 0.651 | Reg loss: 0.020 | Tree loss: 0.651 | Accuracy: 0.718750 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 395 | Batch: 000 / 040 | Total loss: 0.691 | Reg loss: 0.020 | Tree loss: 0.691 | Accuracy: 0.736328 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 396 | Batch: 000 / 040 | Total loss: 0.639 | Reg loss: 0.020 | Tree loss: 0.639 | Accuracy: 0.738281 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 397 | Batch: 000 / 040 | Total loss: 0.617 | Reg loss: 0.020 | Tree loss: 0.617 | Accuracy: 0.757812 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 398 | Batch: 000 / 040 | Total loss: 0.625 | Reg loss: 0.020 | Tree loss: 0.625 | Accuracy: 0.751953 | 0.05 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 399 | Batch: 000 / 040 | Total loss: 0.632 | Reg loss: 0.020 | Tree loss: 0.632 | Accuracy: 0.740234 | 0.05 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0871f5b67c4844b3a4a3f668ddf5df8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f5bc9b51514ff6b5566d2cff8ece96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4918c956498149d095ec10956bad1ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6911322d13a04a0083890df4ce4a367b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 4.928571428571429\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "5002\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "3331\n",
      "============== Pattern 7 ==============\n",
      "11581\n",
      "============== Pattern 8 ==============\n",
      "138\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "403\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "Average comprehensibility: 25.428571428571427\n",
      "std comprehensibility: 8.666143364630344\n",
      "var comprehensibility: 75.10204081632654\n",
      "minimum comprehensibility: 4\n",
      "maximum comprehensibility: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    }
   ],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
