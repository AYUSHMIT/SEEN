{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.market_basket_dataset import MarketBasketDataset, BinaryEncodingTransform, RemoveItemsTransform\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "tree_depth = 8\n",
    "device = 'cuda'\n",
    "dataset_path = r\"/mnt/qnap/ekosman/Groceries_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the market basket dataset and use one-hot encoding for items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MarketBasketDataset(dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(dataset.n_items, 50, 4).train().to(device)\n",
    "epochs = 500\n",
    "lr = 5e-3\n",
    "batch_size = 512\n",
    "log_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform = torchvision.transforms.Compose([\n",
    "    RemoveItemsTransform(p=0.5),\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")\n",
    "dataset.target_transform = torchvision.transforms.Compose([\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 500 | iteration 0 / 30 | Total Loss: 8.164026260375977 | KNN Loss: 6.224818229675293 | BCE Loss: 1.9392085075378418\n",
      "Epoch 0 / 500 | iteration 5 / 30 | Total Loss: 8.184050559997559 | KNN Loss: 6.224360942840576 | BCE Loss: 1.9596898555755615\n",
      "Epoch 0 / 500 | iteration 10 / 30 | Total Loss: 8.180439949035645 | KNN Loss: 6.224224090576172 | BCE Loss: 1.956215739250183\n",
      "Epoch 0 / 500 | iteration 15 / 30 | Total Loss: 8.135895729064941 | KNN Loss: 6.223940849304199 | BCE Loss: 1.9119547605514526\n",
      "Epoch 0 / 500 | iteration 20 / 30 | Total Loss: 8.149843215942383 | KNN Loss: 6.2236647605896 | BCE Loss: 1.9261789321899414\n",
      "Epoch 0 / 500 | iteration 25 / 30 | Total Loss: 8.154428482055664 | KNN Loss: 6.223090648651123 | BCE Loss: 1.931337833404541\n",
      "Epoch 1 / 500 | iteration 0 / 30 | Total Loss: 8.125213623046875 | KNN Loss: 6.22247838973999 | BCE Loss: 1.9027354717254639\n",
      "Epoch 1 / 500 | iteration 5 / 30 | Total Loss: 8.126628875732422 | KNN Loss: 6.222614765167236 | BCE Loss: 1.9040144681930542\n",
      "Epoch 1 / 500 | iteration 10 / 30 | Total Loss: 8.127716064453125 | KNN Loss: 6.222031116485596 | BCE Loss: 1.9056854248046875\n",
      "Epoch 1 / 500 | iteration 15 / 30 | Total Loss: 8.152535438537598 | KNN Loss: 6.221351623535156 | BCE Loss: 1.9311840534210205\n",
      "Epoch 1 / 500 | iteration 20 / 30 | Total Loss: 8.101099967956543 | KNN Loss: 6.221257209777832 | BCE Loss: 1.8798424005508423\n",
      "Epoch 1 / 500 | iteration 25 / 30 | Total Loss: 8.088813781738281 | KNN Loss: 6.220979690551758 | BCE Loss: 1.8678338527679443\n",
      "Epoch 2 / 500 | iteration 0 / 30 | Total Loss: 8.123397827148438 | KNN Loss: 6.2198896408081055 | BCE Loss: 1.9035083055496216\n",
      "Epoch 2 / 500 | iteration 5 / 30 | Total Loss: 8.045560836791992 | KNN Loss: 6.219793796539307 | BCE Loss: 1.8257675170898438\n",
      "Epoch 2 / 500 | iteration 10 / 30 | Total Loss: 8.073592185974121 | KNN Loss: 6.219255447387695 | BCE Loss: 1.8543367385864258\n",
      "Epoch 2 / 500 | iteration 15 / 30 | Total Loss: 8.098766326904297 | KNN Loss: 6.218778610229492 | BCE Loss: 1.8799875974655151\n",
      "Epoch 2 / 500 | iteration 20 / 30 | Total Loss: 8.085643768310547 | KNN Loss: 6.217991828918457 | BCE Loss: 1.8676522970199585\n",
      "Epoch 2 / 500 | iteration 25 / 30 | Total Loss: 8.081839561462402 | KNN Loss: 6.217271327972412 | BCE Loss: 1.8645678758621216\n",
      "Epoch 3 / 500 | iteration 0 / 30 | Total Loss: 8.061222076416016 | KNN Loss: 6.216300010681152 | BCE Loss: 1.8449220657348633\n",
      "Epoch 3 / 500 | iteration 5 / 30 | Total Loss: 8.077391624450684 | KNN Loss: 6.215976238250732 | BCE Loss: 1.8614156246185303\n",
      "Epoch 3 / 500 | iteration 10 / 30 | Total Loss: 8.029373168945312 | KNN Loss: 6.214900493621826 | BCE Loss: 1.8144729137420654\n",
      "Epoch 3 / 500 | iteration 15 / 30 | Total Loss: 8.024787902832031 | KNN Loss: 6.2142839431762695 | BCE Loss: 1.8105039596557617\n",
      "Epoch 3 / 500 | iteration 20 / 30 | Total Loss: 8.020146369934082 | KNN Loss: 6.21329927444458 | BCE Loss: 1.8068467378616333\n",
      "Epoch 3 / 500 | iteration 25 / 30 | Total Loss: 7.9632463455200195 | KNN Loss: 6.213320732116699 | BCE Loss: 1.7499254941940308\n",
      "Epoch 4 / 500 | iteration 0 / 30 | Total Loss: 8.006953239440918 | KNN Loss: 6.2123284339904785 | BCE Loss: 1.7946245670318604\n",
      "Epoch 4 / 500 | iteration 5 / 30 | Total Loss: 7.98313045501709 | KNN Loss: 6.210511684417725 | BCE Loss: 1.7726188898086548\n",
      "Epoch 4 / 500 | iteration 10 / 30 | Total Loss: 7.953400135040283 | KNN Loss: 6.209649562835693 | BCE Loss: 1.7437506914138794\n",
      "Epoch 4 / 500 | iteration 15 / 30 | Total Loss: 7.952014923095703 | KNN Loss: 6.207643032073975 | BCE Loss: 1.7443718910217285\n",
      "Epoch 4 / 500 | iteration 20 / 30 | Total Loss: 7.96186637878418 | KNN Loss: 6.207949161529541 | BCE Loss: 1.7539169788360596\n",
      "Epoch 4 / 500 | iteration 25 / 30 | Total Loss: 7.956680774688721 | KNN Loss: 6.2067718505859375 | BCE Loss: 1.7499090433120728\n",
      "Epoch 5 / 500 | iteration 0 / 30 | Total Loss: 7.930814743041992 | KNN Loss: 6.204442024230957 | BCE Loss: 1.7263727188110352\n",
      "Epoch 5 / 500 | iteration 5 / 30 | Total Loss: 7.943406581878662 | KNN Loss: 6.203005790710449 | BCE Loss: 1.740400791168213\n",
      "Epoch 5 / 500 | iteration 10 / 30 | Total Loss: 7.900575160980225 | KNN Loss: 6.201244354248047 | BCE Loss: 1.6993306875228882\n",
      "Epoch 5 / 500 | iteration 15 / 30 | Total Loss: 7.907474517822266 | KNN Loss: 6.200294494628906 | BCE Loss: 1.7071797847747803\n",
      "Epoch 5 / 500 | iteration 20 / 30 | Total Loss: 7.8712944984436035 | KNN Loss: 6.196554660797119 | BCE Loss: 1.6747398376464844\n",
      "Epoch 5 / 500 | iteration 25 / 30 | Total Loss: 7.848519802093506 | KNN Loss: 6.197192668914795 | BCE Loss: 1.651327133178711\n",
      "Epoch 6 / 500 | iteration 0 / 30 | Total Loss: 7.886351585388184 | KNN Loss: 6.193751335144043 | BCE Loss: 1.6926000118255615\n",
      "Epoch 6 / 500 | iteration 5 / 30 | Total Loss: 7.844567775726318 | KNN Loss: 6.191524505615234 | BCE Loss: 1.653043270111084\n",
      "Epoch 6 / 500 | iteration 10 / 30 | Total Loss: 7.8294243812561035 | KNN Loss: 6.188765048980713 | BCE Loss: 1.6406594514846802\n",
      "Epoch 6 / 500 | iteration 15 / 30 | Total Loss: 7.833751201629639 | KNN Loss: 6.1838154792785645 | BCE Loss: 1.6499356031417847\n",
      "Epoch 6 / 500 | iteration 20 / 30 | Total Loss: 7.825509071350098 | KNN Loss: 6.183408737182617 | BCE Loss: 1.642100214958191\n",
      "Epoch 6 / 500 | iteration 25 / 30 | Total Loss: 7.813015937805176 | KNN Loss: 6.184974193572998 | BCE Loss: 1.6280418634414673\n",
      "Epoch 7 / 500 | iteration 0 / 30 | Total Loss: 7.807609558105469 | KNN Loss: 6.174218654632568 | BCE Loss: 1.63339102268219\n",
      "Epoch 7 / 500 | iteration 5 / 30 | Total Loss: 7.812155723571777 | KNN Loss: 6.1700286865234375 | BCE Loss: 1.6421270370483398\n",
      "Epoch 7 / 500 | iteration 10 / 30 | Total Loss: 7.7032623291015625 | KNN Loss: 6.1671600341796875 | BCE Loss: 1.536102533340454\n",
      "Epoch 7 / 500 | iteration 15 / 30 | Total Loss: 7.70433235168457 | KNN Loss: 6.166873931884766 | BCE Loss: 1.5374584197998047\n",
      "Epoch 7 / 500 | iteration 20 / 30 | Total Loss: 7.713771820068359 | KNN Loss: 6.1611857414245605 | BCE Loss: 1.552586317062378\n",
      "Epoch 7 / 500 | iteration 25 / 30 | Total Loss: 7.69298791885376 | KNN Loss: 6.151010036468506 | BCE Loss: 1.5419777631759644\n",
      "Epoch 8 / 500 | iteration 0 / 30 | Total Loss: 7.651645660400391 | KNN Loss: 6.135525703430176 | BCE Loss: 1.5161199569702148\n",
      "Epoch 8 / 500 | iteration 5 / 30 | Total Loss: 7.571700096130371 | KNN Loss: 6.131096839904785 | BCE Loss: 1.4406030178070068\n",
      "Epoch 8 / 500 | iteration 10 / 30 | Total Loss: 7.590227127075195 | KNN Loss: 6.1278204917907715 | BCE Loss: 1.4624067544937134\n",
      "Epoch 8 / 500 | iteration 15 / 30 | Total Loss: 7.584151744842529 | KNN Loss: 6.1231207847595215 | BCE Loss: 1.4610310792922974\n",
      "Epoch 8 / 500 | iteration 20 / 30 | Total Loss: 7.576847076416016 | KNN Loss: 6.1059393882751465 | BCE Loss: 1.4709076881408691\n",
      "Epoch 8 / 500 | iteration 25 / 30 | Total Loss: 7.532452583312988 | KNN Loss: 6.099063873291016 | BCE Loss: 1.4333889484405518\n",
      "Epoch 9 / 500 | iteration 0 / 30 | Total Loss: 7.486900806427002 | KNN Loss: 6.085338115692139 | BCE Loss: 1.4015626907348633\n",
      "Epoch 9 / 500 | iteration 5 / 30 | Total Loss: 7.424190521240234 | KNN Loss: 6.078092575073242 | BCE Loss: 1.3460981845855713\n",
      "Epoch 9 / 500 | iteration 10 / 30 | Total Loss: 7.424142837524414 | KNN Loss: 6.0623345375061035 | BCE Loss: 1.3618084192276\n",
      "Epoch 9 / 500 | iteration 15 / 30 | Total Loss: 7.337262153625488 | KNN Loss: 6.029635429382324 | BCE Loss: 1.307626724243164\n",
      "Epoch 9 / 500 | iteration 20 / 30 | Total Loss: 7.337217330932617 | KNN Loss: 6.030308246612549 | BCE Loss: 1.3069090843200684\n",
      "Epoch 9 / 500 | iteration 25 / 30 | Total Loss: 7.280452728271484 | KNN Loss: 5.992873668670654 | BCE Loss: 1.2875792980194092\n",
      "Epoch 10 / 500 | iteration 0 / 30 | Total Loss: 7.260833263397217 | KNN Loss: 5.963484287261963 | BCE Loss: 1.297348976135254\n",
      "Epoch 10 / 500 | iteration 5 / 30 | Total Loss: 7.174396991729736 | KNN Loss: 5.913610458374023 | BCE Loss: 1.260786533355713\n",
      "Epoch 10 / 500 | iteration 10 / 30 | Total Loss: 7.176612377166748 | KNN Loss: 5.918147563934326 | BCE Loss: 1.2584649324417114\n",
      "Epoch 10 / 500 | iteration 15 / 30 | Total Loss: 7.128912448883057 | KNN Loss: 5.877597808837891 | BCE Loss: 1.251314640045166\n",
      "Epoch 10 / 500 | iteration 20 / 30 | Total Loss: 7.0045247077941895 | KNN Loss: 5.82342004776001 | BCE Loss: 1.1811046600341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 500 | iteration 25 / 30 | Total Loss: 6.929956436157227 | KNN Loss: 5.7535014152526855 | BCE Loss: 1.1764552593231201\n",
      "Epoch 11 / 500 | iteration 0 / 30 | Total Loss: 6.860462665557861 | KNN Loss: 5.719170093536377 | BCE Loss: 1.141292691230774\n",
      "Epoch 11 / 500 | iteration 5 / 30 | Total Loss: 6.783545970916748 | KNN Loss: 5.627161502838135 | BCE Loss: 1.1563844680786133\n",
      "Epoch 11 / 500 | iteration 10 / 30 | Total Loss: 6.727011203765869 | KNN Loss: 5.563403606414795 | BCE Loss: 1.1636075973510742\n",
      "Epoch 11 / 500 | iteration 15 / 30 | Total Loss: 6.586681842803955 | KNN Loss: 5.452396869659424 | BCE Loss: 1.1342850923538208\n",
      "Epoch 11 / 500 | iteration 20 / 30 | Total Loss: 6.4945807456970215 | KNN Loss: 5.36434268951416 | BCE Loss: 1.1302380561828613\n",
      "Epoch 11 / 500 | iteration 25 / 30 | Total Loss: 6.422830581665039 | KNN Loss: 5.273220062255859 | BCE Loss: 1.1496105194091797\n",
      "Epoch 12 / 500 | iteration 0 / 30 | Total Loss: 6.283742427825928 | KNN Loss: 5.15598201751709 | BCE Loss: 1.1277605295181274\n",
      "Epoch 12 / 500 | iteration 5 / 30 | Total Loss: 6.106497764587402 | KNN Loss: 5.015478134155273 | BCE Loss: 1.0910193920135498\n",
      "Epoch 12 / 500 | iteration 10 / 30 | Total Loss: 5.949456691741943 | KNN Loss: 4.8804240226745605 | BCE Loss: 1.0690325498580933\n",
      "Epoch 12 / 500 | iteration 15 / 30 | Total Loss: 5.916788578033447 | KNN Loss: 4.792495250701904 | BCE Loss: 1.1242934465408325\n",
      "Epoch 12 / 500 | iteration 20 / 30 | Total Loss: 5.772458553314209 | KNN Loss: 4.670154094696045 | BCE Loss: 1.102304458618164\n",
      "Epoch 12 / 500 | iteration 25 / 30 | Total Loss: 5.570682048797607 | KNN Loss: 4.492358684539795 | BCE Loss: 1.0783233642578125\n",
      "Epoch 13 / 500 | iteration 0 / 30 | Total Loss: 5.514935493469238 | KNN Loss: 4.403773307800293 | BCE Loss: 1.1111621856689453\n",
      "Epoch 13 / 500 | iteration 5 / 30 | Total Loss: 5.37019157409668 | KNN Loss: 4.2770891189575195 | BCE Loss: 1.0931024551391602\n",
      "Epoch 13 / 500 | iteration 10 / 30 | Total Loss: 5.31020450592041 | KNN Loss: 4.199667930603027 | BCE Loss: 1.1105365753173828\n",
      "Epoch 13 / 500 | iteration 15 / 30 | Total Loss: 5.21885871887207 | KNN Loss: 4.09681510925293 | BCE Loss: 1.1220438480377197\n",
      "Epoch 13 / 500 | iteration 20 / 30 | Total Loss: 5.043272972106934 | KNN Loss: 3.9671034812927246 | BCE Loss: 1.076169729232788\n",
      "Epoch 13 / 500 | iteration 25 / 30 | Total Loss: 5.041938304901123 | KNN Loss: 3.938082456588745 | BCE Loss: 1.103855848312378\n",
      "Epoch 14 / 500 | iteration 0 / 30 | Total Loss: 4.925056457519531 | KNN Loss: 3.8128039836883545 | BCE Loss: 1.1122525930404663\n",
      "Epoch 14 / 500 | iteration 5 / 30 | Total Loss: 4.840662956237793 | KNN Loss: 3.742133617401123 | BCE Loss: 1.0985294580459595\n",
      "Epoch 14 / 500 | iteration 10 / 30 | Total Loss: 4.747398376464844 | KNN Loss: 3.683828830718994 | BCE Loss: 1.0635697841644287\n",
      "Epoch 14 / 500 | iteration 15 / 30 | Total Loss: 4.679863929748535 | KNN Loss: 3.5926501750946045 | BCE Loss: 1.0872135162353516\n",
      "Epoch 14 / 500 | iteration 20 / 30 | Total Loss: 4.602519989013672 | KNN Loss: 3.503183603286743 | BCE Loss: 1.0993366241455078\n",
      "Epoch 14 / 500 | iteration 25 / 30 | Total Loss: 4.519984722137451 | KNN Loss: 3.4389731884002686 | BCE Loss: 1.0810115337371826\n",
      "Epoch 15 / 500 | iteration 0 / 30 | Total Loss: 4.4842209815979 | KNN Loss: 3.4160373210906982 | BCE Loss: 1.0681836605072021\n",
      "Epoch 15 / 500 | iteration 5 / 30 | Total Loss: 4.456269264221191 | KNN Loss: 3.38022780418396 | BCE Loss: 1.0760416984558105\n",
      "Epoch 15 / 500 | iteration 10 / 30 | Total Loss: 4.377005100250244 | KNN Loss: 3.2997395992279053 | BCE Loss: 1.0772655010223389\n",
      "Epoch 15 / 500 | iteration 15 / 30 | Total Loss: 4.3144917488098145 | KNN Loss: 3.2328929901123047 | BCE Loss: 1.0815986394882202\n",
      "Epoch 15 / 500 | iteration 20 / 30 | Total Loss: 4.275678634643555 | KNN Loss: 3.2125043869018555 | BCE Loss: 1.0631744861602783\n",
      "Epoch 15 / 500 | iteration 25 / 30 | Total Loss: 4.257591724395752 | KNN Loss: 3.175178050994873 | BCE Loss: 1.0824135541915894\n",
      "Epoch 16 / 500 | iteration 0 / 30 | Total Loss: 4.23342227935791 | KNN Loss: 3.1444711685180664 | BCE Loss: 1.0889511108398438\n",
      "Epoch 16 / 500 | iteration 5 / 30 | Total Loss: 4.221839904785156 | KNN Loss: 3.1305623054504395 | BCE Loss: 1.0912773609161377\n",
      "Epoch 16 / 500 | iteration 10 / 30 | Total Loss: 4.132291793823242 | KNN Loss: 3.0657994747161865 | BCE Loss: 1.0664925575256348\n",
      "Epoch 16 / 500 | iteration 15 / 30 | Total Loss: 4.070467472076416 | KNN Loss: 3.019876480102539 | BCE Loss: 1.0505911111831665\n",
      "Epoch 16 / 500 | iteration 20 / 30 | Total Loss: 4.10467529296875 | KNN Loss: 3.003718137741089 | BCE Loss: 1.1009573936462402\n",
      "Epoch 16 / 500 | iteration 25 / 30 | Total Loss: 4.050561904907227 | KNN Loss: 2.9637184143066406 | BCE Loss: 1.086843490600586\n",
      "Epoch 17 / 500 | iteration 0 / 30 | Total Loss: 4.047893524169922 | KNN Loss: 2.963932514190674 | BCE Loss: 1.083961009979248\n",
      "Epoch 17 / 500 | iteration 5 / 30 | Total Loss: 3.9872007369995117 | KNN Loss: 2.927119493484497 | BCE Loss: 1.0600813627243042\n",
      "Epoch 17 / 500 | iteration 10 / 30 | Total Loss: 3.977665424346924 | KNN Loss: 2.9137930870056152 | BCE Loss: 1.063872218132019\n",
      "Epoch 17 / 500 | iteration 15 / 30 | Total Loss: 3.993283271789551 | KNN Loss: 2.9330434799194336 | BCE Loss: 1.0602396726608276\n",
      "Epoch 17 / 500 | iteration 20 / 30 | Total Loss: 3.9525561332702637 | KNN Loss: 2.8958358764648438 | BCE Loss: 1.0567203760147095\n",
      "Epoch 17 / 500 | iteration 25 / 30 | Total Loss: 3.9217944145202637 | KNN Loss: 2.8541834354400635 | BCE Loss: 1.0676109790802002\n",
      "Epoch 18 / 500 | iteration 0 / 30 | Total Loss: 3.9323649406433105 | KNN Loss: 2.8632678985595703 | BCE Loss: 1.0690970420837402\n",
      "Epoch 18 / 500 | iteration 5 / 30 | Total Loss: 3.927105188369751 | KNN Loss: 2.8966970443725586 | BCE Loss: 1.0304081439971924\n",
      "Epoch 18 / 500 | iteration 10 / 30 | Total Loss: 3.886415958404541 | KNN Loss: 2.8147881031036377 | BCE Loss: 1.0716279745101929\n",
      "Epoch 18 / 500 | iteration 15 / 30 | Total Loss: 3.8814706802368164 | KNN Loss: 2.822521686553955 | BCE Loss: 1.0589489936828613\n",
      "Epoch 18 / 500 | iteration 20 / 30 | Total Loss: 3.834398031234741 | KNN Loss: 2.7682793140411377 | BCE Loss: 1.0661187171936035\n",
      "Epoch 18 / 500 | iteration 25 / 30 | Total Loss: 3.874691963195801 | KNN Loss: 2.799801826477051 | BCE Loss: 1.0748900175094604\n",
      "Epoch 19 / 500 | iteration 0 / 30 | Total Loss: 3.8653600215911865 | KNN Loss: 2.801494598388672 | BCE Loss: 1.0638654232025146\n",
      "Epoch 19 / 500 | iteration 5 / 30 | Total Loss: 3.823071002960205 | KNN Loss: 2.773725748062134 | BCE Loss: 1.0493452548980713\n",
      "Epoch 19 / 500 | iteration 10 / 30 | Total Loss: 3.814579725265503 | KNN Loss: 2.7493038177490234 | BCE Loss: 1.0652759075164795\n",
      "Epoch 19 / 500 | iteration 15 / 30 | Total Loss: 3.8463311195373535 | KNN Loss: 2.7747414112091064 | BCE Loss: 1.0715895891189575\n",
      "Epoch 19 / 500 | iteration 20 / 30 | Total Loss: 3.83003306388855 | KNN Loss: 2.7806520462036133 | BCE Loss: 1.0493810176849365\n",
      "Epoch 19 / 500 | iteration 25 / 30 | Total Loss: 3.775912046432495 | KNN Loss: 2.7170042991638184 | BCE Loss: 1.0589077472686768\n",
      "Epoch 20 / 500 | iteration 0 / 30 | Total Loss: 3.863348960876465 | KNN Loss: 2.798790216445923 | BCE Loss: 1.064558744430542\n",
      "Epoch 20 / 500 | iteration 5 / 30 | Total Loss: 3.7692174911499023 | KNN Loss: 2.686410665512085 | BCE Loss: 1.0828067064285278\n",
      "Epoch 20 / 500 | iteration 10 / 30 | Total Loss: 3.776134967803955 | KNN Loss: 2.731841802597046 | BCE Loss: 1.0442932844161987\n",
      "Epoch 20 / 500 | iteration 15 / 30 | Total Loss: 3.7560172080993652 | KNN Loss: 2.7176411151885986 | BCE Loss: 1.038375973701477\n",
      "Epoch 20 / 500 | iteration 20 / 30 | Total Loss: 3.7791638374328613 | KNN Loss: 2.7292540073394775 | BCE Loss: 1.0499098300933838\n",
      "Epoch 20 / 500 | iteration 25 / 30 | Total Loss: 3.743647336959839 | KNN Loss: 2.697387456893921 | BCE Loss: 1.046259880065918\n",
      "Epoch 21 / 500 | iteration 0 / 30 | Total Loss: 3.780594825744629 | KNN Loss: 2.7396953105926514 | BCE Loss: 1.0408995151519775\n",
      "Epoch 21 / 500 | iteration 5 / 30 | Total Loss: 3.749032735824585 | KNN Loss: 2.68869948387146 | BCE Loss: 1.060333251953125\n",
      "Epoch 21 / 500 | iteration 10 / 30 | Total Loss: 3.79679536819458 | KNN Loss: 2.7268285751342773 | BCE Loss: 1.0699669122695923\n",
      "Epoch 21 / 500 | iteration 15 / 30 | Total Loss: 3.822382926940918 | KNN Loss: 2.757492780685425 | BCE Loss: 1.0648900270462036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 500 | iteration 20 / 30 | Total Loss: 3.7727081775665283 | KNN Loss: 2.703932285308838 | BCE Loss: 1.0687758922576904\n",
      "Epoch 21 / 500 | iteration 25 / 30 | Total Loss: 3.7198593616485596 | KNN Loss: 2.672633171081543 | BCE Loss: 1.0472261905670166\n",
      "Epoch 22 / 500 | iteration 0 / 30 | Total Loss: 3.7044451236724854 | KNN Loss: 2.654899835586548 | BCE Loss: 1.0495452880859375\n",
      "Epoch 22 / 500 | iteration 5 / 30 | Total Loss: 3.72906494140625 | KNN Loss: 2.709667921066284 | BCE Loss: 1.0193970203399658\n",
      "Epoch 22 / 500 | iteration 10 / 30 | Total Loss: 3.7616140842437744 | KNN Loss: 2.7004189491271973 | BCE Loss: 1.0611951351165771\n",
      "Epoch 22 / 500 | iteration 15 / 30 | Total Loss: 3.775270462036133 | KNN Loss: 2.7181968688964844 | BCE Loss: 1.0570734739303589\n",
      "Epoch 22 / 500 | iteration 20 / 30 | Total Loss: 3.724064826965332 | KNN Loss: 2.66469407081604 | BCE Loss: 1.059370756149292\n",
      "Epoch 22 / 500 | iteration 25 / 30 | Total Loss: 3.689032793045044 | KNN Loss: 2.62568736076355 | BCE Loss: 1.0633454322814941\n",
      "Epoch 23 / 500 | iteration 0 / 30 | Total Loss: 3.6699202060699463 | KNN Loss: 2.6364586353302 | BCE Loss: 1.033461570739746\n",
      "Epoch 23 / 500 | iteration 5 / 30 | Total Loss: 3.6792054176330566 | KNN Loss: 2.6038272380828857 | BCE Loss: 1.0753782987594604\n",
      "Epoch 23 / 500 | iteration 10 / 30 | Total Loss: 3.707850694656372 | KNN Loss: 2.680039882659912 | BCE Loss: 1.02781081199646\n",
      "Epoch 23 / 500 | iteration 15 / 30 | Total Loss: 3.7767162322998047 | KNN Loss: 2.7182319164276123 | BCE Loss: 1.058484435081482\n",
      "Epoch 23 / 500 | iteration 20 / 30 | Total Loss: 3.7354838848114014 | KNN Loss: 2.69138240814209 | BCE Loss: 1.0441014766693115\n",
      "Epoch 23 / 500 | iteration 25 / 30 | Total Loss: 3.699486255645752 | KNN Loss: 2.65828537940979 | BCE Loss: 1.0412007570266724\n",
      "Epoch 24 / 500 | iteration 0 / 30 | Total Loss: 3.6747336387634277 | KNN Loss: 2.6475138664245605 | BCE Loss: 1.0272197723388672\n",
      "Epoch 24 / 500 | iteration 5 / 30 | Total Loss: 3.6653668880462646 | KNN Loss: 2.630871534347534 | BCE Loss: 1.0344953536987305\n",
      "Epoch 24 / 500 | iteration 10 / 30 | Total Loss: 3.7075424194335938 | KNN Loss: 2.6548445224761963 | BCE Loss: 1.052697777748108\n",
      "Epoch 24 / 500 | iteration 15 / 30 | Total Loss: 3.6670844554901123 | KNN Loss: 2.638472318649292 | BCE Loss: 1.0286121368408203\n",
      "Epoch 24 / 500 | iteration 20 / 30 | Total Loss: 3.7088513374328613 | KNN Loss: 2.6492080688476562 | BCE Loss: 1.0596431493759155\n",
      "Epoch 24 / 500 | iteration 25 / 30 | Total Loss: 3.7050557136535645 | KNN Loss: 2.674032211303711 | BCE Loss: 1.0310235023498535\n",
      "Epoch 25 / 500 | iteration 0 / 30 | Total Loss: 3.744516372680664 | KNN Loss: 2.711911916732788 | BCE Loss: 1.032604455947876\n",
      "Epoch 25 / 500 | iteration 5 / 30 | Total Loss: 3.7129878997802734 | KNN Loss: 2.659057378768921 | BCE Loss: 1.053930640220642\n",
      "Epoch 25 / 500 | iteration 10 / 30 | Total Loss: 3.706892967224121 | KNN Loss: 2.6737537384033203 | BCE Loss: 1.0331392288208008\n",
      "Epoch 25 / 500 | iteration 15 / 30 | Total Loss: 3.7069506645202637 | KNN Loss: 2.640242099761963 | BCE Loss: 1.0667084455490112\n",
      "Epoch 25 / 500 | iteration 20 / 30 | Total Loss: 3.76318359375 | KNN Loss: 2.7140302658081055 | BCE Loss: 1.049153447151184\n",
      "Epoch 25 / 500 | iteration 25 / 30 | Total Loss: 3.730734348297119 | KNN Loss: 2.676924705505371 | BCE Loss: 1.0538097620010376\n",
      "Epoch 26 / 500 | iteration 0 / 30 | Total Loss: 3.67097806930542 | KNN Loss: 2.617716073989868 | BCE Loss: 1.0532619953155518\n",
      "Epoch 26 / 500 | iteration 5 / 30 | Total Loss: 3.666607141494751 | KNN Loss: 2.6658544540405273 | BCE Loss: 1.0007526874542236\n",
      "Epoch 26 / 500 | iteration 10 / 30 | Total Loss: 3.679851531982422 | KNN Loss: 2.666256904602051 | BCE Loss: 1.0135947465896606\n",
      "Epoch 26 / 500 | iteration 15 / 30 | Total Loss: 3.681943655014038 | KNN Loss: 2.6302402019500732 | BCE Loss: 1.0517034530639648\n",
      "Epoch 26 / 500 | iteration 20 / 30 | Total Loss: 3.690762519836426 | KNN Loss: 2.6360578536987305 | BCE Loss: 1.0547046661376953\n",
      "Epoch 26 / 500 | iteration 25 / 30 | Total Loss: 3.6304144859313965 | KNN Loss: 2.6006202697753906 | BCE Loss: 1.0297940969467163\n",
      "Epoch 27 / 500 | iteration 0 / 30 | Total Loss: 3.707752227783203 | KNN Loss: 2.6590380668640137 | BCE Loss: 1.048714280128479\n",
      "Epoch 27 / 500 | iteration 5 / 30 | Total Loss: 3.6886703968048096 | KNN Loss: 2.6565303802490234 | BCE Loss: 1.0321400165557861\n",
      "Epoch 27 / 500 | iteration 10 / 30 | Total Loss: 3.6743087768554688 | KNN Loss: 2.6406972408294678 | BCE Loss: 1.0336116552352905\n",
      "Epoch 27 / 500 | iteration 15 / 30 | Total Loss: 3.67754864692688 | KNN Loss: 2.6481940746307373 | BCE Loss: 1.0293545722961426\n",
      "Epoch 27 / 500 | iteration 20 / 30 | Total Loss: 3.6737260818481445 | KNN Loss: 2.6282365322113037 | BCE Loss: 1.0454894304275513\n",
      "Epoch 27 / 500 | iteration 25 / 30 | Total Loss: 3.6352243423461914 | KNN Loss: 2.601062774658203 | BCE Loss: 1.0341615676879883\n",
      "Epoch 28 / 500 | iteration 0 / 30 | Total Loss: 3.6173620223999023 | KNN Loss: 2.59157133102417 | BCE Loss: 1.0257905721664429\n",
      "Epoch 28 / 500 | iteration 5 / 30 | Total Loss: 3.598223924636841 | KNN Loss: 2.5839743614196777 | BCE Loss: 1.014249563217163\n",
      "Epoch 28 / 500 | iteration 10 / 30 | Total Loss: 3.7510221004486084 | KNN Loss: 2.6831719875335693 | BCE Loss: 1.067850112915039\n",
      "Epoch 28 / 500 | iteration 15 / 30 | Total Loss: 3.6241352558135986 | KNN Loss: 2.585448741912842 | BCE Loss: 1.0386865139007568\n",
      "Epoch 28 / 500 | iteration 20 / 30 | Total Loss: 3.6756882667541504 | KNN Loss: 2.6408531665802 | BCE Loss: 1.0348351001739502\n",
      "Epoch 28 / 500 | iteration 25 / 30 | Total Loss: 3.6557326316833496 | KNN Loss: 2.622662305831909 | BCE Loss: 1.0330703258514404\n",
      "Epoch 29 / 500 | iteration 0 / 30 | Total Loss: 3.6619372367858887 | KNN Loss: 2.6306233406066895 | BCE Loss: 1.0313137769699097\n",
      "Epoch 29 / 500 | iteration 5 / 30 | Total Loss: 3.6283538341522217 | KNN Loss: 2.6094250679016113 | BCE Loss: 1.0189287662506104\n",
      "Epoch 29 / 500 | iteration 10 / 30 | Total Loss: 3.740227699279785 | KNN Loss: 2.677323818206787 | BCE Loss: 1.0629037618637085\n",
      "Epoch 29 / 500 | iteration 15 / 30 | Total Loss: 3.664079427719116 | KNN Loss: 2.6232547760009766 | BCE Loss: 1.0408246517181396\n",
      "Epoch 29 / 500 | iteration 20 / 30 | Total Loss: 3.6986114978790283 | KNN Loss: 2.6325695514678955 | BCE Loss: 1.0660419464111328\n",
      "Epoch 29 / 500 | iteration 25 / 30 | Total Loss: 3.6900243759155273 | KNN Loss: 2.6470015048980713 | BCE Loss: 1.0430227518081665\n",
      "Epoch 30 / 500 | iteration 0 / 30 | Total Loss: 3.540195941925049 | KNN Loss: 2.5455996990203857 | BCE Loss: 0.9945962429046631\n",
      "Epoch 30 / 500 | iteration 5 / 30 | Total Loss: 3.631899833679199 | KNN Loss: 2.5924413204193115 | BCE Loss: 1.0394583940505981\n",
      "Epoch 30 / 500 | iteration 10 / 30 | Total Loss: 3.6424121856689453 | KNN Loss: 2.615025043487549 | BCE Loss: 1.027387261390686\n",
      "Epoch 30 / 500 | iteration 15 / 30 | Total Loss: 3.6156692504882812 | KNN Loss: 2.5827715396881104 | BCE Loss: 1.0328978300094604\n",
      "Epoch 30 / 500 | iteration 20 / 30 | Total Loss: 3.6671409606933594 | KNN Loss: 2.627601146697998 | BCE Loss: 1.0395398139953613\n",
      "Epoch 30 / 500 | iteration 25 / 30 | Total Loss: 3.6050026416778564 | KNN Loss: 2.5719950199127197 | BCE Loss: 1.0330076217651367\n",
      "Epoch 31 / 500 | iteration 0 / 30 | Total Loss: 3.6386361122131348 | KNN Loss: 2.595132350921631 | BCE Loss: 1.043503761291504\n",
      "Epoch 31 / 500 | iteration 5 / 30 | Total Loss: 3.6869778633117676 | KNN Loss: 2.634068489074707 | BCE Loss: 1.0529093742370605\n",
      "Epoch 31 / 500 | iteration 10 / 30 | Total Loss: 3.6057798862457275 | KNN Loss: 2.5665204524993896 | BCE Loss: 1.039259433746338\n",
      "Epoch 31 / 500 | iteration 15 / 30 | Total Loss: 3.6990151405334473 | KNN Loss: 2.6584455966949463 | BCE Loss: 1.0405696630477905\n",
      "Epoch 31 / 500 | iteration 20 / 30 | Total Loss: 3.595470905303955 | KNN Loss: 2.5780675411224365 | BCE Loss: 1.0174033641815186\n",
      "Epoch 31 / 500 | iteration 25 / 30 | Total Loss: 3.6186413764953613 | KNN Loss: 2.6129488945007324 | BCE Loss: 1.0056923627853394\n",
      "Epoch 32 / 500 | iteration 0 / 30 | Total Loss: 3.711869955062866 | KNN Loss: 2.6845622062683105 | BCE Loss: 1.0273077487945557\n",
      "Epoch 32 / 500 | iteration 5 / 30 | Total Loss: 3.6238391399383545 | KNN Loss: 2.5684380531311035 | BCE Loss: 1.055401086807251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 500 | iteration 10 / 30 | Total Loss: 3.6349692344665527 | KNN Loss: 2.5865023136138916 | BCE Loss: 1.0484668016433716\n",
      "Epoch 32 / 500 | iteration 15 / 30 | Total Loss: 3.709860324859619 | KNN Loss: 2.6696319580078125 | BCE Loss: 1.0402283668518066\n",
      "Epoch 32 / 500 | iteration 20 / 30 | Total Loss: 3.582477569580078 | KNN Loss: 2.54008150100708 | BCE Loss: 1.0423959493637085\n",
      "Epoch 32 / 500 | iteration 25 / 30 | Total Loss: 3.575697898864746 | KNN Loss: 2.571176767349243 | BCE Loss: 1.004521131515503\n",
      "Epoch 33 / 500 | iteration 0 / 30 | Total Loss: 3.658238410949707 | KNN Loss: 2.632403612136841 | BCE Loss: 1.0258347988128662\n",
      "Epoch 33 / 500 | iteration 5 / 30 | Total Loss: 3.5832250118255615 | KNN Loss: 2.5571794509887695 | BCE Loss: 1.026045560836792\n",
      "Epoch 33 / 500 | iteration 10 / 30 | Total Loss: 3.619227647781372 | KNN Loss: 2.572521686553955 | BCE Loss: 1.046705961227417\n",
      "Epoch 33 / 500 | iteration 15 / 30 | Total Loss: 3.5785794258117676 | KNN Loss: 2.559694528579712 | BCE Loss: 1.0188847780227661\n",
      "Epoch 33 / 500 | iteration 20 / 30 | Total Loss: 3.6523914337158203 | KNN Loss: 2.6209568977355957 | BCE Loss: 1.0314346551895142\n",
      "Epoch 33 / 500 | iteration 25 / 30 | Total Loss: 3.597318410873413 | KNN Loss: 2.5839028358459473 | BCE Loss: 1.0134155750274658\n",
      "Epoch 34 / 500 | iteration 0 / 30 | Total Loss: 3.637413501739502 | KNN Loss: 2.5859625339508057 | BCE Loss: 1.0514509677886963\n",
      "Epoch 34 / 500 | iteration 5 / 30 | Total Loss: 3.6109485626220703 | KNN Loss: 2.5619983673095703 | BCE Loss: 1.0489503145217896\n",
      "Epoch 34 / 500 | iteration 10 / 30 | Total Loss: 3.7172818183898926 | KNN Loss: 2.6557228565216064 | BCE Loss: 1.0615590810775757\n",
      "Epoch 34 / 500 | iteration 15 / 30 | Total Loss: 3.624694347381592 | KNN Loss: 2.5954833030700684 | BCE Loss: 1.029211163520813\n",
      "Epoch 34 / 500 | iteration 20 / 30 | Total Loss: 3.6631648540496826 | KNN Loss: 2.6201350688934326 | BCE Loss: 1.04302978515625\n",
      "Epoch 34 / 500 | iteration 25 / 30 | Total Loss: 3.558389186859131 | KNN Loss: 2.5466361045837402 | BCE Loss: 1.011752963066101\n",
      "Epoch 35 / 500 | iteration 0 / 30 | Total Loss: 3.6758406162261963 | KNN Loss: 2.645238161087036 | BCE Loss: 1.0306024551391602\n",
      "Epoch 35 / 500 | iteration 5 / 30 | Total Loss: 3.6684064865112305 | KNN Loss: 2.640456438064575 | BCE Loss: 1.0279500484466553\n",
      "Epoch 35 / 500 | iteration 10 / 30 | Total Loss: 3.631098747253418 | KNN Loss: 2.604680061340332 | BCE Loss: 1.026418685913086\n",
      "Epoch 35 / 500 | iteration 15 / 30 | Total Loss: 3.6540799140930176 | KNN Loss: 2.644099712371826 | BCE Loss: 1.009980320930481\n",
      "Epoch 35 / 500 | iteration 20 / 30 | Total Loss: 3.6072044372558594 | KNN Loss: 2.5781428813934326 | BCE Loss: 1.0290615558624268\n",
      "Epoch 35 / 500 | iteration 25 / 30 | Total Loss: 3.6378936767578125 | KNN Loss: 2.607003927230835 | BCE Loss: 1.0308897495269775\n",
      "Epoch 36 / 500 | iteration 0 / 30 | Total Loss: 3.5977911949157715 | KNN Loss: 2.568309783935547 | BCE Loss: 1.029481291770935\n",
      "Epoch 36 / 500 | iteration 5 / 30 | Total Loss: 3.633688449859619 | KNN Loss: 2.605661153793335 | BCE Loss: 1.0280274152755737\n",
      "Epoch 36 / 500 | iteration 10 / 30 | Total Loss: 3.586378812789917 | KNN Loss: 2.545560836791992 | BCE Loss: 1.0408179759979248\n",
      "Epoch 36 / 500 | iteration 15 / 30 | Total Loss: 3.6046981811523438 | KNN Loss: 2.568171262741089 | BCE Loss: 1.0365270376205444\n",
      "Epoch 36 / 500 | iteration 20 / 30 | Total Loss: 3.5788235664367676 | KNN Loss: 2.561669111251831 | BCE Loss: 1.017154335975647\n",
      "Epoch 36 / 500 | iteration 25 / 30 | Total Loss: 3.5643911361694336 | KNN Loss: 2.5411863327026367 | BCE Loss: 1.0232048034667969\n",
      "Epoch 37 / 500 | iteration 0 / 30 | Total Loss: 3.643930196762085 | KNN Loss: 2.613848924636841 | BCE Loss: 1.0300812721252441\n",
      "Epoch 37 / 500 | iteration 5 / 30 | Total Loss: 3.62315034866333 | KNN Loss: 2.608863592147827 | BCE Loss: 1.0142866373062134\n",
      "Epoch 37 / 500 | iteration 10 / 30 | Total Loss: 3.683915615081787 | KNN Loss: 2.626901626586914 | BCE Loss: 1.057013988494873\n",
      "Epoch 37 / 500 | iteration 15 / 30 | Total Loss: 3.6309354305267334 | KNN Loss: 2.5732524394989014 | BCE Loss: 1.057682991027832\n",
      "Epoch 37 / 500 | iteration 20 / 30 | Total Loss: 3.5948727130889893 | KNN Loss: 2.5867388248443604 | BCE Loss: 1.008133888244629\n",
      "Epoch 37 / 500 | iteration 25 / 30 | Total Loss: 3.582505702972412 | KNN Loss: 2.558040142059326 | BCE Loss: 1.024465560913086\n",
      "Epoch 38 / 500 | iteration 0 / 30 | Total Loss: 3.6088199615478516 | KNN Loss: 2.5740630626678467 | BCE Loss: 1.0347568988800049\n",
      "Epoch 38 / 500 | iteration 5 / 30 | Total Loss: 3.5786020755767822 | KNN Loss: 2.5695884227752686 | BCE Loss: 1.0090136528015137\n",
      "Epoch 38 / 500 | iteration 10 / 30 | Total Loss: 3.619070053100586 | KNN Loss: 2.6052050590515137 | BCE Loss: 1.0138649940490723\n",
      "Epoch 38 / 500 | iteration 15 / 30 | Total Loss: 3.6403675079345703 | KNN Loss: 2.5901362895965576 | BCE Loss: 1.0502312183380127\n",
      "Epoch 38 / 500 | iteration 20 / 30 | Total Loss: 3.617764711380005 | KNN Loss: 2.548096179962158 | BCE Loss: 1.0696685314178467\n",
      "Epoch 38 / 500 | iteration 25 / 30 | Total Loss: 3.584778308868408 | KNN Loss: 2.5588223934173584 | BCE Loss: 1.0259560346603394\n",
      "Epoch 39 / 500 | iteration 0 / 30 | Total Loss: 3.6070597171783447 | KNN Loss: 2.546295404434204 | BCE Loss: 1.0607643127441406\n",
      "Epoch 39 / 500 | iteration 5 / 30 | Total Loss: 3.6501970291137695 | KNN Loss: 2.6254642009735107 | BCE Loss: 1.0247328281402588\n",
      "Epoch 39 / 500 | iteration 10 / 30 | Total Loss: 3.586582660675049 | KNN Loss: 2.587721347808838 | BCE Loss: 0.9988614320755005\n",
      "Epoch 39 / 500 | iteration 15 / 30 | Total Loss: 3.596139907836914 | KNN Loss: 2.5688698291778564 | BCE Loss: 1.027269959449768\n",
      "Epoch 39 / 500 | iteration 20 / 30 | Total Loss: 3.557915687561035 | KNN Loss: 2.542587995529175 | BCE Loss: 1.0153276920318604\n",
      "Epoch 39 / 500 | iteration 25 / 30 | Total Loss: 3.5934956073760986 | KNN Loss: 2.569246768951416 | BCE Loss: 1.0242488384246826\n",
      "Epoch 40 / 500 | iteration 0 / 30 | Total Loss: 3.661764144897461 | KNN Loss: 2.6367263793945312 | BCE Loss: 1.0250377655029297\n",
      "Epoch 40 / 500 | iteration 5 / 30 | Total Loss: 3.5861663818359375 | KNN Loss: 2.570403575897217 | BCE Loss: 1.0157626867294312\n",
      "Epoch 40 / 500 | iteration 10 / 30 | Total Loss: 3.6103675365448 | KNN Loss: 2.5887832641601562 | BCE Loss: 1.0215842723846436\n",
      "Epoch 40 / 500 | iteration 15 / 30 | Total Loss: 3.6056151390075684 | KNN Loss: 2.5909860134124756 | BCE Loss: 1.0146290063858032\n",
      "Epoch 40 / 500 | iteration 20 / 30 | Total Loss: 3.5970771312713623 | KNN Loss: 2.564756393432617 | BCE Loss: 1.0323207378387451\n",
      "Epoch 40 / 500 | iteration 25 / 30 | Total Loss: 3.6547818183898926 | KNN Loss: 2.6211280822753906 | BCE Loss: 1.0336536169052124\n",
      "Epoch 41 / 500 | iteration 0 / 30 | Total Loss: 3.5558156967163086 | KNN Loss: 2.56335711479187 | BCE Loss: 0.992458701133728\n",
      "Epoch 41 / 500 | iteration 5 / 30 | Total Loss: 3.5948235988616943 | KNN Loss: 2.5698680877685547 | BCE Loss: 1.0249555110931396\n",
      "Epoch 41 / 500 | iteration 10 / 30 | Total Loss: 3.6252989768981934 | KNN Loss: 2.6113719940185547 | BCE Loss: 1.0139271020889282\n",
      "Epoch 41 / 500 | iteration 15 / 30 | Total Loss: 3.6261959075927734 | KNN Loss: 2.5992259979248047 | BCE Loss: 1.0269700288772583\n",
      "Epoch 41 / 500 | iteration 20 / 30 | Total Loss: 3.707380533218384 | KNN Loss: 2.64981746673584 | BCE Loss: 1.057563066482544\n",
      "Epoch 41 / 500 | iteration 25 / 30 | Total Loss: 3.621497631072998 | KNN Loss: 2.5728418827056885 | BCE Loss: 1.0486557483673096\n",
      "Epoch 42 / 500 | iteration 0 / 30 | Total Loss: 3.6137704849243164 | KNN Loss: 2.5481436252593994 | BCE Loss: 1.0656267404556274\n",
      "Epoch 42 / 500 | iteration 5 / 30 | Total Loss: 3.5827910900115967 | KNN Loss: 2.5920932292938232 | BCE Loss: 0.9906978607177734\n",
      "Epoch 42 / 500 | iteration 10 / 30 | Total Loss: 3.5932726860046387 | KNN Loss: 2.550945520401001 | BCE Loss: 1.0423272848129272\n",
      "Epoch 42 / 500 | iteration 15 / 30 | Total Loss: 3.556704521179199 | KNN Loss: 2.5600807666778564 | BCE Loss: 0.9966237545013428\n",
      "Epoch 42 / 500 | iteration 20 / 30 | Total Loss: 3.5710463523864746 | KNN Loss: 2.5386011600494385 | BCE Loss: 1.0324451923370361\n",
      "Epoch 42 / 500 | iteration 25 / 30 | Total Loss: 3.598348617553711 | KNN Loss: 2.5572056770324707 | BCE Loss: 1.0411429405212402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 / 500 | iteration 0 / 30 | Total Loss: 3.610761880874634 | KNN Loss: 2.56288743019104 | BCE Loss: 1.0478744506835938\n",
      "Epoch 43 / 500 | iteration 5 / 30 | Total Loss: 3.5444395542144775 | KNN Loss: 2.53094220161438 | BCE Loss: 1.0134973526000977\n",
      "Epoch 43 / 500 | iteration 10 / 30 | Total Loss: 3.677459716796875 | KNN Loss: 2.616302013397217 | BCE Loss: 1.0611577033996582\n",
      "Epoch 43 / 500 | iteration 15 / 30 | Total Loss: 3.6485652923583984 | KNN Loss: 2.6028311252593994 | BCE Loss: 1.0457342863082886\n",
      "Epoch 43 / 500 | iteration 20 / 30 | Total Loss: 3.5360727310180664 | KNN Loss: 2.542710304260254 | BCE Loss: 0.993362307548523\n",
      "Epoch 43 / 500 | iteration 25 / 30 | Total Loss: 3.5642385482788086 | KNN Loss: 2.5197808742523193 | BCE Loss: 1.0444576740264893\n",
      "Epoch 44 / 500 | iteration 0 / 30 | Total Loss: 3.6286654472351074 | KNN Loss: 2.5832479000091553 | BCE Loss: 1.0454174280166626\n",
      "Epoch 44 / 500 | iteration 5 / 30 | Total Loss: 3.601832866668701 | KNN Loss: 2.5612523555755615 | BCE Loss: 1.0405806303024292\n",
      "Epoch 44 / 500 | iteration 10 / 30 | Total Loss: 3.660444736480713 | KNN Loss: 2.6414966583251953 | BCE Loss: 1.0189480781555176\n",
      "Epoch 44 / 500 | iteration 15 / 30 | Total Loss: 3.6276252269744873 | KNN Loss: 2.5921871662139893 | BCE Loss: 1.035438060760498\n",
      "Epoch 44 / 500 | iteration 20 / 30 | Total Loss: 3.5191564559936523 | KNN Loss: 2.5259034633636475 | BCE Loss: 0.9932528734207153\n",
      "Epoch 44 / 500 | iteration 25 / 30 | Total Loss: 3.5793182849884033 | KNN Loss: 2.541994094848633 | BCE Loss: 1.0373241901397705\n",
      "Epoch 45 / 500 | iteration 0 / 30 | Total Loss: 3.5700631141662598 | KNN Loss: 2.52815318107605 | BCE Loss: 1.04190993309021\n",
      "Epoch 45 / 500 | iteration 5 / 30 | Total Loss: 3.5970683097839355 | KNN Loss: 2.5645153522491455 | BCE Loss: 1.0325530767440796\n",
      "Epoch 45 / 500 | iteration 10 / 30 | Total Loss: 3.619441032409668 | KNN Loss: 2.5561439990997314 | BCE Loss: 1.0632970333099365\n",
      "Epoch 45 / 500 | iteration 15 / 30 | Total Loss: 3.5932765007019043 | KNN Loss: 2.571011781692505 | BCE Loss: 1.0222647190093994\n",
      "Epoch 45 / 500 | iteration 20 / 30 | Total Loss: 3.586435079574585 | KNN Loss: 2.5739052295684814 | BCE Loss: 1.0125298500061035\n",
      "Epoch 45 / 500 | iteration 25 / 30 | Total Loss: 3.706402540206909 | KNN Loss: 2.651179075241089 | BCE Loss: 1.0552234649658203\n",
      "Epoch 46 / 500 | iteration 0 / 30 | Total Loss: 3.6302645206451416 | KNN Loss: 2.5964934825897217 | BCE Loss: 1.03377103805542\n",
      "Epoch 46 / 500 | iteration 5 / 30 | Total Loss: 3.5708723068237305 | KNN Loss: 2.526886463165283 | BCE Loss: 1.0439858436584473\n",
      "Epoch 46 / 500 | iteration 10 / 30 | Total Loss: 3.663271903991699 | KNN Loss: 2.6245570182800293 | BCE Loss: 1.0387150049209595\n",
      "Epoch 46 / 500 | iteration 15 / 30 | Total Loss: 3.596954584121704 | KNN Loss: 2.5880444049835205 | BCE Loss: 1.0089101791381836\n",
      "Epoch 46 / 500 | iteration 20 / 30 | Total Loss: 3.5605506896972656 | KNN Loss: 2.5241732597351074 | BCE Loss: 1.0363774299621582\n",
      "Epoch 46 / 500 | iteration 25 / 30 | Total Loss: 3.6003265380859375 | KNN Loss: 2.552578926086426 | BCE Loss: 1.0477476119995117\n",
      "Epoch 47 / 500 | iteration 0 / 30 | Total Loss: 3.5801968574523926 | KNN Loss: 2.548022985458374 | BCE Loss: 1.0321738719940186\n",
      "Epoch 47 / 500 | iteration 5 / 30 | Total Loss: 3.542909860610962 | KNN Loss: 2.5250916481018066 | BCE Loss: 1.0178182125091553\n",
      "Epoch 47 / 500 | iteration 10 / 30 | Total Loss: 3.640798568725586 | KNN Loss: 2.616758108139038 | BCE Loss: 1.0240403413772583\n",
      "Epoch 47 / 500 | iteration 15 / 30 | Total Loss: 3.5891547203063965 | KNN Loss: 2.5282421112060547 | BCE Loss: 1.0609124898910522\n",
      "Epoch 47 / 500 | iteration 20 / 30 | Total Loss: 3.552283763885498 | KNN Loss: 2.5383129119873047 | BCE Loss: 1.0139708518981934\n",
      "Epoch 47 / 500 | iteration 25 / 30 | Total Loss: 3.52040433883667 | KNN Loss: 2.5277602672576904 | BCE Loss: 0.9926439523696899\n",
      "Epoch 48 / 500 | iteration 0 / 30 | Total Loss: 3.5567755699157715 | KNN Loss: 2.5395498275756836 | BCE Loss: 1.017225742340088\n",
      "Epoch 48 / 500 | iteration 5 / 30 | Total Loss: 3.5664758682250977 | KNN Loss: 2.5742733478546143 | BCE Loss: 0.9922025203704834\n",
      "Epoch 48 / 500 | iteration 10 / 30 | Total Loss: 3.6122536659240723 | KNN Loss: 2.592351198196411 | BCE Loss: 1.0199023485183716\n",
      "Epoch 48 / 500 | iteration 15 / 30 | Total Loss: 3.5885250568389893 | KNN Loss: 2.558426856994629 | BCE Loss: 1.0300981998443604\n",
      "Epoch 48 / 500 | iteration 20 / 30 | Total Loss: 3.6235878467559814 | KNN Loss: 2.6233370304107666 | BCE Loss: 1.0002508163452148\n",
      "Epoch 48 / 500 | iteration 25 / 30 | Total Loss: 3.5525975227355957 | KNN Loss: 2.520894765853882 | BCE Loss: 1.0317028760910034\n",
      "Epoch 49 / 500 | iteration 0 / 30 | Total Loss: 3.5612239837646484 | KNN Loss: 2.541367769241333 | BCE Loss: 1.0198562145233154\n",
      "Epoch 49 / 500 | iteration 5 / 30 | Total Loss: 3.597069263458252 | KNN Loss: 2.5711543560028076 | BCE Loss: 1.0259149074554443\n",
      "Epoch 49 / 500 | iteration 10 / 30 | Total Loss: 3.572782278060913 | KNN Loss: 2.5662057399749756 | BCE Loss: 1.0065765380859375\n",
      "Epoch 49 / 500 | iteration 15 / 30 | Total Loss: 3.6200814247131348 | KNN Loss: 2.5841667652130127 | BCE Loss: 1.0359145402908325\n",
      "Epoch 49 / 500 | iteration 20 / 30 | Total Loss: 3.5729870796203613 | KNN Loss: 2.564777374267578 | BCE Loss: 1.0082098245620728\n",
      "Epoch 49 / 500 | iteration 25 / 30 | Total Loss: 3.6122984886169434 | KNN Loss: 2.594355344772339 | BCE Loss: 1.017943024635315\n",
      "Epoch 50 / 500 | iteration 0 / 30 | Total Loss: 3.55292010307312 | KNN Loss: 2.541452169418335 | BCE Loss: 1.0114679336547852\n",
      "Epoch 50 / 500 | iteration 5 / 30 | Total Loss: 3.61230206489563 | KNN Loss: 2.587273359298706 | BCE Loss: 1.0250287055969238\n",
      "Epoch 50 / 500 | iteration 10 / 30 | Total Loss: 3.614631175994873 | KNN Loss: 2.5629825592041016 | BCE Loss: 1.0516486167907715\n",
      "Epoch 50 / 500 | iteration 15 / 30 | Total Loss: 3.557711124420166 | KNN Loss: 2.547353744506836 | BCE Loss: 1.01035737991333\n",
      "Epoch 50 / 500 | iteration 20 / 30 | Total Loss: 3.597402811050415 | KNN Loss: 2.5543744564056396 | BCE Loss: 1.0430283546447754\n",
      "Epoch 50 / 500 | iteration 25 / 30 | Total Loss: 3.6039328575134277 | KNN Loss: 2.5386693477630615 | BCE Loss: 1.0652635097503662\n",
      "Epoch 51 / 500 | iteration 0 / 30 | Total Loss: 3.599252939224243 | KNN Loss: 2.5651159286499023 | BCE Loss: 1.0341370105743408\n",
      "Epoch 51 / 500 | iteration 5 / 30 | Total Loss: 3.5636353492736816 | KNN Loss: 2.5014493465423584 | BCE Loss: 1.0621861219406128\n",
      "Epoch 51 / 500 | iteration 10 / 30 | Total Loss: 3.5450165271759033 | KNN Loss: 2.51413893699646 | BCE Loss: 1.0308775901794434\n",
      "Epoch 51 / 500 | iteration 15 / 30 | Total Loss: 3.630911111831665 | KNN Loss: 2.5767247676849365 | BCE Loss: 1.0541863441467285\n",
      "Epoch 51 / 500 | iteration 20 / 30 | Total Loss: 3.579986095428467 | KNN Loss: 2.539384603500366 | BCE Loss: 1.0406014919281006\n",
      "Epoch 51 / 500 | iteration 25 / 30 | Total Loss: 3.5465879440307617 | KNN Loss: 2.5423855781555176 | BCE Loss: 1.0042023658752441\n",
      "Epoch 52 / 500 | iteration 0 / 30 | Total Loss: 3.5628507137298584 | KNN Loss: 2.5498557090759277 | BCE Loss: 1.0129950046539307\n",
      "Epoch 52 / 500 | iteration 5 / 30 | Total Loss: 3.560120105743408 | KNN Loss: 2.5760858058929443 | BCE Loss: 0.9840344190597534\n",
      "Epoch 52 / 500 | iteration 10 / 30 | Total Loss: 3.5457611083984375 | KNN Loss: 2.525498390197754 | BCE Loss: 1.0202628374099731\n",
      "Epoch 52 / 500 | iteration 15 / 30 | Total Loss: 3.571408271789551 | KNN Loss: 2.5292325019836426 | BCE Loss: 1.0421757698059082\n",
      "Epoch 52 / 500 | iteration 20 / 30 | Total Loss: 3.6082589626312256 | KNN Loss: 2.572070360183716 | BCE Loss: 1.0361886024475098\n",
      "Epoch 52 / 500 | iteration 25 / 30 | Total Loss: 3.5590577125549316 | KNN Loss: 2.5692036151885986 | BCE Loss: 0.9898539781570435\n",
      "Epoch 53 / 500 | iteration 0 / 30 | Total Loss: 3.5959391593933105 | KNN Loss: 2.581179618835449 | BCE Loss: 1.0147594213485718\n",
      "Epoch 53 / 500 | iteration 5 / 30 | Total Loss: 3.5352401733398438 | KNN Loss: 2.528599500656128 | BCE Loss: 1.0066405534744263\n",
      "Epoch 53 / 500 | iteration 10 / 30 | Total Loss: 3.657027244567871 | KNN Loss: 2.5984857082366943 | BCE Loss: 1.0585416555404663\n",
      "Epoch 53 / 500 | iteration 15 / 30 | Total Loss: 3.577127695083618 | KNN Loss: 2.564495086669922 | BCE Loss: 1.0126326084136963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 / 500 | iteration 20 / 30 | Total Loss: 3.5895376205444336 | KNN Loss: 2.5695345401763916 | BCE Loss: 1.0200029611587524\n",
      "Epoch 53 / 500 | iteration 25 / 30 | Total Loss: 3.5572471618652344 | KNN Loss: 2.551034450531006 | BCE Loss: 1.0062127113342285\n",
      "Epoch 54 / 500 | iteration 0 / 30 | Total Loss: 3.576753616333008 | KNN Loss: 2.546872615814209 | BCE Loss: 1.0298810005187988\n",
      "Epoch 54 / 500 | iteration 5 / 30 | Total Loss: 3.6599910259246826 | KNN Loss: 2.6025888919830322 | BCE Loss: 1.0574021339416504\n",
      "Epoch 54 / 500 | iteration 10 / 30 | Total Loss: 3.6276564598083496 | KNN Loss: 2.5744032859802246 | BCE Loss: 1.0532532930374146\n",
      "Epoch 54 / 500 | iteration 15 / 30 | Total Loss: 3.587306499481201 | KNN Loss: 2.5536444187164307 | BCE Loss: 1.03366219997406\n",
      "Epoch 54 / 500 | iteration 20 / 30 | Total Loss: 3.5825631618499756 | KNN Loss: 2.5526204109191895 | BCE Loss: 1.0299427509307861\n",
      "Epoch 54 / 500 | iteration 25 / 30 | Total Loss: 3.598851203918457 | KNN Loss: 2.569169521331787 | BCE Loss: 1.0296815633773804\n",
      "Epoch 55 / 500 | iteration 0 / 30 | Total Loss: 3.5175399780273438 | KNN Loss: 2.5243093967437744 | BCE Loss: 0.9932304620742798\n",
      "Epoch 55 / 500 | iteration 5 / 30 | Total Loss: 3.573202133178711 | KNN Loss: 2.557793617248535 | BCE Loss: 1.0154086351394653\n",
      "Epoch 55 / 500 | iteration 10 / 30 | Total Loss: 3.539384603500366 | KNN Loss: 2.5241737365722656 | BCE Loss: 1.0152108669281006\n",
      "Epoch 55 / 500 | iteration 15 / 30 | Total Loss: 3.5976245403289795 | KNN Loss: 2.5688483715057373 | BCE Loss: 1.0287761688232422\n",
      "Epoch 55 / 500 | iteration 20 / 30 | Total Loss: 3.6252081394195557 | KNN Loss: 2.5733413696289062 | BCE Loss: 1.0518667697906494\n",
      "Epoch 55 / 500 | iteration 25 / 30 | Total Loss: 3.536771774291992 | KNN Loss: 2.5304436683654785 | BCE Loss: 1.0063279867172241\n",
      "Epoch 56 / 500 | iteration 0 / 30 | Total Loss: 3.5870046615600586 | KNN Loss: 2.5653204917907715 | BCE Loss: 1.021684169769287\n",
      "Epoch 56 / 500 | iteration 5 / 30 | Total Loss: 3.5527303218841553 | KNN Loss: 2.5311973094940186 | BCE Loss: 1.0215330123901367\n",
      "Epoch 56 / 500 | iteration 10 / 30 | Total Loss: 3.5481576919555664 | KNN Loss: 2.542917013168335 | BCE Loss: 1.0052406787872314\n",
      "Epoch 56 / 500 | iteration 15 / 30 | Total Loss: 3.529972553253174 | KNN Loss: 2.5041587352752686 | BCE Loss: 1.0258138179779053\n",
      "Epoch 56 / 500 | iteration 20 / 30 | Total Loss: 3.5746352672576904 | KNN Loss: 2.540045738220215 | BCE Loss: 1.0345895290374756\n",
      "Epoch 56 / 500 | iteration 25 / 30 | Total Loss: 3.5986695289611816 | KNN Loss: 2.5769927501678467 | BCE Loss: 1.021676778793335\n",
      "Epoch 57 / 500 | iteration 0 / 30 | Total Loss: 3.558511257171631 | KNN Loss: 2.5609569549560547 | BCE Loss: 0.9975542426109314\n",
      "Epoch 57 / 500 | iteration 5 / 30 | Total Loss: 3.5364279747009277 | KNN Loss: 2.542170763015747 | BCE Loss: 0.9942570924758911\n",
      "Epoch 57 / 500 | iteration 10 / 30 | Total Loss: 3.547799587249756 | KNN Loss: 2.542055130004883 | BCE Loss: 1.0057443380355835\n",
      "Epoch 57 / 500 | iteration 15 / 30 | Total Loss: 3.579592704772949 | KNN Loss: 2.5739798545837402 | BCE Loss: 1.0056129693984985\n",
      "Epoch 57 / 500 | iteration 20 / 30 | Total Loss: 3.6234960556030273 | KNN Loss: 2.595578670501709 | BCE Loss: 1.0279173851013184\n",
      "Epoch 57 / 500 | iteration 25 / 30 | Total Loss: 3.538594961166382 | KNN Loss: 2.5224549770355225 | BCE Loss: 1.0161399841308594\n",
      "Epoch 58 / 500 | iteration 0 / 30 | Total Loss: 3.5844221115112305 | KNN Loss: 2.5510785579681396 | BCE Loss: 1.0333435535430908\n",
      "Epoch 58 / 500 | iteration 5 / 30 | Total Loss: 3.580939769744873 | KNN Loss: 2.56785249710083 | BCE Loss: 1.0130871534347534\n",
      "Epoch 58 / 500 | iteration 10 / 30 | Total Loss: 3.580599308013916 | KNN Loss: 2.54093861579895 | BCE Loss: 1.0396605730056763\n",
      "Epoch 58 / 500 | iteration 15 / 30 | Total Loss: 3.550027370452881 | KNN Loss: 2.5087151527404785 | BCE Loss: 1.0413122177124023\n",
      "Epoch 58 / 500 | iteration 20 / 30 | Total Loss: 3.5903432369232178 | KNN Loss: 2.57464861869812 | BCE Loss: 1.0156946182250977\n",
      "Epoch 58 / 500 | iteration 25 / 30 | Total Loss: 3.5867321491241455 | KNN Loss: 2.5692873001098633 | BCE Loss: 1.0174448490142822\n",
      "Epoch 59 / 500 | iteration 0 / 30 | Total Loss: 3.5874693393707275 | KNN Loss: 2.5507142543792725 | BCE Loss: 1.036755084991455\n",
      "Epoch 59 / 500 | iteration 5 / 30 | Total Loss: 3.535789966583252 | KNN Loss: 2.509221315383911 | BCE Loss: 1.0265686511993408\n",
      "Epoch 59 / 500 | iteration 10 / 30 | Total Loss: 3.550457715988159 | KNN Loss: 2.5294246673583984 | BCE Loss: 1.0210330486297607\n",
      "Epoch 59 / 500 | iteration 15 / 30 | Total Loss: 3.563615322113037 | KNN Loss: 2.5324580669403076 | BCE Loss: 1.03115713596344\n",
      "Epoch 59 / 500 | iteration 20 / 30 | Total Loss: 3.512042999267578 | KNN Loss: 2.517849922180176 | BCE Loss: 0.9941931962966919\n",
      "Epoch 59 / 500 | iteration 25 / 30 | Total Loss: 3.5702927112579346 | KNN Loss: 2.52429461479187 | BCE Loss: 1.0459980964660645\n",
      "Epoch 60 / 500 | iteration 0 / 30 | Total Loss: 3.6095874309539795 | KNN Loss: 2.5672874450683594 | BCE Loss: 1.0422999858856201\n",
      "Epoch 60 / 500 | iteration 5 / 30 | Total Loss: 3.602991819381714 | KNN Loss: 2.5793797969818115 | BCE Loss: 1.0236120223999023\n",
      "Epoch 60 / 500 | iteration 10 / 30 | Total Loss: 3.530795097351074 | KNN Loss: 2.5563876628875732 | BCE Loss: 0.9744073748588562\n",
      "Epoch 60 / 500 | iteration 15 / 30 | Total Loss: 3.591383934020996 | KNN Loss: 2.5751423835754395 | BCE Loss: 1.0162415504455566\n",
      "Epoch 60 / 500 | iteration 20 / 30 | Total Loss: 3.528575897216797 | KNN Loss: 2.520042896270752 | BCE Loss: 1.0085331201553345\n",
      "Epoch 60 / 500 | iteration 25 / 30 | Total Loss: 3.509446144104004 | KNN Loss: 2.5052268505096436 | BCE Loss: 1.00421941280365\n",
      "Epoch 61 / 500 | iteration 0 / 30 | Total Loss: 3.5553500652313232 | KNN Loss: 2.5427818298339844 | BCE Loss: 1.0125682353973389\n",
      "Epoch 61 / 500 | iteration 5 / 30 | Total Loss: 3.619014263153076 | KNN Loss: 2.5957815647125244 | BCE Loss: 1.0232326984405518\n",
      "Epoch 61 / 500 | iteration 10 / 30 | Total Loss: 3.530179977416992 | KNN Loss: 2.5291171073913574 | BCE Loss: 1.0010627508163452\n",
      "Epoch 61 / 500 | iteration 15 / 30 | Total Loss: 3.5582637786865234 | KNN Loss: 2.526329278945923 | BCE Loss: 1.0319344997406006\n",
      "Epoch 61 / 500 | iteration 20 / 30 | Total Loss: 3.5734481811523438 | KNN Loss: 2.548368453979492 | BCE Loss: 1.0250797271728516\n",
      "Epoch 61 / 500 | iteration 25 / 30 | Total Loss: 3.6117589473724365 | KNN Loss: 2.5791873931884766 | BCE Loss: 1.03257155418396\n",
      "Epoch 62 / 500 | iteration 0 / 30 | Total Loss: 3.5380187034606934 | KNN Loss: 2.497567653656006 | BCE Loss: 1.040451169013977\n",
      "Epoch 62 / 500 | iteration 5 / 30 | Total Loss: 3.540811061859131 | KNN Loss: 2.5516960620880127 | BCE Loss: 0.9891149997711182\n",
      "Epoch 62 / 500 | iteration 10 / 30 | Total Loss: 3.590195655822754 | KNN Loss: 2.576059341430664 | BCE Loss: 1.0141363143920898\n",
      "Epoch 62 / 500 | iteration 15 / 30 | Total Loss: 3.572632312774658 | KNN Loss: 2.532243490219116 | BCE Loss: 1.040388822555542\n",
      "Epoch 62 / 500 | iteration 20 / 30 | Total Loss: 3.566650629043579 | KNN Loss: 2.5169622898101807 | BCE Loss: 1.0496883392333984\n",
      "Epoch 62 / 500 | iteration 25 / 30 | Total Loss: 3.5983080863952637 | KNN Loss: 2.5567755699157715 | BCE Loss: 1.0415325164794922\n",
      "Epoch 63 / 500 | iteration 0 / 30 | Total Loss: 3.535888671875 | KNN Loss: 2.5246379375457764 | BCE Loss: 1.0112507343292236\n",
      "Epoch 63 / 500 | iteration 5 / 30 | Total Loss: 3.5152549743652344 | KNN Loss: 2.508437395095825 | BCE Loss: 1.0068176984786987\n",
      "Epoch 63 / 500 | iteration 10 / 30 | Total Loss: 3.5724544525146484 | KNN Loss: 2.561244487762451 | BCE Loss: 1.0112100839614868\n",
      "Epoch 63 / 500 | iteration 15 / 30 | Total Loss: 3.557493209838867 | KNN Loss: 2.544072151184082 | BCE Loss: 1.0134210586547852\n",
      "Epoch 63 / 500 | iteration 20 / 30 | Total Loss: 3.60793399810791 | KNN Loss: 2.5664873123168945 | BCE Loss: 1.041446566581726\n",
      "Epoch 63 / 500 | iteration 25 / 30 | Total Loss: 3.567521095275879 | KNN Loss: 2.5565402507781982 | BCE Loss: 1.0109807252883911\n",
      "Epoch 64 / 500 | iteration 0 / 30 | Total Loss: 3.599149227142334 | KNN Loss: 2.5721161365509033 | BCE Loss: 1.0270330905914307\n",
      "Epoch 64 / 500 | iteration 5 / 30 | Total Loss: 3.5777735710144043 | KNN Loss: 2.539155960083008 | BCE Loss: 1.038617491722107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 / 500 | iteration 10 / 30 | Total Loss: 3.585465908050537 | KNN Loss: 2.552129030227661 | BCE Loss: 1.0333369970321655\n",
      "Epoch 64 / 500 | iteration 15 / 30 | Total Loss: 3.5608396530151367 | KNN Loss: 2.5394670963287354 | BCE Loss: 1.0213725566864014\n",
      "Epoch 64 / 500 | iteration 20 / 30 | Total Loss: 3.5875821113586426 | KNN Loss: 2.570178508758545 | BCE Loss: 1.017403483390808\n",
      "Epoch 64 / 500 | iteration 25 / 30 | Total Loss: 3.5298104286193848 | KNN Loss: 2.4983975887298584 | BCE Loss: 1.0314128398895264\n",
      "Epoch 65 / 500 | iteration 0 / 30 | Total Loss: 3.5792436599731445 | KNN Loss: 2.533919095993042 | BCE Loss: 1.045324444770813\n",
      "Epoch 65 / 500 | iteration 5 / 30 | Total Loss: 3.516679525375366 | KNN Loss: 2.5165629386901855 | BCE Loss: 1.0001165866851807\n",
      "Epoch 65 / 500 | iteration 10 / 30 | Total Loss: 3.5751900672912598 | KNN Loss: 2.519615650177002 | BCE Loss: 1.0555744171142578\n",
      "Epoch 65 / 500 | iteration 15 / 30 | Total Loss: 3.564438819885254 | KNN Loss: 2.549682855606079 | BCE Loss: 1.0147559642791748\n",
      "Epoch 65 / 500 | iteration 20 / 30 | Total Loss: 3.5644359588623047 | KNN Loss: 2.5339975357055664 | BCE Loss: 1.0304384231567383\n",
      "Epoch 65 / 500 | iteration 25 / 30 | Total Loss: 3.5574488639831543 | KNN Loss: 2.5141427516937256 | BCE Loss: 1.0433061122894287\n",
      "Epoch 66 / 500 | iteration 0 / 30 | Total Loss: 3.5756285190582275 | KNN Loss: 2.5590784549713135 | BCE Loss: 1.016550064086914\n",
      "Epoch 66 / 500 | iteration 5 / 30 | Total Loss: 3.5418496131896973 | KNN Loss: 2.5189387798309326 | BCE Loss: 1.022910714149475\n",
      "Epoch 66 / 500 | iteration 10 / 30 | Total Loss: 3.5430970191955566 | KNN Loss: 2.517732858657837 | BCE Loss: 1.0253640413284302\n",
      "Epoch 66 / 500 | iteration 15 / 30 | Total Loss: 3.584981918334961 | KNN Loss: 2.561145305633545 | BCE Loss: 1.0238367319107056\n",
      "Epoch 66 / 500 | iteration 20 / 30 | Total Loss: 3.515681743621826 | KNN Loss: 2.531503915786743 | BCE Loss: 0.984177827835083\n",
      "Epoch 66 / 500 | iteration 25 / 30 | Total Loss: 3.514984607696533 | KNN Loss: 2.5199244022369385 | BCE Loss: 0.9950602054595947\n",
      "Epoch 67 / 500 | iteration 0 / 30 | Total Loss: 3.6053218841552734 | KNN Loss: 2.557222843170166 | BCE Loss: 1.0480990409851074\n",
      "Epoch 67 / 500 | iteration 5 / 30 | Total Loss: 3.594390869140625 | KNN Loss: 2.5682337284088135 | BCE Loss: 1.0261571407318115\n",
      "Epoch 67 / 500 | iteration 10 / 30 | Total Loss: 3.573293924331665 | KNN Loss: 2.5530788898468018 | BCE Loss: 1.0202150344848633\n",
      "Epoch 67 / 500 | iteration 15 / 30 | Total Loss: 3.554600954055786 | KNN Loss: 2.518723487854004 | BCE Loss: 1.0358774662017822\n",
      "Epoch 67 / 500 | iteration 20 / 30 | Total Loss: 3.4900615215301514 | KNN Loss: 2.4935965538024902 | BCE Loss: 0.9964649677276611\n",
      "Epoch 67 / 500 | iteration 25 / 30 | Total Loss: 3.560504198074341 | KNN Loss: 2.5204503536224365 | BCE Loss: 1.0400538444519043\n",
      "Epoch 68 / 500 | iteration 0 / 30 | Total Loss: 3.546320676803589 | KNN Loss: 2.505544424057007 | BCE Loss: 1.040776252746582\n",
      "Epoch 68 / 500 | iteration 5 / 30 | Total Loss: 3.582386016845703 | KNN Loss: 2.5724873542785645 | BCE Loss: 1.0098986625671387\n",
      "Epoch 68 / 500 | iteration 10 / 30 | Total Loss: 3.507730484008789 | KNN Loss: 2.5025665760040283 | BCE Loss: 1.0051640272140503\n",
      "Epoch 68 / 500 | iteration 15 / 30 | Total Loss: 3.5364010334014893 | KNN Loss: 2.523319959640503 | BCE Loss: 1.0130810737609863\n",
      "Epoch 68 / 500 | iteration 20 / 30 | Total Loss: 3.540710687637329 | KNN Loss: 2.512937068939209 | BCE Loss: 1.0277736186981201\n",
      "Epoch 68 / 500 | iteration 25 / 30 | Total Loss: 3.5742287635803223 | KNN Loss: 2.5349221229553223 | BCE Loss: 1.0393065214157104\n",
      "Epoch 69 / 500 | iteration 0 / 30 | Total Loss: 3.542222261428833 | KNN Loss: 2.524384021759033 | BCE Loss: 1.0178382396697998\n",
      "Epoch 69 / 500 | iteration 5 / 30 | Total Loss: 3.5383193492889404 | KNN Loss: 2.5213053226470947 | BCE Loss: 1.0170140266418457\n",
      "Epoch 69 / 500 | iteration 10 / 30 | Total Loss: 3.541962146759033 | KNN Loss: 2.529726266860962 | BCE Loss: 1.0122359991073608\n",
      "Epoch 69 / 500 | iteration 15 / 30 | Total Loss: 3.583411455154419 | KNN Loss: 2.5389275550842285 | BCE Loss: 1.0444839000701904\n",
      "Epoch 69 / 500 | iteration 20 / 30 | Total Loss: 3.540414333343506 | KNN Loss: 2.523815631866455 | BCE Loss: 1.0165988206863403\n",
      "Epoch 69 / 500 | iteration 25 / 30 | Total Loss: 3.5566983222961426 | KNN Loss: 2.5323240756988525 | BCE Loss: 1.0243743658065796\n",
      "Epoch 70 / 500 | iteration 0 / 30 | Total Loss: 3.5396945476531982 | KNN Loss: 2.5300679206848145 | BCE Loss: 1.0096266269683838\n",
      "Epoch 70 / 500 | iteration 5 / 30 | Total Loss: 3.574364185333252 | KNN Loss: 2.571183204650879 | BCE Loss: 1.0031808614730835\n",
      "Epoch 70 / 500 | iteration 10 / 30 | Total Loss: 3.591573715209961 | KNN Loss: 2.574129819869995 | BCE Loss: 1.0174440145492554\n",
      "Epoch 70 / 500 | iteration 15 / 30 | Total Loss: 3.548699378967285 | KNN Loss: 2.534911632537842 | BCE Loss: 1.0137876272201538\n",
      "Epoch 70 / 500 | iteration 20 / 30 | Total Loss: 3.557088851928711 | KNN Loss: 2.5294604301452637 | BCE Loss: 1.0276284217834473\n",
      "Epoch 70 / 500 | iteration 25 / 30 | Total Loss: 3.534226417541504 | KNN Loss: 2.5102434158325195 | BCE Loss: 1.023983120918274\n",
      "Epoch 71 / 500 | iteration 0 / 30 | Total Loss: 3.515460729598999 | KNN Loss: 2.507220983505249 | BCE Loss: 1.00823974609375\n",
      "Epoch 71 / 500 | iteration 5 / 30 | Total Loss: 3.5784528255462646 | KNN Loss: 2.5409300327301025 | BCE Loss: 1.037522792816162\n",
      "Epoch 71 / 500 | iteration 10 / 30 | Total Loss: 3.537121057510376 | KNN Loss: 2.5199179649353027 | BCE Loss: 1.0172030925750732\n",
      "Epoch 71 / 500 | iteration 15 / 30 | Total Loss: 3.5742557048797607 | KNN Loss: 2.5448169708251953 | BCE Loss: 1.0294387340545654\n",
      "Epoch 71 / 500 | iteration 20 / 30 | Total Loss: 3.5345544815063477 | KNN Loss: 2.503889560699463 | BCE Loss: 1.0306649208068848\n",
      "Epoch 71 / 500 | iteration 25 / 30 | Total Loss: 3.5735669136047363 | KNN Loss: 2.5089046955108643 | BCE Loss: 1.0646623373031616\n",
      "Epoch 72 / 500 | iteration 0 / 30 | Total Loss: 3.5560030937194824 | KNN Loss: 2.5144805908203125 | BCE Loss: 1.04152250289917\n",
      "Epoch 72 / 500 | iteration 5 / 30 | Total Loss: 3.5454049110412598 | KNN Loss: 2.5512170791625977 | BCE Loss: 0.9941878318786621\n",
      "Epoch 72 / 500 | iteration 10 / 30 | Total Loss: 3.5505456924438477 | KNN Loss: 2.537158727645874 | BCE Loss: 1.0133869647979736\n",
      "Epoch 72 / 500 | iteration 15 / 30 | Total Loss: 3.5508856773376465 | KNN Loss: 2.5223398208618164 | BCE Loss: 1.02854585647583\n",
      "Epoch 72 / 500 | iteration 20 / 30 | Total Loss: 3.5704169273376465 | KNN Loss: 2.5634422302246094 | BCE Loss: 1.0069748163223267\n",
      "Epoch 72 / 500 | iteration 25 / 30 | Total Loss: 3.6169278621673584 | KNN Loss: 2.5727901458740234 | BCE Loss: 1.044137716293335\n",
      "Epoch 73 / 500 | iteration 0 / 30 | Total Loss: 3.5520758628845215 | KNN Loss: 2.5502283573150635 | BCE Loss: 1.0018473863601685\n",
      "Epoch 73 / 500 | iteration 5 / 30 | Total Loss: 3.558298349380493 | KNN Loss: 2.524386405944824 | BCE Loss: 1.033911943435669\n",
      "Epoch 73 / 500 | iteration 10 / 30 | Total Loss: 3.5303874015808105 | KNN Loss: 2.5106184482574463 | BCE Loss: 1.0197688341140747\n",
      "Epoch 73 / 500 | iteration 15 / 30 | Total Loss: 3.5165271759033203 | KNN Loss: 2.50909423828125 | BCE Loss: 1.0074329376220703\n",
      "Epoch 73 / 500 | iteration 20 / 30 | Total Loss: 3.551239490509033 | KNN Loss: 2.500427722930908 | BCE Loss: 1.050811767578125\n",
      "Epoch 73 / 500 | iteration 25 / 30 | Total Loss: 3.572948694229126 | KNN Loss: 2.526456117630005 | BCE Loss: 1.046492576599121\n",
      "Epoch 74 / 500 | iteration 0 / 30 | Total Loss: 3.5419933795928955 | KNN Loss: 2.539825916290283 | BCE Loss: 1.0021674633026123\n",
      "Epoch 74 / 500 | iteration 5 / 30 | Total Loss: 3.52711820602417 | KNN Loss: 2.499450206756592 | BCE Loss: 1.0276679992675781\n",
      "Epoch 74 / 500 | iteration 10 / 30 | Total Loss: 3.57053279876709 | KNN Loss: 2.5355091094970703 | BCE Loss: 1.03502357006073\n",
      "Epoch 74 / 500 | iteration 15 / 30 | Total Loss: 3.5165958404541016 | KNN Loss: 2.493041515350342 | BCE Loss: 1.0235542058944702\n",
      "Epoch 74 / 500 | iteration 20 / 30 | Total Loss: 3.572711706161499 | KNN Loss: 2.579080581665039 | BCE Loss: 0.99363112449646\n",
      "Epoch 74 / 500 | iteration 25 / 30 | Total Loss: 3.521897077560425 | KNN Loss: 2.4895436763763428 | BCE Loss: 1.032353401184082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 500 | iteration 0 / 30 | Total Loss: 3.5113983154296875 | KNN Loss: 2.489837884902954 | BCE Loss: 1.021560549736023\n",
      "Epoch 75 / 500 | iteration 5 / 30 | Total Loss: 3.551206588745117 | KNN Loss: 2.510192394256592 | BCE Loss: 1.041014313697815\n",
      "Epoch 75 / 500 | iteration 10 / 30 | Total Loss: 3.5672738552093506 | KNN Loss: 2.5317435264587402 | BCE Loss: 1.0355303287506104\n",
      "Epoch 75 / 500 | iteration 15 / 30 | Total Loss: 3.5376336574554443 | KNN Loss: 2.539167881011963 | BCE Loss: 0.9984658360481262\n",
      "Epoch 75 / 500 | iteration 20 / 30 | Total Loss: 3.5633864402770996 | KNN Loss: 2.520132541656494 | BCE Loss: 1.0432538986206055\n",
      "Epoch 75 / 500 | iteration 25 / 30 | Total Loss: 3.5208120346069336 | KNN Loss: 2.514152765274048 | BCE Loss: 1.0066593885421753\n",
      "Epoch 76 / 500 | iteration 0 / 30 | Total Loss: 3.5505008697509766 | KNN Loss: 2.507652997970581 | BCE Loss: 1.042847990989685\n",
      "Epoch 76 / 500 | iteration 5 / 30 | Total Loss: 3.588606357574463 | KNN Loss: 2.574306011199951 | BCE Loss: 1.0143002271652222\n",
      "Epoch 76 / 500 | iteration 10 / 30 | Total Loss: 3.5227913856506348 | KNN Loss: 2.531543493270874 | BCE Loss: 0.9912480115890503\n",
      "Epoch 76 / 500 | iteration 15 / 30 | Total Loss: 3.499779462814331 | KNN Loss: 2.4691274166107178 | BCE Loss: 1.0306520462036133\n",
      "Epoch 76 / 500 | iteration 20 / 30 | Total Loss: 3.570596218109131 | KNN Loss: 2.5300652980804443 | BCE Loss: 1.040531039237976\n",
      "Epoch 76 / 500 | iteration 25 / 30 | Total Loss: 3.4944963455200195 | KNN Loss: 2.4957425594329834 | BCE Loss: 0.9987537860870361\n",
      "Epoch 77 / 500 | iteration 0 / 30 | Total Loss: 3.5341243743896484 | KNN Loss: 2.497276782989502 | BCE Loss: 1.036847472190857\n",
      "Epoch 77 / 500 | iteration 5 / 30 | Total Loss: 3.5514025688171387 | KNN Loss: 2.539757013320923 | BCE Loss: 1.0116456747055054\n",
      "Epoch 77 / 500 | iteration 10 / 30 | Total Loss: 3.511451005935669 | KNN Loss: 2.4807190895080566 | BCE Loss: 1.0307319164276123\n",
      "Epoch 77 / 500 | iteration 15 / 30 | Total Loss: 3.5035948753356934 | KNN Loss: 2.5096592903137207 | BCE Loss: 0.9939354658126831\n",
      "Epoch 77 / 500 | iteration 20 / 30 | Total Loss: 3.52176833152771 | KNN Loss: 2.4959301948547363 | BCE Loss: 1.0258381366729736\n",
      "Epoch 77 / 500 | iteration 25 / 30 | Total Loss: 3.5741214752197266 | KNN Loss: 2.5361032485961914 | BCE Loss: 1.0380182266235352\n",
      "Epoch 78 / 500 | iteration 0 / 30 | Total Loss: 3.5315189361572266 | KNN Loss: 2.4985411167144775 | BCE Loss: 1.032977819442749\n",
      "Epoch 78 / 500 | iteration 5 / 30 | Total Loss: 3.598893880844116 | KNN Loss: 2.5723865032196045 | BCE Loss: 1.0265073776245117\n",
      "Epoch 78 / 500 | iteration 10 / 30 | Total Loss: 3.5379550457000732 | KNN Loss: 2.496486186981201 | BCE Loss: 1.041468858718872\n",
      "Epoch 78 / 500 | iteration 15 / 30 | Total Loss: 3.5735552310943604 | KNN Loss: 2.551323652267456 | BCE Loss: 1.0222315788269043\n",
      "Epoch 78 / 500 | iteration 20 / 30 | Total Loss: 3.531315326690674 | KNN Loss: 2.504281997680664 | BCE Loss: 1.0270334482192993\n",
      "Epoch 78 / 500 | iteration 25 / 30 | Total Loss: 3.521942615509033 | KNN Loss: 2.505603313446045 | BCE Loss: 1.0163393020629883\n",
      "Epoch 79 / 500 | iteration 0 / 30 | Total Loss: 3.557483673095703 | KNN Loss: 2.5652568340301514 | BCE Loss: 0.9922269582748413\n",
      "Epoch 79 / 500 | iteration 5 / 30 | Total Loss: 3.595829963684082 | KNN Loss: 2.5712172985076904 | BCE Loss: 1.0246126651763916\n",
      "Epoch 79 / 500 | iteration 10 / 30 | Total Loss: 3.5853469371795654 | KNN Loss: 2.5625927448272705 | BCE Loss: 1.022754192352295\n",
      "Epoch 79 / 500 | iteration 15 / 30 | Total Loss: 3.512478828430176 | KNN Loss: 2.507505416870117 | BCE Loss: 1.0049734115600586\n",
      "Epoch 79 / 500 | iteration 20 / 30 | Total Loss: 3.524181365966797 | KNN Loss: 2.490833044052124 | BCE Loss: 1.0333482027053833\n",
      "Epoch 79 / 500 | iteration 25 / 30 | Total Loss: 3.5117692947387695 | KNN Loss: 2.483915328979492 | BCE Loss: 1.027854084968567\n",
      "Epoch 80 / 500 | iteration 0 / 30 | Total Loss: 3.5210859775543213 | KNN Loss: 2.5073249340057373 | BCE Loss: 1.013761043548584\n",
      "Epoch 80 / 500 | iteration 5 / 30 | Total Loss: 3.5387203693389893 | KNN Loss: 2.5193750858306885 | BCE Loss: 1.0193452835083008\n",
      "Epoch 80 / 500 | iteration 10 / 30 | Total Loss: 3.564828872680664 | KNN Loss: 2.541346311569214 | BCE Loss: 1.0234825611114502\n",
      "Epoch 80 / 500 | iteration 15 / 30 | Total Loss: 3.532349109649658 | KNN Loss: 2.5406203269958496 | BCE Loss: 0.9917287230491638\n",
      "Epoch 80 / 500 | iteration 20 / 30 | Total Loss: 3.5602216720581055 | KNN Loss: 2.5248496532440186 | BCE Loss: 1.035372018814087\n",
      "Epoch 80 / 500 | iteration 25 / 30 | Total Loss: 3.5537095069885254 | KNN Loss: 2.561293601989746 | BCE Loss: 0.9924157857894897\n",
      "Epoch 81 / 500 | iteration 0 / 30 | Total Loss: 3.5378925800323486 | KNN Loss: 2.525446891784668 | BCE Loss: 1.0124456882476807\n",
      "Epoch 81 / 500 | iteration 5 / 30 | Total Loss: 3.5801451206207275 | KNN Loss: 2.5267562866210938 | BCE Loss: 1.0533888339996338\n",
      "Epoch 81 / 500 | iteration 10 / 30 | Total Loss: 3.56451678276062 | KNN Loss: 2.5329437255859375 | BCE Loss: 1.0315730571746826\n",
      "Epoch 81 / 500 | iteration 15 / 30 | Total Loss: 3.578279495239258 | KNN Loss: 2.5513975620269775 | BCE Loss: 1.0268820524215698\n",
      "Epoch 81 / 500 | iteration 20 / 30 | Total Loss: 3.5651025772094727 | KNN Loss: 2.535139560699463 | BCE Loss: 1.0299630165100098\n",
      "Epoch 81 / 500 | iteration 25 / 30 | Total Loss: 3.549955129623413 | KNN Loss: 2.5073652267456055 | BCE Loss: 1.0425899028778076\n",
      "Epoch 82 / 500 | iteration 0 / 30 | Total Loss: 3.530461549758911 | KNN Loss: 2.5410993099212646 | BCE Loss: 0.9893622994422913\n",
      "Epoch 82 / 500 | iteration 5 / 30 | Total Loss: 3.498739242553711 | KNN Loss: 2.5072829723358154 | BCE Loss: 0.9914563894271851\n",
      "Epoch 82 / 500 | iteration 10 / 30 | Total Loss: 3.5232949256896973 | KNN Loss: 2.4914326667785645 | BCE Loss: 1.0318623781204224\n",
      "Epoch 82 / 500 | iteration 15 / 30 | Total Loss: 3.5635199546813965 | KNN Loss: 2.552581787109375 | BCE Loss: 1.010938048362732\n",
      "Epoch 82 / 500 | iteration 20 / 30 | Total Loss: 3.5336713790893555 | KNN Loss: 2.499889373779297 | BCE Loss: 1.0337820053100586\n",
      "Epoch 82 / 500 | iteration 25 / 30 | Total Loss: 3.522029161453247 | KNN Loss: 2.507301092147827 | BCE Loss: 1.01472806930542\n",
      "Epoch 83 / 500 | iteration 0 / 30 | Total Loss: 3.5395472049713135 | KNN Loss: 2.51155686378479 | BCE Loss: 1.0279903411865234\n",
      "Epoch 83 / 500 | iteration 5 / 30 | Total Loss: 3.5974087715148926 | KNN Loss: 2.5727434158325195 | BCE Loss: 1.0246652364730835\n",
      "Epoch 83 / 500 | iteration 10 / 30 | Total Loss: 3.5363149642944336 | KNN Loss: 2.543159246444702 | BCE Loss: 0.993155837059021\n",
      "Epoch 83 / 500 | iteration 15 / 30 | Total Loss: 3.5237550735473633 | KNN Loss: 2.507904291152954 | BCE Loss: 1.0158506631851196\n",
      "Epoch 83 / 500 | iteration 20 / 30 | Total Loss: 3.528916597366333 | KNN Loss: 2.5253422260284424 | BCE Loss: 1.0035743713378906\n",
      "Epoch 83 / 500 | iteration 25 / 30 | Total Loss: 3.559251308441162 | KNN Loss: 2.5327069759368896 | BCE Loss: 1.026544451713562\n",
      "Epoch 84 / 500 | iteration 0 / 30 | Total Loss: 3.574390411376953 | KNN Loss: 2.5234618186950684 | BCE Loss: 1.0509287118911743\n",
      "Epoch 84 / 500 | iteration 5 / 30 | Total Loss: 3.589815139770508 | KNN Loss: 2.5432887077331543 | BCE Loss: 1.046526312828064\n",
      "Epoch 84 / 500 | iteration 10 / 30 | Total Loss: 3.5433454513549805 | KNN Loss: 2.504452705383301 | BCE Loss: 1.0388927459716797\n",
      "Epoch 84 / 500 | iteration 15 / 30 | Total Loss: 3.539945602416992 | KNN Loss: 2.538153886795044 | BCE Loss: 1.0017917156219482\n",
      "Epoch 84 / 500 | iteration 20 / 30 | Total Loss: 3.519651412963867 | KNN Loss: 2.4803977012634277 | BCE Loss: 1.03925359249115\n",
      "Epoch 84 / 500 | iteration 25 / 30 | Total Loss: 3.535860776901245 | KNN Loss: 2.5058295726776123 | BCE Loss: 1.0300312042236328\n",
      "Epoch 85 / 500 | iteration 0 / 30 | Total Loss: 3.6006031036376953 | KNN Loss: 2.5867583751678467 | BCE Loss: 1.0138448476791382\n",
      "Epoch 85 / 500 | iteration 5 / 30 | Total Loss: 3.5298991203308105 | KNN Loss: 2.5056347846984863 | BCE Loss: 1.0242643356323242\n",
      "Epoch 85 / 500 | iteration 10 / 30 | Total Loss: 3.487459897994995 | KNN Loss: 2.485527992248535 | BCE Loss: 1.00193190574646\n",
      "Epoch 85 / 500 | iteration 15 / 30 | Total Loss: 3.508493423461914 | KNN Loss: 2.516390562057495 | BCE Loss: 0.9921027421951294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 500 | iteration 20 / 30 | Total Loss: 3.5259575843811035 | KNN Loss: 2.514822006225586 | BCE Loss: 1.0111355781555176\n",
      "Epoch 85 / 500 | iteration 25 / 30 | Total Loss: 3.5052566528320312 | KNN Loss: 2.4733643531799316 | BCE Loss: 1.0318922996520996\n",
      "Epoch 86 / 500 | iteration 0 / 30 | Total Loss: 3.5190553665161133 | KNN Loss: 2.5123367309570312 | BCE Loss: 1.0067187547683716\n",
      "Epoch 86 / 500 | iteration 5 / 30 | Total Loss: 3.552382469177246 | KNN Loss: 2.5506584644317627 | BCE Loss: 1.0017238855361938\n",
      "Epoch 86 / 500 | iteration 10 / 30 | Total Loss: 3.5013747215270996 | KNN Loss: 2.486071825027466 | BCE Loss: 1.0153028964996338\n",
      "Epoch 86 / 500 | iteration 15 / 30 | Total Loss: 3.475728988647461 | KNN Loss: 2.478623628616333 | BCE Loss: 0.9971053004264832\n",
      "Epoch 86 / 500 | iteration 20 / 30 | Total Loss: 3.5276479721069336 | KNN Loss: 2.4986956119537354 | BCE Loss: 1.0289524793624878\n",
      "Epoch 86 / 500 | iteration 25 / 30 | Total Loss: 3.5383169651031494 | KNN Loss: 2.510927677154541 | BCE Loss: 1.0273892879486084\n",
      "Epoch 87 / 500 | iteration 0 / 30 | Total Loss: 3.525036573410034 | KNN Loss: 2.4961018562316895 | BCE Loss: 1.0289347171783447\n",
      "Epoch 87 / 500 | iteration 5 / 30 | Total Loss: 3.5352022647857666 | KNN Loss: 2.523832082748413 | BCE Loss: 1.0113701820373535\n",
      "Epoch 87 / 500 | iteration 10 / 30 | Total Loss: 3.5510873794555664 | KNN Loss: 2.527113437652588 | BCE Loss: 1.0239739418029785\n",
      "Epoch 87 / 500 | iteration 15 / 30 | Total Loss: 3.5484492778778076 | KNN Loss: 2.515571355819702 | BCE Loss: 1.0328779220581055\n",
      "Epoch 87 / 500 | iteration 20 / 30 | Total Loss: 3.5448789596557617 | KNN Loss: 2.5525217056274414 | BCE Loss: 0.9923573136329651\n",
      "Epoch 87 / 500 | iteration 25 / 30 | Total Loss: 3.5101771354675293 | KNN Loss: 2.5002875328063965 | BCE Loss: 1.0098896026611328\n",
      "Epoch 88 / 500 | iteration 0 / 30 | Total Loss: 3.518644332885742 | KNN Loss: 2.500288963317871 | BCE Loss: 1.0183554887771606\n",
      "Epoch 88 / 500 | iteration 5 / 30 | Total Loss: 3.554745674133301 | KNN Loss: 2.535550832748413 | BCE Loss: 1.0191949605941772\n",
      "Epoch 88 / 500 | iteration 10 / 30 | Total Loss: 3.5504212379455566 | KNN Loss: 2.5263123512268066 | BCE Loss: 1.0241090059280396\n",
      "Epoch 88 / 500 | iteration 15 / 30 | Total Loss: 3.5231122970581055 | KNN Loss: 2.505143404006958 | BCE Loss: 1.017968773841858\n",
      "Epoch 88 / 500 | iteration 20 / 30 | Total Loss: 3.5003550052642822 | KNN Loss: 2.502906322479248 | BCE Loss: 0.9974486231803894\n",
      "Epoch 88 / 500 | iteration 25 / 30 | Total Loss: 3.5275638103485107 | KNN Loss: 2.5137245655059814 | BCE Loss: 1.0138392448425293\n",
      "Epoch 89 / 500 | iteration 0 / 30 | Total Loss: 3.5076847076416016 | KNN Loss: 2.4738662242889404 | BCE Loss: 1.0338186025619507\n",
      "Epoch 89 / 500 | iteration 5 / 30 | Total Loss: 3.5221943855285645 | KNN Loss: 2.50327730178833 | BCE Loss: 1.0189170837402344\n",
      "Epoch 89 / 500 | iteration 10 / 30 | Total Loss: 3.5216639041900635 | KNN Loss: 2.5076613426208496 | BCE Loss: 1.0140025615692139\n",
      "Epoch 89 / 500 | iteration 15 / 30 | Total Loss: 3.573525905609131 | KNN Loss: 2.559448003768921 | BCE Loss: 1.0140780210494995\n",
      "Epoch 89 / 500 | iteration 20 / 30 | Total Loss: 3.528149366378784 | KNN Loss: 2.478466033935547 | BCE Loss: 1.0496833324432373\n",
      "Epoch 89 / 500 | iteration 25 / 30 | Total Loss: 3.536407709121704 | KNN Loss: 2.4748008251190186 | BCE Loss: 1.0616068840026855\n",
      "Epoch 90 / 500 | iteration 0 / 30 | Total Loss: 3.510895252227783 | KNN Loss: 2.501283884048462 | BCE Loss: 1.0096114873886108\n",
      "Epoch 90 / 500 | iteration 5 / 30 | Total Loss: 3.5637125968933105 | KNN Loss: 2.532433271408081 | BCE Loss: 1.0312793254852295\n",
      "Epoch 90 / 500 | iteration 10 / 30 | Total Loss: 3.54066801071167 | KNN Loss: 2.513929605484009 | BCE Loss: 1.0267382860183716\n",
      "Epoch 90 / 500 | iteration 15 / 30 | Total Loss: 3.5069808959960938 | KNN Loss: 2.5160510540008545 | BCE Loss: 0.9909297823905945\n",
      "Epoch 90 / 500 | iteration 20 / 30 | Total Loss: 3.5483222007751465 | KNN Loss: 2.5369467735290527 | BCE Loss: 1.0113755464553833\n",
      "Epoch 90 / 500 | iteration 25 / 30 | Total Loss: 3.547475576400757 | KNN Loss: 2.5018515586853027 | BCE Loss: 1.045624017715454\n",
      "Epoch 91 / 500 | iteration 0 / 30 | Total Loss: 3.548375368118286 | KNN Loss: 2.5408942699432373 | BCE Loss: 1.0074810981750488\n",
      "Epoch 91 / 500 | iteration 5 / 30 | Total Loss: 3.5158023834228516 | KNN Loss: 2.480578899383545 | BCE Loss: 1.035223364830017\n",
      "Epoch 91 / 500 | iteration 10 / 30 | Total Loss: 3.4942073822021484 | KNN Loss: 2.5058791637420654 | BCE Loss: 0.9883282780647278\n",
      "Epoch 91 / 500 | iteration 15 / 30 | Total Loss: 3.5313432216644287 | KNN Loss: 2.5133628845214844 | BCE Loss: 1.0179803371429443\n",
      "Epoch 91 / 500 | iteration 20 / 30 | Total Loss: 3.542297840118408 | KNN Loss: 2.5004098415374756 | BCE Loss: 1.0418879985809326\n",
      "Epoch 91 / 500 | iteration 25 / 30 | Total Loss: 3.521148681640625 | KNN Loss: 2.4815638065338135 | BCE Loss: 1.0395848751068115\n",
      "Epoch 92 / 500 | iteration 0 / 30 | Total Loss: 3.548847198486328 | KNN Loss: 2.508789539337158 | BCE Loss: 1.0400575399398804\n",
      "Epoch 92 / 500 | iteration 5 / 30 | Total Loss: 3.6078548431396484 | KNN Loss: 2.560922861099243 | BCE Loss: 1.0469318628311157\n",
      "Epoch 92 / 500 | iteration 10 / 30 | Total Loss: 3.507770538330078 | KNN Loss: 2.482846975326538 | BCE Loss: 1.0249234437942505\n",
      "Epoch 92 / 500 | iteration 15 / 30 | Total Loss: 3.5459372997283936 | KNN Loss: 2.5229651927948 | BCE Loss: 1.0229721069335938\n",
      "Epoch 92 / 500 | iteration 20 / 30 | Total Loss: 3.5035324096679688 | KNN Loss: 2.4886629581451416 | BCE Loss: 1.0148693323135376\n",
      "Epoch 92 / 500 | iteration 25 / 30 | Total Loss: 3.5285329818725586 | KNN Loss: 2.4844324588775635 | BCE Loss: 1.0441005229949951\n",
      "Epoch 93 / 500 | iteration 0 / 30 | Total Loss: 3.4976463317871094 | KNN Loss: 2.498512029647827 | BCE Loss: 0.9991343021392822\n",
      "Epoch 93 / 500 | iteration 5 / 30 | Total Loss: 3.5441951751708984 | KNN Loss: 2.505831241607666 | BCE Loss: 1.0383638143539429\n",
      "Epoch 93 / 500 | iteration 10 / 30 | Total Loss: 3.5483269691467285 | KNN Loss: 2.5110723972320557 | BCE Loss: 1.0372545719146729\n",
      "Epoch 93 / 500 | iteration 15 / 30 | Total Loss: 3.4788308143615723 | KNN Loss: 2.471571683883667 | BCE Loss: 1.0072592496871948\n",
      "Epoch 93 / 500 | iteration 20 / 30 | Total Loss: 3.528890609741211 | KNN Loss: 2.5178756713867188 | BCE Loss: 1.0110148191452026\n",
      "Epoch 93 / 500 | iteration 25 / 30 | Total Loss: 3.5302646160125732 | KNN Loss: 2.4992027282714844 | BCE Loss: 1.0310618877410889\n",
      "Epoch 94 / 500 | iteration 0 / 30 | Total Loss: 3.5150294303894043 | KNN Loss: 2.5219781398773193 | BCE Loss: 0.9930512309074402\n",
      "Epoch 94 / 500 | iteration 5 / 30 | Total Loss: 3.5067272186279297 | KNN Loss: 2.4560019969940186 | BCE Loss: 1.0507252216339111\n",
      "Epoch 94 / 500 | iteration 10 / 30 | Total Loss: 3.4986605644226074 | KNN Loss: 2.5055630207061768 | BCE Loss: 0.9930976629257202\n",
      "Epoch 94 / 500 | iteration 15 / 30 | Total Loss: 3.503046751022339 | KNN Loss: 2.4842777252197266 | BCE Loss: 1.0187690258026123\n",
      "Epoch 94 / 500 | iteration 20 / 30 | Total Loss: 3.4605135917663574 | KNN Loss: 2.4550228118896484 | BCE Loss: 1.005490779876709\n",
      "Epoch 94 / 500 | iteration 25 / 30 | Total Loss: 3.4801998138427734 | KNN Loss: 2.4688949584960938 | BCE Loss: 1.0113048553466797\n",
      "Epoch 95 / 500 | iteration 0 / 30 | Total Loss: 3.532968521118164 | KNN Loss: 2.491640567779541 | BCE Loss: 1.0413278341293335\n",
      "Epoch 95 / 500 | iteration 5 / 30 | Total Loss: 3.454507827758789 | KNN Loss: 2.4767394065856934 | BCE Loss: 0.9777684211730957\n",
      "Epoch 95 / 500 | iteration 10 / 30 | Total Loss: 3.528585910797119 | KNN Loss: 2.4943325519561768 | BCE Loss: 1.034253478050232\n",
      "Epoch 95 / 500 | iteration 15 / 30 | Total Loss: 3.4856226444244385 | KNN Loss: 2.476374626159668 | BCE Loss: 1.0092480182647705\n",
      "Epoch 95 / 500 | iteration 20 / 30 | Total Loss: 3.5176825523376465 | KNN Loss: 2.5132882595062256 | BCE Loss: 1.0043944120407104\n",
      "Epoch 95 / 500 | iteration 25 / 30 | Total Loss: 3.518827438354492 | KNN Loss: 2.506000280380249 | BCE Loss: 1.0128271579742432\n",
      "Epoch 96 / 500 | iteration 0 / 30 | Total Loss: 3.5648510456085205 | KNN Loss: 2.5094664096832275 | BCE Loss: 1.055384635925293\n",
      "Epoch 96 / 500 | iteration 5 / 30 | Total Loss: 3.5387611389160156 | KNN Loss: 2.5235402584075928 | BCE Loss: 1.0152209997177124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 / 500 | iteration 10 / 30 | Total Loss: 3.506221055984497 | KNN Loss: 2.4730634689331055 | BCE Loss: 1.0331575870513916\n",
      "Epoch 96 / 500 | iteration 15 / 30 | Total Loss: 3.562993288040161 | KNN Loss: 2.5314979553222656 | BCE Loss: 1.0314953327178955\n",
      "Epoch 96 / 500 | iteration 20 / 30 | Total Loss: 3.5189082622528076 | KNN Loss: 2.532003164291382 | BCE Loss: 0.986905038356781\n",
      "Epoch 96 / 500 | iteration 25 / 30 | Total Loss: 3.5038681030273438 | KNN Loss: 2.493849039077759 | BCE Loss: 1.010019063949585\n",
      "Epoch 97 / 500 | iteration 0 / 30 | Total Loss: 3.542483329772949 | KNN Loss: 2.507343292236328 | BCE Loss: 1.035140037536621\n",
      "Epoch 97 / 500 | iteration 5 / 30 | Total Loss: 3.5304887294769287 | KNN Loss: 2.466078996658325 | BCE Loss: 1.0644097328186035\n",
      "Epoch 97 / 500 | iteration 10 / 30 | Total Loss: 3.5315475463867188 | KNN Loss: 2.49580454826355 | BCE Loss: 1.035742998123169\n",
      "Epoch 97 / 500 | iteration 15 / 30 | Total Loss: 3.5670032501220703 | KNN Loss: 2.52927303314209 | BCE Loss: 1.03773033618927\n",
      "Epoch 97 / 500 | iteration 20 / 30 | Total Loss: 3.5187997817993164 | KNN Loss: 2.5006656646728516 | BCE Loss: 1.0181339979171753\n",
      "Epoch 97 / 500 | iteration 25 / 30 | Total Loss: 3.5091958045959473 | KNN Loss: 2.4839210510253906 | BCE Loss: 1.0252747535705566\n",
      "Epoch 98 / 500 | iteration 0 / 30 | Total Loss: 3.5438942909240723 | KNN Loss: 2.5137124061584473 | BCE Loss: 1.030181884765625\n",
      "Epoch 98 / 500 | iteration 5 / 30 | Total Loss: 3.5405642986297607 | KNN Loss: 2.533512592315674 | BCE Loss: 1.007051706314087\n",
      "Epoch 98 / 500 | iteration 10 / 30 | Total Loss: 3.526775598526001 | KNN Loss: 2.513594388961792 | BCE Loss: 1.013181209564209\n",
      "Epoch 98 / 500 | iteration 15 / 30 | Total Loss: 3.56113862991333 | KNN Loss: 2.552527666091919 | BCE Loss: 1.0086108446121216\n",
      "Epoch 98 / 500 | iteration 20 / 30 | Total Loss: 3.521432876586914 | KNN Loss: 2.497361183166504 | BCE Loss: 1.0240716934204102\n",
      "Epoch 98 / 500 | iteration 25 / 30 | Total Loss: 3.494166135787964 | KNN Loss: 2.480485439300537 | BCE Loss: 1.0136806964874268\n",
      "Epoch 99 / 500 | iteration 0 / 30 | Total Loss: 3.5010924339294434 | KNN Loss: 2.4752449989318848 | BCE Loss: 1.025847315788269\n",
      "Epoch 99 / 500 | iteration 5 / 30 | Total Loss: 3.5517773628234863 | KNN Loss: 2.539228916168213 | BCE Loss: 1.012548565864563\n",
      "Epoch 99 / 500 | iteration 10 / 30 | Total Loss: 3.485462188720703 | KNN Loss: 2.4726548194885254 | BCE Loss: 1.0128073692321777\n",
      "Epoch 99 / 500 | iteration 15 / 30 | Total Loss: 3.5024161338806152 | KNN Loss: 2.5074715614318848 | BCE Loss: 0.9949446320533752\n",
      "Epoch 99 / 500 | iteration 20 / 30 | Total Loss: 3.5257649421691895 | KNN Loss: 2.4989113807678223 | BCE Loss: 1.0268535614013672\n",
      "Epoch 99 / 500 | iteration 25 / 30 | Total Loss: 3.463409900665283 | KNN Loss: 2.4802405834198 | BCE Loss: 0.9831693172454834\n",
      "Epoch 100 / 500 | iteration 0 / 30 | Total Loss: 3.512733221054077 | KNN Loss: 2.4940879344940186 | BCE Loss: 1.0186452865600586\n",
      "Epoch 100 / 500 | iteration 5 / 30 | Total Loss: 3.5460963249206543 | KNN Loss: 2.5489327907562256 | BCE Loss: 0.9971634149551392\n",
      "Epoch 100 / 500 | iteration 10 / 30 | Total Loss: 3.552640914916992 | KNN Loss: 2.5362212657928467 | BCE Loss: 1.016419529914856\n",
      "Epoch 100 / 500 | iteration 15 / 30 | Total Loss: 3.5346932411193848 | KNN Loss: 2.489936351776123 | BCE Loss: 1.0447568893432617\n",
      "Epoch 100 / 500 | iteration 20 / 30 | Total Loss: 3.5175063610076904 | KNN Loss: 2.5032787322998047 | BCE Loss: 1.0142276287078857\n",
      "Epoch 100 / 500 | iteration 25 / 30 | Total Loss: 3.4961400032043457 | KNN Loss: 2.4778144359588623 | BCE Loss: 1.018325686454773\n",
      "Epoch 101 / 500 | iteration 0 / 30 | Total Loss: 3.508060932159424 | KNN Loss: 2.48880672454834 | BCE Loss: 1.019254207611084\n",
      "Epoch 101 / 500 | iteration 5 / 30 | Total Loss: 3.53924822807312 | KNN Loss: 2.50472354888916 | BCE Loss: 1.03452467918396\n",
      "Epoch 101 / 500 | iteration 10 / 30 | Total Loss: 3.513740062713623 | KNN Loss: 2.4953410625457764 | BCE Loss: 1.0183991193771362\n",
      "Epoch 101 / 500 | iteration 15 / 30 | Total Loss: 3.5200462341308594 | KNN Loss: 2.511657953262329 | BCE Loss: 1.0083884000778198\n",
      "Epoch 101 / 500 | iteration 20 / 30 | Total Loss: 3.5472910404205322 | KNN Loss: 2.5080368518829346 | BCE Loss: 1.0392541885375977\n",
      "Epoch 101 / 500 | iteration 25 / 30 | Total Loss: 3.5444271564483643 | KNN Loss: 2.496462106704712 | BCE Loss: 1.0479650497436523\n",
      "Epoch 102 / 500 | iteration 0 / 30 | Total Loss: 3.5161876678466797 | KNN Loss: 2.489062547683716 | BCE Loss: 1.0271251201629639\n",
      "Epoch 102 / 500 | iteration 5 / 30 | Total Loss: 3.5035970211029053 | KNN Loss: 2.4900825023651123 | BCE Loss: 1.013514518737793\n",
      "Epoch 102 / 500 | iteration 10 / 30 | Total Loss: 3.5200891494750977 | KNN Loss: 2.5126700401306152 | BCE Loss: 1.0074191093444824\n",
      "Epoch 102 / 500 | iteration 15 / 30 | Total Loss: 3.518594741821289 | KNN Loss: 2.501858711242676 | BCE Loss: 1.0167361497879028\n",
      "Epoch 102 / 500 | iteration 20 / 30 | Total Loss: 3.512953042984009 | KNN Loss: 2.479790687561035 | BCE Loss: 1.0331623554229736\n",
      "Epoch 102 / 500 | iteration 25 / 30 | Total Loss: 3.49255633354187 | KNN Loss: 2.4894678592681885 | BCE Loss: 1.0030884742736816\n",
      "Epoch 103 / 500 | iteration 0 / 30 | Total Loss: 3.496173858642578 | KNN Loss: 2.4893484115600586 | BCE Loss: 1.0068254470825195\n",
      "Epoch 103 / 500 | iteration 5 / 30 | Total Loss: 3.533452033996582 | KNN Loss: 2.5249102115631104 | BCE Loss: 1.0085418224334717\n",
      "Epoch 103 / 500 | iteration 10 / 30 | Total Loss: 3.5155370235443115 | KNN Loss: 2.4941811561584473 | BCE Loss: 1.0213558673858643\n",
      "Epoch 103 / 500 | iteration 15 / 30 | Total Loss: 3.4922611713409424 | KNN Loss: 2.4913976192474365 | BCE Loss: 1.0008635520935059\n",
      "Epoch 103 / 500 | iteration 20 / 30 | Total Loss: 3.546309232711792 | KNN Loss: 2.5076029300689697 | BCE Loss: 1.0387063026428223\n",
      "Epoch 103 / 500 | iteration 25 / 30 | Total Loss: 3.513387680053711 | KNN Loss: 2.520566940307617 | BCE Loss: 0.9928207397460938\n",
      "Epoch 104 / 500 | iteration 0 / 30 | Total Loss: 3.565624713897705 | KNN Loss: 2.5263171195983887 | BCE Loss: 1.0393075942993164\n",
      "Epoch 104 / 500 | iteration 5 / 30 | Total Loss: 3.513847589492798 | KNN Loss: 2.5031626224517822 | BCE Loss: 1.0106849670410156\n",
      "Epoch 104 / 500 | iteration 10 / 30 | Total Loss: 3.5303726196289062 | KNN Loss: 2.5273659229278564 | BCE Loss: 1.0030068159103394\n",
      "Epoch 104 / 500 | iteration 15 / 30 | Total Loss: 3.508892059326172 | KNN Loss: 2.4895541667938232 | BCE Loss: 1.0193380117416382\n",
      "Epoch 104 / 500 | iteration 20 / 30 | Total Loss: 3.516329765319824 | KNN Loss: 2.4799976348876953 | BCE Loss: 1.0363322496414185\n",
      "Epoch 104 / 500 | iteration 25 / 30 | Total Loss: 3.494877338409424 | KNN Loss: 2.492143154144287 | BCE Loss: 1.0027341842651367\n",
      "Epoch 105 / 500 | iteration 0 / 30 | Total Loss: 3.5389158725738525 | KNN Loss: 2.5200159549713135 | BCE Loss: 1.018899917602539\n",
      "Epoch 105 / 500 | iteration 5 / 30 | Total Loss: 3.5128283500671387 | KNN Loss: 2.474383592605591 | BCE Loss: 1.0384447574615479\n",
      "Epoch 105 / 500 | iteration 10 / 30 | Total Loss: 3.534876823425293 | KNN Loss: 2.5281643867492676 | BCE Loss: 1.0067124366760254\n",
      "Epoch 105 / 500 | iteration 15 / 30 | Total Loss: 3.5630717277526855 | KNN Loss: 2.5289859771728516 | BCE Loss: 1.034085750579834\n",
      "Epoch 105 / 500 | iteration 20 / 30 | Total Loss: 3.572887897491455 | KNN Loss: 2.5180366039276123 | BCE Loss: 1.0548511743545532\n",
      "Epoch 105 / 500 | iteration 25 / 30 | Total Loss: 3.464545726776123 | KNN Loss: 2.4610342979431152 | BCE Loss: 1.0035114288330078\n",
      "Epoch   106: reducing learning rate of group 0 to 3.5000e-03.\n",
      "Epoch 106 / 500 | iteration 0 / 30 | Total Loss: 3.5094919204711914 | KNN Loss: 2.4830033779144287 | BCE Loss: 1.0264885425567627\n",
      "Epoch 106 / 500 | iteration 5 / 30 | Total Loss: 3.535470962524414 | KNN Loss: 2.5112204551696777 | BCE Loss: 1.0242503881454468\n",
      "Epoch 106 / 500 | iteration 10 / 30 | Total Loss: 3.496323823928833 | KNN Loss: 2.500885248184204 | BCE Loss: 0.9954385161399841\n",
      "Epoch 106 / 500 | iteration 15 / 30 | Total Loss: 3.511566638946533 | KNN Loss: 2.4962174892425537 | BCE Loss: 1.0153491497039795\n",
      "Epoch 106 / 500 | iteration 20 / 30 | Total Loss: 3.5038535594940186 | KNN Loss: 2.483722686767578 | BCE Loss: 1.0201308727264404\n",
      "Epoch 106 / 500 | iteration 25 / 30 | Total Loss: 3.541691541671753 | KNN Loss: 2.532351016998291 | BCE Loss: 1.009340524673462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 / 500 | iteration 0 / 30 | Total Loss: 3.4873452186584473 | KNN Loss: 2.485896110534668 | BCE Loss: 1.0014492273330688\n",
      "Epoch 107 / 500 | iteration 5 / 30 | Total Loss: 3.567662000656128 | KNN Loss: 2.553964376449585 | BCE Loss: 1.013697624206543\n",
      "Epoch 107 / 500 | iteration 10 / 30 | Total Loss: 3.5459632873535156 | KNN Loss: 2.5208258628845215 | BCE Loss: 1.0251374244689941\n",
      "Epoch 107 / 500 | iteration 15 / 30 | Total Loss: 3.5103864669799805 | KNN Loss: 2.4966509342193604 | BCE Loss: 1.0137355327606201\n",
      "Epoch 107 / 500 | iteration 20 / 30 | Total Loss: 3.5276284217834473 | KNN Loss: 2.4909420013427734 | BCE Loss: 1.0366865396499634\n",
      "Epoch 107 / 500 | iteration 25 / 30 | Total Loss: 3.4602839946746826 | KNN Loss: 2.4719700813293457 | BCE Loss: 0.9883139729499817\n",
      "Epoch 108 / 500 | iteration 0 / 30 | Total Loss: 3.5015876293182373 | KNN Loss: 2.4686832427978516 | BCE Loss: 1.0329043865203857\n",
      "Epoch 108 / 500 | iteration 5 / 30 | Total Loss: 3.533907175064087 | KNN Loss: 2.5301153659820557 | BCE Loss: 1.0037918090820312\n",
      "Epoch 108 / 500 | iteration 10 / 30 | Total Loss: 3.4947211742401123 | KNN Loss: 2.4729092121124268 | BCE Loss: 1.0218119621276855\n",
      "Epoch 108 / 500 | iteration 15 / 30 | Total Loss: 3.514120101928711 | KNN Loss: 2.484020233154297 | BCE Loss: 1.030099868774414\n",
      "Epoch 108 / 500 | iteration 20 / 30 | Total Loss: 3.505679130554199 | KNN Loss: 2.4928200244903564 | BCE Loss: 1.0128591060638428\n",
      "Epoch 108 / 500 | iteration 25 / 30 | Total Loss: 3.5281472206115723 | KNN Loss: 2.505510091781616 | BCE Loss: 1.0226370096206665\n",
      "Epoch 109 / 500 | iteration 0 / 30 | Total Loss: 3.5250086784362793 | KNN Loss: 2.4955015182495117 | BCE Loss: 1.0295072793960571\n",
      "Epoch 109 / 500 | iteration 5 / 30 | Total Loss: 3.501382350921631 | KNN Loss: 2.4897828102111816 | BCE Loss: 1.0115995407104492\n",
      "Epoch 109 / 500 | iteration 10 / 30 | Total Loss: 3.526951313018799 | KNN Loss: 2.4902219772338867 | BCE Loss: 1.0367292165756226\n",
      "Epoch 109 / 500 | iteration 15 / 30 | Total Loss: 3.513519763946533 | KNN Loss: 2.497450590133667 | BCE Loss: 1.0160691738128662\n",
      "Epoch 109 / 500 | iteration 20 / 30 | Total Loss: 3.502776861190796 | KNN Loss: 2.4916088581085205 | BCE Loss: 1.0111680030822754\n",
      "Epoch 109 / 500 | iteration 25 / 30 | Total Loss: 3.509467840194702 | KNN Loss: 2.470571756362915 | BCE Loss: 1.038896083831787\n",
      "Epoch 110 / 500 | iteration 0 / 30 | Total Loss: 3.5374553203582764 | KNN Loss: 2.5051636695861816 | BCE Loss: 1.0322916507720947\n",
      "Epoch 110 / 500 | iteration 5 / 30 | Total Loss: 3.524785041809082 | KNN Loss: 2.517110586166382 | BCE Loss: 1.0076745748519897\n",
      "Epoch 110 / 500 | iteration 10 / 30 | Total Loss: 3.573023796081543 | KNN Loss: 2.525369882583618 | BCE Loss: 1.0476539134979248\n",
      "Epoch 110 / 500 | iteration 15 / 30 | Total Loss: 3.5563015937805176 | KNN Loss: 2.5264477729797363 | BCE Loss: 1.0298538208007812\n",
      "Epoch 110 / 500 | iteration 20 / 30 | Total Loss: 3.5489866733551025 | KNN Loss: 2.4717302322387695 | BCE Loss: 1.077256441116333\n",
      "Epoch 110 / 500 | iteration 25 / 30 | Total Loss: 3.510394334793091 | KNN Loss: 2.5099294185638428 | BCE Loss: 1.000464916229248\n",
      "Epoch 111 / 500 | iteration 0 / 30 | Total Loss: 3.5224952697753906 | KNN Loss: 2.482883930206299 | BCE Loss: 1.0396112203598022\n",
      "Epoch 111 / 500 | iteration 5 / 30 | Total Loss: 3.5007503032684326 | KNN Loss: 2.4643521308898926 | BCE Loss: 1.03639817237854\n",
      "Epoch 111 / 500 | iteration 10 / 30 | Total Loss: 3.501316785812378 | KNN Loss: 2.4800126552581787 | BCE Loss: 1.0213041305541992\n",
      "Epoch 111 / 500 | iteration 15 / 30 | Total Loss: 3.4979443550109863 | KNN Loss: 2.510775089263916 | BCE Loss: 0.9871693253517151\n",
      "Epoch 111 / 500 | iteration 20 / 30 | Total Loss: 3.5294127464294434 | KNN Loss: 2.5018062591552734 | BCE Loss: 1.02760648727417\n",
      "Epoch 111 / 500 | iteration 25 / 30 | Total Loss: 3.469257354736328 | KNN Loss: 2.4717366695404053 | BCE Loss: 0.9975208044052124\n",
      "Epoch 112 / 500 | iteration 0 / 30 | Total Loss: 3.530714988708496 | KNN Loss: 2.531219005584717 | BCE Loss: 0.9994959831237793\n",
      "Epoch 112 / 500 | iteration 5 / 30 | Total Loss: 3.5641403198242188 | KNN Loss: 2.5311315059661865 | BCE Loss: 1.0330088138580322\n",
      "Epoch 112 / 500 | iteration 10 / 30 | Total Loss: 3.491253614425659 | KNN Loss: 2.495375871658325 | BCE Loss: 0.9958778023719788\n",
      "Epoch 112 / 500 | iteration 15 / 30 | Total Loss: 3.5015249252319336 | KNN Loss: 2.4864513874053955 | BCE Loss: 1.0150736570358276\n",
      "Epoch 112 / 500 | iteration 20 / 30 | Total Loss: 3.50836181640625 | KNN Loss: 2.4945502281188965 | BCE Loss: 1.013811469078064\n",
      "Epoch 112 / 500 | iteration 25 / 30 | Total Loss: 3.4923505783081055 | KNN Loss: 2.492483139038086 | BCE Loss: 0.9998674988746643\n",
      "Epoch 113 / 500 | iteration 0 / 30 | Total Loss: 3.5047225952148438 | KNN Loss: 2.482180118560791 | BCE Loss: 1.0225424766540527\n",
      "Epoch 113 / 500 | iteration 5 / 30 | Total Loss: 3.497387409210205 | KNN Loss: 2.487281560897827 | BCE Loss: 1.010105848312378\n",
      "Epoch 113 / 500 | iteration 10 / 30 | Total Loss: 3.505760908126831 | KNN Loss: 2.487668991088867 | BCE Loss: 1.0180919170379639\n",
      "Epoch 113 / 500 | iteration 15 / 30 | Total Loss: 3.4979372024536133 | KNN Loss: 2.485772132873535 | BCE Loss: 1.0121650695800781\n",
      "Epoch 113 / 500 | iteration 20 / 30 | Total Loss: 3.5031661987304688 | KNN Loss: 2.475893259048462 | BCE Loss: 1.0272729396820068\n",
      "Epoch 113 / 500 | iteration 25 / 30 | Total Loss: 3.499616861343384 | KNN Loss: 2.4923555850982666 | BCE Loss: 1.0072612762451172\n",
      "Epoch 114 / 500 | iteration 0 / 30 | Total Loss: 3.4956088066101074 | KNN Loss: 2.486387252807617 | BCE Loss: 1.0092215538024902\n",
      "Epoch 114 / 500 | iteration 5 / 30 | Total Loss: 3.5473546981811523 | KNN Loss: 2.5096397399902344 | BCE Loss: 1.037714958190918\n",
      "Epoch 114 / 500 | iteration 10 / 30 | Total Loss: 3.4926183223724365 | KNN Loss: 2.491152048110962 | BCE Loss: 1.0014662742614746\n",
      "Epoch 114 / 500 | iteration 15 / 30 | Total Loss: 3.539177894592285 | KNN Loss: 2.5086636543273926 | BCE Loss: 1.0305143594741821\n",
      "Epoch 114 / 500 | iteration 20 / 30 | Total Loss: 3.506701946258545 | KNN Loss: 2.479374647140503 | BCE Loss: 1.027327299118042\n",
      "Epoch 114 / 500 | iteration 25 / 30 | Total Loss: 3.481771945953369 | KNN Loss: 2.4662697315216064 | BCE Loss: 1.0155022144317627\n",
      "Epoch 115 / 500 | iteration 0 / 30 | Total Loss: 3.4912195205688477 | KNN Loss: 2.4791274070739746 | BCE Loss: 1.0120919942855835\n",
      "Epoch 115 / 500 | iteration 5 / 30 | Total Loss: 3.5159730911254883 | KNN Loss: 2.497967004776001 | BCE Loss: 1.0180059671401978\n",
      "Epoch 115 / 500 | iteration 10 / 30 | Total Loss: 3.470676898956299 | KNN Loss: 2.474036693572998 | BCE Loss: 0.9966402053833008\n",
      "Epoch 115 / 500 | iteration 15 / 30 | Total Loss: 3.5153982639312744 | KNN Loss: 2.497490167617798 | BCE Loss: 1.0179080963134766\n",
      "Epoch 115 / 500 | iteration 20 / 30 | Total Loss: 3.5259313583374023 | KNN Loss: 2.506317615509033 | BCE Loss: 1.0196138620376587\n",
      "Epoch 115 / 500 | iteration 25 / 30 | Total Loss: 3.4997658729553223 | KNN Loss: 2.4865920543670654 | BCE Loss: 1.0131738185882568\n",
      "Epoch 116 / 500 | iteration 0 / 30 | Total Loss: 3.53954815864563 | KNN Loss: 2.5300397872924805 | BCE Loss: 1.0095083713531494\n",
      "Epoch 116 / 500 | iteration 5 / 30 | Total Loss: 3.5803627967834473 | KNN Loss: 2.5440173149108887 | BCE Loss: 1.036345362663269\n",
      "Epoch 116 / 500 | iteration 10 / 30 | Total Loss: 3.555579423904419 | KNN Loss: 2.5287082195281982 | BCE Loss: 1.0268712043762207\n",
      "Epoch 116 / 500 | iteration 15 / 30 | Total Loss: 3.4797589778900146 | KNN Loss: 2.481144666671753 | BCE Loss: 0.9986143708229065\n",
      "Epoch 116 / 500 | iteration 20 / 30 | Total Loss: 3.444786548614502 | KNN Loss: 2.4451653957366943 | BCE Loss: 0.9996211528778076\n",
      "Epoch 116 / 500 | iteration 25 / 30 | Total Loss: 3.4967195987701416 | KNN Loss: 2.4697070121765137 | BCE Loss: 1.027012586593628\n",
      "Epoch 117 / 500 | iteration 0 / 30 | Total Loss: 3.518073558807373 | KNN Loss: 2.51304292678833 | BCE Loss: 1.0050305128097534\n",
      "Epoch 117 / 500 | iteration 5 / 30 | Total Loss: 3.50274658203125 | KNN Loss: 2.503436803817749 | BCE Loss: 0.9993097186088562\n",
      "Epoch 117 / 500 | iteration 10 / 30 | Total Loss: 3.4855432510375977 | KNN Loss: 2.4666216373443604 | BCE Loss: 1.0189214944839478\n",
      "Epoch 117 / 500 | iteration 15 / 30 | Total Loss: 3.4451136589050293 | KNN Loss: 2.460399627685547 | BCE Loss: 0.9847139120101929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 / 500 | iteration 20 / 30 | Total Loss: 3.581278085708618 | KNN Loss: 2.549314498901367 | BCE Loss: 1.031963586807251\n",
      "Epoch 117 / 500 | iteration 25 / 30 | Total Loss: 3.484386444091797 | KNN Loss: 2.486278772354126 | BCE Loss: 0.9981077909469604\n",
      "Epoch 118 / 500 | iteration 0 / 30 | Total Loss: 3.5107364654541016 | KNN Loss: 2.481480360031128 | BCE Loss: 1.0292561054229736\n",
      "Epoch 118 / 500 | iteration 5 / 30 | Total Loss: 3.498415231704712 | KNN Loss: 2.484563112258911 | BCE Loss: 1.0138521194458008\n",
      "Epoch 118 / 500 | iteration 10 / 30 | Total Loss: 3.453669548034668 | KNN Loss: 2.4866321086883545 | BCE Loss: 0.9670374989509583\n",
      "Epoch 118 / 500 | iteration 15 / 30 | Total Loss: 3.5156712532043457 | KNN Loss: 2.493459463119507 | BCE Loss: 1.0222117900848389\n",
      "Epoch 118 / 500 | iteration 20 / 30 | Total Loss: 3.5361135005950928 | KNN Loss: 2.494555950164795 | BCE Loss: 1.0415575504302979\n",
      "Epoch 118 / 500 | iteration 25 / 30 | Total Loss: 3.521599531173706 | KNN Loss: 2.4794256687164307 | BCE Loss: 1.0421738624572754\n",
      "Epoch 119 / 500 | iteration 0 / 30 | Total Loss: 3.4868931770324707 | KNN Loss: 2.468581438064575 | BCE Loss: 1.018311619758606\n",
      "Epoch 119 / 500 | iteration 5 / 30 | Total Loss: 3.510937213897705 | KNN Loss: 2.489718437194824 | BCE Loss: 1.0212188959121704\n",
      "Epoch 119 / 500 | iteration 10 / 30 | Total Loss: 3.4724481105804443 | KNN Loss: 2.461066722869873 | BCE Loss: 1.0113813877105713\n",
      "Epoch 119 / 500 | iteration 15 / 30 | Total Loss: 3.482786178588867 | KNN Loss: 2.5057575702667236 | BCE Loss: 0.977028489112854\n",
      "Epoch 119 / 500 | iteration 20 / 30 | Total Loss: 3.476954460144043 | KNN Loss: 2.469855308532715 | BCE Loss: 1.0070990324020386\n",
      "Epoch 119 / 500 | iteration 25 / 30 | Total Loss: 3.5051047801971436 | KNN Loss: 2.5026605129241943 | BCE Loss: 1.0024442672729492\n",
      "Epoch 120 / 500 | iteration 0 / 30 | Total Loss: 3.4964752197265625 | KNN Loss: 2.498276948928833 | BCE Loss: 0.9981983304023743\n",
      "Epoch 120 / 500 | iteration 5 / 30 | Total Loss: 3.486363410949707 | KNN Loss: 2.492039918899536 | BCE Loss: 0.9943234324455261\n",
      "Epoch 120 / 500 | iteration 10 / 30 | Total Loss: 3.475524425506592 | KNN Loss: 2.4687018394470215 | BCE Loss: 1.0068227052688599\n",
      "Epoch 120 / 500 | iteration 15 / 30 | Total Loss: 3.5168168544769287 | KNN Loss: 2.5120859146118164 | BCE Loss: 1.0047309398651123\n",
      "Epoch 120 / 500 | iteration 20 / 30 | Total Loss: 3.4975361824035645 | KNN Loss: 2.4721875190734863 | BCE Loss: 1.0253486633300781\n",
      "Epoch 120 / 500 | iteration 25 / 30 | Total Loss: 3.506216287612915 | KNN Loss: 2.47900390625 | BCE Loss: 1.027212381362915\n",
      "Epoch 121 / 500 | iteration 0 / 30 | Total Loss: 3.511491298675537 | KNN Loss: 2.490206480026245 | BCE Loss: 1.021284818649292\n",
      "Epoch 121 / 500 | iteration 5 / 30 | Total Loss: 3.489582061767578 | KNN Loss: 2.482684850692749 | BCE Loss: 1.006897211074829\n",
      "Epoch 121 / 500 | iteration 10 / 30 | Total Loss: 3.516035318374634 | KNN Loss: 2.507542610168457 | BCE Loss: 1.0084927082061768\n",
      "Epoch 121 / 500 | iteration 15 / 30 | Total Loss: 3.5082144737243652 | KNN Loss: 2.4896175861358643 | BCE Loss: 1.0185967683792114\n",
      "Epoch 121 / 500 | iteration 20 / 30 | Total Loss: 3.488294839859009 | KNN Loss: 2.495828628540039 | BCE Loss: 0.9924662113189697\n",
      "Epoch 121 / 500 | iteration 25 / 30 | Total Loss: 3.4883599281311035 | KNN Loss: 2.476428985595703 | BCE Loss: 1.01193106174469\n",
      "Epoch 122 / 500 | iteration 0 / 30 | Total Loss: 3.514115810394287 | KNN Loss: 2.4727299213409424 | BCE Loss: 1.0413860082626343\n",
      "Epoch 122 / 500 | iteration 5 / 30 | Total Loss: 3.5168402194976807 | KNN Loss: 2.4764111042022705 | BCE Loss: 1.0404291152954102\n",
      "Epoch 122 / 500 | iteration 10 / 30 | Total Loss: 3.5079216957092285 | KNN Loss: 2.4920272827148438 | BCE Loss: 1.0158942937850952\n",
      "Epoch 122 / 500 | iteration 15 / 30 | Total Loss: 3.527402877807617 | KNN Loss: 2.4915659427642822 | BCE Loss: 1.0358370542526245\n",
      "Epoch 122 / 500 | iteration 20 / 30 | Total Loss: 3.4885671138763428 | KNN Loss: 2.5062036514282227 | BCE Loss: 0.9823635220527649\n",
      "Epoch 122 / 500 | iteration 25 / 30 | Total Loss: 3.494246482849121 | KNN Loss: 2.4797844886779785 | BCE Loss: 1.0144621133804321\n",
      "Epoch 123 / 500 | iteration 0 / 30 | Total Loss: 3.474299907684326 | KNN Loss: 2.475468873977661 | BCE Loss: 0.9988309144973755\n",
      "Epoch 123 / 500 | iteration 5 / 30 | Total Loss: 3.5523061752319336 | KNN Loss: 2.514841079711914 | BCE Loss: 1.0374650955200195\n",
      "Epoch 123 / 500 | iteration 10 / 30 | Total Loss: 3.5167746543884277 | KNN Loss: 2.512418746948242 | BCE Loss: 1.004355788230896\n",
      "Epoch 123 / 500 | iteration 15 / 30 | Total Loss: 3.52797794342041 | KNN Loss: 2.494562864303589 | BCE Loss: 1.0334151983261108\n",
      "Epoch 123 / 500 | iteration 20 / 30 | Total Loss: 3.5410423278808594 | KNN Loss: 2.493600368499756 | BCE Loss: 1.047442078590393\n",
      "Epoch 123 / 500 | iteration 25 / 30 | Total Loss: 3.483610153198242 | KNN Loss: 2.4879603385925293 | BCE Loss: 0.9956496953964233\n",
      "Epoch 124 / 500 | iteration 0 / 30 | Total Loss: 3.503776788711548 | KNN Loss: 2.4869472980499268 | BCE Loss: 1.016829490661621\n",
      "Epoch 124 / 500 | iteration 5 / 30 | Total Loss: 3.4847776889801025 | KNN Loss: 2.4915168285369873 | BCE Loss: 0.99326092004776\n",
      "Epoch 124 / 500 | iteration 10 / 30 | Total Loss: 3.4819834232330322 | KNN Loss: 2.468799352645874 | BCE Loss: 1.0131840705871582\n",
      "Epoch 124 / 500 | iteration 15 / 30 | Total Loss: 3.4949426651000977 | KNN Loss: 2.4767887592315674 | BCE Loss: 1.0181539058685303\n",
      "Epoch 124 / 500 | iteration 20 / 30 | Total Loss: 3.5804672241210938 | KNN Loss: 2.5394411087036133 | BCE Loss: 1.041025996208191\n",
      "Epoch 124 / 500 | iteration 25 / 30 | Total Loss: 3.470155715942383 | KNN Loss: 2.4596638679504395 | BCE Loss: 1.0104917287826538\n",
      "Epoch 125 / 500 | iteration 0 / 30 | Total Loss: 3.5044519901275635 | KNN Loss: 2.4844281673431396 | BCE Loss: 1.0200238227844238\n",
      "Epoch 125 / 500 | iteration 5 / 30 | Total Loss: 3.550365447998047 | KNN Loss: 2.5340347290039062 | BCE Loss: 1.0163308382034302\n",
      "Epoch 125 / 500 | iteration 10 / 30 | Total Loss: 3.5033934116363525 | KNN Loss: 2.492591381072998 | BCE Loss: 1.0108020305633545\n",
      "Epoch 125 / 500 | iteration 15 / 30 | Total Loss: 3.5150997638702393 | KNN Loss: 2.4991707801818848 | BCE Loss: 1.0159289836883545\n",
      "Epoch 125 / 500 | iteration 20 / 30 | Total Loss: 3.5250802040100098 | KNN Loss: 2.5113396644592285 | BCE Loss: 1.0137405395507812\n",
      "Epoch 125 / 500 | iteration 25 / 30 | Total Loss: 3.4940617084503174 | KNN Loss: 2.4877803325653076 | BCE Loss: 1.0062813758850098\n",
      "Epoch 126 / 500 | iteration 0 / 30 | Total Loss: 3.4788310527801514 | KNN Loss: 2.465527296066284 | BCE Loss: 1.0133037567138672\n",
      "Epoch 126 / 500 | iteration 5 / 30 | Total Loss: 3.519765853881836 | KNN Loss: 2.5078251361846924 | BCE Loss: 1.0119407176971436\n",
      "Epoch 126 / 500 | iteration 10 / 30 | Total Loss: 3.533944845199585 | KNN Loss: 2.525333881378174 | BCE Loss: 1.0086109638214111\n",
      "Epoch 126 / 500 | iteration 15 / 30 | Total Loss: 3.496861219406128 | KNN Loss: 2.473872661590576 | BCE Loss: 1.0229885578155518\n",
      "Epoch 126 / 500 | iteration 20 / 30 | Total Loss: 3.5379483699798584 | KNN Loss: 2.4765427112579346 | BCE Loss: 1.0614056587219238\n",
      "Epoch 126 / 500 | iteration 25 / 30 | Total Loss: 3.503117561340332 | KNN Loss: 2.4817330837249756 | BCE Loss: 1.0213844776153564\n",
      "Epoch 127 / 500 | iteration 0 / 30 | Total Loss: 3.5710253715515137 | KNN Loss: 2.487130641937256 | BCE Loss: 1.0838947296142578\n",
      "Epoch 127 / 500 | iteration 5 / 30 | Total Loss: 3.4840240478515625 | KNN Loss: 2.482038736343384 | BCE Loss: 1.0019851922988892\n",
      "Epoch 127 / 500 | iteration 10 / 30 | Total Loss: 3.506865978240967 | KNN Loss: 2.5149359703063965 | BCE Loss: 0.9919301271438599\n",
      "Epoch 127 / 500 | iteration 15 / 30 | Total Loss: 3.49324369430542 | KNN Loss: 2.493898630142212 | BCE Loss: 0.9993449449539185\n",
      "Epoch 127 / 500 | iteration 20 / 30 | Total Loss: 3.506162405014038 | KNN Loss: 2.4845728874206543 | BCE Loss: 1.0215895175933838\n",
      "Epoch 127 / 500 | iteration 25 / 30 | Total Loss: 3.525358200073242 | KNN Loss: 2.47812819480896 | BCE Loss: 1.0472300052642822\n",
      "Epoch 128 / 500 | iteration 0 / 30 | Total Loss: 3.534604787826538 | KNN Loss: 2.4917755126953125 | BCE Loss: 1.0428292751312256\n",
      "Epoch 128 / 500 | iteration 5 / 30 | Total Loss: 3.483632802963257 | KNN Loss: 2.484348773956299 | BCE Loss: 0.9992840886116028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 / 500 | iteration 10 / 30 | Total Loss: 3.5212621688842773 | KNN Loss: 2.4974770545959473 | BCE Loss: 1.0237849950790405\n",
      "Epoch 128 / 500 | iteration 15 / 30 | Total Loss: 3.527390956878662 | KNN Loss: 2.516160249710083 | BCE Loss: 1.0112305879592896\n",
      "Epoch 128 / 500 | iteration 20 / 30 | Total Loss: 3.5220448970794678 | KNN Loss: 2.502805471420288 | BCE Loss: 1.0192394256591797\n",
      "Epoch 128 / 500 | iteration 25 / 30 | Total Loss: 3.519540786743164 | KNN Loss: 2.470280408859253 | BCE Loss: 1.0492603778839111\n",
      "Epoch 129 / 500 | iteration 0 / 30 | Total Loss: 3.4957807064056396 | KNN Loss: 2.495668888092041 | BCE Loss: 1.0001118183135986\n",
      "Epoch 129 / 500 | iteration 5 / 30 | Total Loss: 3.5080034732818604 | KNN Loss: 2.4827423095703125 | BCE Loss: 1.0252611637115479\n",
      "Epoch 129 / 500 | iteration 10 / 30 | Total Loss: 3.496786117553711 | KNN Loss: 2.4712905883789062 | BCE Loss: 1.0254954099655151\n",
      "Epoch 129 / 500 | iteration 15 / 30 | Total Loss: 3.5710787773132324 | KNN Loss: 2.5089340209960938 | BCE Loss: 1.0621448755264282\n",
      "Epoch 129 / 500 | iteration 20 / 30 | Total Loss: 3.4539031982421875 | KNN Loss: 2.4616785049438477 | BCE Loss: 0.9922246932983398\n",
      "Epoch 129 / 500 | iteration 25 / 30 | Total Loss: 3.5224080085754395 | KNN Loss: 2.482473134994507 | BCE Loss: 1.0399348735809326\n",
      "Epoch 130 / 500 | iteration 0 / 30 | Total Loss: 3.467106342315674 | KNN Loss: 2.4593558311462402 | BCE Loss: 1.007750391960144\n",
      "Epoch 130 / 500 | iteration 5 / 30 | Total Loss: 3.5213112831115723 | KNN Loss: 2.500418186187744 | BCE Loss: 1.0208929777145386\n",
      "Epoch 130 / 500 | iteration 10 / 30 | Total Loss: 3.517702579498291 | KNN Loss: 2.494868755340576 | BCE Loss: 1.0228338241577148\n",
      "Epoch 130 / 500 | iteration 15 / 30 | Total Loss: 3.4681556224823 | KNN Loss: 2.4591169357299805 | BCE Loss: 1.0090386867523193\n",
      "Epoch 130 / 500 | iteration 20 / 30 | Total Loss: 3.5187675952911377 | KNN Loss: 2.4975147247314453 | BCE Loss: 1.0212528705596924\n",
      "Epoch 130 / 500 | iteration 25 / 30 | Total Loss: 3.4811484813690186 | KNN Loss: 2.476649761199951 | BCE Loss: 1.0044987201690674\n",
      "Epoch 131 / 500 | iteration 0 / 30 | Total Loss: 3.4929122924804688 | KNN Loss: 2.4792919158935547 | BCE Loss: 1.013620376586914\n",
      "Epoch 131 / 500 | iteration 5 / 30 | Total Loss: 3.5237879753112793 | KNN Loss: 2.5273220539093018 | BCE Loss: 0.9964660406112671\n",
      "Epoch 131 / 500 | iteration 10 / 30 | Total Loss: 3.5076725482940674 | KNN Loss: 2.499018430709839 | BCE Loss: 1.0086541175842285\n",
      "Epoch 131 / 500 | iteration 15 / 30 | Total Loss: 3.487757682800293 | KNN Loss: 2.5007266998291016 | BCE Loss: 0.987031102180481\n",
      "Epoch 131 / 500 | iteration 20 / 30 | Total Loss: 3.481226682662964 | KNN Loss: 2.478266716003418 | BCE Loss: 1.002959966659546\n",
      "Epoch 131 / 500 | iteration 25 / 30 | Total Loss: 3.462794780731201 | KNN Loss: 2.451693296432495 | BCE Loss: 1.011101484298706\n",
      "Epoch 132 / 500 | iteration 0 / 30 | Total Loss: 3.5001144409179688 | KNN Loss: 2.4749362468719482 | BCE Loss: 1.0251781940460205\n",
      "Epoch 132 / 500 | iteration 5 / 30 | Total Loss: 3.538142442703247 | KNN Loss: 2.4886016845703125 | BCE Loss: 1.0495407581329346\n",
      "Epoch 132 / 500 | iteration 10 / 30 | Total Loss: 3.5096805095672607 | KNN Loss: 2.4842798709869385 | BCE Loss: 1.0254006385803223\n",
      "Epoch 132 / 500 | iteration 15 / 30 | Total Loss: 3.4878036975860596 | KNN Loss: 2.4663949012756348 | BCE Loss: 1.0214087963104248\n",
      "Epoch 132 / 500 | iteration 20 / 30 | Total Loss: 3.513092517852783 | KNN Loss: 2.503612518310547 | BCE Loss: 1.0094801187515259\n",
      "Epoch 132 / 500 | iteration 25 / 30 | Total Loss: 3.5063443183898926 | KNN Loss: 2.496344566345215 | BCE Loss: 1.0099997520446777\n",
      "Epoch 133 / 500 | iteration 0 / 30 | Total Loss: 3.4850058555603027 | KNN Loss: 2.471721649169922 | BCE Loss: 1.0132843255996704\n",
      "Epoch 133 / 500 | iteration 5 / 30 | Total Loss: 3.483215808868408 | KNN Loss: 2.468287467956543 | BCE Loss: 1.0149283409118652\n",
      "Epoch 133 / 500 | iteration 10 / 30 | Total Loss: 3.4610886573791504 | KNN Loss: 2.458984136581421 | BCE Loss: 1.002104640007019\n",
      "Epoch 133 / 500 | iteration 15 / 30 | Total Loss: 3.4957542419433594 | KNN Loss: 2.4828014373779297 | BCE Loss: 1.0129529237747192\n",
      "Epoch 133 / 500 | iteration 20 / 30 | Total Loss: 3.5541141033172607 | KNN Loss: 2.496438503265381 | BCE Loss: 1.0576756000518799\n",
      "Epoch 133 / 500 | iteration 25 / 30 | Total Loss: 3.5084753036499023 | KNN Loss: 2.479928970336914 | BCE Loss: 1.0285463333129883\n",
      "Epoch 134 / 500 | iteration 0 / 30 | Total Loss: 3.4676527976989746 | KNN Loss: 2.482175827026367 | BCE Loss: 0.9854769706726074\n",
      "Epoch 134 / 500 | iteration 5 / 30 | Total Loss: 3.5243170261383057 | KNN Loss: 2.4847960472106934 | BCE Loss: 1.0395209789276123\n",
      "Epoch 134 / 500 | iteration 10 / 30 | Total Loss: 3.533942461013794 | KNN Loss: 2.4837305545806885 | BCE Loss: 1.0502119064331055\n",
      "Epoch 134 / 500 | iteration 15 / 30 | Total Loss: 3.4786996841430664 | KNN Loss: 2.4905877113342285 | BCE Loss: 0.9881118535995483\n",
      "Epoch 134 / 500 | iteration 20 / 30 | Total Loss: 3.508605480194092 | KNN Loss: 2.49715256690979 | BCE Loss: 1.0114529132843018\n",
      "Epoch 134 / 500 | iteration 25 / 30 | Total Loss: 3.516371250152588 | KNN Loss: 2.5103933811187744 | BCE Loss: 1.0059778690338135\n",
      "Epoch 135 / 500 | iteration 0 / 30 | Total Loss: 3.511212110519409 | KNN Loss: 2.499936103820801 | BCE Loss: 1.0112760066986084\n",
      "Epoch 135 / 500 | iteration 5 / 30 | Total Loss: 3.476170778274536 | KNN Loss: 2.4622275829315186 | BCE Loss: 1.0139431953430176\n",
      "Epoch 135 / 500 | iteration 10 / 30 | Total Loss: 3.5213277339935303 | KNN Loss: 2.4848434925079346 | BCE Loss: 1.0364842414855957\n",
      "Epoch 135 / 500 | iteration 15 / 30 | Total Loss: 3.447887897491455 | KNN Loss: 2.469960927963257 | BCE Loss: 0.9779269695281982\n",
      "Epoch 135 / 500 | iteration 20 / 30 | Total Loss: 3.5120959281921387 | KNN Loss: 2.5120348930358887 | BCE Loss: 1.0000609159469604\n",
      "Epoch 135 / 500 | iteration 25 / 30 | Total Loss: 3.4848899841308594 | KNN Loss: 2.4636106491088867 | BCE Loss: 1.021279215812683\n",
      "Epoch 136 / 500 | iteration 0 / 30 | Total Loss: 3.488189458847046 | KNN Loss: 2.5025486946105957 | BCE Loss: 0.9856407642364502\n",
      "Epoch 136 / 500 | iteration 5 / 30 | Total Loss: 3.5027172565460205 | KNN Loss: 2.508275032043457 | BCE Loss: 0.9944421648979187\n",
      "Epoch 136 / 500 | iteration 10 / 30 | Total Loss: 3.5635440349578857 | KNN Loss: 2.535515546798706 | BCE Loss: 1.0280284881591797\n",
      "Epoch 136 / 500 | iteration 15 / 30 | Total Loss: 3.4917964935302734 | KNN Loss: 2.472169876098633 | BCE Loss: 1.0196266174316406\n",
      "Epoch 136 / 500 | iteration 20 / 30 | Total Loss: 3.469716787338257 | KNN Loss: 2.458012580871582 | BCE Loss: 1.0117042064666748\n",
      "Epoch 136 / 500 | iteration 25 / 30 | Total Loss: 3.490612506866455 | KNN Loss: 2.4711079597473145 | BCE Loss: 1.0195046663284302\n",
      "Epoch 137 / 500 | iteration 0 / 30 | Total Loss: 3.489433765411377 | KNN Loss: 2.473686456680298 | BCE Loss: 1.0157474279403687\n",
      "Epoch 137 / 500 | iteration 5 / 30 | Total Loss: 3.4828453063964844 | KNN Loss: 2.4702670574188232 | BCE Loss: 1.0125783681869507\n",
      "Epoch 137 / 500 | iteration 10 / 30 | Total Loss: 3.5453555583953857 | KNN Loss: 2.527390241622925 | BCE Loss: 1.017965316772461\n",
      "Epoch 137 / 500 | iteration 15 / 30 | Total Loss: 3.493668794631958 | KNN Loss: 2.45231032371521 | BCE Loss: 1.041358470916748\n",
      "Epoch 137 / 500 | iteration 20 / 30 | Total Loss: 3.488949775695801 | KNN Loss: 2.478825330734253 | BCE Loss: 1.0101244449615479\n",
      "Epoch 137 / 500 | iteration 25 / 30 | Total Loss: 3.5503876209259033 | KNN Loss: 2.51784348487854 | BCE Loss: 1.0325441360473633\n",
      "Epoch 138 / 500 | iteration 0 / 30 | Total Loss: 3.487332820892334 | KNN Loss: 2.4858181476593018 | BCE Loss: 1.0015147924423218\n",
      "Epoch 138 / 500 | iteration 5 / 30 | Total Loss: 3.5267491340637207 | KNN Loss: 2.508894205093384 | BCE Loss: 1.0178548097610474\n",
      "Epoch 138 / 500 | iteration 10 / 30 | Total Loss: 3.502424478530884 | KNN Loss: 2.4792540073394775 | BCE Loss: 1.0231704711914062\n",
      "Epoch 138 / 500 | iteration 15 / 30 | Total Loss: 3.5590474605560303 | KNN Loss: 2.5221545696258545 | BCE Loss: 1.0368928909301758\n",
      "Epoch 138 / 500 | iteration 20 / 30 | Total Loss: 3.5221331119537354 | KNN Loss: 2.498908281326294 | BCE Loss: 1.0232248306274414\n",
      "Epoch 138 / 500 | iteration 25 / 30 | Total Loss: 3.4854025840759277 | KNN Loss: 2.4739413261413574 | BCE Loss: 1.0114612579345703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 500 | iteration 0 / 30 | Total Loss: 3.482316732406616 | KNN Loss: 2.4791340827941895 | BCE Loss: 1.0031826496124268\n",
      "Epoch 139 / 500 | iteration 5 / 30 | Total Loss: 3.5040557384490967 | KNN Loss: 2.473863363265991 | BCE Loss: 1.0301923751831055\n",
      "Epoch 139 / 500 | iteration 10 / 30 | Total Loss: 3.5037801265716553 | KNN Loss: 2.484387159347534 | BCE Loss: 1.019392967224121\n",
      "Epoch 139 / 500 | iteration 15 / 30 | Total Loss: 3.482200860977173 | KNN Loss: 2.4948575496673584 | BCE Loss: 0.9873433709144592\n",
      "Epoch 139 / 500 | iteration 20 / 30 | Total Loss: 3.522592544555664 | KNN Loss: 2.492755651473999 | BCE Loss: 1.029836893081665\n",
      "Epoch 139 / 500 | iteration 25 / 30 | Total Loss: 3.4807376861572266 | KNN Loss: 2.4747965335845947 | BCE Loss: 1.0059412717819214\n",
      "Epoch 140 / 500 | iteration 0 / 30 | Total Loss: 3.516231060028076 | KNN Loss: 2.4755067825317383 | BCE Loss: 1.0407243967056274\n",
      "Epoch 140 / 500 | iteration 5 / 30 | Total Loss: 3.5319228172302246 | KNN Loss: 2.526315212249756 | BCE Loss: 1.0056076049804688\n",
      "Epoch 140 / 500 | iteration 10 / 30 | Total Loss: 3.520824432373047 | KNN Loss: 2.4818403720855713 | BCE Loss: 1.0389840602874756\n",
      "Epoch 140 / 500 | iteration 15 / 30 | Total Loss: 3.4609243869781494 | KNN Loss: 2.465104341506958 | BCE Loss: 0.9958199858665466\n",
      "Epoch 140 / 500 | iteration 20 / 30 | Total Loss: 3.489583969116211 | KNN Loss: 2.4962656497955322 | BCE Loss: 0.9933184385299683\n",
      "Epoch 140 / 500 | iteration 25 / 30 | Total Loss: 3.4804883003234863 | KNN Loss: 2.4550974369049072 | BCE Loss: 1.0253909826278687\n",
      "Epoch 141 / 500 | iteration 0 / 30 | Total Loss: 3.5609357357025146 | KNN Loss: 2.5266778469085693 | BCE Loss: 1.0342578887939453\n",
      "Epoch 141 / 500 | iteration 5 / 30 | Total Loss: 3.512573719024658 | KNN Loss: 2.498476982116699 | BCE Loss: 1.014096736907959\n",
      "Epoch 141 / 500 | iteration 10 / 30 | Total Loss: 3.4892075061798096 | KNN Loss: 2.479595422744751 | BCE Loss: 1.0096120834350586\n",
      "Epoch 141 / 500 | iteration 15 / 30 | Total Loss: 3.5146803855895996 | KNN Loss: 2.5020856857299805 | BCE Loss: 1.0125945806503296\n",
      "Epoch 141 / 500 | iteration 20 / 30 | Total Loss: 3.520916223526001 | KNN Loss: 2.499265432357788 | BCE Loss: 1.021650791168213\n",
      "Epoch 141 / 500 | iteration 25 / 30 | Total Loss: 3.5008418560028076 | KNN Loss: 2.459820508956909 | BCE Loss: 1.0410213470458984\n",
      "Epoch 142 / 500 | iteration 0 / 30 | Total Loss: 3.5106613636016846 | KNN Loss: 2.4745006561279297 | BCE Loss: 1.0361607074737549\n",
      "Epoch 142 / 500 | iteration 5 / 30 | Total Loss: 3.4654061794281006 | KNN Loss: 2.463423013687134 | BCE Loss: 1.0019831657409668\n",
      "Epoch 142 / 500 | iteration 10 / 30 | Total Loss: 3.503790855407715 | KNN Loss: 2.466386079788208 | BCE Loss: 1.0374046564102173\n",
      "Epoch 142 / 500 | iteration 15 / 30 | Total Loss: 3.510824680328369 | KNN Loss: 2.4728357791900635 | BCE Loss: 1.0379889011383057\n",
      "Epoch 142 / 500 | iteration 20 / 30 | Total Loss: 3.5126826763153076 | KNN Loss: 2.502981185913086 | BCE Loss: 1.0097014904022217\n",
      "Epoch 142 / 500 | iteration 25 / 30 | Total Loss: 3.488680124282837 | KNN Loss: 2.4629554748535156 | BCE Loss: 1.0257246494293213\n",
      "Epoch 143 / 500 | iteration 0 / 30 | Total Loss: 3.508472204208374 | KNN Loss: 2.516974449157715 | BCE Loss: 0.9914976954460144\n",
      "Epoch 143 / 500 | iteration 5 / 30 | Total Loss: 3.474097490310669 | KNN Loss: 2.434521436691284 | BCE Loss: 1.0395760536193848\n",
      "Epoch 143 / 500 | iteration 10 / 30 | Total Loss: 3.5033342838287354 | KNN Loss: 2.4636926651000977 | BCE Loss: 1.0396416187286377\n",
      "Epoch 143 / 500 | iteration 15 / 30 | Total Loss: 3.4800641536712646 | KNN Loss: 2.4646780490875244 | BCE Loss: 1.0153861045837402\n",
      "Epoch 143 / 500 | iteration 20 / 30 | Total Loss: 3.5160892009735107 | KNN Loss: 2.456331491470337 | BCE Loss: 1.0597577095031738\n",
      "Epoch 143 / 500 | iteration 25 / 30 | Total Loss: 3.4496450424194336 | KNN Loss: 2.447247266769409 | BCE Loss: 1.0023977756500244\n",
      "Epoch 144 / 500 | iteration 0 / 30 | Total Loss: 3.4841551780700684 | KNN Loss: 2.452533721923828 | BCE Loss: 1.0316214561462402\n",
      "Epoch 144 / 500 | iteration 5 / 30 | Total Loss: 3.453329086303711 | KNN Loss: 2.4551842212677 | BCE Loss: 0.9981449842453003\n",
      "Epoch 144 / 500 | iteration 10 / 30 | Total Loss: 3.518092393875122 | KNN Loss: 2.517200231552124 | BCE Loss: 1.000892162322998\n",
      "Epoch 144 / 500 | iteration 15 / 30 | Total Loss: 3.4866855144500732 | KNN Loss: 2.4964685440063477 | BCE Loss: 0.9902169108390808\n",
      "Epoch 144 / 500 | iteration 20 / 30 | Total Loss: 3.529074192047119 | KNN Loss: 2.479478359222412 | BCE Loss: 1.049595832824707\n",
      "Epoch 144 / 500 | iteration 25 / 30 | Total Loss: 3.498455286026001 | KNN Loss: 2.4834351539611816 | BCE Loss: 1.0150201320648193\n",
      "Epoch 145 / 500 | iteration 0 / 30 | Total Loss: 3.499450445175171 | KNN Loss: 2.4641504287719727 | BCE Loss: 1.0353000164031982\n",
      "Epoch 145 / 500 | iteration 5 / 30 | Total Loss: 3.490922689437866 | KNN Loss: 2.488938570022583 | BCE Loss: 1.0019841194152832\n",
      "Epoch 145 / 500 | iteration 10 / 30 | Total Loss: 3.4943904876708984 | KNN Loss: 2.455763101577759 | BCE Loss: 1.0386273860931396\n",
      "Epoch 145 / 500 | iteration 15 / 30 | Total Loss: 3.4658002853393555 | KNN Loss: 2.4646737575531006 | BCE Loss: 1.0011265277862549\n",
      "Epoch 145 / 500 | iteration 20 / 30 | Total Loss: 3.49548602104187 | KNN Loss: 2.48458194732666 | BCE Loss: 1.01090407371521\n",
      "Epoch 145 / 500 | iteration 25 / 30 | Total Loss: 3.5153958797454834 | KNN Loss: 2.4839723110198975 | BCE Loss: 1.031423568725586\n",
      "Epoch 146 / 500 | iteration 0 / 30 | Total Loss: 3.496469020843506 | KNN Loss: 2.470327854156494 | BCE Loss: 1.0261412858963013\n",
      "Epoch 146 / 500 | iteration 5 / 30 | Total Loss: 3.53955078125 | KNN Loss: 2.4846279621124268 | BCE Loss: 1.0549228191375732\n",
      "Epoch 146 / 500 | iteration 10 / 30 | Total Loss: 3.505302667617798 | KNN Loss: 2.488201379776001 | BCE Loss: 1.0171012878417969\n",
      "Epoch 146 / 500 | iteration 15 / 30 | Total Loss: 3.574573516845703 | KNN Loss: 2.5387942790985107 | BCE Loss: 1.0357791185379028\n",
      "Epoch 146 / 500 | iteration 20 / 30 | Total Loss: 3.5397534370422363 | KNN Loss: 2.503926992416382 | BCE Loss: 1.035826325416565\n",
      "Epoch 146 / 500 | iteration 25 / 30 | Total Loss: 3.471921920776367 | KNN Loss: 2.460602283477783 | BCE Loss: 1.011319637298584\n",
      "Epoch 147 / 500 | iteration 0 / 30 | Total Loss: 3.5034468173980713 | KNN Loss: 2.4804251194000244 | BCE Loss: 1.0230216979980469\n",
      "Epoch 147 / 500 | iteration 5 / 30 | Total Loss: 3.517280340194702 | KNN Loss: 2.4657509326934814 | BCE Loss: 1.0515294075012207\n",
      "Epoch 147 / 500 | iteration 10 / 30 | Total Loss: 3.4994988441467285 | KNN Loss: 2.4928128719329834 | BCE Loss: 1.0066859722137451\n",
      "Epoch 147 / 500 | iteration 15 / 30 | Total Loss: 3.4641406536102295 | KNN Loss: 2.4647605419158936 | BCE Loss: 0.9993801712989807\n",
      "Epoch 147 / 500 | iteration 20 / 30 | Total Loss: 3.5366950035095215 | KNN Loss: 2.490182876586914 | BCE Loss: 1.0465120077133179\n",
      "Epoch 147 / 500 | iteration 25 / 30 | Total Loss: 3.5098042488098145 | KNN Loss: 2.462217092514038 | BCE Loss: 1.0475871562957764\n",
      "Epoch 148 / 500 | iteration 0 / 30 | Total Loss: 3.549905300140381 | KNN Loss: 2.4964418411254883 | BCE Loss: 1.053463339805603\n",
      "Epoch 148 / 500 | iteration 5 / 30 | Total Loss: 3.495454788208008 | KNN Loss: 2.47538685798645 | BCE Loss: 1.0200679302215576\n",
      "Epoch 148 / 500 | iteration 10 / 30 | Total Loss: 3.4861810207366943 | KNN Loss: 2.4695756435394287 | BCE Loss: 1.0166053771972656\n",
      "Epoch 148 / 500 | iteration 15 / 30 | Total Loss: 3.571356773376465 | KNN Loss: 2.526987075805664 | BCE Loss: 1.0443696975708008\n",
      "Epoch 148 / 500 | iteration 20 / 30 | Total Loss: 3.501246690750122 | KNN Loss: 2.4668185710906982 | BCE Loss: 1.0344281196594238\n",
      "Epoch 148 / 500 | iteration 25 / 30 | Total Loss: 3.5427820682525635 | KNN Loss: 2.485001564025879 | BCE Loss: 1.0577805042266846\n",
      "Epoch 149 / 500 | iteration 0 / 30 | Total Loss: 3.545246124267578 | KNN Loss: 2.499049186706543 | BCE Loss: 1.0461969375610352\n",
      "Epoch 149 / 500 | iteration 5 / 30 | Total Loss: 3.5070202350616455 | KNN Loss: 2.4948244094848633 | BCE Loss: 1.0121958255767822\n",
      "Epoch 149 / 500 | iteration 10 / 30 | Total Loss: 3.512965679168701 | KNN Loss: 2.507080554962158 | BCE Loss: 1.0058852434158325\n",
      "Epoch 149 / 500 | iteration 15 / 30 | Total Loss: 3.4976561069488525 | KNN Loss: 2.4771599769592285 | BCE Loss: 1.020496129989624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 500 | iteration 20 / 30 | Total Loss: 3.4819135665893555 | KNN Loss: 2.476623058319092 | BCE Loss: 1.0052905082702637\n",
      "Epoch 149 / 500 | iteration 25 / 30 | Total Loss: 3.504093647003174 | KNN Loss: 2.474837303161621 | BCE Loss: 1.0292563438415527\n",
      "Epoch 150 / 500 | iteration 0 / 30 | Total Loss: 3.522616386413574 | KNN Loss: 2.49013090133667 | BCE Loss: 1.0324856042861938\n",
      "Epoch 150 / 500 | iteration 5 / 30 | Total Loss: 3.452866554260254 | KNN Loss: 2.4645397663116455 | BCE Loss: 0.9883266687393188\n",
      "Epoch 150 / 500 | iteration 10 / 30 | Total Loss: 3.4894609451293945 | KNN Loss: 2.501044511795044 | BCE Loss: 0.9884165525436401\n",
      "Epoch 150 / 500 | iteration 15 / 30 | Total Loss: 3.5418457984924316 | KNN Loss: 2.4853861331939697 | BCE Loss: 1.0564595460891724\n",
      "Epoch 150 / 500 | iteration 20 / 30 | Total Loss: 3.491000175476074 | KNN Loss: 2.461798906326294 | BCE Loss: 1.0292011499404907\n",
      "Epoch 150 / 500 | iteration 25 / 30 | Total Loss: 3.4834799766540527 | KNN Loss: 2.4744436740875244 | BCE Loss: 1.0090361833572388\n",
      "Epoch 151 / 500 | iteration 0 / 30 | Total Loss: 3.458052635192871 | KNN Loss: 2.4764938354492188 | BCE Loss: 0.9815587997436523\n",
      "Epoch 151 / 500 | iteration 5 / 30 | Total Loss: 3.4762015342712402 | KNN Loss: 2.4710116386413574 | BCE Loss: 1.0051898956298828\n",
      "Epoch 151 / 500 | iteration 10 / 30 | Total Loss: 3.5319085121154785 | KNN Loss: 2.4854378700256348 | BCE Loss: 1.0464705228805542\n",
      "Epoch 151 / 500 | iteration 15 / 30 | Total Loss: 3.4950032234191895 | KNN Loss: 2.5060620307922363 | BCE Loss: 0.9889413118362427\n",
      "Epoch 151 / 500 | iteration 20 / 30 | Total Loss: 3.541612386703491 | KNN Loss: 2.505208969116211 | BCE Loss: 1.0364034175872803\n",
      "Epoch 151 / 500 | iteration 25 / 30 | Total Loss: 3.4955220222473145 | KNN Loss: 2.4843363761901855 | BCE Loss: 1.011185646057129\n",
      "Epoch 152 / 500 | iteration 0 / 30 | Total Loss: 3.4646077156066895 | KNN Loss: 2.469038963317871 | BCE Loss: 0.9955686926841736\n",
      "Epoch 152 / 500 | iteration 5 / 30 | Total Loss: 3.501613140106201 | KNN Loss: 2.475731372833252 | BCE Loss: 1.0258816480636597\n",
      "Epoch 152 / 500 | iteration 10 / 30 | Total Loss: 3.5172927379608154 | KNN Loss: 2.5076029300689697 | BCE Loss: 1.0096898078918457\n",
      "Epoch 152 / 500 | iteration 15 / 30 | Total Loss: 3.496018648147583 | KNN Loss: 2.4836668968200684 | BCE Loss: 1.0123517513275146\n",
      "Epoch 152 / 500 | iteration 20 / 30 | Total Loss: 3.5089616775512695 | KNN Loss: 2.4953699111938477 | BCE Loss: 1.0135916471481323\n",
      "Epoch 152 / 500 | iteration 25 / 30 | Total Loss: 3.5031228065490723 | KNN Loss: 2.4675979614257812 | BCE Loss: 1.0355249643325806\n",
      "Epoch 153 / 500 | iteration 0 / 30 | Total Loss: 3.4534521102905273 | KNN Loss: 2.4759230613708496 | BCE Loss: 0.9775289297103882\n",
      "Epoch 153 / 500 | iteration 5 / 30 | Total Loss: 3.546262502670288 | KNN Loss: 2.5185647010803223 | BCE Loss: 1.0276978015899658\n",
      "Epoch 153 / 500 | iteration 10 / 30 | Total Loss: 3.544480562210083 | KNN Loss: 2.519108295440674 | BCE Loss: 1.0253722667694092\n",
      "Epoch 153 / 500 | iteration 15 / 30 | Total Loss: 3.479220151901245 | KNN Loss: 2.462470293045044 | BCE Loss: 1.0167498588562012\n",
      "Epoch 153 / 500 | iteration 20 / 30 | Total Loss: 3.4636290073394775 | KNN Loss: 2.4585683345794678 | BCE Loss: 1.0050606727600098\n",
      "Epoch 153 / 500 | iteration 25 / 30 | Total Loss: 3.5024681091308594 | KNN Loss: 2.482300281524658 | BCE Loss: 1.0201678276062012\n",
      "Epoch 154 / 500 | iteration 0 / 30 | Total Loss: 3.5222420692443848 | KNN Loss: 2.491831064224243 | BCE Loss: 1.0304110050201416\n",
      "Epoch 154 / 500 | iteration 5 / 30 | Total Loss: 3.4893791675567627 | KNN Loss: 2.4690959453582764 | BCE Loss: 1.0202832221984863\n",
      "Epoch 154 / 500 | iteration 10 / 30 | Total Loss: 3.466111660003662 | KNN Loss: 2.459326982498169 | BCE Loss: 1.0067846775054932\n",
      "Epoch 154 / 500 | iteration 15 / 30 | Total Loss: 3.4691097736358643 | KNN Loss: 2.4512650966644287 | BCE Loss: 1.0178446769714355\n",
      "Epoch 154 / 500 | iteration 20 / 30 | Total Loss: 3.497729778289795 | KNN Loss: 2.4797770977020264 | BCE Loss: 1.0179526805877686\n",
      "Epoch 154 / 500 | iteration 25 / 30 | Total Loss: 3.5265402793884277 | KNN Loss: 2.4788882732391357 | BCE Loss: 1.047652006149292\n",
      "Epoch 155 / 500 | iteration 0 / 30 | Total Loss: 3.540726661682129 | KNN Loss: 2.531747817993164 | BCE Loss: 1.0089788436889648\n",
      "Epoch 155 / 500 | iteration 5 / 30 | Total Loss: 3.5157089233398438 | KNN Loss: 2.472132444381714 | BCE Loss: 1.0435765981674194\n",
      "Epoch 155 / 500 | iteration 10 / 30 | Total Loss: 3.5212926864624023 | KNN Loss: 2.482123374938965 | BCE Loss: 1.0391693115234375\n",
      "Epoch 155 / 500 | iteration 15 / 30 | Total Loss: 3.5306529998779297 | KNN Loss: 2.5125207901000977 | BCE Loss: 1.018132209777832\n",
      "Epoch 155 / 500 | iteration 20 / 30 | Total Loss: 3.523066282272339 | KNN Loss: 2.5205698013305664 | BCE Loss: 1.0024964809417725\n",
      "Epoch 155 / 500 | iteration 25 / 30 | Total Loss: 3.5371084213256836 | KNN Loss: 2.4993107318878174 | BCE Loss: 1.0377976894378662\n",
      "Epoch 156 / 500 | iteration 0 / 30 | Total Loss: 3.468148708343506 | KNN Loss: 2.4708540439605713 | BCE Loss: 0.997294545173645\n",
      "Epoch 156 / 500 | iteration 5 / 30 | Total Loss: 3.500638484954834 | KNN Loss: 2.4652771949768066 | BCE Loss: 1.0353612899780273\n",
      "Epoch 156 / 500 | iteration 10 / 30 | Total Loss: 3.4758753776550293 | KNN Loss: 2.4697234630584717 | BCE Loss: 1.006151795387268\n",
      "Epoch 156 / 500 | iteration 15 / 30 | Total Loss: 3.4608442783355713 | KNN Loss: 2.454519510269165 | BCE Loss: 1.0063247680664062\n",
      "Epoch 156 / 500 | iteration 20 / 30 | Total Loss: 3.4730358123779297 | KNN Loss: 2.463116407394409 | BCE Loss: 1.0099194049835205\n",
      "Epoch 156 / 500 | iteration 25 / 30 | Total Loss: 3.4762468338012695 | KNN Loss: 2.470674753189087 | BCE Loss: 1.0055720806121826\n",
      "Epoch 157 / 500 | iteration 0 / 30 | Total Loss: 3.4995760917663574 | KNN Loss: 2.476384162902832 | BCE Loss: 1.0231919288635254\n",
      "Epoch 157 / 500 | iteration 5 / 30 | Total Loss: 3.467834711074829 | KNN Loss: 2.4855892658233643 | BCE Loss: 0.9822455048561096\n",
      "Epoch 157 / 500 | iteration 10 / 30 | Total Loss: 3.4635396003723145 | KNN Loss: 2.462601661682129 | BCE Loss: 1.0009379386901855\n",
      "Epoch 157 / 500 | iteration 15 / 30 | Total Loss: 3.5120787620544434 | KNN Loss: 2.480445146560669 | BCE Loss: 1.031633734703064\n",
      "Epoch 157 / 500 | iteration 20 / 30 | Total Loss: 3.494725465774536 | KNN Loss: 2.4865031242370605 | BCE Loss: 1.0082223415374756\n",
      "Epoch 157 / 500 | iteration 25 / 30 | Total Loss: 3.514514446258545 | KNN Loss: 2.4966135025024414 | BCE Loss: 1.017900824546814\n",
      "Epoch 158 / 500 | iteration 0 / 30 | Total Loss: 3.5530359745025635 | KNN Loss: 2.5334105491638184 | BCE Loss: 1.0196254253387451\n",
      "Epoch 158 / 500 | iteration 5 / 30 | Total Loss: 3.5141968727111816 | KNN Loss: 2.477301597595215 | BCE Loss: 1.0368953943252563\n",
      "Epoch 158 / 500 | iteration 10 / 30 | Total Loss: 3.508084297180176 | KNN Loss: 2.501734495162964 | BCE Loss: 1.006349802017212\n",
      "Epoch 158 / 500 | iteration 15 / 30 | Total Loss: 3.4581754207611084 | KNN Loss: 2.455615520477295 | BCE Loss: 1.0025599002838135\n",
      "Epoch 158 / 500 | iteration 20 / 30 | Total Loss: 3.5062408447265625 | KNN Loss: 2.505746841430664 | BCE Loss: 1.0004940032958984\n",
      "Epoch 158 / 500 | iteration 25 / 30 | Total Loss: 3.4705326557159424 | KNN Loss: 2.454160690307617 | BCE Loss: 1.0163719654083252\n",
      "Epoch 159 / 500 | iteration 0 / 30 | Total Loss: 3.4603681564331055 | KNN Loss: 2.4604406356811523 | BCE Loss: 0.9999275803565979\n",
      "Epoch 159 / 500 | iteration 5 / 30 | Total Loss: 3.4874861240386963 | KNN Loss: 2.472459554672241 | BCE Loss: 1.015026569366455\n",
      "Epoch 159 / 500 | iteration 10 / 30 | Total Loss: 3.490448474884033 | KNN Loss: 2.475849151611328 | BCE Loss: 1.014599323272705\n",
      "Epoch 159 / 500 | iteration 15 / 30 | Total Loss: 3.523587226867676 | KNN Loss: 2.488403081893921 | BCE Loss: 1.0351842641830444\n",
      "Epoch 159 / 500 | iteration 20 / 30 | Total Loss: 3.485860824584961 | KNN Loss: 2.480759620666504 | BCE Loss: 1.0051013231277466\n",
      "Epoch 159 / 500 | iteration 25 / 30 | Total Loss: 3.4897713661193848 | KNN Loss: 2.497206211090088 | BCE Loss: 0.9925651550292969\n",
      "Epoch 160 / 500 | iteration 0 / 30 | Total Loss: 3.5340490341186523 | KNN Loss: 2.4769880771636963 | BCE Loss: 1.0570610761642456\n",
      "Epoch 160 / 500 | iteration 5 / 30 | Total Loss: 3.508608818054199 | KNN Loss: 2.498826742172241 | BCE Loss: 1.009782075881958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 / 500 | iteration 10 / 30 | Total Loss: 3.4842495918273926 | KNN Loss: 2.4631786346435547 | BCE Loss: 1.0210708379745483\n",
      "Epoch 160 / 500 | iteration 15 / 30 | Total Loss: 3.490623712539673 | KNN Loss: 2.4754111766815186 | BCE Loss: 1.0152125358581543\n",
      "Epoch 160 / 500 | iteration 20 / 30 | Total Loss: 3.5053629875183105 | KNN Loss: 2.498751640319824 | BCE Loss: 1.0066113471984863\n",
      "Epoch 160 / 500 | iteration 25 / 30 | Total Loss: 3.5257866382598877 | KNN Loss: 2.5125467777252197 | BCE Loss: 1.013239860534668\n",
      "Epoch 161 / 500 | iteration 0 / 30 | Total Loss: 3.520066499710083 | KNN Loss: 2.488219976425171 | BCE Loss: 1.031846523284912\n",
      "Epoch 161 / 500 | iteration 5 / 30 | Total Loss: 3.4922516345977783 | KNN Loss: 2.471696138381958 | BCE Loss: 1.0205554962158203\n",
      "Epoch 161 / 500 | iteration 10 / 30 | Total Loss: 3.4958648681640625 | KNN Loss: 2.4635989665985107 | BCE Loss: 1.0322657823562622\n",
      "Epoch 161 / 500 | iteration 15 / 30 | Total Loss: 3.5132272243499756 | KNN Loss: 2.490487813949585 | BCE Loss: 1.0227394104003906\n",
      "Epoch 161 / 500 | iteration 20 / 30 | Total Loss: 3.4946095943450928 | KNN Loss: 2.4845261573791504 | BCE Loss: 1.0100834369659424\n",
      "Epoch 161 / 500 | iteration 25 / 30 | Total Loss: 3.526752471923828 | KNN Loss: 2.496718168258667 | BCE Loss: 1.0300343036651611\n",
      "Epoch   162: reducing learning rate of group 0 to 2.4500e-03.\n",
      "Epoch 162 / 500 | iteration 0 / 30 | Total Loss: 3.485041618347168 | KNN Loss: 2.4783742427825928 | BCE Loss: 1.0066674947738647\n",
      "Epoch 162 / 500 | iteration 5 / 30 | Total Loss: 3.49826717376709 | KNN Loss: 2.476260185241699 | BCE Loss: 1.0220069885253906\n",
      "Epoch 162 / 500 | iteration 10 / 30 | Total Loss: 3.4901034832000732 | KNN Loss: 2.4713144302368164 | BCE Loss: 1.0187890529632568\n",
      "Epoch 162 / 500 | iteration 15 / 30 | Total Loss: 3.559540271759033 | KNN Loss: 2.506417989730835 | BCE Loss: 1.0531221628189087\n",
      "Epoch 162 / 500 | iteration 20 / 30 | Total Loss: 3.49735164642334 | KNN Loss: 2.4752042293548584 | BCE Loss: 1.0221474170684814\n",
      "Epoch 162 / 500 | iteration 25 / 30 | Total Loss: 3.527329444885254 | KNN Loss: 2.484480381011963 | BCE Loss: 1.042849063873291\n",
      "Epoch 163 / 500 | iteration 0 / 30 | Total Loss: 3.5076892375946045 | KNN Loss: 2.504876136779785 | BCE Loss: 1.0028131008148193\n",
      "Epoch 163 / 500 | iteration 5 / 30 | Total Loss: 3.5095973014831543 | KNN Loss: 2.4947383403778076 | BCE Loss: 1.0148588418960571\n",
      "Epoch 163 / 500 | iteration 10 / 30 | Total Loss: 3.5700619220733643 | KNN Loss: 2.514118194580078 | BCE Loss: 1.0559437274932861\n",
      "Epoch 163 / 500 | iteration 15 / 30 | Total Loss: 3.4833836555480957 | KNN Loss: 2.4734890460968018 | BCE Loss: 1.0098944902420044\n",
      "Epoch 163 / 500 | iteration 20 / 30 | Total Loss: 3.5213685035705566 | KNN Loss: 2.4867727756500244 | BCE Loss: 1.0345957279205322\n",
      "Epoch 163 / 500 | iteration 25 / 30 | Total Loss: 3.531013250350952 | KNN Loss: 2.477839946746826 | BCE Loss: 1.053173303604126\n",
      "Epoch 164 / 500 | iteration 0 / 30 | Total Loss: 3.5032567977905273 | KNN Loss: 2.484818458557129 | BCE Loss: 1.0184383392333984\n",
      "Epoch 164 / 500 | iteration 5 / 30 | Total Loss: 3.5025582313537598 | KNN Loss: 2.481257915496826 | BCE Loss: 1.021300196647644\n",
      "Epoch 164 / 500 | iteration 10 / 30 | Total Loss: 3.518683433532715 | KNN Loss: 2.4826440811157227 | BCE Loss: 1.0360393524169922\n",
      "Epoch 164 / 500 | iteration 15 / 30 | Total Loss: 3.506394863128662 | KNN Loss: 2.489976167678833 | BCE Loss: 1.0164185762405396\n",
      "Epoch 164 / 500 | iteration 20 / 30 | Total Loss: 3.516993999481201 | KNN Loss: 2.4861772060394287 | BCE Loss: 1.0308167934417725\n",
      "Epoch 164 / 500 | iteration 25 / 30 | Total Loss: 3.490638017654419 | KNN Loss: 2.47719144821167 | BCE Loss: 1.013446569442749\n",
      "Epoch 165 / 500 | iteration 0 / 30 | Total Loss: 3.5351829528808594 | KNN Loss: 2.511305809020996 | BCE Loss: 1.0238771438598633\n",
      "Epoch 165 / 500 | iteration 5 / 30 | Total Loss: 3.4928767681121826 | KNN Loss: 2.4822797775268555 | BCE Loss: 1.0105969905853271\n",
      "Epoch 165 / 500 | iteration 10 / 30 | Total Loss: 3.490631580352783 | KNN Loss: 2.478560447692871 | BCE Loss: 1.0120712518692017\n",
      "Epoch 165 / 500 | iteration 15 / 30 | Total Loss: 3.5290350914001465 | KNN Loss: 2.5076305866241455 | BCE Loss: 1.021404504776001\n",
      "Epoch 165 / 500 | iteration 20 / 30 | Total Loss: 3.5183801651000977 | KNN Loss: 2.5021755695343018 | BCE Loss: 1.016204595565796\n",
      "Epoch 165 / 500 | iteration 25 / 30 | Total Loss: 3.501873254776001 | KNN Loss: 2.492863416671753 | BCE Loss: 1.009009838104248\n",
      "Epoch 166 / 500 | iteration 0 / 30 | Total Loss: 3.544597625732422 | KNN Loss: 2.4961299896240234 | BCE Loss: 1.048467755317688\n",
      "Epoch 166 / 500 | iteration 5 / 30 | Total Loss: 3.4860289096832275 | KNN Loss: 2.4703824520111084 | BCE Loss: 1.0156464576721191\n",
      "Epoch 166 / 500 | iteration 10 / 30 | Total Loss: 3.5115365982055664 | KNN Loss: 2.4718785285949707 | BCE Loss: 1.0396580696105957\n",
      "Epoch 166 / 500 | iteration 15 / 30 | Total Loss: 3.471849203109741 | KNN Loss: 2.4729673862457275 | BCE Loss: 0.9988818168640137\n",
      "Epoch 166 / 500 | iteration 20 / 30 | Total Loss: 3.518911838531494 | KNN Loss: 2.4767420291900635 | BCE Loss: 1.0421698093414307\n",
      "Epoch 166 / 500 | iteration 25 / 30 | Total Loss: 3.4810914993286133 | KNN Loss: 2.473008632659912 | BCE Loss: 1.0080828666687012\n",
      "Epoch 167 / 500 | iteration 0 / 30 | Total Loss: 3.4791548252105713 | KNN Loss: 2.4536805152893066 | BCE Loss: 1.0254743099212646\n",
      "Epoch 167 / 500 | iteration 5 / 30 | Total Loss: 3.498757839202881 | KNN Loss: 2.502948045730591 | BCE Loss: 0.9958099126815796\n",
      "Epoch 167 / 500 | iteration 10 / 30 | Total Loss: 3.5225625038146973 | KNN Loss: 2.5036723613739014 | BCE Loss: 1.0188900232315063\n",
      "Epoch 167 / 500 | iteration 15 / 30 | Total Loss: 3.493941307067871 | KNN Loss: 2.471799373626709 | BCE Loss: 1.0221418142318726\n",
      "Epoch 167 / 500 | iteration 20 / 30 | Total Loss: 3.4962024688720703 | KNN Loss: 2.4981672763824463 | BCE Loss: 0.9980353116989136\n",
      "Epoch 167 / 500 | iteration 25 / 30 | Total Loss: 3.4607133865356445 | KNN Loss: 2.4442317485809326 | BCE Loss: 1.016481637954712\n",
      "Epoch 168 / 500 | iteration 0 / 30 | Total Loss: 3.5179085731506348 | KNN Loss: 2.5022149085998535 | BCE Loss: 1.0156936645507812\n",
      "Epoch 168 / 500 | iteration 5 / 30 | Total Loss: 3.492198944091797 | KNN Loss: 2.4817609786987305 | BCE Loss: 1.0104378461837769\n",
      "Epoch 168 / 500 | iteration 10 / 30 | Total Loss: 3.47700834274292 | KNN Loss: 2.458073139190674 | BCE Loss: 1.0189350843429565\n",
      "Epoch 168 / 500 | iteration 15 / 30 | Total Loss: 3.5276408195495605 | KNN Loss: 2.5028789043426514 | BCE Loss: 1.0247620344161987\n",
      "Epoch 168 / 500 | iteration 20 / 30 | Total Loss: 3.4837327003479004 | KNN Loss: 2.475721597671509 | BCE Loss: 1.0080112218856812\n",
      "Epoch 168 / 500 | iteration 25 / 30 | Total Loss: 3.5358211994171143 | KNN Loss: 2.4766645431518555 | BCE Loss: 1.0591566562652588\n",
      "Epoch 169 / 500 | iteration 0 / 30 | Total Loss: 3.5077340602874756 | KNN Loss: 2.476011037826538 | BCE Loss: 1.0317230224609375\n",
      "Epoch 169 / 500 | iteration 5 / 30 | Total Loss: 3.518738269805908 | KNN Loss: 2.4686028957366943 | BCE Loss: 1.0501353740692139\n",
      "Epoch 169 / 500 | iteration 10 / 30 | Total Loss: 3.491819381713867 | KNN Loss: 2.4789764881134033 | BCE Loss: 1.0128430128097534\n",
      "Epoch 169 / 500 | iteration 15 / 30 | Total Loss: 3.4549620151519775 | KNN Loss: 2.4879279136657715 | BCE Loss: 0.967034101486206\n",
      "Epoch 169 / 500 | iteration 20 / 30 | Total Loss: 3.50337553024292 | KNN Loss: 2.467992067337036 | BCE Loss: 1.0353834629058838\n",
      "Epoch 169 / 500 | iteration 25 / 30 | Total Loss: 3.504535675048828 | KNN Loss: 2.491849660873413 | BCE Loss: 1.0126861333847046\n",
      "Epoch 170 / 500 | iteration 0 / 30 | Total Loss: 3.5369184017181396 | KNN Loss: 2.5004286766052246 | BCE Loss: 1.036489725112915\n",
      "Epoch 170 / 500 | iteration 5 / 30 | Total Loss: 3.5072035789489746 | KNN Loss: 2.4936065673828125 | BCE Loss: 1.013597011566162\n",
      "Epoch 170 / 500 | iteration 10 / 30 | Total Loss: 3.516308069229126 | KNN Loss: 2.5068204402923584 | BCE Loss: 1.0094876289367676\n",
      "Epoch 170 / 500 | iteration 15 / 30 | Total Loss: 3.496483325958252 | KNN Loss: 2.4914069175720215 | BCE Loss: 1.0050764083862305\n",
      "Epoch 170 / 500 | iteration 20 / 30 | Total Loss: 3.5238184928894043 | KNN Loss: 2.4798624515533447 | BCE Loss: 1.0439561605453491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 / 500 | iteration 25 / 30 | Total Loss: 3.536038398742676 | KNN Loss: 2.486983060836792 | BCE Loss: 1.0490552186965942\n",
      "Epoch 171 / 500 | iteration 0 / 30 | Total Loss: 3.4819111824035645 | KNN Loss: 2.4913947582244873 | BCE Loss: 0.9905164837837219\n",
      "Epoch 171 / 500 | iteration 5 / 30 | Total Loss: 3.5052528381347656 | KNN Loss: 2.503960371017456 | BCE Loss: 1.00129234790802\n",
      "Epoch 171 / 500 | iteration 10 / 30 | Total Loss: 3.4983720779418945 | KNN Loss: 2.4889581203460693 | BCE Loss: 1.0094139575958252\n",
      "Epoch 171 / 500 | iteration 15 / 30 | Total Loss: 3.45648455619812 | KNN Loss: 2.4666526317596436 | BCE Loss: 0.9898319244384766\n",
      "Epoch 171 / 500 | iteration 20 / 30 | Total Loss: 3.4699037075042725 | KNN Loss: 2.455061197280884 | BCE Loss: 1.0148425102233887\n",
      "Epoch 171 / 500 | iteration 25 / 30 | Total Loss: 3.455717086791992 | KNN Loss: 2.4700863361358643 | BCE Loss: 0.9856308102607727\n",
      "Epoch 172 / 500 | iteration 0 / 30 | Total Loss: 3.487621784210205 | KNN Loss: 2.463165521621704 | BCE Loss: 1.0244563817977905\n",
      "Epoch 172 / 500 | iteration 5 / 30 | Total Loss: 3.4669926166534424 | KNN Loss: 2.4581494331359863 | BCE Loss: 1.008843183517456\n",
      "Epoch 172 / 500 | iteration 10 / 30 | Total Loss: 3.5111887454986572 | KNN Loss: 2.4869725704193115 | BCE Loss: 1.0242161750793457\n",
      "Epoch 172 / 500 | iteration 15 / 30 | Total Loss: 3.5196468830108643 | KNN Loss: 2.4711155891418457 | BCE Loss: 1.0485312938690186\n",
      "Epoch 172 / 500 | iteration 20 / 30 | Total Loss: 3.4427859783172607 | KNN Loss: 2.456713914871216 | BCE Loss: 0.9860720634460449\n",
      "Epoch 172 / 500 | iteration 25 / 30 | Total Loss: 3.489936590194702 | KNN Loss: 2.4559803009033203 | BCE Loss: 1.0339562892913818\n",
      "Epoch 173 / 500 | iteration 0 / 30 | Total Loss: 3.4755568504333496 | KNN Loss: 2.4531197547912598 | BCE Loss: 1.0224370956420898\n",
      "Epoch 173 / 500 | iteration 5 / 30 | Total Loss: 3.497697114944458 | KNN Loss: 2.4754717350006104 | BCE Loss: 1.0222253799438477\n",
      "Epoch 173 / 500 | iteration 10 / 30 | Total Loss: 3.473766326904297 | KNN Loss: 2.47068452835083 | BCE Loss: 1.0030819177627563\n",
      "Epoch 173 / 500 | iteration 15 / 30 | Total Loss: 3.483431339263916 | KNN Loss: 2.4881765842437744 | BCE Loss: 0.9952548742294312\n",
      "Epoch 173 / 500 | iteration 20 / 30 | Total Loss: 3.4697437286376953 | KNN Loss: 2.4732587337493896 | BCE Loss: 0.9964849948883057\n",
      "Epoch 173 / 500 | iteration 25 / 30 | Total Loss: 3.4955267906188965 | KNN Loss: 2.4687955379486084 | BCE Loss: 1.0267313718795776\n",
      "Epoch 174 / 500 | iteration 0 / 30 | Total Loss: 3.512773275375366 | KNN Loss: 2.5135793685913086 | BCE Loss: 0.9991938471794128\n",
      "Epoch 174 / 500 | iteration 5 / 30 | Total Loss: 3.559819221496582 | KNN Loss: 2.510406732559204 | BCE Loss: 1.049412488937378\n",
      "Epoch 174 / 500 | iteration 10 / 30 | Total Loss: 3.4627535343170166 | KNN Loss: 2.458632469177246 | BCE Loss: 1.0041210651397705\n",
      "Epoch 174 / 500 | iteration 15 / 30 | Total Loss: 3.4742400646209717 | KNN Loss: 2.4429569244384766 | BCE Loss: 1.0312831401824951\n",
      "Epoch 174 / 500 | iteration 20 / 30 | Total Loss: 3.4731669425964355 | KNN Loss: 2.4661097526550293 | BCE Loss: 1.0070573091506958\n",
      "Epoch 174 / 500 | iteration 25 / 30 | Total Loss: 3.4513192176818848 | KNN Loss: 2.4601221084594727 | BCE Loss: 0.9911969900131226\n",
      "Epoch 175 / 500 | iteration 0 / 30 | Total Loss: 3.509660005569458 | KNN Loss: 2.4797377586364746 | BCE Loss: 1.0299222469329834\n",
      "Epoch 175 / 500 | iteration 5 / 30 | Total Loss: 3.509720802307129 | KNN Loss: 2.4629690647125244 | BCE Loss: 1.046751856803894\n",
      "Epoch 175 / 500 | iteration 10 / 30 | Total Loss: 3.5526251792907715 | KNN Loss: 2.489295244216919 | BCE Loss: 1.063329815864563\n",
      "Epoch 175 / 500 | iteration 15 / 30 | Total Loss: 3.4786536693573 | KNN Loss: 2.472703456878662 | BCE Loss: 1.0059502124786377\n",
      "Epoch 175 / 500 | iteration 20 / 30 | Total Loss: 3.496333599090576 | KNN Loss: 2.4563281536102295 | BCE Loss: 1.0400054454803467\n",
      "Epoch 175 / 500 | iteration 25 / 30 | Total Loss: 3.489537000656128 | KNN Loss: 2.467491388320923 | BCE Loss: 1.022045612335205\n",
      "Epoch 176 / 500 | iteration 0 / 30 | Total Loss: 3.481186866760254 | KNN Loss: 2.4829132556915283 | BCE Loss: 0.9982736110687256\n",
      "Epoch 176 / 500 | iteration 5 / 30 | Total Loss: 3.499913215637207 | KNN Loss: 2.489473819732666 | BCE Loss: 1.010439395904541\n",
      "Epoch 176 / 500 | iteration 10 / 30 | Total Loss: 3.4633142948150635 | KNN Loss: 2.458977222442627 | BCE Loss: 1.0043370723724365\n",
      "Epoch 176 / 500 | iteration 15 / 30 | Total Loss: 3.5337975025177 | KNN Loss: 2.5295581817626953 | BCE Loss: 1.0042393207550049\n",
      "Epoch 176 / 500 | iteration 20 / 30 | Total Loss: 3.486264705657959 | KNN Loss: 2.4679203033447266 | BCE Loss: 1.0183444023132324\n",
      "Epoch 176 / 500 | iteration 25 / 30 | Total Loss: 3.499359130859375 | KNN Loss: 2.4894886016845703 | BCE Loss: 1.0098705291748047\n",
      "Epoch 177 / 500 | iteration 0 / 30 | Total Loss: 3.4733986854553223 | KNN Loss: 2.458051919937134 | BCE Loss: 1.015346646308899\n",
      "Epoch 177 / 500 | iteration 5 / 30 | Total Loss: 3.490541458129883 | KNN Loss: 2.47060489654541 | BCE Loss: 1.0199365615844727\n",
      "Epoch 177 / 500 | iteration 10 / 30 | Total Loss: 3.483031749725342 | KNN Loss: 2.465672731399536 | BCE Loss: 1.0173590183258057\n",
      "Epoch 177 / 500 | iteration 15 / 30 | Total Loss: 3.514841079711914 | KNN Loss: 2.4961133003234863 | BCE Loss: 1.0187278985977173\n",
      "Epoch 177 / 500 | iteration 20 / 30 | Total Loss: 3.471493721008301 | KNN Loss: 2.4557249546051025 | BCE Loss: 1.0157687664031982\n",
      "Epoch 177 / 500 | iteration 25 / 30 | Total Loss: 3.497880458831787 | KNN Loss: 2.489016056060791 | BCE Loss: 1.008864402770996\n",
      "Epoch 178 / 500 | iteration 0 / 30 | Total Loss: 3.504918336868286 | KNN Loss: 2.460352659225464 | BCE Loss: 1.0445656776428223\n",
      "Epoch 178 / 500 | iteration 5 / 30 | Total Loss: 3.5063095092773438 | KNN Loss: 2.494262933731079 | BCE Loss: 1.0120465755462646\n",
      "Epoch 178 / 500 | iteration 10 / 30 | Total Loss: 3.4639854431152344 | KNN Loss: 2.4526822566986084 | BCE Loss: 1.0113033056259155\n",
      "Epoch 178 / 500 | iteration 15 / 30 | Total Loss: 3.4876139163970947 | KNN Loss: 2.4964711666107178 | BCE Loss: 0.9911426901817322\n",
      "Epoch 178 / 500 | iteration 20 / 30 | Total Loss: 3.4913644790649414 | KNN Loss: 2.4663851261138916 | BCE Loss: 1.0249793529510498\n",
      "Epoch 178 / 500 | iteration 25 / 30 | Total Loss: 3.4598171710968018 | KNN Loss: 2.4721124172210693 | BCE Loss: 0.9877048134803772\n",
      "Epoch   179: reducing learning rate of group 0 to 1.7150e-03.\n",
      "Epoch 179 / 500 | iteration 0 / 30 | Total Loss: 3.4663827419281006 | KNN Loss: 2.4676365852355957 | BCE Loss: 0.9987460970878601\n",
      "Epoch 179 / 500 | iteration 5 / 30 | Total Loss: 3.4908230304718018 | KNN Loss: 2.4646201133728027 | BCE Loss: 1.026202917098999\n",
      "Epoch 179 / 500 | iteration 10 / 30 | Total Loss: 3.4750349521636963 | KNN Loss: 2.4665584564208984 | BCE Loss: 1.0084764957427979\n",
      "Epoch 179 / 500 | iteration 15 / 30 | Total Loss: 3.4605648517608643 | KNN Loss: 2.4607462882995605 | BCE Loss: 0.9998185038566589\n",
      "Epoch 179 / 500 | iteration 20 / 30 | Total Loss: 3.496582269668579 | KNN Loss: 2.4779365062713623 | BCE Loss: 1.0186457633972168\n",
      "Epoch 179 / 500 | iteration 25 / 30 | Total Loss: 3.493891954421997 | KNN Loss: 2.460645914077759 | BCE Loss: 1.0332460403442383\n",
      "Epoch 180 / 500 | iteration 0 / 30 | Total Loss: 3.5478672981262207 | KNN Loss: 2.488492488861084 | BCE Loss: 1.0593748092651367\n",
      "Epoch 180 / 500 | iteration 5 / 30 | Total Loss: 3.4689855575561523 | KNN Loss: 2.4712836742401123 | BCE Loss: 0.9977020025253296\n",
      "Epoch 180 / 500 | iteration 10 / 30 | Total Loss: 3.5174546241760254 | KNN Loss: 2.486353635787964 | BCE Loss: 1.0311009883880615\n",
      "Epoch 180 / 500 | iteration 15 / 30 | Total Loss: 3.4419374465942383 | KNN Loss: 2.4455158710479736 | BCE Loss: 0.9964214563369751\n",
      "Epoch 180 / 500 | iteration 20 / 30 | Total Loss: 3.5478882789611816 | KNN Loss: 2.494232416152954 | BCE Loss: 1.053655982017517\n",
      "Epoch 180 / 500 | iteration 25 / 30 | Total Loss: 3.5064330101013184 | KNN Loss: 2.472806692123413 | BCE Loss: 1.0336264371871948\n",
      "Epoch 181 / 500 | iteration 0 / 30 | Total Loss: 3.4738292694091797 | KNN Loss: 2.474421262741089 | BCE Loss: 0.9994081258773804\n",
      "Epoch 181 / 500 | iteration 5 / 30 | Total Loss: 3.517960548400879 | KNN Loss: 2.472198486328125 | BCE Loss: 1.045762062072754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181 / 500 | iteration 10 / 30 | Total Loss: 3.5404510498046875 | KNN Loss: 2.5114963054656982 | BCE Loss: 1.0289547443389893\n",
      "Epoch 181 / 500 | iteration 15 / 30 | Total Loss: 3.489990234375 | KNN Loss: 2.4874119758605957 | BCE Loss: 1.0025782585144043\n",
      "Epoch 181 / 500 | iteration 20 / 30 | Total Loss: 3.5134968757629395 | KNN Loss: 2.477597951889038 | BCE Loss: 1.0358989238739014\n",
      "Epoch 181 / 500 | iteration 25 / 30 | Total Loss: 3.494162082672119 | KNN Loss: 2.4808385372161865 | BCE Loss: 1.0133235454559326\n",
      "Epoch 182 / 500 | iteration 0 / 30 | Total Loss: 3.4722747802734375 | KNN Loss: 2.467616081237793 | BCE Loss: 1.004658579826355\n",
      "Epoch 182 / 500 | iteration 5 / 30 | Total Loss: 3.467479944229126 | KNN Loss: 2.4614691734313965 | BCE Loss: 1.0060107707977295\n",
      "Epoch 182 / 500 | iteration 10 / 30 | Total Loss: 3.527548313140869 | KNN Loss: 2.48189377784729 | BCE Loss: 1.045654535293579\n",
      "Epoch 182 / 500 | iteration 15 / 30 | Total Loss: 3.4685022830963135 | KNN Loss: 2.4814517498016357 | BCE Loss: 0.9870505332946777\n",
      "Epoch 182 / 500 | iteration 20 / 30 | Total Loss: 3.5260722637176514 | KNN Loss: 2.4914422035217285 | BCE Loss: 1.0346300601959229\n",
      "Epoch 182 / 500 | iteration 25 / 30 | Total Loss: 3.4875881671905518 | KNN Loss: 2.4689910411834717 | BCE Loss: 1.01859712600708\n",
      "Epoch 183 / 500 | iteration 0 / 30 | Total Loss: 3.4514875411987305 | KNN Loss: 2.4427783489227295 | BCE Loss: 1.008709192276001\n",
      "Epoch 183 / 500 | iteration 5 / 30 | Total Loss: 3.5205206871032715 | KNN Loss: 2.49690842628479 | BCE Loss: 1.023612380027771\n",
      "Epoch 183 / 500 | iteration 10 / 30 | Total Loss: 3.4810714721679688 | KNN Loss: 2.501514196395874 | BCE Loss: 0.9795572757720947\n",
      "Epoch 183 / 500 | iteration 15 / 30 | Total Loss: 3.494708776473999 | KNN Loss: 2.4744441509246826 | BCE Loss: 1.0202646255493164\n",
      "Epoch 183 / 500 | iteration 20 / 30 | Total Loss: 3.5111777782440186 | KNN Loss: 2.478473663330078 | BCE Loss: 1.0327041149139404\n",
      "Epoch 183 / 500 | iteration 25 / 30 | Total Loss: 3.456085205078125 | KNN Loss: 2.4580130577087402 | BCE Loss: 0.9980721473693848\n",
      "Epoch 184 / 500 | iteration 0 / 30 | Total Loss: 3.492896318435669 | KNN Loss: 2.4887466430664062 | BCE Loss: 1.0041496753692627\n",
      "Epoch 184 / 500 | iteration 5 / 30 | Total Loss: 3.4925613403320312 | KNN Loss: 2.4941647052764893 | BCE Loss: 0.9983967542648315\n",
      "Epoch 184 / 500 | iteration 10 / 30 | Total Loss: 3.4533891677856445 | KNN Loss: 2.4558043479919434 | BCE Loss: 0.9975849390029907\n",
      "Epoch 184 / 500 | iteration 15 / 30 | Total Loss: 3.513303279876709 | KNN Loss: 2.4674556255340576 | BCE Loss: 1.0458475351333618\n",
      "Epoch 184 / 500 | iteration 20 / 30 | Total Loss: 3.532383918762207 | KNN Loss: 2.514078378677368 | BCE Loss: 1.0183055400848389\n",
      "Epoch 184 / 500 | iteration 25 / 30 | Total Loss: 3.4902195930480957 | KNN Loss: 2.482379198074341 | BCE Loss: 1.0078402757644653\n",
      "Epoch 185 / 500 | iteration 0 / 30 | Total Loss: 3.4584388732910156 | KNN Loss: 2.4496653079986572 | BCE Loss: 1.0087735652923584\n",
      "Epoch 185 / 500 | iteration 5 / 30 | Total Loss: 3.4794037342071533 | KNN Loss: 2.474395275115967 | BCE Loss: 1.0050084590911865\n",
      "Epoch 185 / 500 | iteration 10 / 30 | Total Loss: 3.4802193641662598 | KNN Loss: 2.481214761734009 | BCE Loss: 0.9990045428276062\n",
      "Epoch 185 / 500 | iteration 15 / 30 | Total Loss: 3.498647689819336 | KNN Loss: 2.477915048599243 | BCE Loss: 1.0207326412200928\n",
      "Epoch 185 / 500 | iteration 20 / 30 | Total Loss: 3.4633846282958984 | KNN Loss: 2.4615397453308105 | BCE Loss: 1.001844882965088\n",
      "Epoch 185 / 500 | iteration 25 / 30 | Total Loss: 3.5081751346588135 | KNN Loss: 2.4914941787719727 | BCE Loss: 1.0166809558868408\n",
      "Epoch 186 / 500 | iteration 0 / 30 | Total Loss: 3.4986701011657715 | KNN Loss: 2.4490318298339844 | BCE Loss: 1.049638271331787\n",
      "Epoch 186 / 500 | iteration 5 / 30 | Total Loss: 3.461683511734009 | KNN Loss: 2.468137502670288 | BCE Loss: 0.9935460090637207\n",
      "Epoch 186 / 500 | iteration 10 / 30 | Total Loss: 3.4780876636505127 | KNN Loss: 2.4768667221069336 | BCE Loss: 1.001220941543579\n",
      "Epoch 186 / 500 | iteration 15 / 30 | Total Loss: 3.4988362789154053 | KNN Loss: 2.4716312885284424 | BCE Loss: 1.027204990386963\n",
      "Epoch 186 / 500 | iteration 20 / 30 | Total Loss: 3.479790449142456 | KNN Loss: 2.456047534942627 | BCE Loss: 1.023742914199829\n",
      "Epoch 186 / 500 | iteration 25 / 30 | Total Loss: 3.4462413787841797 | KNN Loss: 2.4595706462860107 | BCE Loss: 0.986670732498169\n",
      "Epoch 187 / 500 | iteration 0 / 30 | Total Loss: 3.5020792484283447 | KNN Loss: 2.4825055599212646 | BCE Loss: 1.01957368850708\n",
      "Epoch 187 / 500 | iteration 5 / 30 | Total Loss: 3.482738494873047 | KNN Loss: 2.469015121459961 | BCE Loss: 1.0137234926223755\n",
      "Epoch 187 / 500 | iteration 10 / 30 | Total Loss: 3.509190320968628 | KNN Loss: 2.498711585998535 | BCE Loss: 1.0104787349700928\n",
      "Epoch 187 / 500 | iteration 15 / 30 | Total Loss: 3.480715274810791 | KNN Loss: 2.476900815963745 | BCE Loss: 1.003814458847046\n",
      "Epoch 187 / 500 | iteration 20 / 30 | Total Loss: 3.454395055770874 | KNN Loss: 2.4695119857788086 | BCE Loss: 0.9848830103874207\n",
      "Epoch 187 / 500 | iteration 25 / 30 | Total Loss: 3.459207057952881 | KNN Loss: 2.468898057937622 | BCE Loss: 0.9903088808059692\n",
      "Epoch 188 / 500 | iteration 0 / 30 | Total Loss: 3.480193614959717 | KNN Loss: 2.4633214473724365 | BCE Loss: 1.0168721675872803\n",
      "Epoch 188 / 500 | iteration 5 / 30 | Total Loss: 3.460045099258423 | KNN Loss: 2.459914445877075 | BCE Loss: 1.0001306533813477\n",
      "Epoch 188 / 500 | iteration 10 / 30 | Total Loss: 3.4605960845947266 | KNN Loss: 2.4646835327148438 | BCE Loss: 0.9959126114845276\n",
      "Epoch 188 / 500 | iteration 15 / 30 | Total Loss: 3.524416923522949 | KNN Loss: 2.488469123840332 | BCE Loss: 1.0359477996826172\n",
      "Epoch 188 / 500 | iteration 20 / 30 | Total Loss: 3.463437557220459 | KNN Loss: 2.4649219512939453 | BCE Loss: 0.9985157251358032\n",
      "Epoch 188 / 500 | iteration 25 / 30 | Total Loss: 3.463548183441162 | KNN Loss: 2.464731216430664 | BCE Loss: 0.998816967010498\n",
      "Epoch 189 / 500 | iteration 0 / 30 | Total Loss: 3.428802490234375 | KNN Loss: 2.4266409873962402 | BCE Loss: 1.0021615028381348\n",
      "Epoch 189 / 500 | iteration 5 / 30 | Total Loss: 3.482910633087158 | KNN Loss: 2.4877328872680664 | BCE Loss: 0.9951777458190918\n",
      "Epoch 189 / 500 | iteration 10 / 30 | Total Loss: 3.492095708847046 | KNN Loss: 2.4634852409362793 | BCE Loss: 1.0286104679107666\n",
      "Epoch 189 / 500 | iteration 15 / 30 | Total Loss: 3.5043447017669678 | KNN Loss: 2.4943325519561768 | BCE Loss: 1.010012149810791\n",
      "Epoch 189 / 500 | iteration 20 / 30 | Total Loss: 3.4426450729370117 | KNN Loss: 2.457108497619629 | BCE Loss: 0.9855364561080933\n",
      "Epoch 189 / 500 | iteration 25 / 30 | Total Loss: 3.4755568504333496 | KNN Loss: 2.4693117141723633 | BCE Loss: 1.0062450170516968\n",
      "Epoch 190 / 500 | iteration 0 / 30 | Total Loss: 3.507862091064453 | KNN Loss: 2.4725756645202637 | BCE Loss: 1.0352864265441895\n",
      "Epoch 190 / 500 | iteration 5 / 30 | Total Loss: 3.5031533241271973 | KNN Loss: 2.4838993549346924 | BCE Loss: 1.0192540884017944\n",
      "Epoch 190 / 500 | iteration 10 / 30 | Total Loss: 3.5000970363616943 | KNN Loss: 2.4751925468444824 | BCE Loss: 1.024904489517212\n",
      "Epoch 190 / 500 | iteration 15 / 30 | Total Loss: 3.4496097564697266 | KNN Loss: 2.461848497390747 | BCE Loss: 0.9877612590789795\n",
      "Epoch 190 / 500 | iteration 20 / 30 | Total Loss: 3.498760223388672 | KNN Loss: 2.4674806594848633 | BCE Loss: 1.031279444694519\n",
      "Epoch 190 / 500 | iteration 25 / 30 | Total Loss: 3.4958271980285645 | KNN Loss: 2.481076717376709 | BCE Loss: 1.0147504806518555\n",
      "Epoch 191 / 500 | iteration 0 / 30 | Total Loss: 3.5041396617889404 | KNN Loss: 2.493077278137207 | BCE Loss: 1.0110623836517334\n",
      "Epoch 191 / 500 | iteration 5 / 30 | Total Loss: 3.461866855621338 | KNN Loss: 2.471855640411377 | BCE Loss: 0.9900113344192505\n",
      "Epoch 191 / 500 | iteration 10 / 30 | Total Loss: 3.5341622829437256 | KNN Loss: 2.5272462368011475 | BCE Loss: 1.0069160461425781\n",
      "Epoch 191 / 500 | iteration 15 / 30 | Total Loss: 3.5573859214782715 | KNN Loss: 2.5050740242004395 | BCE Loss: 1.0523117780685425\n",
      "Epoch 191 / 500 | iteration 20 / 30 | Total Loss: 3.4941811561584473 | KNN Loss: 2.470649480819702 | BCE Loss: 1.0235317945480347\n",
      "Epoch 191 / 500 | iteration 25 / 30 | Total Loss: 3.4991369247436523 | KNN Loss: 2.456949472427368 | BCE Loss: 1.0421873331069946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 500 | iteration 0 / 30 | Total Loss: 3.466597557067871 | KNN Loss: 2.4687345027923584 | BCE Loss: 0.9978631734848022\n",
      "Epoch 192 / 500 | iteration 5 / 30 | Total Loss: 3.4962000846862793 | KNN Loss: 2.489098072052002 | BCE Loss: 1.007102131843567\n",
      "Epoch 192 / 500 | iteration 10 / 30 | Total Loss: 3.475496530532837 | KNN Loss: 2.4516568183898926 | BCE Loss: 1.0238397121429443\n",
      "Epoch 192 / 500 | iteration 15 / 30 | Total Loss: 3.4903697967529297 | KNN Loss: 2.4665439128875732 | BCE Loss: 1.0238258838653564\n",
      "Epoch 192 / 500 | iteration 20 / 30 | Total Loss: 3.477313995361328 | KNN Loss: 2.4598562717437744 | BCE Loss: 1.0174577236175537\n",
      "Epoch 192 / 500 | iteration 25 / 30 | Total Loss: 3.482335090637207 | KNN Loss: 2.4766244888305664 | BCE Loss: 1.0057107210159302\n",
      "Epoch 193 / 500 | iteration 0 / 30 | Total Loss: 3.510077476501465 | KNN Loss: 2.5040981769561768 | BCE Loss: 1.0059791803359985\n",
      "Epoch 193 / 500 | iteration 5 / 30 | Total Loss: 3.4522902965545654 | KNN Loss: 2.463104009628296 | BCE Loss: 0.9891862869262695\n",
      "Epoch 193 / 500 | iteration 10 / 30 | Total Loss: 3.520911931991577 | KNN Loss: 2.4802558422088623 | BCE Loss: 1.0406560897827148\n",
      "Epoch 193 / 500 | iteration 15 / 30 | Total Loss: 3.4876112937927246 | KNN Loss: 2.494633674621582 | BCE Loss: 0.9929776191711426\n",
      "Epoch 193 / 500 | iteration 20 / 30 | Total Loss: 3.474750280380249 | KNN Loss: 2.486147165298462 | BCE Loss: 0.9886031746864319\n",
      "Epoch 193 / 500 | iteration 25 / 30 | Total Loss: 3.524528741836548 | KNN Loss: 2.4957690238952637 | BCE Loss: 1.0287597179412842\n",
      "Epoch 194 / 500 | iteration 0 / 30 | Total Loss: 3.501338481903076 | KNN Loss: 2.4874308109283447 | BCE Loss: 1.0139076709747314\n",
      "Epoch 194 / 500 | iteration 5 / 30 | Total Loss: 3.501429319381714 | KNN Loss: 2.492168426513672 | BCE Loss: 1.009260892868042\n",
      "Epoch 194 / 500 | iteration 10 / 30 | Total Loss: 3.495811939239502 | KNN Loss: 2.4755990505218506 | BCE Loss: 1.0202127695083618\n",
      "Epoch 194 / 500 | iteration 15 / 30 | Total Loss: 3.4826011657714844 | KNN Loss: 2.4789228439331055 | BCE Loss: 1.003678321838379\n",
      "Epoch 194 / 500 | iteration 20 / 30 | Total Loss: 3.4947478771209717 | KNN Loss: 2.4906728267669678 | BCE Loss: 1.004075050354004\n",
      "Epoch 194 / 500 | iteration 25 / 30 | Total Loss: 3.457397937774658 | KNN Loss: 2.4562220573425293 | BCE Loss: 1.001175880432129\n",
      "Epoch 195 / 500 | iteration 0 / 30 | Total Loss: 3.5084969997406006 | KNN Loss: 2.490591049194336 | BCE Loss: 1.0179059505462646\n",
      "Epoch 195 / 500 | iteration 5 / 30 | Total Loss: 3.4836349487304688 | KNN Loss: 2.479142665863037 | BCE Loss: 1.0044922828674316\n",
      "Epoch 195 / 500 | iteration 10 / 30 | Total Loss: 3.4870903491973877 | KNN Loss: 2.465430498123169 | BCE Loss: 1.0216598510742188\n",
      "Epoch 195 / 500 | iteration 15 / 30 | Total Loss: 3.5257315635681152 | KNN Loss: 2.498199939727783 | BCE Loss: 1.0275317430496216\n",
      "Epoch 195 / 500 | iteration 20 / 30 | Total Loss: 3.5059847831726074 | KNN Loss: 2.476991653442383 | BCE Loss: 1.0289932489395142\n",
      "Epoch 195 / 500 | iteration 25 / 30 | Total Loss: 3.5591530799865723 | KNN Loss: 2.5070338249206543 | BCE Loss: 1.0521191358566284\n",
      "Epoch 196 / 500 | iteration 0 / 30 | Total Loss: 3.4445109367370605 | KNN Loss: 2.4401378631591797 | BCE Loss: 1.0043730735778809\n",
      "Epoch 196 / 500 | iteration 5 / 30 | Total Loss: 3.4490044116973877 | KNN Loss: 2.4533634185791016 | BCE Loss: 0.9956410527229309\n",
      "Epoch 196 / 500 | iteration 10 / 30 | Total Loss: 3.5035760402679443 | KNN Loss: 2.4820809364318848 | BCE Loss: 1.0214951038360596\n",
      "Epoch 196 / 500 | iteration 15 / 30 | Total Loss: 3.474341869354248 | KNN Loss: 2.497483491897583 | BCE Loss: 0.9768584370613098\n",
      "Epoch 196 / 500 | iteration 20 / 30 | Total Loss: 3.480471134185791 | KNN Loss: 2.487473726272583 | BCE Loss: 0.992997407913208\n",
      "Epoch 196 / 500 | iteration 25 / 30 | Total Loss: 3.4480128288269043 | KNN Loss: 2.460195779800415 | BCE Loss: 0.9878171682357788\n",
      "Epoch 197 / 500 | iteration 0 / 30 | Total Loss: 3.4833927154541016 | KNN Loss: 2.4786722660064697 | BCE Loss: 1.0047204494476318\n",
      "Epoch 197 / 500 | iteration 5 / 30 | Total Loss: 3.501671552658081 | KNN Loss: 2.467564821243286 | BCE Loss: 1.034106731414795\n",
      "Epoch 197 / 500 | iteration 10 / 30 | Total Loss: 3.4462978839874268 | KNN Loss: 2.4642186164855957 | BCE Loss: 0.982079267501831\n",
      "Epoch 197 / 500 | iteration 15 / 30 | Total Loss: 3.4981026649475098 | KNN Loss: 2.485058069229126 | BCE Loss: 1.0130447149276733\n",
      "Epoch 197 / 500 | iteration 20 / 30 | Total Loss: 3.466703414916992 | KNN Loss: 2.4753148555755615 | BCE Loss: 0.9913884997367859\n",
      "Epoch 197 / 500 | iteration 25 / 30 | Total Loss: 3.4487602710723877 | KNN Loss: 2.440302610397339 | BCE Loss: 1.0084576606750488\n",
      "Epoch 198 / 500 | iteration 0 / 30 | Total Loss: 3.4791131019592285 | KNN Loss: 2.4713916778564453 | BCE Loss: 1.0077214241027832\n",
      "Epoch 198 / 500 | iteration 5 / 30 | Total Loss: 3.464430809020996 | KNN Loss: 2.4496560096740723 | BCE Loss: 1.0147747993469238\n",
      "Epoch 198 / 500 | iteration 10 / 30 | Total Loss: 3.4639768600463867 | KNN Loss: 2.4724109172821045 | BCE Loss: 0.9915659427642822\n",
      "Epoch 198 / 500 | iteration 15 / 30 | Total Loss: 3.5261387825012207 | KNN Loss: 2.495744466781616 | BCE Loss: 1.0303943157196045\n",
      "Epoch 198 / 500 | iteration 20 / 30 | Total Loss: 3.4949707984924316 | KNN Loss: 2.4695019721984863 | BCE Loss: 1.0254688262939453\n",
      "Epoch 198 / 500 | iteration 25 / 30 | Total Loss: 3.480863094329834 | KNN Loss: 2.467974901199341 | BCE Loss: 1.0128883123397827\n",
      "Epoch 199 / 500 | iteration 0 / 30 | Total Loss: 3.4404568672180176 | KNN Loss: 2.447100877761841 | BCE Loss: 0.9933558702468872\n",
      "Epoch 199 / 500 | iteration 5 / 30 | Total Loss: 3.4832754135131836 | KNN Loss: 2.484341621398926 | BCE Loss: 0.9989339113235474\n",
      "Epoch 199 / 500 | iteration 10 / 30 | Total Loss: 3.446560859680176 | KNN Loss: 2.4420278072357178 | BCE Loss: 1.004533052444458\n",
      "Epoch 199 / 500 | iteration 15 / 30 | Total Loss: 3.4691474437713623 | KNN Loss: 2.4616689682006836 | BCE Loss: 1.0074784755706787\n",
      "Epoch 199 / 500 | iteration 20 / 30 | Total Loss: 3.4813241958618164 | KNN Loss: 2.5005264282226562 | BCE Loss: 0.9807977676391602\n",
      "Epoch 199 / 500 | iteration 25 / 30 | Total Loss: 3.4874768257141113 | KNN Loss: 2.487746000289917 | BCE Loss: 0.9997307062149048\n",
      "Epoch 200 / 500 | iteration 0 / 30 | Total Loss: 3.502842903137207 | KNN Loss: 2.5021350383758545 | BCE Loss: 1.000707983970642\n",
      "Epoch 200 / 500 | iteration 5 / 30 | Total Loss: 3.4965758323669434 | KNN Loss: 2.4864449501037598 | BCE Loss: 1.0101308822631836\n",
      "Epoch 200 / 500 | iteration 10 / 30 | Total Loss: 3.4771459102630615 | KNN Loss: 2.4547924995422363 | BCE Loss: 1.0223534107208252\n",
      "Epoch 200 / 500 | iteration 15 / 30 | Total Loss: 3.48422908782959 | KNN Loss: 2.466019868850708 | BCE Loss: 1.0182090997695923\n",
      "Epoch 200 / 500 | iteration 20 / 30 | Total Loss: 3.481635093688965 | KNN Loss: 2.460881233215332 | BCE Loss: 1.0207538604736328\n",
      "Epoch 200 / 500 | iteration 25 / 30 | Total Loss: 3.480642318725586 | KNN Loss: 2.4715576171875 | BCE Loss: 1.0090845823287964\n",
      "Epoch 201 / 500 | iteration 0 / 30 | Total Loss: 3.5038490295410156 | KNN Loss: 2.4840588569641113 | BCE Loss: 1.0197901725769043\n",
      "Epoch 201 / 500 | iteration 5 / 30 | Total Loss: 3.493725299835205 | KNN Loss: 2.4837193489074707 | BCE Loss: 1.0100059509277344\n",
      "Epoch 201 / 500 | iteration 10 / 30 | Total Loss: 3.5170717239379883 | KNN Loss: 2.489047050476074 | BCE Loss: 1.028024673461914\n",
      "Epoch 201 / 500 | iteration 15 / 30 | Total Loss: 3.476658582687378 | KNN Loss: 2.475358009338379 | BCE Loss: 1.001300573348999\n",
      "Epoch 201 / 500 | iteration 20 / 30 | Total Loss: 3.456007957458496 | KNN Loss: 2.472707986831665 | BCE Loss: 0.9832999110221863\n",
      "Epoch 201 / 500 | iteration 25 / 30 | Total Loss: 3.4985361099243164 | KNN Loss: 2.491156816482544 | BCE Loss: 1.0073792934417725\n",
      "Epoch 202 / 500 | iteration 0 / 30 | Total Loss: 3.485503673553467 | KNN Loss: 2.4894330501556396 | BCE Loss: 0.9960705041885376\n",
      "Epoch 202 / 500 | iteration 5 / 30 | Total Loss: 3.4705450534820557 | KNN Loss: 2.4691474437713623 | BCE Loss: 1.0013976097106934\n",
      "Epoch 202 / 500 | iteration 10 / 30 | Total Loss: 3.5011446475982666 | KNN Loss: 2.4615442752838135 | BCE Loss: 1.0396003723144531\n",
      "Epoch 202 / 500 | iteration 15 / 30 | Total Loss: 3.485607385635376 | KNN Loss: 2.46960186958313 | BCE Loss: 1.016005516052246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 / 500 | iteration 20 / 30 | Total Loss: 3.521244525909424 | KNN Loss: 2.501488208770752 | BCE Loss: 1.0197563171386719\n",
      "Epoch 202 / 500 | iteration 25 / 30 | Total Loss: 3.544469118118286 | KNN Loss: 2.489837169647217 | BCE Loss: 1.0546319484710693\n",
      "Epoch 203 / 500 | iteration 0 / 30 | Total Loss: 3.4819629192352295 | KNN Loss: 2.455026149749756 | BCE Loss: 1.0269367694854736\n",
      "Epoch 203 / 500 | iteration 5 / 30 | Total Loss: 3.5292177200317383 | KNN Loss: 2.4953784942626953 | BCE Loss: 1.033839225769043\n",
      "Epoch 203 / 500 | iteration 10 / 30 | Total Loss: 3.414332389831543 | KNN Loss: 2.428968667984009 | BCE Loss: 0.9853636026382446\n",
      "Epoch 203 / 500 | iteration 15 / 30 | Total Loss: 3.491642713546753 | KNN Loss: 2.494187831878662 | BCE Loss: 0.997454822063446\n",
      "Epoch 203 / 500 | iteration 20 / 30 | Total Loss: 3.450909376144409 | KNN Loss: 2.4501454830169678 | BCE Loss: 1.0007638931274414\n",
      "Epoch 203 / 500 | iteration 25 / 30 | Total Loss: 3.4956445693969727 | KNN Loss: 2.49507212638855 | BCE Loss: 1.0005724430084229\n",
      "Epoch 204 / 500 | iteration 0 / 30 | Total Loss: 3.438570499420166 | KNN Loss: 2.4499707221984863 | BCE Loss: 0.9885997772216797\n",
      "Epoch 204 / 500 | iteration 5 / 30 | Total Loss: 3.50297474861145 | KNN Loss: 2.475538492202759 | BCE Loss: 1.0274362564086914\n",
      "Epoch 204 / 500 | iteration 10 / 30 | Total Loss: 3.468069076538086 | KNN Loss: 2.4788475036621094 | BCE Loss: 0.9892216324806213\n",
      "Epoch 204 / 500 | iteration 15 / 30 | Total Loss: 3.4713668823242188 | KNN Loss: 2.4714694023132324 | BCE Loss: 0.9998973608016968\n",
      "Epoch 204 / 500 | iteration 20 / 30 | Total Loss: 3.494749069213867 | KNN Loss: 2.477968454360962 | BCE Loss: 1.0167806148529053\n",
      "Epoch 204 / 500 | iteration 25 / 30 | Total Loss: 3.484647035598755 | KNN Loss: 2.4607324600219727 | BCE Loss: 1.0239145755767822\n",
      "Epoch 205 / 500 | iteration 0 / 30 | Total Loss: 3.4549431800842285 | KNN Loss: 2.451240062713623 | BCE Loss: 1.0037031173706055\n",
      "Epoch 205 / 500 | iteration 5 / 30 | Total Loss: 3.479001045227051 | KNN Loss: 2.4632985591888428 | BCE Loss: 1.0157026052474976\n",
      "Epoch 205 / 500 | iteration 10 / 30 | Total Loss: 3.4995980262756348 | KNN Loss: 2.4739279747009277 | BCE Loss: 1.025670051574707\n",
      "Epoch 205 / 500 | iteration 15 / 30 | Total Loss: 3.5054352283477783 | KNN Loss: 2.4934170246124268 | BCE Loss: 1.0120182037353516\n",
      "Epoch 205 / 500 | iteration 20 / 30 | Total Loss: 3.468191623687744 | KNN Loss: 2.4900224208831787 | BCE Loss: 0.9781692624092102\n",
      "Epoch 205 / 500 | iteration 25 / 30 | Total Loss: 3.517066717147827 | KNN Loss: 2.4770658016204834 | BCE Loss: 1.0400009155273438\n",
      "Epoch 206 / 500 | iteration 0 / 30 | Total Loss: 3.4639713764190674 | KNN Loss: 2.4520955085754395 | BCE Loss: 1.011875867843628\n",
      "Epoch 206 / 500 | iteration 5 / 30 | Total Loss: 3.4815804958343506 | KNN Loss: 2.4759981632232666 | BCE Loss: 1.005582332611084\n",
      "Epoch 206 / 500 | iteration 10 / 30 | Total Loss: 3.4781718254089355 | KNN Loss: 2.4809134006500244 | BCE Loss: 0.9972585439682007\n",
      "Epoch 206 / 500 | iteration 15 / 30 | Total Loss: 3.5014657974243164 | KNN Loss: 2.484987735748291 | BCE Loss: 1.0164780616760254\n",
      "Epoch 206 / 500 | iteration 20 / 30 | Total Loss: 3.5179872512817383 | KNN Loss: 2.4860761165618896 | BCE Loss: 1.0319112539291382\n",
      "Epoch 206 / 500 | iteration 25 / 30 | Total Loss: 3.466684341430664 | KNN Loss: 2.4311771392822266 | BCE Loss: 1.0355072021484375\n",
      "Epoch 207 / 500 | iteration 0 / 30 | Total Loss: 3.4519834518432617 | KNN Loss: 2.455648422241211 | BCE Loss: 0.9963349103927612\n",
      "Epoch 207 / 500 | iteration 5 / 30 | Total Loss: 3.4735026359558105 | KNN Loss: 2.477830648422241 | BCE Loss: 0.9956719279289246\n",
      "Epoch 207 / 500 | iteration 10 / 30 | Total Loss: 3.4520907402038574 | KNN Loss: 2.4445128440856934 | BCE Loss: 1.007577896118164\n",
      "Epoch 207 / 500 | iteration 15 / 30 | Total Loss: 3.5236358642578125 | KNN Loss: 2.480397939682007 | BCE Loss: 1.0432379245758057\n",
      "Epoch 207 / 500 | iteration 20 / 30 | Total Loss: 3.4468843936920166 | KNN Loss: 2.4436635971069336 | BCE Loss: 1.003220796585083\n",
      "Epoch 207 / 500 | iteration 25 / 30 | Total Loss: 3.502326488494873 | KNN Loss: 2.4765992164611816 | BCE Loss: 1.0257272720336914\n",
      "Epoch 208 / 500 | iteration 0 / 30 | Total Loss: 3.478773832321167 | KNN Loss: 2.450981378555298 | BCE Loss: 1.0277924537658691\n",
      "Epoch 208 / 500 | iteration 5 / 30 | Total Loss: 3.5034005641937256 | KNN Loss: 2.478231430053711 | BCE Loss: 1.0251691341400146\n",
      "Epoch 208 / 500 | iteration 10 / 30 | Total Loss: 3.478821039199829 | KNN Loss: 2.45782208442688 | BCE Loss: 1.0209989547729492\n",
      "Epoch 208 / 500 | iteration 15 / 30 | Total Loss: 3.4856276512145996 | KNN Loss: 2.466116189956665 | BCE Loss: 1.0195115804672241\n",
      "Epoch 208 / 500 | iteration 20 / 30 | Total Loss: 3.501021146774292 | KNN Loss: 2.473074436187744 | BCE Loss: 1.0279467105865479\n",
      "Epoch 208 / 500 | iteration 25 / 30 | Total Loss: 3.441819667816162 | KNN Loss: 2.441389322280884 | BCE Loss: 1.0004303455352783\n",
      "Epoch 209 / 500 | iteration 0 / 30 | Total Loss: 3.4813897609710693 | KNN Loss: 2.471035957336426 | BCE Loss: 1.0103538036346436\n",
      "Epoch 209 / 500 | iteration 5 / 30 | Total Loss: 3.4709737300872803 | KNN Loss: 2.468580961227417 | BCE Loss: 1.0023927688598633\n",
      "Epoch 209 / 500 | iteration 10 / 30 | Total Loss: 3.4821114540100098 | KNN Loss: 2.487722873687744 | BCE Loss: 0.9943884611129761\n",
      "Epoch 209 / 500 | iteration 15 / 30 | Total Loss: 3.4502594470977783 | KNN Loss: 2.445514678955078 | BCE Loss: 1.0047447681427002\n",
      "Epoch 209 / 500 | iteration 20 / 30 | Total Loss: 3.5030617713928223 | KNN Loss: 2.452411413192749 | BCE Loss: 1.0506503582000732\n",
      "Epoch 209 / 500 | iteration 25 / 30 | Total Loss: 3.4556450843811035 | KNN Loss: 2.448970317840576 | BCE Loss: 1.0066747665405273\n",
      "Epoch   210: reducing learning rate of group 0 to 1.2005e-03.\n",
      "Epoch 210 / 500 | iteration 0 / 30 | Total Loss: 3.4689745903015137 | KNN Loss: 2.4744834899902344 | BCE Loss: 0.9944912195205688\n",
      "Epoch 210 / 500 | iteration 5 / 30 | Total Loss: 3.5007119178771973 | KNN Loss: 2.4934475421905518 | BCE Loss: 1.007264256477356\n",
      "Epoch 210 / 500 | iteration 10 / 30 | Total Loss: 3.4856231212615967 | KNN Loss: 2.4553844928741455 | BCE Loss: 1.0302386283874512\n",
      "Epoch 210 / 500 | iteration 15 / 30 | Total Loss: 3.4917023181915283 | KNN Loss: 2.4668571949005127 | BCE Loss: 1.0248451232910156\n",
      "Epoch 210 / 500 | iteration 20 / 30 | Total Loss: 3.4759507179260254 | KNN Loss: 2.481806993484497 | BCE Loss: 0.9941437244415283\n",
      "Epoch 210 / 500 | iteration 25 / 30 | Total Loss: 3.5028505325317383 | KNN Loss: 2.4763667583465576 | BCE Loss: 1.0264837741851807\n",
      "Epoch 211 / 500 | iteration 0 / 30 | Total Loss: 3.4532482624053955 | KNN Loss: 2.4565815925598145 | BCE Loss: 0.9966666102409363\n",
      "Epoch 211 / 500 | iteration 5 / 30 | Total Loss: 3.4709863662719727 | KNN Loss: 2.469622850418091 | BCE Loss: 1.0013635158538818\n",
      "Epoch 211 / 500 | iteration 10 / 30 | Total Loss: 3.4610350131988525 | KNN Loss: 2.4754114151000977 | BCE Loss: 0.9856235384941101\n",
      "Epoch 211 / 500 | iteration 15 / 30 | Total Loss: 3.4754116535186768 | KNN Loss: 2.4699809551239014 | BCE Loss: 1.0054306983947754\n",
      "Epoch 211 / 500 | iteration 20 / 30 | Total Loss: 3.466769218444824 | KNN Loss: 2.431818962097168 | BCE Loss: 1.0349502563476562\n",
      "Epoch 211 / 500 | iteration 25 / 30 | Total Loss: 3.4627490043640137 | KNN Loss: 2.4512956142425537 | BCE Loss: 1.01145339012146\n",
      "Epoch 212 / 500 | iteration 0 / 30 | Total Loss: 3.491893768310547 | KNN Loss: 2.4615185260772705 | BCE Loss: 1.030375361442566\n",
      "Epoch 212 / 500 | iteration 5 / 30 | Total Loss: 3.4351372718811035 | KNN Loss: 2.4522721767425537 | BCE Loss: 0.9828650951385498\n",
      "Epoch 212 / 500 | iteration 10 / 30 | Total Loss: 3.5222361087799072 | KNN Loss: 2.488290548324585 | BCE Loss: 1.0339455604553223\n",
      "Epoch 212 / 500 | iteration 15 / 30 | Total Loss: 3.4898428916931152 | KNN Loss: 2.4461631774902344 | BCE Loss: 1.0436797142028809\n",
      "Epoch 212 / 500 | iteration 20 / 30 | Total Loss: 3.4793004989624023 | KNN Loss: 2.4773662090301514 | BCE Loss: 1.001934289932251\n",
      "Epoch 212 / 500 | iteration 25 / 30 | Total Loss: 3.4872043132781982 | KNN Loss: 2.461561679840088 | BCE Loss: 1.0256426334381104\n",
      "Epoch 213 / 500 | iteration 0 / 30 | Total Loss: 3.46157169342041 | KNN Loss: 2.4439518451690674 | BCE Loss: 1.0176198482513428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213 / 500 | iteration 5 / 30 | Total Loss: 3.4666881561279297 | KNN Loss: 2.4429380893707275 | BCE Loss: 1.0237501859664917\n",
      "Epoch 213 / 500 | iteration 10 / 30 | Total Loss: 3.475761890411377 | KNN Loss: 2.4680514335632324 | BCE Loss: 1.0077104568481445\n",
      "Epoch 213 / 500 | iteration 15 / 30 | Total Loss: 3.4060983657836914 | KNN Loss: 2.4355077743530273 | BCE Loss: 0.9705907106399536\n",
      "Epoch 213 / 500 | iteration 20 / 30 | Total Loss: 3.4767813682556152 | KNN Loss: 2.473816394805908 | BCE Loss: 1.002964973449707\n",
      "Epoch 213 / 500 | iteration 25 / 30 | Total Loss: 3.500514030456543 | KNN Loss: 2.4512157440185547 | BCE Loss: 1.0492981672286987\n",
      "Epoch 214 / 500 | iteration 0 / 30 | Total Loss: 3.5339837074279785 | KNN Loss: 2.500840425491333 | BCE Loss: 1.033143162727356\n",
      "Epoch 214 / 500 | iteration 5 / 30 | Total Loss: 3.4960975646972656 | KNN Loss: 2.456702709197998 | BCE Loss: 1.0393948554992676\n",
      "Epoch 214 / 500 | iteration 10 / 30 | Total Loss: 3.477818489074707 | KNN Loss: 2.453343152999878 | BCE Loss: 1.0244754552841187\n",
      "Epoch 214 / 500 | iteration 15 / 30 | Total Loss: 3.4972429275512695 | KNN Loss: 2.4836907386779785 | BCE Loss: 1.0135523080825806\n",
      "Epoch 214 / 500 | iteration 20 / 30 | Total Loss: 3.449106216430664 | KNN Loss: 2.4557671546936035 | BCE Loss: 0.993338942527771\n",
      "Epoch 214 / 500 | iteration 25 / 30 | Total Loss: 3.460139751434326 | KNN Loss: 2.4470160007476807 | BCE Loss: 1.013123869895935\n",
      "Epoch 215 / 500 | iteration 0 / 30 | Total Loss: 3.4829907417297363 | KNN Loss: 2.4742648601531982 | BCE Loss: 1.008725881576538\n",
      "Epoch 215 / 500 | iteration 5 / 30 | Total Loss: 3.4981307983398438 | KNN Loss: 2.4757189750671387 | BCE Loss: 1.022411823272705\n",
      "Epoch 215 / 500 | iteration 10 / 30 | Total Loss: 3.503354072570801 | KNN Loss: 2.4884300231933594 | BCE Loss: 1.014924168586731\n",
      "Epoch 215 / 500 | iteration 15 / 30 | Total Loss: 3.4584474563598633 | KNN Loss: 2.455916166305542 | BCE Loss: 1.0025312900543213\n",
      "Epoch 215 / 500 | iteration 20 / 30 | Total Loss: 3.4732608795166016 | KNN Loss: 2.465165138244629 | BCE Loss: 1.0080957412719727\n",
      "Epoch 215 / 500 | iteration 25 / 30 | Total Loss: 3.4654927253723145 | KNN Loss: 2.46066951751709 | BCE Loss: 1.0048232078552246\n",
      "Epoch 216 / 500 | iteration 0 / 30 | Total Loss: 3.4873199462890625 | KNN Loss: 2.457225799560547 | BCE Loss: 1.0300941467285156\n",
      "Epoch 216 / 500 | iteration 5 / 30 | Total Loss: 3.489663600921631 | KNN Loss: 2.467122793197632 | BCE Loss: 1.022540807723999\n",
      "Epoch 216 / 500 | iteration 10 / 30 | Total Loss: 3.4752542972564697 | KNN Loss: 2.4557788372039795 | BCE Loss: 1.0194754600524902\n",
      "Epoch 216 / 500 | iteration 15 / 30 | Total Loss: 3.5021917819976807 | KNN Loss: 2.484032392501831 | BCE Loss: 1.0181593894958496\n",
      "Epoch 216 / 500 | iteration 20 / 30 | Total Loss: 3.4709668159484863 | KNN Loss: 2.4597253799438477 | BCE Loss: 1.0112413167953491\n",
      "Epoch 216 / 500 | iteration 25 / 30 | Total Loss: 3.516319990158081 | KNN Loss: 2.4690945148468018 | BCE Loss: 1.0472254753112793\n",
      "Epoch 217 / 500 | iteration 0 / 30 | Total Loss: 3.5217409133911133 | KNN Loss: 2.4895925521850586 | BCE Loss: 1.0321483612060547\n",
      "Epoch 217 / 500 | iteration 5 / 30 | Total Loss: 3.4820706844329834 | KNN Loss: 2.466716766357422 | BCE Loss: 1.0153539180755615\n",
      "Epoch 217 / 500 | iteration 10 / 30 | Total Loss: 3.4799294471740723 | KNN Loss: 2.436401605606079 | BCE Loss: 1.0435278415679932\n",
      "Epoch 217 / 500 | iteration 15 / 30 | Total Loss: 3.4616522789001465 | KNN Loss: 2.454409122467041 | BCE Loss: 1.007243275642395\n",
      "Epoch 217 / 500 | iteration 20 / 30 | Total Loss: 3.5108230113983154 | KNN Loss: 2.499635934829712 | BCE Loss: 1.0111870765686035\n",
      "Epoch 217 / 500 | iteration 25 / 30 | Total Loss: 3.476416826248169 | KNN Loss: 2.464524030685425 | BCE Loss: 1.0118927955627441\n",
      "Epoch 218 / 500 | iteration 0 / 30 | Total Loss: 3.4923136234283447 | KNN Loss: 2.4766201972961426 | BCE Loss: 1.0156934261322021\n",
      "Epoch 218 / 500 | iteration 5 / 30 | Total Loss: 3.5005011558532715 | KNN Loss: 2.4789819717407227 | BCE Loss: 1.0215190649032593\n",
      "Epoch 218 / 500 | iteration 10 / 30 | Total Loss: 3.4776101112365723 | KNN Loss: 2.4823453426361084 | BCE Loss: 0.9952648878097534\n",
      "Epoch 218 / 500 | iteration 15 / 30 | Total Loss: 3.4839975833892822 | KNN Loss: 2.4646847248077393 | BCE Loss: 1.019312858581543\n",
      "Epoch 218 / 500 | iteration 20 / 30 | Total Loss: 3.525869607925415 | KNN Loss: 2.4826579093933105 | BCE Loss: 1.0432116985321045\n",
      "Epoch 218 / 500 | iteration 25 / 30 | Total Loss: 3.475682258605957 | KNN Loss: 2.4644951820373535 | BCE Loss: 1.0111870765686035\n",
      "Epoch 219 / 500 | iteration 0 / 30 | Total Loss: 3.450681686401367 | KNN Loss: 2.463444948196411 | BCE Loss: 0.9872367978096008\n",
      "Epoch 219 / 500 | iteration 5 / 30 | Total Loss: 3.5074825286865234 | KNN Loss: 2.4905331134796143 | BCE Loss: 1.0169494152069092\n",
      "Epoch 219 / 500 | iteration 10 / 30 | Total Loss: 3.4960062503814697 | KNN Loss: 2.474778890609741 | BCE Loss: 1.0212273597717285\n",
      "Epoch 219 / 500 | iteration 15 / 30 | Total Loss: 3.4600143432617188 | KNN Loss: 2.4554603099823 | BCE Loss: 1.0045541524887085\n",
      "Epoch 219 / 500 | iteration 20 / 30 | Total Loss: 3.478559970855713 | KNN Loss: 2.4546947479248047 | BCE Loss: 1.0238651037216187\n",
      "Epoch 219 / 500 | iteration 25 / 30 | Total Loss: 3.426487922668457 | KNN Loss: 2.4605319499969482 | BCE Loss: 0.9659559726715088\n",
      "Epoch 220 / 500 | iteration 0 / 30 | Total Loss: 3.491511821746826 | KNN Loss: 2.4726972579956055 | BCE Loss: 1.0188144445419312\n",
      "Epoch 220 / 500 | iteration 5 / 30 | Total Loss: 3.5269579887390137 | KNN Loss: 2.5000810623168945 | BCE Loss: 1.0268769264221191\n",
      "Epoch 220 / 500 | iteration 10 / 30 | Total Loss: 3.479597568511963 | KNN Loss: 2.469935178756714 | BCE Loss: 1.009662389755249\n",
      "Epoch 220 / 500 | iteration 15 / 30 | Total Loss: 3.4323630332946777 | KNN Loss: 2.4404330253601074 | BCE Loss: 0.9919299483299255\n",
      "Epoch 220 / 500 | iteration 20 / 30 | Total Loss: 3.471602201461792 | KNN Loss: 2.4556941986083984 | BCE Loss: 1.0159080028533936\n",
      "Epoch 220 / 500 | iteration 25 / 30 | Total Loss: 3.470613718032837 | KNN Loss: 2.4566104412078857 | BCE Loss: 1.0140032768249512\n",
      "Epoch 221 / 500 | iteration 0 / 30 | Total Loss: 3.461451292037964 | KNN Loss: 2.484189987182617 | BCE Loss: 0.9772613048553467\n",
      "Epoch 221 / 500 | iteration 5 / 30 | Total Loss: 3.491316318511963 | KNN Loss: 2.465266227722168 | BCE Loss: 1.026050090789795\n",
      "Epoch 221 / 500 | iteration 10 / 30 | Total Loss: 3.4373624324798584 | KNN Loss: 2.4365992546081543 | BCE Loss: 1.000763177871704\n",
      "Epoch 221 / 500 | iteration 15 / 30 | Total Loss: 3.4831652641296387 | KNN Loss: 2.466862201690674 | BCE Loss: 1.0163030624389648\n",
      "Epoch 221 / 500 | iteration 20 / 30 | Total Loss: 3.4881606101989746 | KNN Loss: 2.466198444366455 | BCE Loss: 1.021962285041809\n",
      "Epoch 221 / 500 | iteration 25 / 30 | Total Loss: 3.4568042755126953 | KNN Loss: 2.436758279800415 | BCE Loss: 1.0200459957122803\n",
      "Epoch 222 / 500 | iteration 0 / 30 | Total Loss: 3.471524238586426 | KNN Loss: 2.4607317447662354 | BCE Loss: 1.01079261302948\n",
      "Epoch 222 / 500 | iteration 5 / 30 | Total Loss: 3.4755873680114746 | KNN Loss: 2.4669742584228516 | BCE Loss: 1.008613109588623\n",
      "Epoch 222 / 500 | iteration 10 / 30 | Total Loss: 3.467059373855591 | KNN Loss: 2.4781718254089355 | BCE Loss: 0.9888875484466553\n",
      "Epoch 222 / 500 | iteration 15 / 30 | Total Loss: 3.4630210399627686 | KNN Loss: 2.4798367023468018 | BCE Loss: 0.9831843376159668\n",
      "Epoch 222 / 500 | iteration 20 / 30 | Total Loss: 3.5412213802337646 | KNN Loss: 2.499210834503174 | BCE Loss: 1.0420105457305908\n",
      "Epoch 222 / 500 | iteration 25 / 30 | Total Loss: 3.4471640586853027 | KNN Loss: 2.435542345046997 | BCE Loss: 1.0116217136383057\n",
      "Epoch 223 / 500 | iteration 0 / 30 | Total Loss: 3.496192455291748 | KNN Loss: 2.469313621520996 | BCE Loss: 1.026878833770752\n",
      "Epoch 223 / 500 | iteration 5 / 30 | Total Loss: 3.514918088912964 | KNN Loss: 2.489665985107422 | BCE Loss: 1.025252103805542\n",
      "Epoch 223 / 500 | iteration 10 / 30 | Total Loss: 3.5235283374786377 | KNN Loss: 2.4901764392852783 | BCE Loss: 1.0333518981933594\n",
      "Epoch 223 / 500 | iteration 15 / 30 | Total Loss: 3.441810131072998 | KNN Loss: 2.444495677947998 | BCE Loss: 0.9973143339157104\n",
      "Epoch 223 / 500 | iteration 20 / 30 | Total Loss: 3.468904495239258 | KNN Loss: 2.468496799468994 | BCE Loss: 1.0004076957702637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 / 500 | iteration 25 / 30 | Total Loss: 3.4682388305664062 | KNN Loss: 2.4789772033691406 | BCE Loss: 0.9892617464065552\n",
      "Epoch 224 / 500 | iteration 0 / 30 | Total Loss: 3.4530858993530273 | KNN Loss: 2.4361634254455566 | BCE Loss: 1.0169223546981812\n",
      "Epoch 224 / 500 | iteration 5 / 30 | Total Loss: 3.5178747177124023 | KNN Loss: 2.4939587116241455 | BCE Loss: 1.0239160060882568\n",
      "Epoch 224 / 500 | iteration 10 / 30 | Total Loss: 3.5003507137298584 | KNN Loss: 2.469301700592041 | BCE Loss: 1.0310490131378174\n",
      "Epoch 224 / 500 | iteration 15 / 30 | Total Loss: 3.481722354888916 | KNN Loss: 2.4644556045532227 | BCE Loss: 1.0172666311264038\n",
      "Epoch 224 / 500 | iteration 20 / 30 | Total Loss: 3.4827194213867188 | KNN Loss: 2.471250295639038 | BCE Loss: 1.0114692449569702\n",
      "Epoch 224 / 500 | iteration 25 / 30 | Total Loss: 3.510706663131714 | KNN Loss: 2.4650845527648926 | BCE Loss: 1.0456221103668213\n",
      "Epoch 225 / 500 | iteration 0 / 30 | Total Loss: 3.5160083770751953 | KNN Loss: 2.476087808609009 | BCE Loss: 1.0399205684661865\n",
      "Epoch 225 / 500 | iteration 5 / 30 | Total Loss: 3.4821395874023438 | KNN Loss: 2.4755618572235107 | BCE Loss: 1.006577730178833\n",
      "Epoch 225 / 500 | iteration 10 / 30 | Total Loss: 3.4969725608825684 | KNN Loss: 2.480602502822876 | BCE Loss: 1.0163700580596924\n",
      "Epoch 225 / 500 | iteration 15 / 30 | Total Loss: 3.47198486328125 | KNN Loss: 2.4746575355529785 | BCE Loss: 0.9973272085189819\n",
      "Epoch 225 / 500 | iteration 20 / 30 | Total Loss: 3.518517017364502 | KNN Loss: 2.4716172218322754 | BCE Loss: 1.046899676322937\n",
      "Epoch 225 / 500 | iteration 25 / 30 | Total Loss: 3.4774014949798584 | KNN Loss: 2.4406425952911377 | BCE Loss: 1.0367588996887207\n",
      "Epoch 226 / 500 | iteration 0 / 30 | Total Loss: 3.494690418243408 | KNN Loss: 2.445722818374634 | BCE Loss: 1.0489675998687744\n",
      "Epoch 226 / 500 | iteration 5 / 30 | Total Loss: 3.454606771469116 | KNN Loss: 2.450087308883667 | BCE Loss: 1.0045194625854492\n",
      "Epoch 226 / 500 | iteration 10 / 30 | Total Loss: 3.4489989280700684 | KNN Loss: 2.4575436115264893 | BCE Loss: 0.9914553165435791\n",
      "Epoch 226 / 500 | iteration 15 / 30 | Total Loss: 3.4617230892181396 | KNN Loss: 2.455965042114258 | BCE Loss: 1.0057580471038818\n",
      "Epoch 226 / 500 | iteration 20 / 30 | Total Loss: 3.4953560829162598 | KNN Loss: 2.481571912765503 | BCE Loss: 1.0137842893600464\n",
      "Epoch 226 / 500 | iteration 25 / 30 | Total Loss: 3.433966636657715 | KNN Loss: 2.4431357383728027 | BCE Loss: 0.9908307790756226\n",
      "Epoch 227 / 500 | iteration 0 / 30 | Total Loss: 3.4991114139556885 | KNN Loss: 2.4826197624206543 | BCE Loss: 1.0164916515350342\n",
      "Epoch 227 / 500 | iteration 5 / 30 | Total Loss: 3.4723544120788574 | KNN Loss: 2.476408004760742 | BCE Loss: 0.9959465265274048\n",
      "Epoch 227 / 500 | iteration 10 / 30 | Total Loss: 3.500192642211914 | KNN Loss: 2.4759521484375 | BCE Loss: 1.0242406129837036\n",
      "Epoch 227 / 500 | iteration 15 / 30 | Total Loss: 3.447695016860962 | KNN Loss: 2.464844226837158 | BCE Loss: 0.9828507900238037\n",
      "Epoch 227 / 500 | iteration 20 / 30 | Total Loss: 3.4693031311035156 | KNN Loss: 2.465174674987793 | BCE Loss: 1.0041284561157227\n",
      "Epoch 227 / 500 | iteration 25 / 30 | Total Loss: 3.4946305751800537 | KNN Loss: 2.453218936920166 | BCE Loss: 1.0414116382598877\n",
      "Epoch 228 / 500 | iteration 0 / 30 | Total Loss: 3.4407405853271484 | KNN Loss: 2.4629998207092285 | BCE Loss: 0.9777407050132751\n",
      "Epoch 228 / 500 | iteration 5 / 30 | Total Loss: 3.47054386138916 | KNN Loss: 2.4596965312957764 | BCE Loss: 1.0108473300933838\n",
      "Epoch 228 / 500 | iteration 10 / 30 | Total Loss: 3.4472906589508057 | KNN Loss: 2.437541961669922 | BCE Loss: 1.0097486972808838\n",
      "Epoch 228 / 500 | iteration 15 / 30 | Total Loss: 3.497163772583008 | KNN Loss: 2.4569389820098877 | BCE Loss: 1.0402249097824097\n",
      "Epoch 228 / 500 | iteration 20 / 30 | Total Loss: 3.4572534561157227 | KNN Loss: 2.4593467712402344 | BCE Loss: 0.9979068040847778\n",
      "Epoch 228 / 500 | iteration 25 / 30 | Total Loss: 3.437291145324707 | KNN Loss: 2.4319286346435547 | BCE Loss: 1.005362629890442\n",
      "Epoch 229 / 500 | iteration 0 / 30 | Total Loss: 3.512205123901367 | KNN Loss: 2.483569622039795 | BCE Loss: 1.0286355018615723\n",
      "Epoch 229 / 500 | iteration 5 / 30 | Total Loss: 3.4392709732055664 | KNN Loss: 2.452929735183716 | BCE Loss: 0.9863413572311401\n",
      "Epoch 229 / 500 | iteration 10 / 30 | Total Loss: 3.4846577644348145 | KNN Loss: 2.4695677757263184 | BCE Loss: 1.015089988708496\n",
      "Epoch 229 / 500 | iteration 15 / 30 | Total Loss: 3.4901652336120605 | KNN Loss: 2.4777095317840576 | BCE Loss: 1.0124555826187134\n",
      "Epoch 229 / 500 | iteration 20 / 30 | Total Loss: 3.50386643409729 | KNN Loss: 2.473789930343628 | BCE Loss: 1.030076503753662\n",
      "Epoch 229 / 500 | iteration 25 / 30 | Total Loss: 3.4846737384796143 | KNN Loss: 2.4747414588928223 | BCE Loss: 1.009932279586792\n",
      "Epoch 230 / 500 | iteration 0 / 30 | Total Loss: 3.5377328395843506 | KNN Loss: 2.494666576385498 | BCE Loss: 1.0430662631988525\n",
      "Epoch 230 / 500 | iteration 5 / 30 | Total Loss: 3.4676623344421387 | KNN Loss: 2.4546375274658203 | BCE Loss: 1.013024926185608\n",
      "Epoch 230 / 500 | iteration 10 / 30 | Total Loss: 3.509284496307373 | KNN Loss: 2.475494623184204 | BCE Loss: 1.033789873123169\n",
      "Epoch 230 / 500 | iteration 15 / 30 | Total Loss: 3.468526601791382 | KNN Loss: 2.459333896636963 | BCE Loss: 1.009192705154419\n",
      "Epoch 230 / 500 | iteration 20 / 30 | Total Loss: 3.476947784423828 | KNN Loss: 2.4482648372650146 | BCE Loss: 1.0286829471588135\n",
      "Epoch 230 / 500 | iteration 25 / 30 | Total Loss: 3.465860366821289 | KNN Loss: 2.472985029220581 | BCE Loss: 0.9928754568099976\n",
      "Epoch 231 / 500 | iteration 0 / 30 | Total Loss: 3.461272716522217 | KNN Loss: 2.4478466510772705 | BCE Loss: 1.0134260654449463\n",
      "Epoch 231 / 500 | iteration 5 / 30 | Total Loss: 3.4971187114715576 | KNN Loss: 2.4825825691223145 | BCE Loss: 1.0145361423492432\n",
      "Epoch 231 / 500 | iteration 10 / 30 | Total Loss: 3.5055675506591797 | KNN Loss: 2.4819724559783936 | BCE Loss: 1.0235949754714966\n",
      "Epoch 231 / 500 | iteration 15 / 30 | Total Loss: 3.467745780944824 | KNN Loss: 2.466158866882324 | BCE Loss: 1.0015869140625\n",
      "Epoch 231 / 500 | iteration 20 / 30 | Total Loss: 3.490100860595703 | KNN Loss: 2.4390931129455566 | BCE Loss: 1.0510077476501465\n",
      "Epoch 231 / 500 | iteration 25 / 30 | Total Loss: 3.50234317779541 | KNN Loss: 2.489985466003418 | BCE Loss: 1.0123578310012817\n",
      "Epoch 232 / 500 | iteration 0 / 30 | Total Loss: 3.5112926959991455 | KNN Loss: 2.4599525928497314 | BCE Loss: 1.051340103149414\n",
      "Epoch 232 / 500 | iteration 5 / 30 | Total Loss: 3.4954538345336914 | KNN Loss: 2.4566330909729004 | BCE Loss: 1.038820743560791\n",
      "Epoch 232 / 500 | iteration 10 / 30 | Total Loss: 3.480625629425049 | KNN Loss: 2.4840710163116455 | BCE Loss: 0.9965547323226929\n",
      "Epoch 232 / 500 | iteration 15 / 30 | Total Loss: 3.4845285415649414 | KNN Loss: 2.460479497909546 | BCE Loss: 1.024048924446106\n",
      "Epoch 232 / 500 | iteration 20 / 30 | Total Loss: 3.468637466430664 | KNN Loss: 2.448406934738159 | BCE Loss: 1.0202305316925049\n",
      "Epoch 232 / 500 | iteration 25 / 30 | Total Loss: 3.4543275833129883 | KNN Loss: 2.461642265319824 | BCE Loss: 0.9926853179931641\n",
      "Epoch 233 / 500 | iteration 0 / 30 | Total Loss: 3.4474682807922363 | KNN Loss: 2.4570648670196533 | BCE Loss: 0.9904032945632935\n",
      "Epoch 233 / 500 | iteration 5 / 30 | Total Loss: 3.483834743499756 | KNN Loss: 2.439307928085327 | BCE Loss: 1.0445266962051392\n",
      "Epoch 233 / 500 | iteration 10 / 30 | Total Loss: 3.465576171875 | KNN Loss: 2.4811766147613525 | BCE Loss: 0.9843994379043579\n",
      "Epoch 233 / 500 | iteration 15 / 30 | Total Loss: 3.4858222007751465 | KNN Loss: 2.468414545059204 | BCE Loss: 1.0174076557159424\n",
      "Epoch 233 / 500 | iteration 20 / 30 | Total Loss: 3.4762277603149414 | KNN Loss: 2.4376299381256104 | BCE Loss: 1.038597822189331\n",
      "Epoch 233 / 500 | iteration 25 / 30 | Total Loss: 3.455355167388916 | KNN Loss: 2.45279860496521 | BCE Loss: 1.0025566816329956\n",
      "Epoch 234 / 500 | iteration 0 / 30 | Total Loss: 3.4819273948669434 | KNN Loss: 2.4680421352386475 | BCE Loss: 1.013885259628296\n",
      "Epoch 234 / 500 | iteration 5 / 30 | Total Loss: 3.472100257873535 | KNN Loss: 2.449610471725464 | BCE Loss: 1.0224897861480713\n",
      "Epoch 234 / 500 | iteration 10 / 30 | Total Loss: 3.5120537281036377 | KNN Loss: 2.4884088039398193 | BCE Loss: 1.0236449241638184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234 / 500 | iteration 15 / 30 | Total Loss: 3.487150192260742 | KNN Loss: 2.457684278488159 | BCE Loss: 1.0294660329818726\n",
      "Epoch 234 / 500 | iteration 20 / 30 | Total Loss: 3.516845703125 | KNN Loss: 2.489135265350342 | BCE Loss: 1.0277105569839478\n",
      "Epoch 234 / 500 | iteration 25 / 30 | Total Loss: 3.480289936065674 | KNN Loss: 2.4600515365600586 | BCE Loss: 1.0202382802963257\n",
      "Epoch 235 / 500 | iteration 0 / 30 | Total Loss: 3.5107548236846924 | KNN Loss: 2.4997782707214355 | BCE Loss: 1.0109765529632568\n",
      "Epoch 235 / 500 | iteration 5 / 30 | Total Loss: 3.4701790809631348 | KNN Loss: 2.4584739208221436 | BCE Loss: 1.0117051601409912\n",
      "Epoch 235 / 500 | iteration 10 / 30 | Total Loss: 3.49613094329834 | KNN Loss: 2.455707550048828 | BCE Loss: 1.0404233932495117\n",
      "Epoch 235 / 500 | iteration 15 / 30 | Total Loss: 3.466824769973755 | KNN Loss: 2.4414374828338623 | BCE Loss: 1.0253872871398926\n",
      "Epoch 235 / 500 | iteration 20 / 30 | Total Loss: 3.4956817626953125 | KNN Loss: 2.489654302597046 | BCE Loss: 1.0060275793075562\n",
      "Epoch 235 / 500 | iteration 25 / 30 | Total Loss: 3.495335102081299 | KNN Loss: 2.4983439445495605 | BCE Loss: 0.9969912171363831\n",
      "Epoch 236 / 500 | iteration 0 / 30 | Total Loss: 3.4671237468719482 | KNN Loss: 2.471134901046753 | BCE Loss: 0.9959887862205505\n",
      "Epoch 236 / 500 | iteration 5 / 30 | Total Loss: 3.4640088081359863 | KNN Loss: 2.4300596714019775 | BCE Loss: 1.0339490175247192\n",
      "Epoch 236 / 500 | iteration 10 / 30 | Total Loss: 3.5337259769439697 | KNN Loss: 2.4865009784698486 | BCE Loss: 1.047224998474121\n",
      "Epoch 236 / 500 | iteration 15 / 30 | Total Loss: 3.499298095703125 | KNN Loss: 2.478010892868042 | BCE Loss: 1.0212870836257935\n",
      "Epoch 236 / 500 | iteration 20 / 30 | Total Loss: 3.4660415649414062 | KNN Loss: 2.4590954780578613 | BCE Loss: 1.006946086883545\n",
      "Epoch 236 / 500 | iteration 25 / 30 | Total Loss: 3.48836088180542 | KNN Loss: 2.487961769104004 | BCE Loss: 1.000399112701416\n",
      "Epoch 237 / 500 | iteration 0 / 30 | Total Loss: 3.476672410964966 | KNN Loss: 2.428365707397461 | BCE Loss: 1.0483067035675049\n",
      "Epoch 237 / 500 | iteration 5 / 30 | Total Loss: 3.4467830657958984 | KNN Loss: 2.4444355964660645 | BCE Loss: 1.0023473501205444\n",
      "Epoch 237 / 500 | iteration 10 / 30 | Total Loss: 3.4410767555236816 | KNN Loss: 2.431968927383423 | BCE Loss: 1.0091078281402588\n",
      "Epoch 237 / 500 | iteration 15 / 30 | Total Loss: 3.4744110107421875 | KNN Loss: 2.4659860134124756 | BCE Loss: 1.0084248781204224\n",
      "Epoch 237 / 500 | iteration 20 / 30 | Total Loss: 3.457305431365967 | KNN Loss: 2.476346492767334 | BCE Loss: 0.9809590578079224\n",
      "Epoch 237 / 500 | iteration 25 / 30 | Total Loss: 3.467543125152588 | KNN Loss: 2.4538986682891846 | BCE Loss: 1.0136444568634033\n",
      "Epoch   238: reducing learning rate of group 0 to 8.4035e-04.\n",
      "Epoch 238 / 500 | iteration 0 / 30 | Total Loss: 3.4886257648468018 | KNN Loss: 2.4578769207000732 | BCE Loss: 1.0307488441467285\n",
      "Epoch 238 / 500 | iteration 5 / 30 | Total Loss: 3.4439635276794434 | KNN Loss: 2.457488536834717 | BCE Loss: 0.9864751100540161\n",
      "Epoch 238 / 500 | iteration 10 / 30 | Total Loss: 3.470947265625 | KNN Loss: 2.4646666049957275 | BCE Loss: 1.0062806606292725\n",
      "Epoch 238 / 500 | iteration 15 / 30 | Total Loss: 3.5280256271362305 | KNN Loss: 2.5154385566711426 | BCE Loss: 1.012587070465088\n",
      "Epoch 238 / 500 | iteration 20 / 30 | Total Loss: 3.480764865875244 | KNN Loss: 2.4591870307922363 | BCE Loss: 1.0215779542922974\n",
      "Epoch 238 / 500 | iteration 25 / 30 | Total Loss: 3.438593626022339 | KNN Loss: 2.4315712451934814 | BCE Loss: 1.0070223808288574\n",
      "Epoch 239 / 500 | iteration 0 / 30 | Total Loss: 3.459545135498047 | KNN Loss: 2.4603958129882812 | BCE Loss: 0.9991493821144104\n",
      "Epoch 239 / 500 | iteration 5 / 30 | Total Loss: 3.4215493202209473 | KNN Loss: 2.4420359134674072 | BCE Loss: 0.9795135259628296\n",
      "Epoch 239 / 500 | iteration 10 / 30 | Total Loss: 3.477806568145752 | KNN Loss: 2.4515221118927 | BCE Loss: 1.0262843370437622\n",
      "Epoch 239 / 500 | iteration 15 / 30 | Total Loss: 3.4821550846099854 | KNN Loss: 2.4773411750793457 | BCE Loss: 1.0048139095306396\n",
      "Epoch 239 / 500 | iteration 20 / 30 | Total Loss: 3.5155043601989746 | KNN Loss: 2.4913008213043213 | BCE Loss: 1.0242036581039429\n",
      "Epoch 239 / 500 | iteration 25 / 30 | Total Loss: 3.488865852355957 | KNN Loss: 2.4734017848968506 | BCE Loss: 1.015464186668396\n",
      "Epoch 240 / 500 | iteration 0 / 30 | Total Loss: 3.44346284866333 | KNN Loss: 2.4608335494995117 | BCE Loss: 0.9826291799545288\n",
      "Epoch 240 / 500 | iteration 5 / 30 | Total Loss: 3.458562135696411 | KNN Loss: 2.457228899002075 | BCE Loss: 1.001333236694336\n",
      "Epoch 240 / 500 | iteration 10 / 30 | Total Loss: 3.456116199493408 | KNN Loss: 2.448404312133789 | BCE Loss: 1.0077117681503296\n",
      "Epoch 240 / 500 | iteration 15 / 30 | Total Loss: 3.4651756286621094 | KNN Loss: 2.4474000930786133 | BCE Loss: 1.017775535583496\n",
      "Epoch 240 / 500 | iteration 20 / 30 | Total Loss: 3.4693806171417236 | KNN Loss: 2.465700626373291 | BCE Loss: 1.0036799907684326\n",
      "Epoch 240 / 500 | iteration 25 / 30 | Total Loss: 3.448176860809326 | KNN Loss: 2.440217971801758 | BCE Loss: 1.007959008216858\n",
      "Epoch 241 / 500 | iteration 0 / 30 | Total Loss: 3.4959263801574707 | KNN Loss: 2.460155725479126 | BCE Loss: 1.0357706546783447\n",
      "Epoch 241 / 500 | iteration 5 / 30 | Total Loss: 3.456573009490967 | KNN Loss: 2.4453229904174805 | BCE Loss: 1.0112498998641968\n",
      "Epoch 241 / 500 | iteration 10 / 30 | Total Loss: 3.497821092605591 | KNN Loss: 2.4735631942749023 | BCE Loss: 1.0242578983306885\n",
      "Epoch 241 / 500 | iteration 15 / 30 | Total Loss: 3.443049192428589 | KNN Loss: 2.4397504329681396 | BCE Loss: 1.0032987594604492\n",
      "Epoch 241 / 500 | iteration 20 / 30 | Total Loss: 3.5081887245178223 | KNN Loss: 2.4727632999420166 | BCE Loss: 1.0354253053665161\n",
      "Epoch 241 / 500 | iteration 25 / 30 | Total Loss: 3.4991455078125 | KNN Loss: 2.4710216522216797 | BCE Loss: 1.0281237363815308\n",
      "Epoch 242 / 500 | iteration 0 / 30 | Total Loss: 3.470101833343506 | KNN Loss: 2.4747769832611084 | BCE Loss: 0.9953248500823975\n",
      "Epoch 242 / 500 | iteration 5 / 30 | Total Loss: 3.553960084915161 | KNN Loss: 2.479384422302246 | BCE Loss: 1.074575662612915\n",
      "Epoch 242 / 500 | iteration 10 / 30 | Total Loss: 3.4668264389038086 | KNN Loss: 2.4637906551361084 | BCE Loss: 1.0030357837677002\n",
      "Epoch 242 / 500 | iteration 15 / 30 | Total Loss: 3.492736339569092 | KNN Loss: 2.4564425945281982 | BCE Loss: 1.0362937450408936\n",
      "Epoch 242 / 500 | iteration 20 / 30 | Total Loss: 3.468989133834839 | KNN Loss: 2.4658801555633545 | BCE Loss: 1.0031089782714844\n",
      "Epoch 242 / 500 | iteration 25 / 30 | Total Loss: 3.4736855030059814 | KNN Loss: 2.4525604248046875 | BCE Loss: 1.021125078201294\n",
      "Epoch 243 / 500 | iteration 0 / 30 | Total Loss: 3.4692881107330322 | KNN Loss: 2.440453052520752 | BCE Loss: 1.0288350582122803\n",
      "Epoch 243 / 500 | iteration 5 / 30 | Total Loss: 3.4425406455993652 | KNN Loss: 2.44461727142334 | BCE Loss: 0.9979234337806702\n",
      "Epoch 243 / 500 | iteration 10 / 30 | Total Loss: 3.454252243041992 | KNN Loss: 2.4561500549316406 | BCE Loss: 0.998102068901062\n",
      "Epoch 243 / 500 | iteration 15 / 30 | Total Loss: 3.468263864517212 | KNN Loss: 2.450404167175293 | BCE Loss: 1.017859697341919\n",
      "Epoch 243 / 500 | iteration 20 / 30 | Total Loss: 3.453148603439331 | KNN Loss: 2.4568676948547363 | BCE Loss: 0.9962809085845947\n",
      "Epoch 243 / 500 | iteration 25 / 30 | Total Loss: 3.5311925411224365 | KNN Loss: 2.489086866378784 | BCE Loss: 1.0421056747436523\n",
      "Epoch 244 / 500 | iteration 0 / 30 | Total Loss: 3.535712480545044 | KNN Loss: 2.4804182052612305 | BCE Loss: 1.0552942752838135\n",
      "Epoch 244 / 500 | iteration 5 / 30 | Total Loss: 3.450485944747925 | KNN Loss: 2.461350440979004 | BCE Loss: 0.9891355037689209\n",
      "Epoch 244 / 500 | iteration 10 / 30 | Total Loss: 3.49226450920105 | KNN Loss: 2.4493930339813232 | BCE Loss: 1.0428714752197266\n",
      "Epoch 244 / 500 | iteration 15 / 30 | Total Loss: 3.4705183506011963 | KNN Loss: 2.4518048763275146 | BCE Loss: 1.0187134742736816\n",
      "Epoch 244 / 500 | iteration 20 / 30 | Total Loss: 3.4460082054138184 | KNN Loss: 2.45808744430542 | BCE Loss: 0.9879207611083984\n",
      "Epoch 244 / 500 | iteration 25 / 30 | Total Loss: 3.4979991912841797 | KNN Loss: 2.463271379470825 | BCE Loss: 1.034727931022644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245 / 500 | iteration 0 / 30 | Total Loss: 3.43994140625 | KNN Loss: 2.448589324951172 | BCE Loss: 0.9913519620895386\n",
      "Epoch 245 / 500 | iteration 5 / 30 | Total Loss: 3.4686684608459473 | KNN Loss: 2.433504581451416 | BCE Loss: 1.0351638793945312\n",
      "Epoch 245 / 500 | iteration 10 / 30 | Total Loss: 3.4746437072753906 | KNN Loss: 2.466587781906128 | BCE Loss: 1.0080558061599731\n",
      "Epoch 245 / 500 | iteration 15 / 30 | Total Loss: 3.526972770690918 | KNN Loss: 2.4982352256774902 | BCE Loss: 1.0287376642227173\n",
      "Epoch 245 / 500 | iteration 20 / 30 | Total Loss: 3.49519419670105 | KNN Loss: 2.4866888523101807 | BCE Loss: 1.0085053443908691\n",
      "Epoch 245 / 500 | iteration 25 / 30 | Total Loss: 3.454439163208008 | KNN Loss: 2.4561712741851807 | BCE Loss: 0.9982680082321167\n",
      "Epoch 246 / 500 | iteration 0 / 30 | Total Loss: 3.4670865535736084 | KNN Loss: 2.4497711658477783 | BCE Loss: 1.01731538772583\n",
      "Epoch 246 / 500 | iteration 5 / 30 | Total Loss: 3.469473361968994 | KNN Loss: 2.448495388031006 | BCE Loss: 1.0209779739379883\n",
      "Epoch 246 / 500 | iteration 10 / 30 | Total Loss: 3.4803738594055176 | KNN Loss: 2.468676805496216 | BCE Loss: 1.0116970539093018\n",
      "Epoch 246 / 500 | iteration 15 / 30 | Total Loss: 3.4854371547698975 | KNN Loss: 2.4913511276245117 | BCE Loss: 0.994085967540741\n",
      "Epoch 246 / 500 | iteration 20 / 30 | Total Loss: 3.46342134475708 | KNN Loss: 2.462397336959839 | BCE Loss: 1.0010240077972412\n",
      "Epoch 246 / 500 | iteration 25 / 30 | Total Loss: 3.4932403564453125 | KNN Loss: 2.4629764556884766 | BCE Loss: 1.0302637815475464\n",
      "Epoch 247 / 500 | iteration 0 / 30 | Total Loss: 3.489891290664673 | KNN Loss: 2.4782469272613525 | BCE Loss: 1.0116443634033203\n",
      "Epoch 247 / 500 | iteration 5 / 30 | Total Loss: 3.4738669395446777 | KNN Loss: 2.4653682708740234 | BCE Loss: 1.0084987878799438\n",
      "Epoch 247 / 500 | iteration 10 / 30 | Total Loss: 3.521820068359375 | KNN Loss: 2.4733734130859375 | BCE Loss: 1.0484466552734375\n",
      "Epoch 247 / 500 | iteration 15 / 30 | Total Loss: 3.4375133514404297 | KNN Loss: 2.414274215698242 | BCE Loss: 1.0232391357421875\n",
      "Epoch 247 / 500 | iteration 20 / 30 | Total Loss: 3.452604293823242 | KNN Loss: 2.455723524093628 | BCE Loss: 0.996880829334259\n",
      "Epoch 247 / 500 | iteration 25 / 30 | Total Loss: 3.4990639686584473 | KNN Loss: 2.448538064956665 | BCE Loss: 1.0505259037017822\n",
      "Epoch 248 / 500 | iteration 0 / 30 | Total Loss: 3.497061252593994 | KNN Loss: 2.480494260787964 | BCE Loss: 1.0165669918060303\n",
      "Epoch 248 / 500 | iteration 5 / 30 | Total Loss: 3.4315526485443115 | KNN Loss: 2.4266366958618164 | BCE Loss: 1.0049159526824951\n",
      "Epoch 248 / 500 | iteration 10 / 30 | Total Loss: 3.4613847732543945 | KNN Loss: 2.4709041118621826 | BCE Loss: 0.9904806613922119\n",
      "Epoch 248 / 500 | iteration 15 / 30 | Total Loss: 3.4618313312530518 | KNN Loss: 2.439971685409546 | BCE Loss: 1.0218596458435059\n",
      "Epoch 248 / 500 | iteration 20 / 30 | Total Loss: 3.496385097503662 | KNN Loss: 2.4593334197998047 | BCE Loss: 1.0370516777038574\n",
      "Epoch 248 / 500 | iteration 25 / 30 | Total Loss: 3.5087385177612305 | KNN Loss: 2.4657437801361084 | BCE Loss: 1.042994737625122\n",
      "Epoch   249: reducing learning rate of group 0 to 5.8824e-04.\n",
      "Epoch 249 / 500 | iteration 0 / 30 | Total Loss: 3.487661600112915 | KNN Loss: 2.4577927589416504 | BCE Loss: 1.0298688411712646\n",
      "Epoch 249 / 500 | iteration 5 / 30 | Total Loss: 3.4872543811798096 | KNN Loss: 2.4700419902801514 | BCE Loss: 1.0172123908996582\n",
      "Epoch 249 / 500 | iteration 10 / 30 | Total Loss: 3.441678524017334 | KNN Loss: 2.460508346557617 | BCE Loss: 0.9811701774597168\n",
      "Epoch 249 / 500 | iteration 15 / 30 | Total Loss: 3.47053599357605 | KNN Loss: 2.4443776607513428 | BCE Loss: 1.026158332824707\n",
      "Epoch 249 / 500 | iteration 20 / 30 | Total Loss: 3.473092555999756 | KNN Loss: 2.4693665504455566 | BCE Loss: 1.0037260055541992\n",
      "Epoch 249 / 500 | iteration 25 / 30 | Total Loss: 3.4862101078033447 | KNN Loss: 2.4679512977600098 | BCE Loss: 1.018258810043335\n",
      "Epoch 250 / 500 | iteration 0 / 30 | Total Loss: 3.480952262878418 | KNN Loss: 2.4604530334472656 | BCE Loss: 1.0204991102218628\n",
      "Epoch 250 / 500 | iteration 5 / 30 | Total Loss: 3.4613029956817627 | KNN Loss: 2.4756765365600586 | BCE Loss: 0.9856265187263489\n",
      "Epoch 250 / 500 | iteration 10 / 30 | Total Loss: 3.4399120807647705 | KNN Loss: 2.4405877590179443 | BCE Loss: 0.9993243217468262\n",
      "Epoch 250 / 500 | iteration 15 / 30 | Total Loss: 3.540273666381836 | KNN Loss: 2.4914896488189697 | BCE Loss: 1.0487838983535767\n",
      "Epoch 250 / 500 | iteration 20 / 30 | Total Loss: 3.4852612018585205 | KNN Loss: 2.472698450088501 | BCE Loss: 1.0125627517700195\n",
      "Epoch 250 / 500 | iteration 25 / 30 | Total Loss: 3.5044286251068115 | KNN Loss: 2.4931819438934326 | BCE Loss: 1.011246681213379\n",
      "Epoch 251 / 500 | iteration 0 / 30 | Total Loss: 3.472546100616455 | KNN Loss: 2.450063467025757 | BCE Loss: 1.0224825143814087\n",
      "Epoch 251 / 500 | iteration 5 / 30 | Total Loss: 3.4969897270202637 | KNN Loss: 2.4664018154144287 | BCE Loss: 1.0305877923965454\n",
      "Epoch 251 / 500 | iteration 10 / 30 | Total Loss: 3.4864859580993652 | KNN Loss: 2.4889633655548096 | BCE Loss: 0.9975227117538452\n",
      "Epoch 251 / 500 | iteration 15 / 30 | Total Loss: 3.4744958877563477 | KNN Loss: 2.477149248123169 | BCE Loss: 0.9973467588424683\n",
      "Epoch 251 / 500 | iteration 20 / 30 | Total Loss: 3.515005111694336 | KNN Loss: 2.4982595443725586 | BCE Loss: 1.0167455673217773\n",
      "Epoch 251 / 500 | iteration 25 / 30 | Total Loss: 3.4510583877563477 | KNN Loss: 2.47713565826416 | BCE Loss: 0.9739227294921875\n",
      "Epoch 252 / 500 | iteration 0 / 30 | Total Loss: 3.4458484649658203 | KNN Loss: 2.426588535308838 | BCE Loss: 1.0192598104476929\n",
      "Epoch 252 / 500 | iteration 5 / 30 | Total Loss: 3.436246633529663 | KNN Loss: 2.428971290588379 | BCE Loss: 1.0072753429412842\n",
      "Epoch 252 / 500 | iteration 10 / 30 | Total Loss: 3.482936382293701 | KNN Loss: 2.480217933654785 | BCE Loss: 1.002718448638916\n",
      "Epoch 252 / 500 | iteration 15 / 30 | Total Loss: 3.4618372917175293 | KNN Loss: 2.4531805515289307 | BCE Loss: 1.0086567401885986\n",
      "Epoch 252 / 500 | iteration 20 / 30 | Total Loss: 3.486032009124756 | KNN Loss: 2.4563441276550293 | BCE Loss: 1.029687762260437\n",
      "Epoch 252 / 500 | iteration 25 / 30 | Total Loss: 3.4403164386749268 | KNN Loss: 2.437717914581299 | BCE Loss: 1.002598524093628\n",
      "Epoch 253 / 500 | iteration 0 / 30 | Total Loss: 3.469266891479492 | KNN Loss: 2.449069023132324 | BCE Loss: 1.020197868347168\n",
      "Epoch 253 / 500 | iteration 5 / 30 | Total Loss: 3.5308985710144043 | KNN Loss: 2.497627019882202 | BCE Loss: 1.0332715511322021\n",
      "Epoch 253 / 500 | iteration 10 / 30 | Total Loss: 3.4706482887268066 | KNN Loss: 2.446460008621216 | BCE Loss: 1.0241882801055908\n",
      "Epoch 253 / 500 | iteration 15 / 30 | Total Loss: 3.4612064361572266 | KNN Loss: 2.444185256958008 | BCE Loss: 1.0170211791992188\n",
      "Epoch 253 / 500 | iteration 20 / 30 | Total Loss: 3.475037097930908 | KNN Loss: 2.4414846897125244 | BCE Loss: 1.0335524082183838\n",
      "Epoch 253 / 500 | iteration 25 / 30 | Total Loss: 3.44307017326355 | KNN Loss: 2.453122138977051 | BCE Loss: 0.989948034286499\n",
      "Epoch 254 / 500 | iteration 0 / 30 | Total Loss: 3.503098249435425 | KNN Loss: 2.469756603240967 | BCE Loss: 1.033341646194458\n",
      "Epoch 254 / 500 | iteration 5 / 30 | Total Loss: 3.486362934112549 | KNN Loss: 2.466817617416382 | BCE Loss: 1.0195451974868774\n",
      "Epoch 254 / 500 | iteration 10 / 30 | Total Loss: 3.4944024085998535 | KNN Loss: 2.4486732482910156 | BCE Loss: 1.0457292795181274\n",
      "Epoch 254 / 500 | iteration 15 / 30 | Total Loss: 3.4527130126953125 | KNN Loss: 2.425119638442993 | BCE Loss: 1.0275934934616089\n",
      "Epoch 254 / 500 | iteration 20 / 30 | Total Loss: 3.485973358154297 | KNN Loss: 2.4833011627197266 | BCE Loss: 1.0026721954345703\n",
      "Epoch 254 / 500 | iteration 25 / 30 | Total Loss: 3.453578472137451 | KNN Loss: 2.4394097328186035 | BCE Loss: 1.0141687393188477\n",
      "Epoch 255 / 500 | iteration 0 / 30 | Total Loss: 3.4238712787628174 | KNN Loss: 2.434382438659668 | BCE Loss: 0.9894888401031494\n",
      "Epoch 255 / 500 | iteration 5 / 30 | Total Loss: 3.4514293670654297 | KNN Loss: 2.4401073455810547 | BCE Loss: 1.011322021484375\n",
      "Epoch 255 / 500 | iteration 10 / 30 | Total Loss: 3.5081608295440674 | KNN Loss: 2.4900918006896973 | BCE Loss: 1.0180690288543701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255 / 500 | iteration 15 / 30 | Total Loss: 3.500812530517578 | KNN Loss: 2.4851438999176025 | BCE Loss: 1.015668511390686\n",
      "Epoch 255 / 500 | iteration 20 / 30 | Total Loss: 3.4908697605133057 | KNN Loss: 2.4316227436065674 | BCE Loss: 1.0592470169067383\n",
      "Epoch 255 / 500 | iteration 25 / 30 | Total Loss: 3.5236706733703613 | KNN Loss: 2.494957447052002 | BCE Loss: 1.028713345527649\n",
      "Epoch 256 / 500 | iteration 0 / 30 | Total Loss: 3.4648239612579346 | KNN Loss: 2.446715831756592 | BCE Loss: 1.0181081295013428\n",
      "Epoch 256 / 500 | iteration 5 / 30 | Total Loss: 3.4858226776123047 | KNN Loss: 2.46500825881958 | BCE Loss: 1.0208144187927246\n",
      "Epoch 256 / 500 | iteration 10 / 30 | Total Loss: 3.4975953102111816 | KNN Loss: 2.4745688438415527 | BCE Loss: 1.023026466369629\n",
      "Epoch 256 / 500 | iteration 15 / 30 | Total Loss: 3.493410110473633 | KNN Loss: 2.4550998210906982 | BCE Loss: 1.0383102893829346\n",
      "Epoch 256 / 500 | iteration 20 / 30 | Total Loss: 3.4657177925109863 | KNN Loss: 2.457394599914551 | BCE Loss: 1.008323311805725\n",
      "Epoch 256 / 500 | iteration 25 / 30 | Total Loss: 3.4681336879730225 | KNN Loss: 2.4180264472961426 | BCE Loss: 1.0501072406768799\n",
      "Epoch 257 / 500 | iteration 0 / 30 | Total Loss: 3.4505748748779297 | KNN Loss: 2.4344396591186523 | BCE Loss: 1.0161352157592773\n",
      "Epoch 257 / 500 | iteration 5 / 30 | Total Loss: 3.4438014030456543 | KNN Loss: 2.438605785369873 | BCE Loss: 1.0051957368850708\n",
      "Epoch 257 / 500 | iteration 10 / 30 | Total Loss: 3.4712886810302734 | KNN Loss: 2.4474868774414062 | BCE Loss: 1.0238018035888672\n",
      "Epoch 257 / 500 | iteration 15 / 30 | Total Loss: 3.474999189376831 | KNN Loss: 2.4459757804870605 | BCE Loss: 1.0290234088897705\n",
      "Epoch 257 / 500 | iteration 20 / 30 | Total Loss: 3.4699010848999023 | KNN Loss: 2.4524757862091064 | BCE Loss: 1.017425298690796\n",
      "Epoch 257 / 500 | iteration 25 / 30 | Total Loss: 3.470427989959717 | KNN Loss: 2.4413058757781982 | BCE Loss: 1.029122233390808\n",
      "Epoch 258 / 500 | iteration 0 / 30 | Total Loss: 3.484147071838379 | KNN Loss: 2.4485228061676025 | BCE Loss: 1.0356241464614868\n",
      "Epoch 258 / 500 | iteration 5 / 30 | Total Loss: 3.4900102615356445 | KNN Loss: 2.5001883506774902 | BCE Loss: 0.9898218512535095\n",
      "Epoch 258 / 500 | iteration 10 / 30 | Total Loss: 3.455824851989746 | KNN Loss: 2.4264791011810303 | BCE Loss: 1.0293458700180054\n",
      "Epoch 258 / 500 | iteration 15 / 30 | Total Loss: 3.4832262992858887 | KNN Loss: 2.4793989658355713 | BCE Loss: 1.0038273334503174\n",
      "Epoch 258 / 500 | iteration 20 / 30 | Total Loss: 3.420397996902466 | KNN Loss: 2.4318180084228516 | BCE Loss: 0.9885799884796143\n",
      "Epoch 258 / 500 | iteration 25 / 30 | Total Loss: 3.45548677444458 | KNN Loss: 2.4420487880706787 | BCE Loss: 1.0134379863739014\n",
      "Epoch 259 / 500 | iteration 0 / 30 | Total Loss: 3.4656543731689453 | KNN Loss: 2.4424357414245605 | BCE Loss: 1.0232186317443848\n",
      "Epoch 259 / 500 | iteration 5 / 30 | Total Loss: 3.465643882751465 | KNN Loss: 2.4673962593078613 | BCE Loss: 0.9982476830482483\n",
      "Epoch 259 / 500 | iteration 10 / 30 | Total Loss: 3.486865520477295 | KNN Loss: 2.4658329486846924 | BCE Loss: 1.0210325717926025\n",
      "Epoch 259 / 500 | iteration 15 / 30 | Total Loss: 3.4759318828582764 | KNN Loss: 2.4623491764068604 | BCE Loss: 1.013582706451416\n",
      "Epoch 259 / 500 | iteration 20 / 30 | Total Loss: 3.457656145095825 | KNN Loss: 2.4408440589904785 | BCE Loss: 1.0168120861053467\n",
      "Epoch 259 / 500 | iteration 25 / 30 | Total Loss: 3.4319958686828613 | KNN Loss: 2.458796977996826 | BCE Loss: 0.9731988906860352\n",
      "Epoch 260 / 500 | iteration 0 / 30 | Total Loss: 3.4762673377990723 | KNN Loss: 2.4446041584014893 | BCE Loss: 1.0316632986068726\n",
      "Epoch 260 / 500 | iteration 5 / 30 | Total Loss: 3.448484182357788 | KNN Loss: 2.447690963745117 | BCE Loss: 1.000793218612671\n",
      "Epoch 260 / 500 | iteration 10 / 30 | Total Loss: 3.4645092487335205 | KNN Loss: 2.454828977584839 | BCE Loss: 1.0096802711486816\n",
      "Epoch 260 / 500 | iteration 15 / 30 | Total Loss: 3.4924190044403076 | KNN Loss: 2.4859538078308105 | BCE Loss: 1.006465196609497\n",
      "Epoch 260 / 500 | iteration 20 / 30 | Total Loss: 3.453742504119873 | KNN Loss: 2.423506259918213 | BCE Loss: 1.0302361249923706\n",
      "Epoch 260 / 500 | iteration 25 / 30 | Total Loss: 3.474834680557251 | KNN Loss: 2.444237470626831 | BCE Loss: 1.03059720993042\n",
      "Epoch 261 / 500 | iteration 0 / 30 | Total Loss: 3.4349446296691895 | KNN Loss: 2.4494757652282715 | BCE Loss: 0.9854689836502075\n",
      "Epoch 261 / 500 | iteration 5 / 30 | Total Loss: 3.446577787399292 | KNN Loss: 2.4490983486175537 | BCE Loss: 0.9974793791770935\n",
      "Epoch 261 / 500 | iteration 10 / 30 | Total Loss: 3.503420114517212 | KNN Loss: 2.4759533405303955 | BCE Loss: 1.0274667739868164\n",
      "Epoch 261 / 500 | iteration 15 / 30 | Total Loss: 3.4649806022644043 | KNN Loss: 2.4317541122436523 | BCE Loss: 1.0332266092300415\n",
      "Epoch 261 / 500 | iteration 20 / 30 | Total Loss: 3.443147897720337 | KNN Loss: 2.448319911956787 | BCE Loss: 0.994827926158905\n",
      "Epoch 261 / 500 | iteration 25 / 30 | Total Loss: 3.4389290809631348 | KNN Loss: 2.4414420127868652 | BCE Loss: 0.9974870085716248\n",
      "Epoch 262 / 500 | iteration 0 / 30 | Total Loss: 3.465787649154663 | KNN Loss: 2.446202278137207 | BCE Loss: 1.019585371017456\n",
      "Epoch 262 / 500 | iteration 5 / 30 | Total Loss: 3.466686248779297 | KNN Loss: 2.440676212310791 | BCE Loss: 1.0260100364685059\n",
      "Epoch 262 / 500 | iteration 10 / 30 | Total Loss: 3.491044759750366 | KNN Loss: 2.460728645324707 | BCE Loss: 1.0303161144256592\n",
      "Epoch 262 / 500 | iteration 15 / 30 | Total Loss: 3.470721960067749 | KNN Loss: 2.43113374710083 | BCE Loss: 1.039588212966919\n",
      "Epoch 262 / 500 | iteration 20 / 30 | Total Loss: 3.503666400909424 | KNN Loss: 2.4710490703582764 | BCE Loss: 1.0326173305511475\n",
      "Epoch 262 / 500 | iteration 25 / 30 | Total Loss: 3.4442458152770996 | KNN Loss: 2.455064296722412 | BCE Loss: 0.9891815185546875\n",
      "Epoch 263 / 500 | iteration 0 / 30 | Total Loss: 3.4469361305236816 | KNN Loss: 2.429525375366211 | BCE Loss: 1.0174108743667603\n",
      "Epoch 263 / 500 | iteration 5 / 30 | Total Loss: 3.4545154571533203 | KNN Loss: 2.4433233737945557 | BCE Loss: 1.0111920833587646\n",
      "Epoch 263 / 500 | iteration 10 / 30 | Total Loss: 3.5210678577423096 | KNN Loss: 2.4675915241241455 | BCE Loss: 1.053476333618164\n",
      "Epoch 263 / 500 | iteration 15 / 30 | Total Loss: 3.4825427532196045 | KNN Loss: 2.498133897781372 | BCE Loss: 0.9844089150428772\n",
      "Epoch 263 / 500 | iteration 20 / 30 | Total Loss: 3.4633452892303467 | KNN Loss: 2.445025682449341 | BCE Loss: 1.0183196067810059\n",
      "Epoch 263 / 500 | iteration 25 / 30 | Total Loss: 3.459789276123047 | KNN Loss: 2.4466798305511475 | BCE Loss: 1.013109564781189\n",
      "Epoch 264 / 500 | iteration 0 / 30 | Total Loss: 3.461822509765625 | KNN Loss: 2.444582462310791 | BCE Loss: 1.017240047454834\n",
      "Epoch 264 / 500 | iteration 5 / 30 | Total Loss: 3.484442710876465 | KNN Loss: 2.488929033279419 | BCE Loss: 0.9955137372016907\n",
      "Epoch 264 / 500 | iteration 10 / 30 | Total Loss: 3.493425130844116 | KNN Loss: 2.466505289077759 | BCE Loss: 1.0269198417663574\n",
      "Epoch 264 / 500 | iteration 15 / 30 | Total Loss: 3.4604110717773438 | KNN Loss: 2.433786630630493 | BCE Loss: 1.0266244411468506\n",
      "Epoch 264 / 500 | iteration 20 / 30 | Total Loss: 3.4686200618743896 | KNN Loss: 2.4687933921813965 | BCE Loss: 0.9998266696929932\n",
      "Epoch 264 / 500 | iteration 25 / 30 | Total Loss: 3.44628643989563 | KNN Loss: 2.4384703636169434 | BCE Loss: 1.0078160762786865\n",
      "Epoch 265 / 500 | iteration 0 / 30 | Total Loss: 3.4554924964904785 | KNN Loss: 2.4532625675201416 | BCE Loss: 1.002229928970337\n",
      "Epoch 265 / 500 | iteration 5 / 30 | Total Loss: 3.458298683166504 | KNN Loss: 2.4564223289489746 | BCE Loss: 1.0018763542175293\n",
      "Epoch 265 / 500 | iteration 10 / 30 | Total Loss: 3.439152479171753 | KNN Loss: 2.439013719558716 | BCE Loss: 1.000138759613037\n",
      "Epoch 265 / 500 | iteration 15 / 30 | Total Loss: 3.4345834255218506 | KNN Loss: 2.4336650371551514 | BCE Loss: 1.0009183883666992\n",
      "Epoch 265 / 500 | iteration 20 / 30 | Total Loss: 3.4814743995666504 | KNN Loss: 2.4656126499176025 | BCE Loss: 1.0158616304397583\n",
      "Epoch 265 / 500 | iteration 25 / 30 | Total Loss: 3.4755518436431885 | KNN Loss: 2.4446473121643066 | BCE Loss: 1.0309045314788818\n",
      "Epoch 266 / 500 | iteration 0 / 30 | Total Loss: 3.4745540618896484 | KNN Loss: 2.4586212635040283 | BCE Loss: 1.0159327983856201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266 / 500 | iteration 5 / 30 | Total Loss: 3.4793930053710938 | KNN Loss: 2.4455349445343018 | BCE Loss: 1.0338579416275024\n",
      "Epoch 266 / 500 | iteration 10 / 30 | Total Loss: 3.494457960128784 | KNN Loss: 2.453348159790039 | BCE Loss: 1.0411098003387451\n",
      "Epoch 266 / 500 | iteration 15 / 30 | Total Loss: 3.4696717262268066 | KNN Loss: 2.4808340072631836 | BCE Loss: 0.9888378381729126\n",
      "Epoch 266 / 500 | iteration 20 / 30 | Total Loss: 3.4969067573547363 | KNN Loss: 2.4618964195251465 | BCE Loss: 1.0350102186203003\n",
      "Epoch 266 / 500 | iteration 25 / 30 | Total Loss: 3.4299352169036865 | KNN Loss: 2.4306607246398926 | BCE Loss: 0.9992745518684387\n",
      "Epoch 267 / 500 | iteration 0 / 30 | Total Loss: 3.444842576980591 | KNN Loss: 2.4461121559143066 | BCE Loss: 0.9987304210662842\n",
      "Epoch 267 / 500 | iteration 5 / 30 | Total Loss: 3.45875883102417 | KNN Loss: 2.4498467445373535 | BCE Loss: 1.0089120864868164\n",
      "Epoch 267 / 500 | iteration 10 / 30 | Total Loss: 3.4739418029785156 | KNN Loss: 2.4450488090515137 | BCE Loss: 1.028892993927002\n",
      "Epoch 267 / 500 | iteration 15 / 30 | Total Loss: 3.4590814113616943 | KNN Loss: 2.459939956665039 | BCE Loss: 0.9991414546966553\n",
      "Epoch 267 / 500 | iteration 20 / 30 | Total Loss: 3.4242477416992188 | KNN Loss: 2.4371681213378906 | BCE Loss: 0.9870795011520386\n",
      "Epoch 267 / 500 | iteration 25 / 30 | Total Loss: 3.502014636993408 | KNN Loss: 2.4896421432495117 | BCE Loss: 1.012372374534607\n",
      "Epoch 268 / 500 | iteration 0 / 30 | Total Loss: 3.4920597076416016 | KNN Loss: 2.48988676071167 | BCE Loss: 1.0021729469299316\n",
      "Epoch 268 / 500 | iteration 5 / 30 | Total Loss: 3.453376531600952 | KNN Loss: 2.4389445781707764 | BCE Loss: 1.0144319534301758\n",
      "Epoch 268 / 500 | iteration 10 / 30 | Total Loss: 3.4937238693237305 | KNN Loss: 2.4801223278045654 | BCE Loss: 1.0136016607284546\n",
      "Epoch 268 / 500 | iteration 15 / 30 | Total Loss: 3.473111867904663 | KNN Loss: 2.4539692401885986 | BCE Loss: 1.0191426277160645\n",
      "Epoch 268 / 500 | iteration 20 / 30 | Total Loss: 3.5065083503723145 | KNN Loss: 2.4773240089416504 | BCE Loss: 1.029184341430664\n",
      "Epoch 268 / 500 | iteration 25 / 30 | Total Loss: 3.4521875381469727 | KNN Loss: 2.439347982406616 | BCE Loss: 1.012839674949646\n",
      "Epoch 269 / 500 | iteration 0 / 30 | Total Loss: 3.470287799835205 | KNN Loss: 2.4524643421173096 | BCE Loss: 1.0178234577178955\n",
      "Epoch 269 / 500 | iteration 5 / 30 | Total Loss: 3.4750301837921143 | KNN Loss: 2.4780473709106445 | BCE Loss: 0.996982753276825\n",
      "Epoch 269 / 500 | iteration 10 / 30 | Total Loss: 3.471311569213867 | KNN Loss: 2.4485244750976562 | BCE Loss: 1.0227872133255005\n",
      "Epoch 269 / 500 | iteration 15 / 30 | Total Loss: 3.4710474014282227 | KNN Loss: 2.4522464275360107 | BCE Loss: 1.018800973892212\n",
      "Epoch 269 / 500 | iteration 20 / 30 | Total Loss: 3.4781792163848877 | KNN Loss: 2.4690916538238525 | BCE Loss: 1.0090875625610352\n",
      "Epoch 269 / 500 | iteration 25 / 30 | Total Loss: 3.519062042236328 | KNN Loss: 2.4626224040985107 | BCE Loss: 1.0564396381378174\n",
      "Epoch 270 / 500 | iteration 0 / 30 | Total Loss: 3.4873242378234863 | KNN Loss: 2.4510791301727295 | BCE Loss: 1.0362452268600464\n",
      "Epoch 270 / 500 | iteration 5 / 30 | Total Loss: 3.4641849994659424 | KNN Loss: 2.434101104736328 | BCE Loss: 1.0300838947296143\n",
      "Epoch 270 / 500 | iteration 10 / 30 | Total Loss: 3.484498977661133 | KNN Loss: 2.4537088871002197 | BCE Loss: 1.030790090560913\n",
      "Epoch 270 / 500 | iteration 15 / 30 | Total Loss: 3.4859113693237305 | KNN Loss: 2.4563024044036865 | BCE Loss: 1.0296090841293335\n",
      "Epoch 270 / 500 | iteration 20 / 30 | Total Loss: 3.507814645767212 | KNN Loss: 2.4869189262390137 | BCE Loss: 1.0208957195281982\n",
      "Epoch 270 / 500 | iteration 25 / 30 | Total Loss: 3.480736494064331 | KNN Loss: 2.455965280532837 | BCE Loss: 1.0247712135314941\n",
      "Epoch 271 / 500 | iteration 0 / 30 | Total Loss: 3.436424493789673 | KNN Loss: 2.4344406127929688 | BCE Loss: 1.001983880996704\n",
      "Epoch 271 / 500 | iteration 5 / 30 | Total Loss: 3.4727916717529297 | KNN Loss: 2.456864356994629 | BCE Loss: 1.0159271955490112\n",
      "Epoch 271 / 500 | iteration 10 / 30 | Total Loss: 3.4696779251098633 | KNN Loss: 2.4690191745758057 | BCE Loss: 1.0006588697433472\n",
      "Epoch 271 / 500 | iteration 15 / 30 | Total Loss: 3.4050698280334473 | KNN Loss: 2.4114041328430176 | BCE Loss: 0.9936656355857849\n",
      "Epoch 271 / 500 | iteration 20 / 30 | Total Loss: 3.472161054611206 | KNN Loss: 2.4744961261749268 | BCE Loss: 0.9976649880409241\n",
      "Epoch 271 / 500 | iteration 25 / 30 | Total Loss: 3.503384828567505 | KNN Loss: 2.455179452896118 | BCE Loss: 1.0482053756713867\n",
      "Epoch 272 / 500 | iteration 0 / 30 | Total Loss: 3.495394706726074 | KNN Loss: 2.4737815856933594 | BCE Loss: 1.0216131210327148\n",
      "Epoch 272 / 500 | iteration 5 / 30 | Total Loss: 3.430431365966797 | KNN Loss: 2.4158313274383545 | BCE Loss: 1.0145999193191528\n",
      "Epoch 272 / 500 | iteration 10 / 30 | Total Loss: 3.4356493949890137 | KNN Loss: 2.4353489875793457 | BCE Loss: 1.000300407409668\n",
      "Epoch 272 / 500 | iteration 15 / 30 | Total Loss: 3.4456777572631836 | KNN Loss: 2.426025390625 | BCE Loss: 1.0196524858474731\n",
      "Epoch 272 / 500 | iteration 20 / 30 | Total Loss: 3.456977367401123 | KNN Loss: 2.4602513313293457 | BCE Loss: 0.9967259168624878\n",
      "Epoch 272 / 500 | iteration 25 / 30 | Total Loss: 3.4775967597961426 | KNN Loss: 2.4501237869262695 | BCE Loss: 1.027472972869873\n",
      "Epoch 273 / 500 | iteration 0 / 30 | Total Loss: 3.466796398162842 | KNN Loss: 2.4591522216796875 | BCE Loss: 1.0076440572738647\n",
      "Epoch 273 / 500 | iteration 5 / 30 | Total Loss: 3.4664223194122314 | KNN Loss: 2.4628477096557617 | BCE Loss: 1.0035746097564697\n",
      "Epoch 273 / 500 | iteration 10 / 30 | Total Loss: 3.4513449668884277 | KNN Loss: 2.46366810798645 | BCE Loss: 0.987676739692688\n",
      "Epoch 273 / 500 | iteration 15 / 30 | Total Loss: 3.464611053466797 | KNN Loss: 2.452402353286743 | BCE Loss: 1.0122085809707642\n",
      "Epoch 273 / 500 | iteration 20 / 30 | Total Loss: 3.464954376220703 | KNN Loss: 2.4492170810699463 | BCE Loss: 1.0157371759414673\n",
      "Epoch 273 / 500 | iteration 25 / 30 | Total Loss: 3.469680070877075 | KNN Loss: 2.4585459232330322 | BCE Loss: 1.011134147644043\n",
      "Epoch 274 / 500 | iteration 0 / 30 | Total Loss: 3.456509828567505 | KNN Loss: 2.4354312419891357 | BCE Loss: 1.0210785865783691\n",
      "Epoch 274 / 500 | iteration 5 / 30 | Total Loss: 3.455942153930664 | KNN Loss: 2.436044931411743 | BCE Loss: 1.019897222518921\n",
      "Epoch 274 / 500 | iteration 10 / 30 | Total Loss: 3.5030481815338135 | KNN Loss: 2.459914207458496 | BCE Loss: 1.0431339740753174\n",
      "Epoch 274 / 500 | iteration 15 / 30 | Total Loss: 3.4383583068847656 | KNN Loss: 2.4269306659698486 | BCE Loss: 1.011427640914917\n",
      "Epoch 274 / 500 | iteration 20 / 30 | Total Loss: 3.4296021461486816 | KNN Loss: 2.4353082180023193 | BCE Loss: 0.9942938089370728\n",
      "Epoch 274 / 500 | iteration 25 / 30 | Total Loss: 3.5150697231292725 | KNN Loss: 2.4912729263305664 | BCE Loss: 1.023796796798706\n",
      "Epoch 275 / 500 | iteration 0 / 30 | Total Loss: 3.471008539199829 | KNN Loss: 2.4453349113464355 | BCE Loss: 1.0256736278533936\n",
      "Epoch 275 / 500 | iteration 5 / 30 | Total Loss: 3.4728636741638184 | KNN Loss: 2.454080820083618 | BCE Loss: 1.0187827348709106\n",
      "Epoch 275 / 500 | iteration 10 / 30 | Total Loss: 3.474158525466919 | KNN Loss: 2.4691827297210693 | BCE Loss: 1.0049757957458496\n",
      "Epoch 275 / 500 | iteration 15 / 30 | Total Loss: 3.4644761085510254 | KNN Loss: 2.4649925231933594 | BCE Loss: 0.9994834661483765\n",
      "Epoch 275 / 500 | iteration 20 / 30 | Total Loss: 3.4563300609588623 | KNN Loss: 2.436769723892212 | BCE Loss: 1.0195603370666504\n",
      "Epoch 275 / 500 | iteration 25 / 30 | Total Loss: 3.4887337684631348 | KNN Loss: 2.459320306777954 | BCE Loss: 1.0294134616851807\n",
      "Epoch 276 / 500 | iteration 0 / 30 | Total Loss: 3.468231201171875 | KNN Loss: 2.4574882984161377 | BCE Loss: 1.0107427835464478\n",
      "Epoch 276 / 500 | iteration 5 / 30 | Total Loss: 3.4430999755859375 | KNN Loss: 2.4332029819488525 | BCE Loss: 1.009896993637085\n",
      "Epoch 276 / 500 | iteration 10 / 30 | Total Loss: 3.4556002616882324 | KNN Loss: 2.443453073501587 | BCE Loss: 1.012147307395935\n",
      "Epoch 276 / 500 | iteration 15 / 30 | Total Loss: 3.4884095191955566 | KNN Loss: 2.476641893386841 | BCE Loss: 1.0117676258087158\n",
      "Epoch 276 / 500 | iteration 20 / 30 | Total Loss: 3.5003790855407715 | KNN Loss: 2.4431746006011963 | BCE Loss: 1.0572043657302856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 / 500 | iteration 25 / 30 | Total Loss: 3.4779164791107178 | KNN Loss: 2.4540045261383057 | BCE Loss: 1.023911952972412\n",
      "Epoch 277 / 500 | iteration 0 / 30 | Total Loss: 3.432441473007202 | KNN Loss: 2.4330930709838867 | BCE Loss: 0.9993483424186707\n",
      "Epoch 277 / 500 | iteration 5 / 30 | Total Loss: 3.4827635288238525 | KNN Loss: 2.4495465755462646 | BCE Loss: 1.033216953277588\n",
      "Epoch 277 / 500 | iteration 10 / 30 | Total Loss: 3.4427547454833984 | KNN Loss: 2.4392154216766357 | BCE Loss: 1.0035394430160522\n",
      "Epoch 277 / 500 | iteration 15 / 30 | Total Loss: 3.4746475219726562 | KNN Loss: 2.4598522186279297 | BCE Loss: 1.014795184135437\n",
      "Epoch 277 / 500 | iteration 20 / 30 | Total Loss: 3.4226436614990234 | KNN Loss: 2.4271819591522217 | BCE Loss: 0.9954617023468018\n",
      "Epoch 277 / 500 | iteration 25 / 30 | Total Loss: 3.4650306701660156 | KNN Loss: 2.4415688514709473 | BCE Loss: 1.0234618186950684\n",
      "Epoch 278 / 500 | iteration 0 / 30 | Total Loss: 3.4120399951934814 | KNN Loss: 2.412889242172241 | BCE Loss: 0.9991507530212402\n",
      "Epoch 278 / 500 | iteration 5 / 30 | Total Loss: 3.4484682083129883 | KNN Loss: 2.435905694961548 | BCE Loss: 1.01256263256073\n",
      "Epoch 278 / 500 | iteration 10 / 30 | Total Loss: 3.4528346061706543 | KNN Loss: 2.4392902851104736 | BCE Loss: 1.0135442018508911\n",
      "Epoch 278 / 500 | iteration 15 / 30 | Total Loss: 3.4371724128723145 | KNN Loss: 2.4139087200164795 | BCE Loss: 1.023263692855835\n",
      "Epoch 278 / 500 | iteration 20 / 30 | Total Loss: 3.4533116817474365 | KNN Loss: 2.443718671798706 | BCE Loss: 1.0095930099487305\n",
      "Epoch 278 / 500 | iteration 25 / 30 | Total Loss: 3.4936914443969727 | KNN Loss: 2.4453060626983643 | BCE Loss: 1.0483853816986084\n",
      "Epoch 279 / 500 | iteration 0 / 30 | Total Loss: 3.4444408416748047 | KNN Loss: 2.442244291305542 | BCE Loss: 1.0021964311599731\n",
      "Epoch 279 / 500 | iteration 5 / 30 | Total Loss: 3.434749126434326 | KNN Loss: 2.440410852432251 | BCE Loss: 0.9943381547927856\n",
      "Epoch 279 / 500 | iteration 10 / 30 | Total Loss: 3.4844882488250732 | KNN Loss: 2.4549460411071777 | BCE Loss: 1.0295422077178955\n",
      "Epoch 279 / 500 | iteration 15 / 30 | Total Loss: 3.4799022674560547 | KNN Loss: 2.458134412765503 | BCE Loss: 1.0217677354812622\n",
      "Epoch 279 / 500 | iteration 20 / 30 | Total Loss: 3.499539375305176 | KNN Loss: 2.454724073410034 | BCE Loss: 1.044815182685852\n",
      "Epoch 279 / 500 | iteration 25 / 30 | Total Loss: 3.4969024658203125 | KNN Loss: 2.451000452041626 | BCE Loss: 1.045901894569397\n",
      "Epoch 280 / 500 | iteration 0 / 30 | Total Loss: 3.44692325592041 | KNN Loss: 2.4558510780334473 | BCE Loss: 0.9910720586776733\n",
      "Epoch 280 / 500 | iteration 5 / 30 | Total Loss: 3.4773387908935547 | KNN Loss: 2.464913845062256 | BCE Loss: 1.0124249458312988\n",
      "Epoch 280 / 500 | iteration 10 / 30 | Total Loss: 3.4750547409057617 | KNN Loss: 2.449369192123413 | BCE Loss: 1.025685429573059\n",
      "Epoch 280 / 500 | iteration 15 / 30 | Total Loss: 3.479750156402588 | KNN Loss: 2.453730583190918 | BCE Loss: 1.02601957321167\n",
      "Epoch 280 / 500 | iteration 20 / 30 | Total Loss: 3.5147922039031982 | KNN Loss: 2.455514907836914 | BCE Loss: 1.0592772960662842\n",
      "Epoch 280 / 500 | iteration 25 / 30 | Total Loss: 3.4776058197021484 | KNN Loss: 2.4398200511932373 | BCE Loss: 1.0377857685089111\n",
      "Epoch   281: reducing learning rate of group 0 to 4.1177e-04.\n",
      "Epoch 281 / 500 | iteration 0 / 30 | Total Loss: 3.4794046878814697 | KNN Loss: 2.461620330810547 | BCE Loss: 1.0177843570709229\n",
      "Epoch 281 / 500 | iteration 5 / 30 | Total Loss: 3.4343819618225098 | KNN Loss: 2.432225465774536 | BCE Loss: 1.0021566152572632\n",
      "Epoch 281 / 500 | iteration 10 / 30 | Total Loss: 3.4239768981933594 | KNN Loss: 2.431349754333496 | BCE Loss: 0.9926271438598633\n",
      "Epoch 281 / 500 | iteration 15 / 30 | Total Loss: 3.523484230041504 | KNN Loss: 2.4979934692382812 | BCE Loss: 1.0254908800125122\n",
      "Epoch 281 / 500 | iteration 20 / 30 | Total Loss: 3.500004768371582 | KNN Loss: 2.4728689193725586 | BCE Loss: 1.0271357297897339\n",
      "Epoch 281 / 500 | iteration 25 / 30 | Total Loss: 3.5278587341308594 | KNN Loss: 2.5075411796569824 | BCE Loss: 1.0203176736831665\n",
      "Epoch 282 / 500 | iteration 0 / 30 | Total Loss: 3.4418416023254395 | KNN Loss: 2.4369945526123047 | BCE Loss: 1.0048469305038452\n",
      "Epoch 282 / 500 | iteration 5 / 30 | Total Loss: 3.4528539180755615 | KNN Loss: 2.458163022994995 | BCE Loss: 0.9946908950805664\n",
      "Epoch 282 / 500 | iteration 10 / 30 | Total Loss: 3.484865188598633 | KNN Loss: 2.470423936843872 | BCE Loss: 1.0144413709640503\n",
      "Epoch 282 / 500 | iteration 15 / 30 | Total Loss: 3.493041515350342 | KNN Loss: 2.4892678260803223 | BCE Loss: 1.0037736892700195\n",
      "Epoch 282 / 500 | iteration 20 / 30 | Total Loss: 3.4353623390197754 | KNN Loss: 2.4036130905151367 | BCE Loss: 1.0317492485046387\n",
      "Epoch 282 / 500 | iteration 25 / 30 | Total Loss: 3.5053911209106445 | KNN Loss: 2.4740161895751953 | BCE Loss: 1.0313749313354492\n",
      "Epoch 283 / 500 | iteration 0 / 30 | Total Loss: 3.4838383197784424 | KNN Loss: 2.471921443939209 | BCE Loss: 1.0119168758392334\n",
      "Epoch 283 / 500 | iteration 5 / 30 | Total Loss: 3.438457489013672 | KNN Loss: 2.453599214553833 | BCE Loss: 0.9848582744598389\n",
      "Epoch 283 / 500 | iteration 10 / 30 | Total Loss: 3.4333081245422363 | KNN Loss: 2.4336373805999756 | BCE Loss: 0.9996708035469055\n",
      "Epoch 283 / 500 | iteration 15 / 30 | Total Loss: 3.4676194190979004 | KNN Loss: 2.4379873275756836 | BCE Loss: 1.0296320915222168\n",
      "Epoch 283 / 500 | iteration 20 / 30 | Total Loss: 3.43870210647583 | KNN Loss: 2.4283857345581055 | BCE Loss: 1.0103163719177246\n",
      "Epoch 283 / 500 | iteration 25 / 30 | Total Loss: 3.4790172576904297 | KNN Loss: 2.4494788646698 | BCE Loss: 1.0295383930206299\n",
      "Epoch 284 / 500 | iteration 0 / 30 | Total Loss: 3.478503704071045 | KNN Loss: 2.450542449951172 | BCE Loss: 1.0279611349105835\n",
      "Epoch 284 / 500 | iteration 5 / 30 | Total Loss: 3.463341236114502 | KNN Loss: 2.4433999061584473 | BCE Loss: 1.0199413299560547\n",
      "Epoch 284 / 500 | iteration 10 / 30 | Total Loss: 3.4503676891326904 | KNN Loss: 2.4187822341918945 | BCE Loss: 1.031585454940796\n",
      "Epoch 284 / 500 | iteration 15 / 30 | Total Loss: 3.463688373565674 | KNN Loss: 2.4559075832366943 | BCE Loss: 1.007780909538269\n",
      "Epoch 284 / 500 | iteration 20 / 30 | Total Loss: 3.445356845855713 | KNN Loss: 2.447486639022827 | BCE Loss: 0.9978702068328857\n",
      "Epoch 284 / 500 | iteration 25 / 30 | Total Loss: 3.474867820739746 | KNN Loss: 2.4841272830963135 | BCE Loss: 0.9907404184341431\n",
      "Epoch 285 / 500 | iteration 0 / 30 | Total Loss: 3.444385290145874 | KNN Loss: 2.428910493850708 | BCE Loss: 1.015474796295166\n",
      "Epoch 285 / 500 | iteration 5 / 30 | Total Loss: 3.5033459663391113 | KNN Loss: 2.4715540409088135 | BCE Loss: 1.0317919254302979\n",
      "Epoch 285 / 500 | iteration 10 / 30 | Total Loss: 3.4688398838043213 | KNN Loss: 2.4423556327819824 | BCE Loss: 1.0264842510223389\n",
      "Epoch 285 / 500 | iteration 15 / 30 | Total Loss: 3.464928150177002 | KNN Loss: 2.418274164199829 | BCE Loss: 1.0466539859771729\n",
      "Epoch 285 / 500 | iteration 20 / 30 | Total Loss: 3.467860698699951 | KNN Loss: 2.471489191055298 | BCE Loss: 0.9963715076446533\n",
      "Epoch 285 / 500 | iteration 25 / 30 | Total Loss: 3.473597526550293 | KNN Loss: 2.4625561237335205 | BCE Loss: 1.011041522026062\n",
      "Epoch 286 / 500 | iteration 0 / 30 | Total Loss: 3.468320369720459 | KNN Loss: 2.4637773036956787 | BCE Loss: 1.0045431852340698\n",
      "Epoch 286 / 500 | iteration 5 / 30 | Total Loss: 3.491063117980957 | KNN Loss: 2.4553885459899902 | BCE Loss: 1.0356744527816772\n",
      "Epoch 286 / 500 | iteration 10 / 30 | Total Loss: 3.4718017578125 | KNN Loss: 2.4443109035491943 | BCE Loss: 1.0274909734725952\n",
      "Epoch 286 / 500 | iteration 15 / 30 | Total Loss: 3.433112621307373 | KNN Loss: 2.4325945377349854 | BCE Loss: 1.0005179643630981\n",
      "Epoch 286 / 500 | iteration 20 / 30 | Total Loss: 3.4568045139312744 | KNN Loss: 2.4530465602874756 | BCE Loss: 1.0037579536437988\n",
      "Epoch 286 / 500 | iteration 25 / 30 | Total Loss: 3.4510746002197266 | KNN Loss: 2.4429216384887695 | BCE Loss: 1.008152961730957\n",
      "Epoch 287 / 500 | iteration 0 / 30 | Total Loss: 3.45467472076416 | KNN Loss: 2.453822135925293 | BCE Loss: 1.0008525848388672\n",
      "Epoch 287 / 500 | iteration 5 / 30 | Total Loss: 3.4620814323425293 | KNN Loss: 2.4471707344055176 | BCE Loss: 1.0149108171463013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287 / 500 | iteration 10 / 30 | Total Loss: 3.484673500061035 | KNN Loss: 2.4439029693603516 | BCE Loss: 1.040770411491394\n",
      "Epoch 287 / 500 | iteration 15 / 30 | Total Loss: 3.453619956970215 | KNN Loss: 2.4371225833892822 | BCE Loss: 1.016497254371643\n",
      "Epoch 287 / 500 | iteration 20 / 30 | Total Loss: 3.4600253105163574 | KNN Loss: 2.4508986473083496 | BCE Loss: 1.0091267824172974\n",
      "Epoch 287 / 500 | iteration 25 / 30 | Total Loss: 3.474038600921631 | KNN Loss: 2.4546124935150146 | BCE Loss: 1.0194261074066162\n",
      "Epoch 288 / 500 | iteration 0 / 30 | Total Loss: 3.4919047355651855 | KNN Loss: 2.4647786617279053 | BCE Loss: 1.0271261930465698\n",
      "Epoch 288 / 500 | iteration 5 / 30 | Total Loss: 3.4771616458892822 | KNN Loss: 2.4328725337982178 | BCE Loss: 1.0442891120910645\n",
      "Epoch 288 / 500 | iteration 10 / 30 | Total Loss: 3.4543333053588867 | KNN Loss: 2.454338788986206 | BCE Loss: 0.9999945759773254\n",
      "Epoch 288 / 500 | iteration 15 / 30 | Total Loss: 3.460477113723755 | KNN Loss: 2.4376912117004395 | BCE Loss: 1.0227859020233154\n",
      "Epoch 288 / 500 | iteration 20 / 30 | Total Loss: 3.478818655014038 | KNN Loss: 2.4603841304779053 | BCE Loss: 1.0184345245361328\n",
      "Epoch 288 / 500 | iteration 25 / 30 | Total Loss: 3.4641470909118652 | KNN Loss: 2.438544988632202 | BCE Loss: 1.025602102279663\n",
      "Epoch 289 / 500 | iteration 0 / 30 | Total Loss: 3.504497528076172 | KNN Loss: 2.4628090858459473 | BCE Loss: 1.041688323020935\n",
      "Epoch 289 / 500 | iteration 5 / 30 | Total Loss: 3.4443345069885254 | KNN Loss: 2.4223742485046387 | BCE Loss: 1.0219603776931763\n",
      "Epoch 289 / 500 | iteration 10 / 30 | Total Loss: 3.4793426990509033 | KNN Loss: 2.4708099365234375 | BCE Loss: 1.0085327625274658\n",
      "Epoch 289 / 500 | iteration 15 / 30 | Total Loss: 3.4566054344177246 | KNN Loss: 2.4431440830230713 | BCE Loss: 1.0134613513946533\n",
      "Epoch 289 / 500 | iteration 20 / 30 | Total Loss: 3.46816349029541 | KNN Loss: 2.4368228912353516 | BCE Loss: 1.0313405990600586\n",
      "Epoch 289 / 500 | iteration 25 / 30 | Total Loss: 3.507890224456787 | KNN Loss: 2.4777750968933105 | BCE Loss: 1.0301151275634766\n",
      "Epoch 290 / 500 | iteration 0 / 30 | Total Loss: 3.4809041023254395 | KNN Loss: 2.4565796852111816 | BCE Loss: 1.0243244171142578\n",
      "Epoch 290 / 500 | iteration 5 / 30 | Total Loss: 3.4210684299468994 | KNN Loss: 2.4316256046295166 | BCE Loss: 0.9894428253173828\n",
      "Epoch 290 / 500 | iteration 10 / 30 | Total Loss: 3.46734619140625 | KNN Loss: 2.4651777744293213 | BCE Loss: 1.0021684169769287\n",
      "Epoch 290 / 500 | iteration 15 / 30 | Total Loss: 3.4795732498168945 | KNN Loss: 2.442793607711792 | BCE Loss: 1.0367796421051025\n",
      "Epoch 290 / 500 | iteration 20 / 30 | Total Loss: 3.4811062812805176 | KNN Loss: 2.4800589084625244 | BCE Loss: 1.0010472536087036\n",
      "Epoch 290 / 500 | iteration 25 / 30 | Total Loss: 3.4647305011749268 | KNN Loss: 2.4494783878326416 | BCE Loss: 1.0152521133422852\n",
      "Epoch 291 / 500 | iteration 0 / 30 | Total Loss: 3.482666492462158 | KNN Loss: 2.481245517730713 | BCE Loss: 1.0014209747314453\n",
      "Epoch 291 / 500 | iteration 5 / 30 | Total Loss: 3.4679195880889893 | KNN Loss: 2.463895559310913 | BCE Loss: 1.0040240287780762\n",
      "Epoch 291 / 500 | iteration 10 / 30 | Total Loss: 3.493168830871582 | KNN Loss: 2.4787895679473877 | BCE Loss: 1.0143792629241943\n",
      "Epoch 291 / 500 | iteration 15 / 30 | Total Loss: 3.4607176780700684 | KNN Loss: 2.4638166427612305 | BCE Loss: 0.9969010353088379\n",
      "Epoch 291 / 500 | iteration 20 / 30 | Total Loss: 3.4580588340759277 | KNN Loss: 2.445890188217163 | BCE Loss: 1.0121686458587646\n",
      "Epoch 291 / 500 | iteration 25 / 30 | Total Loss: 3.4426474571228027 | KNN Loss: 2.4276483058929443 | BCE Loss: 1.0149990320205688\n",
      "Epoch 292 / 500 | iteration 0 / 30 | Total Loss: 3.467381000518799 | KNN Loss: 2.4577689170837402 | BCE Loss: 1.009611964225769\n",
      "Epoch 292 / 500 | iteration 5 / 30 | Total Loss: 3.5141844749450684 | KNN Loss: 2.478816270828247 | BCE Loss: 1.0353680849075317\n",
      "Epoch 292 / 500 | iteration 10 / 30 | Total Loss: 3.442370653152466 | KNN Loss: 2.4339685440063477 | BCE Loss: 1.0084021091461182\n",
      "Epoch 292 / 500 | iteration 15 / 30 | Total Loss: 3.4666826725006104 | KNN Loss: 2.453042984008789 | BCE Loss: 1.0136396884918213\n",
      "Epoch 292 / 500 | iteration 20 / 30 | Total Loss: 3.504112482070923 | KNN Loss: 2.498561143875122 | BCE Loss: 1.0055513381958008\n",
      "Epoch 292 / 500 | iteration 25 / 30 | Total Loss: 3.4487345218658447 | KNN Loss: 2.4526047706604004 | BCE Loss: 0.9961296916007996\n",
      "Epoch 293 / 500 | iteration 0 / 30 | Total Loss: 3.508118152618408 | KNN Loss: 2.4838571548461914 | BCE Loss: 1.0242608785629272\n",
      "Epoch 293 / 500 | iteration 5 / 30 | Total Loss: 3.4247183799743652 | KNN Loss: 2.4265482425689697 | BCE Loss: 0.9981701374053955\n",
      "Epoch 293 / 500 | iteration 10 / 30 | Total Loss: 3.4625802040100098 | KNN Loss: 2.4645438194274902 | BCE Loss: 0.9980365037918091\n",
      "Epoch 293 / 500 | iteration 15 / 30 | Total Loss: 3.4207382202148438 | KNN Loss: 2.4212164878845215 | BCE Loss: 0.9995217323303223\n",
      "Epoch 293 / 500 | iteration 20 / 30 | Total Loss: 3.469562292098999 | KNN Loss: 2.4629883766174316 | BCE Loss: 1.0065739154815674\n",
      "Epoch 293 / 500 | iteration 25 / 30 | Total Loss: 3.474311590194702 | KNN Loss: 2.4630942344665527 | BCE Loss: 1.0112173557281494\n",
      "Epoch 294 / 500 | iteration 0 / 30 | Total Loss: 3.441422700881958 | KNN Loss: 2.4288885593414307 | BCE Loss: 1.0125341415405273\n",
      "Epoch 294 / 500 | iteration 5 / 30 | Total Loss: 3.465926170349121 | KNN Loss: 2.438154935836792 | BCE Loss: 1.027771234512329\n",
      "Epoch 294 / 500 | iteration 10 / 30 | Total Loss: 3.452439069747925 | KNN Loss: 2.4271137714385986 | BCE Loss: 1.0253252983093262\n",
      "Epoch 294 / 500 | iteration 15 / 30 | Total Loss: 3.4585037231445312 | KNN Loss: 2.442349910736084 | BCE Loss: 1.0161538124084473\n",
      "Epoch 294 / 500 | iteration 20 / 30 | Total Loss: 3.4510459899902344 | KNN Loss: 2.4442052841186523 | BCE Loss: 1.0068408250808716\n",
      "Epoch 294 / 500 | iteration 25 / 30 | Total Loss: 3.4501824378967285 | KNN Loss: 2.4546539783477783 | BCE Loss: 0.9955285787582397\n",
      "Epoch 295 / 500 | iteration 0 / 30 | Total Loss: 3.492377281188965 | KNN Loss: 2.4696147441864014 | BCE Loss: 1.022762417793274\n",
      "Epoch 295 / 500 | iteration 5 / 30 | Total Loss: 3.4449188709259033 | KNN Loss: 2.4546754360198975 | BCE Loss: 0.9902434945106506\n",
      "Epoch 295 / 500 | iteration 10 / 30 | Total Loss: 3.4458940029144287 | KNN Loss: 2.4227373600006104 | BCE Loss: 1.0231566429138184\n",
      "Epoch 295 / 500 | iteration 15 / 30 | Total Loss: 3.488827705383301 | KNN Loss: 2.4753801822662354 | BCE Loss: 1.0134475231170654\n",
      "Epoch 295 / 500 | iteration 20 / 30 | Total Loss: 3.440612316131592 | KNN Loss: 2.450122594833374 | BCE Loss: 0.9904898405075073\n",
      "Epoch 295 / 500 | iteration 25 / 30 | Total Loss: 3.436581611633301 | KNN Loss: 2.4270288944244385 | BCE Loss: 1.0095527172088623\n",
      "Epoch 296 / 500 | iteration 0 / 30 | Total Loss: 3.48649001121521 | KNN Loss: 2.479452610015869 | BCE Loss: 1.0070374011993408\n",
      "Epoch 296 / 500 | iteration 5 / 30 | Total Loss: 3.462170124053955 | KNN Loss: 2.433208465576172 | BCE Loss: 1.0289616584777832\n",
      "Epoch 296 / 500 | iteration 10 / 30 | Total Loss: 3.4687397480010986 | KNN Loss: 2.4224889278411865 | BCE Loss: 1.046250820159912\n",
      "Epoch 296 / 500 | iteration 15 / 30 | Total Loss: 3.4722094535827637 | KNN Loss: 2.420138120651245 | BCE Loss: 1.052071452140808\n",
      "Epoch 296 / 500 | iteration 20 / 30 | Total Loss: 3.4102625846862793 | KNN Loss: 2.433342933654785 | BCE Loss: 0.9769196510314941\n",
      "Epoch 296 / 500 | iteration 25 / 30 | Total Loss: 3.4356536865234375 | KNN Loss: 2.4473445415496826 | BCE Loss: 0.9883092641830444\n",
      "Epoch 297 / 500 | iteration 0 / 30 | Total Loss: 3.5212414264678955 | KNN Loss: 2.4681992530822754 | BCE Loss: 1.0530421733856201\n",
      "Epoch 297 / 500 | iteration 5 / 30 | Total Loss: 3.4317495822906494 | KNN Loss: 2.4473960399627686 | BCE Loss: 0.9843536019325256\n",
      "Epoch 297 / 500 | iteration 10 / 30 | Total Loss: 3.4861836433410645 | KNN Loss: 2.4727091789245605 | BCE Loss: 1.013474464416504\n",
      "Epoch 297 / 500 | iteration 15 / 30 | Total Loss: 3.4342775344848633 | KNN Loss: 2.441716194152832 | BCE Loss: 0.9925613403320312\n",
      "Epoch 297 / 500 | iteration 20 / 30 | Total Loss: 3.4266068935394287 | KNN Loss: 2.4443349838256836 | BCE Loss: 0.9822719693183899\n",
      "Epoch 297 / 500 | iteration 25 / 30 | Total Loss: 3.4288055896759033 | KNN Loss: 2.416591167449951 | BCE Loss: 1.0122144222259521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 / 500 | iteration 0 / 30 | Total Loss: 3.4963135719299316 | KNN Loss: 2.467194080352783 | BCE Loss: 1.0291194915771484\n",
      "Epoch 298 / 500 | iteration 5 / 30 | Total Loss: 3.4381637573242188 | KNN Loss: 2.4402761459350586 | BCE Loss: 0.9978876113891602\n",
      "Epoch 298 / 500 | iteration 10 / 30 | Total Loss: 3.4735970497131348 | KNN Loss: 2.441227674484253 | BCE Loss: 1.0323693752288818\n",
      "Epoch 298 / 500 | iteration 15 / 30 | Total Loss: 3.425041913986206 | KNN Loss: 2.422712802886963 | BCE Loss: 1.0023291110992432\n",
      "Epoch 298 / 500 | iteration 20 / 30 | Total Loss: 3.456709861755371 | KNN Loss: 2.4374852180480957 | BCE Loss: 1.0192246437072754\n",
      "Epoch 298 / 500 | iteration 25 / 30 | Total Loss: 3.4864721298217773 | KNN Loss: 2.4347658157348633 | BCE Loss: 1.0517061948776245\n",
      "Epoch 299 / 500 | iteration 0 / 30 | Total Loss: 3.5064194202423096 | KNN Loss: 2.476707696914673 | BCE Loss: 1.0297117233276367\n",
      "Epoch 299 / 500 | iteration 5 / 30 | Total Loss: 3.46610689163208 | KNN Loss: 2.4460506439208984 | BCE Loss: 1.0200562477111816\n",
      "Epoch 299 / 500 | iteration 10 / 30 | Total Loss: 3.4673192501068115 | KNN Loss: 2.4517602920532227 | BCE Loss: 1.0155589580535889\n",
      "Epoch 299 / 500 | iteration 15 / 30 | Total Loss: 3.4518508911132812 | KNN Loss: 2.4411394596099854 | BCE Loss: 1.0107115507125854\n",
      "Epoch 299 / 500 | iteration 20 / 30 | Total Loss: 3.4415645599365234 | KNN Loss: 2.449925661087036 | BCE Loss: 0.9916387796401978\n",
      "Epoch 299 / 500 | iteration 25 / 30 | Total Loss: 3.463743209838867 | KNN Loss: 2.442362070083618 | BCE Loss: 1.0213810205459595\n",
      "Epoch 300 / 500 | iteration 0 / 30 | Total Loss: 3.490438222885132 | KNN Loss: 2.474318027496338 | BCE Loss: 1.016120195388794\n",
      "Epoch 300 / 500 | iteration 5 / 30 | Total Loss: 3.459047317504883 | KNN Loss: 2.4646010398864746 | BCE Loss: 0.9944462776184082\n",
      "Epoch 300 / 500 | iteration 10 / 30 | Total Loss: 3.439101457595825 | KNN Loss: 2.4334795475006104 | BCE Loss: 1.0056219100952148\n",
      "Epoch 300 / 500 | iteration 15 / 30 | Total Loss: 3.4293386936187744 | KNN Loss: 2.4236338138580322 | BCE Loss: 1.0057048797607422\n",
      "Epoch 300 / 500 | iteration 20 / 30 | Total Loss: 3.4342589378356934 | KNN Loss: 2.4336373805999756 | BCE Loss: 1.0006215572357178\n",
      "Epoch 300 / 500 | iteration 25 / 30 | Total Loss: 3.4688901901245117 | KNN Loss: 2.458922863006592 | BCE Loss: 1.0099672079086304\n",
      "Epoch 301 / 500 | iteration 0 / 30 | Total Loss: 3.4509737491607666 | KNN Loss: 2.450838327407837 | BCE Loss: 1.0001354217529297\n",
      "Epoch 301 / 500 | iteration 5 / 30 | Total Loss: 3.463405132293701 | KNN Loss: 2.4462051391601562 | BCE Loss: 1.017199993133545\n",
      "Epoch 301 / 500 | iteration 10 / 30 | Total Loss: 3.4968276023864746 | KNN Loss: 2.472219228744507 | BCE Loss: 1.0246084928512573\n",
      "Epoch 301 / 500 | iteration 15 / 30 | Total Loss: 3.4114227294921875 | KNN Loss: 2.4187238216400146 | BCE Loss: 0.9926987886428833\n",
      "Epoch 301 / 500 | iteration 20 / 30 | Total Loss: 3.479098081588745 | KNN Loss: 2.452033042907715 | BCE Loss: 1.0270650386810303\n",
      "Epoch 301 / 500 | iteration 25 / 30 | Total Loss: 3.4510998725891113 | KNN Loss: 2.457038164138794 | BCE Loss: 0.9940616488456726\n",
      "Epoch 302 / 500 | iteration 0 / 30 | Total Loss: 3.4954264163970947 | KNN Loss: 2.472480058670044 | BCE Loss: 1.0229463577270508\n",
      "Epoch 302 / 500 | iteration 5 / 30 | Total Loss: 3.5044524669647217 | KNN Loss: 2.4596033096313477 | BCE Loss: 1.044849157333374\n",
      "Epoch 302 / 500 | iteration 10 / 30 | Total Loss: 3.492703437805176 | KNN Loss: 2.4593143463134766 | BCE Loss: 1.0333889722824097\n",
      "Epoch 302 / 500 | iteration 15 / 30 | Total Loss: 3.4354958534240723 | KNN Loss: 2.4333066940307617 | BCE Loss: 1.0021891593933105\n",
      "Epoch 302 / 500 | iteration 20 / 30 | Total Loss: 3.447050094604492 | KNN Loss: 2.4433233737945557 | BCE Loss: 1.0037267208099365\n",
      "Epoch 302 / 500 | iteration 25 / 30 | Total Loss: 3.4616103172302246 | KNN Loss: 2.4434468746185303 | BCE Loss: 1.0181635618209839\n",
      "Epoch 303 / 500 | iteration 0 / 30 | Total Loss: 3.4870445728302 | KNN Loss: 2.45288348197937 | BCE Loss: 1.03416109085083\n",
      "Epoch 303 / 500 | iteration 5 / 30 | Total Loss: 3.492225170135498 | KNN Loss: 2.4825472831726074 | BCE Loss: 1.0096778869628906\n",
      "Epoch 303 / 500 | iteration 10 / 30 | Total Loss: 3.456685781478882 | KNN Loss: 2.473687171936035 | BCE Loss: 0.9829986095428467\n",
      "Epoch 303 / 500 | iteration 15 / 30 | Total Loss: 3.420241355895996 | KNN Loss: 2.436145067214966 | BCE Loss: 0.9840962290763855\n",
      "Epoch 303 / 500 | iteration 20 / 30 | Total Loss: 3.463832378387451 | KNN Loss: 2.4643540382385254 | BCE Loss: 0.9994784593582153\n",
      "Epoch 303 / 500 | iteration 25 / 30 | Total Loss: 3.4782352447509766 | KNN Loss: 2.438602924346924 | BCE Loss: 1.0396324396133423\n",
      "Epoch 304 / 500 | iteration 0 / 30 | Total Loss: 3.4942190647125244 | KNN Loss: 2.487112283706665 | BCE Loss: 1.0071067810058594\n",
      "Epoch 304 / 500 | iteration 5 / 30 | Total Loss: 3.494666576385498 | KNN Loss: 2.484062671661377 | BCE Loss: 1.0106040239334106\n",
      "Epoch 304 / 500 | iteration 10 / 30 | Total Loss: 3.4574427604675293 | KNN Loss: 2.45200777053833 | BCE Loss: 1.0054351091384888\n",
      "Epoch 304 / 500 | iteration 15 / 30 | Total Loss: 3.4346091747283936 | KNN Loss: 2.4403162002563477 | BCE Loss: 0.9942929744720459\n",
      "Epoch 304 / 500 | iteration 20 / 30 | Total Loss: 3.4450266361236572 | KNN Loss: 2.4396421909332275 | BCE Loss: 1.0053844451904297\n",
      "Epoch 304 / 500 | iteration 25 / 30 | Total Loss: 3.4290647506713867 | KNN Loss: 2.4248669147491455 | BCE Loss: 1.0041978359222412\n",
      "Epoch 305 / 500 | iteration 0 / 30 | Total Loss: 3.4444122314453125 | KNN Loss: 2.4328691959381104 | BCE Loss: 1.0115429162979126\n",
      "Epoch 305 / 500 | iteration 5 / 30 | Total Loss: 3.5204672813415527 | KNN Loss: 2.4708404541015625 | BCE Loss: 1.0496269464492798\n",
      "Epoch 305 / 500 | iteration 10 / 30 | Total Loss: 3.452805757522583 | KNN Loss: 2.4506218433380127 | BCE Loss: 1.0021839141845703\n",
      "Epoch 305 / 500 | iteration 15 / 30 | Total Loss: 3.467799663543701 | KNN Loss: 2.423262119293213 | BCE Loss: 1.0445375442504883\n",
      "Epoch 305 / 500 | iteration 20 / 30 | Total Loss: 3.426820755004883 | KNN Loss: 2.426670789718628 | BCE Loss: 1.0001498460769653\n",
      "Epoch 305 / 500 | iteration 25 / 30 | Total Loss: 3.480602741241455 | KNN Loss: 2.4346957206726074 | BCE Loss: 1.0459070205688477\n",
      "Epoch   306: reducing learning rate of group 0 to 2.8824e-04.\n",
      "Epoch 306 / 500 | iteration 0 / 30 | Total Loss: 3.4499661922454834 | KNN Loss: 2.456212043762207 | BCE Loss: 0.9937540888786316\n",
      "Epoch 306 / 500 | iteration 5 / 30 | Total Loss: 3.4919629096984863 | KNN Loss: 2.4735052585601807 | BCE Loss: 1.0184576511383057\n",
      "Epoch 306 / 500 | iteration 10 / 30 | Total Loss: 3.451643943786621 | KNN Loss: 2.4544179439544678 | BCE Loss: 0.9972261190414429\n",
      "Epoch 306 / 500 | iteration 15 / 30 | Total Loss: 3.474199056625366 | KNN Loss: 2.4562270641326904 | BCE Loss: 1.0179719924926758\n",
      "Epoch 306 / 500 | iteration 20 / 30 | Total Loss: 3.418998956680298 | KNN Loss: 2.4373843669891357 | BCE Loss: 0.9816145896911621\n",
      "Epoch 306 / 500 | iteration 25 / 30 | Total Loss: 3.4825756549835205 | KNN Loss: 2.4619483947753906 | BCE Loss: 1.0206272602081299\n",
      "Epoch 307 / 500 | iteration 0 / 30 | Total Loss: 3.471639633178711 | KNN Loss: 2.455918073654175 | BCE Loss: 1.0157215595245361\n",
      "Epoch 307 / 500 | iteration 5 / 30 | Total Loss: 3.4807610511779785 | KNN Loss: 2.4780380725860596 | BCE Loss: 1.0027228593826294\n",
      "Epoch 307 / 500 | iteration 10 / 30 | Total Loss: 3.4259936809539795 | KNN Loss: 2.4143266677856445 | BCE Loss: 1.011667013168335\n",
      "Epoch 307 / 500 | iteration 15 / 30 | Total Loss: 3.464142084121704 | KNN Loss: 2.423624277114868 | BCE Loss: 1.040517807006836\n",
      "Epoch 307 / 500 | iteration 20 / 30 | Total Loss: 3.474299907684326 | KNN Loss: 2.4615211486816406 | BCE Loss: 1.012778639793396\n",
      "Epoch 307 / 500 | iteration 25 / 30 | Total Loss: 3.4654645919799805 | KNN Loss: 2.4530892372131348 | BCE Loss: 1.0123753547668457\n",
      "Epoch 308 / 500 | iteration 0 / 30 | Total Loss: 3.447465658187866 | KNN Loss: 2.441690444946289 | BCE Loss: 1.0057752132415771\n",
      "Epoch 308 / 500 | iteration 5 / 30 | Total Loss: 3.43291974067688 | KNN Loss: 2.425466537475586 | BCE Loss: 1.007453203201294\n",
      "Epoch 308 / 500 | iteration 10 / 30 | Total Loss: 3.4096474647521973 | KNN Loss: 2.4251606464385986 | BCE Loss: 0.9844868183135986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308 / 500 | iteration 15 / 30 | Total Loss: 3.44573974609375 | KNN Loss: 2.4388303756713867 | BCE Loss: 1.0069092512130737\n",
      "Epoch 308 / 500 | iteration 20 / 30 | Total Loss: 3.495628595352173 | KNN Loss: 2.4559507369995117 | BCE Loss: 1.0396778583526611\n",
      "Epoch 308 / 500 | iteration 25 / 30 | Total Loss: 3.474010467529297 | KNN Loss: 2.47218656539917 | BCE Loss: 1.0018237829208374\n",
      "Epoch 309 / 500 | iteration 0 / 30 | Total Loss: 3.4567947387695312 | KNN Loss: 2.4463653564453125 | BCE Loss: 1.0104292631149292\n",
      "Epoch 309 / 500 | iteration 5 / 30 | Total Loss: 3.453601360321045 | KNN Loss: 2.44804310798645 | BCE Loss: 1.0055583715438843\n",
      "Epoch 309 / 500 | iteration 10 / 30 | Total Loss: 3.480644941329956 | KNN Loss: 2.460764169692993 | BCE Loss: 1.019880771636963\n",
      "Epoch 309 / 500 | iteration 15 / 30 | Total Loss: 3.502180576324463 | KNN Loss: 2.4563088417053223 | BCE Loss: 1.0458717346191406\n",
      "Epoch 309 / 500 | iteration 20 / 30 | Total Loss: 3.4481253623962402 | KNN Loss: 2.432525157928467 | BCE Loss: 1.0156002044677734\n",
      "Epoch 309 / 500 | iteration 25 / 30 | Total Loss: 3.46640944480896 | KNN Loss: 2.44016170501709 | BCE Loss: 1.0262477397918701\n",
      "Epoch 310 / 500 | iteration 0 / 30 | Total Loss: 3.4484193325042725 | KNN Loss: 2.433387041091919 | BCE Loss: 1.0150322914123535\n",
      "Epoch 310 / 500 | iteration 5 / 30 | Total Loss: 3.4721553325653076 | KNN Loss: 2.454970121383667 | BCE Loss: 1.0171852111816406\n",
      "Epoch 310 / 500 | iteration 10 / 30 | Total Loss: 3.4537553787231445 | KNN Loss: 2.4288489818573 | BCE Loss: 1.0249063968658447\n",
      "Epoch 310 / 500 | iteration 15 / 30 | Total Loss: 3.4454541206359863 | KNN Loss: 2.4289770126342773 | BCE Loss: 1.016477108001709\n",
      "Epoch 310 / 500 | iteration 20 / 30 | Total Loss: 3.428534746170044 | KNN Loss: 2.439114809036255 | BCE Loss: 0.9894199371337891\n",
      "Epoch 310 / 500 | iteration 25 / 30 | Total Loss: 3.4135043621063232 | KNN Loss: 2.4440183639526367 | BCE Loss: 0.9694860577583313\n",
      "Epoch 311 / 500 | iteration 0 / 30 | Total Loss: 3.482635259628296 | KNN Loss: 2.4705312252044678 | BCE Loss: 1.0121040344238281\n",
      "Epoch 311 / 500 | iteration 5 / 30 | Total Loss: 3.4956603050231934 | KNN Loss: 2.4643912315368652 | BCE Loss: 1.0312689542770386\n",
      "Epoch 311 / 500 | iteration 10 / 30 | Total Loss: 3.430579662322998 | KNN Loss: 2.4501729011535645 | BCE Loss: 0.9804067611694336\n",
      "Epoch 311 / 500 | iteration 15 / 30 | Total Loss: 3.4491353034973145 | KNN Loss: 2.432055950164795 | BCE Loss: 1.0170793533325195\n",
      "Epoch 311 / 500 | iteration 20 / 30 | Total Loss: 3.4627695083618164 | KNN Loss: 2.4286563396453857 | BCE Loss: 1.0341131687164307\n",
      "Epoch 311 / 500 | iteration 25 / 30 | Total Loss: 3.4770586490631104 | KNN Loss: 2.470893621444702 | BCE Loss: 1.0061650276184082\n",
      "Epoch 312 / 500 | iteration 0 / 30 | Total Loss: 3.447495698928833 | KNN Loss: 2.4314141273498535 | BCE Loss: 1.0160815715789795\n",
      "Epoch 312 / 500 | iteration 5 / 30 | Total Loss: 3.426750421524048 | KNN Loss: 2.4443676471710205 | BCE Loss: 0.9823827147483826\n",
      "Epoch 312 / 500 | iteration 10 / 30 | Total Loss: 3.466113567352295 | KNN Loss: 2.459845542907715 | BCE Loss: 1.0062679052352905\n",
      "Epoch 312 / 500 | iteration 15 / 30 | Total Loss: 3.4388866424560547 | KNN Loss: 2.420013189315796 | BCE Loss: 1.0188733339309692\n",
      "Epoch 312 / 500 | iteration 20 / 30 | Total Loss: 3.490011692047119 | KNN Loss: 2.475048065185547 | BCE Loss: 1.0149637460708618\n",
      "Epoch 312 / 500 | iteration 25 / 30 | Total Loss: 3.441215753555298 | KNN Loss: 2.4471402168273926 | BCE Loss: 0.9940755367279053\n",
      "Epoch 313 / 500 | iteration 0 / 30 | Total Loss: 3.5350372791290283 | KNN Loss: 2.452631711959839 | BCE Loss: 1.0824055671691895\n",
      "Epoch 313 / 500 | iteration 5 / 30 | Total Loss: 3.494201421737671 | KNN Loss: 2.490949869155884 | BCE Loss: 1.003251552581787\n",
      "Epoch 313 / 500 | iteration 10 / 30 | Total Loss: 3.4510927200317383 | KNN Loss: 2.441823959350586 | BCE Loss: 1.0092686414718628\n",
      "Epoch 313 / 500 | iteration 15 / 30 | Total Loss: 3.5372257232666016 | KNN Loss: 2.491600751876831 | BCE Loss: 1.0456249713897705\n",
      "Epoch 313 / 500 | iteration 20 / 30 | Total Loss: 3.482880115509033 | KNN Loss: 2.4501097202301025 | BCE Loss: 1.0327702760696411\n",
      "Epoch 313 / 500 | iteration 25 / 30 | Total Loss: 3.4734554290771484 | KNN Loss: 2.4454152584075928 | BCE Loss: 1.0280402898788452\n",
      "Epoch 314 / 500 | iteration 0 / 30 | Total Loss: 3.4902634620666504 | KNN Loss: 2.490575075149536 | BCE Loss: 0.999688446521759\n",
      "Epoch 314 / 500 | iteration 5 / 30 | Total Loss: 3.444992780685425 | KNN Loss: 2.4351236820220947 | BCE Loss: 1.00986909866333\n",
      "Epoch 314 / 500 | iteration 10 / 30 | Total Loss: 3.470872402191162 | KNN Loss: 2.440858840942383 | BCE Loss: 1.0300135612487793\n",
      "Epoch 314 / 500 | iteration 15 / 30 | Total Loss: 3.453782081604004 | KNN Loss: 2.4423890113830566 | BCE Loss: 1.0113930702209473\n",
      "Epoch 314 / 500 | iteration 20 / 30 | Total Loss: 3.4595534801483154 | KNN Loss: 2.4620673656463623 | BCE Loss: 0.9974861145019531\n",
      "Epoch 314 / 500 | iteration 25 / 30 | Total Loss: 3.501790761947632 | KNN Loss: 2.4728949069976807 | BCE Loss: 1.0288958549499512\n",
      "Epoch 315 / 500 | iteration 0 / 30 | Total Loss: 3.4835174083709717 | KNN Loss: 2.458447217941284 | BCE Loss: 1.0250701904296875\n",
      "Epoch 315 / 500 | iteration 5 / 30 | Total Loss: 3.455005407333374 | KNN Loss: 2.442383289337158 | BCE Loss: 1.0126221179962158\n",
      "Epoch 315 / 500 | iteration 10 / 30 | Total Loss: 3.47982120513916 | KNN Loss: 2.466892719268799 | BCE Loss: 1.0129283666610718\n",
      "Epoch 315 / 500 | iteration 15 / 30 | Total Loss: 3.4563488960266113 | KNN Loss: 2.450707197189331 | BCE Loss: 1.0056415796279907\n",
      "Epoch 315 / 500 | iteration 20 / 30 | Total Loss: 3.4455947875976562 | KNN Loss: 2.4377386569976807 | BCE Loss: 1.007856011390686\n",
      "Epoch 315 / 500 | iteration 25 / 30 | Total Loss: 3.465620756149292 | KNN Loss: 2.4624385833740234 | BCE Loss: 1.0031821727752686\n",
      "Epoch 316 / 500 | iteration 0 / 30 | Total Loss: 3.495643138885498 | KNN Loss: 2.4419682025909424 | BCE Loss: 1.0536749362945557\n",
      "Epoch 316 / 500 | iteration 5 / 30 | Total Loss: 3.4460387229919434 | KNN Loss: 2.447922945022583 | BCE Loss: 0.9981156587600708\n",
      "Epoch 316 / 500 | iteration 10 / 30 | Total Loss: 3.4959301948547363 | KNN Loss: 2.4796323776245117 | BCE Loss: 1.0162979364395142\n",
      "Epoch 316 / 500 | iteration 15 / 30 | Total Loss: 3.4687888622283936 | KNN Loss: 2.4437015056610107 | BCE Loss: 1.0250873565673828\n",
      "Epoch 316 / 500 | iteration 20 / 30 | Total Loss: 3.430123805999756 | KNN Loss: 2.412900447845459 | BCE Loss: 1.0172233581542969\n",
      "Epoch 316 / 500 | iteration 25 / 30 | Total Loss: 3.4355075359344482 | KNN Loss: 2.4222543239593506 | BCE Loss: 1.0132532119750977\n",
      "Epoch   317: reducing learning rate of group 0 to 2.0177e-04.\n",
      "Epoch 317 / 500 | iteration 0 / 30 | Total Loss: 3.452488422393799 | KNN Loss: 2.4347288608551025 | BCE Loss: 1.0177595615386963\n",
      "Epoch 317 / 500 | iteration 5 / 30 | Total Loss: 3.4767160415649414 | KNN Loss: 2.466937780380249 | BCE Loss: 1.0097782611846924\n",
      "Epoch 317 / 500 | iteration 10 / 30 | Total Loss: 3.4602575302124023 | KNN Loss: 2.4482827186584473 | BCE Loss: 1.011974811553955\n",
      "Epoch 317 / 500 | iteration 15 / 30 | Total Loss: 3.4505996704101562 | KNN Loss: 2.4501194953918457 | BCE Loss: 1.0004801750183105\n",
      "Epoch 317 / 500 | iteration 20 / 30 | Total Loss: 3.434718132019043 | KNN Loss: 2.410027027130127 | BCE Loss: 1.0246909856796265\n",
      "Epoch 317 / 500 | iteration 25 / 30 | Total Loss: 3.4708008766174316 | KNN Loss: 2.453342914581299 | BCE Loss: 1.0174579620361328\n",
      "Epoch 318 / 500 | iteration 0 / 30 | Total Loss: 3.483179807662964 | KNN Loss: 2.4652111530303955 | BCE Loss: 1.0179686546325684\n",
      "Epoch 318 / 500 | iteration 5 / 30 | Total Loss: 3.4293622970581055 | KNN Loss: 2.4088239669799805 | BCE Loss: 1.0205382108688354\n",
      "Epoch 318 / 500 | iteration 10 / 30 | Total Loss: 3.498598575592041 | KNN Loss: 2.4652979373931885 | BCE Loss: 1.033300518989563\n",
      "Epoch 318 / 500 | iteration 15 / 30 | Total Loss: 3.441736936569214 | KNN Loss: 2.450563907623291 | BCE Loss: 0.9911730885505676\n",
      "Epoch 318 / 500 | iteration 20 / 30 | Total Loss: 3.4118900299072266 | KNN Loss: 2.417235851287842 | BCE Loss: 0.9946540594100952\n",
      "Epoch 318 / 500 | iteration 25 / 30 | Total Loss: 3.494203805923462 | KNN Loss: 2.474743127822876 | BCE Loss: 1.019460678100586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319 / 500 | iteration 0 / 30 | Total Loss: 3.4951343536376953 | KNN Loss: 2.4988577365875244 | BCE Loss: 0.9962764978408813\n",
      "Epoch 319 / 500 | iteration 5 / 30 | Total Loss: 3.463897228240967 | KNN Loss: 2.4661757946014404 | BCE Loss: 0.9977214336395264\n",
      "Epoch 319 / 500 | iteration 10 / 30 | Total Loss: 3.4419898986816406 | KNN Loss: 2.4483163356781006 | BCE Loss: 0.9936736822128296\n",
      "Epoch 319 / 500 | iteration 15 / 30 | Total Loss: 3.455347776412964 | KNN Loss: 2.4182567596435547 | BCE Loss: 1.0370910167694092\n",
      "Epoch 319 / 500 | iteration 20 / 30 | Total Loss: 3.4829821586608887 | KNN Loss: 2.469203233718872 | BCE Loss: 1.0137790441513062\n",
      "Epoch 319 / 500 | iteration 25 / 30 | Total Loss: 3.4745564460754395 | KNN Loss: 2.4561941623687744 | BCE Loss: 1.0183621644973755\n",
      "Epoch 320 / 500 | iteration 0 / 30 | Total Loss: 3.450375556945801 | KNN Loss: 2.4403364658355713 | BCE Loss: 1.01003897190094\n",
      "Epoch 320 / 500 | iteration 5 / 30 | Total Loss: 3.459965229034424 | KNN Loss: 2.4405295848846436 | BCE Loss: 1.0194356441497803\n",
      "Epoch 320 / 500 | iteration 10 / 30 | Total Loss: 3.4352917671203613 | KNN Loss: 2.442840576171875 | BCE Loss: 0.9924513101577759\n",
      "Epoch 320 / 500 | iteration 15 / 30 | Total Loss: 3.456845998764038 | KNN Loss: 2.4362053871154785 | BCE Loss: 1.0206406116485596\n",
      "Epoch 320 / 500 | iteration 20 / 30 | Total Loss: 3.473721742630005 | KNN Loss: 2.4523043632507324 | BCE Loss: 1.0214173793792725\n",
      "Epoch 320 / 500 | iteration 25 / 30 | Total Loss: 3.4911601543426514 | KNN Loss: 2.4567999839782715 | BCE Loss: 1.0343601703643799\n",
      "Epoch 321 / 500 | iteration 0 / 30 | Total Loss: 3.4446094036102295 | KNN Loss: 2.4419054985046387 | BCE Loss: 1.0027039051055908\n",
      "Epoch 321 / 500 | iteration 5 / 30 | Total Loss: 3.4741477966308594 | KNN Loss: 2.441409111022949 | BCE Loss: 1.0327386856079102\n",
      "Epoch 321 / 500 | iteration 10 / 30 | Total Loss: 3.4537782669067383 | KNN Loss: 2.4267852306365967 | BCE Loss: 1.0269930362701416\n",
      "Epoch 321 / 500 | iteration 15 / 30 | Total Loss: 3.478578805923462 | KNN Loss: 2.4604339599609375 | BCE Loss: 1.0181448459625244\n",
      "Epoch 321 / 500 | iteration 20 / 30 | Total Loss: 3.4672346115112305 | KNN Loss: 2.453137159347534 | BCE Loss: 1.0140974521636963\n",
      "Epoch 321 / 500 | iteration 25 / 30 | Total Loss: 3.4666213989257812 | KNN Loss: 2.440572500228882 | BCE Loss: 1.026049017906189\n",
      "Epoch 322 / 500 | iteration 0 / 30 | Total Loss: 3.488828182220459 | KNN Loss: 2.4757113456726074 | BCE Loss: 1.0131168365478516\n",
      "Epoch 322 / 500 | iteration 5 / 30 | Total Loss: 3.4718494415283203 | KNN Loss: 2.465941905975342 | BCE Loss: 1.0059075355529785\n",
      "Epoch 322 / 500 | iteration 10 / 30 | Total Loss: 3.4729137420654297 | KNN Loss: 2.458657741546631 | BCE Loss: 1.0142560005187988\n",
      "Epoch 322 / 500 | iteration 15 / 30 | Total Loss: 3.4759294986724854 | KNN Loss: 2.449479103088379 | BCE Loss: 1.0264503955841064\n",
      "Epoch 322 / 500 | iteration 20 / 30 | Total Loss: 3.500187873840332 | KNN Loss: 2.492143154144287 | BCE Loss: 1.008044719696045\n",
      "Epoch 322 / 500 | iteration 25 / 30 | Total Loss: 3.497054100036621 | KNN Loss: 2.443336248397827 | BCE Loss: 1.053717851638794\n",
      "Epoch 323 / 500 | iteration 0 / 30 | Total Loss: 3.477827310562134 | KNN Loss: 2.437138795852661 | BCE Loss: 1.0406885147094727\n",
      "Epoch 323 / 500 | iteration 5 / 30 | Total Loss: 3.4620819091796875 | KNN Loss: 2.4314827919006348 | BCE Loss: 1.0305989980697632\n",
      "Epoch 323 / 500 | iteration 10 / 30 | Total Loss: 3.4290101528167725 | KNN Loss: 2.4186697006225586 | BCE Loss: 1.0103404521942139\n",
      "Epoch 323 / 500 | iteration 15 / 30 | Total Loss: 3.4711978435516357 | KNN Loss: 2.4638895988464355 | BCE Loss: 1.0073082447052002\n",
      "Epoch 323 / 500 | iteration 20 / 30 | Total Loss: 3.442808151245117 | KNN Loss: 2.4328951835632324 | BCE Loss: 1.0099129676818848\n",
      "Epoch 323 / 500 | iteration 25 / 30 | Total Loss: 3.437021255493164 | KNN Loss: 2.4425559043884277 | BCE Loss: 0.9944654107093811\n",
      "Epoch 324 / 500 | iteration 0 / 30 | Total Loss: 3.4893574714660645 | KNN Loss: 2.4665699005126953 | BCE Loss: 1.0227874517440796\n",
      "Epoch 324 / 500 | iteration 5 / 30 | Total Loss: 3.439645290374756 | KNN Loss: 2.4412479400634766 | BCE Loss: 0.9983972311019897\n",
      "Epoch 324 / 500 | iteration 10 / 30 | Total Loss: 3.42932391166687 | KNN Loss: 2.4156503677368164 | BCE Loss: 1.0136735439300537\n",
      "Epoch 324 / 500 | iteration 15 / 30 | Total Loss: 3.476602792739868 | KNN Loss: 2.4625816345214844 | BCE Loss: 1.0140211582183838\n",
      "Epoch 324 / 500 | iteration 20 / 30 | Total Loss: 3.486177682876587 | KNN Loss: 2.4434168338775635 | BCE Loss: 1.0427608489990234\n",
      "Epoch 324 / 500 | iteration 25 / 30 | Total Loss: 3.450594902038574 | KNN Loss: 2.4331164360046387 | BCE Loss: 1.017478346824646\n",
      "Epoch 325 / 500 | iteration 0 / 30 | Total Loss: 3.450234889984131 | KNN Loss: 2.4403247833251953 | BCE Loss: 1.009910225868225\n",
      "Epoch 325 / 500 | iteration 5 / 30 | Total Loss: 3.4244136810302734 | KNN Loss: 2.4397144317626953 | BCE Loss: 0.9846992492675781\n",
      "Epoch 325 / 500 | iteration 10 / 30 | Total Loss: 3.4416537284851074 | KNN Loss: 2.418599843978882 | BCE Loss: 1.0230540037155151\n",
      "Epoch 325 / 500 | iteration 15 / 30 | Total Loss: 3.4452338218688965 | KNN Loss: 2.413027048110962 | BCE Loss: 1.0322067737579346\n",
      "Epoch 325 / 500 | iteration 20 / 30 | Total Loss: 3.4732584953308105 | KNN Loss: 2.4106504917144775 | BCE Loss: 1.0626081228256226\n",
      "Epoch 325 / 500 | iteration 25 / 30 | Total Loss: 3.4532599449157715 | KNN Loss: 2.4407243728637695 | BCE Loss: 1.0125356912612915\n",
      "Epoch 326 / 500 | iteration 0 / 30 | Total Loss: 3.456556558609009 | KNN Loss: 2.452130079269409 | BCE Loss: 1.0044264793395996\n",
      "Epoch 326 / 500 | iteration 5 / 30 | Total Loss: 3.478667736053467 | KNN Loss: 2.455899953842163 | BCE Loss: 1.0227677822113037\n",
      "Epoch 326 / 500 | iteration 10 / 30 | Total Loss: 3.472482204437256 | KNN Loss: 2.44730281829834 | BCE Loss: 1.0251795053482056\n",
      "Epoch 326 / 500 | iteration 15 / 30 | Total Loss: 3.4366679191589355 | KNN Loss: 2.419163703918457 | BCE Loss: 1.0175042152404785\n",
      "Epoch 326 / 500 | iteration 20 / 30 | Total Loss: 3.4928102493286133 | KNN Loss: 2.4633853435516357 | BCE Loss: 1.0294249057769775\n",
      "Epoch 326 / 500 | iteration 25 / 30 | Total Loss: 3.454218626022339 | KNN Loss: 2.4316954612731934 | BCE Loss: 1.0225231647491455\n",
      "Epoch 327 / 500 | iteration 0 / 30 | Total Loss: 3.453463077545166 | KNN Loss: 2.4338080883026123 | BCE Loss: 1.0196548700332642\n",
      "Epoch 327 / 500 | iteration 5 / 30 | Total Loss: 3.452495574951172 | KNN Loss: 2.429741859436035 | BCE Loss: 1.0227537155151367\n",
      "Epoch 327 / 500 | iteration 10 / 30 | Total Loss: 3.467954397201538 | KNN Loss: 2.470879077911377 | BCE Loss: 0.9970753192901611\n",
      "Epoch 327 / 500 | iteration 15 / 30 | Total Loss: 3.4507598876953125 | KNN Loss: 2.4446380138397217 | BCE Loss: 1.0061217546463013\n",
      "Epoch 327 / 500 | iteration 20 / 30 | Total Loss: 3.4899160861968994 | KNN Loss: 2.492489814758301 | BCE Loss: 0.9974262118339539\n",
      "Epoch 327 / 500 | iteration 25 / 30 | Total Loss: 3.5151119232177734 | KNN Loss: 2.4553370475769043 | BCE Loss: 1.0597748756408691\n",
      "Epoch   328: reducing learning rate of group 0 to 1.4124e-04.\n",
      "Epoch 328 / 500 | iteration 0 / 30 | Total Loss: 3.4849603176116943 | KNN Loss: 2.472181558609009 | BCE Loss: 1.0127787590026855\n",
      "Epoch 328 / 500 | iteration 5 / 30 | Total Loss: 3.437816619873047 | KNN Loss: 2.4659011363983154 | BCE Loss: 0.9719153642654419\n",
      "Epoch 328 / 500 | iteration 10 / 30 | Total Loss: 3.4503636360168457 | KNN Loss: 2.427401304244995 | BCE Loss: 1.022962212562561\n",
      "Epoch 328 / 500 | iteration 15 / 30 | Total Loss: 3.4274826049804688 | KNN Loss: 2.4439897537231445 | BCE Loss: 0.9834928512573242\n",
      "Epoch 328 / 500 | iteration 20 / 30 | Total Loss: 3.455125331878662 | KNN Loss: 2.4297218322753906 | BCE Loss: 1.0254034996032715\n",
      "Epoch 328 / 500 | iteration 25 / 30 | Total Loss: 3.4786229133605957 | KNN Loss: 2.4415123462677 | BCE Loss: 1.0371105670928955\n",
      "Epoch 329 / 500 | iteration 0 / 30 | Total Loss: 3.4316012859344482 | KNN Loss: 2.421182155609131 | BCE Loss: 1.0104191303253174\n",
      "Epoch 329 / 500 | iteration 5 / 30 | Total Loss: 3.475356340408325 | KNN Loss: 2.446434736251831 | BCE Loss: 1.0289216041564941\n",
      "Epoch 329 / 500 | iteration 10 / 30 | Total Loss: 3.5034985542297363 | KNN Loss: 2.479959726333618 | BCE Loss: 1.0235387086868286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329 / 500 | iteration 15 / 30 | Total Loss: 3.487696409225464 | KNN Loss: 2.4417428970336914 | BCE Loss: 1.0459535121917725\n",
      "Epoch 329 / 500 | iteration 20 / 30 | Total Loss: 3.5294198989868164 | KNN Loss: 2.4545137882232666 | BCE Loss: 1.0749059915542603\n",
      "Epoch 329 / 500 | iteration 25 / 30 | Total Loss: 3.4387598037719727 | KNN Loss: 2.4374871253967285 | BCE Loss: 1.0012726783752441\n",
      "Epoch 330 / 500 | iteration 0 / 30 | Total Loss: 3.433992862701416 | KNN Loss: 2.43955135345459 | BCE Loss: 0.9944414496421814\n",
      "Epoch 330 / 500 | iteration 5 / 30 | Total Loss: 3.461209297180176 | KNN Loss: 2.4528281688690186 | BCE Loss: 1.0083811283111572\n",
      "Epoch 330 / 500 | iteration 10 / 30 | Total Loss: 3.4461655616760254 | KNN Loss: 2.429147720336914 | BCE Loss: 1.0170178413391113\n",
      "Epoch 330 / 500 | iteration 15 / 30 | Total Loss: 3.4675862789154053 | KNN Loss: 2.4561471939086914 | BCE Loss: 1.0114390850067139\n",
      "Epoch 330 / 500 | iteration 20 / 30 | Total Loss: 3.4564170837402344 | KNN Loss: 2.439178705215454 | BCE Loss: 1.0172384977340698\n",
      "Epoch 330 / 500 | iteration 25 / 30 | Total Loss: 3.439344644546509 | KNN Loss: 2.4541518688201904 | BCE Loss: 0.9851927161216736\n",
      "Epoch 331 / 500 | iteration 0 / 30 | Total Loss: 3.4554967880249023 | KNN Loss: 2.4288384914398193 | BCE Loss: 1.026658296585083\n",
      "Epoch 331 / 500 | iteration 5 / 30 | Total Loss: 3.4565322399139404 | KNN Loss: 2.450378179550171 | BCE Loss: 1.0061540603637695\n",
      "Epoch 331 / 500 | iteration 10 / 30 | Total Loss: 3.43978214263916 | KNN Loss: 2.417788028717041 | BCE Loss: 1.0219941139221191\n",
      "Epoch 331 / 500 | iteration 15 / 30 | Total Loss: 3.478118419647217 | KNN Loss: 2.4725542068481445 | BCE Loss: 1.0055640935897827\n",
      "Epoch 331 / 500 | iteration 20 / 30 | Total Loss: 3.4750595092773438 | KNN Loss: 2.4665136337280273 | BCE Loss: 1.008545994758606\n",
      "Epoch 331 / 500 | iteration 25 / 30 | Total Loss: 3.4579806327819824 | KNN Loss: 2.463581085205078 | BCE Loss: 0.9943996071815491\n",
      "Epoch 332 / 500 | iteration 0 / 30 | Total Loss: 3.5050206184387207 | KNN Loss: 2.4975576400756836 | BCE Loss: 1.0074628591537476\n",
      "Epoch 332 / 500 | iteration 5 / 30 | Total Loss: 3.464405059814453 | KNN Loss: 2.4426419734954834 | BCE Loss: 1.0217632055282593\n",
      "Epoch 332 / 500 | iteration 10 / 30 | Total Loss: 3.4754233360290527 | KNN Loss: 2.4708268642425537 | BCE Loss: 1.004596471786499\n",
      "Epoch 332 / 500 | iteration 15 / 30 | Total Loss: 3.424121379852295 | KNN Loss: 2.4405195713043213 | BCE Loss: 0.9836018085479736\n",
      "Epoch 332 / 500 | iteration 20 / 30 | Total Loss: 3.4853475093841553 | KNN Loss: 2.467226982116699 | BCE Loss: 1.018120527267456\n",
      "Epoch 332 / 500 | iteration 25 / 30 | Total Loss: 3.45906138420105 | KNN Loss: 2.4383795261383057 | BCE Loss: 1.0206818580627441\n",
      "Epoch 333 / 500 | iteration 0 / 30 | Total Loss: 3.4708034992218018 | KNN Loss: 2.45923113822937 | BCE Loss: 1.0115723609924316\n",
      "Epoch 333 / 500 | iteration 5 / 30 | Total Loss: 3.4974684715270996 | KNN Loss: 2.455413818359375 | BCE Loss: 1.042054533958435\n",
      "Epoch 333 / 500 | iteration 10 / 30 | Total Loss: 3.488863706588745 | KNN Loss: 2.4732208251953125 | BCE Loss: 1.0156428813934326\n",
      "Epoch 333 / 500 | iteration 15 / 30 | Total Loss: 3.444803476333618 | KNN Loss: 2.436603546142578 | BCE Loss: 1.00819993019104\n",
      "Epoch 333 / 500 | iteration 20 / 30 | Total Loss: 3.4913034439086914 | KNN Loss: 2.457122325897217 | BCE Loss: 1.0341811180114746\n",
      "Epoch 333 / 500 | iteration 25 / 30 | Total Loss: 3.44714093208313 | KNN Loss: 2.4591660499572754 | BCE Loss: 0.9879749417304993\n",
      "Epoch 334 / 500 | iteration 0 / 30 | Total Loss: 3.4455409049987793 | KNN Loss: 2.448368549346924 | BCE Loss: 0.9971724152565002\n",
      "Epoch 334 / 500 | iteration 5 / 30 | Total Loss: 3.488774299621582 | KNN Loss: 2.4481420516967773 | BCE Loss: 1.0406322479248047\n",
      "Epoch 334 / 500 | iteration 10 / 30 | Total Loss: 3.489316940307617 | KNN Loss: 2.4724583625793457 | BCE Loss: 1.016858458518982\n",
      "Epoch 334 / 500 | iteration 15 / 30 | Total Loss: 3.442355155944824 | KNN Loss: 2.4425501823425293 | BCE Loss: 0.9998049139976501\n",
      "Epoch 334 / 500 | iteration 20 / 30 | Total Loss: 3.46177339553833 | KNN Loss: 2.4430580139160156 | BCE Loss: 1.0187153816223145\n",
      "Epoch 334 / 500 | iteration 25 / 30 | Total Loss: 3.457268238067627 | KNN Loss: 2.4470064640045166 | BCE Loss: 1.0102617740631104\n",
      "Epoch 335 / 500 | iteration 0 / 30 | Total Loss: 3.4312844276428223 | KNN Loss: 2.4320285320281982 | BCE Loss: 0.9992560148239136\n",
      "Epoch 335 / 500 | iteration 5 / 30 | Total Loss: 3.474547863006592 | KNN Loss: 2.4418129920959473 | BCE Loss: 1.0327348709106445\n",
      "Epoch 335 / 500 | iteration 10 / 30 | Total Loss: 3.4551682472229004 | KNN Loss: 2.4360225200653076 | BCE Loss: 1.0191457271575928\n",
      "Epoch 335 / 500 | iteration 15 / 30 | Total Loss: 3.450028419494629 | KNN Loss: 2.434114933013916 | BCE Loss: 1.0159136056900024\n",
      "Epoch 335 / 500 | iteration 20 / 30 | Total Loss: 3.467954635620117 | KNN Loss: 2.446558713912964 | BCE Loss: 1.0213959217071533\n",
      "Epoch 335 / 500 | iteration 25 / 30 | Total Loss: 3.4558284282684326 | KNN Loss: 2.439181089401245 | BCE Loss: 1.0166473388671875\n",
      "Epoch 336 / 500 | iteration 0 / 30 | Total Loss: 3.434591293334961 | KNN Loss: 2.4176840782165527 | BCE Loss: 1.0169072151184082\n",
      "Epoch 336 / 500 | iteration 5 / 30 | Total Loss: 3.476010322570801 | KNN Loss: 2.459172248840332 | BCE Loss: 1.0168380737304688\n",
      "Epoch 336 / 500 | iteration 10 / 30 | Total Loss: 3.488295316696167 | KNN Loss: 2.4669435024261475 | BCE Loss: 1.0213518142700195\n",
      "Epoch 336 / 500 | iteration 15 / 30 | Total Loss: 3.445499897003174 | KNN Loss: 2.4353127479553223 | BCE Loss: 1.0101871490478516\n",
      "Epoch 336 / 500 | iteration 20 / 30 | Total Loss: 3.430891752243042 | KNN Loss: 2.428544521331787 | BCE Loss: 1.0023472309112549\n",
      "Epoch 336 / 500 | iteration 25 / 30 | Total Loss: 3.440267562866211 | KNN Loss: 2.448793888092041 | BCE Loss: 0.9914737939834595\n",
      "Epoch 337 / 500 | iteration 0 / 30 | Total Loss: 3.481011390686035 | KNN Loss: 2.4778196811676025 | BCE Loss: 1.003191590309143\n",
      "Epoch 337 / 500 | iteration 5 / 30 | Total Loss: 3.4739558696746826 | KNN Loss: 2.4701993465423584 | BCE Loss: 1.0037565231323242\n",
      "Epoch 337 / 500 | iteration 10 / 30 | Total Loss: 3.424206256866455 | KNN Loss: 2.4322187900543213 | BCE Loss: 0.9919873476028442\n",
      "Epoch 337 / 500 | iteration 15 / 30 | Total Loss: 3.4459657669067383 | KNN Loss: 2.454633951187134 | BCE Loss: 0.9913316965103149\n",
      "Epoch 337 / 500 | iteration 20 / 30 | Total Loss: 3.491454601287842 | KNN Loss: 2.4956305027008057 | BCE Loss: 0.9958240389823914\n",
      "Epoch 337 / 500 | iteration 25 / 30 | Total Loss: 3.4414916038513184 | KNN Loss: 2.4289658069610596 | BCE Loss: 1.0125256776809692\n",
      "Epoch 338 / 500 | iteration 0 / 30 | Total Loss: 3.448866367340088 | KNN Loss: 2.465190887451172 | BCE Loss: 0.983675479888916\n",
      "Epoch 338 / 500 | iteration 5 / 30 | Total Loss: 3.458754062652588 | KNN Loss: 2.4443440437316895 | BCE Loss: 1.0144098997116089\n",
      "Epoch 338 / 500 | iteration 10 / 30 | Total Loss: 3.4673514366149902 | KNN Loss: 2.447813034057617 | BCE Loss: 1.0195385217666626\n",
      "Epoch 338 / 500 | iteration 15 / 30 | Total Loss: 3.471330404281616 | KNN Loss: 2.4413130283355713 | BCE Loss: 1.030017375946045\n",
      "Epoch 338 / 500 | iteration 20 / 30 | Total Loss: 3.4878878593444824 | KNN Loss: 2.4426379203796387 | BCE Loss: 1.0452499389648438\n",
      "Epoch 338 / 500 | iteration 25 / 30 | Total Loss: 3.4351348876953125 | KNN Loss: 2.4266297817230225 | BCE Loss: 1.0085049867630005\n",
      "Epoch   339: reducing learning rate of group 0 to 9.8866e-05.\n",
      "Epoch 339 / 500 | iteration 0 / 30 | Total Loss: 3.441725254058838 | KNN Loss: 2.4249703884124756 | BCE Loss: 1.0167549848556519\n",
      "Epoch 339 / 500 | iteration 5 / 30 | Total Loss: 3.4787631034851074 | KNN Loss: 2.455878257751465 | BCE Loss: 1.0228849649429321\n",
      "Epoch 339 / 500 | iteration 10 / 30 | Total Loss: 3.456740617752075 | KNN Loss: 2.4298863410949707 | BCE Loss: 1.0268542766571045\n",
      "Epoch 339 / 500 | iteration 15 / 30 | Total Loss: 3.4694466590881348 | KNN Loss: 2.4397926330566406 | BCE Loss: 1.0296540260314941\n",
      "Epoch 339 / 500 | iteration 20 / 30 | Total Loss: 3.4861550331115723 | KNN Loss: 2.436173677444458 | BCE Loss: 1.0499814748764038\n",
      "Epoch 339 / 500 | iteration 25 / 30 | Total Loss: 3.4830005168914795 | KNN Loss: 2.468228340148926 | BCE Loss: 1.0147721767425537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340 / 500 | iteration 0 / 30 | Total Loss: 3.4628241062164307 | KNN Loss: 2.450666666030884 | BCE Loss: 1.0121574401855469\n",
      "Epoch 340 / 500 | iteration 5 / 30 | Total Loss: 3.4313652515411377 | KNN Loss: 2.440866231918335 | BCE Loss: 0.9904990196228027\n",
      "Epoch 340 / 500 | iteration 10 / 30 | Total Loss: 3.440450668334961 | KNN Loss: 2.4465572834014893 | BCE Loss: 0.9938932657241821\n",
      "Epoch 340 / 500 | iteration 15 / 30 | Total Loss: 3.4485034942626953 | KNN Loss: 2.4247398376464844 | BCE Loss: 1.0237637758255005\n",
      "Epoch 340 / 500 | iteration 20 / 30 | Total Loss: 3.4983177185058594 | KNN Loss: 2.480395793914795 | BCE Loss: 1.017922043800354\n",
      "Epoch 340 / 500 | iteration 25 / 30 | Total Loss: 3.4470086097717285 | KNN Loss: 2.4370381832122803 | BCE Loss: 1.0099705457687378\n",
      "Epoch 341 / 500 | iteration 0 / 30 | Total Loss: 3.430767774581909 | KNN Loss: 2.416963815689087 | BCE Loss: 1.0138039588928223\n",
      "Epoch 341 / 500 | iteration 5 / 30 | Total Loss: 3.433671712875366 | KNN Loss: 2.4293715953826904 | BCE Loss: 1.0043001174926758\n",
      "Epoch 341 / 500 | iteration 10 / 30 | Total Loss: 3.4735846519470215 | KNN Loss: 2.445469856262207 | BCE Loss: 1.028114676475525\n",
      "Epoch 341 / 500 | iteration 15 / 30 | Total Loss: 3.4629082679748535 | KNN Loss: 2.4602742195129395 | BCE Loss: 1.002634048461914\n",
      "Epoch 341 / 500 | iteration 20 / 30 | Total Loss: 3.43955659866333 | KNN Loss: 2.4437153339385986 | BCE Loss: 0.9958412051200867\n",
      "Epoch 341 / 500 | iteration 25 / 30 | Total Loss: 3.464573621749878 | KNN Loss: 2.4488744735717773 | BCE Loss: 1.0156991481781006\n",
      "Epoch 342 / 500 | iteration 0 / 30 | Total Loss: 3.4518189430236816 | KNN Loss: 2.427640199661255 | BCE Loss: 1.0241787433624268\n",
      "Epoch 342 / 500 | iteration 5 / 30 | Total Loss: 3.479741096496582 | KNN Loss: 2.4787216186523438 | BCE Loss: 1.0010195970535278\n",
      "Epoch 342 / 500 | iteration 10 / 30 | Total Loss: 3.4730725288391113 | KNN Loss: 2.47904634475708 | BCE Loss: 0.9940261840820312\n",
      "Epoch 342 / 500 | iteration 15 / 30 | Total Loss: 3.45212459564209 | KNN Loss: 2.460428476333618 | BCE Loss: 0.9916962385177612\n",
      "Epoch 342 / 500 | iteration 20 / 30 | Total Loss: 3.4711828231811523 | KNN Loss: 2.436295747756958 | BCE Loss: 1.0348870754241943\n",
      "Epoch 342 / 500 | iteration 25 / 30 | Total Loss: 3.4172892570495605 | KNN Loss: 2.4227664470672607 | BCE Loss: 0.9945228099822998\n",
      "Epoch 343 / 500 | iteration 0 / 30 | Total Loss: 3.4828221797943115 | KNN Loss: 2.4392426013946533 | BCE Loss: 1.0435795783996582\n",
      "Epoch 343 / 500 | iteration 5 / 30 | Total Loss: 3.4067764282226562 | KNN Loss: 2.4232583045959473 | BCE Loss: 0.9835180044174194\n",
      "Epoch 343 / 500 | iteration 10 / 30 | Total Loss: 3.471773862838745 | KNN Loss: 2.4753968715667725 | BCE Loss: 0.9963769912719727\n",
      "Epoch 343 / 500 | iteration 15 / 30 | Total Loss: 3.473801612854004 | KNN Loss: 2.448148488998413 | BCE Loss: 1.0256531238555908\n",
      "Epoch 343 / 500 | iteration 20 / 30 | Total Loss: 3.428852081298828 | KNN Loss: 2.417888879776001 | BCE Loss: 1.0109632015228271\n",
      "Epoch 343 / 500 | iteration 25 / 30 | Total Loss: 3.479708671569824 | KNN Loss: 2.4385666847229004 | BCE Loss: 1.0411421060562134\n",
      "Epoch 344 / 500 | iteration 0 / 30 | Total Loss: 3.474856376647949 | KNN Loss: 2.4271838665008545 | BCE Loss: 1.0476725101470947\n",
      "Epoch 344 / 500 | iteration 5 / 30 | Total Loss: 3.4837496280670166 | KNN Loss: 2.469648599624634 | BCE Loss: 1.0141010284423828\n",
      "Epoch 344 / 500 | iteration 10 / 30 | Total Loss: 3.4950878620147705 | KNN Loss: 2.49267840385437 | BCE Loss: 1.0024094581604004\n",
      "Epoch 344 / 500 | iteration 15 / 30 | Total Loss: 3.4826602935791016 | KNN Loss: 2.4369912147521973 | BCE Loss: 1.0456690788269043\n",
      "Epoch 344 / 500 | iteration 20 / 30 | Total Loss: 3.448866605758667 | KNN Loss: 2.4533534049987793 | BCE Loss: 0.9955132007598877\n",
      "Epoch 344 / 500 | iteration 25 / 30 | Total Loss: 3.471243381500244 | KNN Loss: 2.4467356204986572 | BCE Loss: 1.0245076417922974\n",
      "Epoch 345 / 500 | iteration 0 / 30 | Total Loss: 3.433974266052246 | KNN Loss: 2.4233644008636475 | BCE Loss: 1.0106098651885986\n",
      "Epoch 345 / 500 | iteration 5 / 30 | Total Loss: 3.44600772857666 | KNN Loss: 2.4349606037139893 | BCE Loss: 1.0110472440719604\n",
      "Epoch 345 / 500 | iteration 10 / 30 | Total Loss: 3.5277440547943115 | KNN Loss: 2.467292070388794 | BCE Loss: 1.0604519844055176\n",
      "Epoch 345 / 500 | iteration 15 / 30 | Total Loss: 3.450840473175049 | KNN Loss: 2.4373276233673096 | BCE Loss: 1.0135128498077393\n",
      "Epoch 345 / 500 | iteration 20 / 30 | Total Loss: 3.4666709899902344 | KNN Loss: 2.428706169128418 | BCE Loss: 1.0379648208618164\n",
      "Epoch 345 / 500 | iteration 25 / 30 | Total Loss: 3.439716339111328 | KNN Loss: 2.436739921569824 | BCE Loss: 1.002976417541504\n",
      "Epoch 346 / 500 | iteration 0 / 30 | Total Loss: 3.4982333183288574 | KNN Loss: 2.4620163440704346 | BCE Loss: 1.0362169742584229\n",
      "Epoch 346 / 500 | iteration 5 / 30 | Total Loss: 3.4641008377075195 | KNN Loss: 2.4618139266967773 | BCE Loss: 1.0022870302200317\n",
      "Epoch 346 / 500 | iteration 10 / 30 | Total Loss: 3.4750680923461914 | KNN Loss: 2.4503471851348877 | BCE Loss: 1.0247207880020142\n",
      "Epoch 346 / 500 | iteration 15 / 30 | Total Loss: 3.4524285793304443 | KNN Loss: 2.442996025085449 | BCE Loss: 1.0094325542449951\n",
      "Epoch 346 / 500 | iteration 20 / 30 | Total Loss: 3.5060336589813232 | KNN Loss: 2.485658645629883 | BCE Loss: 1.0203750133514404\n",
      "Epoch 346 / 500 | iteration 25 / 30 | Total Loss: 3.4559617042541504 | KNN Loss: 2.439621686935425 | BCE Loss: 1.0163400173187256\n",
      "Epoch 347 / 500 | iteration 0 / 30 | Total Loss: 3.453078269958496 | KNN Loss: 2.433154582977295 | BCE Loss: 1.0199238061904907\n",
      "Epoch 347 / 500 | iteration 5 / 30 | Total Loss: 3.4526760578155518 | KNN Loss: 2.4381296634674072 | BCE Loss: 1.0145463943481445\n",
      "Epoch 347 / 500 | iteration 10 / 30 | Total Loss: 3.4225306510925293 | KNN Loss: 2.427037239074707 | BCE Loss: 0.9954933524131775\n",
      "Epoch 347 / 500 | iteration 15 / 30 | Total Loss: 3.445150375366211 | KNN Loss: 2.4553589820861816 | BCE Loss: 0.9897915124893188\n",
      "Epoch 347 / 500 | iteration 20 / 30 | Total Loss: 3.432790994644165 | KNN Loss: 2.420736312866211 | BCE Loss: 1.012054681777954\n",
      "Epoch 347 / 500 | iteration 25 / 30 | Total Loss: 3.438394069671631 | KNN Loss: 2.414752960205078 | BCE Loss: 1.0236412286758423\n",
      "Epoch 348 / 500 | iteration 0 / 30 | Total Loss: 3.443160057067871 | KNN Loss: 2.437474250793457 | BCE Loss: 1.005685806274414\n",
      "Epoch 348 / 500 | iteration 5 / 30 | Total Loss: 3.4241135120391846 | KNN Loss: 2.421203136444092 | BCE Loss: 1.0029103755950928\n",
      "Epoch 348 / 500 | iteration 10 / 30 | Total Loss: 3.4913601875305176 | KNN Loss: 2.4512779712677 | BCE Loss: 1.0400822162628174\n",
      "Epoch 348 / 500 | iteration 15 / 30 | Total Loss: 3.449042320251465 | KNN Loss: 2.440882682800293 | BCE Loss: 1.0081596374511719\n",
      "Epoch 348 / 500 | iteration 20 / 30 | Total Loss: 3.4414403438568115 | KNN Loss: 2.431540012359619 | BCE Loss: 1.0099003314971924\n",
      "Epoch 348 / 500 | iteration 25 / 30 | Total Loss: 3.448406934738159 | KNN Loss: 2.462433338165283 | BCE Loss: 0.9859736561775208\n",
      "Epoch 349 / 500 | iteration 0 / 30 | Total Loss: 3.466017961502075 | KNN Loss: 2.4586291313171387 | BCE Loss: 1.0073888301849365\n",
      "Epoch 349 / 500 | iteration 5 / 30 | Total Loss: 3.4213614463806152 | KNN Loss: 2.4283857345581055 | BCE Loss: 0.9929755926132202\n",
      "Epoch 349 / 500 | iteration 10 / 30 | Total Loss: 3.4242031574249268 | KNN Loss: 2.413813352584839 | BCE Loss: 1.010389804840088\n",
      "Epoch 349 / 500 | iteration 15 / 30 | Total Loss: 3.46567702293396 | KNN Loss: 2.4633705615997314 | BCE Loss: 1.0023064613342285\n",
      "Epoch 349 / 500 | iteration 20 / 30 | Total Loss: 3.4372425079345703 | KNN Loss: 2.432802200317383 | BCE Loss: 1.0044403076171875\n",
      "Epoch 349 / 500 | iteration 25 / 30 | Total Loss: 3.492198944091797 | KNN Loss: 2.4747915267944336 | BCE Loss: 1.0174074172973633\n",
      "Epoch   350: reducing learning rate of group 0 to 6.9206e-05.\n",
      "Epoch 350 / 500 | iteration 0 / 30 | Total Loss: 3.432305097579956 | KNN Loss: 2.4389891624450684 | BCE Loss: 0.9933158755302429\n",
      "Epoch 350 / 500 | iteration 5 / 30 | Total Loss: 3.46114182472229 | KNN Loss: 2.4493014812469482 | BCE Loss: 1.0118403434753418\n",
      "Epoch 350 / 500 | iteration 10 / 30 | Total Loss: 3.4498062133789062 | KNN Loss: 2.427927255630493 | BCE Loss: 1.021878957748413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 / 500 | iteration 15 / 30 | Total Loss: 3.451826810836792 | KNN Loss: 2.4359049797058105 | BCE Loss: 1.0159218311309814\n",
      "Epoch 350 / 500 | iteration 20 / 30 | Total Loss: 3.4243640899658203 | KNN Loss: 2.4164812564849854 | BCE Loss: 1.007882833480835\n",
      "Epoch 350 / 500 | iteration 25 / 30 | Total Loss: 3.4216995239257812 | KNN Loss: 2.421969175338745 | BCE Loss: 0.9997302889823914\n",
      "Epoch 351 / 500 | iteration 0 / 30 | Total Loss: 3.451133966445923 | KNN Loss: 2.454793691635132 | BCE Loss: 0.996340274810791\n",
      "Epoch 351 / 500 | iteration 5 / 30 | Total Loss: 3.4513702392578125 | KNN Loss: 2.4259397983551025 | BCE Loss: 1.0254305601119995\n",
      "Epoch 351 / 500 | iteration 10 / 30 | Total Loss: 3.4961676597595215 | KNN Loss: 2.4557600021362305 | BCE Loss: 1.040407657623291\n",
      "Epoch 351 / 500 | iteration 15 / 30 | Total Loss: 3.4682564735412598 | KNN Loss: 2.4321274757385254 | BCE Loss: 1.0361289978027344\n",
      "Epoch 351 / 500 | iteration 20 / 30 | Total Loss: 3.4320778846740723 | KNN Loss: 2.4404749870300293 | BCE Loss: 0.9916030168533325\n",
      "Epoch 351 / 500 | iteration 25 / 30 | Total Loss: 3.5110058784484863 | KNN Loss: 2.482496738433838 | BCE Loss: 1.0285090208053589\n",
      "Epoch 352 / 500 | iteration 0 / 30 | Total Loss: 3.4669928550720215 | KNN Loss: 2.467987060546875 | BCE Loss: 0.9990057349205017\n",
      "Epoch 352 / 500 | iteration 5 / 30 | Total Loss: 3.4232804775238037 | KNN Loss: 2.4263815879821777 | BCE Loss: 0.9968988299369812\n",
      "Epoch 352 / 500 | iteration 10 / 30 | Total Loss: 3.4405107498168945 | KNN Loss: 2.433595657348633 | BCE Loss: 1.0069152116775513\n",
      "Epoch 352 / 500 | iteration 15 / 30 | Total Loss: 3.490046977996826 | KNN Loss: 2.4536843299865723 | BCE Loss: 1.036362648010254\n",
      "Epoch 352 / 500 | iteration 20 / 30 | Total Loss: 3.470574140548706 | KNN Loss: 2.473175048828125 | BCE Loss: 0.997399091720581\n",
      "Epoch 352 / 500 | iteration 25 / 30 | Total Loss: 3.4958136081695557 | KNN Loss: 2.480374813079834 | BCE Loss: 1.0154387950897217\n",
      "Epoch 353 / 500 | iteration 0 / 30 | Total Loss: 3.429471015930176 | KNN Loss: 2.42667818069458 | BCE Loss: 1.0027927160263062\n",
      "Epoch 353 / 500 | iteration 5 / 30 | Total Loss: 3.4985079765319824 | KNN Loss: 2.4458136558532715 | BCE Loss: 1.052694320678711\n",
      "Epoch 353 / 500 | iteration 10 / 30 | Total Loss: 3.492466449737549 | KNN Loss: 2.4743411540985107 | BCE Loss: 1.0181251764297485\n",
      "Epoch 353 / 500 | iteration 15 / 30 | Total Loss: 3.4602293968200684 | KNN Loss: 2.4277398586273193 | BCE Loss: 1.0324896574020386\n",
      "Epoch 353 / 500 | iteration 20 / 30 | Total Loss: 3.428318977355957 | KNN Loss: 2.445964813232422 | BCE Loss: 0.9823541641235352\n",
      "Epoch 353 / 500 | iteration 25 / 30 | Total Loss: 3.4739935398101807 | KNN Loss: 2.458237648010254 | BCE Loss: 1.0157558917999268\n",
      "Epoch 354 / 500 | iteration 0 / 30 | Total Loss: 3.4684908390045166 | KNN Loss: 2.464240550994873 | BCE Loss: 1.0042502880096436\n",
      "Epoch 354 / 500 | iteration 5 / 30 | Total Loss: 3.4465460777282715 | KNN Loss: 2.4447782039642334 | BCE Loss: 1.0017677545547485\n",
      "Epoch 354 / 500 | iteration 10 / 30 | Total Loss: 3.461468458175659 | KNN Loss: 2.4592459201812744 | BCE Loss: 1.0022225379943848\n",
      "Epoch 354 / 500 | iteration 15 / 30 | Total Loss: 3.4206533432006836 | KNN Loss: 2.424128532409668 | BCE Loss: 0.9965248703956604\n",
      "Epoch 354 / 500 | iteration 20 / 30 | Total Loss: 3.455502510070801 | KNN Loss: 2.4471919536590576 | BCE Loss: 1.0083105564117432\n",
      "Epoch 354 / 500 | iteration 25 / 30 | Total Loss: 3.455392360687256 | KNN Loss: 2.433018922805786 | BCE Loss: 1.0223734378814697\n",
      "Epoch 355 / 500 | iteration 0 / 30 | Total Loss: 3.4469361305236816 | KNN Loss: 2.4632506370544434 | BCE Loss: 0.9836856126785278\n",
      "Epoch 355 / 500 | iteration 5 / 30 | Total Loss: 3.5239033699035645 | KNN Loss: 2.4792239665985107 | BCE Loss: 1.0446794033050537\n",
      "Epoch 355 / 500 | iteration 10 / 30 | Total Loss: 3.4777164459228516 | KNN Loss: 2.4907026290893555 | BCE Loss: 0.9870138168334961\n",
      "Epoch 355 / 500 | iteration 15 / 30 | Total Loss: 3.427683115005493 | KNN Loss: 2.411740303039551 | BCE Loss: 1.0159428119659424\n",
      "Epoch 355 / 500 | iteration 20 / 30 | Total Loss: 3.464082956314087 | KNN Loss: 2.4601995944976807 | BCE Loss: 1.0038833618164062\n",
      "Epoch 355 / 500 | iteration 25 / 30 | Total Loss: 3.4610683917999268 | KNN Loss: 2.4284698963165283 | BCE Loss: 1.0325984954833984\n",
      "Epoch 356 / 500 | iteration 0 / 30 | Total Loss: 3.4506337642669678 | KNN Loss: 2.4322547912597656 | BCE Loss: 1.0183789730072021\n",
      "Epoch 356 / 500 | iteration 5 / 30 | Total Loss: 3.4518933296203613 | KNN Loss: 2.4325013160705566 | BCE Loss: 1.0193918943405151\n",
      "Epoch 356 / 500 | iteration 10 / 30 | Total Loss: 3.3849287033081055 | KNN Loss: 2.4070823192596436 | BCE Loss: 0.9778465032577515\n",
      "Epoch 356 / 500 | iteration 15 / 30 | Total Loss: 3.513979434967041 | KNN Loss: 2.4849367141723633 | BCE Loss: 1.0290427207946777\n",
      "Epoch 356 / 500 | iteration 20 / 30 | Total Loss: 3.4659500122070312 | KNN Loss: 2.4467499256134033 | BCE Loss: 1.0191999673843384\n",
      "Epoch 356 / 500 | iteration 25 / 30 | Total Loss: 3.4505791664123535 | KNN Loss: 2.439516305923462 | BCE Loss: 1.011062741279602\n",
      "Epoch 357 / 500 | iteration 0 / 30 | Total Loss: 3.4305319786071777 | KNN Loss: 2.4269514083862305 | BCE Loss: 1.0035804510116577\n",
      "Epoch 357 / 500 | iteration 5 / 30 | Total Loss: 3.440427541732788 | KNN Loss: 2.4305055141448975 | BCE Loss: 1.0099220275878906\n",
      "Epoch 357 / 500 | iteration 10 / 30 | Total Loss: 3.457634210586548 | KNN Loss: 2.4357688426971436 | BCE Loss: 1.0218653678894043\n",
      "Epoch 357 / 500 | iteration 15 / 30 | Total Loss: 3.476816177368164 | KNN Loss: 2.4280340671539307 | BCE Loss: 1.048782229423523\n",
      "Epoch 357 / 500 | iteration 20 / 30 | Total Loss: 3.4083070755004883 | KNN Loss: 2.4389431476593018 | BCE Loss: 0.9693639278411865\n",
      "Epoch 357 / 500 | iteration 25 / 30 | Total Loss: 3.455270528793335 | KNN Loss: 2.4469687938690186 | BCE Loss: 1.0083017349243164\n",
      "Epoch 358 / 500 | iteration 0 / 30 | Total Loss: 3.4301156997680664 | KNN Loss: 2.403947353363037 | BCE Loss: 1.0261684656143188\n",
      "Epoch 358 / 500 | iteration 5 / 30 | Total Loss: 3.4843082427978516 | KNN Loss: 2.46144962310791 | BCE Loss: 1.022858738899231\n",
      "Epoch 358 / 500 | iteration 10 / 30 | Total Loss: 3.466470956802368 | KNN Loss: 2.431581735610962 | BCE Loss: 1.0348892211914062\n",
      "Epoch 358 / 500 | iteration 15 / 30 | Total Loss: 3.452080011367798 | KNN Loss: 2.4328556060791016 | BCE Loss: 1.0192244052886963\n",
      "Epoch 358 / 500 | iteration 20 / 30 | Total Loss: 3.4681756496429443 | KNN Loss: 2.4418861865997314 | BCE Loss: 1.026289463043213\n",
      "Epoch 358 / 500 | iteration 25 / 30 | Total Loss: 3.462337017059326 | KNN Loss: 2.452113151550293 | BCE Loss: 1.0102237462997437\n",
      "Epoch 359 / 500 | iteration 0 / 30 | Total Loss: 3.4494810104370117 | KNN Loss: 2.4426403045654297 | BCE Loss: 1.006840705871582\n",
      "Epoch 359 / 500 | iteration 5 / 30 | Total Loss: 3.4546048641204834 | KNN Loss: 2.4577314853668213 | BCE Loss: 0.9968733191490173\n",
      "Epoch 359 / 500 | iteration 10 / 30 | Total Loss: 3.4754798412323 | KNN Loss: 2.4538848400115967 | BCE Loss: 1.0215950012207031\n",
      "Epoch 359 / 500 | iteration 15 / 30 | Total Loss: 3.4548497200012207 | KNN Loss: 2.4440455436706543 | BCE Loss: 1.010804295539856\n",
      "Epoch 359 / 500 | iteration 20 / 30 | Total Loss: 3.5031142234802246 | KNN Loss: 2.455045700073242 | BCE Loss: 1.0480685234069824\n",
      "Epoch 359 / 500 | iteration 25 / 30 | Total Loss: 3.492293119430542 | KNN Loss: 2.4844281673431396 | BCE Loss: 1.0078649520874023\n",
      "Epoch 360 / 500 | iteration 0 / 30 | Total Loss: 3.4476003646850586 | KNN Loss: 2.443206310272217 | BCE Loss: 1.0043940544128418\n",
      "Epoch 360 / 500 | iteration 5 / 30 | Total Loss: 3.474496603012085 | KNN Loss: 2.4654948711395264 | BCE Loss: 1.0090017318725586\n",
      "Epoch 360 / 500 | iteration 10 / 30 | Total Loss: 3.5026540756225586 | KNN Loss: 2.490083694458008 | BCE Loss: 1.0125702619552612\n",
      "Epoch 360 / 500 | iteration 15 / 30 | Total Loss: 3.478264570236206 | KNN Loss: 2.4827139377593994 | BCE Loss: 0.9955505728721619\n",
      "Epoch 360 / 500 | iteration 20 / 30 | Total Loss: 3.47774600982666 | KNN Loss: 2.4715375900268555 | BCE Loss: 1.0062083005905151\n",
      "Epoch 360 / 500 | iteration 25 / 30 | Total Loss: 3.475910186767578 | KNN Loss: 2.4470009803771973 | BCE Loss: 1.0289092063903809\n",
      "Epoch   361: reducing learning rate of group 0 to 4.8445e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361 / 500 | iteration 0 / 30 | Total Loss: 3.4307641983032227 | KNN Loss: 2.4071671962738037 | BCE Loss: 1.0235971212387085\n",
      "Epoch 361 / 500 | iteration 5 / 30 | Total Loss: 3.4367942810058594 | KNN Loss: 2.428792953491211 | BCE Loss: 1.0080012083053589\n",
      "Epoch 361 / 500 | iteration 10 / 30 | Total Loss: 3.4668169021606445 | KNN Loss: 2.4456634521484375 | BCE Loss: 1.0211533308029175\n",
      "Epoch 361 / 500 | iteration 15 / 30 | Total Loss: 3.473691940307617 | KNN Loss: 2.4372177124023438 | BCE Loss: 1.0364742279052734\n",
      "Epoch 361 / 500 | iteration 20 / 30 | Total Loss: 3.4736852645874023 | KNN Loss: 2.481696128845215 | BCE Loss: 0.991989254951477\n",
      "Epoch 361 / 500 | iteration 25 / 30 | Total Loss: 3.4969851970672607 | KNN Loss: 2.4619152545928955 | BCE Loss: 1.0350699424743652\n",
      "Epoch 362 / 500 | iteration 0 / 30 | Total Loss: 3.4558610916137695 | KNN Loss: 2.4420931339263916 | BCE Loss: 1.013767957687378\n",
      "Epoch 362 / 500 | iteration 5 / 30 | Total Loss: 3.4741268157958984 | KNN Loss: 2.4822916984558105 | BCE Loss: 0.9918351769447327\n",
      "Epoch 362 / 500 | iteration 10 / 30 | Total Loss: 3.4642155170440674 | KNN Loss: 2.4514875411987305 | BCE Loss: 1.012727975845337\n",
      "Epoch 362 / 500 | iteration 15 / 30 | Total Loss: 3.4800121784210205 | KNN Loss: 2.475410223007202 | BCE Loss: 1.0046019554138184\n",
      "Epoch 362 / 500 | iteration 20 / 30 | Total Loss: 3.4589297771453857 | KNN Loss: 2.4474644660949707 | BCE Loss: 1.011465311050415\n",
      "Epoch 362 / 500 | iteration 25 / 30 | Total Loss: 3.4528896808624268 | KNN Loss: 2.444941997528076 | BCE Loss: 1.0079476833343506\n",
      "Epoch 363 / 500 | iteration 0 / 30 | Total Loss: 3.471011161804199 | KNN Loss: 2.4680731296539307 | BCE Loss: 1.0029380321502686\n",
      "Epoch 363 / 500 | iteration 5 / 30 | Total Loss: 3.474490165710449 | KNN Loss: 2.4979817867279053 | BCE Loss: 0.976508378982544\n",
      "Epoch 363 / 500 | iteration 10 / 30 | Total Loss: 3.4716978073120117 | KNN Loss: 2.44500470161438 | BCE Loss: 1.0266929864883423\n",
      "Epoch 363 / 500 | iteration 15 / 30 | Total Loss: 3.444248914718628 | KNN Loss: 2.430283308029175 | BCE Loss: 1.0139656066894531\n",
      "Epoch 363 / 500 | iteration 20 / 30 | Total Loss: 3.4601097106933594 | KNN Loss: 2.434757709503174 | BCE Loss: 1.025352120399475\n",
      "Epoch 363 / 500 | iteration 25 / 30 | Total Loss: 3.466183662414551 | KNN Loss: 2.459320068359375 | BCE Loss: 1.0068637132644653\n",
      "Epoch 364 / 500 | iteration 0 / 30 | Total Loss: 3.4409334659576416 | KNN Loss: 2.4440503120422363 | BCE Loss: 0.9968831539154053\n",
      "Epoch 364 / 500 | iteration 5 / 30 | Total Loss: 3.392488479614258 | KNN Loss: 2.4116342067718506 | BCE Loss: 0.9808541536331177\n",
      "Epoch 364 / 500 | iteration 10 / 30 | Total Loss: 3.488598346710205 | KNN Loss: 2.4512641429901123 | BCE Loss: 1.0373343229293823\n",
      "Epoch 364 / 500 | iteration 15 / 30 | Total Loss: 3.4647207260131836 | KNN Loss: 2.4313530921936035 | BCE Loss: 1.03336763381958\n",
      "Epoch 364 / 500 | iteration 20 / 30 | Total Loss: 3.465930461883545 | KNN Loss: 2.4635510444641113 | BCE Loss: 1.0023794174194336\n",
      "Epoch 364 / 500 | iteration 25 / 30 | Total Loss: 3.4840056896209717 | KNN Loss: 2.452265977859497 | BCE Loss: 1.0317397117614746\n",
      "Epoch 365 / 500 | iteration 0 / 30 | Total Loss: 3.4724607467651367 | KNN Loss: 2.457197666168213 | BCE Loss: 1.0152631998062134\n",
      "Epoch 365 / 500 | iteration 5 / 30 | Total Loss: 3.4923558235168457 | KNN Loss: 2.469360113143921 | BCE Loss: 1.0229955911636353\n",
      "Epoch 365 / 500 | iteration 10 / 30 | Total Loss: 3.4494709968566895 | KNN Loss: 2.4385242462158203 | BCE Loss: 1.0109467506408691\n",
      "Epoch 365 / 500 | iteration 15 / 30 | Total Loss: 3.4293479919433594 | KNN Loss: 2.4307494163513184 | BCE Loss: 0.9985986948013306\n",
      "Epoch 365 / 500 | iteration 20 / 30 | Total Loss: 3.4668450355529785 | KNN Loss: 2.467693328857422 | BCE Loss: 0.9991518259048462\n",
      "Epoch 365 / 500 | iteration 25 / 30 | Total Loss: 3.443653106689453 | KNN Loss: 2.42793869972229 | BCE Loss: 1.015714406967163\n",
      "Epoch 366 / 500 | iteration 0 / 30 | Total Loss: 3.484264612197876 | KNN Loss: 2.445084571838379 | BCE Loss: 1.039180040359497\n",
      "Epoch 366 / 500 | iteration 5 / 30 | Total Loss: 3.4569296836853027 | KNN Loss: 2.452479362487793 | BCE Loss: 1.0044503211975098\n",
      "Epoch 366 / 500 | iteration 10 / 30 | Total Loss: 3.4396209716796875 | KNN Loss: 2.4321281909942627 | BCE Loss: 1.0074927806854248\n",
      "Epoch 366 / 500 | iteration 15 / 30 | Total Loss: 3.437262773513794 | KNN Loss: 2.4430041313171387 | BCE Loss: 0.9942586421966553\n",
      "Epoch 366 / 500 | iteration 20 / 30 | Total Loss: 3.4959211349487305 | KNN Loss: 2.4873297214508057 | BCE Loss: 1.0085912942886353\n",
      "Epoch 366 / 500 | iteration 25 / 30 | Total Loss: 3.4727070331573486 | KNN Loss: 2.467674493789673 | BCE Loss: 1.0050325393676758\n",
      "Epoch 367 / 500 | iteration 0 / 30 | Total Loss: 3.4878270626068115 | KNN Loss: 2.471937417984009 | BCE Loss: 1.0158896446228027\n",
      "Epoch 367 / 500 | iteration 5 / 30 | Total Loss: 3.48113751411438 | KNN Loss: 2.462183713912964 | BCE Loss: 1.018953800201416\n",
      "Epoch 367 / 500 | iteration 10 / 30 | Total Loss: 3.4385523796081543 | KNN Loss: 2.4297728538513184 | BCE Loss: 1.008779525756836\n",
      "Epoch 367 / 500 | iteration 15 / 30 | Total Loss: 3.492232322692871 | KNN Loss: 2.4829165935516357 | BCE Loss: 1.009315848350525\n",
      "Epoch 367 / 500 | iteration 20 / 30 | Total Loss: 3.4523448944091797 | KNN Loss: 2.446744203567505 | BCE Loss: 1.0056006908416748\n",
      "Epoch 367 / 500 | iteration 25 / 30 | Total Loss: 3.4682114124298096 | KNN Loss: 2.4642996788024902 | BCE Loss: 1.0039117336273193\n",
      "Epoch 368 / 500 | iteration 0 / 30 | Total Loss: 3.420599937438965 | KNN Loss: 2.427748680114746 | BCE Loss: 0.9928513765335083\n",
      "Epoch 368 / 500 | iteration 5 / 30 | Total Loss: 3.44386625289917 | KNN Loss: 2.4435670375823975 | BCE Loss: 1.0002992153167725\n",
      "Epoch 368 / 500 | iteration 10 / 30 | Total Loss: 3.4218316078186035 | KNN Loss: 2.427170991897583 | BCE Loss: 0.9946607351303101\n",
      "Epoch 368 / 500 | iteration 15 / 30 | Total Loss: 3.4706475734710693 | KNN Loss: 2.4706122875213623 | BCE Loss: 1.000035285949707\n",
      "Epoch 368 / 500 | iteration 20 / 30 | Total Loss: 3.465940475463867 | KNN Loss: 2.4300129413604736 | BCE Loss: 1.0359275341033936\n",
      "Epoch 368 / 500 | iteration 25 / 30 | Total Loss: 3.519864082336426 | KNN Loss: 2.5083961486816406 | BCE Loss: 1.0114679336547852\n",
      "Epoch 369 / 500 | iteration 0 / 30 | Total Loss: 3.453425168991089 | KNN Loss: 2.4291858673095703 | BCE Loss: 1.0242393016815186\n",
      "Epoch 369 / 500 | iteration 5 / 30 | Total Loss: 3.424525737762451 | KNN Loss: 2.4516119956970215 | BCE Loss: 0.9729136228561401\n",
      "Epoch 369 / 500 | iteration 10 / 30 | Total Loss: 3.451296806335449 | KNN Loss: 2.451629638671875 | BCE Loss: 0.9996672868728638\n",
      "Epoch 369 / 500 | iteration 15 / 30 | Total Loss: 3.5093770027160645 | KNN Loss: 2.4569027423858643 | BCE Loss: 1.0524742603302002\n",
      "Epoch 369 / 500 | iteration 20 / 30 | Total Loss: 3.480555295944214 | KNN Loss: 2.472532272338867 | BCE Loss: 1.0080230236053467\n",
      "Epoch 369 / 500 | iteration 25 / 30 | Total Loss: 3.4350550174713135 | KNN Loss: 2.4257984161376953 | BCE Loss: 1.0092566013336182\n",
      "Epoch 370 / 500 | iteration 0 / 30 | Total Loss: 3.4724857807159424 | KNN Loss: 2.462678909301758 | BCE Loss: 1.0098068714141846\n",
      "Epoch 370 / 500 | iteration 5 / 30 | Total Loss: 3.4719676971435547 | KNN Loss: 2.4516446590423584 | BCE Loss: 1.0203231573104858\n",
      "Epoch 370 / 500 | iteration 10 / 30 | Total Loss: 3.4383702278137207 | KNN Loss: 2.429931163787842 | BCE Loss: 1.0084391832351685\n",
      "Epoch 370 / 500 | iteration 15 / 30 | Total Loss: 3.468507766723633 | KNN Loss: 2.4777791500091553 | BCE Loss: 0.9907286167144775\n",
      "Epoch 370 / 500 | iteration 20 / 30 | Total Loss: 3.5102009773254395 | KNN Loss: 2.485414981842041 | BCE Loss: 1.024786114692688\n",
      "Epoch 370 / 500 | iteration 25 / 30 | Total Loss: 3.458137035369873 | KNN Loss: 2.4382357597351074 | BCE Loss: 1.0199012756347656\n",
      "Epoch 371 / 500 | iteration 0 / 30 | Total Loss: 3.456531524658203 | KNN Loss: 2.4385342597961426 | BCE Loss: 1.0179972648620605\n",
      "Epoch 371 / 500 | iteration 5 / 30 | Total Loss: 3.4623825550079346 | KNN Loss: 2.4740569591522217 | BCE Loss: 0.9883255362510681\n",
      "Epoch 371 / 500 | iteration 10 / 30 | Total Loss: 3.4337432384490967 | KNN Loss: 2.4415993690490723 | BCE Loss: 0.9921438694000244\n",
      "Epoch 371 / 500 | iteration 15 / 30 | Total Loss: 3.3944036960601807 | KNN Loss: 2.421194553375244 | BCE Loss: 0.9732091426849365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371 / 500 | iteration 20 / 30 | Total Loss: 3.45676851272583 | KNN Loss: 2.422055721282959 | BCE Loss: 1.0347126722335815\n",
      "Epoch 371 / 500 | iteration 25 / 30 | Total Loss: 3.452685832977295 | KNN Loss: 2.4204068183898926 | BCE Loss: 1.0322790145874023\n",
      "Epoch   372: reducing learning rate of group 0 to 3.3911e-05.\n",
      "Epoch 372 / 500 | iteration 0 / 30 | Total Loss: 3.456789493560791 | KNN Loss: 2.434203863143921 | BCE Loss: 1.0225855112075806\n",
      "Epoch 372 / 500 | iteration 5 / 30 | Total Loss: 3.464006185531616 | KNN Loss: 2.4412076473236084 | BCE Loss: 1.0227985382080078\n",
      "Epoch 372 / 500 | iteration 10 / 30 | Total Loss: 3.4395852088928223 | KNN Loss: 2.4570276737213135 | BCE Loss: 0.9825576543807983\n",
      "Epoch 372 / 500 | iteration 15 / 30 | Total Loss: 3.465245246887207 | KNN Loss: 2.460357189178467 | BCE Loss: 1.0048880577087402\n",
      "Epoch 372 / 500 | iteration 20 / 30 | Total Loss: 3.4620110988616943 | KNN Loss: 2.4449644088745117 | BCE Loss: 1.0170466899871826\n",
      "Epoch 372 / 500 | iteration 25 / 30 | Total Loss: 3.4835474491119385 | KNN Loss: 2.468900442123413 | BCE Loss: 1.0146470069885254\n",
      "Epoch 373 / 500 | iteration 0 / 30 | Total Loss: 3.4405407905578613 | KNN Loss: 2.430020332336426 | BCE Loss: 1.010520577430725\n",
      "Epoch 373 / 500 | iteration 5 / 30 | Total Loss: 3.481417655944824 | KNN Loss: 2.4508121013641357 | BCE Loss: 1.0306055545806885\n",
      "Epoch 373 / 500 | iteration 10 / 30 | Total Loss: 3.4236955642700195 | KNN Loss: 2.4242165088653564 | BCE Loss: 0.9994791746139526\n",
      "Epoch 373 / 500 | iteration 15 / 30 | Total Loss: 3.463322162628174 | KNN Loss: 2.436527967453003 | BCE Loss: 1.0267940759658813\n",
      "Epoch 373 / 500 | iteration 20 / 30 | Total Loss: 3.483619213104248 | KNN Loss: 2.4777143001556396 | BCE Loss: 1.0059049129486084\n",
      "Epoch 373 / 500 | iteration 25 / 30 | Total Loss: 3.4487242698669434 | KNN Loss: 2.445384979248047 | BCE Loss: 1.003339409828186\n",
      "Epoch 374 / 500 | iteration 0 / 30 | Total Loss: 3.4798390865325928 | KNN Loss: 2.4489846229553223 | BCE Loss: 1.0308544635772705\n",
      "Epoch 374 / 500 | iteration 5 / 30 | Total Loss: 3.4320249557495117 | KNN Loss: 2.414119243621826 | BCE Loss: 1.017905592918396\n",
      "Epoch 374 / 500 | iteration 10 / 30 | Total Loss: 3.4561257362365723 | KNN Loss: 2.442486047744751 | BCE Loss: 1.0136396884918213\n",
      "Epoch 374 / 500 | iteration 15 / 30 | Total Loss: 3.427375555038452 | KNN Loss: 2.432450532913208 | BCE Loss: 0.9949250817298889\n",
      "Epoch 374 / 500 | iteration 20 / 30 | Total Loss: 3.4372849464416504 | KNN Loss: 2.4229228496551514 | BCE Loss: 1.014362096786499\n",
      "Epoch 374 / 500 | iteration 25 / 30 | Total Loss: 3.478461742401123 | KNN Loss: 2.459120512008667 | BCE Loss: 1.019341230392456\n",
      "Epoch 375 / 500 | iteration 0 / 30 | Total Loss: 3.483135223388672 | KNN Loss: 2.458540916442871 | BCE Loss: 1.0245944261550903\n",
      "Epoch 375 / 500 | iteration 5 / 30 | Total Loss: 3.461832046508789 | KNN Loss: 2.4325153827667236 | BCE Loss: 1.029316782951355\n",
      "Epoch 375 / 500 | iteration 10 / 30 | Total Loss: 3.4445598125457764 | KNN Loss: 2.4367854595184326 | BCE Loss: 1.0077743530273438\n",
      "Epoch 375 / 500 | iteration 15 / 30 | Total Loss: 3.5049424171447754 | KNN Loss: 2.489826202392578 | BCE Loss: 1.0151162147521973\n",
      "Epoch 375 / 500 | iteration 20 / 30 | Total Loss: 3.485539436340332 | KNN Loss: 2.4522433280944824 | BCE Loss: 1.0332962274551392\n",
      "Epoch 375 / 500 | iteration 25 / 30 | Total Loss: 3.4622538089752197 | KNN Loss: 2.435821294784546 | BCE Loss: 1.0264325141906738\n",
      "Epoch 376 / 500 | iteration 0 / 30 | Total Loss: 3.4243316650390625 | KNN Loss: 2.4401888847351074 | BCE Loss: 0.9841427803039551\n",
      "Epoch 376 / 500 | iteration 5 / 30 | Total Loss: 3.4245147705078125 | KNN Loss: 2.415221929550171 | BCE Loss: 1.009292721748352\n",
      "Epoch 376 / 500 | iteration 10 / 30 | Total Loss: 3.4518861770629883 | KNN Loss: 2.4327008724212646 | BCE Loss: 1.019185185432434\n",
      "Epoch 376 / 500 | iteration 15 / 30 | Total Loss: 3.4527981281280518 | KNN Loss: 2.4179954528808594 | BCE Loss: 1.0348026752471924\n",
      "Epoch 376 / 500 | iteration 20 / 30 | Total Loss: 3.478679656982422 | KNN Loss: 2.4596002101898193 | BCE Loss: 1.019079566001892\n",
      "Epoch 376 / 500 | iteration 25 / 30 | Total Loss: 3.4534072875976562 | KNN Loss: 2.4578826427459717 | BCE Loss: 0.9955246448516846\n",
      "Epoch 377 / 500 | iteration 0 / 30 | Total Loss: 3.454145908355713 | KNN Loss: 2.4388768672943115 | BCE Loss: 1.0152690410614014\n",
      "Epoch 377 / 500 | iteration 5 / 30 | Total Loss: 3.443587303161621 | KNN Loss: 2.42510986328125 | BCE Loss: 1.0184773206710815\n",
      "Epoch 377 / 500 | iteration 10 / 30 | Total Loss: 3.424431800842285 | KNN Loss: 2.4086525440216064 | BCE Loss: 1.0157793760299683\n",
      "Epoch 377 / 500 | iteration 15 / 30 | Total Loss: 3.4638240337371826 | KNN Loss: 2.446075439453125 | BCE Loss: 1.0177485942840576\n",
      "Epoch 377 / 500 | iteration 20 / 30 | Total Loss: 3.451578378677368 | KNN Loss: 2.4244163036346436 | BCE Loss: 1.0271620750427246\n",
      "Epoch 377 / 500 | iteration 25 / 30 | Total Loss: 3.464695453643799 | KNN Loss: 2.4435317516326904 | BCE Loss: 1.0211637020111084\n",
      "Epoch 378 / 500 | iteration 0 / 30 | Total Loss: 3.432281732559204 | KNN Loss: 2.420441150665283 | BCE Loss: 1.011840581893921\n",
      "Epoch 378 / 500 | iteration 5 / 30 | Total Loss: 3.430824041366577 | KNN Loss: 2.411830186843872 | BCE Loss: 1.018993854522705\n",
      "Epoch 378 / 500 | iteration 10 / 30 | Total Loss: 3.4262051582336426 | KNN Loss: 2.419255495071411 | BCE Loss: 1.0069496631622314\n",
      "Epoch 378 / 500 | iteration 15 / 30 | Total Loss: 3.5192439556121826 | KNN Loss: 2.4853897094726562 | BCE Loss: 1.0338542461395264\n",
      "Epoch 378 / 500 | iteration 20 / 30 | Total Loss: 3.4801251888275146 | KNN Loss: 2.476896047592163 | BCE Loss: 1.0032291412353516\n",
      "Epoch 378 / 500 | iteration 25 / 30 | Total Loss: 3.475459337234497 | KNN Loss: 2.4686224460601807 | BCE Loss: 1.0068368911743164\n",
      "Epoch 379 / 500 | iteration 0 / 30 | Total Loss: 3.479766607284546 | KNN Loss: 2.4615511894226074 | BCE Loss: 1.0182154178619385\n",
      "Epoch 379 / 500 | iteration 5 / 30 | Total Loss: 3.4365458488464355 | KNN Loss: 2.462383985519409 | BCE Loss: 0.9741617441177368\n",
      "Epoch 379 / 500 | iteration 10 / 30 | Total Loss: 3.4565508365631104 | KNN Loss: 2.4498472213745117 | BCE Loss: 1.0067036151885986\n",
      "Epoch 379 / 500 | iteration 15 / 30 | Total Loss: 3.4546914100646973 | KNN Loss: 2.405534267425537 | BCE Loss: 1.0491570234298706\n",
      "Epoch 379 / 500 | iteration 20 / 30 | Total Loss: 3.4587323665618896 | KNN Loss: 2.470766544342041 | BCE Loss: 0.9879657626152039\n",
      "Epoch 379 / 500 | iteration 25 / 30 | Total Loss: 3.429539918899536 | KNN Loss: 2.4230635166168213 | BCE Loss: 1.0064764022827148\n",
      "Epoch 380 / 500 | iteration 0 / 30 | Total Loss: 3.373920440673828 | KNN Loss: 2.404886484146118 | BCE Loss: 0.9690338969230652\n",
      "Epoch 380 / 500 | iteration 5 / 30 | Total Loss: 3.4445505142211914 | KNN Loss: 2.4329450130462646 | BCE Loss: 1.0116055011749268\n",
      "Epoch 380 / 500 | iteration 10 / 30 | Total Loss: 3.466014862060547 | KNN Loss: 2.461038112640381 | BCE Loss: 1.004976749420166\n",
      "Epoch 380 / 500 | iteration 15 / 30 | Total Loss: 3.483757734298706 | KNN Loss: 2.486220121383667 | BCE Loss: 0.9975376129150391\n",
      "Epoch 380 / 500 | iteration 20 / 30 | Total Loss: 3.448263645172119 | KNN Loss: 2.453312397003174 | BCE Loss: 0.9949513077735901\n",
      "Epoch 380 / 500 | iteration 25 / 30 | Total Loss: 3.4413599967956543 | KNN Loss: 2.4315898418426514 | BCE Loss: 1.0097702741622925\n",
      "Epoch 381 / 500 | iteration 0 / 30 | Total Loss: 3.428853988647461 | KNN Loss: 2.417212724685669 | BCE Loss: 1.011641263961792\n",
      "Epoch 381 / 500 | iteration 5 / 30 | Total Loss: 3.465325117111206 | KNN Loss: 2.445502519607544 | BCE Loss: 1.019822597503662\n",
      "Epoch 381 / 500 | iteration 10 / 30 | Total Loss: 3.447505474090576 | KNN Loss: 2.4313173294067383 | BCE Loss: 1.016188144683838\n",
      "Epoch 381 / 500 | iteration 15 / 30 | Total Loss: 3.447592258453369 | KNN Loss: 2.438100576400757 | BCE Loss: 1.0094916820526123\n",
      "Epoch 381 / 500 | iteration 20 / 30 | Total Loss: 3.4506592750549316 | KNN Loss: 2.4278926849365234 | BCE Loss: 1.0227664709091187\n",
      "Epoch 381 / 500 | iteration 25 / 30 | Total Loss: 3.4668641090393066 | KNN Loss: 2.4361531734466553 | BCE Loss: 1.0307109355926514\n",
      "Epoch 382 / 500 | iteration 0 / 30 | Total Loss: 3.5093507766723633 | KNN Loss: 2.4769601821899414 | BCE Loss: 1.0323905944824219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382 / 500 | iteration 5 / 30 | Total Loss: 3.4356589317321777 | KNN Loss: 2.4302480220794678 | BCE Loss: 1.0054107904434204\n",
      "Epoch 382 / 500 | iteration 10 / 30 | Total Loss: 3.4638590812683105 | KNN Loss: 2.4563090801239014 | BCE Loss: 1.0075498819351196\n",
      "Epoch 382 / 500 | iteration 15 / 30 | Total Loss: 3.4861347675323486 | KNN Loss: 2.4605329036712646 | BCE Loss: 1.025601863861084\n",
      "Epoch 382 / 500 | iteration 20 / 30 | Total Loss: 3.49409556388855 | KNN Loss: 2.462716579437256 | BCE Loss: 1.031378984451294\n",
      "Epoch 382 / 500 | iteration 25 / 30 | Total Loss: 3.4988198280334473 | KNN Loss: 2.4902713298797607 | BCE Loss: 1.008548378944397\n",
      "Epoch   383: reducing learning rate of group 0 to 2.3738e-05.\n",
      "Epoch 383 / 500 | iteration 0 / 30 | Total Loss: 3.426450252532959 | KNN Loss: 2.4382364749908447 | BCE Loss: 0.9882137775421143\n",
      "Epoch 383 / 500 | iteration 5 / 30 | Total Loss: 3.465665578842163 | KNN Loss: 2.4518051147460938 | BCE Loss: 1.0138604640960693\n",
      "Epoch 383 / 500 | iteration 10 / 30 | Total Loss: 3.4218533039093018 | KNN Loss: 2.4331607818603516 | BCE Loss: 0.9886925220489502\n",
      "Epoch 383 / 500 | iteration 15 / 30 | Total Loss: 3.422013998031616 | KNN Loss: 2.4171102046966553 | BCE Loss: 1.004903793334961\n",
      "Epoch 383 / 500 | iteration 20 / 30 | Total Loss: 3.450016736984253 | KNN Loss: 2.444833517074585 | BCE Loss: 1.005183219909668\n",
      "Epoch 383 / 500 | iteration 25 / 30 | Total Loss: 3.4514622688293457 | KNN Loss: 2.4266865253448486 | BCE Loss: 1.0247758626937866\n",
      "Epoch 384 / 500 | iteration 0 / 30 | Total Loss: 3.4338183403015137 | KNN Loss: 2.432652235031128 | BCE Loss: 1.0011662244796753\n",
      "Epoch 384 / 500 | iteration 5 / 30 | Total Loss: 3.4889843463897705 | KNN Loss: 2.4837329387664795 | BCE Loss: 1.005251407623291\n",
      "Epoch 384 / 500 | iteration 10 / 30 | Total Loss: 3.50260853767395 | KNN Loss: 2.473046064376831 | BCE Loss: 1.0295624732971191\n",
      "Epoch 384 / 500 | iteration 15 / 30 | Total Loss: 3.421745777130127 | KNN Loss: 2.399711847305298 | BCE Loss: 1.022033929824829\n",
      "Epoch 384 / 500 | iteration 20 / 30 | Total Loss: 3.494694709777832 | KNN Loss: 2.4498562812805176 | BCE Loss: 1.0448384284973145\n",
      "Epoch 384 / 500 | iteration 25 / 30 | Total Loss: 3.418401002883911 | KNN Loss: 2.419922113418579 | BCE Loss: 0.998478889465332\n",
      "Epoch 385 / 500 | iteration 0 / 30 | Total Loss: 3.4250221252441406 | KNN Loss: 2.420346975326538 | BCE Loss: 1.0046751499176025\n",
      "Epoch 385 / 500 | iteration 5 / 30 | Total Loss: 3.474243640899658 | KNN Loss: 2.4470701217651367 | BCE Loss: 1.0271735191345215\n",
      "Epoch 385 / 500 | iteration 10 / 30 | Total Loss: 3.5198657512664795 | KNN Loss: 2.474637269973755 | BCE Loss: 1.0452284812927246\n",
      "Epoch 385 / 500 | iteration 15 / 30 | Total Loss: 3.4351062774658203 | KNN Loss: 2.4161412715911865 | BCE Loss: 1.0189648866653442\n",
      "Epoch 385 / 500 | iteration 20 / 30 | Total Loss: 3.4664173126220703 | KNN Loss: 2.4729456901550293 | BCE Loss: 0.9934717416763306\n",
      "Epoch 385 / 500 | iteration 25 / 30 | Total Loss: 3.479379653930664 | KNN Loss: 2.4577555656433105 | BCE Loss: 1.0216240882873535\n",
      "Epoch 386 / 500 | iteration 0 / 30 | Total Loss: 3.4491100311279297 | KNN Loss: 2.4544076919555664 | BCE Loss: 0.9947023391723633\n",
      "Epoch 386 / 500 | iteration 5 / 30 | Total Loss: 3.4416348934173584 | KNN Loss: 2.4562220573425293 | BCE Loss: 0.9854128360748291\n",
      "Epoch 386 / 500 | iteration 10 / 30 | Total Loss: 3.469614028930664 | KNN Loss: 2.457411527633667 | BCE Loss: 1.0122023820877075\n",
      "Epoch 386 / 500 | iteration 15 / 30 | Total Loss: 3.4004712104797363 | KNN Loss: 2.4112584590911865 | BCE Loss: 0.9892126321792603\n",
      "Epoch 386 / 500 | iteration 20 / 30 | Total Loss: 3.448621988296509 | KNN Loss: 2.4353981018066406 | BCE Loss: 1.0132238864898682\n",
      "Epoch 386 / 500 | iteration 25 / 30 | Total Loss: 3.4878878593444824 | KNN Loss: 2.4748330116271973 | BCE Loss: 1.0130547285079956\n",
      "Epoch 387 / 500 | iteration 0 / 30 | Total Loss: 3.4706220626831055 | KNN Loss: 2.4534759521484375 | BCE Loss: 1.0171462297439575\n",
      "Epoch 387 / 500 | iteration 5 / 30 | Total Loss: 3.4440832138061523 | KNN Loss: 2.420348644256592 | BCE Loss: 1.0237345695495605\n",
      "Epoch 387 / 500 | iteration 10 / 30 | Total Loss: 3.431021213531494 | KNN Loss: 2.4269838333129883 | BCE Loss: 1.0040372610092163\n",
      "Epoch 387 / 500 | iteration 15 / 30 | Total Loss: 3.460059881210327 | KNN Loss: 2.4369993209838867 | BCE Loss: 1.0230605602264404\n",
      "Epoch 387 / 500 | iteration 20 / 30 | Total Loss: 3.4862146377563477 | KNN Loss: 2.479492425918579 | BCE Loss: 1.006722331047058\n",
      "Epoch 387 / 500 | iteration 25 / 30 | Total Loss: 3.490676164627075 | KNN Loss: 2.4588799476623535 | BCE Loss: 1.0317962169647217\n",
      "Epoch 388 / 500 | iteration 0 / 30 | Total Loss: 3.4689831733703613 | KNN Loss: 2.4272501468658447 | BCE Loss: 1.041732907295227\n",
      "Epoch 388 / 500 | iteration 5 / 30 | Total Loss: 3.467836380004883 | KNN Loss: 2.4237477779388428 | BCE Loss: 1.04408860206604\n",
      "Epoch 388 / 500 | iteration 10 / 30 | Total Loss: 3.446791172027588 | KNN Loss: 2.4321579933166504 | BCE Loss: 1.0146331787109375\n",
      "Epoch 388 / 500 | iteration 15 / 30 | Total Loss: 3.427180290222168 | KNN Loss: 2.432987689971924 | BCE Loss: 0.9941924810409546\n",
      "Epoch 388 / 500 | iteration 20 / 30 | Total Loss: 3.4727671146392822 | KNN Loss: 2.4290027618408203 | BCE Loss: 1.043764352798462\n",
      "Epoch 388 / 500 | iteration 25 / 30 | Total Loss: 3.4430527687072754 | KNN Loss: 2.435913562774658 | BCE Loss: 1.0071392059326172\n",
      "Epoch 389 / 500 | iteration 0 / 30 | Total Loss: 3.472902297973633 | KNN Loss: 2.4664554595947266 | BCE Loss: 1.0064467191696167\n",
      "Epoch 389 / 500 | iteration 5 / 30 | Total Loss: 3.460177421569824 | KNN Loss: 2.4580137729644775 | BCE Loss: 1.0021635293960571\n",
      "Epoch 389 / 500 | iteration 10 / 30 | Total Loss: 3.447371482849121 | KNN Loss: 2.4412732124328613 | BCE Loss: 1.0060981512069702\n",
      "Epoch 389 / 500 | iteration 15 / 30 | Total Loss: 3.477426528930664 | KNN Loss: 2.4360437393188477 | BCE Loss: 1.041382908821106\n",
      "Epoch 389 / 500 | iteration 20 / 30 | Total Loss: 3.482329845428467 | KNN Loss: 2.4627115726470947 | BCE Loss: 1.019618272781372\n",
      "Epoch 389 / 500 | iteration 25 / 30 | Total Loss: 3.471402645111084 | KNN Loss: 2.4279680252075195 | BCE Loss: 1.0434346199035645\n",
      "Epoch 390 / 500 | iteration 0 / 30 | Total Loss: 3.460256576538086 | KNN Loss: 2.4358034133911133 | BCE Loss: 1.0244531631469727\n",
      "Epoch 390 / 500 | iteration 5 / 30 | Total Loss: 3.4492409229278564 | KNN Loss: 2.4284346103668213 | BCE Loss: 1.0208063125610352\n",
      "Epoch 390 / 500 | iteration 10 / 30 | Total Loss: 3.4641127586364746 | KNN Loss: 2.440347194671631 | BCE Loss: 1.0237655639648438\n",
      "Epoch 390 / 500 | iteration 15 / 30 | Total Loss: 3.4801864624023438 | KNN Loss: 2.456071615219116 | BCE Loss: 1.024114966392517\n",
      "Epoch 390 / 500 | iteration 20 / 30 | Total Loss: 3.481635570526123 | KNN Loss: 2.463982343673706 | BCE Loss: 1.017653226852417\n",
      "Epoch 390 / 500 | iteration 25 / 30 | Total Loss: 3.4725453853607178 | KNN Loss: 2.4562666416168213 | BCE Loss: 1.0162787437438965\n",
      "Epoch 391 / 500 | iteration 0 / 30 | Total Loss: 3.4276764392852783 | KNN Loss: 2.4197778701782227 | BCE Loss: 1.0078985691070557\n",
      "Epoch 391 / 500 | iteration 5 / 30 | Total Loss: 3.441500186920166 | KNN Loss: 2.435959815979004 | BCE Loss: 1.0055402517318726\n",
      "Epoch 391 / 500 | iteration 10 / 30 | Total Loss: 3.4679300785064697 | KNN Loss: 2.4440839290618896 | BCE Loss: 1.02384614944458\n",
      "Epoch 391 / 500 | iteration 15 / 30 | Total Loss: 3.4622530937194824 | KNN Loss: 2.4594342708587646 | BCE Loss: 1.0028189420700073\n",
      "Epoch 391 / 500 | iteration 20 / 30 | Total Loss: 3.427475690841675 | KNN Loss: 2.4243221282958984 | BCE Loss: 1.0031535625457764\n",
      "Epoch 391 / 500 | iteration 25 / 30 | Total Loss: 3.4287939071655273 | KNN Loss: 2.4301838874816895 | BCE Loss: 0.9986101388931274\n",
      "Epoch 392 / 500 | iteration 0 / 30 | Total Loss: 3.524454116821289 | KNN Loss: 2.4720346927642822 | BCE Loss: 1.0524193048477173\n",
      "Epoch 392 / 500 | iteration 5 / 30 | Total Loss: 3.4616003036499023 | KNN Loss: 2.4696438312530518 | BCE Loss: 0.9919565320014954\n",
      "Epoch 392 / 500 | iteration 10 / 30 | Total Loss: 3.435652732849121 | KNN Loss: 2.4400129318237305 | BCE Loss: 0.9956398010253906\n",
      "Epoch 392 / 500 | iteration 15 / 30 | Total Loss: 3.457749366760254 | KNN Loss: 2.434283494949341 | BCE Loss: 1.023465871810913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392 / 500 | iteration 20 / 30 | Total Loss: 3.470994472503662 | KNN Loss: 2.4397103786468506 | BCE Loss: 1.0312840938568115\n",
      "Epoch 392 / 500 | iteration 25 / 30 | Total Loss: 3.501615047454834 | KNN Loss: 2.4897356033325195 | BCE Loss: 1.0118794441223145\n",
      "Epoch 393 / 500 | iteration 0 / 30 | Total Loss: 3.460090398788452 | KNN Loss: 2.4271278381347656 | BCE Loss: 1.0329625606536865\n",
      "Epoch 393 / 500 | iteration 5 / 30 | Total Loss: 3.4711830615997314 | KNN Loss: 2.4630308151245117 | BCE Loss: 1.0081522464752197\n",
      "Epoch 393 / 500 | iteration 10 / 30 | Total Loss: 3.429441452026367 | KNN Loss: 2.425044536590576 | BCE Loss: 1.004396915435791\n",
      "Epoch 393 / 500 | iteration 15 / 30 | Total Loss: 3.465471029281616 | KNN Loss: 2.451066732406616 | BCE Loss: 1.014404296875\n",
      "Epoch 393 / 500 | iteration 20 / 30 | Total Loss: 3.4621341228485107 | KNN Loss: 2.4483399391174316 | BCE Loss: 1.013794183731079\n",
      "Epoch 393 / 500 | iteration 25 / 30 | Total Loss: 3.508707046508789 | KNN Loss: 2.461805820465088 | BCE Loss: 1.0469012260437012\n",
      "Epoch 394 / 500 | iteration 0 / 30 | Total Loss: 3.416823387145996 | KNN Loss: 2.4189515113830566 | BCE Loss: 0.997871994972229\n",
      "Epoch 394 / 500 | iteration 5 / 30 | Total Loss: 3.4716641902923584 | KNN Loss: 2.430551528930664 | BCE Loss: 1.0411126613616943\n",
      "Epoch 394 / 500 | iteration 10 / 30 | Total Loss: 3.450518846511841 | KNN Loss: 2.4384653568267822 | BCE Loss: 1.0120534896850586\n",
      "Epoch 394 / 500 | iteration 15 / 30 | Total Loss: 3.492568254470825 | KNN Loss: 2.4824681282043457 | BCE Loss: 1.0101001262664795\n",
      "Epoch 394 / 500 | iteration 20 / 30 | Total Loss: 3.4659206867218018 | KNN Loss: 2.4469451904296875 | BCE Loss: 1.0189754962921143\n",
      "Epoch 394 / 500 | iteration 25 / 30 | Total Loss: 3.464526653289795 | KNN Loss: 2.437040090560913 | BCE Loss: 1.0274866819381714\n",
      "Epoch 395 / 500 | iteration 0 / 30 | Total Loss: 3.439978837966919 | KNN Loss: 2.4357450008392334 | BCE Loss: 1.0042338371276855\n",
      "Epoch 395 / 500 | iteration 5 / 30 | Total Loss: 3.4559783935546875 | KNN Loss: 2.4495856761932373 | BCE Loss: 1.0063927173614502\n",
      "Epoch 395 / 500 | iteration 10 / 30 | Total Loss: 3.4672770500183105 | KNN Loss: 2.4424960613250732 | BCE Loss: 1.0247811079025269\n",
      "Epoch 395 / 500 | iteration 15 / 30 | Total Loss: 3.461606979370117 | KNN Loss: 2.434753894805908 | BCE Loss: 1.0268532037734985\n",
      "Epoch 395 / 500 | iteration 20 / 30 | Total Loss: 3.429654121398926 | KNN Loss: 2.43438982963562 | BCE Loss: 0.9952643513679504\n",
      "Epoch 395 / 500 | iteration 25 / 30 | Total Loss: 3.4851927757263184 | KNN Loss: 2.4472875595092773 | BCE Loss: 1.037905216217041\n",
      "Epoch 396 / 500 | iteration 0 / 30 | Total Loss: 3.4846229553222656 | KNN Loss: 2.465846300125122 | BCE Loss: 1.0187766551971436\n",
      "Epoch 396 / 500 | iteration 5 / 30 | Total Loss: 3.4512245655059814 | KNN Loss: 2.442258834838867 | BCE Loss: 1.0089657306671143\n",
      "Epoch 396 / 500 | iteration 10 / 30 | Total Loss: 3.4591917991638184 | KNN Loss: 2.4526054859161377 | BCE Loss: 1.0065863132476807\n",
      "Epoch 396 / 500 | iteration 15 / 30 | Total Loss: 3.459860324859619 | KNN Loss: 2.4437553882598877 | BCE Loss: 1.0161049365997314\n",
      "Epoch 396 / 500 | iteration 20 / 30 | Total Loss: 3.481381893157959 | KNN Loss: 2.4675350189208984 | BCE Loss: 1.0138468742370605\n",
      "Epoch 396 / 500 | iteration 25 / 30 | Total Loss: 3.4813601970672607 | KNN Loss: 2.4420225620269775 | BCE Loss: 1.0393376350402832\n",
      "Epoch 397 / 500 | iteration 0 / 30 | Total Loss: 3.436295986175537 | KNN Loss: 2.439969778060913 | BCE Loss: 0.9963261485099792\n",
      "Epoch 397 / 500 | iteration 5 / 30 | Total Loss: 3.4431610107421875 | KNN Loss: 2.442542314529419 | BCE Loss: 1.000618577003479\n",
      "Epoch 397 / 500 | iteration 10 / 30 | Total Loss: 3.4763193130493164 | KNN Loss: 2.4599664211273193 | BCE Loss: 1.016352891921997\n",
      "Epoch 397 / 500 | iteration 15 / 30 | Total Loss: 3.4285035133361816 | KNN Loss: 2.4379072189331055 | BCE Loss: 0.9905961751937866\n",
      "Epoch 397 / 500 | iteration 20 / 30 | Total Loss: 3.4552738666534424 | KNN Loss: 2.4402997493743896 | BCE Loss: 1.0149741172790527\n",
      "Epoch 397 / 500 | iteration 25 / 30 | Total Loss: 3.4577038288116455 | KNN Loss: 2.4536726474761963 | BCE Loss: 1.0040311813354492\n",
      "Epoch 398 / 500 | iteration 0 / 30 | Total Loss: 3.47615909576416 | KNN Loss: 2.456559658050537 | BCE Loss: 1.019599437713623\n",
      "Epoch 398 / 500 | iteration 5 / 30 | Total Loss: 3.472350597381592 | KNN Loss: 2.4552805423736572 | BCE Loss: 1.0170701742172241\n",
      "Epoch 398 / 500 | iteration 10 / 30 | Total Loss: 3.487952709197998 | KNN Loss: 2.4830455780029297 | BCE Loss: 1.0049071311950684\n",
      "Epoch 398 / 500 | iteration 15 / 30 | Total Loss: 3.4244396686553955 | KNN Loss: 2.4410834312438965 | BCE Loss: 0.9833562970161438\n",
      "Epoch 398 / 500 | iteration 20 / 30 | Total Loss: 3.463040828704834 | KNN Loss: 2.4463493824005127 | BCE Loss: 1.0166914463043213\n",
      "Epoch 398 / 500 | iteration 25 / 30 | Total Loss: 3.4557018280029297 | KNN Loss: 2.4488604068756104 | BCE Loss: 1.0068415403366089\n",
      "Epoch 399 / 500 | iteration 0 / 30 | Total Loss: 3.500373363494873 | KNN Loss: 2.453058958053589 | BCE Loss: 1.0473144054412842\n",
      "Epoch 399 / 500 | iteration 5 / 30 | Total Loss: 3.526081085205078 | KNN Loss: 2.510871648788452 | BCE Loss: 1.015209436416626\n",
      "Epoch 399 / 500 | iteration 10 / 30 | Total Loss: 3.412956953048706 | KNN Loss: 2.4424567222595215 | BCE Loss: 0.9705002307891846\n",
      "Epoch 399 / 500 | iteration 15 / 30 | Total Loss: 3.458981990814209 | KNN Loss: 2.475241184234619 | BCE Loss: 0.9837406873703003\n",
      "Epoch 399 / 500 | iteration 20 / 30 | Total Loss: 3.4531912803649902 | KNN Loss: 2.4319519996643066 | BCE Loss: 1.0212392807006836\n",
      "Epoch 399 / 500 | iteration 25 / 30 | Total Loss: 3.504091501235962 | KNN Loss: 2.4693503379821777 | BCE Loss: 1.0347411632537842\n",
      "Epoch 400 / 500 | iteration 0 / 30 | Total Loss: 3.428267240524292 | KNN Loss: 2.426241636276245 | BCE Loss: 1.0020256042480469\n",
      "Epoch 400 / 500 | iteration 5 / 30 | Total Loss: 3.449749708175659 | KNN Loss: 2.441523313522339 | BCE Loss: 1.0082263946533203\n",
      "Epoch 400 / 500 | iteration 10 / 30 | Total Loss: 3.405332088470459 | KNN Loss: 2.403196096420288 | BCE Loss: 1.002135992050171\n",
      "Epoch 400 / 500 | iteration 15 / 30 | Total Loss: 3.443887233734131 | KNN Loss: 2.41681170463562 | BCE Loss: 1.0270755290985107\n",
      "Epoch 400 / 500 | iteration 20 / 30 | Total Loss: 3.4794538021087646 | KNN Loss: 2.4618449211120605 | BCE Loss: 1.017608880996704\n",
      "Epoch 400 / 500 | iteration 25 / 30 | Total Loss: 3.4466488361358643 | KNN Loss: 2.412715435028076 | BCE Loss: 1.033933401107788\n",
      "Epoch 401 / 500 | iteration 0 / 30 | Total Loss: 3.4695773124694824 | KNN Loss: 2.4362361431121826 | BCE Loss: 1.0333410501480103\n",
      "Epoch 401 / 500 | iteration 5 / 30 | Total Loss: 3.4487085342407227 | KNN Loss: 2.442148447036743 | BCE Loss: 1.006560206413269\n",
      "Epoch 401 / 500 | iteration 10 / 30 | Total Loss: 3.5020618438720703 | KNN Loss: 2.4838638305664062 | BCE Loss: 1.0181978940963745\n",
      "Epoch 401 / 500 | iteration 15 / 30 | Total Loss: 3.4637115001678467 | KNN Loss: 2.453709125518799 | BCE Loss: 1.0100023746490479\n",
      "Epoch 401 / 500 | iteration 20 / 30 | Total Loss: 3.4366543292999268 | KNN Loss: 2.4280099868774414 | BCE Loss: 1.0086443424224854\n",
      "Epoch 401 / 500 | iteration 25 / 30 | Total Loss: 3.44846773147583 | KNN Loss: 2.425130605697632 | BCE Loss: 1.0233371257781982\n",
      "Epoch 402 / 500 | iteration 0 / 30 | Total Loss: 3.4334452152252197 | KNN Loss: 2.426640510559082 | BCE Loss: 1.0068047046661377\n",
      "Epoch 402 / 500 | iteration 5 / 30 | Total Loss: 3.4835047721862793 | KNN Loss: 2.4775383472442627 | BCE Loss: 1.0059664249420166\n",
      "Epoch 402 / 500 | iteration 10 / 30 | Total Loss: 3.446993589401245 | KNN Loss: 2.453730344772339 | BCE Loss: 0.993263304233551\n",
      "Epoch 402 / 500 | iteration 15 / 30 | Total Loss: 3.468273401260376 | KNN Loss: 2.4467363357543945 | BCE Loss: 1.0215370655059814\n",
      "Epoch 402 / 500 | iteration 20 / 30 | Total Loss: 3.4690089225769043 | KNN Loss: 2.4645748138427734 | BCE Loss: 1.0044341087341309\n",
      "Epoch 402 / 500 | iteration 25 / 30 | Total Loss: 3.5025134086608887 | KNN Loss: 2.472219705581665 | BCE Loss: 1.030293583869934\n",
      "Epoch 403 / 500 | iteration 0 / 30 | Total Loss: 3.4458138942718506 | KNN Loss: 2.44046950340271 | BCE Loss: 1.0053443908691406\n",
      "Epoch 403 / 500 | iteration 5 / 30 | Total Loss: 3.478649616241455 | KNN Loss: 2.463575601577759 | BCE Loss: 1.0150738954544067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403 / 500 | iteration 10 / 30 | Total Loss: 3.4628725051879883 | KNN Loss: 2.4468088150024414 | BCE Loss: 1.0160636901855469\n",
      "Epoch 403 / 500 | iteration 15 / 30 | Total Loss: 3.476689100265503 | KNN Loss: 2.4794442653656006 | BCE Loss: 0.9972448348999023\n",
      "Epoch 403 / 500 | iteration 20 / 30 | Total Loss: 3.473046064376831 | KNN Loss: 2.4464361667633057 | BCE Loss: 1.0266098976135254\n",
      "Epoch 403 / 500 | iteration 25 / 30 | Total Loss: 3.480100631713867 | KNN Loss: 2.466578483581543 | BCE Loss: 1.0135222673416138\n",
      "Epoch 404 / 500 | iteration 0 / 30 | Total Loss: 3.4549713134765625 | KNN Loss: 2.442111015319824 | BCE Loss: 1.0128604173660278\n",
      "Epoch 404 / 500 | iteration 5 / 30 | Total Loss: 3.4482712745666504 | KNN Loss: 2.4365503787994385 | BCE Loss: 1.011720895767212\n",
      "Epoch 404 / 500 | iteration 10 / 30 | Total Loss: 3.456695079803467 | KNN Loss: 2.4581100940704346 | BCE Loss: 0.9985849261283875\n",
      "Epoch 404 / 500 | iteration 15 / 30 | Total Loss: 3.47969388961792 | KNN Loss: 2.456876754760742 | BCE Loss: 1.0228172540664673\n",
      "Epoch 404 / 500 | iteration 20 / 30 | Total Loss: 3.4431371688842773 | KNN Loss: 2.4471256732940674 | BCE Loss: 0.9960113763809204\n",
      "Epoch 404 / 500 | iteration 25 / 30 | Total Loss: 3.483940839767456 | KNN Loss: 2.443042516708374 | BCE Loss: 1.040898323059082\n",
      "Epoch 405 / 500 | iteration 0 / 30 | Total Loss: 3.4496655464172363 | KNN Loss: 2.439026117324829 | BCE Loss: 1.0106393098831177\n",
      "Epoch 405 / 500 | iteration 5 / 30 | Total Loss: 3.4232890605926514 | KNN Loss: 2.4302213191986084 | BCE Loss: 0.993067741394043\n",
      "Epoch 405 / 500 | iteration 10 / 30 | Total Loss: 3.458287000656128 | KNN Loss: 2.446974992752075 | BCE Loss: 1.0113120079040527\n",
      "Epoch 405 / 500 | iteration 15 / 30 | Total Loss: 3.4513847827911377 | KNN Loss: 2.4290614128112793 | BCE Loss: 1.0223233699798584\n",
      "Epoch 405 / 500 | iteration 20 / 30 | Total Loss: 3.456186056137085 | KNN Loss: 2.428424119949341 | BCE Loss: 1.0277619361877441\n",
      "Epoch 405 / 500 | iteration 25 / 30 | Total Loss: 3.4588985443115234 | KNN Loss: 2.437443733215332 | BCE Loss: 1.0214546918869019\n",
      "Epoch 406 / 500 | iteration 0 / 30 | Total Loss: 3.488823413848877 | KNN Loss: 2.46122670173645 | BCE Loss: 1.0275968313217163\n",
      "Epoch 406 / 500 | iteration 5 / 30 | Total Loss: 3.467658042907715 | KNN Loss: 2.4625558853149414 | BCE Loss: 1.0051020383834839\n",
      "Epoch 406 / 500 | iteration 10 / 30 | Total Loss: 3.448673725128174 | KNN Loss: 2.4547901153564453 | BCE Loss: 0.9938835501670837\n",
      "Epoch 406 / 500 | iteration 15 / 30 | Total Loss: 3.449260711669922 | KNN Loss: 2.4414985179901123 | BCE Loss: 1.00776207447052\n",
      "Epoch 406 / 500 | iteration 20 / 30 | Total Loss: 3.463224411010742 | KNN Loss: 2.438477039337158 | BCE Loss: 1.0247474908828735\n",
      "Epoch 406 / 500 | iteration 25 / 30 | Total Loss: 3.45112943649292 | KNN Loss: 2.4329488277435303 | BCE Loss: 1.0181804895401\n",
      "Epoch 407 / 500 | iteration 0 / 30 | Total Loss: 3.465020179748535 | KNN Loss: 2.452528238296509 | BCE Loss: 1.0124919414520264\n",
      "Epoch 407 / 500 | iteration 5 / 30 | Total Loss: 3.429939031600952 | KNN Loss: 2.448591470718384 | BCE Loss: 0.9813476204872131\n",
      "Epoch 407 / 500 | iteration 10 / 30 | Total Loss: 3.48746395111084 | KNN Loss: 2.4319801330566406 | BCE Loss: 1.0554839372634888\n",
      "Epoch 407 / 500 | iteration 15 / 30 | Total Loss: 3.435275077819824 | KNN Loss: 2.4463653564453125 | BCE Loss: 0.9889098405838013\n",
      "Epoch 407 / 500 | iteration 20 / 30 | Total Loss: 3.4111461639404297 | KNN Loss: 2.4170382022857666 | BCE Loss: 0.9941080808639526\n",
      "Epoch 407 / 500 | iteration 25 / 30 | Total Loss: 3.470250129699707 | KNN Loss: 2.4346096515655518 | BCE Loss: 1.0356403589248657\n",
      "Epoch 408 / 500 | iteration 0 / 30 | Total Loss: 3.4554388523101807 | KNN Loss: 2.4454708099365234 | BCE Loss: 1.0099680423736572\n",
      "Epoch 408 / 500 | iteration 5 / 30 | Total Loss: 3.4438180923461914 | KNN Loss: 2.43414568901062 | BCE Loss: 1.0096725225448608\n",
      "Epoch 408 / 500 | iteration 10 / 30 | Total Loss: 3.425137758255005 | KNN Loss: 2.427138090133667 | BCE Loss: 0.9979996681213379\n",
      "Epoch 408 / 500 | iteration 15 / 30 | Total Loss: 3.3945791721343994 | KNN Loss: 2.4075987339019775 | BCE Loss: 0.9869804978370667\n",
      "Epoch 408 / 500 | iteration 20 / 30 | Total Loss: 3.51255202293396 | KNN Loss: 2.491384506225586 | BCE Loss: 1.021167516708374\n",
      "Epoch 408 / 500 | iteration 25 / 30 | Total Loss: 3.400724172592163 | KNN Loss: 2.407137155532837 | BCE Loss: 0.9935870170593262\n",
      "Epoch 409 / 500 | iteration 0 / 30 | Total Loss: 3.459254741668701 | KNN Loss: 2.418064832687378 | BCE Loss: 1.0411899089813232\n",
      "Epoch 409 / 500 | iteration 5 / 30 | Total Loss: 3.492192029953003 | KNN Loss: 2.456103801727295 | BCE Loss: 1.036088228225708\n",
      "Epoch 409 / 500 | iteration 10 / 30 | Total Loss: 3.4536683559417725 | KNN Loss: 2.452139377593994 | BCE Loss: 1.0015289783477783\n",
      "Epoch 409 / 500 | iteration 15 / 30 | Total Loss: 3.437674045562744 | KNN Loss: 2.445094347000122 | BCE Loss: 0.9925796985626221\n",
      "Epoch 409 / 500 | iteration 20 / 30 | Total Loss: 3.492116928100586 | KNN Loss: 2.4746270179748535 | BCE Loss: 1.0174899101257324\n",
      "Epoch 409 / 500 | iteration 25 / 30 | Total Loss: 3.4465842247009277 | KNN Loss: 2.4280624389648438 | BCE Loss: 1.018521785736084\n",
      "Epoch   410: reducing learning rate of group 0 to 1.6616e-05.\n",
      "Epoch 410 / 500 | iteration 0 / 30 | Total Loss: 3.466704845428467 | KNN Loss: 2.4464495182037354 | BCE Loss: 1.020255446434021\n",
      "Epoch 410 / 500 | iteration 5 / 30 | Total Loss: 3.3946709632873535 | KNN Loss: 2.4089319705963135 | BCE Loss: 0.98573899269104\n",
      "Epoch 410 / 500 | iteration 10 / 30 | Total Loss: 3.472651958465576 | KNN Loss: 2.4827582836151123 | BCE Loss: 0.9898937940597534\n",
      "Epoch 410 / 500 | iteration 15 / 30 | Total Loss: 3.4319088459014893 | KNN Loss: 2.422633647918701 | BCE Loss: 1.009275197982788\n",
      "Epoch 410 / 500 | iteration 20 / 30 | Total Loss: 3.440777540206909 | KNN Loss: 2.451260805130005 | BCE Loss: 0.9895167350769043\n",
      "Epoch 410 / 500 | iteration 25 / 30 | Total Loss: 3.401834726333618 | KNN Loss: 2.409627676010132 | BCE Loss: 0.9922071099281311\n",
      "Epoch 411 / 500 | iteration 0 / 30 | Total Loss: 3.4756696224212646 | KNN Loss: 2.4712958335876465 | BCE Loss: 1.0043737888336182\n",
      "Epoch 411 / 500 | iteration 5 / 30 | Total Loss: 3.475874662399292 | KNN Loss: 2.4768407344818115 | BCE Loss: 0.9990339279174805\n",
      "Epoch 411 / 500 | iteration 10 / 30 | Total Loss: 3.4703238010406494 | KNN Loss: 2.4472203254699707 | BCE Loss: 1.0231034755706787\n",
      "Epoch 411 / 500 | iteration 15 / 30 | Total Loss: 3.445376396179199 | KNN Loss: 2.4231529235839844 | BCE Loss: 1.0222234725952148\n",
      "Epoch 411 / 500 | iteration 20 / 30 | Total Loss: 3.4625465869903564 | KNN Loss: 2.4379115104675293 | BCE Loss: 1.0246350765228271\n",
      "Epoch 411 / 500 | iteration 25 / 30 | Total Loss: 3.4538869857788086 | KNN Loss: 2.4588797092437744 | BCE Loss: 0.9950072169303894\n",
      "Epoch 412 / 500 | iteration 0 / 30 | Total Loss: 3.4593729972839355 | KNN Loss: 2.4670608043670654 | BCE Loss: 0.9923123121261597\n",
      "Epoch 412 / 500 | iteration 5 / 30 | Total Loss: 3.4651761054992676 | KNN Loss: 2.439025402069092 | BCE Loss: 1.0261507034301758\n",
      "Epoch 412 / 500 | iteration 10 / 30 | Total Loss: 3.4520671367645264 | KNN Loss: 2.448323965072632 | BCE Loss: 1.0037431716918945\n",
      "Epoch 412 / 500 | iteration 15 / 30 | Total Loss: 3.4417128562927246 | KNN Loss: 2.442643880844116 | BCE Loss: 0.999069094657898\n",
      "Epoch 412 / 500 | iteration 20 / 30 | Total Loss: 3.4465346336364746 | KNN Loss: 2.442565679550171 | BCE Loss: 1.0039689540863037\n",
      "Epoch 412 / 500 | iteration 25 / 30 | Total Loss: 3.480121374130249 | KNN Loss: 2.4471511840820312 | BCE Loss: 1.0329701900482178\n",
      "Epoch 413 / 500 | iteration 0 / 30 | Total Loss: 3.4322850704193115 | KNN Loss: 2.437225818634033 | BCE Loss: 0.9950592517852783\n",
      "Epoch 413 / 500 | iteration 5 / 30 | Total Loss: 3.4551923274993896 | KNN Loss: 2.4348816871643066 | BCE Loss: 1.020310640335083\n",
      "Epoch 413 / 500 | iteration 10 / 30 | Total Loss: 3.465567111968994 | KNN Loss: 2.4870362281799316 | BCE Loss: 0.9785308241844177\n",
      "Epoch 413 / 500 | iteration 15 / 30 | Total Loss: 3.452256917953491 | KNN Loss: 2.440474510192871 | BCE Loss: 1.0117824077606201\n",
      "Epoch 413 / 500 | iteration 20 / 30 | Total Loss: 3.472202777862549 | KNN Loss: 2.463367223739624 | BCE Loss: 1.0088355541229248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413 / 500 | iteration 25 / 30 | Total Loss: 3.4526660442352295 | KNN Loss: 2.4355456829071045 | BCE Loss: 1.017120361328125\n",
      "Epoch 414 / 500 | iteration 0 / 30 | Total Loss: 3.4548628330230713 | KNN Loss: 2.4479410648345947 | BCE Loss: 1.0069217681884766\n",
      "Epoch 414 / 500 | iteration 5 / 30 | Total Loss: 3.447676181793213 | KNN Loss: 2.432644844055176 | BCE Loss: 1.0150312185287476\n",
      "Epoch 414 / 500 | iteration 10 / 30 | Total Loss: 3.5004615783691406 | KNN Loss: 2.454744815826416 | BCE Loss: 1.0457167625427246\n",
      "Epoch 414 / 500 | iteration 15 / 30 | Total Loss: 3.43498158454895 | KNN Loss: 2.4332122802734375 | BCE Loss: 1.0017693042755127\n",
      "Epoch 414 / 500 | iteration 20 / 30 | Total Loss: 3.4490609169006348 | KNN Loss: 2.4323794841766357 | BCE Loss: 1.0166815519332886\n",
      "Epoch 414 / 500 | iteration 25 / 30 | Total Loss: 3.443997383117676 | KNN Loss: 2.431135654449463 | BCE Loss: 1.0128618478775024\n",
      "Epoch 415 / 500 | iteration 0 / 30 | Total Loss: 3.4691872596740723 | KNN Loss: 2.4317331314086914 | BCE Loss: 1.0374541282653809\n",
      "Epoch 415 / 500 | iteration 5 / 30 | Total Loss: 3.4177708625793457 | KNN Loss: 2.428785800933838 | BCE Loss: 0.9889851808547974\n",
      "Epoch 415 / 500 | iteration 10 / 30 | Total Loss: 3.476209878921509 | KNN Loss: 2.4517109394073486 | BCE Loss: 1.0244989395141602\n",
      "Epoch 415 / 500 | iteration 15 / 30 | Total Loss: 3.4510395526885986 | KNN Loss: 2.4404819011688232 | BCE Loss: 1.0105576515197754\n",
      "Epoch 415 / 500 | iteration 20 / 30 | Total Loss: 3.4338979721069336 | KNN Loss: 2.422844171524048 | BCE Loss: 1.0110536813735962\n",
      "Epoch 415 / 500 | iteration 25 / 30 | Total Loss: 3.4239084720611572 | KNN Loss: 2.45328950881958 | BCE Loss: 0.9706189632415771\n",
      "Epoch 416 / 500 | iteration 0 / 30 | Total Loss: 3.448333501815796 | KNN Loss: 2.429771900177002 | BCE Loss: 1.018561601638794\n",
      "Epoch 416 / 500 | iteration 5 / 30 | Total Loss: 3.487107515335083 | KNN Loss: 2.452815532684326 | BCE Loss: 1.0342919826507568\n",
      "Epoch 416 / 500 | iteration 10 / 30 | Total Loss: 3.42834210395813 | KNN Loss: 2.4230520725250244 | BCE Loss: 1.0052900314331055\n",
      "Epoch 416 / 500 | iteration 15 / 30 | Total Loss: 3.510969400405884 | KNN Loss: 2.4711527824401855 | BCE Loss: 1.0398166179656982\n",
      "Epoch 416 / 500 | iteration 20 / 30 | Total Loss: 3.425795078277588 | KNN Loss: 2.4245049953460693 | BCE Loss: 1.001290202140808\n",
      "Epoch 416 / 500 | iteration 25 / 30 | Total Loss: 3.4575815200805664 | KNN Loss: 2.440247058868408 | BCE Loss: 1.0173345804214478\n",
      "Epoch 417 / 500 | iteration 0 / 30 | Total Loss: 3.439703941345215 | KNN Loss: 2.4264187812805176 | BCE Loss: 1.0132851600646973\n",
      "Epoch 417 / 500 | iteration 5 / 30 | Total Loss: 3.4501547813415527 | KNN Loss: 2.4540464878082275 | BCE Loss: 0.9961082935333252\n",
      "Epoch 417 / 500 | iteration 10 / 30 | Total Loss: 3.4801206588745117 | KNN Loss: 2.4373350143432617 | BCE Loss: 1.04278564453125\n",
      "Epoch 417 / 500 | iteration 15 / 30 | Total Loss: 3.4629454612731934 | KNN Loss: 2.4472525119781494 | BCE Loss: 1.015692949295044\n",
      "Epoch 417 / 500 | iteration 20 / 30 | Total Loss: 3.4728219509124756 | KNN Loss: 2.450309991836548 | BCE Loss: 1.0225119590759277\n",
      "Epoch 417 / 500 | iteration 25 / 30 | Total Loss: 3.501049518585205 | KNN Loss: 2.4623329639434814 | BCE Loss: 1.0387166738510132\n",
      "Epoch 418 / 500 | iteration 0 / 30 | Total Loss: 3.485424041748047 | KNN Loss: 2.476806163787842 | BCE Loss: 1.008617877960205\n",
      "Epoch 418 / 500 | iteration 5 / 30 | Total Loss: 3.467359781265259 | KNN Loss: 2.4435606002807617 | BCE Loss: 1.023799180984497\n",
      "Epoch 418 / 500 | iteration 10 / 30 | Total Loss: 3.4726505279541016 | KNN Loss: 2.4533424377441406 | BCE Loss: 1.019308090209961\n",
      "Epoch 418 / 500 | iteration 15 / 30 | Total Loss: 3.523221015930176 | KNN Loss: 2.504194974899292 | BCE Loss: 1.0190261602401733\n",
      "Epoch 418 / 500 | iteration 20 / 30 | Total Loss: 3.4681825637817383 | KNN Loss: 2.4307713508605957 | BCE Loss: 1.037411093711853\n",
      "Epoch 418 / 500 | iteration 25 / 30 | Total Loss: 3.4545984268188477 | KNN Loss: 2.468031644821167 | BCE Loss: 0.9865666627883911\n",
      "Epoch 419 / 500 | iteration 0 / 30 | Total Loss: 3.4821364879608154 | KNN Loss: 2.444566488265991 | BCE Loss: 1.0375699996948242\n",
      "Epoch 419 / 500 | iteration 5 / 30 | Total Loss: 3.4467012882232666 | KNN Loss: 2.3973705768585205 | BCE Loss: 1.049330711364746\n",
      "Epoch 419 / 500 | iteration 10 / 30 | Total Loss: 3.451962947845459 | KNN Loss: 2.437436103820801 | BCE Loss: 1.0145268440246582\n",
      "Epoch 419 / 500 | iteration 15 / 30 | Total Loss: 3.4170937538146973 | KNN Loss: 2.4176998138427734 | BCE Loss: 0.9993938207626343\n",
      "Epoch 419 / 500 | iteration 20 / 30 | Total Loss: 3.4522950649261475 | KNN Loss: 2.4362518787384033 | BCE Loss: 1.0160431861877441\n",
      "Epoch 419 / 500 | iteration 25 / 30 | Total Loss: 3.4408133029937744 | KNN Loss: 2.448216676712036 | BCE Loss: 0.9925965666770935\n",
      "Epoch 420 / 500 | iteration 0 / 30 | Total Loss: 3.4596610069274902 | KNN Loss: 2.45446515083313 | BCE Loss: 1.0051957368850708\n",
      "Epoch 420 / 500 | iteration 5 / 30 | Total Loss: 3.4061501026153564 | KNN Loss: 2.4069573879241943 | BCE Loss: 0.9991927146911621\n",
      "Epoch 420 / 500 | iteration 10 / 30 | Total Loss: 3.443310499191284 | KNN Loss: 2.441647529602051 | BCE Loss: 1.0016629695892334\n",
      "Epoch 420 / 500 | iteration 15 / 30 | Total Loss: 3.456692695617676 | KNN Loss: 2.4355571269989014 | BCE Loss: 1.0211354494094849\n",
      "Epoch 420 / 500 | iteration 20 / 30 | Total Loss: 3.45867919921875 | KNN Loss: 2.436763048171997 | BCE Loss: 1.021916151046753\n",
      "Epoch 420 / 500 | iteration 25 / 30 | Total Loss: 3.4710192680358887 | KNN Loss: 2.4287564754486084 | BCE Loss: 1.0422627925872803\n",
      "Epoch   421: reducing learning rate of group 0 to 1.1632e-05.\n",
      "Epoch 421 / 500 | iteration 0 / 30 | Total Loss: 3.4556126594543457 | KNN Loss: 2.446958541870117 | BCE Loss: 1.008654236793518\n",
      "Epoch 421 / 500 | iteration 5 / 30 | Total Loss: 3.4188098907470703 | KNN Loss: 2.4171905517578125 | BCE Loss: 1.0016193389892578\n",
      "Epoch 421 / 500 | iteration 10 / 30 | Total Loss: 3.5142369270324707 | KNN Loss: 2.4711899757385254 | BCE Loss: 1.0430470705032349\n",
      "Epoch 421 / 500 | iteration 15 / 30 | Total Loss: 3.416142463684082 | KNN Loss: 2.4354395866394043 | BCE Loss: 0.9807029962539673\n",
      "Epoch 421 / 500 | iteration 20 / 30 | Total Loss: 3.4822373390197754 | KNN Loss: 2.4751408100128174 | BCE Loss: 1.0070966482162476\n",
      "Epoch 421 / 500 | iteration 25 / 30 | Total Loss: 3.442333459854126 | KNN Loss: 2.437706708908081 | BCE Loss: 1.004626750946045\n",
      "Epoch 422 / 500 | iteration 0 / 30 | Total Loss: 3.477321147918701 | KNN Loss: 2.470550060272217 | BCE Loss: 1.0067710876464844\n",
      "Epoch 422 / 500 | iteration 5 / 30 | Total Loss: 3.5065207481384277 | KNN Loss: 2.485960006713867 | BCE Loss: 1.0205607414245605\n",
      "Epoch 422 / 500 | iteration 10 / 30 | Total Loss: 3.4541521072387695 | KNN Loss: 2.4337801933288574 | BCE Loss: 1.0203720331192017\n",
      "Epoch 422 / 500 | iteration 15 / 30 | Total Loss: 3.4589614868164062 | KNN Loss: 2.430190086364746 | BCE Loss: 1.0287715196609497\n",
      "Epoch 422 / 500 | iteration 20 / 30 | Total Loss: 3.4813966751098633 | KNN Loss: 2.452965021133423 | BCE Loss: 1.02843177318573\n",
      "Epoch 422 / 500 | iteration 25 / 30 | Total Loss: 3.4339680671691895 | KNN Loss: 2.4377522468566895 | BCE Loss: 0.9962158799171448\n",
      "Epoch 423 / 500 | iteration 0 / 30 | Total Loss: 3.4670519828796387 | KNN Loss: 2.452882766723633 | BCE Loss: 1.0141692161560059\n",
      "Epoch 423 / 500 | iteration 5 / 30 | Total Loss: 3.5027294158935547 | KNN Loss: 2.441312789916992 | BCE Loss: 1.0614166259765625\n",
      "Epoch 423 / 500 | iteration 10 / 30 | Total Loss: 3.469843626022339 | KNN Loss: 2.4616217613220215 | BCE Loss: 1.0082218647003174\n",
      "Epoch 423 / 500 | iteration 15 / 30 | Total Loss: 3.4546828269958496 | KNN Loss: 2.4636847972869873 | BCE Loss: 0.9909980893135071\n",
      "Epoch 423 / 500 | iteration 20 / 30 | Total Loss: 3.4382550716400146 | KNN Loss: 2.434155225753784 | BCE Loss: 1.0040998458862305\n",
      "Epoch 423 / 500 | iteration 25 / 30 | Total Loss: 3.458164691925049 | KNN Loss: 2.4298617839813232 | BCE Loss: 1.0283029079437256\n",
      "Epoch 424 / 500 | iteration 0 / 30 | Total Loss: 3.466639995574951 | KNN Loss: 2.4574429988861084 | BCE Loss: 1.0091969966888428\n",
      "Epoch 424 / 500 | iteration 5 / 30 | Total Loss: 3.4731414318084717 | KNN Loss: 2.4372198581695557 | BCE Loss: 1.035921573638916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424 / 500 | iteration 10 / 30 | Total Loss: 3.4722704887390137 | KNN Loss: 2.4437897205352783 | BCE Loss: 1.0284807682037354\n",
      "Epoch 424 / 500 | iteration 15 / 30 | Total Loss: 3.4408159255981445 | KNN Loss: 2.4402902126312256 | BCE Loss: 1.0005258321762085\n",
      "Epoch 424 / 500 | iteration 20 / 30 | Total Loss: 3.465956211090088 | KNN Loss: 2.4784810543060303 | BCE Loss: 0.9874750375747681\n",
      "Epoch 424 / 500 | iteration 25 / 30 | Total Loss: 3.461963653564453 | KNN Loss: 2.449181079864502 | BCE Loss: 1.0127826929092407\n",
      "Epoch 425 / 500 | iteration 0 / 30 | Total Loss: 3.458625555038452 | KNN Loss: 2.4408457279205322 | BCE Loss: 1.01777982711792\n",
      "Epoch 425 / 500 | iteration 5 / 30 | Total Loss: 3.4682774543762207 | KNN Loss: 2.432546854019165 | BCE Loss: 1.0357304811477661\n",
      "Epoch 425 / 500 | iteration 10 / 30 | Total Loss: 3.471376895904541 | KNN Loss: 2.4650843143463135 | BCE Loss: 1.006292700767517\n",
      "Epoch 425 / 500 | iteration 15 / 30 | Total Loss: 3.4297189712524414 | KNN Loss: 2.4240593910217285 | BCE Loss: 1.0056594610214233\n",
      "Epoch 425 / 500 | iteration 20 / 30 | Total Loss: 3.457472324371338 | KNN Loss: 2.4333913326263428 | BCE Loss: 1.0240811109542847\n",
      "Epoch 425 / 500 | iteration 25 / 30 | Total Loss: 3.486152410507202 | KNN Loss: 2.463189125061035 | BCE Loss: 1.022963285446167\n",
      "Epoch 426 / 500 | iteration 0 / 30 | Total Loss: 3.4482979774475098 | KNN Loss: 2.4463911056518555 | BCE Loss: 1.0019068717956543\n",
      "Epoch 426 / 500 | iteration 5 / 30 | Total Loss: 3.429184913635254 | KNN Loss: 2.416020393371582 | BCE Loss: 1.0131645202636719\n",
      "Epoch 426 / 500 | iteration 10 / 30 | Total Loss: 3.4879891872406006 | KNN Loss: 2.493212938308716 | BCE Loss: 0.9947762489318848\n",
      "Epoch 426 / 500 | iteration 15 / 30 | Total Loss: 3.4485135078430176 | KNN Loss: 2.4555978775024414 | BCE Loss: 0.9929155707359314\n",
      "Epoch 426 / 500 | iteration 20 / 30 | Total Loss: 3.5354325771331787 | KNN Loss: 2.4694995880126953 | BCE Loss: 1.0659329891204834\n",
      "Epoch 426 / 500 | iteration 25 / 30 | Total Loss: 3.444270133972168 | KNN Loss: 2.4215664863586426 | BCE Loss: 1.0227036476135254\n",
      "Epoch 427 / 500 | iteration 0 / 30 | Total Loss: 3.522170066833496 | KNN Loss: 2.48190975189209 | BCE Loss: 1.0402604341506958\n",
      "Epoch 427 / 500 | iteration 5 / 30 | Total Loss: 3.4455392360687256 | KNN Loss: 2.4359681606292725 | BCE Loss: 1.0095710754394531\n",
      "Epoch 427 / 500 | iteration 10 / 30 | Total Loss: 3.4642772674560547 | KNN Loss: 2.4492039680480957 | BCE Loss: 1.015073299407959\n",
      "Epoch 427 / 500 | iteration 15 / 30 | Total Loss: 3.4445314407348633 | KNN Loss: 2.4367029666900635 | BCE Loss: 1.0078285932540894\n",
      "Epoch 427 / 500 | iteration 20 / 30 | Total Loss: 3.4774742126464844 | KNN Loss: 2.4657962322235107 | BCE Loss: 1.011677861213684\n",
      "Epoch 427 / 500 | iteration 25 / 30 | Total Loss: 3.4462413787841797 | KNN Loss: 2.4598562717437744 | BCE Loss: 0.9863851070404053\n",
      "Epoch 428 / 500 | iteration 0 / 30 | Total Loss: 3.4350340366363525 | KNN Loss: 2.44197678565979 | BCE Loss: 0.9930572509765625\n",
      "Epoch 428 / 500 | iteration 5 / 30 | Total Loss: 3.476362705230713 | KNN Loss: 2.4629437923431396 | BCE Loss: 1.0134189128875732\n",
      "Epoch 428 / 500 | iteration 10 / 30 | Total Loss: 3.4894399642944336 | KNN Loss: 2.4757702350616455 | BCE Loss: 1.0136696100234985\n",
      "Epoch 428 / 500 | iteration 15 / 30 | Total Loss: 3.4642820358276367 | KNN Loss: 2.4514870643615723 | BCE Loss: 1.012795090675354\n",
      "Epoch 428 / 500 | iteration 20 / 30 | Total Loss: 3.4744434356689453 | KNN Loss: 2.454437732696533 | BCE Loss: 1.020005702972412\n",
      "Epoch 428 / 500 | iteration 25 / 30 | Total Loss: 3.484622001647949 | KNN Loss: 2.435303211212158 | BCE Loss: 1.049318790435791\n",
      "Epoch 429 / 500 | iteration 0 / 30 | Total Loss: 3.443751335144043 | KNN Loss: 2.403766393661499 | BCE Loss: 1.039984941482544\n",
      "Epoch 429 / 500 | iteration 5 / 30 | Total Loss: 3.4756782054901123 | KNN Loss: 2.466993570327759 | BCE Loss: 1.0086846351623535\n",
      "Epoch 429 / 500 | iteration 10 / 30 | Total Loss: 3.4170303344726562 | KNN Loss: 2.4130921363830566 | BCE Loss: 1.0039383172988892\n",
      "Epoch 429 / 500 | iteration 15 / 30 | Total Loss: 3.419420003890991 | KNN Loss: 2.419283390045166 | BCE Loss: 1.0001366138458252\n",
      "Epoch 429 / 500 | iteration 20 / 30 | Total Loss: 3.439037322998047 | KNN Loss: 2.442890167236328 | BCE Loss: 0.9961472153663635\n",
      "Epoch 429 / 500 | iteration 25 / 30 | Total Loss: 3.4324183464050293 | KNN Loss: 2.430811882019043 | BCE Loss: 1.0016064643859863\n",
      "Epoch 430 / 500 | iteration 0 / 30 | Total Loss: 3.4497523307800293 | KNN Loss: 2.442108631134033 | BCE Loss: 1.007643699645996\n",
      "Epoch 430 / 500 | iteration 5 / 30 | Total Loss: 3.430966854095459 | KNN Loss: 2.461801052093506 | BCE Loss: 0.9691657423973083\n",
      "Epoch 430 / 500 | iteration 10 / 30 | Total Loss: 3.4637959003448486 | KNN Loss: 2.433974027633667 | BCE Loss: 1.0298218727111816\n",
      "Epoch 430 / 500 | iteration 15 / 30 | Total Loss: 3.4396462440490723 | KNN Loss: 2.4148898124694824 | BCE Loss: 1.0247564315795898\n",
      "Epoch 430 / 500 | iteration 20 / 30 | Total Loss: 3.4469966888427734 | KNN Loss: 2.4424054622650146 | BCE Loss: 1.0045912265777588\n",
      "Epoch 430 / 500 | iteration 25 / 30 | Total Loss: 3.455970048904419 | KNN Loss: 2.4295806884765625 | BCE Loss: 1.0263893604278564\n",
      "Epoch 431 / 500 | iteration 0 / 30 | Total Loss: 3.5036284923553467 | KNN Loss: 2.4697768688201904 | BCE Loss: 1.0338516235351562\n",
      "Epoch 431 / 500 | iteration 5 / 30 | Total Loss: 3.433331251144409 | KNN Loss: 2.4233012199401855 | BCE Loss: 1.0100300312042236\n",
      "Epoch 431 / 500 | iteration 10 / 30 | Total Loss: 3.483017921447754 | KNN Loss: 2.4850451946258545 | BCE Loss: 0.997972846031189\n",
      "Epoch 431 / 500 | iteration 15 / 30 | Total Loss: 3.5004091262817383 | KNN Loss: 2.4693703651428223 | BCE Loss: 1.031038761138916\n",
      "Epoch 431 / 500 | iteration 20 / 30 | Total Loss: 3.448279857635498 | KNN Loss: 2.44006085395813 | BCE Loss: 1.0082190036773682\n",
      "Epoch 431 / 500 | iteration 25 / 30 | Total Loss: 3.4940807819366455 | KNN Loss: 2.4793684482574463 | BCE Loss: 1.0147123336791992\n",
      "Epoch   432: reducing learning rate of group 0 to 8.1421e-06.\n",
      "Epoch 432 / 500 | iteration 0 / 30 | Total Loss: 3.5180234909057617 | KNN Loss: 2.479029893875122 | BCE Loss: 1.0389935970306396\n",
      "Epoch 432 / 500 | iteration 5 / 30 | Total Loss: 3.462778091430664 | KNN Loss: 2.447787046432495 | BCE Loss: 1.0149909257888794\n",
      "Epoch 432 / 500 | iteration 10 / 30 | Total Loss: 3.4618818759918213 | KNN Loss: 2.4455649852752686 | BCE Loss: 1.0163168907165527\n",
      "Epoch 432 / 500 | iteration 15 / 30 | Total Loss: 3.45770263671875 | KNN Loss: 2.466510772705078 | BCE Loss: 0.9911918044090271\n",
      "Epoch 432 / 500 | iteration 20 / 30 | Total Loss: 3.4934701919555664 | KNN Loss: 2.481459856033325 | BCE Loss: 1.0120103359222412\n",
      "Epoch 432 / 500 | iteration 25 / 30 | Total Loss: 3.4323315620422363 | KNN Loss: 2.4472851753234863 | BCE Loss: 0.9850464463233948\n",
      "Epoch 433 / 500 | iteration 0 / 30 | Total Loss: 3.484043598175049 | KNN Loss: 2.4660556316375732 | BCE Loss: 1.0179880857467651\n",
      "Epoch 433 / 500 | iteration 5 / 30 | Total Loss: 3.42683744430542 | KNN Loss: 2.441668748855591 | BCE Loss: 0.9851686358451843\n",
      "Epoch 433 / 500 | iteration 10 / 30 | Total Loss: 3.4646494388580322 | KNN Loss: 2.440152406692505 | BCE Loss: 1.0244970321655273\n",
      "Epoch 433 / 500 | iteration 15 / 30 | Total Loss: 3.491572380065918 | KNN Loss: 2.4675650596618652 | BCE Loss: 1.0240074396133423\n",
      "Epoch 433 / 500 | iteration 20 / 30 | Total Loss: 3.465115547180176 | KNN Loss: 2.460689067840576 | BCE Loss: 1.00442636013031\n",
      "Epoch 433 / 500 | iteration 25 / 30 | Total Loss: 3.4667015075683594 | KNN Loss: 2.438206672668457 | BCE Loss: 1.0284948348999023\n",
      "Epoch 434 / 500 | iteration 0 / 30 | Total Loss: 3.4045205116271973 | KNN Loss: 2.3950674533843994 | BCE Loss: 1.0094530582427979\n",
      "Epoch 434 / 500 | iteration 5 / 30 | Total Loss: 3.450504779815674 | KNN Loss: 2.435509443283081 | BCE Loss: 1.0149954557418823\n",
      "Epoch 434 / 500 | iteration 10 / 30 | Total Loss: 3.450970411300659 | KNN Loss: 2.4598309993743896 | BCE Loss: 0.9911393523216248\n",
      "Epoch 434 / 500 | iteration 15 / 30 | Total Loss: 3.4450597763061523 | KNN Loss: 2.446221351623535 | BCE Loss: 0.9988384246826172\n",
      "Epoch 434 / 500 | iteration 20 / 30 | Total Loss: 3.45377779006958 | KNN Loss: 2.43190598487854 | BCE Loss: 1.02187180519104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434 / 500 | iteration 25 / 30 | Total Loss: 3.429617404937744 | KNN Loss: 2.42323637008667 | BCE Loss: 1.0063809156417847\n",
      "Epoch 435 / 500 | iteration 0 / 30 | Total Loss: 3.4497780799865723 | KNN Loss: 2.466322183609009 | BCE Loss: 0.9834557771682739\n",
      "Epoch 435 / 500 | iteration 5 / 30 | Total Loss: 3.4866178035736084 | KNN Loss: 2.45715594291687 | BCE Loss: 1.0294618606567383\n",
      "Epoch 435 / 500 | iteration 10 / 30 | Total Loss: 3.478959083557129 | KNN Loss: 2.4637222290039062 | BCE Loss: 1.0152369737625122\n",
      "Epoch 435 / 500 | iteration 15 / 30 | Total Loss: 3.526686191558838 | KNN Loss: 2.4768800735473633 | BCE Loss: 1.0498061180114746\n",
      "Epoch 435 / 500 | iteration 20 / 30 | Total Loss: 3.4363651275634766 | KNN Loss: 2.4207119941711426 | BCE Loss: 1.015653133392334\n",
      "Epoch 435 / 500 | iteration 25 / 30 | Total Loss: 3.460972547531128 | KNN Loss: 2.4455013275146484 | BCE Loss: 1.0154712200164795\n",
      "Epoch 436 / 500 | iteration 0 / 30 | Total Loss: 3.5019798278808594 | KNN Loss: 2.469747304916382 | BCE Loss: 1.0322325229644775\n",
      "Epoch 436 / 500 | iteration 5 / 30 | Total Loss: 3.518672227859497 | KNN Loss: 2.4693214893341064 | BCE Loss: 1.0493507385253906\n",
      "Epoch 436 / 500 | iteration 10 / 30 | Total Loss: 3.4621171951293945 | KNN Loss: 2.436074733734131 | BCE Loss: 1.0260424613952637\n",
      "Epoch 436 / 500 | iteration 15 / 30 | Total Loss: 3.454318046569824 | KNN Loss: 2.4262876510620117 | BCE Loss: 1.0280303955078125\n",
      "Epoch 436 / 500 | iteration 20 / 30 | Total Loss: 3.432359457015991 | KNN Loss: 2.4406049251556396 | BCE Loss: 0.9917545318603516\n",
      "Epoch 436 / 500 | iteration 25 / 30 | Total Loss: 3.4473319053649902 | KNN Loss: 2.4365453720092773 | BCE Loss: 1.010786533355713\n",
      "Epoch 437 / 500 | iteration 0 / 30 | Total Loss: 3.4699301719665527 | KNN Loss: 2.4316904544830322 | BCE Loss: 1.0382397174835205\n",
      "Epoch 437 / 500 | iteration 5 / 30 | Total Loss: 3.445878744125366 | KNN Loss: 2.427633047103882 | BCE Loss: 1.0182456970214844\n",
      "Epoch 437 / 500 | iteration 10 / 30 | Total Loss: 3.441030740737915 | KNN Loss: 2.4388716220855713 | BCE Loss: 1.0021591186523438\n",
      "Epoch 437 / 500 | iteration 15 / 30 | Total Loss: 3.435159206390381 | KNN Loss: 2.424598455429077 | BCE Loss: 1.0105607509613037\n",
      "Epoch 437 / 500 | iteration 20 / 30 | Total Loss: 3.4982566833496094 | KNN Loss: 2.4710757732391357 | BCE Loss: 1.027180790901184\n",
      "Epoch 437 / 500 | iteration 25 / 30 | Total Loss: 3.4521098136901855 | KNN Loss: 2.438514471054077 | BCE Loss: 1.0135953426361084\n",
      "Epoch 438 / 500 | iteration 0 / 30 | Total Loss: 3.467381477355957 | KNN Loss: 2.446636915206909 | BCE Loss: 1.0207446813583374\n",
      "Epoch 438 / 500 | iteration 5 / 30 | Total Loss: 3.4363350868225098 | KNN Loss: 2.436384916305542 | BCE Loss: 0.9999502301216125\n",
      "Epoch 438 / 500 | iteration 10 / 30 | Total Loss: 3.451726198196411 | KNN Loss: 2.4382288455963135 | BCE Loss: 1.0134973526000977\n",
      "Epoch 438 / 500 | iteration 15 / 30 | Total Loss: 3.4156816005706787 | KNN Loss: 2.407874584197998 | BCE Loss: 1.0078070163726807\n",
      "Epoch 438 / 500 | iteration 20 / 30 | Total Loss: 3.4914939403533936 | KNN Loss: 2.497612714767456 | BCE Loss: 0.9938812851905823\n",
      "Epoch 438 / 500 | iteration 25 / 30 | Total Loss: 3.424074411392212 | KNN Loss: 2.439155101776123 | BCE Loss: 0.9849193096160889\n",
      "Epoch 439 / 500 | iteration 0 / 30 | Total Loss: 3.4993348121643066 | KNN Loss: 2.4906468391418457 | BCE Loss: 1.0086880922317505\n",
      "Epoch 439 / 500 | iteration 5 / 30 | Total Loss: 3.483053684234619 | KNN Loss: 2.4691174030303955 | BCE Loss: 1.013936161994934\n",
      "Epoch 439 / 500 | iteration 10 / 30 | Total Loss: 3.4893813133239746 | KNN Loss: 2.4662017822265625 | BCE Loss: 1.0231794118881226\n",
      "Epoch 439 / 500 | iteration 15 / 30 | Total Loss: 3.419066905975342 | KNN Loss: 2.436856746673584 | BCE Loss: 0.982210099697113\n",
      "Epoch 439 / 500 | iteration 20 / 30 | Total Loss: 3.415192127227783 | KNN Loss: 2.426792860031128 | BCE Loss: 0.9883993864059448\n",
      "Epoch 439 / 500 | iteration 25 / 30 | Total Loss: 3.4346985816955566 | KNN Loss: 2.4214184284210205 | BCE Loss: 1.0132802724838257\n",
      "Epoch 440 / 500 | iteration 0 / 30 | Total Loss: 3.437736988067627 | KNN Loss: 2.4322235584259033 | BCE Loss: 1.0055134296417236\n",
      "Epoch 440 / 500 | iteration 5 / 30 | Total Loss: 3.4590041637420654 | KNN Loss: 2.449558734893799 | BCE Loss: 1.0094454288482666\n",
      "Epoch 440 / 500 | iteration 10 / 30 | Total Loss: 3.4214234352111816 | KNN Loss: 2.4399518966674805 | BCE Loss: 0.9814715385437012\n",
      "Epoch 440 / 500 | iteration 15 / 30 | Total Loss: 3.4453396797180176 | KNN Loss: 2.4193737506866455 | BCE Loss: 1.025965929031372\n",
      "Epoch 440 / 500 | iteration 20 / 30 | Total Loss: 3.453653335571289 | KNN Loss: 2.433976173400879 | BCE Loss: 1.0196771621704102\n",
      "Epoch 440 / 500 | iteration 25 / 30 | Total Loss: 3.4357261657714844 | KNN Loss: 2.430360794067383 | BCE Loss: 1.0053654909133911\n",
      "Epoch 441 / 500 | iteration 0 / 30 | Total Loss: 3.4528121948242188 | KNN Loss: 2.4511470794677734 | BCE Loss: 1.0016652345657349\n",
      "Epoch 441 / 500 | iteration 5 / 30 | Total Loss: 3.4577081203460693 | KNN Loss: 2.490025043487549 | BCE Loss: 0.9676830768585205\n",
      "Epoch 441 / 500 | iteration 10 / 30 | Total Loss: 3.4519691467285156 | KNN Loss: 2.415010929107666 | BCE Loss: 1.03695809841156\n",
      "Epoch 441 / 500 | iteration 15 / 30 | Total Loss: 3.516552448272705 | KNN Loss: 2.48892879486084 | BCE Loss: 1.0276236534118652\n",
      "Epoch 441 / 500 | iteration 20 / 30 | Total Loss: 3.451289176940918 | KNN Loss: 2.4072999954223633 | BCE Loss: 1.0439891815185547\n",
      "Epoch 441 / 500 | iteration 25 / 30 | Total Loss: 3.453181028366089 | KNN Loss: 2.4726476669311523 | BCE Loss: 0.9805334210395813\n",
      "Epoch 442 / 500 | iteration 0 / 30 | Total Loss: 3.4794161319732666 | KNN Loss: 2.4549460411071777 | BCE Loss: 1.0244700908660889\n",
      "Epoch 442 / 500 | iteration 5 / 30 | Total Loss: 3.45182466506958 | KNN Loss: 2.442979335784912 | BCE Loss: 1.008845329284668\n",
      "Epoch 442 / 500 | iteration 10 / 30 | Total Loss: 3.4479105472564697 | KNN Loss: 2.449820041656494 | BCE Loss: 0.9980904459953308\n",
      "Epoch 442 / 500 | iteration 15 / 30 | Total Loss: 3.4310474395751953 | KNN Loss: 2.4330620765686035 | BCE Loss: 0.9979853630065918\n",
      "Epoch 442 / 500 | iteration 20 / 30 | Total Loss: 3.535067558288574 | KNN Loss: 2.490873098373413 | BCE Loss: 1.0441944599151611\n",
      "Epoch 442 / 500 | iteration 25 / 30 | Total Loss: 3.4171347618103027 | KNN Loss: 2.4241628646850586 | BCE Loss: 0.9929718971252441\n",
      "Epoch   443: reducing learning rate of group 0 to 5.6994e-06.\n",
      "Epoch 443 / 500 | iteration 0 / 30 | Total Loss: 3.4554030895233154 | KNN Loss: 2.4536962509155273 | BCE Loss: 1.001706838607788\n",
      "Epoch 443 / 500 | iteration 5 / 30 | Total Loss: 3.4092578887939453 | KNN Loss: 2.42692494392395 | BCE Loss: 0.9823328256607056\n",
      "Epoch 443 / 500 | iteration 10 / 30 | Total Loss: 3.457064151763916 | KNN Loss: 2.4378786087036133 | BCE Loss: 1.0191855430603027\n",
      "Epoch 443 / 500 | iteration 15 / 30 | Total Loss: 3.508049488067627 | KNN Loss: 2.476990222930908 | BCE Loss: 1.0310592651367188\n",
      "Epoch 443 / 500 | iteration 20 / 30 | Total Loss: 3.4321093559265137 | KNN Loss: 2.449286460876465 | BCE Loss: 0.9828228950500488\n",
      "Epoch 443 / 500 | iteration 25 / 30 | Total Loss: 3.4974093437194824 | KNN Loss: 2.479217290878296 | BCE Loss: 1.018192172050476\n",
      "Epoch 444 / 500 | iteration 0 / 30 | Total Loss: 3.4655673503875732 | KNN Loss: 2.438164472579956 | BCE Loss: 1.0274028778076172\n",
      "Epoch 444 / 500 | iteration 5 / 30 | Total Loss: 3.4529807567596436 | KNN Loss: 2.4339640140533447 | BCE Loss: 1.0190167427062988\n",
      "Epoch 444 / 500 | iteration 10 / 30 | Total Loss: 3.491624355316162 | KNN Loss: 2.4924871921539307 | BCE Loss: 0.9991371631622314\n",
      "Epoch 444 / 500 | iteration 15 / 30 | Total Loss: 3.4604573249816895 | KNN Loss: 2.4611542224884033 | BCE Loss: 0.9993031024932861\n",
      "Epoch 444 / 500 | iteration 20 / 30 | Total Loss: 3.5015368461608887 | KNN Loss: 2.474843740463257 | BCE Loss: 1.0266932249069214\n",
      "Epoch 444 / 500 | iteration 25 / 30 | Total Loss: 3.509984254837036 | KNN Loss: 2.4862723350524902 | BCE Loss: 1.023711919784546\n",
      "Epoch 445 / 500 | iteration 0 / 30 | Total Loss: 3.4322004318237305 | KNN Loss: 2.4319236278533936 | BCE Loss: 1.000276803970337\n",
      "Epoch 445 / 500 | iteration 5 / 30 | Total Loss: 3.4853501319885254 | KNN Loss: 2.454617977142334 | BCE Loss: 1.0307320356369019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445 / 500 | iteration 10 / 30 | Total Loss: 3.4624907970428467 | KNN Loss: 2.463801145553589 | BCE Loss: 0.9986896514892578\n",
      "Epoch 445 / 500 | iteration 15 / 30 | Total Loss: 3.420482635498047 | KNN Loss: 2.4239392280578613 | BCE Loss: 0.996543288230896\n",
      "Epoch 445 / 500 | iteration 20 / 30 | Total Loss: 3.4632930755615234 | KNN Loss: 2.435424566268921 | BCE Loss: 1.027868390083313\n",
      "Epoch 445 / 500 | iteration 25 / 30 | Total Loss: 3.4622347354888916 | KNN Loss: 2.436458110809326 | BCE Loss: 1.0257766246795654\n",
      "Epoch 446 / 500 | iteration 0 / 30 | Total Loss: 3.397132396697998 | KNN Loss: 2.425917863845825 | BCE Loss: 0.9712145328521729\n",
      "Epoch 446 / 500 | iteration 5 / 30 | Total Loss: 3.4580068588256836 | KNN Loss: 2.4454846382141113 | BCE Loss: 1.0125222206115723\n",
      "Epoch 446 / 500 | iteration 10 / 30 | Total Loss: 3.5098018646240234 | KNN Loss: 2.4948716163635254 | BCE Loss: 1.0149301290512085\n",
      "Epoch 446 / 500 | iteration 15 / 30 | Total Loss: 3.4408397674560547 | KNN Loss: 2.4229085445404053 | BCE Loss: 1.0179311037063599\n",
      "Epoch 446 / 500 | iteration 20 / 30 | Total Loss: 3.4644694328308105 | KNN Loss: 2.4480679035186768 | BCE Loss: 1.0164015293121338\n",
      "Epoch 446 / 500 | iteration 25 / 30 | Total Loss: 3.463160991668701 | KNN Loss: 2.448897123336792 | BCE Loss: 1.0142637491226196\n",
      "Epoch 447 / 500 | iteration 0 / 30 | Total Loss: 3.4653213024139404 | KNN Loss: 2.467163324356079 | BCE Loss: 0.9981580376625061\n",
      "Epoch 447 / 500 | iteration 5 / 30 | Total Loss: 3.4632081985473633 | KNN Loss: 2.4487569332122803 | BCE Loss: 1.0144513845443726\n",
      "Epoch 447 / 500 | iteration 10 / 30 | Total Loss: 3.4377408027648926 | KNN Loss: 2.4597434997558594 | BCE Loss: 0.9779973030090332\n",
      "Epoch 447 / 500 | iteration 15 / 30 | Total Loss: 3.464733600616455 | KNN Loss: 2.451443672180176 | BCE Loss: 1.0132899284362793\n",
      "Epoch 447 / 500 | iteration 20 / 30 | Total Loss: 3.4448118209838867 | KNN Loss: 2.4346516132354736 | BCE Loss: 1.010160207748413\n",
      "Epoch 447 / 500 | iteration 25 / 30 | Total Loss: 3.4430243968963623 | KNN Loss: 2.449507236480713 | BCE Loss: 0.9935171604156494\n",
      "Epoch 448 / 500 | iteration 0 / 30 | Total Loss: 3.4418182373046875 | KNN Loss: 2.4371891021728516 | BCE Loss: 1.0046290159225464\n",
      "Epoch 448 / 500 | iteration 5 / 30 | Total Loss: 3.4486401081085205 | KNN Loss: 2.421111583709717 | BCE Loss: 1.0275285243988037\n",
      "Epoch 448 / 500 | iteration 10 / 30 | Total Loss: 3.479794979095459 | KNN Loss: 2.4580326080322266 | BCE Loss: 1.0217623710632324\n",
      "Epoch 448 / 500 | iteration 15 / 30 | Total Loss: 3.4432425498962402 | KNN Loss: 2.4167463779449463 | BCE Loss: 1.026496171951294\n",
      "Epoch 448 / 500 | iteration 20 / 30 | Total Loss: 3.489086627960205 | KNN Loss: 2.468921661376953 | BCE Loss: 1.0201650857925415\n",
      "Epoch 448 / 500 | iteration 25 / 30 | Total Loss: 3.456664800643921 | KNN Loss: 2.464970588684082 | BCE Loss: 0.9916942119598389\n",
      "Epoch 449 / 500 | iteration 0 / 30 | Total Loss: 3.481172800064087 | KNN Loss: 2.458984613418579 | BCE Loss: 1.0221881866455078\n",
      "Epoch 449 / 500 | iteration 5 / 30 | Total Loss: 3.4546337127685547 | KNN Loss: 2.446518898010254 | BCE Loss: 1.0081148147583008\n",
      "Epoch 449 / 500 | iteration 10 / 30 | Total Loss: 3.479820728302002 | KNN Loss: 2.4663822650909424 | BCE Loss: 1.0134384632110596\n",
      "Epoch 449 / 500 | iteration 15 / 30 | Total Loss: 3.445812940597534 | KNN Loss: 2.435817003250122 | BCE Loss: 1.009995937347412\n",
      "Epoch 449 / 500 | iteration 20 / 30 | Total Loss: 3.447178363800049 | KNN Loss: 2.4527528285980225 | BCE Loss: 0.9944256544113159\n",
      "Epoch 449 / 500 | iteration 25 / 30 | Total Loss: 3.442556858062744 | KNN Loss: 2.4313766956329346 | BCE Loss: 1.01118004322052\n",
      "Epoch 450 / 500 | iteration 0 / 30 | Total Loss: 3.4571897983551025 | KNN Loss: 2.460561752319336 | BCE Loss: 0.9966281056404114\n",
      "Epoch 450 / 500 | iteration 5 / 30 | Total Loss: 3.4596500396728516 | KNN Loss: 2.4483814239501953 | BCE Loss: 1.0112686157226562\n",
      "Epoch 450 / 500 | iteration 10 / 30 | Total Loss: 3.4281680583953857 | KNN Loss: 2.427013874053955 | BCE Loss: 1.0011541843414307\n",
      "Epoch 450 / 500 | iteration 15 / 30 | Total Loss: 3.427095413208008 | KNN Loss: 2.4212229251861572 | BCE Loss: 1.0058724880218506\n",
      "Epoch 450 / 500 | iteration 20 / 30 | Total Loss: 3.409207820892334 | KNN Loss: 2.4206910133361816 | BCE Loss: 0.9885166883468628\n",
      "Epoch 450 / 500 | iteration 25 / 30 | Total Loss: 3.4786839485168457 | KNN Loss: 2.4635164737701416 | BCE Loss: 1.015167474746704\n",
      "Epoch 451 / 500 | iteration 0 / 30 | Total Loss: 3.4384570121765137 | KNN Loss: 2.4262852668762207 | BCE Loss: 1.0121716260910034\n",
      "Epoch 451 / 500 | iteration 5 / 30 | Total Loss: 3.445888042449951 | KNN Loss: 2.4389233589172363 | BCE Loss: 1.0069646835327148\n",
      "Epoch 451 / 500 | iteration 10 / 30 | Total Loss: 3.426002264022827 | KNN Loss: 2.4342355728149414 | BCE Loss: 0.9917666912078857\n",
      "Epoch 451 / 500 | iteration 15 / 30 | Total Loss: 3.4792661666870117 | KNN Loss: 2.443424940109253 | BCE Loss: 1.0358411073684692\n",
      "Epoch 451 / 500 | iteration 20 / 30 | Total Loss: 3.501434326171875 | KNN Loss: 2.4452764987945557 | BCE Loss: 1.0561578273773193\n",
      "Epoch 451 / 500 | iteration 25 / 30 | Total Loss: 3.4845829010009766 | KNN Loss: 2.4544832706451416 | BCE Loss: 1.030099630355835\n",
      "Epoch 452 / 500 | iteration 0 / 30 | Total Loss: 3.520662784576416 | KNN Loss: 2.5089476108551025 | BCE Loss: 1.011715292930603\n",
      "Epoch 452 / 500 | iteration 5 / 30 | Total Loss: 3.418898344039917 | KNN Loss: 2.4429335594177246 | BCE Loss: 0.9759647846221924\n",
      "Epoch 452 / 500 | iteration 10 / 30 | Total Loss: 3.481238842010498 | KNN Loss: 2.4644811153411865 | BCE Loss: 1.016757845878601\n",
      "Epoch 452 / 500 | iteration 15 / 30 | Total Loss: 3.4209718704223633 | KNN Loss: 2.407867670059204 | BCE Loss: 1.0131042003631592\n",
      "Epoch 452 / 500 | iteration 20 / 30 | Total Loss: 3.4325995445251465 | KNN Loss: 2.442352771759033 | BCE Loss: 0.9902468323707581\n",
      "Epoch 452 / 500 | iteration 25 / 30 | Total Loss: 3.4214401245117188 | KNN Loss: 2.4175732135772705 | BCE Loss: 1.0038667917251587\n",
      "Epoch 453 / 500 | iteration 0 / 30 | Total Loss: 3.477963924407959 | KNN Loss: 2.4470295906066895 | BCE Loss: 1.0309343338012695\n",
      "Epoch 453 / 500 | iteration 5 / 30 | Total Loss: 3.5020546913146973 | KNN Loss: 2.491333246231079 | BCE Loss: 1.0107215642929077\n",
      "Epoch 453 / 500 | iteration 10 / 30 | Total Loss: 3.4877679347991943 | KNN Loss: 2.4578521251678467 | BCE Loss: 1.0299158096313477\n",
      "Epoch 453 / 500 | iteration 15 / 30 | Total Loss: 3.46862530708313 | KNN Loss: 2.470696210861206 | BCE Loss: 0.997929036617279\n",
      "Epoch 453 / 500 | iteration 20 / 30 | Total Loss: 3.4398341178894043 | KNN Loss: 2.446259021759033 | BCE Loss: 0.9935750365257263\n",
      "Epoch 453 / 500 | iteration 25 / 30 | Total Loss: 3.449239730834961 | KNN Loss: 2.4362480640411377 | BCE Loss: 1.0129916667938232\n",
      "Epoch   454: reducing learning rate of group 0 to 3.9896e-06.\n",
      "Epoch 454 / 500 | iteration 0 / 30 | Total Loss: 3.4701614379882812 | KNN Loss: 2.461398124694824 | BCE Loss: 1.0087631940841675\n",
      "Epoch 454 / 500 | iteration 5 / 30 | Total Loss: 3.4265191555023193 | KNN Loss: 2.4182965755462646 | BCE Loss: 1.0082225799560547\n",
      "Epoch 454 / 500 | iteration 10 / 30 | Total Loss: 3.4452953338623047 | KNN Loss: 2.458075523376465 | BCE Loss: 0.9872198700904846\n",
      "Epoch 454 / 500 | iteration 15 / 30 | Total Loss: 3.4933595657348633 | KNN Loss: 2.4500136375427246 | BCE Loss: 1.0433460474014282\n",
      "Epoch 454 / 500 | iteration 20 / 30 | Total Loss: 3.4619815349578857 | KNN Loss: 2.450430154800415 | BCE Loss: 1.0115513801574707\n",
      "Epoch 454 / 500 | iteration 25 / 30 | Total Loss: 3.476821184158325 | KNN Loss: 2.453627109527588 | BCE Loss: 1.0231940746307373\n",
      "Epoch 455 / 500 | iteration 0 / 30 | Total Loss: 3.4463906288146973 | KNN Loss: 2.437333106994629 | BCE Loss: 1.0090575218200684\n",
      "Epoch 455 / 500 | iteration 5 / 30 | Total Loss: 3.4622697830200195 | KNN Loss: 2.4358255863189697 | BCE Loss: 1.0264440774917603\n",
      "Epoch 455 / 500 | iteration 10 / 30 | Total Loss: 3.4468541145324707 | KNN Loss: 2.4345245361328125 | BCE Loss: 1.0123294591903687\n",
      "Epoch 455 / 500 | iteration 15 / 30 | Total Loss: 3.435316324234009 | KNN Loss: 2.439615249633789 | BCE Loss: 0.9957011342048645\n",
      "Epoch 455 / 500 | iteration 20 / 30 | Total Loss: 3.402336597442627 | KNN Loss: 2.396733283996582 | BCE Loss: 1.0056034326553345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455 / 500 | iteration 25 / 30 | Total Loss: 3.4797115325927734 | KNN Loss: 2.4524600505828857 | BCE Loss: 1.0272513628005981\n",
      "Epoch 456 / 500 | iteration 0 / 30 | Total Loss: 3.490490436553955 | KNN Loss: 2.4655580520629883 | BCE Loss: 1.0249323844909668\n",
      "Epoch 456 / 500 | iteration 5 / 30 | Total Loss: 3.450888156890869 | KNN Loss: 2.4461400508880615 | BCE Loss: 1.0047482252120972\n",
      "Epoch 456 / 500 | iteration 10 / 30 | Total Loss: 3.4608447551727295 | KNN Loss: 2.4407060146331787 | BCE Loss: 1.0201387405395508\n",
      "Epoch 456 / 500 | iteration 15 / 30 | Total Loss: 3.427189350128174 | KNN Loss: 2.4095282554626465 | BCE Loss: 1.0176609754562378\n",
      "Epoch 456 / 500 | iteration 20 / 30 | Total Loss: 3.440563201904297 | KNN Loss: 2.4440314769744873 | BCE Loss: 0.9965318441390991\n",
      "Epoch 456 / 500 | iteration 25 / 30 | Total Loss: 3.4479925632476807 | KNN Loss: 2.4262053966522217 | BCE Loss: 1.021787166595459\n",
      "Epoch 457 / 500 | iteration 0 / 30 | Total Loss: 3.444863796234131 | KNN Loss: 2.4381039142608643 | BCE Loss: 1.006759762763977\n",
      "Epoch 457 / 500 | iteration 5 / 30 | Total Loss: 3.4702911376953125 | KNN Loss: 2.4396684169769287 | BCE Loss: 1.0306226015090942\n",
      "Epoch 457 / 500 | iteration 10 / 30 | Total Loss: 3.4477975368499756 | KNN Loss: 2.4641189575195312 | BCE Loss: 0.9836785793304443\n",
      "Epoch 457 / 500 | iteration 15 / 30 | Total Loss: 3.4369313716888428 | KNN Loss: 2.4249818325042725 | BCE Loss: 1.0119495391845703\n",
      "Epoch 457 / 500 | iteration 20 / 30 | Total Loss: 3.477992296218872 | KNN Loss: 2.4491798877716064 | BCE Loss: 1.0288124084472656\n",
      "Epoch 457 / 500 | iteration 25 / 30 | Total Loss: 3.4111227989196777 | KNN Loss: 2.439777135848999 | BCE Loss: 0.9713457822799683\n",
      "Epoch 458 / 500 | iteration 0 / 30 | Total Loss: 3.4346492290496826 | KNN Loss: 2.4359147548675537 | BCE Loss: 0.9987344145774841\n",
      "Epoch 458 / 500 | iteration 5 / 30 | Total Loss: 3.52595853805542 | KNN Loss: 2.484632730484009 | BCE Loss: 1.0413258075714111\n",
      "Epoch 458 / 500 | iteration 10 / 30 | Total Loss: 3.4371566772460938 | KNN Loss: 2.437512159347534 | BCE Loss: 0.9996446371078491\n",
      "Epoch 458 / 500 | iteration 15 / 30 | Total Loss: 3.421325206756592 | KNN Loss: 2.402771234512329 | BCE Loss: 1.0185538530349731\n",
      "Epoch 458 / 500 | iteration 20 / 30 | Total Loss: 3.449814796447754 | KNN Loss: 2.4641900062561035 | BCE Loss: 0.9856248497962952\n",
      "Epoch 458 / 500 | iteration 25 / 30 | Total Loss: 3.5275838375091553 | KNN Loss: 2.4860148429870605 | BCE Loss: 1.0415689945220947\n",
      "Epoch 459 / 500 | iteration 0 / 30 | Total Loss: 3.4185214042663574 | KNN Loss: 2.426586627960205 | BCE Loss: 0.9919348955154419\n",
      "Epoch 459 / 500 | iteration 5 / 30 | Total Loss: 3.436561346054077 | KNN Loss: 2.427189588546753 | BCE Loss: 1.0093717575073242\n",
      "Epoch 459 / 500 | iteration 10 / 30 | Total Loss: 3.514010190963745 | KNN Loss: 2.4619390964508057 | BCE Loss: 1.0520710945129395\n",
      "Epoch 459 / 500 | iteration 15 / 30 | Total Loss: 3.4426779747009277 | KNN Loss: 2.4593281745910645 | BCE Loss: 0.9833496809005737\n",
      "Epoch 459 / 500 | iteration 20 / 30 | Total Loss: 3.424983024597168 | KNN Loss: 2.432328701019287 | BCE Loss: 0.9926544427871704\n",
      "Epoch 459 / 500 | iteration 25 / 30 | Total Loss: 3.435520887374878 | KNN Loss: 2.412092447280884 | BCE Loss: 1.0234284400939941\n",
      "Epoch 460 / 500 | iteration 0 / 30 | Total Loss: 3.4676685333251953 | KNN Loss: 2.4567618370056152 | BCE Loss: 1.0109068155288696\n",
      "Epoch 460 / 500 | iteration 5 / 30 | Total Loss: 3.4505367279052734 | KNN Loss: 2.43843936920166 | BCE Loss: 1.0120974779129028\n",
      "Epoch 460 / 500 | iteration 10 / 30 | Total Loss: 3.492056369781494 | KNN Loss: 2.47308349609375 | BCE Loss: 1.0189729928970337\n",
      "Epoch 460 / 500 | iteration 15 / 30 | Total Loss: 3.4378461837768555 | KNN Loss: 2.444673538208008 | BCE Loss: 0.9931725263595581\n",
      "Epoch 460 / 500 | iteration 20 / 30 | Total Loss: 3.499115467071533 | KNN Loss: 2.4763824939727783 | BCE Loss: 1.0227329730987549\n",
      "Epoch 460 / 500 | iteration 25 / 30 | Total Loss: 3.4693288803100586 | KNN Loss: 2.470588445663452 | BCE Loss: 0.998740553855896\n",
      "Epoch 461 / 500 | iteration 0 / 30 | Total Loss: 3.444068431854248 | KNN Loss: 2.4166157245635986 | BCE Loss: 1.027452826499939\n",
      "Epoch 461 / 500 | iteration 5 / 30 | Total Loss: 3.461596965789795 | KNN Loss: 2.4457643032073975 | BCE Loss: 1.0158326625823975\n",
      "Epoch 461 / 500 | iteration 10 / 30 | Total Loss: 3.482985496520996 | KNN Loss: 2.447321891784668 | BCE Loss: 1.0356637239456177\n",
      "Epoch 461 / 500 | iteration 15 / 30 | Total Loss: 3.456362247467041 | KNN Loss: 2.454619884490967 | BCE Loss: 1.0017422437667847\n",
      "Epoch 461 / 500 | iteration 20 / 30 | Total Loss: 3.4504852294921875 | KNN Loss: 2.4307336807250977 | BCE Loss: 1.0197515487670898\n",
      "Epoch 461 / 500 | iteration 25 / 30 | Total Loss: 3.434237480163574 | KNN Loss: 2.4367313385009766 | BCE Loss: 0.9975060820579529\n",
      "Epoch 462 / 500 | iteration 0 / 30 | Total Loss: 3.4898176193237305 | KNN Loss: 2.44612717628479 | BCE Loss: 1.0436904430389404\n",
      "Epoch 462 / 500 | iteration 5 / 30 | Total Loss: 3.524918794631958 | KNN Loss: 2.4900107383728027 | BCE Loss: 1.0349080562591553\n",
      "Epoch 462 / 500 | iteration 10 / 30 | Total Loss: 3.456134796142578 | KNN Loss: 2.4282312393188477 | BCE Loss: 1.0279035568237305\n",
      "Epoch 462 / 500 | iteration 15 / 30 | Total Loss: 3.4447519779205322 | KNN Loss: 2.429874897003174 | BCE Loss: 1.0148770809173584\n",
      "Epoch 462 / 500 | iteration 20 / 30 | Total Loss: 3.4347646236419678 | KNN Loss: 2.4738943576812744 | BCE Loss: 0.9608702659606934\n",
      "Epoch 462 / 500 | iteration 25 / 30 | Total Loss: 3.4918041229248047 | KNN Loss: 2.4502646923065186 | BCE Loss: 1.0415394306182861\n",
      "Epoch 463 / 500 | iteration 0 / 30 | Total Loss: 3.454166889190674 | KNN Loss: 2.4194397926330566 | BCE Loss: 1.0347270965576172\n",
      "Epoch 463 / 500 | iteration 5 / 30 | Total Loss: 3.481921434402466 | KNN Loss: 2.444167137145996 | BCE Loss: 1.0377542972564697\n",
      "Epoch 463 / 500 | iteration 10 / 30 | Total Loss: 3.4005372524261475 | KNN Loss: 2.416332721710205 | BCE Loss: 0.9842045307159424\n",
      "Epoch 463 / 500 | iteration 15 / 30 | Total Loss: 3.4587807655334473 | KNN Loss: 2.457585334777832 | BCE Loss: 1.0011953115463257\n",
      "Epoch 463 / 500 | iteration 20 / 30 | Total Loss: 3.4723753929138184 | KNN Loss: 2.434134006500244 | BCE Loss: 1.0382413864135742\n",
      "Epoch 463 / 500 | iteration 25 / 30 | Total Loss: 3.4707746505737305 | KNN Loss: 2.446833610534668 | BCE Loss: 1.0239410400390625\n",
      "Epoch 464 / 500 | iteration 0 / 30 | Total Loss: 3.5192418098449707 | KNN Loss: 2.481304168701172 | BCE Loss: 1.0379376411437988\n",
      "Epoch 464 / 500 | iteration 5 / 30 | Total Loss: 3.4741227626800537 | KNN Loss: 2.468305826187134 | BCE Loss: 1.00581693649292\n",
      "Epoch 464 / 500 | iteration 10 / 30 | Total Loss: 3.4632225036621094 | KNN Loss: 2.450077772140503 | BCE Loss: 1.013144850730896\n",
      "Epoch 464 / 500 | iteration 15 / 30 | Total Loss: 3.455723762512207 | KNN Loss: 2.4590094089508057 | BCE Loss: 0.9967143535614014\n",
      "Epoch 464 / 500 | iteration 20 / 30 | Total Loss: 3.4350037574768066 | KNN Loss: 2.423863649368286 | BCE Loss: 1.0111401081085205\n",
      "Epoch 464 / 500 | iteration 25 / 30 | Total Loss: 3.433018445968628 | KNN Loss: 2.4327776432037354 | BCE Loss: 1.0002408027648926\n",
      "Epoch   465: reducing learning rate of group 0 to 2.7927e-06.\n",
      "Epoch 465 / 500 | iteration 0 / 30 | Total Loss: 3.4411721229553223 | KNN Loss: 2.429452896118164 | BCE Loss: 1.0117193460464478\n",
      "Epoch 465 / 500 | iteration 5 / 30 | Total Loss: 3.449303150177002 | KNN Loss: 2.4233663082122803 | BCE Loss: 1.0259369611740112\n",
      "Epoch 465 / 500 | iteration 10 / 30 | Total Loss: 3.471085548400879 | KNN Loss: 2.438906192779541 | BCE Loss: 1.0321792364120483\n",
      "Epoch 465 / 500 | iteration 15 / 30 | Total Loss: 3.419394016265869 | KNN Loss: 2.44109845161438 | BCE Loss: 0.978295624256134\n",
      "Epoch 465 / 500 | iteration 20 / 30 | Total Loss: 3.4592385292053223 | KNN Loss: 2.467195510864258 | BCE Loss: 0.9920428991317749\n",
      "Epoch 465 / 500 | iteration 25 / 30 | Total Loss: 3.4567575454711914 | KNN Loss: 2.439779043197632 | BCE Loss: 1.01697838306427\n",
      "Epoch 466 / 500 | iteration 0 / 30 | Total Loss: 3.4685866832733154 | KNN Loss: 2.43776535987854 | BCE Loss: 1.0308213233947754\n",
      "Epoch 466 / 500 | iteration 5 / 30 | Total Loss: 3.443726062774658 | KNN Loss: 2.456620931625366 | BCE Loss: 0.987105131149292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466 / 500 | iteration 10 / 30 | Total Loss: 3.4270777702331543 | KNN Loss: 2.43412709236145 | BCE Loss: 0.9929506778717041\n",
      "Epoch 466 / 500 | iteration 15 / 30 | Total Loss: 3.4769558906555176 | KNN Loss: 2.4305708408355713 | BCE Loss: 1.0463851690292358\n",
      "Epoch 466 / 500 | iteration 20 / 30 | Total Loss: 3.5045700073242188 | KNN Loss: 2.4780433177948 | BCE Loss: 1.0265265703201294\n",
      "Epoch 466 / 500 | iteration 25 / 30 | Total Loss: 3.434802532196045 | KNN Loss: 2.4517154693603516 | BCE Loss: 0.9830871224403381\n",
      "Epoch 467 / 500 | iteration 0 / 30 | Total Loss: 3.5032684803009033 | KNN Loss: 2.4783828258514404 | BCE Loss: 1.024885654449463\n",
      "Epoch 467 / 500 | iteration 5 / 30 | Total Loss: 3.4402925968170166 | KNN Loss: 2.4393630027770996 | BCE Loss: 1.000929594039917\n",
      "Epoch 467 / 500 | iteration 10 / 30 | Total Loss: 3.4974653720855713 | KNN Loss: 2.4704699516296387 | BCE Loss: 1.0269954204559326\n",
      "Epoch 467 / 500 | iteration 15 / 30 | Total Loss: 3.4298720359802246 | KNN Loss: 2.4396941661834717 | BCE Loss: 0.9901779890060425\n",
      "Epoch 467 / 500 | iteration 20 / 30 | Total Loss: 3.4548375606536865 | KNN Loss: 2.4383349418640137 | BCE Loss: 1.0165026187896729\n",
      "Epoch 467 / 500 | iteration 25 / 30 | Total Loss: 3.409494400024414 | KNN Loss: 2.408839464187622 | BCE Loss: 1.000654935836792\n",
      "Epoch 468 / 500 | iteration 0 / 30 | Total Loss: 3.4639101028442383 | KNN Loss: 2.425586700439453 | BCE Loss: 1.0383234024047852\n",
      "Epoch 468 / 500 | iteration 5 / 30 | Total Loss: 3.41694974899292 | KNN Loss: 2.4166243076324463 | BCE Loss: 1.0003255605697632\n",
      "Epoch 468 / 500 | iteration 10 / 30 | Total Loss: 3.4216551780700684 | KNN Loss: 2.4387354850769043 | BCE Loss: 0.9829198122024536\n",
      "Epoch 468 / 500 | iteration 15 / 30 | Total Loss: 3.4184231758117676 | KNN Loss: 2.4259767532348633 | BCE Loss: 0.9924463033676147\n",
      "Epoch 468 / 500 | iteration 20 / 30 | Total Loss: 3.4683666229248047 | KNN Loss: 2.452326536178589 | BCE Loss: 1.0160400867462158\n",
      "Epoch 468 / 500 | iteration 25 / 30 | Total Loss: 3.4613375663757324 | KNN Loss: 2.454845905303955 | BCE Loss: 1.0064916610717773\n",
      "Epoch 469 / 500 | iteration 0 / 30 | Total Loss: 3.4457545280456543 | KNN Loss: 2.4308924674987793 | BCE Loss: 1.0148619413375854\n",
      "Epoch 469 / 500 | iteration 5 / 30 | Total Loss: 3.487875461578369 | KNN Loss: 2.483886480331421 | BCE Loss: 1.0039888620376587\n",
      "Epoch 469 / 500 | iteration 10 / 30 | Total Loss: 3.464094877243042 | KNN Loss: 2.4596846103668213 | BCE Loss: 1.0044102668762207\n",
      "Epoch 469 / 500 | iteration 15 / 30 | Total Loss: 3.434696912765503 | KNN Loss: 2.4224207401275635 | BCE Loss: 1.0122761726379395\n",
      "Epoch 469 / 500 | iteration 20 / 30 | Total Loss: 3.4502623081207275 | KNN Loss: 2.44511079788208 | BCE Loss: 1.0051515102386475\n",
      "Epoch 469 / 500 | iteration 25 / 30 | Total Loss: 3.487854480743408 | KNN Loss: 2.4755611419677734 | BCE Loss: 1.0122932195663452\n",
      "Epoch 470 / 500 | iteration 0 / 30 | Total Loss: 3.4068803787231445 | KNN Loss: 2.4267349243164062 | BCE Loss: 0.9801453351974487\n",
      "Epoch 470 / 500 | iteration 5 / 30 | Total Loss: 3.4691081047058105 | KNN Loss: 2.439145088195801 | BCE Loss: 1.0299628973007202\n",
      "Epoch 470 / 500 | iteration 10 / 30 | Total Loss: 3.487271785736084 | KNN Loss: 2.468661308288574 | BCE Loss: 1.0186104774475098\n",
      "Epoch 470 / 500 | iteration 15 / 30 | Total Loss: 3.4547948837280273 | KNN Loss: 2.4559597969055176 | BCE Loss: 0.9988352060317993\n",
      "Epoch 470 / 500 | iteration 20 / 30 | Total Loss: 3.466721296310425 | KNN Loss: 2.470860242843628 | BCE Loss: 0.9958610534667969\n",
      "Epoch 470 / 500 | iteration 25 / 30 | Total Loss: 3.4649240970611572 | KNN Loss: 2.418182134628296 | BCE Loss: 1.0467419624328613\n",
      "Epoch 471 / 500 | iteration 0 / 30 | Total Loss: 3.4331750869750977 | KNN Loss: 2.412052631378174 | BCE Loss: 1.0211225748062134\n",
      "Epoch 471 / 500 | iteration 5 / 30 | Total Loss: 3.4660773277282715 | KNN Loss: 2.4590940475463867 | BCE Loss: 1.0069831609725952\n",
      "Epoch 471 / 500 | iteration 10 / 30 | Total Loss: 3.4586598873138428 | KNN Loss: 2.4565999507904053 | BCE Loss: 1.0020599365234375\n",
      "Epoch 471 / 500 | iteration 15 / 30 | Total Loss: 3.452653169631958 | KNN Loss: 2.4340643882751465 | BCE Loss: 1.0185887813568115\n",
      "Epoch 471 / 500 | iteration 20 / 30 | Total Loss: 3.450666904449463 | KNN Loss: 2.4483768939971924 | BCE Loss: 1.00229012966156\n",
      "Epoch 471 / 500 | iteration 25 / 30 | Total Loss: 3.474709987640381 | KNN Loss: 2.465754508972168 | BCE Loss: 1.0089555978775024\n",
      "Epoch 472 / 500 | iteration 0 / 30 | Total Loss: 3.491990566253662 | KNN Loss: 2.443451166152954 | BCE Loss: 1.048539400100708\n",
      "Epoch 472 / 500 | iteration 5 / 30 | Total Loss: 3.4687612056732178 | KNN Loss: 2.460268497467041 | BCE Loss: 1.0084927082061768\n",
      "Epoch 472 / 500 | iteration 10 / 30 | Total Loss: 3.4459457397460938 | KNN Loss: 2.418290138244629 | BCE Loss: 1.0276557207107544\n",
      "Epoch 472 / 500 | iteration 15 / 30 | Total Loss: 3.495755434036255 | KNN Loss: 2.4873852729797363 | BCE Loss: 1.0083701610565186\n",
      "Epoch 472 / 500 | iteration 20 / 30 | Total Loss: 3.452152729034424 | KNN Loss: 2.421294689178467 | BCE Loss: 1.030858039855957\n",
      "Epoch 472 / 500 | iteration 25 / 30 | Total Loss: 3.48268723487854 | KNN Loss: 2.4747183322906494 | BCE Loss: 1.0079689025878906\n",
      "Epoch 473 / 500 | iteration 0 / 30 | Total Loss: 3.4616379737854004 | KNN Loss: 2.442574977874756 | BCE Loss: 1.0190629959106445\n",
      "Epoch 473 / 500 | iteration 5 / 30 | Total Loss: 3.5105695724487305 | KNN Loss: 2.4627420902252197 | BCE Loss: 1.0478274822235107\n",
      "Epoch 473 / 500 | iteration 10 / 30 | Total Loss: 3.467957019805908 | KNN Loss: 2.4745545387268066 | BCE Loss: 0.9934024810791016\n",
      "Epoch 473 / 500 | iteration 15 / 30 | Total Loss: 3.4421470165252686 | KNN Loss: 2.4446310997009277 | BCE Loss: 0.9975159168243408\n",
      "Epoch 473 / 500 | iteration 20 / 30 | Total Loss: 3.4499123096466064 | KNN Loss: 2.442976474761963 | BCE Loss: 1.0069358348846436\n",
      "Epoch 473 / 500 | iteration 25 / 30 | Total Loss: 3.448394536972046 | KNN Loss: 2.4458980560302734 | BCE Loss: 1.0024964809417725\n",
      "Epoch 474 / 500 | iteration 0 / 30 | Total Loss: 3.438109874725342 | KNN Loss: 2.4185523986816406 | BCE Loss: 1.0195573568344116\n",
      "Epoch 474 / 500 | iteration 5 / 30 | Total Loss: 3.5111048221588135 | KNN Loss: 2.4695029258728027 | BCE Loss: 1.0416018962860107\n",
      "Epoch 474 / 500 | iteration 10 / 30 | Total Loss: 3.434636116027832 | KNN Loss: 2.448232650756836 | BCE Loss: 0.9864035844802856\n",
      "Epoch 474 / 500 | iteration 15 / 30 | Total Loss: 3.4986572265625 | KNN Loss: 2.4501683712005615 | BCE Loss: 1.0484888553619385\n",
      "Epoch 474 / 500 | iteration 20 / 30 | Total Loss: 3.449382781982422 | KNN Loss: 2.436391592025757 | BCE Loss: 1.012991189956665\n",
      "Epoch 474 / 500 | iteration 25 / 30 | Total Loss: 3.4901161193847656 | KNN Loss: 2.4719481468200684 | BCE Loss: 1.0181680917739868\n",
      "Epoch 475 / 500 | iteration 0 / 30 | Total Loss: 3.4783589839935303 | KNN Loss: 2.4497323036193848 | BCE Loss: 1.0286266803741455\n",
      "Epoch 475 / 500 | iteration 5 / 30 | Total Loss: 3.4821701049804688 | KNN Loss: 2.455141305923462 | BCE Loss: 1.0270289182662964\n",
      "Epoch 475 / 500 | iteration 10 / 30 | Total Loss: 3.418968677520752 | KNN Loss: 2.420433759689331 | BCE Loss: 0.9985349774360657\n",
      "Epoch 475 / 500 | iteration 15 / 30 | Total Loss: 3.4367873668670654 | KNN Loss: 2.4294300079345703 | BCE Loss: 1.0073573589324951\n",
      "Epoch 475 / 500 | iteration 20 / 30 | Total Loss: 3.4299378395080566 | KNN Loss: 2.423491954803467 | BCE Loss: 1.0064460039138794\n",
      "Epoch 475 / 500 | iteration 25 / 30 | Total Loss: 3.4609713554382324 | KNN Loss: 2.427150249481201 | BCE Loss: 1.0338209867477417\n",
      "Epoch   476: reducing learning rate of group 0 to 1.9549e-06.\n",
      "Epoch 476 / 500 | iteration 0 / 30 | Total Loss: 3.4847512245178223 | KNN Loss: 2.459076404571533 | BCE Loss: 1.025674819946289\n",
      "Epoch 476 / 500 | iteration 5 / 30 | Total Loss: 3.455643653869629 | KNN Loss: 2.429702043533325 | BCE Loss: 1.0259414911270142\n",
      "Epoch 476 / 500 | iteration 10 / 30 | Total Loss: 3.410623073577881 | KNN Loss: 2.4107043743133545 | BCE Loss: 0.9999185800552368\n",
      "Epoch 476 / 500 | iteration 15 / 30 | Total Loss: 3.446570873260498 | KNN Loss: 2.45218563079834 | BCE Loss: 0.994385302066803\n",
      "Epoch 476 / 500 | iteration 20 / 30 | Total Loss: 3.4616310596466064 | KNN Loss: 2.4401063919067383 | BCE Loss: 1.0215246677398682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476 / 500 | iteration 25 / 30 | Total Loss: 3.4186818599700928 | KNN Loss: 2.420632839202881 | BCE Loss: 0.9980490803718567\n",
      "Epoch 477 / 500 | iteration 0 / 30 | Total Loss: 3.4992356300354004 | KNN Loss: 2.478489875793457 | BCE Loss: 1.0207457542419434\n",
      "Epoch 477 / 500 | iteration 5 / 30 | Total Loss: 3.456890821456909 | KNN Loss: 2.46777081489563 | BCE Loss: 0.9891200065612793\n",
      "Epoch 477 / 500 | iteration 10 / 30 | Total Loss: 3.455470561981201 | KNN Loss: 2.433079719543457 | BCE Loss: 1.0223909616470337\n",
      "Epoch 477 / 500 | iteration 15 / 30 | Total Loss: 3.4551830291748047 | KNN Loss: 2.440864086151123 | BCE Loss: 1.0143189430236816\n",
      "Epoch 477 / 500 | iteration 20 / 30 | Total Loss: 3.474964141845703 | KNN Loss: 2.452160120010376 | BCE Loss: 1.0228039026260376\n",
      "Epoch 477 / 500 | iteration 25 / 30 | Total Loss: 3.4621801376342773 | KNN Loss: 2.4839096069335938 | BCE Loss: 0.9782705307006836\n",
      "Epoch 478 / 500 | iteration 0 / 30 | Total Loss: 3.4525279998779297 | KNN Loss: 2.435366153717041 | BCE Loss: 1.0171618461608887\n",
      "Epoch 478 / 500 | iteration 5 / 30 | Total Loss: 3.4659264087677 | KNN Loss: 2.432720184326172 | BCE Loss: 1.0332062244415283\n",
      "Epoch 478 / 500 | iteration 10 / 30 | Total Loss: 3.443203926086426 | KNN Loss: 2.4268558025360107 | BCE Loss: 1.016348123550415\n",
      "Epoch 478 / 500 | iteration 15 / 30 | Total Loss: 3.469461441040039 | KNN Loss: 2.4729769229888916 | BCE Loss: 0.9964845180511475\n",
      "Epoch 478 / 500 | iteration 20 / 30 | Total Loss: 3.4197702407836914 | KNN Loss: 2.414973020553589 | BCE Loss: 1.0047972202301025\n",
      "Epoch 478 / 500 | iteration 25 / 30 | Total Loss: 3.480309009552002 | KNN Loss: 2.4709432125091553 | BCE Loss: 1.0093657970428467\n",
      "Epoch 479 / 500 | iteration 0 / 30 | Total Loss: 3.489654302597046 | KNN Loss: 2.462994337081909 | BCE Loss: 1.0266599655151367\n",
      "Epoch 479 / 500 | iteration 5 / 30 | Total Loss: 3.4373440742492676 | KNN Loss: 2.4611103534698486 | BCE Loss: 0.9762336015701294\n",
      "Epoch 479 / 500 | iteration 10 / 30 | Total Loss: 3.4585318565368652 | KNN Loss: 2.4453470706939697 | BCE Loss: 1.0131847858428955\n",
      "Epoch 479 / 500 | iteration 15 / 30 | Total Loss: 3.463862657546997 | KNN Loss: 2.4409191608428955 | BCE Loss: 1.0229434967041016\n",
      "Epoch 479 / 500 | iteration 20 / 30 | Total Loss: 3.483006477355957 | KNN Loss: 2.4749913215637207 | BCE Loss: 1.0080152750015259\n",
      "Epoch 479 / 500 | iteration 25 / 30 | Total Loss: 3.432753086090088 | KNN Loss: 2.4185445308685303 | BCE Loss: 1.0142085552215576\n",
      "Epoch 480 / 500 | iteration 0 / 30 | Total Loss: 3.4822165966033936 | KNN Loss: 2.480860471725464 | BCE Loss: 1.0013561248779297\n",
      "Epoch 480 / 500 | iteration 5 / 30 | Total Loss: 3.4237961769104004 | KNN Loss: 2.435947895050049 | BCE Loss: 0.9878482222557068\n",
      "Epoch 480 / 500 | iteration 10 / 30 | Total Loss: 3.474862575531006 | KNN Loss: 2.469721794128418 | BCE Loss: 1.0051406621932983\n",
      "Epoch 480 / 500 | iteration 15 / 30 | Total Loss: 3.5275521278381348 | KNN Loss: 2.4863529205322266 | BCE Loss: 1.0411992073059082\n",
      "Epoch 480 / 500 | iteration 20 / 30 | Total Loss: 3.447521686553955 | KNN Loss: 2.4461798667907715 | BCE Loss: 1.001341700553894\n",
      "Epoch 480 / 500 | iteration 25 / 30 | Total Loss: 3.479687213897705 | KNN Loss: 2.474867820739746 | BCE Loss: 1.004819393157959\n",
      "Epoch 481 / 500 | iteration 0 / 30 | Total Loss: 3.5319480895996094 | KNN Loss: 2.4990293979644775 | BCE Loss: 1.0329186916351318\n",
      "Epoch 481 / 500 | iteration 5 / 30 | Total Loss: 3.456712484359741 | KNN Loss: 2.4251937866210938 | BCE Loss: 1.0315186977386475\n",
      "Epoch 481 / 500 | iteration 10 / 30 | Total Loss: 3.4236416816711426 | KNN Loss: 2.413958787918091 | BCE Loss: 1.0096828937530518\n",
      "Epoch 481 / 500 | iteration 15 / 30 | Total Loss: 3.466663360595703 | KNN Loss: 2.4357354640960693 | BCE Loss: 1.0309278964996338\n",
      "Epoch 481 / 500 | iteration 20 / 30 | Total Loss: 3.480659246444702 | KNN Loss: 2.4424445629119873 | BCE Loss: 1.0382146835327148\n",
      "Epoch 481 / 500 | iteration 25 / 30 | Total Loss: 3.4740734100341797 | KNN Loss: 2.462726593017578 | BCE Loss: 1.0113468170166016\n",
      "Epoch 482 / 500 | iteration 0 / 30 | Total Loss: 3.4509246349334717 | KNN Loss: 2.464468240737915 | BCE Loss: 0.9864563941955566\n",
      "Epoch 482 / 500 | iteration 5 / 30 | Total Loss: 3.411710739135742 | KNN Loss: 2.4179134368896484 | BCE Loss: 0.9937971830368042\n",
      "Epoch 482 / 500 | iteration 10 / 30 | Total Loss: 3.476534843444824 | KNN Loss: 2.456911325454712 | BCE Loss: 1.0196235179901123\n",
      "Epoch 482 / 500 | iteration 15 / 30 | Total Loss: 3.4749066829681396 | KNN Loss: 2.4520702362060547 | BCE Loss: 1.022836446762085\n",
      "Epoch 482 / 500 | iteration 20 / 30 | Total Loss: 3.458559036254883 | KNN Loss: 2.445467472076416 | BCE Loss: 1.0130915641784668\n",
      "Epoch 482 / 500 | iteration 25 / 30 | Total Loss: 3.4649369716644287 | KNN Loss: 2.4606902599334717 | BCE Loss: 1.004246711730957\n",
      "Epoch 483 / 500 | iteration 0 / 30 | Total Loss: 3.464566707611084 | KNN Loss: 2.4494893550872803 | BCE Loss: 1.0150773525238037\n",
      "Epoch 483 / 500 | iteration 5 / 30 | Total Loss: 3.464958667755127 | KNN Loss: 2.4417426586151123 | BCE Loss: 1.023215889930725\n",
      "Epoch 483 / 500 | iteration 10 / 30 | Total Loss: 3.4566335678100586 | KNN Loss: 2.4245870113372803 | BCE Loss: 1.0320465564727783\n",
      "Epoch 483 / 500 | iteration 15 / 30 | Total Loss: 3.405796766281128 | KNN Loss: 2.3992021083831787 | BCE Loss: 1.0065946578979492\n",
      "Epoch 483 / 500 | iteration 20 / 30 | Total Loss: 3.4880049228668213 | KNN Loss: 2.4767777919769287 | BCE Loss: 1.0112271308898926\n",
      "Epoch 483 / 500 | iteration 25 / 30 | Total Loss: 3.486215353012085 | KNN Loss: 2.443469524383545 | BCE Loss: 1.04274582862854\n",
      "Epoch 484 / 500 | iteration 0 / 30 | Total Loss: 3.462493419647217 | KNN Loss: 2.427089214324951 | BCE Loss: 1.0354042053222656\n",
      "Epoch 484 / 500 | iteration 5 / 30 | Total Loss: 3.495668411254883 | KNN Loss: 2.475433111190796 | BCE Loss: 1.020235300064087\n",
      "Epoch 484 / 500 | iteration 10 / 30 | Total Loss: 3.4661378860473633 | KNN Loss: 2.4653961658477783 | BCE Loss: 1.0007416009902954\n",
      "Epoch 484 / 500 | iteration 15 / 30 | Total Loss: 3.492765426635742 | KNN Loss: 2.4830539226531982 | BCE Loss: 1.009711503982544\n",
      "Epoch 484 / 500 | iteration 20 / 30 | Total Loss: 3.450063705444336 | KNN Loss: 2.411489248275757 | BCE Loss: 1.038574457168579\n",
      "Epoch 484 / 500 | iteration 25 / 30 | Total Loss: 3.4691057205200195 | KNN Loss: 2.4471428394317627 | BCE Loss: 1.0219627618789673\n",
      "Epoch 485 / 500 | iteration 0 / 30 | Total Loss: 3.469820499420166 | KNN Loss: 2.4501428604125977 | BCE Loss: 1.0196776390075684\n",
      "Epoch 485 / 500 | iteration 5 / 30 | Total Loss: 3.478257656097412 | KNN Loss: 2.463502883911133 | BCE Loss: 1.0147547721862793\n",
      "Epoch 485 / 500 | iteration 10 / 30 | Total Loss: 3.4339139461517334 | KNN Loss: 2.4207823276519775 | BCE Loss: 1.0131316184997559\n",
      "Epoch 485 / 500 | iteration 15 / 30 | Total Loss: 3.469769239425659 | KNN Loss: 2.4327616691589355 | BCE Loss: 1.0370075702667236\n",
      "Epoch 485 / 500 | iteration 20 / 30 | Total Loss: 3.439103364944458 | KNN Loss: 2.4282593727111816 | BCE Loss: 1.0108439922332764\n",
      "Epoch 485 / 500 | iteration 25 / 30 | Total Loss: 3.4237375259399414 | KNN Loss: 2.424009084701538 | BCE Loss: 0.9997285604476929\n",
      "Epoch 486 / 500 | iteration 0 / 30 | Total Loss: 3.4339489936828613 | KNN Loss: 2.4344887733459473 | BCE Loss: 0.9994603395462036\n",
      "Epoch 486 / 500 | iteration 5 / 30 | Total Loss: 3.4527363777160645 | KNN Loss: 2.451491117477417 | BCE Loss: 1.0012452602386475\n",
      "Epoch 486 / 500 | iteration 10 / 30 | Total Loss: 3.4814980030059814 | KNN Loss: 2.4587905406951904 | BCE Loss: 1.022707462310791\n",
      "Epoch 486 / 500 | iteration 15 / 30 | Total Loss: 3.473686933517456 | KNN Loss: 2.4387893676757812 | BCE Loss: 1.0348975658416748\n",
      "Epoch 486 / 500 | iteration 20 / 30 | Total Loss: 3.505110740661621 | KNN Loss: 2.4713246822357178 | BCE Loss: 1.0337861776351929\n",
      "Epoch 486 / 500 | iteration 25 / 30 | Total Loss: 3.480952024459839 | KNN Loss: 2.4668385982513428 | BCE Loss: 1.014113426208496\n",
      "Epoch   487: reducing learning rate of group 0 to 1.3684e-06.\n",
      "Epoch 487 / 500 | iteration 0 / 30 | Total Loss: 3.4439167976379395 | KNN Loss: 2.41072678565979 | BCE Loss: 1.0331898927688599\n",
      "Epoch 487 / 500 | iteration 5 / 30 | Total Loss: 3.417179584503174 | KNN Loss: 2.4045469760894775 | BCE Loss: 1.0126326084136963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487 / 500 | iteration 10 / 30 | Total Loss: 3.4130349159240723 | KNN Loss: 2.427854061126709 | BCE Loss: 0.9851807355880737\n",
      "Epoch 487 / 500 | iteration 15 / 30 | Total Loss: 3.469191312789917 | KNN Loss: 2.467212677001953 | BCE Loss: 1.0019786357879639\n",
      "Epoch 487 / 500 | iteration 20 / 30 | Total Loss: 3.43693470954895 | KNN Loss: 2.429675340652466 | BCE Loss: 1.0072593688964844\n",
      "Epoch 487 / 500 | iteration 25 / 30 | Total Loss: 3.4785704612731934 | KNN Loss: 2.4568064212799072 | BCE Loss: 1.0217640399932861\n",
      "Epoch 488 / 500 | iteration 0 / 30 | Total Loss: 3.4128501415252686 | KNN Loss: 2.4294497966766357 | BCE Loss: 0.983400285243988\n",
      "Epoch 488 / 500 | iteration 5 / 30 | Total Loss: 3.4198803901672363 | KNN Loss: 2.432467222213745 | BCE Loss: 0.987413227558136\n",
      "Epoch 488 / 500 | iteration 10 / 30 | Total Loss: 3.455881118774414 | KNN Loss: 2.426189661026001 | BCE Loss: 1.029691457748413\n",
      "Epoch 488 / 500 | iteration 15 / 30 | Total Loss: 3.426206588745117 | KNN Loss: 2.4217982292175293 | BCE Loss: 1.0044082403182983\n",
      "Epoch 488 / 500 | iteration 20 / 30 | Total Loss: 3.4921011924743652 | KNN Loss: 2.4799158573150635 | BCE Loss: 1.0121853351593018\n",
      "Epoch 488 / 500 | iteration 25 / 30 | Total Loss: 3.4446325302124023 | KNN Loss: 2.4438955783843994 | BCE Loss: 1.0007368326187134\n",
      "Epoch 489 / 500 | iteration 0 / 30 | Total Loss: 3.4516172409057617 | KNN Loss: 2.4463624954223633 | BCE Loss: 1.005254864692688\n",
      "Epoch 489 / 500 | iteration 5 / 30 | Total Loss: 3.4436092376708984 | KNN Loss: 2.456857204437256 | BCE Loss: 0.9867520332336426\n",
      "Epoch 489 / 500 | iteration 10 / 30 | Total Loss: 3.495497703552246 | KNN Loss: 2.473536491394043 | BCE Loss: 1.0219612121582031\n",
      "Epoch 489 / 500 | iteration 15 / 30 | Total Loss: 3.4031219482421875 | KNN Loss: 2.418898344039917 | BCE Loss: 0.9842237234115601\n",
      "Epoch 489 / 500 | iteration 20 / 30 | Total Loss: 3.510864496231079 | KNN Loss: 2.510226249694824 | BCE Loss: 1.0006382465362549\n",
      "Epoch 489 / 500 | iteration 25 / 30 | Total Loss: 3.4706227779388428 | KNN Loss: 2.4694621562957764 | BCE Loss: 1.0011606216430664\n",
      "Epoch 490 / 500 | iteration 0 / 30 | Total Loss: 3.495757579803467 | KNN Loss: 2.465214729309082 | BCE Loss: 1.0305428504943848\n",
      "Epoch 490 / 500 | iteration 5 / 30 | Total Loss: 3.488072395324707 | KNN Loss: 2.4922828674316406 | BCE Loss: 0.9957894682884216\n",
      "Epoch 490 / 500 | iteration 10 / 30 | Total Loss: 3.468709945678711 | KNN Loss: 2.447535276412964 | BCE Loss: 1.021174669265747\n",
      "Epoch 490 / 500 | iteration 15 / 30 | Total Loss: 3.4290308952331543 | KNN Loss: 2.42392635345459 | BCE Loss: 1.005104660987854\n",
      "Epoch 490 / 500 | iteration 20 / 30 | Total Loss: 3.45839262008667 | KNN Loss: 2.4456727504730225 | BCE Loss: 1.0127198696136475\n",
      "Epoch 490 / 500 | iteration 25 / 30 | Total Loss: 3.4725728034973145 | KNN Loss: 2.457587242126465 | BCE Loss: 1.0149855613708496\n",
      "Epoch 491 / 500 | iteration 0 / 30 | Total Loss: 3.446429967880249 | KNN Loss: 2.4299049377441406 | BCE Loss: 1.0165250301361084\n",
      "Epoch 491 / 500 | iteration 5 / 30 | Total Loss: 3.487431526184082 | KNN Loss: 2.4601850509643555 | BCE Loss: 1.0272465944290161\n",
      "Epoch 491 / 500 | iteration 10 / 30 | Total Loss: 3.5251822471618652 | KNN Loss: 2.493161201477051 | BCE Loss: 1.0320210456848145\n",
      "Epoch 491 / 500 | iteration 15 / 30 | Total Loss: 3.421936511993408 | KNN Loss: 2.4256844520568848 | BCE Loss: 0.9962520003318787\n",
      "Epoch 491 / 500 | iteration 20 / 30 | Total Loss: 3.4636082649230957 | KNN Loss: 2.475959300994873 | BCE Loss: 0.9876490235328674\n",
      "Epoch 491 / 500 | iteration 25 / 30 | Total Loss: 3.46431565284729 | KNN Loss: 2.4483656883239746 | BCE Loss: 1.0159499645233154\n",
      "Epoch 492 / 500 | iteration 0 / 30 | Total Loss: 3.4698617458343506 | KNN Loss: 2.453810453414917 | BCE Loss: 1.0160512924194336\n",
      "Epoch 492 / 500 | iteration 5 / 30 | Total Loss: 3.4951717853546143 | KNN Loss: 2.480299234390259 | BCE Loss: 1.0148725509643555\n",
      "Epoch 492 / 500 | iteration 10 / 30 | Total Loss: 3.4500951766967773 | KNN Loss: 2.4172682762145996 | BCE Loss: 1.0328267812728882\n",
      "Epoch 492 / 500 | iteration 15 / 30 | Total Loss: 3.509786605834961 | KNN Loss: 2.486628293991089 | BCE Loss: 1.023158311843872\n",
      "Epoch 492 / 500 | iteration 20 / 30 | Total Loss: 3.4525349140167236 | KNN Loss: 2.456728458404541 | BCE Loss: 0.9958064556121826\n",
      "Epoch 492 / 500 | iteration 25 / 30 | Total Loss: 3.493332862854004 | KNN Loss: 2.477674961090088 | BCE Loss: 1.015657901763916\n",
      "Epoch 493 / 500 | iteration 0 / 30 | Total Loss: 3.456085681915283 | KNN Loss: 2.4276230335235596 | BCE Loss: 1.0284626483917236\n",
      "Epoch 493 / 500 | iteration 5 / 30 | Total Loss: 3.4495348930358887 | KNN Loss: 2.437732219696045 | BCE Loss: 1.0118027925491333\n",
      "Epoch 493 / 500 | iteration 10 / 30 | Total Loss: 3.4095869064331055 | KNN Loss: 2.4085254669189453 | BCE Loss: 1.0010614395141602\n",
      "Epoch 493 / 500 | iteration 15 / 30 | Total Loss: 3.44828462600708 | KNN Loss: 2.4404542446136475 | BCE Loss: 1.0078303813934326\n",
      "Epoch 493 / 500 | iteration 20 / 30 | Total Loss: 3.4562387466430664 | KNN Loss: 2.4390969276428223 | BCE Loss: 1.0171418190002441\n",
      "Epoch 493 / 500 | iteration 25 / 30 | Total Loss: 3.443922281265259 | KNN Loss: 2.4288570880889893 | BCE Loss: 1.0150651931762695\n",
      "Epoch 494 / 500 | iteration 0 / 30 | Total Loss: 3.449117422103882 | KNN Loss: 2.4421684741973877 | BCE Loss: 1.0069489479064941\n",
      "Epoch 494 / 500 | iteration 5 / 30 | Total Loss: 3.4301810264587402 | KNN Loss: 2.4486823081970215 | BCE Loss: 0.9814988374710083\n",
      "Epoch 494 / 500 | iteration 10 / 30 | Total Loss: 3.4714624881744385 | KNN Loss: 2.4439401626586914 | BCE Loss: 1.027522325515747\n",
      "Epoch 494 / 500 | iteration 15 / 30 | Total Loss: 3.483844757080078 | KNN Loss: 2.470759630203247 | BCE Loss: 1.013085126876831\n",
      "Epoch 494 / 500 | iteration 20 / 30 | Total Loss: 3.490431070327759 | KNN Loss: 2.4404375553131104 | BCE Loss: 1.0499935150146484\n",
      "Epoch 494 / 500 | iteration 25 / 30 | Total Loss: 3.4563639163970947 | KNN Loss: 2.443413019180298 | BCE Loss: 1.0129508972167969\n",
      "Epoch 495 / 500 | iteration 0 / 30 | Total Loss: 3.454089641571045 | KNN Loss: 2.451763391494751 | BCE Loss: 1.0023263692855835\n",
      "Epoch 495 / 500 | iteration 5 / 30 | Total Loss: 3.441612482070923 | KNN Loss: 2.410897731781006 | BCE Loss: 1.030714750289917\n",
      "Epoch 495 / 500 | iteration 10 / 30 | Total Loss: 3.4613687992095947 | KNN Loss: 2.4309544563293457 | BCE Loss: 1.030414342880249\n",
      "Epoch 495 / 500 | iteration 15 / 30 | Total Loss: 3.493967294692993 | KNN Loss: 2.483534574508667 | BCE Loss: 1.0104327201843262\n",
      "Epoch 495 / 500 | iteration 20 / 30 | Total Loss: 3.489895820617676 | KNN Loss: 2.470512628555298 | BCE Loss: 1.0193833112716675\n",
      "Epoch 495 / 500 | iteration 25 / 30 | Total Loss: 3.4408178329467773 | KNN Loss: 2.4408271312713623 | BCE Loss: 0.9999906420707703\n",
      "Epoch 496 / 500 | iteration 0 / 30 | Total Loss: 3.4888925552368164 | KNN Loss: 2.470486879348755 | BCE Loss: 1.0184056758880615\n",
      "Epoch 496 / 500 | iteration 5 / 30 | Total Loss: 3.4622721672058105 | KNN Loss: 2.441816806793213 | BCE Loss: 1.0204554796218872\n",
      "Epoch 496 / 500 | iteration 10 / 30 | Total Loss: 3.482288360595703 | KNN Loss: 2.406496286392212 | BCE Loss: 1.0757920742034912\n",
      "Epoch 496 / 500 | iteration 15 / 30 | Total Loss: 3.491647958755493 | KNN Loss: 2.466771125793457 | BCE Loss: 1.0248768329620361\n",
      "Epoch 496 / 500 | iteration 20 / 30 | Total Loss: 3.4950058460235596 | KNN Loss: 2.4608514308929443 | BCE Loss: 1.0341544151306152\n",
      "Epoch 496 / 500 | iteration 25 / 30 | Total Loss: 3.496227741241455 | KNN Loss: 2.467808961868286 | BCE Loss: 1.028418779373169\n",
      "Epoch 497 / 500 | iteration 0 / 30 | Total Loss: 3.4758493900299072 | KNN Loss: 2.4104371070861816 | BCE Loss: 1.0654122829437256\n",
      "Epoch 497 / 500 | iteration 5 / 30 | Total Loss: 3.4884772300720215 | KNN Loss: 2.4717328548431396 | BCE Loss: 1.0167443752288818\n",
      "Epoch 497 / 500 | iteration 10 / 30 | Total Loss: 3.530132293701172 | KNN Loss: 2.510112762451172 | BCE Loss: 1.02001953125\n",
      "Epoch 497 / 500 | iteration 15 / 30 | Total Loss: 3.466946840286255 | KNN Loss: 2.464625358581543 | BCE Loss: 1.002321481704712\n",
      "Epoch 497 / 500 | iteration 20 / 30 | Total Loss: 3.4428744316101074 | KNN Loss: 2.449665069580078 | BCE Loss: 0.9932094812393188\n",
      "Epoch 497 / 500 | iteration 25 / 30 | Total Loss: 3.464257001876831 | KNN Loss: 2.4718682765960693 | BCE Loss: 0.9923887252807617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   498: reducing learning rate of group 0 to 9.5791e-07.\n",
      "Epoch 498 / 500 | iteration 0 / 30 | Total Loss: 3.493215560913086 | KNN Loss: 2.460930585861206 | BCE Loss: 1.0322850942611694\n",
      "Epoch 498 / 500 | iteration 5 / 30 | Total Loss: 3.4536564350128174 | KNN Loss: 2.4292213916778564 | BCE Loss: 1.024435043334961\n",
      "Epoch 498 / 500 | iteration 10 / 30 | Total Loss: 3.451491594314575 | KNN Loss: 2.449463367462158 | BCE Loss: 1.002028226852417\n",
      "Epoch 498 / 500 | iteration 15 / 30 | Total Loss: 3.4769890308380127 | KNN Loss: 2.4451828002929688 | BCE Loss: 1.031806230545044\n",
      "Epoch 498 / 500 | iteration 20 / 30 | Total Loss: 3.489982843399048 | KNN Loss: 2.4779584407806396 | BCE Loss: 1.0120244026184082\n",
      "Epoch 498 / 500 | iteration 25 / 30 | Total Loss: 3.477921724319458 | KNN Loss: 2.450702428817749 | BCE Loss: 1.027219295501709\n",
      "Epoch 499 / 500 | iteration 0 / 30 | Total Loss: 3.42901873588562 | KNN Loss: 2.4322667121887207 | BCE Loss: 0.9967520833015442\n",
      "Epoch 499 / 500 | iteration 5 / 30 | Total Loss: 3.4288318157196045 | KNN Loss: 2.4176740646362305 | BCE Loss: 1.011157751083374\n",
      "Epoch 499 / 500 | iteration 10 / 30 | Total Loss: 3.4627573490142822 | KNN Loss: 2.450950860977173 | BCE Loss: 1.0118064880371094\n",
      "Epoch 499 / 500 | iteration 15 / 30 | Total Loss: 3.457042694091797 | KNN Loss: 2.46618914604187 | BCE Loss: 0.990853488445282\n",
      "Epoch 499 / 500 | iteration 20 / 30 | Total Loss: 3.4854788780212402 | KNN Loss: 2.4734549522399902 | BCE Loss: 1.0120238065719604\n",
      "Epoch 499 / 500 | iteration 25 / 30 | Total Loss: 3.4853057861328125 | KNN Loss: 2.456956386566162 | BCE Loss: 1.0283492803573608\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "data_iter = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=1,\n",
    "                                     pin_memory=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', verbose=True, factor=0.7, threshold=1e-4)\n",
    "knn_crt = KNNLoss(k=k).to(device)\n",
    "losses = []\n",
    "alpha = 10/170\n",
    "gamma = 2\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(data_iter):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, iterm = model(batch, return_intermidiate=True)\n",
    "        mse_loss = F.binary_cross_entropy_with_logits(outputs, target, reduction='none')\n",
    "        mask = torch.ones_like(mse_loss)\n",
    "        mask[target == 0] = alpha ** gamma\n",
    "        mask[target == 1] = (1 - alpha) ** gamma\n",
    "        mse_loss = (mse_loss * mask).sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(iterm)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = 0\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(data_iter)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | BCE Loss: {mse_loss.item()}\")\n",
    "    \n",
    "    scheduler.step(total_loss / (iteration + 1))\n",
    "    losses.append(total_loss / (iteration + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0974,  2.4199,  2.8636,  3.6784,  2.6929,  0.8784,  2.8699,  2.5165,\n",
      "          2.5702,  2.1222,  2.4783,  2.5003,  1.1700,  2.0119,  1.4261,  1.7646,\n",
      "          1.8027,  3.2493,  2.1962,  2.4891,  1.9998,  2.9664,  2.0832,  2.3126,\n",
      "          2.5504,  1.9909,  2.3046,  1.7974,  1.6798,  0.1771, -0.2215,  0.4746,\n",
      "          0.3704,  1.1309,  1.7533,  1.6911,  1.4606,  2.5366,  0.3809,  1.5309,\n",
      "          0.8706, -0.5006,  0.1272,  2.5845,  1.7429,  0.9854, -0.0687,  0.3883,\n",
      "          1.7073,  2.3993,  1.8991,  0.4401,  1.8039,  0.7181, -0.4625,  1.3088,\n",
      "          0.9047,  1.4864,  1.5912,  2.0448,  0.6664,  0.2319, -0.2534,  1.8781,\n",
      "          1.6133,  2.0089, -2.0149,  0.5438,  2.2521,  2.2253,  1.9007,  0.7418,\n",
      "          1.6033,  2.0876,  1.7641,  1.5441,  0.2970,  0.8440,  0.4793,  1.8122,\n",
      "          0.1397,  0.6163,  1.9695, -0.3058,  0.2172, -0.6535, -2.0342, -0.1630,\n",
      "          0.7243, -2.3721,  0.7076, -0.0236, -0.5952, -0.6824,  0.4202,  1.4988,\n",
      "         -0.9907, -0.6045,  0.4256,  1.4797,  0.9966, -1.3034,  1.1519,  1.3023,\n",
      "         -1.3152, -0.8475, -0.1155,  0.3242, -1.0228, -1.3239, -0.7382, -2.5558,\n",
      "         -0.2675,  1.5838,  1.5462, -0.5036, -0.7472,  0.3348,  1.6818, -2.1116,\n",
      "          0.4195, -0.0058,  0.4557, -0.6560,  0.3233, -0.6974, -0.6877,  1.2409,\n",
      "          0.5642, -0.4997,  0.5312, -0.3966, -1.1261, -0.1926, -0.2896,  1.0890,\n",
      "         -0.2108,  0.3412, -2.3159, -0.7121, -1.1497,  0.8856, -1.7410, -1.0159,\n",
      "         -1.1061, -0.3240, -1.4473, -0.7196, -2.5865, -1.1334, -1.4421, -0.1437,\n",
      "         -1.5187,  0.6523, -1.6447, -0.4948, -3.9450,  0.2077, -0.3237, -0.5985,\n",
      "         -2.3912, -1.4376, -0.9061, -1.2930, -2.1138, -2.2120, -3.5262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor(-3.9450, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(3.6784, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs, iterm = model(dataset[67][0].unsqueeze(0).to(device), return_intermidiate=True)\n",
    "print(outputs)\n",
    "print(outputs.min())\n",
    "print(outputs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fcd376a0984456906cfdc5ea021c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform = torchvision.transforms.Compose([\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")\n",
    "dataset.target_transform = torchvision.transforms.Compose([\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = [d[0].cpu() for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 91.38it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval().cpu()\n",
    "projections = model.calculate_intermidiate(dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822d0c50aed94d0db32b5aff6ab25dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb111c6b02d1439dadf4eccc1e8c5c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit DBSCAN and calculate indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=0.2, min_samples=80).fit_predict(projections)\n",
    "# scores = []\n",
    "# best_score = float('inf')\n",
    "# clusters = None\n",
    "# range_ = list(range(5, 20))\n",
    "# for k in tqdm(range_):\n",
    "#     y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "#     cur_score = davies_bouldin_score(projections, y)\n",
    "#     scores.append(cur_score)\n",
    "    \n",
    "#     if cur_score < best_score:\n",
    "#         best_score = cur_score\n",
    "#         clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0659f0300f554827b62a4ad7f6a386c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn import tree\n",
    "# from sklearn.tree import _tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset = torch.stack(dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = DecisionTreeClassifier(max_depth=200, min_samples_leaf=5)\n",
    "# clf = clf.fit(tensor_dataset[clusters!=-1], clusters[clusters != -1])\n",
    "# print(clf.score(tensor_dataset[clusters!=-1], clusters[clusters != -1]))\n",
    "# print(clf.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# for min_samples in range(1,50, 1):\n",
    "#     clf = DecisionTreeClassifier(max_depth=200, min_samples_leaf=min_samples)\n",
    "#     clf = clf.fit(tensor_dataset[clusters!=-1], clusters[clusters != -1])\n",
    "#     scores.append(clf.score(tensor_dataset[clusters!=-1], clusters[clusters != -1]))\n",
    "    \n",
    "# plt.figure()\n",
    "# plt.plot(list(range(1,50, 1)), scores)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rules(tree, feature_names, class_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    path = []\n",
    "    \n",
    "    def recurse(node, path, paths):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            p1, p2 = list(path), list(path)\n",
    "#             p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "            p1 += [(name, '<=', np.round(threshold, 3))]\n",
    "            recurse(tree_.children_left[node], p1, paths)\n",
    "            p2 += [(name, '>', np.round(threshold, 3))]\n",
    "            recurse(tree_.children_right[node], p2, paths)\n",
    "        else:\n",
    "            path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "            paths += [path]\n",
    "            \n",
    "    recurse(0, path, paths)\n",
    "\n",
    "    # sort by samples count\n",
    "    samples_count = [p[-1][1] for p in paths]\n",
    "    ii = list(np.argsort(samples_count))\n",
    "    paths = [paths[i] for i in reversed(ii)]\n",
    "    \n",
    "    rules = []\n",
    "    for path in paths:\n",
    "        rule = []\n",
    "        \n",
    "        for p in path[:-1]:\n",
    "            rule += [p]\n",
    "        target = \" then \"\n",
    "        if class_names is None:\n",
    "            target += \"response: \"+str(np.round(path[-1][0][0][0],3))\n",
    "        else:\n",
    "            classes = path[-1][0][0]\n",
    "            l = np.argmax(classes)\n",
    "            target += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n",
    "           \n",
    "        proba = np.round(100.0*classes[l]/np.sum(classes),2)\n",
    "        target += f\" | based on {path[-1][1]:,} samples\"\n",
    "        rule_wrapper = {'target': target, 'rule': rule, 'proba': proba}\n",
    "        rules += [rule_wrapper]\n",
    "        \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules = get_rules(clf, dataset.items, clusters[clusters != -1])\n",
    "\n",
    "# for rule in rules:\n",
    "#     n_pos = 0\n",
    "#     for c,p,v in rule['rule']:\n",
    "#         if p == '>':\n",
    "#             n_pos += 1\n",
    "#     rule['pos'] = n_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# probs = [r['proba'] for r in rules]\n",
    "# plt.hist(probs, bins = 100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules = sorted(rules, key=lambda x:x['pos'])\n",
    "# rules = [r for r in rules if r['proba'] > 50]\n",
    "# print(len(rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(17):\n",
    "#     r_i = rules[i]\n",
    "#     print(f\"------------- rule {i} length {len(r_i)} -------------\")\n",
    "#     print(r_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(tensor_dataset[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 100\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=tensor_dataset.shape[1], output_dim=len(clusters - 1), depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "Epoch: 00 | Batch: 000 / 002 | Total loss: 9.605 | Reg loss: 0.009 | Tree loss: 9.605 | Accuracy: 0.000000 | 0.245 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 002 | Total loss: 9.591 | Reg loss: 0.009 | Tree loss: 9.591 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 01 | Batch: 000 / 002 | Total loss: 9.589 | Reg loss: 0.002 | Tree loss: 9.589 | Accuracy: 0.000000 | 0.221 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 002 | Total loss: 9.578 | Reg loss: 0.002 | Tree loss: 9.578 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 02 | Batch: 000 / 002 | Total loss: 9.581 | Reg loss: 0.002 | Tree loss: 9.581 | Accuracy: 0.000000 | 0.22 sec/iter\n",
      "Epoch: 02 | Batch: 001 / 002 | Total loss: 9.568 | Reg loss: 0.003 | Tree loss: 9.568 | Accuracy: 0.000000 | 0.215 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 03 | Batch: 000 / 002 | Total loss: 9.572 | Reg loss: 0.002 | Tree loss: 9.572 | Accuracy: 0.000000 | 0.217 sec/iter\n",
      "Epoch: 03 | Batch: 001 / 002 | Total loss: 9.560 | Reg loss: 0.003 | Tree loss: 9.560 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 04 | Batch: 000 / 002 | Total loss: 9.564 | Reg loss: 0.003 | Tree loss: 9.564 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Epoch: 04 | Batch: 001 / 002 | Total loss: 9.550 | Reg loss: 0.003 | Tree loss: 9.550 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 05 | Batch: 000 / 002 | Total loss: 9.554 | Reg loss: 0.003 | Tree loss: 9.554 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Epoch: 05 | Batch: 001 / 002 | Total loss: 9.543 | Reg loss: 0.003 | Tree loss: 9.543 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 06 | Batch: 000 / 002 | Total loss: 9.546 | Reg loss: 0.003 | Tree loss: 9.546 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Epoch: 06 | Batch: 001 / 002 | Total loss: 9.533 | Reg loss: 0.003 | Tree loss: 9.533 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 07 | Batch: 000 / 002 | Total loss: 9.538 | Reg loss: 0.003 | Tree loss: 9.538 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Epoch: 07 | Batch: 001 / 002 | Total loss: 9.523 | Reg loss: 0.003 | Tree loss: 9.523 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 08 | Batch: 000 / 002 | Total loss: 9.530 | Reg loss: 0.003 | Tree loss: 9.530 | Accuracy: 0.000000 | 0.216 sec/iter\n",
      "Epoch: 08 | Batch: 001 / 002 | Total loss: 9.513 | Reg loss: 0.003 | Tree loss: 9.513 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 09 | Batch: 000 / 002 | Total loss: 9.522 | Reg loss: 0.003 | Tree loss: 9.522 | Accuracy: 0.000000 | 0.215 sec/iter\n",
      "Epoch: 09 | Batch: 001 / 002 | Total loss: 9.504 | Reg loss: 0.004 | Tree loss: 9.504 | Accuracy: 0.000000 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 10 | Batch: 000 / 002 | Total loss: 9.510 | Reg loss: 0.004 | Tree loss: 9.510 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Epoch: 10 | Batch: 001 / 002 | Total loss: 9.499 | Reg loss: 0.004 | Tree loss: 9.499 | Accuracy: 0.000000 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 11 | Batch: 000 / 002 | Total loss: 9.501 | Reg loss: 0.004 | Tree loss: 9.501 | Accuracy: 0.000000 | 0.214 sec/iter\n",
      "Epoch: 11 | Batch: 001 / 002 | Total loss: 9.490 | Reg loss: 0.004 | Tree loss: 9.490 | Accuracy: 0.000000 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 12 | Batch: 000 / 002 | Total loss: 9.494 | Reg loss: 0.004 | Tree loss: 9.494 | Accuracy: 0.001953 | 0.214 sec/iter\n",
      "Epoch: 12 | Batch: 001 / 002 | Total loss: 9.480 | Reg loss: 0.004 | Tree loss: 9.480 | Accuracy: 0.029213 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 13 | Batch: 000 / 002 | Total loss: 9.485 | Reg loss: 0.004 | Tree loss: 9.485 | Accuracy: 0.011719 | 0.213 sec/iter\n",
      "Epoch: 13 | Batch: 001 / 002 | Total loss: 9.472 | Reg loss: 0.004 | Tree loss: 9.472 | Accuracy: 0.125843 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 14 | Batch: 000 / 002 | Total loss: 9.480 | Reg loss: 0.004 | Tree loss: 9.480 | Accuracy: 0.089844 | 0.213 sec/iter\n",
      "Epoch: 14 | Batch: 001 / 002 | Total loss: 9.458 | Reg loss: 0.004 | Tree loss: 9.458 | Accuracy: 0.157303 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 15 | Batch: 000 / 002 | Total loss: 9.467 | Reg loss: 0.004 | Tree loss: 9.467 | Accuracy: 0.148438 | 0.213 sec/iter\n",
      "Epoch: 15 | Batch: 001 / 002 | Total loss: 9.455 | Reg loss: 0.004 | Tree loss: 9.455 | Accuracy: 0.143820 | 0.213 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 16 | Batch: 000 / 002 | Total loss: 9.458 | Reg loss: 0.004 | Tree loss: 9.458 | Accuracy: 0.162109 | 0.214 sec/iter\n",
      "Epoch: 16 | Batch: 001 / 002 | Total loss: 9.447 | Reg loss: 0.005 | Tree loss: 9.447 | Accuracy: 0.132584 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Batch: 000 / 002 | Total loss: 9.449 | Reg loss: 0.005 | Tree loss: 9.449 | Accuracy: 0.140625 | 0.214 sec/iter\n",
      "Epoch: 17 | Batch: 001 / 002 | Total loss: 9.439 | Reg loss: 0.005 | Tree loss: 9.439 | Accuracy: 0.166292 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 18 | Batch: 000 / 002 | Total loss: 9.441 | Reg loss: 0.005 | Tree loss: 9.441 | Accuracy: 0.148438 | 0.215 sec/iter\n",
      "Epoch: 18 | Batch: 001 / 002 | Total loss: 9.429 | Reg loss: 0.005 | Tree loss: 9.429 | Accuracy: 0.184270 | 0.214 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 19 | Batch: 000 / 002 | Total loss: 9.433 | Reg loss: 0.005 | Tree loss: 9.433 | Accuracy: 0.160156 | 0.215 sec/iter\n",
      "Epoch: 19 | Batch: 001 / 002 | Total loss: 9.421 | Reg loss: 0.005 | Tree loss: 9.421 | Accuracy: 0.184270 | 0.215 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 20 | Batch: 000 / 002 | Total loss: 9.427 | Reg loss: 0.005 | Tree loss: 9.427 | Accuracy: 0.166016 | 0.215 sec/iter\n",
      "Epoch: 20 | Batch: 001 / 002 | Total loss: 9.410 | Reg loss: 0.005 | Tree loss: 9.410 | Accuracy: 0.224719 | 0.215 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 21 | Batch: 000 / 002 | Total loss: 9.414 | Reg loss: 0.005 | Tree loss: 9.414 | Accuracy: 0.171875 | 0.216 sec/iter\n",
      "Epoch: 21 | Batch: 001 / 002 | Total loss: 9.407 | Reg loss: 0.005 | Tree loss: 9.407 | Accuracy: 0.238202 | 0.215 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 22 | Batch: 000 / 002 | Total loss: 9.408 | Reg loss: 0.005 | Tree loss: 9.408 | Accuracy: 0.210938 | 0.216 sec/iter\n",
      "Epoch: 22 | Batch: 001 / 002 | Total loss: 9.396 | Reg loss: 0.005 | Tree loss: 9.396 | Accuracy: 0.256180 | 0.216 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 23 | Batch: 000 / 002 | Total loss: 9.396 | Reg loss: 0.005 | Tree loss: 9.396 | Accuracy: 0.212891 | 0.216 sec/iter\n",
      "Epoch: 23 | Batch: 001 / 002 | Total loss: 9.392 | Reg loss: 0.005 | Tree loss: 9.392 | Accuracy: 0.292135 | 0.216 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 24 | Batch: 000 / 002 | Total loss: 9.389 | Reg loss: 0.005 | Tree loss: 9.389 | Accuracy: 0.248047 | 0.217 sec/iter\n",
      "Epoch: 24 | Batch: 001 / 002 | Total loss: 9.381 | Reg loss: 0.006 | Tree loss: 9.381 | Accuracy: 0.330337 | 0.217 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 25 | Batch: 000 / 002 | Total loss: 9.382 | Reg loss: 0.006 | Tree loss: 9.382 | Accuracy: 0.291016 | 0.218 sec/iter\n",
      "Epoch: 25 | Batch: 001 / 002 | Total loss: 9.372 | Reg loss: 0.006 | Tree loss: 9.372 | Accuracy: 0.314607 | 0.217 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 26 | Batch: 000 / 002 | Total loss: 9.376 | Reg loss: 0.006 | Tree loss: 9.376 | Accuracy: 0.312500 | 0.218 sec/iter\n",
      "Epoch: 26 | Batch: 001 / 002 | Total loss: 9.361 | Reg loss: 0.006 | Tree loss: 9.361 | Accuracy: 0.312360 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 27 | Batch: 000 / 002 | Total loss: 9.370 | Reg loss: 0.006 | Tree loss: 9.370 | Accuracy: 0.298828 | 0.218 sec/iter\n",
      "Epoch: 27 | Batch: 001 / 002 | Total loss: 9.350 | Reg loss: 0.006 | Tree loss: 9.350 | Accuracy: 0.330337 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 28 | Batch: 000 / 002 | Total loss: 9.356 | Reg loss: 0.006 | Tree loss: 9.356 | Accuracy: 0.314453 | 0.218 sec/iter\n",
      "Epoch: 28 | Batch: 001 / 002 | Total loss: 9.349 | Reg loss: 0.006 | Tree loss: 9.349 | Accuracy: 0.314607 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 29 | Batch: 000 / 002 | Total loss: 9.350 | Reg loss: 0.006 | Tree loss: 9.350 | Accuracy: 0.324219 | 0.218 sec/iter\n",
      "Epoch: 29 | Batch: 001 / 002 | Total loss: 9.338 | Reg loss: 0.006 | Tree loss: 9.338 | Accuracy: 0.303371 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 30 | Batch: 000 / 002 | Total loss: 9.340 | Reg loss: 0.006 | Tree loss: 9.340 | Accuracy: 0.318359 | 0.218 sec/iter\n",
      "Epoch: 30 | Batch: 001 / 002 | Total loss: 9.333 | Reg loss: 0.006 | Tree loss: 9.333 | Accuracy: 0.310112 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 31 | Batch: 000 / 002 | Total loss: 9.336 | Reg loss: 0.006 | Tree loss: 9.336 | Accuracy: 0.300781 | 0.218 sec/iter\n",
      "Epoch: 31 | Batch: 001 / 002 | Total loss: 9.320 | Reg loss: 0.006 | Tree loss: 9.320 | Accuracy: 0.330337 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 32 | Batch: 000 / 002 | Total loss: 9.324 | Reg loss: 0.006 | Tree loss: 9.324 | Accuracy: 0.318359 | 0.219 sec/iter\n",
      "Epoch: 32 | Batch: 001 / 002 | Total loss: 9.317 | Reg loss: 0.006 | Tree loss: 9.317 | Accuracy: 0.310112 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 33 | Batch: 000 / 002 | Total loss: 9.321 | Reg loss: 0.006 | Tree loss: 9.321 | Accuracy: 0.304688 | 0.219 sec/iter\n",
      "Epoch: 33 | Batch: 001 / 002 | Total loss: 9.302 | Reg loss: 0.006 | Tree loss: 9.302 | Accuracy: 0.325843 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Batch: 000 / 002 | Total loss: 9.307 | Reg loss: 0.006 | Tree loss: 9.307 | Accuracy: 0.306641 | 0.219 sec/iter\n",
      "Epoch: 34 | Batch: 001 / 002 | Total loss: 9.301 | Reg loss: 0.007 | Tree loss: 9.301 | Accuracy: 0.323596 | 0.218 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 35 | Batch: 000 / 002 | Total loss: 9.295 | Reg loss: 0.007 | Tree loss: 9.295 | Accuracy: 0.326172 | 0.219 sec/iter\n",
      "Epoch: 35 | Batch: 001 / 002 | Total loss: 9.298 | Reg loss: 0.007 | Tree loss: 9.298 | Accuracy: 0.301124 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 36 | Batch: 000 / 002 | Total loss: 9.295 | Reg loss: 0.007 | Tree loss: 9.295 | Accuracy: 0.302734 | 0.219 sec/iter\n",
      "Epoch: 36 | Batch: 001 / 002 | Total loss: 9.280 | Reg loss: 0.007 | Tree loss: 9.280 | Accuracy: 0.328090 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 37 | Batch: 000 / 002 | Total loss: 9.283 | Reg loss: 0.007 | Tree loss: 9.283 | Accuracy: 0.326172 | 0.219 sec/iter\n",
      "Epoch: 37 | Batch: 001 / 002 | Total loss: 9.277 | Reg loss: 0.007 | Tree loss: 9.277 | Accuracy: 0.301124 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 38 | Batch: 000 / 002 | Total loss: 9.278 | Reg loss: 0.007 | Tree loss: 9.278 | Accuracy: 0.296875 | 0.219 sec/iter\n",
      "Epoch: 38 | Batch: 001 / 002 | Total loss: 9.266 | Reg loss: 0.007 | Tree loss: 9.266 | Accuracy: 0.334831 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 39 | Batch: 000 / 002 | Total loss: 9.265 | Reg loss: 0.007 | Tree loss: 9.265 | Accuracy: 0.302734 | 0.219 sec/iter\n",
      "Epoch: 39 | Batch: 001 / 002 | Total loss: 9.264 | Reg loss: 0.007 | Tree loss: 9.264 | Accuracy: 0.328090 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 40 | Batch: 000 / 002 | Total loss: 9.256 | Reg loss: 0.007 | Tree loss: 9.256 | Accuracy: 0.330078 | 0.219 sec/iter\n",
      "Epoch: 40 | Batch: 001 / 002 | Total loss: 9.257 | Reg loss: 0.007 | Tree loss: 9.257 | Accuracy: 0.296629 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 41 | Batch: 000 / 002 | Total loss: 9.253 | Reg loss: 0.007 | Tree loss: 9.253 | Accuracy: 0.316406 | 0.22 sec/iter\n",
      "Epoch: 41 | Batch: 001 / 002 | Total loss: 9.243 | Reg loss: 0.007 | Tree loss: 9.243 | Accuracy: 0.312360 | 0.219 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 42 | Batch: 000 / 002 | Total loss: 9.234 | Reg loss: 0.007 | Tree loss: 9.234 | Accuracy: 0.339844 | 0.22 sec/iter\n",
      "Epoch: 42 | Batch: 001 / 002 | Total loss: 9.250 | Reg loss: 0.007 | Tree loss: 9.250 | Accuracy: 0.285393 | 0.22 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 43 | Batch: 000 / 002 | Total loss: 9.234 | Reg loss: 0.007 | Tree loss: 9.234 | Accuracy: 0.328125 | 0.22 sec/iter\n",
      "Epoch: 43 | Batch: 001 / 002 | Total loss: 9.231 | Reg loss: 0.007 | Tree loss: 9.231 | Accuracy: 0.298876 | 0.22 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 44 | Batch: 000 / 002 | Total loss: 9.232 | Reg loss: 0.007 | Tree loss: 9.232 | Accuracy: 0.304688 | 0.22 sec/iter\n",
      "Epoch: 44 | Batch: 001 / 002 | Total loss: 9.217 | Reg loss: 0.007 | Tree loss: 9.217 | Accuracy: 0.325843 | 0.22 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 45 | Batch: 000 / 002 | Total loss: 9.217 | Reg loss: 0.007 | Tree loss: 9.217 | Accuracy: 0.326172 | 0.221 sec/iter\n",
      "Epoch: 45 | Batch: 001 / 002 | Total loss: 9.217 | Reg loss: 0.008 | Tree loss: 9.217 | Accuracy: 0.301124 | 0.221 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 46 | Batch: 000 / 002 | Total loss: 9.213 | Reg loss: 0.008 | Tree loss: 9.213 | Accuracy: 0.318359 | 0.221 sec/iter\n",
      "Epoch: 46 | Batch: 001 / 002 | Total loss: 9.205 | Reg loss: 0.008 | Tree loss: 9.205 | Accuracy: 0.310112 | 0.221 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 47 | Batch: 000 / 002 | Total loss: 9.204 | Reg loss: 0.008 | Tree loss: 9.204 | Accuracy: 0.328125 | 0.222 sec/iter\n",
      "Epoch: 47 | Batch: 001 / 002 | Total loss: 9.198 | Reg loss: 0.008 | Tree loss: 9.198 | Accuracy: 0.298876 | 0.222 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 48 | Batch: 000 / 002 | Total loss: 9.196 | Reg loss: 0.008 | Tree loss: 9.196 | Accuracy: 0.322266 | 0.222 sec/iter\n",
      "Epoch: 48 | Batch: 001 / 002 | Total loss: 9.191 | Reg loss: 0.008 | Tree loss: 9.191 | Accuracy: 0.305618 | 0.222 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 49 | Batch: 000 / 002 | Total loss: 9.184 | Reg loss: 0.008 | Tree loss: 9.184 | Accuracy: 0.343750 | 0.223 sec/iter\n",
      "Epoch: 49 | Batch: 001 / 002 | Total loss: 9.188 | Reg loss: 0.008 | Tree loss: 9.188 | Accuracy: 0.280899 | 0.223 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 50 | Batch: 000 / 002 | Total loss: 9.188 | Reg loss: 0.008 | Tree loss: 9.188 | Accuracy: 0.292969 | 0.223 sec/iter\n",
      "Epoch: 50 | Batch: 001 / 002 | Total loss: 9.166 | Reg loss: 0.008 | Tree loss: 9.166 | Accuracy: 0.339326 | 0.223 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 51 | Batch: 000 / 002 | Total loss: 9.176 | Reg loss: 0.008 | Tree loss: 9.176 | Accuracy: 0.316406 | 0.224 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | Batch: 001 / 002 | Total loss: 9.163 | Reg loss: 0.008 | Tree loss: 9.163 | Accuracy: 0.312360 | 0.224 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 52 | Batch: 000 / 002 | Total loss: 9.161 | Reg loss: 0.008 | Tree loss: 9.161 | Accuracy: 0.347656 | 0.224 sec/iter\n",
      "Epoch: 52 | Batch: 001 / 002 | Total loss: 9.164 | Reg loss: 0.008 | Tree loss: 9.164 | Accuracy: 0.276404 | 0.224 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 53 | Batch: 000 / 002 | Total loss: 9.159 | Reg loss: 0.008 | Tree loss: 9.159 | Accuracy: 0.320312 | 0.225 sec/iter\n",
      "Epoch: 53 | Batch: 001 / 002 | Total loss: 9.149 | Reg loss: 0.008 | Tree loss: 9.149 | Accuracy: 0.307865 | 0.225 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 54 | Batch: 000 / 002 | Total loss: 9.153 | Reg loss: 0.008 | Tree loss: 9.153 | Accuracy: 0.310547 | 0.225 sec/iter\n",
      "Epoch: 54 | Batch: 001 / 002 | Total loss: 9.139 | Reg loss: 0.008 | Tree loss: 9.139 | Accuracy: 0.319101 | 0.225 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 55 | Batch: 000 / 002 | Total loss: 9.144 | Reg loss: 0.008 | Tree loss: 9.144 | Accuracy: 0.312500 | 0.225 sec/iter\n",
      "Epoch: 55 | Batch: 001 / 002 | Total loss: 9.132 | Reg loss: 0.008 | Tree loss: 9.132 | Accuracy: 0.316854 | 0.225 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 56 | Batch: 000 / 002 | Total loss: 9.137 | Reg loss: 0.008 | Tree loss: 9.137 | Accuracy: 0.326172 | 0.226 sec/iter\n",
      "Epoch: 56 | Batch: 001 / 002 | Total loss: 9.124 | Reg loss: 0.009 | Tree loss: 9.124 | Accuracy: 0.301124 | 0.226 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 57 | Batch: 000 / 002 | Total loss: 9.127 | Reg loss: 0.009 | Tree loss: 9.127 | Accuracy: 0.296875 | 0.226 sec/iter\n",
      "Epoch: 57 | Batch: 001 / 002 | Total loss: 9.118 | Reg loss: 0.009 | Tree loss: 9.118 | Accuracy: 0.334831 | 0.226 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 58 | Batch: 000 / 002 | Total loss: 9.116 | Reg loss: 0.009 | Tree loss: 9.116 | Accuracy: 0.318359 | 0.227 sec/iter\n",
      "Epoch: 58 | Batch: 001 / 002 | Total loss: 9.114 | Reg loss: 0.009 | Tree loss: 9.114 | Accuracy: 0.310112 | 0.226 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 59 | Batch: 000 / 002 | Total loss: 9.112 | Reg loss: 0.009 | Tree loss: 9.112 | Accuracy: 0.324219 | 0.227 sec/iter\n",
      "Epoch: 59 | Batch: 001 / 002 | Total loss: 9.102 | Reg loss: 0.009 | Tree loss: 9.102 | Accuracy: 0.303371 | 0.227 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 60 | Batch: 000 / 002 | Total loss: 9.106 | Reg loss: 0.009 | Tree loss: 9.106 | Accuracy: 0.310547 | 0.227 sec/iter\n",
      "Epoch: 60 | Batch: 001 / 002 | Total loss: 9.092 | Reg loss: 0.009 | Tree loss: 9.092 | Accuracy: 0.319101 | 0.227 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 61 | Batch: 000 / 002 | Total loss: 9.098 | Reg loss: 0.009 | Tree loss: 9.098 | Accuracy: 0.314453 | 0.227 sec/iter\n",
      "Epoch: 61 | Batch: 001 / 002 | Total loss: 9.084 | Reg loss: 0.009 | Tree loss: 9.084 | Accuracy: 0.314607 | 0.227 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 62 | Batch: 000 / 002 | Total loss: 9.082 | Reg loss: 0.009 | Tree loss: 9.082 | Accuracy: 0.314453 | 0.228 sec/iter\n",
      "Epoch: 62 | Batch: 001 / 002 | Total loss: 9.086 | Reg loss: 0.009 | Tree loss: 9.086 | Accuracy: 0.314607 | 0.228 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 63 | Batch: 000 / 002 | Total loss: 9.074 | Reg loss: 0.009 | Tree loss: 9.074 | Accuracy: 0.326172 | 0.228 sec/iter\n",
      "Epoch: 63 | Batch: 001 / 002 | Total loss: 9.077 | Reg loss: 0.009 | Tree loss: 9.077 | Accuracy: 0.301124 | 0.228 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 64 | Batch: 000 / 002 | Total loss: 9.071 | Reg loss: 0.009 | Tree loss: 9.071 | Accuracy: 0.318359 | 0.228 sec/iter\n",
      "Epoch: 64 | Batch: 001 / 002 | Total loss: 9.063 | Reg loss: 0.009 | Tree loss: 9.063 | Accuracy: 0.310112 | 0.228 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 65 | Batch: 000 / 002 | Total loss: 9.062 | Reg loss: 0.009 | Tree loss: 9.062 | Accuracy: 0.328125 | 0.229 sec/iter\n",
      "Epoch: 65 | Batch: 001 / 002 | Total loss: 9.057 | Reg loss: 0.009 | Tree loss: 9.057 | Accuracy: 0.298876 | 0.228 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 66 | Batch: 000 / 002 | Total loss: 9.055 | Reg loss: 0.009 | Tree loss: 9.055 | Accuracy: 0.314453 | 0.229 sec/iter\n",
      "Epoch: 66 | Batch: 001 / 002 | Total loss: 9.048 | Reg loss: 0.009 | Tree loss: 9.048 | Accuracy: 0.314607 | 0.229 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 67 | Batch: 000 / 002 | Total loss: 9.058 | Reg loss: 0.009 | Tree loss: 9.058 | Accuracy: 0.296875 | 0.229 sec/iter\n",
      "Epoch: 67 | Batch: 001 / 002 | Total loss: 9.027 | Reg loss: 0.009 | Tree loss: 9.027 | Accuracy: 0.334831 | 0.229 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 68 | Batch: 000 / 002 | Total loss: 9.044 | Reg loss: 0.009 | Tree loss: 9.044 | Accuracy: 0.298828 | 0.229 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 | Batch: 001 / 002 | Total loss: 9.026 | Reg loss: 0.010 | Tree loss: 9.026 | Accuracy: 0.332584 | 0.229 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 69 | Batch: 000 / 002 | Total loss: 9.030 | Reg loss: 0.010 | Tree loss: 9.030 | Accuracy: 0.335938 | 0.23 sec/iter\n",
      "Epoch: 69 | Batch: 001 / 002 | Total loss: 9.025 | Reg loss: 0.010 | Tree loss: 9.025 | Accuracy: 0.289888 | 0.229 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 70 | Batch: 000 / 002 | Total loss: 9.030 | Reg loss: 0.010 | Tree loss: 9.030 | Accuracy: 0.306641 | 0.23 sec/iter\n",
      "Epoch: 70 | Batch: 001 / 002 | Total loss: 9.007 | Reg loss: 0.010 | Tree loss: 9.007 | Accuracy: 0.323596 | 0.229 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 71 | Batch: 000 / 002 | Total loss: 9.020 | Reg loss: 0.010 | Tree loss: 9.020 | Accuracy: 0.312500 | 0.23 sec/iter\n",
      "Epoch: 71 | Batch: 001 / 002 | Total loss: 9.001 | Reg loss: 0.010 | Tree loss: 9.001 | Accuracy: 0.316854 | 0.23 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 72 | Batch: 000 / 002 | Total loss: 9.011 | Reg loss: 0.010 | Tree loss: 9.011 | Accuracy: 0.316406 | 0.23 sec/iter\n",
      "Epoch: 72 | Batch: 001 / 002 | Total loss: 8.994 | Reg loss: 0.010 | Tree loss: 8.994 | Accuracy: 0.312360 | 0.23 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 73 | Batch: 000 / 002 | Total loss: 9.011 | Reg loss: 0.010 | Tree loss: 9.011 | Accuracy: 0.289062 | 0.23 sec/iter\n",
      "Epoch: 73 | Batch: 001 / 002 | Total loss: 8.977 | Reg loss: 0.010 | Tree loss: 8.977 | Accuracy: 0.343820 | 0.23 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 74 | Batch: 000 / 002 | Total loss: 8.991 | Reg loss: 0.010 | Tree loss: 8.991 | Accuracy: 0.300781 | 0.23 sec/iter\n",
      "Epoch: 74 | Batch: 001 / 002 | Total loss: 8.982 | Reg loss: 0.010 | Tree loss: 8.982 | Accuracy: 0.330337 | 0.23 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 75 | Batch: 000 / 002 | Total loss: 8.987 | Reg loss: 0.010 | Tree loss: 8.987 | Accuracy: 0.298828 | 0.231 sec/iter\n",
      "Epoch: 75 | Batch: 001 / 002 | Total loss: 8.969 | Reg loss: 0.010 | Tree loss: 8.969 | Accuracy: 0.332584 | 0.23 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 76 | Batch: 000 / 002 | Total loss: 8.987 | Reg loss: 0.010 | Tree loss: 8.987 | Accuracy: 0.294922 | 0.231 sec/iter\n",
      "Epoch: 76 | Batch: 001 / 002 | Total loss: 8.951 | Reg loss: 0.010 | Tree loss: 8.951 | Accuracy: 0.337079 | 0.231 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 77 | Batch: 000 / 002 | Total loss: 8.972 | Reg loss: 0.010 | Tree loss: 8.972 | Accuracy: 0.312500 | 0.231 sec/iter\n",
      "Epoch: 77 | Batch: 001 / 002 | Total loss: 8.950 | Reg loss: 0.010 | Tree loss: 8.950 | Accuracy: 0.316854 | 0.231 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 78 | Batch: 000 / 002 | Total loss: 8.945 | Reg loss: 0.010 | Tree loss: 8.945 | Accuracy: 0.337891 | 0.231 sec/iter\n",
      "Epoch: 78 | Batch: 001 / 002 | Total loss: 8.964 | Reg loss: 0.010 | Tree loss: 8.964 | Accuracy: 0.287640 | 0.231 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 79 | Batch: 000 / 002 | Total loss: 8.949 | Reg loss: 0.010 | Tree loss: 8.949 | Accuracy: 0.306641 | 0.231 sec/iter\n",
      "Epoch: 79 | Batch: 001 / 002 | Total loss: 8.942 | Reg loss: 0.010 | Tree loss: 8.942 | Accuracy: 0.323596 | 0.231 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 80 | Batch: 000 / 002 | Total loss: 8.937 | Reg loss: 0.010 | Tree loss: 8.937 | Accuracy: 0.339844 | 0.232 sec/iter\n",
      "Epoch: 80 | Batch: 001 / 002 | Total loss: 8.938 | Reg loss: 0.011 | Tree loss: 8.938 | Accuracy: 0.285393 | 0.231 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 81 | Batch: 000 / 002 | Total loss: 8.930 | Reg loss: 0.011 | Tree loss: 8.930 | Accuracy: 0.335938 | 0.232 sec/iter\n",
      "Epoch: 81 | Batch: 001 / 002 | Total loss: 8.927 | Reg loss: 0.011 | Tree loss: 8.927 | Accuracy: 0.289888 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 82 | Batch: 000 / 002 | Total loss: 8.924 | Reg loss: 0.011 | Tree loss: 8.924 | Accuracy: 0.312500 | 0.232 sec/iter\n",
      "Epoch: 82 | Batch: 001 / 002 | Total loss: 8.917 | Reg loss: 0.011 | Tree loss: 8.917 | Accuracy: 0.316854 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 83 | Batch: 000 / 002 | Total loss: 8.915 | Reg loss: 0.011 | Tree loss: 8.915 | Accuracy: 0.310547 | 0.232 sec/iter\n",
      "Epoch: 83 | Batch: 001 / 002 | Total loss: 8.908 | Reg loss: 0.011 | Tree loss: 8.908 | Accuracy: 0.319101 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 84 | Batch: 000 / 002 | Total loss: 8.912 | Reg loss: 0.011 | Tree loss: 8.912 | Accuracy: 0.298828 | 0.232 sec/iter\n",
      "Epoch: 84 | Batch: 001 / 002 | Total loss: 8.894 | Reg loss: 0.011 | Tree loss: 8.894 | Accuracy: 0.332584 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 85 | Batch: 000 / 002 | Total loss: 8.893 | Reg loss: 0.011 | Tree loss: 8.893 | Accuracy: 0.337891 | 0.232 sec/iter\n",
      "Epoch: 85 | Batch: 001 / 002 | Total loss: 8.897 | Reg loss: 0.011 | Tree loss: 8.897 | Accuracy: 0.287640 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 | Batch: 000 / 002 | Total loss: 8.889 | Reg loss: 0.011 | Tree loss: 8.889 | Accuracy: 0.316406 | 0.232 sec/iter\n",
      "Epoch: 86 | Batch: 001 / 002 | Total loss: 8.884 | Reg loss: 0.011 | Tree loss: 8.884 | Accuracy: 0.312360 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 87 | Batch: 000 / 002 | Total loss: 8.886 | Reg loss: 0.011 | Tree loss: 8.886 | Accuracy: 0.306641 | 0.233 sec/iter\n",
      "Epoch: 87 | Batch: 001 / 002 | Total loss: 8.868 | Reg loss: 0.011 | Tree loss: 8.868 | Accuracy: 0.323596 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 88 | Batch: 000 / 002 | Total loss: 8.878 | Reg loss: 0.011 | Tree loss: 8.878 | Accuracy: 0.298828 | 0.233 sec/iter\n",
      "Epoch: 88 | Batch: 001 / 002 | Total loss: 8.858 | Reg loss: 0.011 | Tree loss: 8.858 | Accuracy: 0.332584 | 0.232 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 89 | Batch: 000 / 002 | Total loss: 8.863 | Reg loss: 0.011 | Tree loss: 8.863 | Accuracy: 0.322266 | 0.233 sec/iter\n",
      "Epoch: 89 | Batch: 001 / 002 | Total loss: 8.858 | Reg loss: 0.011 | Tree loss: 8.858 | Accuracy: 0.305618 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 90 | Batch: 000 / 002 | Total loss: 8.853 | Reg loss: 0.011 | Tree loss: 8.853 | Accuracy: 0.324219 | 0.233 sec/iter\n",
      "Epoch: 90 | Batch: 001 / 002 | Total loss: 8.851 | Reg loss: 0.011 | Tree loss: 8.851 | Accuracy: 0.303371 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 91 | Batch: 000 / 002 | Total loss: 8.859 | Reg loss: 0.011 | Tree loss: 8.859 | Accuracy: 0.308594 | 0.233 sec/iter\n",
      "Epoch: 91 | Batch: 001 / 002 | Total loss: 8.824 | Reg loss: 0.011 | Tree loss: 8.824 | Accuracy: 0.321348 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 92 | Batch: 000 / 002 | Total loss: 8.835 | Reg loss: 0.011 | Tree loss: 8.835 | Accuracy: 0.314453 | 0.233 sec/iter\n",
      "Epoch: 92 | Batch: 001 / 002 | Total loss: 8.834 | Reg loss: 0.011 | Tree loss: 8.834 | Accuracy: 0.314607 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 93 | Batch: 000 / 002 | Total loss: 8.833 | Reg loss: 0.011 | Tree loss: 8.833 | Accuracy: 0.322266 | 0.233 sec/iter\n",
      "Epoch: 93 | Batch: 001 / 002 | Total loss: 8.816 | Reg loss: 0.012 | Tree loss: 8.816 | Accuracy: 0.305618 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 94 | Batch: 000 / 002 | Total loss: 8.816 | Reg loss: 0.012 | Tree loss: 8.816 | Accuracy: 0.322266 | 0.233 sec/iter\n",
      "Epoch: 94 | Batch: 001 / 002 | Total loss: 8.818 | Reg loss: 0.012 | Tree loss: 8.818 | Accuracy: 0.305618 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 95 | Batch: 000 / 002 | Total loss: 8.799 | Reg loss: 0.012 | Tree loss: 8.799 | Accuracy: 0.335938 | 0.233 sec/iter\n",
      "Epoch: 95 | Batch: 001 / 002 | Total loss: 8.818 | Reg loss: 0.012 | Tree loss: 8.818 | Accuracy: 0.289888 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 96 | Batch: 000 / 002 | Total loss: 8.800 | Reg loss: 0.012 | Tree loss: 8.800 | Accuracy: 0.320312 | 0.233 sec/iter\n",
      "Epoch: 96 | Batch: 001 / 002 | Total loss: 8.797 | Reg loss: 0.012 | Tree loss: 8.797 | Accuracy: 0.307865 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 97 | Batch: 000 / 002 | Total loss: 8.812 | Reg loss: 0.012 | Tree loss: 8.812 | Accuracy: 0.289062 | 0.234 sec/iter\n",
      "Epoch: 97 | Batch: 001 / 002 | Total loss: 8.764 | Reg loss: 0.012 | Tree loss: 8.764 | Accuracy: 0.343820 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 98 | Batch: 000 / 002 | Total loss: 8.783 | Reg loss: 0.012 | Tree loss: 8.783 | Accuracy: 0.324219 | 0.234 sec/iter\n",
      "Epoch: 98 | Batch: 001 / 002 | Total loss: 8.779 | Reg loss: 0.012 | Tree loss: 8.779 | Accuracy: 0.303371 | 0.234 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 99 | Batch: 000 / 002 | Total loss: 8.785 | Reg loss: 0.012 | Tree loss: 8.785 | Accuracy: 0.316406 | 0.234 sec/iter\n",
      "Epoch: 99 | Batch: 001 / 002 | Total loss: 8.756 | Reg loss: 0.012 | Tree loss: 8.756 | Accuracy: 0.312360 | 0.234 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05e632602f948d5834c5c263d301143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321ab717643941baaaba2e4afe6605a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571d2cd6ee5849eba974846dc6dad081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa1760b4ed34924aba5cd67f4961722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 8.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 256\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "486\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "147\n",
      "============== Pattern 5 ==============\n",
      "20\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "27\n",
      "============== Pattern 9 ==============\n",
      "3\n",
      "============== Pattern 10 ==============\n",
      "16\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "3\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "46\n",
      "============== Pattern 19 ==============\n",
      "8\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "============== Pattern 25 ==============\n",
      "============== Pattern 26 ==============\n",
      "============== Pattern 27 ==============\n",
      "============== Pattern 28 ==============\n",
      "============== Pattern 29 ==============\n",
      "============== Pattern 30 ==============\n",
      "1\n",
      "============== Pattern 31 ==============\n",
      "============== Pattern 32 ==============\n",
      "============== Pattern 33 ==============\n",
      "============== Pattern 34 ==============\n",
      "============== Pattern 35 ==============\n",
      "============== Pattern 36 ==============\n",
      "============== Pattern 37 ==============\n",
      "============== Pattern 38 ==============\n",
      "============== Pattern 39 ==============\n",
      "============== Pattern 40 ==============\n",
      "============== Pattern 41 ==============\n",
      "============== Pattern 42 ==============\n",
      "============== Pattern 43 ==============\n",
      "============== Pattern 44 ==============\n",
      "============== Pattern 45 ==============\n",
      "============== Pattern 46 ==============\n",
      "============== Pattern 47 ==============\n",
      "============== Pattern 48 ==============\n",
      "============== Pattern 49 ==============\n",
      "============== Pattern 50 ==============\n",
      "============== Pattern 51 ==============\n",
      "============== Pattern 52 ==============\n",
      "============== Pattern 53 ==============\n",
      "============== Pattern 54 ==============\n",
      "============== Pattern 55 ==============\n",
      "============== Pattern 56 ==============\n",
      "============== Pattern 57 ==============\n",
      "============== Pattern 58 ==============\n",
      "============== Pattern 59 ==============\n",
      "============== Pattern 60 ==============\n",
      "============== Pattern 61 ==============\n",
      "============== Pattern 62 ==============\n",
      "============== Pattern 63 ==============\n",
      "============== Pattern 64 ==============\n",
      "============== Pattern 65 ==============\n",
      "============== Pattern 66 ==============\n",
      "89\n",
      "============== Pattern 67 ==============\n",
      "============== Pattern 68 ==============\n",
      "============== Pattern 69 ==============\n",
      "============== Pattern 70 ==============\n",
      "============== Pattern 71 ==============\n",
      "============== Pattern 72 ==============\n",
      "============== Pattern 73 ==============\n",
      "============== Pattern 74 ==============\n",
      "============== Pattern 75 ==============\n",
      "============== Pattern 76 ==============\n",
      "============== Pattern 77 ==============\n",
      "7\n",
      "============== Pattern 78 ==============\n",
      "============== Pattern 79 ==============\n",
      "============== Pattern 80 ==============\n",
      "============== Pattern 81 ==============\n",
      "============== Pattern 82 ==============\n",
      "============== Pattern 83 ==============\n",
      "============== Pattern 84 ==============\n",
      "============== Pattern 85 ==============\n",
      "============== Pattern 86 ==============\n",
      "============== Pattern 87 ==============\n",
      "============== Pattern 88 ==============\n",
      "============== Pattern 89 ==============\n",
      "============== Pattern 90 ==============\n",
      "============== Pattern 91 ==============\n",
      "============== Pattern 92 ==============\n",
      "============== Pattern 93 ==============\n",
      "============== Pattern 94 ==============\n",
      "============== Pattern 95 ==============\n",
      "============== Pattern 96 ==============\n",
      "4\n",
      "============== Pattern 97 ==============\n",
      "============== Pattern 98 ==============\n",
      "============== Pattern 99 ==============\n",
      "============== Pattern 100 ==============\n",
      "============== Pattern 101 ==============\n",
      "============== Pattern 102 ==============\n",
      "============== Pattern 103 ==============\n",
      "============== Pattern 104 ==============\n",
      "============== Pattern 105 ==============\n",
      "============== Pattern 106 ==============\n",
      "1\n",
      "============== Pattern 107 ==============\n",
      "============== Pattern 108 ==============\n",
      "============== Pattern 109 ==============\n",
      "============== Pattern 110 ==============\n",
      "============== Pattern 111 ==============\n",
      "============== Pattern 112 ==============\n",
      "============== Pattern 113 ==============\n",
      "============== Pattern 114 ==============\n",
      "============== Pattern 115 ==============\n",
      "============== Pattern 116 ==============\n",
      "============== Pattern 117 ==============\n",
      "============== Pattern 118 ==============\n",
      "============== Pattern 119 ==============\n",
      "============== Pattern 120 ==============\n",
      "============== Pattern 121 ==============\n",
      "============== Pattern 122 ==============\n",
      "============== Pattern 123 ==============\n",
      "============== Pattern 124 ==============\n",
      "============== Pattern 125 ==============\n",
      "============== Pattern 126 ==============\n",
      "============== Pattern 127 ==============\n",
      "============== Pattern 128 ==============\n",
      "93\n",
      "============== Pattern 129 ==============\n",
      "============== Pattern 130 ==============\n",
      "============== Pattern 131 ==============\n",
      "============== Pattern 132 ==============\n",
      "5\n",
      "============== Pattern 133 ==============\n",
      "============== Pattern 134 ==============\n",
      "============== Pattern 135 ==============\n",
      "1\n",
      "============== Pattern 136 ==============\n",
      "============== Pattern 137 ==============\n",
      "============== Pattern 138 ==============\n",
      "============== Pattern 139 ==============\n",
      "============== Pattern 140 ==============\n",
      "============== Pattern 141 ==============\n",
      "============== Pattern 142 ==============\n",
      "============== Pattern 143 ==============\n",
      "============== Pattern 144 ==============\n",
      "============== Pattern 145 ==============\n",
      "============== Pattern 146 ==============\n",
      "============== Pattern 147 ==============\n",
      "============== Pattern 148 ==============\n",
      "============== Pattern 149 ==============\n",
      "============== Pattern 150 ==============\n",
      "============== Pattern 151 ==============\n",
      "============== Pattern 152 ==============\n",
      "============== Pattern 153 ==============\n",
      "============== Pattern 154 ==============\n",
      "============== Pattern 155 ==============\n",
      "============== Pattern 156 ==============\n",
      "============== Pattern 157 ==============\n",
      "============== Pattern 158 ==============\n",
      "============== Pattern 159 ==============\n",
      "============== Pattern 160 ==============\n",
      "============== Pattern 161 ==============\n",
      "============== Pattern 162 ==============\n",
      "============== Pattern 163 ==============\n",
      "============== Pattern 164 ==============\n",
      "============== Pattern 165 ==============\n",
      "============== Pattern 166 ==============\n",
      "============== Pattern 167 ==============\n",
      "============== Pattern 168 ==============\n",
      "============== Pattern 169 ==============\n",
      "============== Pattern 170 ==============\n",
      "============== Pattern 171 ==============\n",
      "============== Pattern 172 ==============\n",
      "============== Pattern 173 ==============\n",
      "============== Pattern 174 ==============\n",
      "============== Pattern 175 ==============\n",
      "============== Pattern 176 ==============\n",
      "============== Pattern 177 ==============\n",
      "============== Pattern 178 ==============\n",
      "============== Pattern 179 ==============\n",
      "============== Pattern 180 ==============\n",
      "============== Pattern 181 ==============\n",
      "============== Pattern 182 ==============\n",
      "============== Pattern 183 ==============\n",
      "============== Pattern 184 ==============\n",
      "============== Pattern 185 ==============\n",
      "============== Pattern 186 ==============\n",
      "============== Pattern 187 ==============\n",
      "============== Pattern 188 ==============\n",
      "============== Pattern 189 ==============\n",
      "============== Pattern 190 ==============\n",
      "============== Pattern 191 ==============\n",
      "============== Pattern 192 ==============\n",
      "============== Pattern 193 ==============\n",
      "============== Pattern 194 ==============\n",
      "============== Pattern 195 ==============\n",
      "============== Pattern 196 ==============\n",
      "============== Pattern 197 ==============\n",
      "============== Pattern 198 ==============\n",
      "============== Pattern 199 ==============\n",
      "============== Pattern 200 ==============\n",
      "============== Pattern 201 ==============\n",
      "============== Pattern 202 ==============\n",
      "============== Pattern 203 ==============\n",
      "============== Pattern 204 ==============\n",
      "============== Pattern 205 ==============\n",
      "============== Pattern 206 ==============\n",
      "============== Pattern 207 ==============\n",
      "============== Pattern 208 ==============\n",
      "============== Pattern 209 ==============\n",
      "============== Pattern 210 ==============\n",
      "============== Pattern 211 ==============\n",
      "============== Pattern 212 ==============\n",
      "============== Pattern 213 ==============\n",
      "============== Pattern 214 ==============\n",
      "============== Pattern 215 ==============\n",
      "============== Pattern 216 ==============\n",
      "============== Pattern 217 ==============\n",
      "============== Pattern 218 ==============\n",
      "============== Pattern 219 ==============\n",
      "============== Pattern 220 ==============\n",
      "============== Pattern 221 ==============\n",
      "============== Pattern 222 ==============\n",
      "============== Pattern 223 ==============\n",
      "============== Pattern 224 ==============\n",
      "============== Pattern 225 ==============\n",
      "============== Pattern 226 ==============\n",
      "============== Pattern 227 ==============\n",
      "============== Pattern 228 ==============\n",
      "============== Pattern 229 ==============\n",
      "============== Pattern 230 ==============\n",
      "============== Pattern 231 ==============\n",
      "============== Pattern 232 ==============\n",
      "============== Pattern 233 ==============\n",
      "============== Pattern 234 ==============\n",
      "============== Pattern 235 ==============\n",
      "============== Pattern 236 ==============\n",
      "============== Pattern 237 ==============\n",
      "============== Pattern 238 ==============\n",
      "============== Pattern 239 ==============\n",
      "============== Pattern 240 ==============\n",
      "============== Pattern 241 ==============\n",
      "============== Pattern 242 ==============\n",
      "============== Pattern 243 ==============\n",
      "============== Pattern 244 ==============\n",
      "============== Pattern 245 ==============\n",
      "============== Pattern 246 ==============\n",
      "============== Pattern 247 ==============\n",
      "============== Pattern 248 ==============\n",
      "============== Pattern 249 ==============\n",
      "============== Pattern 250 ==============\n",
      "============== Pattern 251 ==============\n",
      "============== Pattern 252 ==============\n",
      "============== Pattern 253 ==============\n",
      "============== Pattern 254 ==============\n",
      "============== Pattern 255 ==============\n",
      "============== Pattern 256 ==============\n",
      "Average comprehensibility: 45.640625\n",
      "std comprehensibility: 1.8613434958048447\n",
      "var comprehensibility: 3.464599609375\n",
      "minimum comprehensibility: 42\n",
      "maximum comprehensibility: 48\n"
     ]
    }
   ],
   "source": [
    "attr_names = dataset.items\n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
