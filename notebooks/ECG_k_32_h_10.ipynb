{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 32\n",
    "tree_depth = 10\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'/mnt/qnap/ekosman/mitbih_train.csv'\n",
    "test_data_path = r'/mnt/qnap/ekosman/mitbih_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.358572006225586 | KNN Loss: 5.69699239730835 | CLS Loss: 1.6615793704986572\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 4.858458518981934 | KNN Loss: 4.118841648101807 | CLS Loss: 0.739617109298706\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 4.7575297355651855 | KNN Loss: 4.001819610595703 | CLS Loss: 0.7557100653648376\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 4.550957679748535 | KNN Loss: 3.9674794673919678 | CLS Loss: 0.5834780335426331\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 4.4556169509887695 | KNN Loss: 3.8908891677856445 | CLS Loss: 0.5647277235984802\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 4.35487699508667 | KNN Loss: 3.8714163303375244 | CLS Loss: 0.48346057534217834\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 4.348923206329346 | KNN Loss: 3.8277058601379395 | CLS Loss: 0.5212175250053406\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.310129642486572 | KNN Loss: 3.895495653152466 | CLS Loss: 0.4146338105201721\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.317509651184082 | KNN Loss: 3.898515462875366 | CLS Loss: 0.4189939796924591\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.26209831237793 | KNN Loss: 3.90171480178833 | CLS Loss: 0.36038339138031006\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.281094551086426 | KNN Loss: 3.842071056365967 | CLS Loss: 0.439023494720459\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.305878639221191 | KNN Loss: 3.844691753387451 | CLS Loss: 0.4611869156360626\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.231561660766602 | KNN Loss: 3.852546215057373 | CLS Loss: 0.37901565432548523\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.173552989959717 | KNN Loss: 3.8750431537628174 | CLS Loss: 0.2985098361968994\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.159578800201416 | KNN Loss: 3.803379535675049 | CLS Loss: 0.3561994433403015\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.192231178283691 | KNN Loss: 3.877641201019287 | CLS Loss: 0.3145900070667267\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.19157075881958 | KNN Loss: 3.8490185737609863 | CLS Loss: 0.3425520360469818\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.192810535430908 | KNN Loss: 3.852552890777588 | CLS Loss: 0.34025782346725464\n",
      "Epoch: 001, Loss: 4.4629, Train: 0.9148, Valid: 0.9151, Best: 0.9151\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.2003703117370605 | KNN Loss: 3.8483872413635254 | CLS Loss: 0.35198304057121277\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.108704090118408 | KNN Loss: 3.802938222885132 | CLS Loss: 0.3057658076286316\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.11091423034668 | KNN Loss: 3.802011728286743 | CLS Loss: 0.3089026212692261\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 4.1299614906311035 | KNN Loss: 3.848973512649536 | CLS Loss: 0.28098779916763306\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 4.11537504196167 | KNN Loss: 3.788421392440796 | CLS Loss: 0.326953649520874\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 4.093278884887695 | KNN Loss: 3.796407699584961 | CLS Loss: 0.29687097668647766\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 4.050943374633789 | KNN Loss: 3.7678141593933105 | CLS Loss: 0.28312942385673523\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 4.055922031402588 | KNN Loss: 3.749232292175293 | CLS Loss: 0.30668967962265015\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 4.067280292510986 | KNN Loss: 3.7968926429748535 | CLS Loss: 0.27038776874542236\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 4.065778732299805 | KNN Loss: 3.8133468627929688 | CLS Loss: 0.2524320185184479\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 4.0815277099609375 | KNN Loss: 3.8468306064605713 | CLS Loss: 0.23469701409339905\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 4.083019256591797 | KNN Loss: 3.7900664806365967 | CLS Loss: 0.29295289516448975\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 3.9494924545288086 | KNN Loss: 3.7744486331939697 | CLS Loss: 0.17504394054412842\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 4.036555767059326 | KNN Loss: 3.791656255722046 | CLS Loss: 0.24489973485469818\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 3.961864709854126 | KNN Loss: 3.720162868499756 | CLS Loss: 0.2417018711566925\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 3.9981422424316406 | KNN Loss: 3.7668962478637695 | CLS Loss: 0.2312459796667099\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 3.9404428005218506 | KNN Loss: 3.746520519256592 | CLS Loss: 0.1939222514629364\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 4.006106376647949 | KNN Loss: 3.7745347023010254 | CLS Loss: 0.23157158493995667\n",
      "Epoch: 002, Loss: 4.0444, Train: 0.9506, Valid: 0.9498, Best: 0.9498\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 3.9717180728912354 | KNN Loss: 3.7701964378356934 | CLS Loss: 0.20152170956134796\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 3.9675614833831787 | KNN Loss: 3.7670321464538574 | CLS Loss: 0.2005292773246765\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 3.942990779876709 | KNN Loss: 3.7503292560577393 | CLS Loss: 0.19266149401664734\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 3.988734006881714 | KNN Loss: 3.7491676807403564 | CLS Loss: 0.23956634104251862\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 3.9253880977630615 | KNN Loss: 3.7124526500701904 | CLS Loss: 0.21293538808822632\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 3.888097047805786 | KNN Loss: 3.7257187366485596 | CLS Loss: 0.1623782217502594\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 3.9176316261291504 | KNN Loss: 3.7670912742614746 | CLS Loss: 0.15054035186767578\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 3.9324777126312256 | KNN Loss: 3.754009485244751 | CLS Loss: 0.17846828699111938\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 3.9390578269958496 | KNN Loss: 3.721221685409546 | CLS Loss: 0.2178361564874649\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 3.8890671730041504 | KNN Loss: 3.7297661304473877 | CLS Loss: 0.15930116176605225\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 3.936275005340576 | KNN Loss: 3.73840594291687 | CLS Loss: 0.19786913692951202\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 3.9812517166137695 | KNN Loss: 3.7416296005249023 | CLS Loss: 0.23962214589118958\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 3.9146265983581543 | KNN Loss: 3.7504220008850098 | CLS Loss: 0.16420452296733856\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 3.8650550842285156 | KNN Loss: 3.7119686603546143 | CLS Loss: 0.15308654308319092\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 3.926067352294922 | KNN Loss: 3.724440574645996 | CLS Loss: 0.2016267478466034\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 3.93044376373291 | KNN Loss: 3.74869704246521 | CLS Loss: 0.18174661695957184\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 3.8363800048828125 | KNN Loss: 3.6968324184417725 | CLS Loss: 0.1395474672317505\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 3.876805543899536 | KNN Loss: 3.731126308441162 | CLS Loss: 0.14567920565605164\n",
      "Epoch: 003, Loss: 3.9161, Train: 0.9598, Valid: 0.9577, Best: 0.9577\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 3.8482532501220703 | KNN Loss: 3.716597080230713 | CLS Loss: 0.13165609538555145\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 3.9371557235717773 | KNN Loss: 3.7201383113861084 | CLS Loss: 0.21701738238334656\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 3.917654514312744 | KNN Loss: 3.742138385772705 | CLS Loss: 0.1755160093307495\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 3.8889529705047607 | KNN Loss: 3.7269065380096436 | CLS Loss: 0.16204646229743958\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 3.832775592803955 | KNN Loss: 3.7171192169189453 | CLS Loss: 0.11565640568733215\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 3.871100425720215 | KNN Loss: 3.757614850997925 | CLS Loss: 0.11348556727170944\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 3.8376009464263916 | KNN Loss: 3.6821277141571045 | CLS Loss: 0.1554732322692871\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 3.8696630001068115 | KNN Loss: 3.686988592147827 | CLS Loss: 0.18267446756362915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 3.8621749877929688 | KNN Loss: 3.7199788093566895 | CLS Loss: 0.14219610393047333\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 3.846350908279419 | KNN Loss: 3.7377986907958984 | CLS Loss: 0.10855214297771454\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 3.8782801628112793 | KNN Loss: 3.679821252822876 | CLS Loss: 0.19845889508724213\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 3.8147568702697754 | KNN Loss: 3.693053722381592 | CLS Loss: 0.121703140437603\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 3.862760305404663 | KNN Loss: 3.7014079093933105 | CLS Loss: 0.16135230660438538\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 3.8173587322235107 | KNN Loss: 3.670098304748535 | CLS Loss: 0.14726035296916962\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 3.7751920223236084 | KNN Loss: 3.7059693336486816 | CLS Loss: 0.06922276318073273\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 3.875886917114258 | KNN Loss: 3.701113700866699 | CLS Loss: 0.17477314174175262\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 3.8156189918518066 | KNN Loss: 3.693838119506836 | CLS Loss: 0.12178097665309906\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 3.826509952545166 | KNN Loss: 3.718087673187256 | CLS Loss: 0.10842237621545792\n",
      "Epoch: 004, Loss: 3.8431, Train: 0.9699, Valid: 0.9671, Best: 0.9671\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 3.8062644004821777 | KNN Loss: 3.710482358932495 | CLS Loss: 0.09578194469213486\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 3.841355085372925 | KNN Loss: 3.7067179679870605 | CLS Loss: 0.1346370130777359\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 3.81479549407959 | KNN Loss: 3.6663296222686768 | CLS Loss: 0.14846588671207428\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 3.794732093811035 | KNN Loss: 3.7064969539642334 | CLS Loss: 0.08823514729738235\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 3.773707866668701 | KNN Loss: 3.646665096282959 | CLS Loss: 0.1270427703857422\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 3.7923591136932373 | KNN Loss: 3.648257255554199 | CLS Loss: 0.14410188794136047\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 3.8223581314086914 | KNN Loss: 3.6934454441070557 | CLS Loss: 0.12891268730163574\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 3.780061721801758 | KNN Loss: 3.684417486190796 | CLS Loss: 0.09564422070980072\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 3.8215973377227783 | KNN Loss: 3.6886048316955566 | CLS Loss: 0.13299249112606049\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 3.782452344894409 | KNN Loss: 3.6735944747924805 | CLS Loss: 0.10885779559612274\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 3.8424172401428223 | KNN Loss: 3.7150638103485107 | CLS Loss: 0.12735339999198914\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 3.841392755508423 | KNN Loss: 3.690960645675659 | CLS Loss: 0.15043200552463531\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 3.794480800628662 | KNN Loss: 3.664696455001831 | CLS Loss: 0.12978440523147583\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 3.861072063446045 | KNN Loss: 3.697697877883911 | CLS Loss: 0.16337424516677856\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 3.8511734008789062 | KNN Loss: 3.7004783153533936 | CLS Loss: 0.15069517493247986\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 3.7515408992767334 | KNN Loss: 3.645703077316284 | CLS Loss: 0.10583793371915817\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 3.8103084564208984 | KNN Loss: 3.7353556156158447 | CLS Loss: 0.07495279610157013\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 3.8213250637054443 | KNN Loss: 3.6973772048950195 | CLS Loss: 0.12394778430461884\n",
      "Epoch: 005, Loss: 3.8019, Train: 0.9739, Valid: 0.9714, Best: 0.9714\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 3.779937267303467 | KNN Loss: 3.7013649940490723 | CLS Loss: 0.07857217639684677\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 3.7919256687164307 | KNN Loss: 3.674591302871704 | CLS Loss: 0.11733440309762955\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 3.7798240184783936 | KNN Loss: 3.6684417724609375 | CLS Loss: 0.11138232797384262\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 3.759746551513672 | KNN Loss: 3.6829428672790527 | CLS Loss: 0.0768037885427475\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 3.7732067108154297 | KNN Loss: 3.695476770401001 | CLS Loss: 0.07772999256849289\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 3.7889254093170166 | KNN Loss: 3.669910430908203 | CLS Loss: 0.11901496350765228\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 3.812246084213257 | KNN Loss: 3.70725417137146 | CLS Loss: 0.10499193519353867\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 3.793686866760254 | KNN Loss: 3.693753957748413 | CLS Loss: 0.09993302077054977\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 3.8033854961395264 | KNN Loss: 3.6715259552001953 | CLS Loss: 0.13185951113700867\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 3.754707098007202 | KNN Loss: 3.6672582626342773 | CLS Loss: 0.0874488353729248\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 3.774596691131592 | KNN Loss: 3.669207811355591 | CLS Loss: 0.10538889467716217\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 3.770612955093384 | KNN Loss: 3.6443495750427246 | CLS Loss: 0.12626346945762634\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 3.814154863357544 | KNN Loss: 3.680168628692627 | CLS Loss: 0.13398624956607819\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 3.7910497188568115 | KNN Loss: 3.6755380630493164 | CLS Loss: 0.1155117079615593\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 3.8384852409362793 | KNN Loss: 3.6813604831695557 | CLS Loss: 0.15712469816207886\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 3.7674028873443604 | KNN Loss: 3.6807749271392822 | CLS Loss: 0.0866280347108841\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 3.818084239959717 | KNN Loss: 3.717646360397339 | CLS Loss: 0.10043785721063614\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 3.7651140689849854 | KNN Loss: 3.6688172817230225 | CLS Loss: 0.09629671275615692\n",
      "Epoch: 006, Loss: 3.7788, Train: 0.9747, Valid: 0.9717, Best: 0.9717\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 3.789788246154785 | KNN Loss: 3.6536672115325928 | CLS Loss: 0.13612093031406403\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 3.7651641368865967 | KNN Loss: 3.690303325653076 | CLS Loss: 0.07486070692539215\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 3.7785372734069824 | KNN Loss: 3.6654043197631836 | CLS Loss: 0.11313304305076599\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 3.7272157669067383 | KNN Loss: 3.6604197025299072 | CLS Loss: 0.0667959600687027\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 3.7496068477630615 | KNN Loss: 3.6515676975250244 | CLS Loss: 0.09803906083106995\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 3.7590160369873047 | KNN Loss: 3.656341791152954 | CLS Loss: 0.10267431288957596\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 3.750608444213867 | KNN Loss: 3.6361985206604004 | CLS Loss: 0.11440987139940262\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 3.7473416328430176 | KNN Loss: 3.6543970108032227 | CLS Loss: 0.09294451773166656\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 3.723179578781128 | KNN Loss: 3.6570940017700195 | CLS Loss: 0.06608547270298004\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 3.719045877456665 | KNN Loss: 3.6417312622070312 | CLS Loss: 0.0773146003484726\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 3.8271665573120117 | KNN Loss: 3.6857268810272217 | CLS Loss: 0.14143972098827362\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 3.7459864616394043 | KNN Loss: 3.6421868801116943 | CLS Loss: 0.10379961878061295\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 3.802903652191162 | KNN Loss: 3.6834046840667725 | CLS Loss: 0.1194990798830986\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 3.767643928527832 | KNN Loss: 3.6441261768341064 | CLS Loss: 0.12351784855127335\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 3.717050313949585 | KNN Loss: 3.6208953857421875 | CLS Loss: 0.09615500271320343\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 3.7494287490844727 | KNN Loss: 3.663404941558838 | CLS Loss: 0.08602375537157059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 3.7856101989746094 | KNN Loss: 3.687330722808838 | CLS Loss: 0.09827938675880432\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 3.7485692501068115 | KNN Loss: 3.6494884490966797 | CLS Loss: 0.09908083826303482\n",
      "Epoch: 007, Loss: 3.7624, Train: 0.9775, Valid: 0.9732, Best: 0.9732\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 3.782048463821411 | KNN Loss: 3.664184093475342 | CLS Loss: 0.11786431819200516\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 3.771681070327759 | KNN Loss: 3.6252777576446533 | CLS Loss: 0.1464032530784607\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 3.708716869354248 | KNN Loss: 3.6196749210357666 | CLS Loss: 0.0890420526266098\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 3.746598958969116 | KNN Loss: 3.6318962574005127 | CLS Loss: 0.11470276117324829\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 3.7737317085266113 | KNN Loss: 3.6878867149353027 | CLS Loss: 0.08584505319595337\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 3.7430267333984375 | KNN Loss: 3.6708502769470215 | CLS Loss: 0.07217643409967422\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 3.7643680572509766 | KNN Loss: 3.696665048599243 | CLS Loss: 0.06770304590463638\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 3.769042491912842 | KNN Loss: 3.7003862857818604 | CLS Loss: 0.06865613162517548\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 3.8006975650787354 | KNN Loss: 3.6939826011657715 | CLS Loss: 0.10671498626470566\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 3.78212571144104 | KNN Loss: 3.687171697616577 | CLS Loss: 0.09495410323143005\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 3.7888689041137695 | KNN Loss: 3.727811813354492 | CLS Loss: 0.06105704978108406\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 3.772585153579712 | KNN Loss: 3.651491403579712 | CLS Loss: 0.12109367549419403\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 3.7818331718444824 | KNN Loss: 3.699615001678467 | CLS Loss: 0.08221819251775742\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 3.672447443008423 | KNN Loss: 3.630739688873291 | CLS Loss: 0.041707854717969894\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 3.7960572242736816 | KNN Loss: 3.719552755355835 | CLS Loss: 0.07650452107191086\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 3.714913845062256 | KNN Loss: 3.6514344215393066 | CLS Loss: 0.06347930431365967\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 3.7385671138763428 | KNN Loss: 3.688201427459717 | CLS Loss: 0.05036558210849762\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 3.7071340084075928 | KNN Loss: 3.6210532188415527 | CLS Loss: 0.08608071506023407\n",
      "Epoch: 008, Loss: 3.7442, Train: 0.9801, Valid: 0.9756, Best: 0.9756\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 3.7202706336975098 | KNN Loss: 3.674783706665039 | CLS Loss: 0.045486826449632645\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 3.7289836406707764 | KNN Loss: 3.655388116836548 | CLS Loss: 0.07359551638364792\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 3.7377207279205322 | KNN Loss: 3.657533884048462 | CLS Loss: 0.08018683642148972\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 3.7963101863861084 | KNN Loss: 3.6806910037994385 | CLS Loss: 0.11561916023492813\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 3.7931501865386963 | KNN Loss: 3.721996545791626 | CLS Loss: 0.07115370035171509\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 3.7451581954956055 | KNN Loss: 3.6505045890808105 | CLS Loss: 0.09465354681015015\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 3.750340461730957 | KNN Loss: 3.6791083812713623 | CLS Loss: 0.07123219966888428\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 3.7811391353607178 | KNN Loss: 3.692901611328125 | CLS Loss: 0.08823748677968979\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 3.731168746948242 | KNN Loss: 3.6810269355773926 | CLS Loss: 0.050141867250204086\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 3.7295851707458496 | KNN Loss: 3.647395372390747 | CLS Loss: 0.08218982070684433\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 3.7226402759552 | KNN Loss: 3.6355812549591064 | CLS Loss: 0.08705897629261017\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 3.7155282497406006 | KNN Loss: 3.654634952545166 | CLS Loss: 0.06089329719543457\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 3.757086753845215 | KNN Loss: 3.659822702407837 | CLS Loss: 0.0972641333937645\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 3.7025158405303955 | KNN Loss: 3.6616992950439453 | CLS Loss: 0.04081644117832184\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 3.699247360229492 | KNN Loss: 3.6367642879486084 | CLS Loss: 0.06248302757740021\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 3.7263343334198 | KNN Loss: 3.648092031478882 | CLS Loss: 0.07824226468801498\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 3.7074358463287354 | KNN Loss: 3.655834913253784 | CLS Loss: 0.051601044833660126\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 3.698105812072754 | KNN Loss: 3.634307861328125 | CLS Loss: 0.06379806995391846\n",
      "Epoch: 009, Loss: 3.7414, Train: 0.9804, Valid: 0.9768, Best: 0.9768\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 3.6928396224975586 | KNN Loss: 3.6525399684906006 | CLS Loss: 0.04029959812760353\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 3.7911858558654785 | KNN Loss: 3.700012683868408 | CLS Loss: 0.09117326885461807\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 3.733579397201538 | KNN Loss: 3.638787269592285 | CLS Loss: 0.09479202330112457\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 3.7665605545043945 | KNN Loss: 3.689706802368164 | CLS Loss: 0.07685381919145584\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 3.7900195121765137 | KNN Loss: 3.6820929050445557 | CLS Loss: 0.10792667418718338\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 3.6959071159362793 | KNN Loss: 3.6278066635131836 | CLS Loss: 0.06810033321380615\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 3.706925392150879 | KNN Loss: 3.6767666339874268 | CLS Loss: 0.030158642679452896\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 3.764448404312134 | KNN Loss: 3.6469621658325195 | CLS Loss: 0.11748634278774261\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 3.7375879287719727 | KNN Loss: 3.6840028762817383 | CLS Loss: 0.05358501151204109\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 3.72540020942688 | KNN Loss: 3.626695156097412 | CLS Loss: 0.09870494157075882\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 3.739067316055298 | KNN Loss: 3.6576011180877686 | CLS Loss: 0.08146622031927109\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 3.6808085441589355 | KNN Loss: 3.6466856002807617 | CLS Loss: 0.034123003482818604\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 3.6652908325195312 | KNN Loss: 3.610072374343872 | CLS Loss: 0.055218473076820374\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 3.6983165740966797 | KNN Loss: 3.6289587020874023 | CLS Loss: 0.06935775279998779\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 3.7457518577575684 | KNN Loss: 3.6809473037719727 | CLS Loss: 0.0648045763373375\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 3.7369635105133057 | KNN Loss: 3.645167112350464 | CLS Loss: 0.09179643541574478\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 3.7713825702667236 | KNN Loss: 3.633913278579712 | CLS Loss: 0.13746923208236694\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 3.700322151184082 | KNN Loss: 3.6262879371643066 | CLS Loss: 0.07403421401977539\n",
      "Epoch: 010, Loss: 3.7344, Train: 0.9821, Valid: 0.9779, Best: 0.9779\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 3.691932201385498 | KNN Loss: 3.644277811050415 | CLS Loss: 0.04765436053276062\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 3.69112229347229 | KNN Loss: 3.6524808406829834 | CLS Loss: 0.038641348481178284\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 3.8153929710388184 | KNN Loss: 3.7304461002349854 | CLS Loss: 0.0849468931555748\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 3.7365951538085938 | KNN Loss: 3.6676735877990723 | CLS Loss: 0.06892158836126328\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 3.762904167175293 | KNN Loss: 3.6964855194091797 | CLS Loss: 0.06641863286495209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 3.7452592849731445 | KNN Loss: 3.6759467124938965 | CLS Loss: 0.06931264698505402\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 3.735203742980957 | KNN Loss: 3.6836297512054443 | CLS Loss: 0.05157403647899628\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 3.7291078567504883 | KNN Loss: 3.664486885070801 | CLS Loss: 0.06462091207504272\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 3.723984479904175 | KNN Loss: 3.665686845779419 | CLS Loss: 0.05829761177301407\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 3.703261613845825 | KNN Loss: 3.6206865310668945 | CLS Loss: 0.0825750008225441\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 3.743879795074463 | KNN Loss: 3.671294927597046 | CLS Loss: 0.07258490473031998\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 3.729762315750122 | KNN Loss: 3.6473186016082764 | CLS Loss: 0.08244366198778152\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 3.7208974361419678 | KNN Loss: 3.61767315864563 | CLS Loss: 0.10322431474924088\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 3.6913838386535645 | KNN Loss: 3.622743606567383 | CLS Loss: 0.06864023208618164\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 3.747410297393799 | KNN Loss: 3.6823887825012207 | CLS Loss: 0.06502145528793335\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 3.743793487548828 | KNN Loss: 3.657539129257202 | CLS Loss: 0.08625423908233643\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 3.7434065341949463 | KNN Loss: 3.6711535453796387 | CLS Loss: 0.07225305587053299\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 3.710866689682007 | KNN Loss: 3.6507415771484375 | CLS Loss: 0.060125041753053665\n",
      "Epoch: 011, Loss: 3.7343, Train: 0.9820, Valid: 0.9779, Best: 0.9779\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 3.7027440071105957 | KNN Loss: 3.6642162799835205 | CLS Loss: 0.03852766379714012\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 3.7261974811553955 | KNN Loss: 3.667482852935791 | CLS Loss: 0.05871469900012016\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 3.719113826751709 | KNN Loss: 3.677349328994751 | CLS Loss: 0.04176439344882965\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 3.780568838119507 | KNN Loss: 3.652374029159546 | CLS Loss: 0.1281948983669281\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 3.736881732940674 | KNN Loss: 3.6819474697113037 | CLS Loss: 0.054934266954660416\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 3.6885416507720947 | KNN Loss: 3.642406702041626 | CLS Loss: 0.04613500460982323\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 3.7231578826904297 | KNN Loss: 3.6553468704223633 | CLS Loss: 0.06781098246574402\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 3.705993413925171 | KNN Loss: 3.651667356491089 | CLS Loss: 0.05432604253292084\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 3.7220587730407715 | KNN Loss: 3.62713623046875 | CLS Loss: 0.0949224904179573\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 3.7145485877990723 | KNN Loss: 3.651888132095337 | CLS Loss: 0.06266053766012192\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 3.7132952213287354 | KNN Loss: 3.6565499305725098 | CLS Loss: 0.05674539878964424\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 3.7482035160064697 | KNN Loss: 3.667590856552124 | CLS Loss: 0.08061255514621735\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 3.715238094329834 | KNN Loss: 3.6633667945861816 | CLS Loss: 0.0518714003264904\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 3.6943531036376953 | KNN Loss: 3.620065927505493 | CLS Loss: 0.07428710907697678\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 3.70263671875 | KNN Loss: 3.643664836883545 | CLS Loss: 0.05897194892168045\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 3.7192280292510986 | KNN Loss: 3.672250747680664 | CLS Loss: 0.04697732999920845\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 3.728036403656006 | KNN Loss: 3.6222620010375977 | CLS Loss: 0.10577432811260223\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 3.718596935272217 | KNN Loss: 3.667248249053955 | CLS Loss: 0.05134856700897217\n",
      "Epoch: 012, Loss: 3.7236, Train: 0.9844, Valid: 0.9791, Best: 0.9791\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 3.717498779296875 | KNN Loss: 3.6569936275482178 | CLS Loss: 0.060505207628011703\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 3.7228147983551025 | KNN Loss: 3.673563003540039 | CLS Loss: 0.0492517352104187\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 3.681224822998047 | KNN Loss: 3.638530731201172 | CLS Loss: 0.04269421100616455\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 3.710235595703125 | KNN Loss: 3.6540627479553223 | CLS Loss: 0.056172750890254974\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 3.781715154647827 | KNN Loss: 3.6882314682006836 | CLS Loss: 0.09348373115062714\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 3.746114492416382 | KNN Loss: 3.668161630630493 | CLS Loss: 0.07795283943414688\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 3.742058038711548 | KNN Loss: 3.665377616882324 | CLS Loss: 0.07668038457632065\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 3.660835027694702 | KNN Loss: 3.60627818107605 | CLS Loss: 0.05455673485994339\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 3.742565870285034 | KNN Loss: 3.662033796310425 | CLS Loss: 0.08053218573331833\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 3.707033634185791 | KNN Loss: 3.6212267875671387 | CLS Loss: 0.08580687642097473\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 3.6988162994384766 | KNN Loss: 3.647646427154541 | CLS Loss: 0.05116985738277435\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 3.6999902725219727 | KNN Loss: 3.6632015705108643 | CLS Loss: 0.03678882122039795\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 3.6777520179748535 | KNN Loss: 3.6234827041625977 | CLS Loss: 0.05426925793290138\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 3.7246944904327393 | KNN Loss: 3.6685068607330322 | CLS Loss: 0.05618766322731972\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 3.702918291091919 | KNN Loss: 3.6349105834960938 | CLS Loss: 0.0680077075958252\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 3.7909834384918213 | KNN Loss: 3.6948611736297607 | CLS Loss: 0.0961223617196083\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 3.684112071990967 | KNN Loss: 3.647536277770996 | CLS Loss: 0.03657577559351921\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 3.6868677139282227 | KNN Loss: 3.651336193084717 | CLS Loss: 0.0355314239859581\n",
      "Epoch: 013, Loss: 3.7178, Train: 0.9845, Valid: 0.9801, Best: 0.9801\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 3.6606812477111816 | KNN Loss: 3.63236403465271 | CLS Loss: 0.028317291289567947\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 3.706855058670044 | KNN Loss: 3.6541125774383545 | CLS Loss: 0.05274241417646408\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 3.696658134460449 | KNN Loss: 3.6401612758636475 | CLS Loss: 0.056496892124414444\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 3.7027175426483154 | KNN Loss: 3.6361849308013916 | CLS Loss: 0.0665326863527298\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 3.713364839553833 | KNN Loss: 3.6494553089141846 | CLS Loss: 0.06390944868326187\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 3.6739675998687744 | KNN Loss: 3.6267993450164795 | CLS Loss: 0.0471683032810688\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 3.707659959793091 | KNN Loss: 3.6354763507843018 | CLS Loss: 0.0721835270524025\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 3.714024066925049 | KNN Loss: 3.6148300170898438 | CLS Loss: 0.09919407963752747\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 3.717284679412842 | KNN Loss: 3.637871503829956 | CLS Loss: 0.07941321283578873\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 3.7449843883514404 | KNN Loss: 3.676823139190674 | CLS Loss: 0.068161241710186\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 3.695591926574707 | KNN Loss: 3.6448206901550293 | CLS Loss: 0.050771117210388184\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 3.680239200592041 | KNN Loss: 3.6484057903289795 | CLS Loss: 0.03183337673544884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 3.726778507232666 | KNN Loss: 3.677480459213257 | CLS Loss: 0.049298059195280075\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 3.713148832321167 | KNN Loss: 3.667767286300659 | CLS Loss: 0.04538147523999214\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 3.6706933975219727 | KNN Loss: 3.615631341934204 | CLS Loss: 0.055062130093574524\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 3.7304608821868896 | KNN Loss: 3.6823830604553223 | CLS Loss: 0.04807782918214798\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 3.6848113536834717 | KNN Loss: 3.6287119388580322 | CLS Loss: 0.05609948933124542\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 3.6925601959228516 | KNN Loss: 3.6284523010253906 | CLS Loss: 0.0641079694032669\n",
      "Epoch: 014, Loss: 3.7151, Train: 0.9834, Valid: 0.9782, Best: 0.9801\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 3.7169532775878906 | KNN Loss: 3.634455442428589 | CLS Loss: 0.08249791711568832\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 3.7044169902801514 | KNN Loss: 3.626173734664917 | CLS Loss: 0.07824335247278214\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 3.7277019023895264 | KNN Loss: 3.6695261001586914 | CLS Loss: 0.05817591771483421\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 3.6795260906219482 | KNN Loss: 3.6389918327331543 | CLS Loss: 0.04053431749343872\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 3.698880910873413 | KNN Loss: 3.621829032897949 | CLS Loss: 0.07705177366733551\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 3.6834521293640137 | KNN Loss: 3.637299060821533 | CLS Loss: 0.04615313187241554\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 3.6557111740112305 | KNN Loss: 3.6016924381256104 | CLS Loss: 0.05401874706149101\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 3.692622423171997 | KNN Loss: 3.637037515640259 | CLS Loss: 0.05558481439948082\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 3.6902992725372314 | KNN Loss: 3.6497302055358887 | CLS Loss: 0.04056912660598755\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 3.7059032917022705 | KNN Loss: 3.650906801223755 | CLS Loss: 0.05499657988548279\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 3.7598137855529785 | KNN Loss: 3.6650142669677734 | CLS Loss: 0.09479944407939911\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 3.6842501163482666 | KNN Loss: 3.665022611618042 | CLS Loss: 0.01922747865319252\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 3.689096689224243 | KNN Loss: 3.6377851963043213 | CLS Loss: 0.0513114370405674\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 3.713632106781006 | KNN Loss: 3.673954725265503 | CLS Loss: 0.0396774597465992\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 3.711336135864258 | KNN Loss: 3.637488603591919 | CLS Loss: 0.07384762912988663\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 3.7200493812561035 | KNN Loss: 3.659552812576294 | CLS Loss: 0.060496605932712555\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 3.7216060161590576 | KNN Loss: 3.6288764476776123 | CLS Loss: 0.09272953867912292\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 3.7447268962860107 | KNN Loss: 3.66125226020813 | CLS Loss: 0.08347468078136444\n",
      "Epoch: 015, Loss: 3.7078, Train: 0.9833, Valid: 0.9779, Best: 0.9801\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 3.6964519023895264 | KNN Loss: 3.656909227371216 | CLS Loss: 0.03954271599650383\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 3.6647658348083496 | KNN Loss: 3.617180109024048 | CLS Loss: 0.047585707157850266\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 3.6604738235473633 | KNN Loss: 3.6184165477752686 | CLS Loss: 0.04205732047557831\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 3.7282378673553467 | KNN Loss: 3.667954683303833 | CLS Loss: 0.0602831169962883\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 3.763625144958496 | KNN Loss: 3.6747195720672607 | CLS Loss: 0.08890563249588013\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 3.756032943725586 | KNN Loss: 3.6865298748016357 | CLS Loss: 0.06950316578149796\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 3.66727614402771 | KNN Loss: 3.612957239151001 | CLS Loss: 0.054318904876708984\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 3.6851468086242676 | KNN Loss: 3.6329281330108643 | CLS Loss: 0.05221879482269287\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 3.717834234237671 | KNN Loss: 3.6412665843963623 | CLS Loss: 0.07656761258840561\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 3.660985231399536 | KNN Loss: 3.611891984939575 | CLS Loss: 0.049093328416347504\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 3.713395595550537 | KNN Loss: 3.651566743850708 | CLS Loss: 0.06182888150215149\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 3.7513575553894043 | KNN Loss: 3.712094783782959 | CLS Loss: 0.03926265984773636\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 3.7133514881134033 | KNN Loss: 3.6553618907928467 | CLS Loss: 0.057989515364170074\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 3.688051700592041 | KNN Loss: 3.6204001903533936 | CLS Loss: 0.06765156984329224\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 3.7457215785980225 | KNN Loss: 3.6761550903320312 | CLS Loss: 0.06956654787063599\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 3.7180910110473633 | KNN Loss: 3.623548984527588 | CLS Loss: 0.09454194456338882\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 3.7310893535614014 | KNN Loss: 3.6783673763275146 | CLS Loss: 0.05272186920046806\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 3.6811110973358154 | KNN Loss: 3.623749256134033 | CLS Loss: 0.05736181512475014\n",
      "Epoch: 016, Loss: 3.7103, Train: 0.9859, Valid: 0.9815, Best: 0.9815\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 3.7029292583465576 | KNN Loss: 3.653076410293579 | CLS Loss: 0.04985283315181732\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 3.7443647384643555 | KNN Loss: 3.6916024684906006 | CLS Loss: 0.05276215076446533\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 3.7024643421173096 | KNN Loss: 3.667022466659546 | CLS Loss: 0.03544184938073158\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 3.75106143951416 | KNN Loss: 3.67415189743042 | CLS Loss: 0.07690948247909546\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 3.7128584384918213 | KNN Loss: 3.6551268100738525 | CLS Loss: 0.057731688022613525\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 3.714479923248291 | KNN Loss: 3.682008743286133 | CLS Loss: 0.03247116133570671\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 3.694981575012207 | KNN Loss: 3.6142661571502686 | CLS Loss: 0.08071551471948624\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 3.6949405670166016 | KNN Loss: 3.624246597290039 | CLS Loss: 0.07069388777017593\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 3.704167127609253 | KNN Loss: 3.672056198120117 | CLS Loss: 0.03211092948913574\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 3.6904587745666504 | KNN Loss: 3.6287946701049805 | CLS Loss: 0.06166413426399231\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 3.733541250228882 | KNN Loss: 3.6431660652160645 | CLS Loss: 0.09037510305643082\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 3.6899406909942627 | KNN Loss: 3.6358389854431152 | CLS Loss: 0.054101619869470596\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 3.7038192749023438 | KNN Loss: 3.658829689025879 | CLS Loss: 0.04498961567878723\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 3.7078683376312256 | KNN Loss: 3.6637380123138428 | CLS Loss: 0.04413038492202759\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 3.707310199737549 | KNN Loss: 3.669053554534912 | CLS Loss: 0.03825670853257179\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 3.7035467624664307 | KNN Loss: 3.6614694595336914 | CLS Loss: 0.042077209800481796\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 3.6842832565307617 | KNN Loss: 3.6314218044281006 | CLS Loss: 0.052861537784338\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 3.7558982372283936 | KNN Loss: 3.658036947250366 | CLS Loss: 0.09786132723093033\n",
      "Epoch: 017, Loss: 3.7027, Train: 0.9859, Valid: 0.9811, Best: 0.9815\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 3.7177371978759766 | KNN Loss: 3.656219959259033 | CLS Loss: 0.061517227441072464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 3.6905293464660645 | KNN Loss: 3.6615214347839355 | CLS Loss: 0.029007909819483757\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 3.706444025039673 | KNN Loss: 3.633948802947998 | CLS Loss: 0.07249516248703003\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 3.68507981300354 | KNN Loss: 3.631970167160034 | CLS Loss: 0.05310957878828049\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 3.680185317993164 | KNN Loss: 3.606022357940674 | CLS Loss: 0.0741630345582962\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 3.683511972427368 | KNN Loss: 3.6246085166931152 | CLS Loss: 0.05890338122844696\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 3.679985761642456 | KNN Loss: 3.6364259719848633 | CLS Loss: 0.043559860438108444\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 3.67526912689209 | KNN Loss: 3.6158130168914795 | CLS Loss: 0.059456031769514084\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 3.703122138977051 | KNN Loss: 3.6652636528015137 | CLS Loss: 0.03785858303308487\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 3.701007604598999 | KNN Loss: 3.626283884048462 | CLS Loss: 0.07472363859415054\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 3.688892126083374 | KNN Loss: 3.644160509109497 | CLS Loss: 0.04473162442445755\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 3.687700033187866 | KNN Loss: 3.661647081375122 | CLS Loss: 0.02605300210416317\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 3.755186080932617 | KNN Loss: 3.6719746589660645 | CLS Loss: 0.08321139216423035\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 3.6916401386260986 | KNN Loss: 3.623185634613037 | CLS Loss: 0.06845451891422272\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 3.7084133625030518 | KNN Loss: 3.659477949142456 | CLS Loss: 0.04893543943762779\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 3.683922290802002 | KNN Loss: 3.6502394676208496 | CLS Loss: 0.0336829274892807\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 3.742997646331787 | KNN Loss: 3.637099027633667 | CLS Loss: 0.10589861869812012\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 3.69340443611145 | KNN Loss: 3.6611528396606445 | CLS Loss: 0.03225169703364372\n",
      "Epoch: 018, Loss: 3.7015, Train: 0.9844, Valid: 0.9805, Best: 0.9815\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 3.695286750793457 | KNN Loss: 3.6483170986175537 | CLS Loss: 0.046969763934612274\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 3.685434341430664 | KNN Loss: 3.603926420211792 | CLS Loss: 0.08150800317525864\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 3.66180682182312 | KNN Loss: 3.6289498805999756 | CLS Loss: 0.03285687044262886\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 3.669471263885498 | KNN Loss: 3.622513771057129 | CLS Loss: 0.046957533806562424\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 3.694035291671753 | KNN Loss: 3.664217233657837 | CLS Loss: 0.02981809340417385\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 3.7262697219848633 | KNN Loss: 3.6587836742401123 | CLS Loss: 0.06748604774475098\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 3.67748761177063 | KNN Loss: 3.633843421936035 | CLS Loss: 0.04364423081278801\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 3.6693882942199707 | KNN Loss: 3.626124858856201 | CLS Loss: 0.04326333850622177\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 3.718580722808838 | KNN Loss: 3.6663873195648193 | CLS Loss: 0.05219351500272751\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 3.697007656097412 | KNN Loss: 3.6183505058288574 | CLS Loss: 0.07865723222494125\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 3.7288801670074463 | KNN Loss: 3.609095335006714 | CLS Loss: 0.11978483945131302\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 3.6834919452667236 | KNN Loss: 3.6379339694976807 | CLS Loss: 0.045557983219623566\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 3.680290460586548 | KNN Loss: 3.6238954067230225 | CLS Loss: 0.05639509856700897\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 3.7261154651641846 | KNN Loss: 3.679762601852417 | CLS Loss: 0.04635278135538101\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 3.6775667667388916 | KNN Loss: 3.650850534439087 | CLS Loss: 0.02671615034341812\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 3.6981260776519775 | KNN Loss: 3.6509974002838135 | CLS Loss: 0.047128695994615555\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 3.7469325065612793 | KNN Loss: 3.682973861694336 | CLS Loss: 0.06395862251520157\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 3.6923270225524902 | KNN Loss: 3.6359312534332275 | CLS Loss: 0.05639566481113434\n",
      "Epoch: 019, Loss: 3.6952, Train: 0.9876, Valid: 0.9828, Best: 0.9828\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 3.669935703277588 | KNN Loss: 3.6487672328948975 | CLS Loss: 0.021168572828173637\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 3.6858949661254883 | KNN Loss: 3.655261516571045 | CLS Loss: 0.0306333526968956\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 3.6432583332061768 | KNN Loss: 3.6009225845336914 | CLS Loss: 0.04233584553003311\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 3.706674814224243 | KNN Loss: 3.6550486087799072 | CLS Loss: 0.05162617936730385\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 3.6820173263549805 | KNN Loss: 3.6118569374084473 | CLS Loss: 0.07016030699014664\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 3.663900375366211 | KNN Loss: 3.6300275325775146 | CLS Loss: 0.033872827887535095\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 3.689520835876465 | KNN Loss: 3.653661012649536 | CLS Loss: 0.035859838128089905\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 3.6469509601593018 | KNN Loss: 3.6203720569610596 | CLS Loss: 0.0265789981931448\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 3.6754674911499023 | KNN Loss: 3.63759183883667 | CLS Loss: 0.037875667214393616\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 3.7119181156158447 | KNN Loss: 3.6710920333862305 | CLS Loss: 0.04082619398832321\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 3.7431018352508545 | KNN Loss: 3.6484882831573486 | CLS Loss: 0.09461361169815063\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 3.6711857318878174 | KNN Loss: 3.617330312728882 | CLS Loss: 0.05385546758770943\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 3.73105788230896 | KNN Loss: 3.6857054233551025 | CLS Loss: 0.045352544635534286\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 3.7076573371887207 | KNN Loss: 3.622313976287842 | CLS Loss: 0.08534331619739532\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 3.7501463890075684 | KNN Loss: 3.675153970718384 | CLS Loss: 0.07499232143163681\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 3.7235424518585205 | KNN Loss: 3.671712875366211 | CLS Loss: 0.05182962864637375\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 3.6862494945526123 | KNN Loss: 3.637079954147339 | CLS Loss: 0.04916949197649956\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 3.6338088512420654 | KNN Loss: 3.6037349700927734 | CLS Loss: 0.030073806643486023\n",
      "Epoch: 020, Loss: 3.6902, Train: 0.9877, Valid: 0.9830, Best: 0.9830\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 3.665280818939209 | KNN Loss: 3.6362054347991943 | CLS Loss: 0.029075462371110916\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 3.681788206100464 | KNN Loss: 3.646906852722168 | CLS Loss: 0.03488137945532799\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 3.702208995819092 | KNN Loss: 3.6715433597564697 | CLS Loss: 0.0306655652821064\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 3.713022232055664 | KNN Loss: 3.665261745452881 | CLS Loss: 0.047760527580976486\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 3.710139751434326 | KNN Loss: 3.6677749156951904 | CLS Loss: 0.0423649363219738\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 3.678189516067505 | KNN Loss: 3.659869432449341 | CLS Loss: 0.018320167437195778\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 3.705008029937744 | KNN Loss: 3.624371290206909 | CLS Loss: 0.08063662052154541\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 3.7203710079193115 | KNN Loss: 3.64516544342041 | CLS Loss: 0.07520566880702972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 3.6741855144500732 | KNN Loss: 3.644930601119995 | CLS Loss: 0.029254989698529243\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 3.691176414489746 | KNN Loss: 3.6542088985443115 | CLS Loss: 0.03696751967072487\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 3.6645641326904297 | KNN Loss: 3.6213107109069824 | CLS Loss: 0.04325348883867264\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 3.6763253211975098 | KNN Loss: 3.633737087249756 | CLS Loss: 0.042588163167238235\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 3.675701141357422 | KNN Loss: 3.6434972286224365 | CLS Loss: 0.032203931361436844\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 3.6884822845458984 | KNN Loss: 3.631119728088379 | CLS Loss: 0.05736253783106804\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 3.7111411094665527 | KNN Loss: 3.6606998443603516 | CLS Loss: 0.05044128745794296\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 3.6807398796081543 | KNN Loss: 3.6221776008605957 | CLS Loss: 0.05856219306588173\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 3.7389402389526367 | KNN Loss: 3.702707052230835 | CLS Loss: 0.03623318672180176\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 3.730029344558716 | KNN Loss: 3.6755006313323975 | CLS Loss: 0.054528623819351196\n",
      "Epoch: 021, Loss: 3.6912, Train: 0.9869, Valid: 0.9820, Best: 0.9830\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 3.70021915435791 | KNN Loss: 3.6559927463531494 | CLS Loss: 0.044226400554180145\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 3.7399723529815674 | KNN Loss: 3.6404037475585938 | CLS Loss: 0.09956866502761841\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 3.7012481689453125 | KNN Loss: 3.6622869968414307 | CLS Loss: 0.038961201906204224\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 3.6882870197296143 | KNN Loss: 3.627207040786743 | CLS Loss: 0.06107986718416214\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 3.6599020957946777 | KNN Loss: 3.627250909805298 | CLS Loss: 0.032651085406541824\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 3.749333143234253 | KNN Loss: 3.6808724403381348 | CLS Loss: 0.06846073269844055\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 3.670222043991089 | KNN Loss: 3.622281789779663 | CLS Loss: 0.04794013872742653\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 3.673386812210083 | KNN Loss: 3.6446473598480225 | CLS Loss: 0.02873940020799637\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 3.671621084213257 | KNN Loss: 3.6444475650787354 | CLS Loss: 0.02717352844774723\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 3.675302505493164 | KNN Loss: 3.646211862564087 | CLS Loss: 0.029090657830238342\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 3.6800360679626465 | KNN Loss: 3.63075852394104 | CLS Loss: 0.04927750304341316\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 3.6980910301208496 | KNN Loss: 3.664785146713257 | CLS Loss: 0.03330593928694725\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 3.7038400173187256 | KNN Loss: 3.669924259185791 | CLS Loss: 0.03391566872596741\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 3.6719748973846436 | KNN Loss: 3.640118360519409 | CLS Loss: 0.0318564809858799\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 3.715399980545044 | KNN Loss: 3.661499500274658 | CLS Loss: 0.053900379687547684\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 3.713324785232544 | KNN Loss: 3.669691801071167 | CLS Loss: 0.04363301023840904\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 3.718323230743408 | KNN Loss: 3.643805742263794 | CLS Loss: 0.07451743632555008\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 3.7070727348327637 | KNN Loss: 3.6448814868927 | CLS Loss: 0.0621911957859993\n",
      "Epoch: 022, Loss: 3.6930, Train: 0.9880, Valid: 0.9833, Best: 0.9833\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 3.664665699005127 | KNN Loss: 3.6367101669311523 | CLS Loss: 0.02795548550784588\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 3.6811907291412354 | KNN Loss: 3.6361372470855713 | CLS Loss: 0.04505358263850212\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 3.6988143920898438 | KNN Loss: 3.657778263092041 | CLS Loss: 0.041036054491996765\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 3.715165853500366 | KNN Loss: 3.6455094814300537 | CLS Loss: 0.06965640932321548\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 3.6843624114990234 | KNN Loss: 3.645530939102173 | CLS Loss: 0.03883158415555954\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 3.7024943828582764 | KNN Loss: 3.652146100997925 | CLS Loss: 0.05034836754202843\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 3.7090110778808594 | KNN Loss: 3.6344194412231445 | CLS Loss: 0.07459171116352081\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 3.6639556884765625 | KNN Loss: 3.6180026531219482 | CLS Loss: 0.045952972024679184\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 3.6649351119995117 | KNN Loss: 3.6290183067321777 | CLS Loss: 0.035916768014431\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 3.639802932739258 | KNN Loss: 3.6007614135742188 | CLS Loss: 0.03904157504439354\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 3.723013162612915 | KNN Loss: 3.681159496307373 | CLS Loss: 0.04185366630554199\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 3.655254602432251 | KNN Loss: 3.630800724029541 | CLS Loss: 0.02445392683148384\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 3.7661147117614746 | KNN Loss: 3.6901066303253174 | CLS Loss: 0.07600804418325424\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 3.6970884799957275 | KNN Loss: 3.6503849029541016 | CLS Loss: 0.04670354723930359\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 3.6647531986236572 | KNN Loss: 3.632848024368286 | CLS Loss: 0.03190523386001587\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 3.6560850143432617 | KNN Loss: 3.644727945327759 | CLS Loss: 0.01135711558163166\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 3.6731910705566406 | KNN Loss: 3.645740270614624 | CLS Loss: 0.02745084837079048\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 3.65750789642334 | KNN Loss: 3.624046564102173 | CLS Loss: 0.03346136584877968\n",
      "Epoch: 023, Loss: 3.6862, Train: 0.9872, Valid: 0.9828, Best: 0.9833\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 3.7503349781036377 | KNN Loss: 3.666037082672119 | CLS Loss: 0.08429788053035736\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 3.6565239429473877 | KNN Loss: 3.6063661575317383 | CLS Loss: 0.05015771463513374\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 3.6662957668304443 | KNN Loss: 3.625251531600952 | CLS Loss: 0.04104428365826607\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 3.7060635089874268 | KNN Loss: 3.665048122406006 | CLS Loss: 0.04101541265845299\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 3.735459566116333 | KNN Loss: 3.700653314590454 | CLS Loss: 0.0348062701523304\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 3.7180588245391846 | KNN Loss: 3.67197322845459 | CLS Loss: 0.0460856556892395\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 3.7259206771850586 | KNN Loss: 3.6679861545562744 | CLS Loss: 0.057934556156396866\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 3.6791398525238037 | KNN Loss: 3.623084545135498 | CLS Loss: 0.05605538189411163\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 3.6773011684417725 | KNN Loss: 3.639172077178955 | CLS Loss: 0.03812899813055992\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 3.720440149307251 | KNN Loss: 3.650617837905884 | CLS Loss: 0.06982237845659256\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 3.7037947177886963 | KNN Loss: 3.634495735168457 | CLS Loss: 0.06929909437894821\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 3.675203323364258 | KNN Loss: 3.6160078048706055 | CLS Loss: 0.05919545888900757\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 3.6971020698547363 | KNN Loss: 3.64304780960083 | CLS Loss: 0.05405436083674431\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 3.693209171295166 | KNN Loss: 3.664564371109009 | CLS Loss: 0.028644872829318047\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 3.6979291439056396 | KNN Loss: 3.6338322162628174 | CLS Loss: 0.06409681588411331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 3.6903743743896484 | KNN Loss: 3.6219820976257324 | CLS Loss: 0.0683922991156578\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 3.701960325241089 | KNN Loss: 3.6588029861450195 | CLS Loss: 0.043157245963811874\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 3.6730947494506836 | KNN Loss: 3.6150455474853516 | CLS Loss: 0.05804911628365517\n",
      "Epoch: 024, Loss: 3.6882, Train: 0.9878, Valid: 0.9827, Best: 0.9833\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 3.6799540519714355 | KNN Loss: 3.621143341064453 | CLS Loss: 0.05881066620349884\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 3.6978490352630615 | KNN Loss: 3.6547534465789795 | CLS Loss: 0.043095577508211136\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 3.680058717727661 | KNN Loss: 3.6266684532165527 | CLS Loss: 0.053390275686979294\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 3.657360792160034 | KNN Loss: 3.6209774017333984 | CLS Loss: 0.03638339042663574\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 3.649949073791504 | KNN Loss: 3.622558355331421 | CLS Loss: 0.027390671893954277\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 3.6660454273223877 | KNN Loss: 3.6380279064178467 | CLS Loss: 0.028017455711960793\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 3.6443817615509033 | KNN Loss: 3.6125524044036865 | CLS Loss: 0.03182936832308769\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 3.699881076812744 | KNN Loss: 3.654846668243408 | CLS Loss: 0.04503437131643295\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 3.6569952964782715 | KNN Loss: 3.6174466609954834 | CLS Loss: 0.03954867646098137\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 3.6416728496551514 | KNN Loss: 3.606708526611328 | CLS Loss: 0.034964341670274734\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 3.6952264308929443 | KNN Loss: 3.6457083225250244 | CLS Loss: 0.04951813071966171\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 3.7292773723602295 | KNN Loss: 3.667931079864502 | CLS Loss: 0.06134619563817978\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 3.6902029514312744 | KNN Loss: 3.6535820960998535 | CLS Loss: 0.03662078455090523\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 3.7373743057250977 | KNN Loss: 3.6718270778656006 | CLS Loss: 0.06554719060659409\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 3.6581456661224365 | KNN Loss: 3.6095926761627197 | CLS Loss: 0.048552993685007095\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 3.660001516342163 | KNN Loss: 3.630864381790161 | CLS Loss: 0.02913709171116352\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 3.7007009983062744 | KNN Loss: 3.6649272441864014 | CLS Loss: 0.03577373921871185\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 3.7098159790039062 | KNN Loss: 3.6364362239837646 | CLS Loss: 0.07337969541549683\n",
      "Epoch: 025, Loss: 3.6825, Train: 0.9884, Valid: 0.9833, Best: 0.9833\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 3.7224104404449463 | KNN Loss: 3.6605491638183594 | CLS Loss: 0.06186122074723244\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 3.684561252593994 | KNN Loss: 3.650132894515991 | CLS Loss: 0.03442846238613129\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 3.6810142993927 | KNN Loss: 3.604153871536255 | CLS Loss: 0.0768604427576065\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 3.682903528213501 | KNN Loss: 3.6333532333374023 | CLS Loss: 0.0495503693819046\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 3.649498224258423 | KNN Loss: 3.621843099594116 | CLS Loss: 0.027655016630887985\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 3.640613079071045 | KNN Loss: 3.6083245277404785 | CLS Loss: 0.032288458198308945\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 3.677896499633789 | KNN Loss: 3.6431572437286377 | CLS Loss: 0.034739281982183456\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 3.6854474544525146 | KNN Loss: 3.64420223236084 | CLS Loss: 0.04124530032277107\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 3.666378974914551 | KNN Loss: 3.63570499420166 | CLS Loss: 0.030674032866954803\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 3.665635108947754 | KNN Loss: 3.6255908012390137 | CLS Loss: 0.04004440829157829\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 3.746476650238037 | KNN Loss: 3.6411662101745605 | CLS Loss: 0.10531041026115417\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 3.699552059173584 | KNN Loss: 3.6580405235290527 | CLS Loss: 0.04151159152388573\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 3.6999096870422363 | KNN Loss: 3.6435446739196777 | CLS Loss: 0.056365128606557846\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 3.6706459522247314 | KNN Loss: 3.6226963996887207 | CLS Loss: 0.04794949293136597\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 3.754377841949463 | KNN Loss: 3.697028160095215 | CLS Loss: 0.05734958499670029\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 3.6550137996673584 | KNN Loss: 3.6366817951202393 | CLS Loss: 0.018332000821828842\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 3.662750720977783 | KNN Loss: 3.6430370807647705 | CLS Loss: 0.019713692367076874\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 3.7147395610809326 | KNN Loss: 3.6713204383850098 | CLS Loss: 0.043419159948825836\n",
      "Epoch: 026, Loss: 3.6843, Train: 0.9890, Valid: 0.9839, Best: 0.9839\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 3.6376264095306396 | KNN Loss: 3.599430561065674 | CLS Loss: 0.038195785135030746\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 3.6717562675476074 | KNN Loss: 3.64199161529541 | CLS Loss: 0.02976454235613346\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 3.6476426124572754 | KNN Loss: 3.6103098392486572 | CLS Loss: 0.03733270242810249\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 3.66353178024292 | KNN Loss: 3.6318564414978027 | CLS Loss: 0.03167535364627838\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 3.6485109329223633 | KNN Loss: 3.610326051712036 | CLS Loss: 0.03818495199084282\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 3.7005248069763184 | KNN Loss: 3.684145212173462 | CLS Loss: 0.01637961156666279\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 3.690974473953247 | KNN Loss: 3.6677157878875732 | CLS Loss: 0.0232586320489645\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 3.630084276199341 | KNN Loss: 3.6092238426208496 | CLS Loss: 0.020860549062490463\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 3.677034616470337 | KNN Loss: 3.649463176727295 | CLS Loss: 0.02757137082517147\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 3.6962270736694336 | KNN Loss: 3.6208279132843018 | CLS Loss: 0.07539920508861542\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 3.6752736568450928 | KNN Loss: 3.6247596740722656 | CLS Loss: 0.05051393806934357\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 3.690030097961426 | KNN Loss: 3.665861129760742 | CLS Loss: 0.02416893281042576\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 3.724808931350708 | KNN Loss: 3.662209987640381 | CLS Loss: 0.06259903311729431\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 3.6992835998535156 | KNN Loss: 3.6122872829437256 | CLS Loss: 0.08699638396501541\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 3.660640239715576 | KNN Loss: 3.628962993621826 | CLS Loss: 0.03167734667658806\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 3.7047197818756104 | KNN Loss: 3.6470460891723633 | CLS Loss: 0.057673800736665726\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 3.722581624984741 | KNN Loss: 3.680140733718872 | CLS Loss: 0.04244079813361168\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 3.6895766258239746 | KNN Loss: 3.6326653957366943 | CLS Loss: 0.056911174207925797\n",
      "Epoch: 027, Loss: 3.6768, Train: 0.9903, Valid: 0.9839, Best: 0.9839\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 3.672757863998413 | KNN Loss: 3.6468636989593506 | CLS Loss: 0.025894176214933395\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 3.6909191608428955 | KNN Loss: 3.653322696685791 | CLS Loss: 0.0375964529812336\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 3.6699154376983643 | KNN Loss: 3.627220630645752 | CLS Loss: 0.04269488900899887\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 3.664027452468872 | KNN Loss: 3.639525890350342 | CLS Loss: 0.024501556530594826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 3.683732271194458 | KNN Loss: 3.63784122467041 | CLS Loss: 0.045891132205724716\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 3.7241547107696533 | KNN Loss: 3.6810832023620605 | CLS Loss: 0.04307141527533531\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 3.651355504989624 | KNN Loss: 3.6278281211853027 | CLS Loss: 0.02352738007903099\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 3.700629711151123 | KNN Loss: 3.6274824142456055 | CLS Loss: 0.0731472596526146\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 3.6668405532836914 | KNN Loss: 3.621349811553955 | CLS Loss: 0.04549062252044678\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 3.6885180473327637 | KNN Loss: 3.663614511489868 | CLS Loss: 0.024903450161218643\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 3.652031660079956 | KNN Loss: 3.612787961959839 | CLS Loss: 0.03924375772476196\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 3.6337103843688965 | KNN Loss: 3.586911916732788 | CLS Loss: 0.046798501163721085\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 3.751701831817627 | KNN Loss: 3.618889093399048 | CLS Loss: 0.13281267881393433\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 3.671186685562134 | KNN Loss: 3.6241888999938965 | CLS Loss: 0.0469977967441082\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 3.6933577060699463 | KNN Loss: 3.652466058731079 | CLS Loss: 0.0408916138112545\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 3.701498508453369 | KNN Loss: 3.648099422454834 | CLS Loss: 0.05339911952614784\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 3.628441572189331 | KNN Loss: 3.6104319095611572 | CLS Loss: 0.018009696155786514\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 3.7201507091522217 | KNN Loss: 3.6603002548217773 | CLS Loss: 0.059850532561540604\n",
      "Epoch: 028, Loss: 3.6824, Train: 0.9881, Valid: 0.9813, Best: 0.9839\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 3.6904873847961426 | KNN Loss: 3.6416964530944824 | CLS Loss: 0.048791032284498215\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 3.705090284347534 | KNN Loss: 3.650264024734497 | CLS Loss: 0.054826151579618454\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 3.6309428215026855 | KNN Loss: 3.601278781890869 | CLS Loss: 0.02966413088142872\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 3.6839723587036133 | KNN Loss: 3.6567015647888184 | CLS Loss: 0.027270806953310966\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 3.6769514083862305 | KNN Loss: 3.6383752822875977 | CLS Loss: 0.038576073944568634\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 3.6809399127960205 | KNN Loss: 3.6384315490722656 | CLS Loss: 0.04250834509730339\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 3.656235456466675 | KNN Loss: 3.628507137298584 | CLS Loss: 0.027728278189897537\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 3.7081730365753174 | KNN Loss: 3.684943199157715 | CLS Loss: 0.023229828104376793\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 3.706625461578369 | KNN Loss: 3.6641194820404053 | CLS Loss: 0.042506054043769836\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 3.705655336380005 | KNN Loss: 3.65795636177063 | CLS Loss: 0.04769900068640709\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 3.651968002319336 | KNN Loss: 3.6070923805236816 | CLS Loss: 0.04487555846571922\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 3.697603702545166 | KNN Loss: 3.6493983268737793 | CLS Loss: 0.048205360770225525\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 3.6402385234832764 | KNN Loss: 3.601600408554077 | CLS Loss: 0.038638196885585785\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 3.684926986694336 | KNN Loss: 3.646721601486206 | CLS Loss: 0.038205474615097046\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 3.6903016567230225 | KNN Loss: 3.630690097808838 | CLS Loss: 0.05961162969470024\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 3.6967780590057373 | KNN Loss: 3.6362545490264893 | CLS Loss: 0.0605236254632473\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 3.6592297554016113 | KNN Loss: 3.6043701171875 | CLS Loss: 0.05485973507165909\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 3.665822982788086 | KNN Loss: 3.6334009170532227 | CLS Loss: 0.03242197632789612\n",
      "Epoch: 029, Loss: 3.6750, Train: 0.9905, Valid: 0.9852, Best: 0.9852\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 3.6742353439331055 | KNN Loss: 3.632481336593628 | CLS Loss: 0.04175395146012306\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 3.68729567527771 | KNN Loss: 3.648946523666382 | CLS Loss: 0.03834909945726395\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 3.6397244930267334 | KNN Loss: 3.6128811836242676 | CLS Loss: 0.02684335596859455\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 3.672569513320923 | KNN Loss: 3.6379427909851074 | CLS Loss: 0.03462663292884827\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 3.7385804653167725 | KNN Loss: 3.698434829711914 | CLS Loss: 0.04014555737376213\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 3.656647205352783 | KNN Loss: 3.625612735748291 | CLS Loss: 0.031034519895911217\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 3.699849843978882 | KNN Loss: 3.664407730102539 | CLS Loss: 0.035442158579826355\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 3.6627306938171387 | KNN Loss: 3.6256535053253174 | CLS Loss: 0.03707721829414368\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 3.6520228385925293 | KNN Loss: 3.6176443099975586 | CLS Loss: 0.03437848389148712\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 3.7264904975891113 | KNN Loss: 3.6739907264709473 | CLS Loss: 0.052499882876873016\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 3.6931517124176025 | KNN Loss: 3.636014223098755 | CLS Loss: 0.057137563824653625\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 3.639099359512329 | KNN Loss: 3.6205735206604004 | CLS Loss: 0.018525799736380577\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 3.7213993072509766 | KNN Loss: 3.6787056922912598 | CLS Loss: 0.04269373044371605\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 3.6285080909729004 | KNN Loss: 3.606520891189575 | CLS Loss: 0.021987272426486015\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 3.7055249214172363 | KNN Loss: 3.666971445083618 | CLS Loss: 0.03855343535542488\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 3.6820242404937744 | KNN Loss: 3.6278576850891113 | CLS Loss: 0.05416659638285637\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 3.6339800357818604 | KNN Loss: 3.603189706802368 | CLS Loss: 0.030790433287620544\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 3.6915853023529053 | KNN Loss: 3.629124164581299 | CLS Loss: 0.06246118247509003\n",
      "Epoch: 030, Loss: 3.6768, Train: 0.9904, Valid: 0.9849, Best: 0.9852\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 3.6851389408111572 | KNN Loss: 3.6406688690185547 | CLS Loss: 0.04446996748447418\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 3.711336851119995 | KNN Loss: 3.7010433673858643 | CLS Loss: 0.010293443687260151\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 3.6356637477874756 | KNN Loss: 3.601489305496216 | CLS Loss: 0.03417448699474335\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 3.656973123550415 | KNN Loss: 3.6312146186828613 | CLS Loss: 0.025758521631360054\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 3.69907546043396 | KNN Loss: 3.6574859619140625 | CLS Loss: 0.041589610278606415\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 3.6469171047210693 | KNN Loss: 3.616164207458496 | CLS Loss: 0.03075285069644451\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 3.6356396675109863 | KNN Loss: 3.61924147605896 | CLS Loss: 0.01639823615550995\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 3.6623096466064453 | KNN Loss: 3.6061806678771973 | CLS Loss: 0.05612898990511894\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 3.6926991939544678 | KNN Loss: 3.6713528633117676 | CLS Loss: 0.02134643867611885\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 3.6901538372039795 | KNN Loss: 3.6463141441345215 | CLS Loss: 0.04383965954184532\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 3.657496213912964 | KNN Loss: 3.6169259548187256 | CLS Loss: 0.040570151060819626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 3.688228130340576 | KNN Loss: 3.6507999897003174 | CLS Loss: 0.03742813691496849\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 3.6421101093292236 | KNN Loss: 3.586568593978882 | CLS Loss: 0.05554141104221344\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 3.7111170291900635 | KNN Loss: 3.667830467224121 | CLS Loss: 0.0432865284383297\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 3.691829204559326 | KNN Loss: 3.659367084503174 | CLS Loss: 0.032462190836668015\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 3.6361770629882812 | KNN Loss: 3.6278343200683594 | CLS Loss: 0.008342758752405643\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 3.6458358764648438 | KNN Loss: 3.619546890258789 | CLS Loss: 0.02628910169005394\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 3.6320698261260986 | KNN Loss: 3.6098809242248535 | CLS Loss: 0.022188959643244743\n",
      "Epoch: 031, Loss: 3.6718, Train: 0.9904, Valid: 0.9854, Best: 0.9854\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 3.673222780227661 | KNN Loss: 3.6163835525512695 | CLS Loss: 0.05683927610516548\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 3.6573023796081543 | KNN Loss: 3.594630241394043 | CLS Loss: 0.06267210841178894\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 3.6814217567443848 | KNN Loss: 3.6666758060455322 | CLS Loss: 0.014746058732271194\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 3.6836249828338623 | KNN Loss: 3.653092861175537 | CLS Loss: 0.030532192438840866\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 3.7056148052215576 | KNN Loss: 3.6520819664001465 | CLS Loss: 0.05353279411792755\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 3.664227247238159 | KNN Loss: 3.6391215324401855 | CLS Loss: 0.02510565146803856\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 3.6850075721740723 | KNN Loss: 3.651339530944824 | CLS Loss: 0.03366793319582939\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 3.6500465869903564 | KNN Loss: 3.615915060043335 | CLS Loss: 0.034131575375795364\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 3.6948227882385254 | KNN Loss: 3.658517599105835 | CLS Loss: 0.03630509600043297\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 3.699608087539673 | KNN Loss: 3.6652581691741943 | CLS Loss: 0.03434990718960762\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 3.6788501739501953 | KNN Loss: 3.6370818614959717 | CLS Loss: 0.04176826402544975\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 3.6834239959716797 | KNN Loss: 3.6243934631347656 | CLS Loss: 0.05903063341975212\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 3.6610939502716064 | KNN Loss: 3.64139986038208 | CLS Loss: 0.019694071263074875\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 3.67978572845459 | KNN Loss: 3.6594982147216797 | CLS Loss: 0.020287396386265755\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 3.677405595779419 | KNN Loss: 3.6437690258026123 | CLS Loss: 0.03363655135035515\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 3.6531429290771484 | KNN Loss: 3.6154096126556396 | CLS Loss: 0.037733372300863266\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 3.669635534286499 | KNN Loss: 3.633105516433716 | CLS Loss: 0.03652997687458992\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 3.641568660736084 | KNN Loss: 3.61169695854187 | CLS Loss: 0.029871689155697823\n",
      "Epoch: 032, Loss: 3.6725, Train: 0.9908, Valid: 0.9849, Best: 0.9854\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 3.6703615188598633 | KNN Loss: 3.638448715209961 | CLS Loss: 0.03191271796822548\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 3.634755849838257 | KNN Loss: 3.60520601272583 | CLS Loss: 0.02954973466694355\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 3.669966697692871 | KNN Loss: 3.639702320098877 | CLS Loss: 0.030264263972640038\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 3.6771562099456787 | KNN Loss: 3.6593117713928223 | CLS Loss: 0.017844393849372864\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 3.636223793029785 | KNN Loss: 3.622633695602417 | CLS Loss: 0.013590101152658463\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 3.6498732566833496 | KNN Loss: 3.62036395072937 | CLS Loss: 0.029509318992495537\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 3.6745975017547607 | KNN Loss: 3.6353259086608887 | CLS Loss: 0.03927157074213028\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 3.6602554321289062 | KNN Loss: 3.6137828826904297 | CLS Loss: 0.04647252708673477\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 3.6674585342407227 | KNN Loss: 3.6440651416778564 | CLS Loss: 0.023393459618091583\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 3.6592090129852295 | KNN Loss: 3.620521306991577 | CLS Loss: 0.03868779167532921\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 3.674359083175659 | KNN Loss: 3.6440391540527344 | CLS Loss: 0.030320029705762863\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 3.6618711948394775 | KNN Loss: 3.6235344409942627 | CLS Loss: 0.03833666443824768\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 3.6507363319396973 | KNN Loss: 3.605755090713501 | CLS Loss: 0.04498128220438957\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 3.623244047164917 | KNN Loss: 3.6133222579956055 | CLS Loss: 0.009921815246343613\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 3.6980209350585938 | KNN Loss: 3.627610206604004 | CLS Loss: 0.07041065394878387\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 3.7308452129364014 | KNN Loss: 3.6761209964752197 | CLS Loss: 0.05472414195537567\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 3.6895647048950195 | KNN Loss: 3.6488749980926514 | CLS Loss: 0.040689773857593536\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 3.6471073627471924 | KNN Loss: 3.6031548976898193 | CLS Loss: 0.04395250231027603\n",
      "Epoch: 033, Loss: 3.6684, Train: 0.9900, Valid: 0.9851, Best: 0.9854\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 3.6441380977630615 | KNN Loss: 3.6224474906921387 | CLS Loss: 0.02169065736234188\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 3.6635823249816895 | KNN Loss: 3.620821475982666 | CLS Loss: 0.0427609458565712\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 3.639221668243408 | KNN Loss: 3.620722532272339 | CLS Loss: 0.01849922351539135\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 3.6502602100372314 | KNN Loss: 3.6243410110473633 | CLS Loss: 0.02591915801167488\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 3.6838576793670654 | KNN Loss: 3.6391329765319824 | CLS Loss: 0.04472476989030838\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 3.649385690689087 | KNN Loss: 3.5989670753479004 | CLS Loss: 0.05041862279176712\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 3.684931993484497 | KNN Loss: 3.6640403270721436 | CLS Loss: 0.020891578868031502\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 3.648775577545166 | KNN Loss: 3.6267447471618652 | CLS Loss: 0.022030822932720184\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 3.6977992057800293 | KNN Loss: 3.6434717178344727 | CLS Loss: 0.05432749539613724\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 3.6548311710357666 | KNN Loss: 3.6291232109069824 | CLS Loss: 0.025708025321364403\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 3.651684045791626 | KNN Loss: 3.620694160461426 | CLS Loss: 0.030989870429039\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 3.7030861377716064 | KNN Loss: 3.6388702392578125 | CLS Loss: 0.06421585381031036\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 3.6561331748962402 | KNN Loss: 3.616490602493286 | CLS Loss: 0.03964252769947052\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 3.663891553878784 | KNN Loss: 3.64125394821167 | CLS Loss: 0.022637665271759033\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 3.6389753818511963 | KNN Loss: 3.6080806255340576 | CLS Loss: 0.030894828960299492\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 3.640864849090576 | KNN Loss: 3.597383975982666 | CLS Loss: 0.04348096251487732\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 3.6802423000335693 | KNN Loss: 3.6188580989837646 | CLS Loss: 0.061384111642837524\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 3.6551620960235596 | KNN Loss: 3.6200852394104004 | CLS Loss: 0.03507685661315918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 3.6655, Train: 0.9904, Valid: 0.9851, Best: 0.9854\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 3.659313678741455 | KNN Loss: 3.646801471710205 | CLS Loss: 0.012512186542153358\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 3.658104658126831 | KNN Loss: 3.633042573928833 | CLS Loss: 0.02506212517619133\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 3.6805267333984375 | KNN Loss: 3.6537559032440186 | CLS Loss: 0.02677087113261223\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 3.659950017929077 | KNN Loss: 3.6438732147216797 | CLS Loss: 0.016076767817139626\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 3.638293504714966 | KNN Loss: 3.612647771835327 | CLS Loss: 0.025645634159445763\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 3.749516725540161 | KNN Loss: 3.6963722705841064 | CLS Loss: 0.053144536912441254\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 3.63759446144104 | KNN Loss: 3.623734474182129 | CLS Loss: 0.013860026374459267\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 3.6540791988372803 | KNN Loss: 3.608391761779785 | CLS Loss: 0.045687537640333176\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 3.652186155319214 | KNN Loss: 3.639617919921875 | CLS Loss: 0.012568303383886814\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 3.6757190227508545 | KNN Loss: 3.653688907623291 | CLS Loss: 0.022030053660273552\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 3.6713156700134277 | KNN Loss: 3.6387388706207275 | CLS Loss: 0.032576870173215866\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 3.6990396976470947 | KNN Loss: 3.639878988265991 | CLS Loss: 0.059160806238651276\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 3.6730167865753174 | KNN Loss: 3.625764846801758 | CLS Loss: 0.04725196585059166\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 3.6645374298095703 | KNN Loss: 3.63385009765625 | CLS Loss: 0.030687255784869194\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 3.6239676475524902 | KNN Loss: 3.6039466857910156 | CLS Loss: 0.020020846277475357\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 3.6394500732421875 | KNN Loss: 3.603811740875244 | CLS Loss: 0.03563828021287918\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 3.6589438915252686 | KNN Loss: 3.6214537620544434 | CLS Loss: 0.037490155547857285\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 3.619007110595703 | KNN Loss: 3.6000523567199707 | CLS Loss: 0.018954765051603317\n",
      "Epoch: 035, Loss: 3.6659, Train: 0.9915, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 3.639392137527466 | KNN Loss: 3.6271533966064453 | CLS Loss: 0.012238625437021255\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 3.6271026134490967 | KNN Loss: 3.5967509746551514 | CLS Loss: 0.03035164624452591\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 3.6723039150238037 | KNN Loss: 3.656280279159546 | CLS Loss: 0.016023598611354828\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 3.6589744091033936 | KNN Loss: 3.6262521743774414 | CLS Loss: 0.03272220119833946\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 3.634338140487671 | KNN Loss: 3.617178201675415 | CLS Loss: 0.017159901559352875\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 3.6641883850097656 | KNN Loss: 3.6351842880249023 | CLS Loss: 0.029004020616412163\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 3.7249529361724854 | KNN Loss: 3.692479133605957 | CLS Loss: 0.03247370570898056\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 3.7016994953155518 | KNN Loss: 3.654886484146118 | CLS Loss: 0.04681296646595001\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 3.675680637359619 | KNN Loss: 3.650956630706787 | CLS Loss: 0.024723928421735764\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 3.6393725872039795 | KNN Loss: 3.5906167030334473 | CLS Loss: 0.04875588417053223\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 3.6309220790863037 | KNN Loss: 3.6208460330963135 | CLS Loss: 0.010076009668409824\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 3.670952081680298 | KNN Loss: 3.6397647857666016 | CLS Loss: 0.031187275424599648\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 3.691786527633667 | KNN Loss: 3.657871723175049 | CLS Loss: 0.03391489014029503\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 3.665858268737793 | KNN Loss: 3.6312785148620605 | CLS Loss: 0.034579742699861526\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 3.7049505710601807 | KNN Loss: 3.6140596866607666 | CLS Loss: 0.09089086949825287\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 3.651125907897949 | KNN Loss: 3.626518487930298 | CLS Loss: 0.02460748888552189\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 3.7078094482421875 | KNN Loss: 3.665933847427368 | CLS Loss: 0.04187571257352829\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 3.653980255126953 | KNN Loss: 3.642805814743042 | CLS Loss: 0.011174492537975311\n",
      "Epoch: 036, Loss: 3.6680, Train: 0.9903, Valid: 0.9843, Best: 0.9860\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 3.6829848289489746 | KNN Loss: 3.6193902492523193 | CLS Loss: 0.06359466165304184\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 3.6742515563964844 | KNN Loss: 3.632078170776367 | CLS Loss: 0.0421733483672142\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 3.6845052242279053 | KNN Loss: 3.6576693058013916 | CLS Loss: 0.026835916563868523\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 3.6448211669921875 | KNN Loss: 3.6188931465148926 | CLS Loss: 0.025928078219294548\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 3.6545803546905518 | KNN Loss: 3.624211549758911 | CLS Loss: 0.030368724837899208\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 3.635134220123291 | KNN Loss: 3.6158008575439453 | CLS Loss: 0.019333427771925926\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 3.6634433269500732 | KNN Loss: 3.6338047981262207 | CLS Loss: 0.029638472944498062\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 3.669813632965088 | KNN Loss: 3.6508688926696777 | CLS Loss: 0.0189446359872818\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 3.6511285305023193 | KNN Loss: 3.6143603324890137 | CLS Loss: 0.03676820173859596\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 3.654003381729126 | KNN Loss: 3.621854066848755 | CLS Loss: 0.03214922547340393\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 3.6885626316070557 | KNN Loss: 3.6607043743133545 | CLS Loss: 0.0278581865131855\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 3.64335036277771 | KNN Loss: 3.6326022148132324 | CLS Loss: 0.010748155415058136\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 3.6987953186035156 | KNN Loss: 3.659733295440674 | CLS Loss: 0.039062127470970154\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 3.680473566055298 | KNN Loss: 3.6526429653167725 | CLS Loss: 0.027830516919493675\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 3.693403482437134 | KNN Loss: 3.6692450046539307 | CLS Loss: 0.02415849268436432\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 3.682762861251831 | KNN Loss: 3.6548943519592285 | CLS Loss: 0.027868518605828285\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 3.662022113800049 | KNN Loss: 3.6121163368225098 | CLS Loss: 0.04990588128566742\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 3.6253011226654053 | KNN Loss: 3.60585880279541 | CLS Loss: 0.01944226771593094\n",
      "Epoch: 037, Loss: 3.6665, Train: 0.9925, Valid: 0.9855, Best: 0.9860\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 3.6376991271972656 | KNN Loss: 3.622337818145752 | CLS Loss: 0.015361412428319454\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 3.634828567504883 | KNN Loss: 3.626957416534424 | CLS Loss: 0.007871221750974655\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 3.633310556411743 | KNN Loss: 3.6105332374572754 | CLS Loss: 0.02277727797627449\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 3.639739751815796 | KNN Loss: 3.600440502166748 | CLS Loss: 0.03929927572607994\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 3.751044988632202 | KNN Loss: 3.7116174697875977 | CLS Loss: 0.0394275039434433\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 3.722297191619873 | KNN Loss: 3.6531004905700684 | CLS Loss: 0.06919675320386887\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 3.6808676719665527 | KNN Loss: 3.6052117347717285 | CLS Loss: 0.0756559744477272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 3.7646243572235107 | KNN Loss: 3.6833763122558594 | CLS Loss: 0.08124809712171555\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 3.6657559871673584 | KNN Loss: 3.6157639026641846 | CLS Loss: 0.04999213665723801\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 3.6492063999176025 | KNN Loss: 3.6175856590270996 | CLS Loss: 0.03162074089050293\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 3.6513671875 | KNN Loss: 3.631314754486084 | CLS Loss: 0.020052360370755196\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 3.6682796478271484 | KNN Loss: 3.629516839981079 | CLS Loss: 0.03876269981265068\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 3.6607375144958496 | KNN Loss: 3.62886643409729 | CLS Loss: 0.03187102451920509\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 3.722790002822876 | KNN Loss: 3.6868550777435303 | CLS Loss: 0.03593502938747406\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 3.6698596477508545 | KNN Loss: 3.6325418949127197 | CLS Loss: 0.03731771931052208\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 3.652780055999756 | KNN Loss: 3.633450508117676 | CLS Loss: 0.01932957023382187\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 3.657344102859497 | KNN Loss: 3.6181111335754395 | CLS Loss: 0.039232999086380005\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 3.6235198974609375 | KNN Loss: 3.585019588470459 | CLS Loss: 0.038500215858221054\n",
      "Epoch: 038, Loss: 3.6639, Train: 0.9918, Valid: 0.9844, Best: 0.9860\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 3.687357187271118 | KNN Loss: 3.6465468406677246 | CLS Loss: 0.04081030189990997\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 3.704409122467041 | KNN Loss: 3.6470887660980225 | CLS Loss: 0.057320285588502884\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 3.643632650375366 | KNN Loss: 3.614924907684326 | CLS Loss: 0.028707699850201607\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 3.6421525478363037 | KNN Loss: 3.6132967472076416 | CLS Loss: 0.028855716809630394\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 3.634751081466675 | KNN Loss: 3.606022596359253 | CLS Loss: 0.028728391975164413\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 3.704869508743286 | KNN Loss: 3.6919825077056885 | CLS Loss: 0.01288693118840456\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 3.6249401569366455 | KNN Loss: 3.6029083728790283 | CLS Loss: 0.02203180082142353\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 3.675994873046875 | KNN Loss: 3.629331350326538 | CLS Loss: 0.046663541346788406\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 3.6856472492218018 | KNN Loss: 3.6544365882873535 | CLS Loss: 0.031210653483867645\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 3.683119297027588 | KNN Loss: 3.662367582321167 | CLS Loss: 0.020751794800162315\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 3.651254892349243 | KNN Loss: 3.633190870285034 | CLS Loss: 0.018064117059111595\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 3.667018413543701 | KNN Loss: 3.629188060760498 | CLS Loss: 0.03783031925559044\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 3.6584458351135254 | KNN Loss: 3.6047778129577637 | CLS Loss: 0.05366794392466545\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 3.6455838680267334 | KNN Loss: 3.606717586517334 | CLS Loss: 0.03886629268527031\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 3.6550817489624023 | KNN Loss: 3.6237103939056396 | CLS Loss: 0.0313713401556015\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 3.616579055786133 | KNN Loss: 3.601900100708008 | CLS Loss: 0.014679011888802052\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 3.660517692565918 | KNN Loss: 3.628175735473633 | CLS Loss: 0.032341983169317245\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 3.6897149085998535 | KNN Loss: 3.653076410293579 | CLS Loss: 0.03663858771324158\n",
      "Epoch: 039, Loss: 3.6600, Train: 0.9911, Valid: 0.9842, Best: 0.9860\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 3.649690866470337 | KNN Loss: 3.6209239959716797 | CLS Loss: 0.028766803443431854\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 3.6693131923675537 | KNN Loss: 3.6241586208343506 | CLS Loss: 0.045154593884944916\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 3.683161973953247 | KNN Loss: 3.657212734222412 | CLS Loss: 0.02594924159348011\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 3.65796160697937 | KNN Loss: 3.6335418224334717 | CLS Loss: 0.024419691413640976\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 3.63285493850708 | KNN Loss: 3.6077709197998047 | CLS Loss: 0.02508404850959778\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 3.649467945098877 | KNN Loss: 3.6256206035614014 | CLS Loss: 0.02384733408689499\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 3.6384661197662354 | KNN Loss: 3.611708879470825 | CLS Loss: 0.026757191866636276\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 3.6955654621124268 | KNN Loss: 3.651888132095337 | CLS Loss: 0.04367723688483238\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 3.6260321140289307 | KNN Loss: 3.586465835571289 | CLS Loss: 0.03956636041402817\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 3.6907567977905273 | KNN Loss: 3.6606545448303223 | CLS Loss: 0.030102159827947617\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 3.698617696762085 | KNN Loss: 3.6602838039398193 | CLS Loss: 0.03833392262458801\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 3.6517863273620605 | KNN Loss: 3.6103148460388184 | CLS Loss: 0.041471462696790695\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 3.6746561527252197 | KNN Loss: 3.652926206588745 | CLS Loss: 0.021729903295636177\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 3.682685613632202 | KNN Loss: 3.656721830368042 | CLS Loss: 0.02596389502286911\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 3.6498820781707764 | KNN Loss: 3.6058690547943115 | CLS Loss: 0.04401296749711037\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 3.700284004211426 | KNN Loss: 3.6833786964416504 | CLS Loss: 0.01690535619854927\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 3.6569015979766846 | KNN Loss: 3.6319127082824707 | CLS Loss: 0.02498900331556797\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 3.6594724655151367 | KNN Loss: 3.637744903564453 | CLS Loss: 0.021727608516812325\n",
      "Epoch: 040, Loss: 3.6615, Train: 0.9927, Valid: 0.9849, Best: 0.9860\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 3.658298969268799 | KNN Loss: 3.629084348678589 | CLS Loss: 0.029214635491371155\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 3.66937518119812 | KNN Loss: 3.6314895153045654 | CLS Loss: 0.03788555786013603\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 3.64921498298645 | KNN Loss: 3.630953073501587 | CLS Loss: 0.018261965364217758\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 3.6304376125335693 | KNN Loss: 3.5909485816955566 | CLS Loss: 0.03948907181620598\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 3.690256118774414 | KNN Loss: 3.647899866104126 | CLS Loss: 0.04235624521970749\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 3.6337549686431885 | KNN Loss: 3.6177852153778076 | CLS Loss: 0.015969783067703247\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 3.6656885147094727 | KNN Loss: 3.6334104537963867 | CLS Loss: 0.03227807953953743\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 3.642763614654541 | KNN Loss: 3.61918568611145 | CLS Loss: 0.023578014224767685\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 3.6255462169647217 | KNN Loss: 3.616666316986084 | CLS Loss: 0.008879956789314747\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 3.6961350440979004 | KNN Loss: 3.658015727996826 | CLS Loss: 0.03811943158507347\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 3.676452875137329 | KNN Loss: 3.63427734375 | CLS Loss: 0.04217556491494179\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 3.62835431098938 | KNN Loss: 3.610351800918579 | CLS Loss: 0.01800244115293026\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 3.6212663650512695 | KNN Loss: 3.604607582092285 | CLS Loss: 0.016658710315823555\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 3.6887660026550293 | KNN Loss: 3.6344034671783447 | CLS Loss: 0.05436248332262039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 3.652107000350952 | KNN Loss: 3.636575222015381 | CLS Loss: 0.015531751327216625\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 3.7022857666015625 | KNN Loss: 3.6791675090789795 | CLS Loss: 0.02311818115413189\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 3.66413950920105 | KNN Loss: 3.6246023178100586 | CLS Loss: 0.039537109434604645\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 3.6606552600860596 | KNN Loss: 3.6410980224609375 | CLS Loss: 0.019557276740670204\n",
      "Epoch: 041, Loss: 3.6582, Train: 0.9932, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 3.6573989391326904 | KNN Loss: 3.621546983718872 | CLS Loss: 0.035851992666721344\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 3.63030743598938 | KNN Loss: 3.61606764793396 | CLS Loss: 0.014239874668419361\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 3.651611328125 | KNN Loss: 3.636916160583496 | CLS Loss: 0.014695207588374615\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 3.671076774597168 | KNN Loss: 3.655796527862549 | CLS Loss: 0.01528021041303873\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 3.645289421081543 | KNN Loss: 3.6232223510742188 | CLS Loss: 0.022067178040742874\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 3.6489157676696777 | KNN Loss: 3.6107475757598877 | CLS Loss: 0.038168128579854965\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 3.653372287750244 | KNN Loss: 3.64410662651062 | CLS Loss: 0.00926573108881712\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 3.648181200027466 | KNN Loss: 3.6405246257781982 | CLS Loss: 0.007656692992895842\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 3.6663522720336914 | KNN Loss: 3.636274814605713 | CLS Loss: 0.03007754310965538\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 3.6651456356048584 | KNN Loss: 3.644345283508301 | CLS Loss: 0.020800301805138588\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 3.6402831077575684 | KNN Loss: 3.618067502975464 | CLS Loss: 0.022215591743588448\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 3.6568844318389893 | KNN Loss: 3.635495901107788 | CLS Loss: 0.0213885847479105\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 3.6732594966888428 | KNN Loss: 3.6407058238983154 | CLS Loss: 0.03255373612046242\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 3.675170660018921 | KNN Loss: 3.640363931655884 | CLS Loss: 0.034806616604328156\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 3.6844980716705322 | KNN Loss: 3.663076877593994 | CLS Loss: 0.021421248093247414\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 3.672098398208618 | KNN Loss: 3.650010108947754 | CLS Loss: 0.022088322788476944\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 3.681731939315796 | KNN Loss: 3.640005111694336 | CLS Loss: 0.04172678664326668\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 3.646622896194458 | KNN Loss: 3.6313819885253906 | CLS Loss: 0.015240826644003391\n",
      "Epoch: 042, Loss: 3.6642, Train: 0.9919, Valid: 0.9854, Best: 0.9861\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 3.6832435131073 | KNN Loss: 3.621814489364624 | CLS Loss: 0.0614289715886116\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 3.625002384185791 | KNN Loss: 3.6200146675109863 | CLS Loss: 0.004987796302884817\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 3.641711711883545 | KNN Loss: 3.6173691749572754 | CLS Loss: 0.024342503398656845\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 3.6352486610412598 | KNN Loss: 3.612328052520752 | CLS Loss: 0.022920576855540276\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 3.670875072479248 | KNN Loss: 3.660496473312378 | CLS Loss: 0.010378600098192692\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 3.6673409938812256 | KNN Loss: 3.6447901725769043 | CLS Loss: 0.022550854831933975\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 3.6808087825775146 | KNN Loss: 3.6546790599823 | CLS Loss: 0.02612980268895626\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 3.6523187160491943 | KNN Loss: 3.6361119747161865 | CLS Loss: 0.01620674878358841\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 3.6882517337799072 | KNN Loss: 3.634960174560547 | CLS Loss: 0.053291451185941696\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 3.678500175476074 | KNN Loss: 3.634901285171509 | CLS Loss: 0.043598804622888565\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 3.689567804336548 | KNN Loss: 3.6495521068573 | CLS Loss: 0.040015809237957\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 3.643989324569702 | KNN Loss: 3.6268117427825928 | CLS Loss: 0.017177637666463852\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 3.703568458557129 | KNN Loss: 3.6802682876586914 | CLS Loss: 0.023300116881728172\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 3.678262948989868 | KNN Loss: 3.6532034873962402 | CLS Loss: 0.02505955845117569\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 3.624668836593628 | KNN Loss: 3.588731527328491 | CLS Loss: 0.035937272012233734\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 3.6440160274505615 | KNN Loss: 3.6296796798706055 | CLS Loss: 0.014336236752569675\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 3.646359443664551 | KNN Loss: 3.6191370487213135 | CLS Loss: 0.027222314849495888\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 3.632798433303833 | KNN Loss: 3.619332790374756 | CLS Loss: 0.013465688563883305\n",
      "Epoch: 043, Loss: 3.6597, Train: 0.9921, Valid: 0.9860, Best: 0.9861\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 3.6897218227386475 | KNN Loss: 3.659313678741455 | CLS Loss: 0.030408112332224846\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 3.684835910797119 | KNN Loss: 3.63352632522583 | CLS Loss: 0.05130968987941742\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 3.638749837875366 | KNN Loss: 3.5939340591430664 | CLS Loss: 0.04481580853462219\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 3.6324362754821777 | KNN Loss: 3.606595516204834 | CLS Loss: 0.025840651243925095\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 3.662998914718628 | KNN Loss: 3.6274096965789795 | CLS Loss: 0.035589154809713364\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 3.60278058052063 | KNN Loss: 3.5771427154541016 | CLS Loss: 0.02563786320388317\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 3.607994318008423 | KNN Loss: 3.5948293209075928 | CLS Loss: 0.013164911419153214\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 3.6366138458251953 | KNN Loss: 3.594782590866089 | CLS Loss: 0.041831258684396744\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 3.6559903621673584 | KNN Loss: 3.645120143890381 | CLS Loss: 0.01087016612291336\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 3.6660537719726562 | KNN Loss: 3.63110613822937 | CLS Loss: 0.034947678446769714\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 3.702406883239746 | KNN Loss: 3.662245750427246 | CLS Loss: 0.040161099284887314\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 3.658249855041504 | KNN Loss: 3.6313116550445557 | CLS Loss: 0.026938285678625107\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 3.683528423309326 | KNN Loss: 3.6519737243652344 | CLS Loss: 0.03155466541647911\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 3.731221914291382 | KNN Loss: 3.6638593673706055 | CLS Loss: 0.06736256182193756\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 3.6572117805480957 | KNN Loss: 3.638930320739746 | CLS Loss: 0.01828135922551155\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 3.624664306640625 | KNN Loss: 3.615078926086426 | CLS Loss: 0.009585305117070675\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 3.6833550930023193 | KNN Loss: 3.642448902130127 | CLS Loss: 0.04090626910328865\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 3.675635814666748 | KNN Loss: 3.630998373031616 | CLS Loss: 0.04463735595345497\n",
      "Epoch: 044, Loss: 3.6621, Train: 0.9895, Valid: 0.9843, Best: 0.9861\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 3.626323699951172 | KNN Loss: 3.605219841003418 | CLS Loss: 0.0211038701236248\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 3.634655714035034 | KNN Loss: 3.606430768966675 | CLS Loss: 0.028225015848875046\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 3.6651358604431152 | KNN Loss: 3.652981996536255 | CLS Loss: 0.012153861112892628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 3.6657557487487793 | KNN Loss: 3.6391284465789795 | CLS Loss: 0.026627320796251297\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 3.6343002319335938 | KNN Loss: 3.6166653633117676 | CLS Loss: 0.0176348015666008\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 3.6442413330078125 | KNN Loss: 3.594874382019043 | CLS Loss: 0.0493670292198658\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 3.6451804637908936 | KNN Loss: 3.6213901042938232 | CLS Loss: 0.023790359497070312\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 3.627195358276367 | KNN Loss: 3.606367349624634 | CLS Loss: 0.02082797884941101\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 3.6710758209228516 | KNN Loss: 3.619884490966797 | CLS Loss: 0.05119134858250618\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 3.6580140590667725 | KNN Loss: 3.6266937255859375 | CLS Loss: 0.03132032975554466\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 3.6403822898864746 | KNN Loss: 3.629934787750244 | CLS Loss: 0.010447550565004349\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 3.6595635414123535 | KNN Loss: 3.619135856628418 | CLS Loss: 0.04042769595980644\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 3.664097785949707 | KNN Loss: 3.646267890930176 | CLS Loss: 0.017829829826951027\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 3.67112135887146 | KNN Loss: 3.616986036300659 | CLS Loss: 0.05413533374667168\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 3.70271372795105 | KNN Loss: 3.674950361251831 | CLS Loss: 0.027763396501541138\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 3.6697611808776855 | KNN Loss: 3.6326589584350586 | CLS Loss: 0.037102267146110535\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 3.610811948776245 | KNN Loss: 3.586500883102417 | CLS Loss: 0.024311145767569542\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 3.6542811393737793 | KNN Loss: 3.6249024868011475 | CLS Loss: 0.02937871403992176\n",
      "Epoch: 045, Loss: 3.6560, Train: 0.9926, Valid: 0.9846, Best: 0.9861\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 3.649960517883301 | KNN Loss: 3.635924816131592 | CLS Loss: 0.014035721309483051\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 3.623258590698242 | KNN Loss: 3.5979888439178467 | CLS Loss: 0.02526986040174961\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 3.6424434185028076 | KNN Loss: 3.631654739379883 | CLS Loss: 0.010788569226861\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 3.726341962814331 | KNN Loss: 3.7041611671447754 | CLS Loss: 0.022180834785103798\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 3.6551613807678223 | KNN Loss: 3.633756399154663 | CLS Loss: 0.021405093371868134\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 3.632890224456787 | KNN Loss: 3.6115334033966064 | CLS Loss: 0.021356811746954918\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 3.6739819049835205 | KNN Loss: 3.6422340869903564 | CLS Loss: 0.03174780681729317\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 3.656663656234741 | KNN Loss: 3.616414785385132 | CLS Loss: 0.04024890810251236\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 3.6628031730651855 | KNN Loss: 3.63466477394104 | CLS Loss: 0.0281384140253067\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 3.6503469944000244 | KNN Loss: 3.6241064071655273 | CLS Loss: 0.026240501552820206\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 3.6073107719421387 | KNN Loss: 3.571746826171875 | CLS Loss: 0.03556392341852188\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 3.657839298248291 | KNN Loss: 3.641169309616089 | CLS Loss: 0.016669923439621925\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 3.6361844539642334 | KNN Loss: 3.6188406944274902 | CLS Loss: 0.017343876883387566\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 3.610038995742798 | KNN Loss: 3.5900726318359375 | CLS Loss: 0.019966455176472664\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 3.646158218383789 | KNN Loss: 3.63462233543396 | CLS Loss: 0.011535991914570332\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 3.6556167602539062 | KNN Loss: 3.648773670196533 | CLS Loss: 0.006843082141131163\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 3.6615257263183594 | KNN Loss: 3.6386115550994873 | CLS Loss: 0.022914286702871323\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 3.6212949752807617 | KNN Loss: 3.5989739894866943 | CLS Loss: 0.02232096530497074\n",
      "Epoch: 046, Loss: 3.6543, Train: 0.9936, Valid: 0.9863, Best: 0.9863\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 3.619204044342041 | KNN Loss: 3.59452486038208 | CLS Loss: 0.024679221212863922\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 3.6234536170959473 | KNN Loss: 3.6027371883392334 | CLS Loss: 0.020716331899166107\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 3.6705539226531982 | KNN Loss: 3.6348369121551514 | CLS Loss: 0.035716984421014786\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 3.624372720718384 | KNN Loss: 3.590066909790039 | CLS Loss: 0.034305915236473083\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 3.6050281524658203 | KNN Loss: 3.6001598834991455 | CLS Loss: 0.004868173971772194\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 3.636883497238159 | KNN Loss: 3.6283183097839355 | CLS Loss: 0.008565177209675312\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 3.602666139602661 | KNN Loss: 3.598440170288086 | CLS Loss: 0.004225965589284897\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 3.652391195297241 | KNN Loss: 3.616976022720337 | CLS Loss: 0.035415057092905045\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 3.6190574169158936 | KNN Loss: 3.5829501152038574 | CLS Loss: 0.036107294261455536\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 3.63630747795105 | KNN Loss: 3.6032958030700684 | CLS Loss: 0.033011578023433685\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 3.693105936050415 | KNN Loss: 3.6561386585235596 | CLS Loss: 0.03696732968091965\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 3.652256727218628 | KNN Loss: 3.6291720867156982 | CLS Loss: 0.02308456040918827\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 3.62819766998291 | KNN Loss: 3.583834171295166 | CLS Loss: 0.04436342045664787\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 3.6481521129608154 | KNN Loss: 3.634704113006592 | CLS Loss: 0.013447915203869343\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 3.6250054836273193 | KNN Loss: 3.605961799621582 | CLS Loss: 0.019043613225221634\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 3.6621155738830566 | KNN Loss: 3.625261068344116 | CLS Loss: 0.036854442209005356\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 3.6677231788635254 | KNN Loss: 3.641810417175293 | CLS Loss: 0.025912759825587273\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 3.653930425643921 | KNN Loss: 3.6126108169555664 | CLS Loss: 0.041319575160741806\n",
      "Epoch: 047, Loss: 3.6499, Train: 0.9936, Valid: 0.9862, Best: 0.9863\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 3.658566951751709 | KNN Loss: 3.648317337036133 | CLS Loss: 0.01024969108402729\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 3.645388126373291 | KNN Loss: 3.6304845809936523 | CLS Loss: 0.01490358728915453\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 3.667264223098755 | KNN Loss: 3.661529541015625 | CLS Loss: 0.005734694190323353\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 3.693690538406372 | KNN Loss: 3.677694797515869 | CLS Loss: 0.015995653346180916\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 3.630493640899658 | KNN Loss: 3.592771291732788 | CLS Loss: 0.037722405046224594\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 3.6684906482696533 | KNN Loss: 3.646519184112549 | CLS Loss: 0.021971458569169044\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 3.624157428741455 | KNN Loss: 3.5965116024017334 | CLS Loss: 0.027645934373140335\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 3.675021171569824 | KNN Loss: 3.657729387283325 | CLS Loss: 0.01729179359972477\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 3.640306234359741 | KNN Loss: 3.60117769241333 | CLS Loss: 0.03912863880395889\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 3.6456844806671143 | KNN Loss: 3.6286673545837402 | CLS Loss: 0.017017189413309097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 3.6719095706939697 | KNN Loss: 3.645430326461792 | CLS Loss: 0.026479190215468407\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 3.633803367614746 | KNN Loss: 3.6126937866210938 | CLS Loss: 0.021109672263264656\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 3.692962408065796 | KNN Loss: 3.637575149536133 | CLS Loss: 0.055387210100889206\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 3.662323236465454 | KNN Loss: 3.6105175018310547 | CLS Loss: 0.05180574953556061\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 3.6380743980407715 | KNN Loss: 3.612069606781006 | CLS Loss: 0.0260047297924757\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 3.662916898727417 | KNN Loss: 3.6141738891601562 | CLS Loss: 0.048742905259132385\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 3.6160552501678467 | KNN Loss: 3.600604295730591 | CLS Loss: 0.015450932085514069\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 3.647099733352661 | KNN Loss: 3.619858741760254 | CLS Loss: 0.027241095900535583\n",
      "Epoch: 048, Loss: 3.6514, Train: 0.9933, Valid: 0.9854, Best: 0.9863\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 3.63531231880188 | KNN Loss: 3.6206791400909424 | CLS Loss: 0.014633294194936752\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 3.648542881011963 | KNN Loss: 3.6256518363952637 | CLS Loss: 0.02289094403386116\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 3.634310483932495 | KNN Loss: 3.6199963092803955 | CLS Loss: 0.014314167201519012\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 3.6473798751831055 | KNN Loss: 3.6130402088165283 | CLS Loss: 0.03433957323431969\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 3.649592399597168 | KNN Loss: 3.6132354736328125 | CLS Loss: 0.03635687008500099\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 3.670469284057617 | KNN Loss: 3.62140154838562 | CLS Loss: 0.049067843705415726\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 3.678042411804199 | KNN Loss: 3.617703437805176 | CLS Loss: 0.06033888831734657\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 3.656371831893921 | KNN Loss: 3.6135451793670654 | CLS Loss: 0.042826637625694275\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 3.676333427429199 | KNN Loss: 3.6321499347686768 | CLS Loss: 0.04418354108929634\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 3.6263296604156494 | KNN Loss: 3.5965423583984375 | CLS Loss: 0.02978724054992199\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 3.634516716003418 | KNN Loss: 3.608600616455078 | CLS Loss: 0.025916092097759247\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 3.6638619899749756 | KNN Loss: 3.633251905441284 | CLS Loss: 0.030610069632530212\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 3.644629716873169 | KNN Loss: 3.6201536655426025 | CLS Loss: 0.02447601966559887\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 3.630246639251709 | KNN Loss: 3.613936185836792 | CLS Loss: 0.016310453414916992\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 3.6753334999084473 | KNN Loss: 3.6232008934020996 | CLS Loss: 0.05213257297873497\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 3.6719589233398438 | KNN Loss: 3.645538091659546 | CLS Loss: 0.026420822367072105\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 3.6706063747406006 | KNN Loss: 3.6355268955230713 | CLS Loss: 0.035079482942819595\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 3.6667964458465576 | KNN Loss: 3.6383824348449707 | CLS Loss: 0.028414109721779823\n",
      "Epoch: 049, Loss: 3.6516, Train: 0.9929, Valid: 0.9857, Best: 0.9863\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 3.654690742492676 | KNN Loss: 3.6370697021484375 | CLS Loss: 0.01762101612985134\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 3.652172565460205 | KNN Loss: 3.646306037902832 | CLS Loss: 0.005866451654583216\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 3.6426005363464355 | KNN Loss: 3.616257905960083 | CLS Loss: 0.026342539116740227\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 3.6271846294403076 | KNN Loss: 3.6132302284240723 | CLS Loss: 0.01395435631275177\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 3.6601202487945557 | KNN Loss: 3.6124188899993896 | CLS Loss: 0.04770125821232796\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 3.6289477348327637 | KNN Loss: 3.587948799133301 | CLS Loss: 0.04099905490875244\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 3.6385929584503174 | KNN Loss: 3.6037003993988037 | CLS Loss: 0.03489244729280472\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 3.6263561248779297 | KNN Loss: 3.598949909210205 | CLS Loss: 0.027406105771660805\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 3.6026058197021484 | KNN Loss: 3.583357810974121 | CLS Loss: 0.01924797333776951\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 3.660072088241577 | KNN Loss: 3.634458541870117 | CLS Loss: 0.025613464415073395\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 3.634774923324585 | KNN Loss: 3.609999895095825 | CLS Loss: 0.024774916470050812\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 3.7060348987579346 | KNN Loss: 3.681544303894043 | CLS Loss: 0.024490561336278915\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 3.6437666416168213 | KNN Loss: 3.6115331649780273 | CLS Loss: 0.03223355486989021\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 3.7102115154266357 | KNN Loss: 3.6595258712768555 | CLS Loss: 0.05068574845790863\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 3.6360785961151123 | KNN Loss: 3.623131036758423 | CLS Loss: 0.012947618030011654\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 3.699336051940918 | KNN Loss: 3.668192148208618 | CLS Loss: 0.031143859028816223\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 3.6368982791900635 | KNN Loss: 3.6023542881011963 | CLS Loss: 0.03454389050602913\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 3.647714614868164 | KNN Loss: 3.6269607543945312 | CLS Loss: 0.020753802731633186\n",
      "Epoch: 050, Loss: 3.6524, Train: 0.9926, Valid: 0.9861, Best: 0.9863\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 3.6536974906921387 | KNN Loss: 3.61970591545105 | CLS Loss: 0.03399166092276573\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 3.601454257965088 | KNN Loss: 3.585489511489868 | CLS Loss: 0.01596478745341301\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 3.6123995780944824 | KNN Loss: 3.60005784034729 | CLS Loss: 0.012341758236289024\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 3.661069393157959 | KNN Loss: 3.6310794353485107 | CLS Loss: 0.029989972710609436\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 3.669090986251831 | KNN Loss: 3.651674747467041 | CLS Loss: 0.01741613633930683\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 3.6395466327667236 | KNN Loss: 3.6093952655792236 | CLS Loss: 0.030151456594467163\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 3.646055221557617 | KNN Loss: 3.6381070613861084 | CLS Loss: 0.007948203012347221\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 3.638105630874634 | KNN Loss: 3.6095259189605713 | CLS Loss: 0.028579745441675186\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 3.6363327503204346 | KNN Loss: 3.6265952587127686 | CLS Loss: 0.009737569838762283\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 3.673466682434082 | KNN Loss: 3.6192708015441895 | CLS Loss: 0.05419577658176422\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 3.700762987136841 | KNN Loss: 3.6586251258850098 | CLS Loss: 0.04213792458176613\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 3.633179187774658 | KNN Loss: 3.5933966636657715 | CLS Loss: 0.039782606065273285\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 3.66581654548645 | KNN Loss: 3.6334104537963867 | CLS Loss: 0.032406121492385864\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 3.6937828063964844 | KNN Loss: 3.6548635959625244 | CLS Loss: 0.03891928866505623\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 3.6857974529266357 | KNN Loss: 3.6687207221984863 | CLS Loss: 0.017076708376407623\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 3.6609506607055664 | KNN Loss: 3.655909538269043 | CLS Loss: 0.005041094496846199\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 3.6457507610321045 | KNN Loss: 3.622152090072632 | CLS Loss: 0.023598724976181984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 3.66347599029541 | KNN Loss: 3.6424946784973145 | CLS Loss: 0.020981252193450928\n",
      "Epoch: 051, Loss: 3.6474, Train: 0.9923, Valid: 0.9843, Best: 0.9863\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 3.658198595046997 | KNN Loss: 3.6435351371765137 | CLS Loss: 0.014663368463516235\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 3.694763422012329 | KNN Loss: 3.6649184226989746 | CLS Loss: 0.02984493039548397\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 3.665208101272583 | KNN Loss: 3.6309077739715576 | CLS Loss: 0.034300416707992554\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 3.6332333087921143 | KNN Loss: 3.611560344696045 | CLS Loss: 0.02167295292019844\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 3.6391637325286865 | KNN Loss: 3.6167502403259277 | CLS Loss: 0.022413594648241997\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 3.6723878383636475 | KNN Loss: 3.6497390270233154 | CLS Loss: 0.0226488895714283\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 3.6806933879852295 | KNN Loss: 3.6575393676757812 | CLS Loss: 0.023153945803642273\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 3.6730546951293945 | KNN Loss: 3.6535730361938477 | CLS Loss: 0.019481666386127472\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 3.648345708847046 | KNN Loss: 3.6357638835906982 | CLS Loss: 0.012581929564476013\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 3.628488779067993 | KNN Loss: 3.6118271350860596 | CLS Loss: 0.01666172407567501\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 3.6211745738983154 | KNN Loss: 3.6014106273651123 | CLS Loss: 0.019763927906751633\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 3.6301109790802 | KNN Loss: 3.6198415756225586 | CLS Loss: 0.010269482620060444\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 3.64613938331604 | KNN Loss: 3.59989595413208 | CLS Loss: 0.046243488788604736\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 3.6550586223602295 | KNN Loss: 3.644011974334717 | CLS Loss: 0.011046583764255047\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 3.6705825328826904 | KNN Loss: 3.6442179679870605 | CLS Loss: 0.02636464312672615\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 3.642444133758545 | KNN Loss: 3.6324498653411865 | CLS Loss: 0.009994209744036198\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 3.6873912811279297 | KNN Loss: 3.648949146270752 | CLS Loss: 0.038442231714725494\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 3.651581048965454 | KNN Loss: 3.6105031967163086 | CLS Loss: 0.041077930480241776\n",
      "Epoch: 052, Loss: 3.6494, Train: 0.9927, Valid: 0.9839, Best: 0.9863\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 3.6539528369903564 | KNN Loss: 3.63696026802063 | CLS Loss: 0.016992652788758278\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 3.6709132194519043 | KNN Loss: 3.617180824279785 | CLS Loss: 0.05373246967792511\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 3.651334762573242 | KNN Loss: 3.639091730117798 | CLS Loss: 0.01224308367818594\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 3.6142959594726562 | KNN Loss: 3.6116883754730225 | CLS Loss: 0.0026074908673763275\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 3.62646484375 | KNN Loss: 3.6020774841308594 | CLS Loss: 0.02438727207481861\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 3.6158783435821533 | KNN Loss: 3.5795788764953613 | CLS Loss: 0.036299560219049454\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 3.661780595779419 | KNN Loss: 3.6032779216766357 | CLS Loss: 0.05850275978446007\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 3.6682581901550293 | KNN Loss: 3.617172956466675 | CLS Loss: 0.051085215061903\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 3.650965929031372 | KNN Loss: 3.6198949813842773 | CLS Loss: 0.03107098489999771\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 3.721592903137207 | KNN Loss: 3.6874473094940186 | CLS Loss: 0.0341455414891243\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 3.693429946899414 | KNN Loss: 3.6668779850006104 | CLS Loss: 0.026551924645900726\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 3.651777982711792 | KNN Loss: 3.6262400150299072 | CLS Loss: 0.025537986308336258\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 3.598869800567627 | KNN Loss: 3.577333688735962 | CLS Loss: 0.02153608947992325\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 3.6200270652770996 | KNN Loss: 3.609874963760376 | CLS Loss: 0.010152160190045834\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 3.660038948059082 | KNN Loss: 3.617948293685913 | CLS Loss: 0.042090628296136856\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 3.650075912475586 | KNN Loss: 3.6184749603271484 | CLS Loss: 0.03160100057721138\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 3.642974853515625 | KNN Loss: 3.599461078643799 | CLS Loss: 0.043513666838407516\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 3.671365261077881 | KNN Loss: 3.64414119720459 | CLS Loss: 0.027223967015743256\n",
      "Epoch: 053, Loss: 3.6477, Train: 0.9935, Valid: 0.9849, Best: 0.9863\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 3.6216447353363037 | KNN Loss: 3.613906145095825 | CLS Loss: 0.0077385064214468\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 3.6247849464416504 | KNN Loss: 3.6148078441619873 | CLS Loss: 0.009977111592888832\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 3.6348648071289062 | KNN Loss: 3.6172068119049072 | CLS Loss: 0.017657916992902756\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 3.697786331176758 | KNN Loss: 3.6335110664367676 | CLS Loss: 0.06427530199289322\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 3.6319847106933594 | KNN Loss: 3.6093297004699707 | CLS Loss: 0.022655092179775238\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 3.670102596282959 | KNN Loss: 3.653470754623413 | CLS Loss: 0.016631919890642166\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 3.63688325881958 | KNN Loss: 3.6142385005950928 | CLS Loss: 0.02264484390616417\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 3.622861385345459 | KNN Loss: 3.612959146499634 | CLS Loss: 0.009902243502438068\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 3.658562660217285 | KNN Loss: 3.614118814468384 | CLS Loss: 0.04444396495819092\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 3.646573543548584 | KNN Loss: 3.6197190284729004 | CLS Loss: 0.02685457095503807\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 3.6327965259552 | KNN Loss: 3.600426435470581 | CLS Loss: 0.03237014636397362\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 3.651254653930664 | KNN Loss: 3.630995035171509 | CLS Loss: 0.020259620621800423\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 3.665476083755493 | KNN Loss: 3.6331520080566406 | CLS Loss: 0.03232405707240105\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 3.6420488357543945 | KNN Loss: 3.6224913597106934 | CLS Loss: 0.01955757848918438\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 3.678614377975464 | KNN Loss: 3.6561758518218994 | CLS Loss: 0.022438444197177887\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 3.6246285438537598 | KNN Loss: 3.6031551361083984 | CLS Loss: 0.021473431959748268\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 3.638179302215576 | KNN Loss: 3.6079883575439453 | CLS Loss: 0.03019103594124317\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 3.6390528678894043 | KNN Loss: 3.573403835296631 | CLS Loss: 0.0656491294503212\n",
      "Epoch: 054, Loss: 3.6413, Train: 0.9944, Valid: 0.9862, Best: 0.9863\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 3.6249382495880127 | KNN Loss: 3.600572347640991 | CLS Loss: 0.024365989491343498\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 3.6203885078430176 | KNN Loss: 3.607149362564087 | CLS Loss: 0.013239086605608463\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 3.5982699394226074 | KNN Loss: 3.5887537002563477 | CLS Loss: 0.009516222402453423\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 3.66752552986145 | KNN Loss: 3.6589508056640625 | CLS Loss: 0.008574805222451687\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 3.6212077140808105 | KNN Loss: 3.6082921028137207 | CLS Loss: 0.012915519066154957\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 3.6267201900482178 | KNN Loss: 3.6040751934051514 | CLS Loss: 0.0226448867470026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 3.611485719680786 | KNN Loss: 3.6060333251953125 | CLS Loss: 0.005452336277812719\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 3.6485650539398193 | KNN Loss: 3.624685764312744 | CLS Loss: 0.023879220709204674\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 3.6490020751953125 | KNN Loss: 3.63244891166687 | CLS Loss: 0.016553224995732307\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 3.6282870769500732 | KNN Loss: 3.611921548843384 | CLS Loss: 0.016365550458431244\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 3.619569778442383 | KNN Loss: 3.6002280712127686 | CLS Loss: 0.01934160105884075\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 3.643597364425659 | KNN Loss: 3.6222341060638428 | CLS Loss: 0.021363308653235435\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 3.649646043777466 | KNN Loss: 3.6280531883239746 | CLS Loss: 0.021592896431684494\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 3.669174909591675 | KNN Loss: 3.6433041095733643 | CLS Loss: 0.025870783254504204\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 3.6129727363586426 | KNN Loss: 3.5843663215637207 | CLS Loss: 0.028606334701180458\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 3.676323890686035 | KNN Loss: 3.669240951538086 | CLS Loss: 0.007082899566739798\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 3.6548662185668945 | KNN Loss: 3.628302812576294 | CLS Loss: 0.026563342660665512\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 3.6224827766418457 | KNN Loss: 3.6085593700408936 | CLS Loss: 0.013923417776823044\n",
      "Epoch: 055, Loss: 3.6448, Train: 0.9913, Valid: 0.9846, Best: 0.9863\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 3.6507909297943115 | KNN Loss: 3.600978374481201 | CLS Loss: 0.04981251433491707\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 3.6971981525421143 | KNN Loss: 3.6595206260681152 | CLS Loss: 0.037677451968193054\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 3.616926431655884 | KNN Loss: 3.606492280960083 | CLS Loss: 0.010434246622025967\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 3.6358914375305176 | KNN Loss: 3.628856658935547 | CLS Loss: 0.007034703157842159\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 3.651442289352417 | KNN Loss: 3.6364846229553223 | CLS Loss: 0.014957612380385399\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 3.6494369506835938 | KNN Loss: 3.601736307144165 | CLS Loss: 0.047700755298137665\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 3.6455724239349365 | KNN Loss: 3.629032611846924 | CLS Loss: 0.0165399219840765\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 3.618908166885376 | KNN Loss: 3.6067159175872803 | CLS Loss: 0.012192188762128353\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 3.666471481323242 | KNN Loss: 3.647061586380005 | CLS Loss: 0.019409913569688797\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 3.621151924133301 | KNN Loss: 3.5945260524749756 | CLS Loss: 0.02662595734000206\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 3.6428961753845215 | KNN Loss: 3.6283302307128906 | CLS Loss: 0.014565831050276756\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 3.666957378387451 | KNN Loss: 3.611234664916992 | CLS Loss: 0.055722832679748535\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 3.616075277328491 | KNN Loss: 3.5895256996154785 | CLS Loss: 0.026549695059657097\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 3.686387062072754 | KNN Loss: 3.681378126144409 | CLS Loss: 0.005008841399103403\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 3.63576078414917 | KNN Loss: 3.6164908409118652 | CLS Loss: 0.019269945099949837\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 3.609874725341797 | KNN Loss: 3.600736618041992 | CLS Loss: 0.009138007648289204\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 3.638880729675293 | KNN Loss: 3.6274476051330566 | CLS Loss: 0.01143302209675312\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 3.5933172702789307 | KNN Loss: 3.575460433959961 | CLS Loss: 0.017856737598776817\n",
      "Epoch: 056, Loss: 3.6470, Train: 0.9945, Valid: 0.9865, Best: 0.9865\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 3.596235513687134 | KNN Loss: 3.574223279953003 | CLS Loss: 0.022012153640389442\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 3.646604061126709 | KNN Loss: 3.628032922744751 | CLS Loss: 0.018571214750409126\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 3.672516107559204 | KNN Loss: 3.650682210922241 | CLS Loss: 0.021834013983607292\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 3.6056289672851562 | KNN Loss: 3.5841987133026123 | CLS Loss: 0.02143031731247902\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 3.643049955368042 | KNN Loss: 3.619325876235962 | CLS Loss: 0.023724045604467392\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 3.6217458248138428 | KNN Loss: 3.591113805770874 | CLS Loss: 0.030632024630904198\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 3.630455255508423 | KNN Loss: 3.615323781967163 | CLS Loss: 0.015131457708775997\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 3.6382243633270264 | KNN Loss: 3.62056303024292 | CLS Loss: 0.017661256715655327\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 3.6374590396881104 | KNN Loss: 3.6106128692626953 | CLS Loss: 0.026846151798963547\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 3.62123966217041 | KNN Loss: 3.603534460067749 | CLS Loss: 0.017705174162983894\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 3.6058151721954346 | KNN Loss: 3.6006083488464355 | CLS Loss: 0.005206786561757326\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 3.6696114540100098 | KNN Loss: 3.642470121383667 | CLS Loss: 0.027141215279698372\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 3.6211373805999756 | KNN Loss: 3.6019704341888428 | CLS Loss: 0.019166849553585052\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 3.6434199810028076 | KNN Loss: 3.618882179260254 | CLS Loss: 0.024537788704037666\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 3.627645492553711 | KNN Loss: 3.613492012023926 | CLS Loss: 0.014153454452753067\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 3.7267062664031982 | KNN Loss: 3.6988043785095215 | CLS Loss: 0.02790193259716034\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 3.614501476287842 | KNN Loss: 3.5957438945770264 | CLS Loss: 0.018757669255137444\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 3.6711995601654053 | KNN Loss: 3.6275641918182373 | CLS Loss: 0.04363538697361946\n",
      "Epoch: 057, Loss: 3.6400, Train: 0.9947, Valid: 0.9855, Best: 0.9865\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 3.6725058555603027 | KNN Loss: 3.648238182067871 | CLS Loss: 0.024267738685011864\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 3.606137752532959 | KNN Loss: 3.584460973739624 | CLS Loss: 0.02167680859565735\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 3.628147840499878 | KNN Loss: 3.598829984664917 | CLS Loss: 0.02931777760386467\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 3.610682964324951 | KNN Loss: 3.5858187675476074 | CLS Loss: 0.02486422471702099\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 3.664030075073242 | KNN Loss: 3.642937660217285 | CLS Loss: 0.021092316135764122\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 3.64816951751709 | KNN Loss: 3.614187479019165 | CLS Loss: 0.03398192301392555\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 3.681297540664673 | KNN Loss: 3.658353805541992 | CLS Loss: 0.022943660616874695\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 3.6332125663757324 | KNN Loss: 3.612682342529297 | CLS Loss: 0.020530158653855324\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 3.6366188526153564 | KNN Loss: 3.6097970008850098 | CLS Loss: 0.026821888983249664\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 3.6287074089050293 | KNN Loss: 3.6061851978302 | CLS Loss: 0.022522151470184326\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 3.642803192138672 | KNN Loss: 3.6081714630126953 | CLS Loss: 0.03463183715939522\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 3.6321051120758057 | KNN Loss: 3.6163177490234375 | CLS Loss: 0.015787413343787193\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 3.61905574798584 | KNN Loss: 3.5999889373779297 | CLS Loss: 0.019066911190748215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 3.707387685775757 | KNN Loss: 3.6706461906433105 | CLS Loss: 0.036741551011800766\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 3.6527771949768066 | KNN Loss: 3.588421106338501 | CLS Loss: 0.06435597687959671\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 3.6639392375946045 | KNN Loss: 3.637831211090088 | CLS Loss: 0.02610807865858078\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 3.6500024795532227 | KNN Loss: 3.6244359016418457 | CLS Loss: 0.025566695258021355\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 3.672175168991089 | KNN Loss: 3.649306535720825 | CLS Loss: 0.02286870777606964\n",
      "Epoch: 058, Loss: 3.6435, Train: 0.9943, Valid: 0.9857, Best: 0.9865\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 3.6151020526885986 | KNN Loss: 3.5994064807891846 | CLS Loss: 0.015695666894316673\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 3.668445587158203 | KNN Loss: 3.6377317905426025 | CLS Loss: 0.030713798478245735\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 3.624131441116333 | KNN Loss: 3.6127474308013916 | CLS Loss: 0.01138409785926342\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 3.706712007522583 | KNN Loss: 3.6421616077423096 | CLS Loss: 0.0645504891872406\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 3.6535887718200684 | KNN Loss: 3.6218903064727783 | CLS Loss: 0.03169846534729004\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 3.668903350830078 | KNN Loss: 3.6385669708251953 | CLS Loss: 0.0303362850099802\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 3.6215407848358154 | KNN Loss: 3.5989229679107666 | CLS Loss: 0.02261793427169323\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 3.6382999420166016 | KNN Loss: 3.6241109371185303 | CLS Loss: 0.014189047738909721\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 3.627847671508789 | KNN Loss: 3.6174139976501465 | CLS Loss: 0.010433688759803772\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 3.6241519451141357 | KNN Loss: 3.5983190536499023 | CLS Loss: 0.025832828134298325\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 3.6337783336639404 | KNN Loss: 3.5821127891540527 | CLS Loss: 0.051665522158145905\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 3.641852378845215 | KNN Loss: 3.6383378505706787 | CLS Loss: 0.0035144200082868338\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 3.620199203491211 | KNN Loss: 3.597851276397705 | CLS Loss: 0.022347841411828995\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 3.6792659759521484 | KNN Loss: 3.659665584564209 | CLS Loss: 0.01960049197077751\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 3.6282641887664795 | KNN Loss: 3.617999315261841 | CLS Loss: 0.010264848358929157\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 3.6342360973358154 | KNN Loss: 3.6152679920196533 | CLS Loss: 0.01896819658577442\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 3.651123523712158 | KNN Loss: 3.5991129875183105 | CLS Loss: 0.05201045796275139\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 3.6259958744049072 | KNN Loss: 3.610619068145752 | CLS Loss: 0.01537687610834837\n",
      "Epoch: 059, Loss: 3.6468, Train: 0.9950, Valid: 0.9860, Best: 0.9865\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 3.607621669769287 | KNN Loss: 3.59419846534729 | CLS Loss: 0.013423210941255093\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 3.6140801906585693 | KNN Loss: 3.608368158340454 | CLS Loss: 0.005712037906050682\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 3.6718969345092773 | KNN Loss: 3.637307643890381 | CLS Loss: 0.03458939120173454\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 3.632199764251709 | KNN Loss: 3.6174449920654297 | CLS Loss: 0.014754789881408215\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 3.6334164142608643 | KNN Loss: 3.6028385162353516 | CLS Loss: 0.03057786636054516\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 3.599050760269165 | KNN Loss: 3.595578908920288 | CLS Loss: 0.003471776144579053\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 3.613447904586792 | KNN Loss: 3.604341506958008 | CLS Loss: 0.009106297045946121\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 3.6711325645446777 | KNN Loss: 3.6438846588134766 | CLS Loss: 0.02724784053862095\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 3.712707757949829 | KNN Loss: 3.6938533782958984 | CLS Loss: 0.018854284659028053\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 3.6486244201660156 | KNN Loss: 3.629962682723999 | CLS Loss: 0.018661733716726303\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 3.6307835578918457 | KNN Loss: 3.6007089614868164 | CLS Loss: 0.030074622482061386\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 3.6482889652252197 | KNN Loss: 3.6382744312286377 | CLS Loss: 0.01001456193625927\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 3.6400086879730225 | KNN Loss: 3.6178057193756104 | CLS Loss: 0.02220304310321808\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 3.5905818939208984 | KNN Loss: 3.5851566791534424 | CLS Loss: 0.005425218492746353\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 3.642526388168335 | KNN Loss: 3.629521369934082 | CLS Loss: 0.013004996813833714\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 3.6792092323303223 | KNN Loss: 3.658200263977051 | CLS Loss: 0.02100892923772335\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 3.651326894760132 | KNN Loss: 3.6335666179656982 | CLS Loss: 0.01776035875082016\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 3.6163432598114014 | KNN Loss: 3.5987730026245117 | CLS Loss: 0.017570368945598602\n",
      "Epoch: 060, Loss: 3.6444, Train: 0.9943, Valid: 0.9862, Best: 0.9865\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 3.650383710861206 | KNN Loss: 3.617368698120117 | CLS Loss: 0.03301500156521797\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 3.5949549674987793 | KNN Loss: 3.5903358459472656 | CLS Loss: 0.004619130399078131\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 3.5914103984832764 | KNN Loss: 3.5853819847106934 | CLS Loss: 0.006028361152857542\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 3.6155316829681396 | KNN Loss: 3.6029911041259766 | CLS Loss: 0.012540633790194988\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 3.6259374618530273 | KNN Loss: 3.598507881164551 | CLS Loss: 0.027429483830928802\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 3.6509275436401367 | KNN Loss: 3.6217172145843506 | CLS Loss: 0.029210397973656654\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 3.5848631858825684 | KNN Loss: 3.5707454681396484 | CLS Loss: 0.014117686077952385\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 3.5901918411254883 | KNN Loss: 3.584233283996582 | CLS Loss: 0.0059585850685834885\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 3.6461470127105713 | KNN Loss: 3.6162359714508057 | CLS Loss: 0.029911044985055923\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 3.618520498275757 | KNN Loss: 3.6156418323516846 | CLS Loss: 0.0028786242473870516\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 3.6876819133758545 | KNN Loss: 3.630972146987915 | CLS Loss: 0.05670969933271408\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 3.652787208557129 | KNN Loss: 3.613877058029175 | CLS Loss: 0.03891022130846977\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 3.6507182121276855 | KNN Loss: 3.6107280254364014 | CLS Loss: 0.03999027609825134\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 3.6378655433654785 | KNN Loss: 3.6247825622558594 | CLS Loss: 0.013083077035844326\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 3.687528133392334 | KNN Loss: 3.6629884243011475 | CLS Loss: 0.024539636448025703\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 3.6148812770843506 | KNN Loss: 3.5992090702056885 | CLS Loss: 0.015672091394662857\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 3.630143880844116 | KNN Loss: 3.615863800048828 | CLS Loss: 0.014280060306191444\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 3.6683762073516846 | KNN Loss: 3.6380412578582764 | CLS Loss: 0.030334988608956337\n",
      "Epoch: 061, Loss: 3.6403, Train: 0.9937, Valid: 0.9852, Best: 0.9865\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 3.6640963554382324 | KNN Loss: 3.6405441761016846 | CLS Loss: 0.023552218452095985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 3.624119281768799 | KNN Loss: 3.6121408939361572 | CLS Loss: 0.011978409253060818\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 3.6425552368164062 | KNN Loss: 3.611420154571533 | CLS Loss: 0.031134996563196182\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 3.6632542610168457 | KNN Loss: 3.644176721572876 | CLS Loss: 0.019077586010098457\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 3.673609972000122 | KNN Loss: 3.6403732299804688 | CLS Loss: 0.03323666751384735\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 3.6287682056427 | KNN Loss: 3.606776475906372 | CLS Loss: 0.021991783753037453\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 3.658700704574585 | KNN Loss: 3.631220817565918 | CLS Loss: 0.02747991681098938\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 3.635669231414795 | KNN Loss: 3.6194655895233154 | CLS Loss: 0.016203636303544044\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 3.6306393146514893 | KNN Loss: 3.6098008155822754 | CLS Loss: 0.020838607102632523\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 3.6318535804748535 | KNN Loss: 3.616699695587158 | CLS Loss: 0.01515378151088953\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 3.6719272136688232 | KNN Loss: 3.644477367401123 | CLS Loss: 0.02744974195957184\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 3.703061819076538 | KNN Loss: 3.672539710998535 | CLS Loss: 0.03052213415503502\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 3.5972487926483154 | KNN Loss: 3.5901501178741455 | CLS Loss: 0.0070986137725412846\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 3.6464505195617676 | KNN Loss: 3.6246728897094727 | CLS Loss: 0.02177755907177925\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 3.6791348457336426 | KNN Loss: 3.663527250289917 | CLS Loss: 0.01560754980891943\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 3.6738858222961426 | KNN Loss: 3.625638484954834 | CLS Loss: 0.04824736341834068\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 3.6395933628082275 | KNN Loss: 3.62028169631958 | CLS Loss: 0.01931172050535679\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 3.6772944927215576 | KNN Loss: 3.6562085151672363 | CLS Loss: 0.021086055785417557\n",
      "Epoch: 062, Loss: 3.6444, Train: 0.9935, Valid: 0.9863, Best: 0.9865\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 3.6348233222961426 | KNN Loss: 3.6221182346343994 | CLS Loss: 0.012705206871032715\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 3.6303398609161377 | KNN Loss: 3.6257755756378174 | CLS Loss: 0.0045642852783203125\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 3.6883535385131836 | KNN Loss: 3.6505050659179688 | CLS Loss: 0.037848539650440216\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 3.6509196758270264 | KNN Loss: 3.6403133869171143 | CLS Loss: 0.010606177151203156\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 3.656342029571533 | KNN Loss: 3.6449685096740723 | CLS Loss: 0.01137363351881504\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 3.626901149749756 | KNN Loss: 3.5977659225463867 | CLS Loss: 0.029135113582015038\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 3.6709723472595215 | KNN Loss: 3.635324478149414 | CLS Loss: 0.035647910088300705\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 3.692882537841797 | KNN Loss: 3.647494316101074 | CLS Loss: 0.04538826271891594\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 3.6429197788238525 | KNN Loss: 3.6209869384765625 | CLS Loss: 0.021932849660515785\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 3.657365083694458 | KNN Loss: 3.6249938011169434 | CLS Loss: 0.032371193170547485\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 3.6842918395996094 | KNN Loss: 3.6755950450897217 | CLS Loss: 0.008696796372532845\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 3.635072708129883 | KNN Loss: 3.609058380126953 | CLS Loss: 0.026014287024736404\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 3.6387922763824463 | KNN Loss: 3.622185468673706 | CLS Loss: 0.016606759279966354\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 3.6164159774780273 | KNN Loss: 3.609252452850342 | CLS Loss: 0.007163600064814091\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 3.649590253829956 | KNN Loss: 3.62138295173645 | CLS Loss: 0.028207192197442055\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 3.6394691467285156 | KNN Loss: 3.608267307281494 | CLS Loss: 0.03120192512869835\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 3.615222692489624 | KNN Loss: 3.574090003967285 | CLS Loss: 0.04113279655575752\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 3.615748167037964 | KNN Loss: 3.6066629886627197 | CLS Loss: 0.009085296653211117\n",
      "Epoch: 063, Loss: 3.6431, Train: 0.9952, Valid: 0.9863, Best: 0.9865\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 3.6071810722351074 | KNN Loss: 3.578667163848877 | CLS Loss: 0.028513936325907707\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 3.6065542697906494 | KNN Loss: 3.5961544513702393 | CLS Loss: 0.010399864055216312\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 3.632338047027588 | KNN Loss: 3.6157491207122803 | CLS Loss: 0.01658886857330799\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 3.62363600730896 | KNN Loss: 3.584306478500366 | CLS Loss: 0.03932955116033554\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 3.67000412940979 | KNN Loss: 3.6217124462127686 | CLS Loss: 0.0482916422188282\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 3.651705265045166 | KNN Loss: 3.626884937286377 | CLS Loss: 0.0248203556984663\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 3.6280252933502197 | KNN Loss: 3.608301877975464 | CLS Loss: 0.01972331292927265\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 3.616612672805786 | KNN Loss: 3.584970235824585 | CLS Loss: 0.031642403453588486\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 3.6268086433410645 | KNN Loss: 3.6067168712615967 | CLS Loss: 0.02009171061217785\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 3.6377785205841064 | KNN Loss: 3.626746654510498 | CLS Loss: 0.011031762696802616\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 3.637460231781006 | KNN Loss: 3.621156692504883 | CLS Loss: 0.016303520649671555\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 3.6268017292022705 | KNN Loss: 3.6242151260375977 | CLS Loss: 0.0025865589268505573\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 3.633899688720703 | KNN Loss: 3.611215353012085 | CLS Loss: 0.022684380412101746\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 3.61503005027771 | KNN Loss: 3.598907232284546 | CLS Loss: 0.016122912988066673\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 3.6140403747558594 | KNN Loss: 3.5867910385131836 | CLS Loss: 0.027249427512288094\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 3.6082656383514404 | KNN Loss: 3.580451250076294 | CLS Loss: 0.027814462780952454\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 3.6192758083343506 | KNN Loss: 3.610490560531616 | CLS Loss: 0.008785324171185493\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 3.649498462677002 | KNN Loss: 3.630110502243042 | CLS Loss: 0.01938807964324951\n",
      "Epoch: 064, Loss: 3.6380, Train: 0.9951, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 3.66353702545166 | KNN Loss: 3.647789239883423 | CLS Loss: 0.01574782468378544\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 3.614180564880371 | KNN Loss: 3.6051230430603027 | CLS Loss: 0.009057474322617054\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 3.6349074840545654 | KNN Loss: 3.6270079612731934 | CLS Loss: 0.00789959542453289\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 3.664383888244629 | KNN Loss: 3.6437556743621826 | CLS Loss: 0.020628107711672783\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 3.6379032135009766 | KNN Loss: 3.61795711517334 | CLS Loss: 0.01994604803621769\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 3.660444974899292 | KNN Loss: 3.646960735321045 | CLS Loss: 0.013484283350408077\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 3.6308369636535645 | KNN Loss: 3.6198763847351074 | CLS Loss: 0.010960467159748077\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 3.6133804321289062 | KNN Loss: 3.608691692352295 | CLS Loss: 0.004688769578933716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 3.6313467025756836 | KNN Loss: 3.5977885723114014 | CLS Loss: 0.03355815261602402\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 3.6197214126586914 | KNN Loss: 3.611952781677246 | CLS Loss: 0.007768668700009584\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 3.6323742866516113 | KNN Loss: 3.6215708255767822 | CLS Loss: 0.010803543031215668\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 3.6546242237091064 | KNN Loss: 3.6324174404144287 | CLS Loss: 0.02220667526125908\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 3.61924147605896 | KNN Loss: 3.607754945755005 | CLS Loss: 0.011486422270536423\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 3.620983362197876 | KNN Loss: 3.6117069721221924 | CLS Loss: 0.009276455268263817\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 3.6439037322998047 | KNN Loss: 3.6124794483184814 | CLS Loss: 0.031424324959516525\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 3.6806492805480957 | KNN Loss: 3.6487863063812256 | CLS Loss: 0.0318630114197731\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 3.633897304534912 | KNN Loss: 3.620736837387085 | CLS Loss: 0.013160500675439835\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 3.6388208866119385 | KNN Loss: 3.6102166175842285 | CLS Loss: 0.028604287654161453\n",
      "Epoch: 065, Loss: 3.6387, Train: 0.9943, Valid: 0.9861, Best: 0.9867\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 3.641820192337036 | KNN Loss: 3.6303818225860596 | CLS Loss: 0.011438433080911636\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 3.598167657852173 | KNN Loss: 3.588320255279541 | CLS Loss: 0.00984729453921318\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 3.6336517333984375 | KNN Loss: 3.6061010360717773 | CLS Loss: 0.027550630271434784\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 3.667819023132324 | KNN Loss: 3.654433012008667 | CLS Loss: 0.013385927304625511\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 3.637563943862915 | KNN Loss: 3.611961841583252 | CLS Loss: 0.02560207061469555\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 3.673537015914917 | KNN Loss: 3.6698176860809326 | CLS Loss: 0.003719236934557557\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 3.66514253616333 | KNN Loss: 3.6434311866760254 | CLS Loss: 0.021711252629756927\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 3.6349551677703857 | KNN Loss: 3.591381072998047 | CLS Loss: 0.043574001640081406\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 3.6157519817352295 | KNN Loss: 3.595944881439209 | CLS Loss: 0.01980707049369812\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 3.6264114379882812 | KNN Loss: 3.603360176086426 | CLS Loss: 0.023051192983984947\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 3.597201347351074 | KNN Loss: 3.5897653102874756 | CLS Loss: 0.007435986772179604\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 3.609710931777954 | KNN Loss: 3.578787326812744 | CLS Loss: 0.030923686921596527\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 3.6206302642822266 | KNN Loss: 3.598259925842285 | CLS Loss: 0.022370390594005585\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 3.665297031402588 | KNN Loss: 3.651987314224243 | CLS Loss: 0.013309633359313011\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 3.6609435081481934 | KNN Loss: 3.6261348724365234 | CLS Loss: 0.034808605909347534\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 3.6721251010894775 | KNN Loss: 3.6575615406036377 | CLS Loss: 0.014563510194420815\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 3.639610528945923 | KNN Loss: 3.629664897918701 | CLS Loss: 0.009945587255060673\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 3.6740825176239014 | KNN Loss: 3.6218655109405518 | CLS Loss: 0.05221700295805931\n",
      "Epoch: 066, Loss: 3.6400, Train: 0.9932, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 3.6304121017456055 | KNN Loss: 3.6032443046569824 | CLS Loss: 0.027167916297912598\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 3.640984535217285 | KNN Loss: 3.6332027912139893 | CLS Loss: 0.007781751453876495\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 3.608534336090088 | KNN Loss: 3.59700870513916 | CLS Loss: 0.01152565237134695\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 3.636630058288574 | KNN Loss: 3.6106295585632324 | CLS Loss: 0.026000453159213066\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 3.656886577606201 | KNN Loss: 3.6470534801483154 | CLS Loss: 0.00983313750475645\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 3.6160686016082764 | KNN Loss: 3.6075351238250732 | CLS Loss: 0.00853339396417141\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 3.6523821353912354 | KNN Loss: 3.643113136291504 | CLS Loss: 0.009269006550312042\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 3.6560699939727783 | KNN Loss: 3.6199309825897217 | CLS Loss: 0.03613893687725067\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 3.618720531463623 | KNN Loss: 3.601123809814453 | CLS Loss: 0.017596831545233727\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 3.662307024002075 | KNN Loss: 3.6306591033935547 | CLS Loss: 0.031647972762584686\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 3.6095635890960693 | KNN Loss: 3.5951223373413086 | CLS Loss: 0.014441294595599174\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 3.6299514770507812 | KNN Loss: 3.6124298572540283 | CLS Loss: 0.017521720379590988\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 3.6710312366485596 | KNN Loss: 3.626267194747925 | CLS Loss: 0.04476410523056984\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 3.6059515476226807 | KNN Loss: 3.584901809692383 | CLS Loss: 0.02104971557855606\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 3.6282529830932617 | KNN Loss: 3.604339599609375 | CLS Loss: 0.023913471028208733\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 3.6410889625549316 | KNN Loss: 3.6027088165283203 | CLS Loss: 0.03838024660944939\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 3.6572721004486084 | KNN Loss: 3.6342825889587402 | CLS Loss: 0.02298961766064167\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 3.7398617267608643 | KNN Loss: 3.6868038177490234 | CLS Loss: 0.05305797979235649\n",
      "Epoch: 067, Loss: 3.6390, Train: 0.9940, Valid: 0.9841, Best: 0.9867\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 3.6580612659454346 | KNN Loss: 3.6263203620910645 | CLS Loss: 0.031740881502628326\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 3.6417245864868164 | KNN Loss: 3.630542755126953 | CLS Loss: 0.011181937530636787\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 3.6273117065429688 | KNN Loss: 3.621967077255249 | CLS Loss: 0.005344529636204243\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 3.655198097229004 | KNN Loss: 3.633969306945801 | CLS Loss: 0.02122873067855835\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 3.6542351245880127 | KNN Loss: 3.6302478313446045 | CLS Loss: 0.023987365886569023\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 3.659698724746704 | KNN Loss: 3.6367642879486084 | CLS Loss: 0.022934360429644585\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 3.70751690864563 | KNN Loss: 3.688746213912964 | CLS Loss: 0.018770603463053703\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 3.6411588191986084 | KNN Loss: 3.6201446056365967 | CLS Loss: 0.021014252677559853\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 3.67954421043396 | KNN Loss: 3.662996292114258 | CLS Loss: 0.016547981649637222\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 3.6422042846679688 | KNN Loss: 3.6242897510528564 | CLS Loss: 0.01791461743414402\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 3.6346240043640137 | KNN Loss: 3.6057960987091064 | CLS Loss: 0.02882780320942402\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 3.6211891174316406 | KNN Loss: 3.6075453758239746 | CLS Loss: 0.01364370621740818\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 3.6305301189422607 | KNN Loss: 3.621488094329834 | CLS Loss: 0.009042060934007168\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 3.629314661026001 | KNN Loss: 3.6249616146087646 | CLS Loss: 0.004353078547865152\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 3.624091148376465 | KNN Loss: 3.5884957313537598 | CLS Loss: 0.035595327615737915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 3.660557508468628 | KNN Loss: 3.632819652557373 | CLS Loss: 0.027737827971577644\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 3.619223117828369 | KNN Loss: 3.608908176422119 | CLS Loss: 0.01031486876308918\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 3.6122071743011475 | KNN Loss: 3.5982677936553955 | CLS Loss: 0.013939343392848969\n",
      "Epoch: 068, Loss: 3.6413, Train: 0.9947, Valid: 0.9851, Best: 0.9867\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 3.6390368938446045 | KNN Loss: 3.6132309436798096 | CLS Loss: 0.025805959478020668\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 3.6611318588256836 | KNN Loss: 3.648470163345337 | CLS Loss: 0.012661672197282314\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 3.6345252990722656 | KNN Loss: 3.6111583709716797 | CLS Loss: 0.023366957902908325\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 3.6910717487335205 | KNN Loss: 3.6603481769561768 | CLS Loss: 0.030723586678504944\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 3.635634183883667 | KNN Loss: 3.6196415424346924 | CLS Loss: 0.01599261164665222\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 3.601121187210083 | KNN Loss: 3.589183807373047 | CLS Loss: 0.011937476694583893\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 3.6981637477874756 | KNN Loss: 3.68158221244812 | CLS Loss: 0.016581568866968155\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 3.5897722244262695 | KNN Loss: 3.5842716693878174 | CLS Loss: 0.005500617437064648\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 3.638076066970825 | KNN Loss: 3.613933563232422 | CLS Loss: 0.024142401292920113\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 3.6339128017425537 | KNN Loss: 3.612384796142578 | CLS Loss: 0.021528072655200958\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 3.5860588550567627 | KNN Loss: 3.5833475589752197 | CLS Loss: 0.0027111987583339214\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 3.616628408432007 | KNN Loss: 3.6066012382507324 | CLS Loss: 0.010027101263403893\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 3.60849666595459 | KNN Loss: 3.594774007797241 | CLS Loss: 0.0137226777151227\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 3.6123290061950684 | KNN Loss: 3.582038164138794 | CLS Loss: 0.03029077686369419\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 3.62082576751709 | KNN Loss: 3.605992078781128 | CLS Loss: 0.014833590015769005\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 3.6002602577209473 | KNN Loss: 3.5979385375976562 | CLS Loss: 0.0023218358401209116\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 3.6217896938323975 | KNN Loss: 3.611189603805542 | CLS Loss: 0.010599984787404537\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 3.651005268096924 | KNN Loss: 3.635064125061035 | CLS Loss: 0.015941238030791283\n",
      "Epoch: 069, Loss: 3.6349, Train: 0.9943, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 3.6406304836273193 | KNN Loss: 3.627842426300049 | CLS Loss: 0.012787965126335621\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 3.6309733390808105 | KNN Loss: 3.6022884845733643 | CLS Loss: 0.028684912249445915\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 3.6128652095794678 | KNN Loss: 3.601487636566162 | CLS Loss: 0.011377478949725628\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 3.6060731410980225 | KNN Loss: 3.596733570098877 | CLS Loss: 0.009339594282209873\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 3.6028265953063965 | KNN Loss: 3.5921294689178467 | CLS Loss: 0.01069721207022667\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 3.653205156326294 | KNN Loss: 3.633772611618042 | CLS Loss: 0.019432609900832176\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 3.6211822032928467 | KNN Loss: 3.6081795692443848 | CLS Loss: 0.01300253625959158\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 3.6373543739318848 | KNN Loss: 3.629974126815796 | CLS Loss: 0.0073801809921860695\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 3.6297762393951416 | KNN Loss: 3.6195197105407715 | CLS Loss: 0.010256498120725155\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 3.6412737369537354 | KNN Loss: 3.625791072845459 | CLS Loss: 0.015482652932405472\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 3.587428092956543 | KNN Loss: 3.5736985206604004 | CLS Loss: 0.013729597441852093\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 3.6280407905578613 | KNN Loss: 3.611422061920166 | CLS Loss: 0.016618818044662476\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 3.6374406814575195 | KNN Loss: 3.595961809158325 | CLS Loss: 0.04147889092564583\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 3.5955886840820312 | KNN Loss: 3.583371639251709 | CLS Loss: 0.012216930277645588\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 3.646613359451294 | KNN Loss: 3.6205384731292725 | CLS Loss: 0.026074973866343498\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 3.6732702255249023 | KNN Loss: 3.639833688735962 | CLS Loss: 0.03343651071190834\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 3.6557350158691406 | KNN Loss: 3.6283531188964844 | CLS Loss: 0.027382005006074905\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 3.6311471462249756 | KNN Loss: 3.614197254180908 | CLS Loss: 0.01694977469742298\n",
      "Epoch: 070, Loss: 3.6331, Train: 0.9953, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 3.641385793685913 | KNN Loss: 3.6339163780212402 | CLS Loss: 0.007469408214092255\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 3.671297550201416 | KNN Loss: 3.633915424346924 | CLS Loss: 0.03738212212920189\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 3.6192986965179443 | KNN Loss: 3.6030707359313965 | CLS Loss: 0.016228074207901955\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 3.627728223800659 | KNN Loss: 3.622173547744751 | CLS Loss: 0.00555458664894104\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 3.6048669815063477 | KNN Loss: 3.5955491065979004 | CLS Loss: 0.009317985735833645\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 3.6279637813568115 | KNN Loss: 3.6114706993103027 | CLS Loss: 0.016492964699864388\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 3.6344759464263916 | KNN Loss: 3.619189977645874 | CLS Loss: 0.015285979025065899\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 3.6237077713012695 | KNN Loss: 3.5985751152038574 | CLS Loss: 0.025132590904831886\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 3.6355319023132324 | KNN Loss: 3.6132824420928955 | CLS Loss: 0.022249426692724228\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 3.678913116455078 | KNN Loss: 3.635812997817993 | CLS Loss: 0.04310022294521332\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 3.642194986343384 | KNN Loss: 3.6341588497161865 | CLS Loss: 0.008036063052713871\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 3.640568256378174 | KNN Loss: 3.6149349212646484 | CLS Loss: 0.02563333511352539\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 3.612699508666992 | KNN Loss: 3.598144054412842 | CLS Loss: 0.014555349014699459\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 3.59135365486145 | KNN Loss: 3.5787858963012695 | CLS Loss: 0.012567701749503613\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 3.6254119873046875 | KNN Loss: 3.606316328048706 | CLS Loss: 0.019095616415143013\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 3.713557243347168 | KNN Loss: 3.652327299118042 | CLS Loss: 0.061229970306158066\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 3.659083604812622 | KNN Loss: 3.6289215087890625 | CLS Loss: 0.030162135139107704\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 3.6484451293945312 | KNN Loss: 3.6140658855438232 | CLS Loss: 0.03437921777367592\n",
      "Epoch: 071, Loss: 3.6360, Train: 0.9957, Valid: 0.9863, Best: 0.9867\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 3.6385929584503174 | KNN Loss: 3.6232316493988037 | CLS Loss: 0.015361319296061993\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 3.641017436981201 | KNN Loss: 3.631218194961548 | CLS Loss: 0.009799267165362835\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 3.637047052383423 | KNN Loss: 3.6190407276153564 | CLS Loss: 0.018006213009357452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 3.6367435455322266 | KNN Loss: 3.616748332977295 | CLS Loss: 0.019995326176285744\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 3.6451759338378906 | KNN Loss: 3.610538959503174 | CLS Loss: 0.03463687375187874\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 3.6310174465179443 | KNN Loss: 3.6221866607666016 | CLS Loss: 0.008830725215375423\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 3.6177468299865723 | KNN Loss: 3.6047182083129883 | CLS Loss: 0.013028637506067753\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 3.609560251235962 | KNN Loss: 3.5998153686523438 | CLS Loss: 0.009744923561811447\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 3.6321043968200684 | KNN Loss: 3.618283748626709 | CLS Loss: 0.013820596970617771\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 3.6085708141326904 | KNN Loss: 3.5882840156555176 | CLS Loss: 0.020286763086915016\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 3.6050188541412354 | KNN Loss: 3.5915660858154297 | CLS Loss: 0.013452834449708462\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 3.6331567764282227 | KNN Loss: 3.624476909637451 | CLS Loss: 0.008679797872900963\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 3.6258158683776855 | KNN Loss: 3.607710838317871 | CLS Loss: 0.018105018883943558\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 3.6013238430023193 | KNN Loss: 3.577242851257324 | CLS Loss: 0.024080980569124222\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 3.621417999267578 | KNN Loss: 3.605142831802368 | CLS Loss: 0.016275081783533096\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 3.6636011600494385 | KNN Loss: 3.6381990909576416 | CLS Loss: 0.025402074679732323\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 3.637814998626709 | KNN Loss: 3.622135877609253 | CLS Loss: 0.01567918248474598\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 3.598646402359009 | KNN Loss: 3.588812828063965 | CLS Loss: 0.009833691641688347\n",
      "Epoch: 072, Loss: 3.6322, Train: 0.9947, Valid: 0.9859, Best: 0.9867\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 3.6321659088134766 | KNN Loss: 3.607229471206665 | CLS Loss: 0.024936383590102196\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 3.6303977966308594 | KNN Loss: 3.6237053871154785 | CLS Loss: 0.006692518945783377\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 3.600334882736206 | KNN Loss: 3.587717056274414 | CLS Loss: 0.012617925181984901\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 3.6340980529785156 | KNN Loss: 3.589054584503174 | CLS Loss: 0.04504351317882538\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 3.6167516708374023 | KNN Loss: 3.5853428840637207 | CLS Loss: 0.03140882030129433\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 3.6155641078948975 | KNN Loss: 3.5996761322021484 | CLS Loss: 0.015887895599007607\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 3.6123244762420654 | KNN Loss: 3.6043601036071777 | CLS Loss: 0.007964318618178368\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 3.6329925060272217 | KNN Loss: 3.6087634563446045 | CLS Loss: 0.02422916516661644\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 3.6530494689941406 | KNN Loss: 3.617643356323242 | CLS Loss: 0.03540603071451187\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 3.62489652633667 | KNN Loss: 3.6001217365264893 | CLS Loss: 0.02477479912340641\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 3.626357316970825 | KNN Loss: 3.613862991333008 | CLS Loss: 0.012494334019720554\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 3.64604115486145 | KNN Loss: 3.617832899093628 | CLS Loss: 0.028208158910274506\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 3.6106157302856445 | KNN Loss: 3.5950841903686523 | CLS Loss: 0.01553157065063715\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 3.592684268951416 | KNN Loss: 3.5896859169006348 | CLS Loss: 0.0029983946587890387\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 3.6031603813171387 | KNN Loss: 3.5824480056762695 | CLS Loss: 0.02071239799261093\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 3.6501004695892334 | KNN Loss: 3.6138176918029785 | CLS Loss: 0.03628271818161011\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 3.6140177249908447 | KNN Loss: 3.5973496437072754 | CLS Loss: 0.01666814461350441\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 3.6053617000579834 | KNN Loss: 3.5868678092956543 | CLS Loss: 0.018493913114070892\n",
      "Epoch: 073, Loss: 3.6326, Train: 0.9965, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 3.624648332595825 | KNN Loss: 3.6012439727783203 | CLS Loss: 0.023404261097311974\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 3.6156198978424072 | KNN Loss: 3.587599277496338 | CLS Loss: 0.02802056446671486\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 3.6316585540771484 | KNN Loss: 3.605710029602051 | CLS Loss: 0.025948554277420044\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 3.619507074356079 | KNN Loss: 3.610050678253174 | CLS Loss: 0.00945631880313158\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 3.6228299140930176 | KNN Loss: 3.612299680709839 | CLS Loss: 0.010530209168791771\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 3.680084466934204 | KNN Loss: 3.644911527633667 | CLS Loss: 0.03517282381653786\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 3.5889463424682617 | KNN Loss: 3.58052659034729 | CLS Loss: 0.008419642224907875\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 3.5762906074523926 | KNN Loss: 3.5641820430755615 | CLS Loss: 0.012108509428799152\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 3.623203754425049 | KNN Loss: 3.6135456562042236 | CLS Loss: 0.009658120572566986\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 3.6088414192199707 | KNN Loss: 3.6025869846343994 | CLS Loss: 0.006254380103200674\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 3.696084499359131 | KNN Loss: 3.6770005226135254 | CLS Loss: 0.01908404752612114\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 3.605172634124756 | KNN Loss: 3.603919744491577 | CLS Loss: 0.0012528173392638564\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 3.6418731212615967 | KNN Loss: 3.6203176975250244 | CLS Loss: 0.02155543677508831\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 3.6016628742218018 | KNN Loss: 3.589810371398926 | CLS Loss: 0.011852438561618328\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 3.6909842491149902 | KNN Loss: 3.6566174030303955 | CLS Loss: 0.03436683490872383\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 3.651015043258667 | KNN Loss: 3.5971996784210205 | CLS Loss: 0.053815409541130066\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 3.5924696922302246 | KNN Loss: 3.585716724395752 | CLS Loss: 0.0067529925145208836\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 3.6162877082824707 | KNN Loss: 3.611687421798706 | CLS Loss: 0.004600276704877615\n",
      "Epoch: 074, Loss: 3.6322, Train: 0.9960, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 3.6350672245025635 | KNN Loss: 3.6308207511901855 | CLS Loss: 0.0042464276775717735\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 3.5842583179473877 | KNN Loss: 3.5817906856536865 | CLS Loss: 0.002467713551595807\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 3.6561977863311768 | KNN Loss: 3.6292543411254883 | CLS Loss: 0.026943551376461983\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 3.611222743988037 | KNN Loss: 3.6009418964385986 | CLS Loss: 0.010280809365212917\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 3.6281321048736572 | KNN Loss: 3.6074256896972656 | CLS Loss: 0.020706387236714363\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 3.6193318367004395 | KNN Loss: 3.6140809059143066 | CLS Loss: 0.005251012276858091\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 3.627882242202759 | KNN Loss: 3.6071293354034424 | CLS Loss: 0.020752860233187675\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 3.6299121379852295 | KNN Loss: 3.595097064971924 | CLS Loss: 0.03481514751911163\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 3.63157057762146 | KNN Loss: 3.6027183532714844 | CLS Loss: 0.028852231800556183\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 3.6192479133605957 | KNN Loss: 3.604835033416748 | CLS Loss: 0.014412883669137955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 3.625706911087036 | KNN Loss: 3.6131656169891357 | CLS Loss: 0.012541298754513264\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 3.6068897247314453 | KNN Loss: 3.5812323093414307 | CLS Loss: 0.02565743215382099\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 3.6437222957611084 | KNN Loss: 3.6286258697509766 | CLS Loss: 0.015096385963261127\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 3.607807159423828 | KNN Loss: 3.6026077270507812 | CLS Loss: 0.005199415609240532\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 3.632398843765259 | KNN Loss: 3.621151924133301 | CLS Loss: 0.011246957816183567\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 3.621037006378174 | KNN Loss: 3.6117959022521973 | CLS Loss: 0.009241144172847271\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 3.638749837875366 | KNN Loss: 3.630941390991211 | CLS Loss: 0.007808331400156021\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 3.645456552505493 | KNN Loss: 3.630072832107544 | CLS Loss: 0.015383693389594555\n",
      "Epoch: 075, Loss: 3.6320, Train: 0.9961, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 3.608142614364624 | KNN Loss: 3.606191635131836 | CLS Loss: 0.0019509622361510992\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 3.6088979244232178 | KNN Loss: 3.6050143241882324 | CLS Loss: 0.0038834908045828342\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 3.5862021446228027 | KNN Loss: 3.57808256149292 | CLS Loss: 0.008119647391140461\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 3.6246917247772217 | KNN Loss: 3.6089961528778076 | CLS Loss: 0.015695618465542793\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 3.662142038345337 | KNN Loss: 3.644427537918091 | CLS Loss: 0.01771455816924572\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 3.623764753341675 | KNN Loss: 3.593111276626587 | CLS Loss: 0.03065345622599125\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 3.6230454444885254 | KNN Loss: 3.6169018745422363 | CLS Loss: 0.0061435154639184475\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 3.619580030441284 | KNN Loss: 3.5918726921081543 | CLS Loss: 0.027707336470484734\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 3.6339969635009766 | KNN Loss: 3.6221518516540527 | CLS Loss: 0.011845040135085583\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 3.601508378982544 | KNN Loss: 3.5875580310821533 | CLS Loss: 0.01395028829574585\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 3.643221139907837 | KNN Loss: 3.609280586242676 | CLS Loss: 0.03394058346748352\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 3.611217737197876 | KNN Loss: 3.6037168502807617 | CLS Loss: 0.007501003798097372\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 3.6238951683044434 | KNN Loss: 3.6056079864501953 | CLS Loss: 0.018287096172571182\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 3.6230571269989014 | KNN Loss: 3.594559907913208 | CLS Loss: 0.02849724516272545\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 3.6906049251556396 | KNN Loss: 3.641295909881592 | CLS Loss: 0.049309052526950836\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 3.6447913646698 | KNN Loss: 3.614337921142578 | CLS Loss: 0.030453437939286232\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 3.6313066482543945 | KNN Loss: 3.6193246841430664 | CLS Loss: 0.011981942690908909\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 3.662079334259033 | KNN Loss: 3.6281158924102783 | CLS Loss: 0.03396349027752876\n",
      "Epoch: 076, Loss: 3.6335, Train: 0.9944, Valid: 0.9851, Best: 0.9872\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 3.615330457687378 | KNN Loss: 3.5915920734405518 | CLS Loss: 0.023738406598567963\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 3.6597137451171875 | KNN Loss: 3.6538398265838623 | CLS Loss: 0.005873821675777435\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 3.652254581451416 | KNN Loss: 3.645322561264038 | CLS Loss: 0.006931905634701252\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 3.6312289237976074 | KNN Loss: 3.6166749000549316 | CLS Loss: 0.014553945511579514\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 3.5994949340820312 | KNN Loss: 3.593273401260376 | CLS Loss: 0.0062216492369771\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 3.611475944519043 | KNN Loss: 3.5985031127929688 | CLS Loss: 0.012972808443009853\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 3.6297059059143066 | KNN Loss: 3.6140377521514893 | CLS Loss: 0.015668053179979324\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 3.6348650455474854 | KNN Loss: 3.612103223800659 | CLS Loss: 0.022761715576052666\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 3.6024675369262695 | KNN Loss: 3.5923080444335938 | CLS Loss: 0.010159481316804886\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 3.64216685295105 | KNN Loss: 3.6280782222747803 | CLS Loss: 0.01408869307488203\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 3.647127866744995 | KNN Loss: 3.616274118423462 | CLS Loss: 0.03085372783243656\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 3.612231492996216 | KNN Loss: 3.5951478481292725 | CLS Loss: 0.01708356849849224\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 3.642265796661377 | KNN Loss: 3.611943006515503 | CLS Loss: 0.030322683975100517\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 3.6440019607543945 | KNN Loss: 3.6335713863372803 | CLS Loss: 0.010430690832436085\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 3.6588237285614014 | KNN Loss: 3.6531362533569336 | CLS Loss: 0.0056875599548220634\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 3.642686605453491 | KNN Loss: 3.6238880157470703 | CLS Loss: 0.01879849284887314\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 3.6327052116394043 | KNN Loss: 3.6275148391723633 | CLS Loss: 0.005190413910895586\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 3.610236406326294 | KNN Loss: 3.6011040210723877 | CLS Loss: 0.00913239736109972\n",
      "Epoch: 077, Loss: 3.6352, Train: 0.9950, Valid: 0.9856, Best: 0.9872\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 3.6058201789855957 | KNN Loss: 3.5968804359436035 | CLS Loss: 0.00893964059650898\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 3.6013739109039307 | KNN Loss: 3.5928142070770264 | CLS Loss: 0.008559780195355415\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 3.5813770294189453 | KNN Loss: 3.57759428024292 | CLS Loss: 0.0037827130872756243\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 3.622387170791626 | KNN Loss: 3.6010513305664062 | CLS Loss: 0.021335797384381294\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 3.62741756439209 | KNN Loss: 3.6204230785369873 | CLS Loss: 0.006994405295699835\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 3.6200919151306152 | KNN Loss: 3.608412027359009 | CLS Loss: 0.01167996320873499\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 3.63470458984375 | KNN Loss: 3.621225357055664 | CLS Loss: 0.013479232788085938\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 3.641561985015869 | KNN Loss: 3.626067876815796 | CLS Loss: 0.015494074672460556\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 3.6447527408599854 | KNN Loss: 3.61913800239563 | CLS Loss: 0.02561481110751629\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 3.590010643005371 | KNN Loss: 3.584963798522949 | CLS Loss: 0.005046839360147715\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 3.6415576934814453 | KNN Loss: 3.6178417205810547 | CLS Loss: 0.023716064170002937\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 3.6086387634277344 | KNN Loss: 3.59281325340271 | CLS Loss: 0.015825456008315086\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 3.6189029216766357 | KNN Loss: 3.6116085052490234 | CLS Loss: 0.007294333539903164\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 3.617037773132324 | KNN Loss: 3.5949723720550537 | CLS Loss: 0.022065315395593643\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 3.624898910522461 | KNN Loss: 3.6157333850860596 | CLS Loss: 0.009165454655885696\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 3.636319398880005 | KNN Loss: 3.6056716442108154 | CLS Loss: 0.030647842213511467\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 3.6369571685791016 | KNN Loss: 3.615950584411621 | CLS Loss: 0.021006517112255096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 3.6490485668182373 | KNN Loss: 3.622202157974243 | CLS Loss: 0.02684645727276802\n",
      "Epoch: 078, Loss: 3.6330, Train: 0.9942, Valid: 0.9841, Best: 0.9872\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 3.646577835083008 | KNN Loss: 3.6311686038970947 | CLS Loss: 0.015409338288009167\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 3.5857865810394287 | KNN Loss: 3.582533597946167 | CLS Loss: 0.003253028029575944\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 3.603862762451172 | KNN Loss: 3.592116594314575 | CLS Loss: 0.011746094562113285\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 3.6003713607788086 | KNN Loss: 3.5903584957122803 | CLS Loss: 0.010012773796916008\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 3.6088056564331055 | KNN Loss: 3.5953662395477295 | CLS Loss: 0.013439413160085678\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 3.665938377380371 | KNN Loss: 3.655069589614868 | CLS Loss: 0.010868889279663563\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 3.6359221935272217 | KNN Loss: 3.6087794303894043 | CLS Loss: 0.02714281529188156\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 3.6195037364959717 | KNN Loss: 3.610522508621216 | CLS Loss: 0.008981135673820972\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 3.642383098602295 | KNN Loss: 3.629702091217041 | CLS Loss: 0.012681014835834503\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 3.6444873809814453 | KNN Loss: 3.6259894371032715 | CLS Loss: 0.018497930839657784\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 3.665313720703125 | KNN Loss: 3.6289470195770264 | CLS Loss: 0.036366693675518036\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 3.658780813217163 | KNN Loss: 3.6479554176330566 | CLS Loss: 0.010825368575751781\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 3.6496853828430176 | KNN Loss: 3.6182284355163574 | CLS Loss: 0.03145701810717583\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 3.622202157974243 | KNN Loss: 3.616450309753418 | CLS Loss: 0.005751890130341053\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 3.6137516498565674 | KNN Loss: 3.587968111038208 | CLS Loss: 0.025783421471714973\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 3.6286983489990234 | KNN Loss: 3.625030517578125 | CLS Loss: 0.003667783923447132\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 3.704876184463501 | KNN Loss: 3.6847617626190186 | CLS Loss: 0.020114408805966377\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 3.6261391639709473 | KNN Loss: 3.608287811279297 | CLS Loss: 0.017851317301392555\n",
      "Epoch: 079, Loss: 3.6304, Train: 0.9961, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 3.6276237964630127 | KNN Loss: 3.6068410873413086 | CLS Loss: 0.020782791078090668\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 3.6231861114501953 | KNN Loss: 3.6051082611083984 | CLS Loss: 0.018077731132507324\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 3.6034061908721924 | KNN Loss: 3.5863308906555176 | CLS Loss: 0.017075415700674057\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 3.6408543586730957 | KNN Loss: 3.63226056098938 | CLS Loss: 0.008593686856329441\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 3.6343839168548584 | KNN Loss: 3.62587308883667 | CLS Loss: 0.00851090345531702\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 3.6135263442993164 | KNN Loss: 3.6066958904266357 | CLS Loss: 0.0068304212763905525\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 3.629298686981201 | KNN Loss: 3.6215059757232666 | CLS Loss: 0.007792692631483078\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 3.6367897987365723 | KNN Loss: 3.6272618770599365 | CLS Loss: 0.009528023190796375\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 3.6345460414886475 | KNN Loss: 3.625300168991089 | CLS Loss: 0.009245829656720161\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 3.6955153942108154 | KNN Loss: 3.6697189807891846 | CLS Loss: 0.02579643577337265\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 3.6531152725219727 | KNN Loss: 3.6402790546417236 | CLS Loss: 0.012836148031055927\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 3.6267168521881104 | KNN Loss: 3.6180312633514404 | CLS Loss: 0.008685622364282608\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 3.6730921268463135 | KNN Loss: 3.661541700363159 | CLS Loss: 0.011550537310540676\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 3.6754684448242188 | KNN Loss: 3.6623315811157227 | CLS Loss: 0.013136869296431541\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 3.631199836730957 | KNN Loss: 3.610231876373291 | CLS Loss: 0.020967954769730568\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 3.615246295928955 | KNN Loss: 3.5794453620910645 | CLS Loss: 0.035800833255052567\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 3.6453163623809814 | KNN Loss: 3.6371307373046875 | CLS Loss: 0.008185621351003647\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 3.6391868591308594 | KNN Loss: 3.6247377395629883 | CLS Loss: 0.014449132606387138\n",
      "Epoch: 080, Loss: 3.6338, Train: 0.9963, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 3.6035947799682617 | KNN Loss: 3.5951690673828125 | CLS Loss: 0.008425797335803509\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 3.6100382804870605 | KNN Loss: 3.6026999950408936 | CLS Loss: 0.0073384009301662445\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 3.671935796737671 | KNN Loss: 3.6489956378936768 | CLS Loss: 0.02294025756418705\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 3.650947332382202 | KNN Loss: 3.6214656829833984 | CLS Loss: 0.029481597244739532\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 3.6138737201690674 | KNN Loss: 3.598360061645508 | CLS Loss: 0.015513703227043152\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 3.5969865322113037 | KNN Loss: 3.576709747314453 | CLS Loss: 0.020276889204978943\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 3.6310031414031982 | KNN Loss: 3.6134724617004395 | CLS Loss: 0.017530588433146477\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 3.603693962097168 | KNN Loss: 3.593275308609009 | CLS Loss: 0.010418575257062912\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 3.6149845123291016 | KNN Loss: 3.609715223312378 | CLS Loss: 0.0052693369798362255\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 3.683807134628296 | KNN Loss: 3.6635313034057617 | CLS Loss: 0.020275864750146866\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 3.6583380699157715 | KNN Loss: 3.6492395401000977 | CLS Loss: 0.009098570793867111\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 3.6740264892578125 | KNN Loss: 3.6283819675445557 | CLS Loss: 0.045644551515579224\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 3.6343994140625 | KNN Loss: 3.6028125286102295 | CLS Loss: 0.031586941331624985\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 3.6254734992980957 | KNN Loss: 3.6235544681549072 | CLS Loss: 0.0019191330065950751\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 3.618417978286743 | KNN Loss: 3.6081395149230957 | CLS Loss: 0.010278379544615746\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 3.63850474357605 | KNN Loss: 3.620509386062622 | CLS Loss: 0.017995385453104973\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 3.602226734161377 | KNN Loss: 3.591414451599121 | CLS Loss: 0.010812164284288883\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 3.6297881603240967 | KNN Loss: 3.6212689876556396 | CLS Loss: 0.008519282564520836\n",
      "Epoch: 081, Loss: 3.6367, Train: 0.9953, Valid: 0.9855, Best: 0.9872\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 3.6242897510528564 | KNN Loss: 3.597823143005371 | CLS Loss: 0.02646663971245289\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 3.645970344543457 | KNN Loss: 3.6237168312072754 | CLS Loss: 0.022253600880503654\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 3.6754050254821777 | KNN Loss: 3.656831741333008 | CLS Loss: 0.018573369830846786\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 3.6274468898773193 | KNN Loss: 3.6168627738952637 | CLS Loss: 0.010584091767668724\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 3.6232454776763916 | KNN Loss: 3.6076834201812744 | CLS Loss: 0.01556209847331047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 3.611201524734497 | KNN Loss: 3.5927698612213135 | CLS Loss: 0.018431762233376503\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 3.686183452606201 | KNN Loss: 3.645203113555908 | CLS Loss: 0.04098033159971237\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 3.620623826980591 | KNN Loss: 3.6062984466552734 | CLS Loss: 0.01432543434202671\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 3.655012607574463 | KNN Loss: 3.6447653770446777 | CLS Loss: 0.010247151367366314\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 3.62788724899292 | KNN Loss: 3.594909191131592 | CLS Loss: 0.032978083938360214\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 3.670849323272705 | KNN Loss: 3.6434481143951416 | CLS Loss: 0.027401186525821686\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 3.6312432289123535 | KNN Loss: 3.620168685913086 | CLS Loss: 0.011074580252170563\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 3.645087957382202 | KNN Loss: 3.6072704792022705 | CLS Loss: 0.03781736269593239\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 3.6434459686279297 | KNN Loss: 3.63291072845459 | CLS Loss: 0.010535337030887604\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 3.5974204540252686 | KNN Loss: 3.583423137664795 | CLS Loss: 0.013997340574860573\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 3.615363836288452 | KNN Loss: 3.609560012817383 | CLS Loss: 0.005803808104246855\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 3.6160542964935303 | KNN Loss: 3.610483407974243 | CLS Loss: 0.005570962093770504\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 3.6770262718200684 | KNN Loss: 3.6499969959259033 | CLS Loss: 0.027029333636164665\n",
      "Epoch: 082, Loss: 3.6333, Train: 0.9956, Valid: 0.9850, Best: 0.9872\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 3.614858388900757 | KNN Loss: 3.6011619567871094 | CLS Loss: 0.013696368783712387\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 3.676971912384033 | KNN Loss: 3.671262502670288 | CLS Loss: 0.0057094767689704895\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 3.5925590991973877 | KNN Loss: 3.5899276733398438 | CLS Loss: 0.002631519455462694\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 3.591500759124756 | KNN Loss: 3.589489698410034 | CLS Loss: 0.0020111051853746176\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 3.696455955505371 | KNN Loss: 3.670135259628296 | CLS Loss: 0.02632080763578415\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 3.650494337081909 | KNN Loss: 3.6246893405914307 | CLS Loss: 0.025805039331316948\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 3.596592903137207 | KNN Loss: 3.581407308578491 | CLS Loss: 0.015185617841780186\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 3.587592840194702 | KNN Loss: 3.565459728240967 | CLS Loss: 0.022133102640509605\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 3.62571382522583 | KNN Loss: 3.6200804710388184 | CLS Loss: 0.00563327269628644\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 3.606598377227783 | KNN Loss: 3.591017484664917 | CLS Loss: 0.015580975450575352\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 3.625981092453003 | KNN Loss: 3.601224184036255 | CLS Loss: 0.024756813421845436\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 3.6172351837158203 | KNN Loss: 3.608229160308838 | CLS Loss: 0.009006118401885033\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 3.668457269668579 | KNN Loss: 3.6459219455718994 | CLS Loss: 0.02253527194261551\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 3.6148223876953125 | KNN Loss: 3.589674949645996 | CLS Loss: 0.025147389620542526\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 3.597008466720581 | KNN Loss: 3.5764873027801514 | CLS Loss: 0.020521067082881927\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 3.6075546741485596 | KNN Loss: 3.587540626525879 | CLS Loss: 0.020013947039842606\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 3.6310932636260986 | KNN Loss: 3.6116297245025635 | CLS Loss: 0.019463583827018738\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 3.6454668045043945 | KNN Loss: 3.628445863723755 | CLS Loss: 0.017020897939801216\n",
      "Epoch: 083, Loss: 3.6242, Train: 0.9959, Valid: 0.9852, Best: 0.9872\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 3.6254794597625732 | KNN Loss: 3.623666286468506 | CLS Loss: 0.001813092385418713\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 3.6624526977539062 | KNN Loss: 3.6175222396850586 | CLS Loss: 0.04493040218949318\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 3.65217924118042 | KNN Loss: 3.6364076137542725 | CLS Loss: 0.015771614387631416\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 3.6488561630249023 | KNN Loss: 3.6352858543395996 | CLS Loss: 0.01357035432010889\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 3.6305136680603027 | KNN Loss: 3.62261962890625 | CLS Loss: 0.00789407454431057\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 3.6298398971557617 | KNN Loss: 3.615297794342041 | CLS Loss: 0.014542101882398129\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 3.6453471183776855 | KNN Loss: 3.637608051300049 | CLS Loss: 0.007739075925201178\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 3.592372417449951 | KNN Loss: 3.5866401195526123 | CLS Loss: 0.0057322317734360695\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 3.5998291969299316 | KNN Loss: 3.589599609375 | CLS Loss: 0.010229619219899178\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 3.660478115081787 | KNN Loss: 3.636784553527832 | CLS Loss: 0.023693516850471497\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 3.6325747966766357 | KNN Loss: 3.609764337539673 | CLS Loss: 0.022810542955994606\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 3.632845163345337 | KNN Loss: 3.6022861003875732 | CLS Loss: 0.0305591132491827\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 3.629652976989746 | KNN Loss: 3.6134302616119385 | CLS Loss: 0.01622280292212963\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 3.6995646953582764 | KNN Loss: 3.6759157180786133 | CLS Loss: 0.02364896424114704\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 3.6586244106292725 | KNN Loss: 3.6497316360473633 | CLS Loss: 0.008892788551747799\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 3.6618218421936035 | KNN Loss: 3.6381287574768066 | CLS Loss: 0.023693129420280457\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 3.6382625102996826 | KNN Loss: 3.6269571781158447 | CLS Loss: 0.011305388994514942\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 3.674560546875 | KNN Loss: 3.6379330158233643 | CLS Loss: 0.03662750497460365\n",
      "Epoch: 084, Loss: 3.6313, Train: 0.9931, Valid: 0.9841, Best: 0.9872\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 3.718925714492798 | KNN Loss: 3.694007158279419 | CLS Loss: 0.0249185673892498\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 3.6194491386413574 | KNN Loss: 3.608633279800415 | CLS Loss: 0.010815962217748165\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 3.640205144882202 | KNN Loss: 3.614234685897827 | CLS Loss: 0.02597043104469776\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 3.618396043777466 | KNN Loss: 3.596557378768921 | CLS Loss: 0.021838665008544922\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 3.636387825012207 | KNN Loss: 3.613577365875244 | CLS Loss: 0.022810444235801697\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 3.6043782234191895 | KNN Loss: 3.5961575508117676 | CLS Loss: 0.00822074431926012\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 3.6337108612060547 | KNN Loss: 3.6164729595184326 | CLS Loss: 0.017237814143300056\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 3.639176845550537 | KNN Loss: 3.6168177127838135 | CLS Loss: 0.022359251976013184\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 3.6263508796691895 | KNN Loss: 3.6085219383239746 | CLS Loss: 0.01782893016934395\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 3.6054999828338623 | KNN Loss: 3.595194101333618 | CLS Loss: 0.010305969044566154\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 3.6330575942993164 | KNN Loss: 3.6198208332061768 | CLS Loss: 0.013236792758107185\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 3.6222784519195557 | KNN Loss: 3.593268632888794 | CLS Loss: 0.02900981716811657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 3.6125588417053223 | KNN Loss: 3.594191312789917 | CLS Loss: 0.018367473036050797\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 3.6592376232147217 | KNN Loss: 3.6227962970733643 | CLS Loss: 0.0364413745701313\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 3.6025285720825195 | KNN Loss: 3.599350929260254 | CLS Loss: 0.00317756412550807\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 3.6251296997070312 | KNN Loss: 3.6142663955688477 | CLS Loss: 0.010863285511732101\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 3.64123797416687 | KNN Loss: 3.6189916133880615 | CLS Loss: 0.022246433421969414\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 3.6929051876068115 | KNN Loss: 3.6594653129577637 | CLS Loss: 0.033439815044403076\n",
      "Epoch: 085, Loss: 3.6288, Train: 0.9959, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 3.6058900356292725 | KNN Loss: 3.5889649391174316 | CLS Loss: 0.01692505180835724\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 3.592869997024536 | KNN Loss: 3.584660291671753 | CLS Loss: 0.00820960197597742\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 3.6516125202178955 | KNN Loss: 3.638016700744629 | CLS Loss: 0.013595778495073318\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 3.6095662117004395 | KNN Loss: 3.595548152923584 | CLS Loss: 0.014017947018146515\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 3.589460611343384 | KNN Loss: 3.5816867351531982 | CLS Loss: 0.007773777935653925\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 3.64959716796875 | KNN Loss: 3.6367263793945312 | CLS Loss: 0.012870896607637405\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 3.589780330657959 | KNN Loss: 3.5877716541290283 | CLS Loss: 0.002008701441809535\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 3.6329097747802734 | KNN Loss: 3.62416934967041 | CLS Loss: 0.0087405014783144\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 3.6277472972869873 | KNN Loss: 3.6025922298431396 | CLS Loss: 0.02515512891113758\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 3.603977918624878 | KNN Loss: 3.5932607650756836 | CLS Loss: 0.010717217810451984\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 3.6474106311798096 | KNN Loss: 3.6388814449310303 | CLS Loss: 0.008529208600521088\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 3.6215732097625732 | KNN Loss: 3.593189239501953 | CLS Loss: 0.028384074568748474\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 3.59570050239563 | KNN Loss: 3.583792209625244 | CLS Loss: 0.011908347718417645\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 3.6108758449554443 | KNN Loss: 3.5964863300323486 | CLS Loss: 0.01438960712403059\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 3.674121141433716 | KNN Loss: 3.6675546169281006 | CLS Loss: 0.006566439755260944\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 3.6335086822509766 | KNN Loss: 3.6134679317474365 | CLS Loss: 0.020040659233927727\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 3.6320223808288574 | KNN Loss: 3.6257669925689697 | CLS Loss: 0.006255354732275009\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 3.6338539123535156 | KNN Loss: 3.630040168762207 | CLS Loss: 0.0038137363735586405\n",
      "Epoch: 086, Loss: 3.6273, Train: 0.9959, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 3.644658088684082 | KNN Loss: 3.639507532119751 | CLS Loss: 0.005150577053427696\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 3.630338430404663 | KNN Loss: 3.627072811126709 | CLS Loss: 0.0032657315023243427\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 3.6229653358459473 | KNN Loss: 3.607914686203003 | CLS Loss: 0.015050670132040977\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 3.597644090652466 | KNN Loss: 3.5907468795776367 | CLS Loss: 0.006897262297570705\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 3.609117031097412 | KNN Loss: 3.586351156234741 | CLS Loss: 0.0227658748626709\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 3.693391799926758 | KNN Loss: 3.6665399074554443 | CLS Loss: 0.026851991191506386\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 3.6601548194885254 | KNN Loss: 3.641191005706787 | CLS Loss: 0.018963772803544998\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 3.619877576828003 | KNN Loss: 3.6112494468688965 | CLS Loss: 0.008628054521977901\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 3.6354775428771973 | KNN Loss: 3.626453161239624 | CLS Loss: 0.009024282917380333\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 3.6363861560821533 | KNN Loss: 3.6281914710998535 | CLS Loss: 0.008194778114557266\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 3.6231794357299805 | KNN Loss: 3.612474203109741 | CLS Loss: 0.010705258697271347\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 3.618122100830078 | KNN Loss: 3.5969619750976562 | CLS Loss: 0.021160151809453964\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 3.639768123626709 | KNN Loss: 3.6294753551483154 | CLS Loss: 0.010292792692780495\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 3.6547539234161377 | KNN Loss: 3.635814905166626 | CLS Loss: 0.01893901824951172\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 3.642366409301758 | KNN Loss: 3.632296085357666 | CLS Loss: 0.010070402175188065\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 3.631287097930908 | KNN Loss: 3.6095399856567383 | CLS Loss: 0.02174709178507328\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 3.647664785385132 | KNN Loss: 3.6114227771759033 | CLS Loss: 0.03624192625284195\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 3.602111339569092 | KNN Loss: 3.579463481903076 | CLS Loss: 0.022647757083177567\n",
      "Epoch: 087, Loss: 3.6249, Train: 0.9960, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 3.64802622795105 | KNN Loss: 3.631011962890625 | CLS Loss: 0.01701422408223152\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 3.636009693145752 | KNN Loss: 3.610382556915283 | CLS Loss: 0.025627179071307182\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 3.6273534297943115 | KNN Loss: 3.616769313812256 | CLS Loss: 0.010584132745862007\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 3.642071008682251 | KNN Loss: 3.6206791400909424 | CLS Loss: 0.021391794085502625\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 3.7028720378875732 | KNN Loss: 3.6635172367095947 | CLS Loss: 0.03935476019978523\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 3.638624906539917 | KNN Loss: 3.631772756576538 | CLS Loss: 0.0068522123619914055\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 3.6066529750823975 | KNN Loss: 3.585904836654663 | CLS Loss: 0.02074817568063736\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 3.6632282733917236 | KNN Loss: 3.644704580307007 | CLS Loss: 0.01852373220026493\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 3.626258373260498 | KNN Loss: 3.6184003353118896 | CLS Loss: 0.007858140394091606\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 3.6391243934631348 | KNN Loss: 3.6309120655059814 | CLS Loss: 0.00821234192699194\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 3.619537115097046 | KNN Loss: 3.6169333457946777 | CLS Loss: 0.0026037602219730616\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 3.6283719539642334 | KNN Loss: 3.600773334503174 | CLS Loss: 0.027598712593317032\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 3.632467269897461 | KNN Loss: 3.609593391418457 | CLS Loss: 0.022873925045132637\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 3.6009926795959473 | KNN Loss: 3.589566707611084 | CLS Loss: 0.011426053009927273\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 3.6773056983947754 | KNN Loss: 3.627513885498047 | CLS Loss: 0.04979189857840538\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 3.609065294265747 | KNN Loss: 3.5977559089660645 | CLS Loss: 0.011309465393424034\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 3.6982855796813965 | KNN Loss: 3.681378126144409 | CLS Loss: 0.016907477751374245\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 3.6091432571411133 | KNN Loss: 3.6050755977630615 | CLS Loss: 0.0040676831267774105\n",
      "Epoch: 088, Loss: 3.6303, Train: 0.9950, Valid: 0.9844, Best: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 3.6149990558624268 | KNN Loss: 3.60939884185791 | CLS Loss: 0.005600270349532366\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 3.6503407955169678 | KNN Loss: 3.645698070526123 | CLS Loss: 0.004642823711037636\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 3.654783248901367 | KNN Loss: 3.623379945755005 | CLS Loss: 0.031403351575136185\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 3.6293904781341553 | KNN Loss: 3.6184256076812744 | CLS Loss: 0.010964852757751942\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 3.6030709743499756 | KNN Loss: 3.5788307189941406 | CLS Loss: 0.024240346625447273\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 3.6082193851470947 | KNN Loss: 3.603856325149536 | CLS Loss: 0.004363050684332848\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 3.6563720703125 | KNN Loss: 3.6345913410186768 | CLS Loss: 0.021780764684081078\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 3.5934576988220215 | KNN Loss: 3.5767996311187744 | CLS Loss: 0.016658004373311996\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 3.6467835903167725 | KNN Loss: 3.635049819946289 | CLS Loss: 0.01173371821641922\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 3.5936548709869385 | KNN Loss: 3.5805139541625977 | CLS Loss: 0.013140975497663021\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 3.603661060333252 | KNN Loss: 3.5916526317596436 | CLS Loss: 0.012008520774543285\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 3.6245741844177246 | KNN Loss: 3.6152894496917725 | CLS Loss: 0.009284652769565582\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 3.626450300216675 | KNN Loss: 3.6004204750061035 | CLS Loss: 0.02602984756231308\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 3.6303789615631104 | KNN Loss: 3.6040844917297363 | CLS Loss: 0.026294438168406487\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 3.5922181606292725 | KNN Loss: 3.5739235877990723 | CLS Loss: 0.01829451695084572\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 3.656151056289673 | KNN Loss: 3.6327693462371826 | CLS Loss: 0.023381683975458145\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 3.641467571258545 | KNN Loss: 3.6094939708709717 | CLS Loss: 0.03197358921170235\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 3.642873764038086 | KNN Loss: 3.6398847103118896 | CLS Loss: 0.002989037660881877\n",
      "Epoch: 089, Loss: 3.6289, Train: 0.9956, Valid: 0.9851, Best: 0.9872\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 3.605952024459839 | KNN Loss: 3.6019959449768066 | CLS Loss: 0.0039559886790812016\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 3.648754596710205 | KNN Loss: 3.637385368347168 | CLS Loss: 0.011369345709681511\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 3.603123664855957 | KNN Loss: 3.5993571281433105 | CLS Loss: 0.003766626352444291\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 3.6585991382598877 | KNN Loss: 3.6235110759735107 | CLS Loss: 0.03508799523115158\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 3.5967695713043213 | KNN Loss: 3.59311842918396 | CLS Loss: 0.0036510652862489223\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 3.6342978477478027 | KNN Loss: 3.6254820823669434 | CLS Loss: 0.008815801702439785\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 3.6407928466796875 | KNN Loss: 3.625257968902588 | CLS Loss: 0.015534861013293266\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 3.6018760204315186 | KNN Loss: 3.5984888076782227 | CLS Loss: 0.0033871338237076998\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 3.6139512062072754 | KNN Loss: 3.5991506576538086 | CLS Loss: 0.014800578355789185\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 3.6254749298095703 | KNN Loss: 3.612422227859497 | CLS Loss: 0.01305273175239563\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 3.662527084350586 | KNN Loss: 3.6426448822021484 | CLS Loss: 0.019882163032889366\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 3.6199417114257812 | KNN Loss: 3.5922632217407227 | CLS Loss: 0.027678390964865685\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 3.6523609161376953 | KNN Loss: 3.625244140625 | CLS Loss: 0.02711665630340576\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 3.630908489227295 | KNN Loss: 3.6152303218841553 | CLS Loss: 0.015678059309720993\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 3.628769636154175 | KNN Loss: 3.602524757385254 | CLS Loss: 0.026244960725307465\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 3.67159104347229 | KNN Loss: 3.6505954265594482 | CLS Loss: 0.020995687693357468\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 3.645129442214966 | KNN Loss: 3.6156959533691406 | CLS Loss: 0.02943338081240654\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 3.656287670135498 | KNN Loss: 3.64892578125 | CLS Loss: 0.007361867930740118\n",
      "Epoch: 090, Loss: 3.6321, Train: 0.9950, Valid: 0.9860, Best: 0.9872\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 3.62117862701416 | KNN Loss: 3.6070058345794678 | CLS Loss: 0.014172825962305069\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 3.6614949703216553 | KNN Loss: 3.635819435119629 | CLS Loss: 0.025675617158412933\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 3.6519553661346436 | KNN Loss: 3.631988525390625 | CLS Loss: 0.01996680535376072\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 3.6340129375457764 | KNN Loss: 3.627105712890625 | CLS Loss: 0.006907181348651648\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 3.620976686477661 | KNN Loss: 3.6081652641296387 | CLS Loss: 0.012811421416699886\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 3.6307692527770996 | KNN Loss: 3.625683546066284 | CLS Loss: 0.005085645243525505\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 3.5994341373443604 | KNN Loss: 3.590843915939331 | CLS Loss: 0.008590241894125938\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 3.645318031311035 | KNN Loss: 3.6279613971710205 | CLS Loss: 0.017356639727950096\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 3.6279006004333496 | KNN Loss: 3.590240955352783 | CLS Loss: 0.03765958547592163\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 3.660902500152588 | KNN Loss: 3.648747682571411 | CLS Loss: 0.012154876254498959\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 3.6050496101379395 | KNN Loss: 3.596909284591675 | CLS Loss: 0.00814034603536129\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 3.640953779220581 | KNN Loss: 3.6126456260681152 | CLS Loss: 0.028308145701885223\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 3.635209560394287 | KNN Loss: 3.6240293979644775 | CLS Loss: 0.011180181056261063\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 3.64939284324646 | KNN Loss: 3.6406309604644775 | CLS Loss: 0.008761782199144363\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 3.612884044647217 | KNN Loss: 3.585428237915039 | CLS Loss: 0.027455909177660942\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 3.6100292205810547 | KNN Loss: 3.580050468444824 | CLS Loss: 0.02997884899377823\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 3.6992392539978027 | KNN Loss: 3.681666374206543 | CLS Loss: 0.017572907730937004\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 3.636526584625244 | KNN Loss: 3.6247692108154297 | CLS Loss: 0.01175737101584673\n",
      "Epoch: 091, Loss: 3.6329, Train: 0.9949, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 3.604247570037842 | KNN Loss: 3.5772604942321777 | CLS Loss: 0.026987137272953987\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 3.621828079223633 | KNN Loss: 3.595659017562866 | CLS Loss: 0.02616901323199272\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 3.5963218212127686 | KNN Loss: 3.591784954071045 | CLS Loss: 0.004536830820143223\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 3.6507766246795654 | KNN Loss: 3.632579803466797 | CLS Loss: 0.018196918070316315\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 3.6045420169830322 | KNN Loss: 3.580570697784424 | CLS Loss: 0.023971404880285263\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 3.5937020778656006 | KNN Loss: 3.5846691131591797 | CLS Loss: 0.009032957255840302\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 3.6430256366729736 | KNN Loss: 3.6218771934509277 | CLS Loss: 0.021148500964045525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 3.6233327388763428 | KNN Loss: 3.604680061340332 | CLS Loss: 0.01865277625620365\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 3.641547203063965 | KNN Loss: 3.6300694942474365 | CLS Loss: 0.011477712541818619\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 3.5979886054992676 | KNN Loss: 3.580007791519165 | CLS Loss: 0.017980894073843956\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 3.6289801597595215 | KNN Loss: 3.603811740875244 | CLS Loss: 0.025168459862470627\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 3.587360382080078 | KNN Loss: 3.5826799869537354 | CLS Loss: 0.004680283833295107\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 3.624922037124634 | KNN Loss: 3.586778402328491 | CLS Loss: 0.03814353793859482\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 3.5966484546661377 | KNN Loss: 3.5827393531799316 | CLS Loss: 0.013909182511270046\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 3.6142418384552 | KNN Loss: 3.589949131011963 | CLS Loss: 0.024292660877108574\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 3.664818048477173 | KNN Loss: 3.6134965419769287 | CLS Loss: 0.05132158100605011\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 3.6235690116882324 | KNN Loss: 3.5977766513824463 | CLS Loss: 0.02579234540462494\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 3.6502888202667236 | KNN Loss: 3.6267576217651367 | CLS Loss: 0.023531099781394005\n",
      "Epoch: 092, Loss: 3.6283, Train: 0.9959, Valid: 0.9870, Best: 0.9872\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 3.6383841037750244 | KNN Loss: 3.6005945205688477 | CLS Loss: 0.037789542227983475\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 3.6185238361358643 | KNN Loss: 3.5953478813171387 | CLS Loss: 0.023176023736596107\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 3.625030755996704 | KNN Loss: 3.619692325592041 | CLS Loss: 0.005338443908840418\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 3.620922327041626 | KNN Loss: 3.606062173843384 | CLS Loss: 0.014860074035823345\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 3.6313695907592773 | KNN Loss: 3.6164448261260986 | CLS Loss: 0.014924684539437294\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 3.627307653427124 | KNN Loss: 3.6118273735046387 | CLS Loss: 0.015480352565646172\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 3.6332106590270996 | KNN Loss: 3.6214489936828613 | CLS Loss: 0.011761746369302273\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 3.6308205127716064 | KNN Loss: 3.6111536026000977 | CLS Loss: 0.019666895270347595\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 3.614525079727173 | KNN Loss: 3.6055195331573486 | CLS Loss: 0.009005486965179443\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 3.626648187637329 | KNN Loss: 3.619772434234619 | CLS Loss: 0.006875780876725912\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 3.6306140422821045 | KNN Loss: 3.6090102195739746 | CLS Loss: 0.02160375565290451\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 3.640463352203369 | KNN Loss: 3.6265599727630615 | CLS Loss: 0.013903441838920116\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 3.638620138168335 | KNN Loss: 3.5987355709075928 | CLS Loss: 0.03988465294241905\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 3.6276614665985107 | KNN Loss: 3.60974383354187 | CLS Loss: 0.01791759394109249\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 3.594679832458496 | KNN Loss: 3.5663111209869385 | CLS Loss: 0.02836880087852478\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 3.606466293334961 | KNN Loss: 3.599989652633667 | CLS Loss: 0.00647668307647109\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 3.6288952827453613 | KNN Loss: 3.6199212074279785 | CLS Loss: 0.008974145166575909\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 3.6364569664001465 | KNN Loss: 3.610926628112793 | CLS Loss: 0.025530429556965828\n",
      "Epoch: 093, Loss: 3.6229, Train: 0.9967, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 3.6340112686157227 | KNN Loss: 3.5977461338043213 | CLS Loss: 0.03626520186662674\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 3.656430721282959 | KNN Loss: 3.632565975189209 | CLS Loss: 0.023864826187491417\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 3.6196794509887695 | KNN Loss: 3.598111867904663 | CLS Loss: 0.02156762219965458\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 3.624147891998291 | KNN Loss: 3.6058661937713623 | CLS Loss: 0.01828162930905819\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 3.629633665084839 | KNN Loss: 3.6066033840179443 | CLS Loss: 0.023030215874314308\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 3.663572311401367 | KNN Loss: 3.6512436866760254 | CLS Loss: 0.012328566052019596\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 3.5769388675689697 | KNN Loss: 3.5753698348999023 | CLS Loss: 0.0015689145075157285\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 3.598322629928589 | KNN Loss: 3.5956411361694336 | CLS Loss: 0.002681384328752756\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 3.6318347454071045 | KNN Loss: 3.622441053390503 | CLS Loss: 0.009393596090376377\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 3.6208815574645996 | KNN Loss: 3.5895066261291504 | CLS Loss: 0.03137482330203056\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 3.6336894035339355 | KNN Loss: 3.5962815284729004 | CLS Loss: 0.037407975643873215\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 3.619750738143921 | KNN Loss: 3.600480079650879 | CLS Loss: 0.019270703196525574\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 3.617481231689453 | KNN Loss: 3.607661008834839 | CLS Loss: 0.009820160456001759\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 3.6081151962280273 | KNN Loss: 3.5850772857666016 | CLS Loss: 0.0230378657579422\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 3.6028552055358887 | KNN Loss: 3.5865185260772705 | CLS Loss: 0.01633668877184391\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 3.6719000339508057 | KNN Loss: 3.657480001449585 | CLS Loss: 0.01441999152302742\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 3.6324539184570312 | KNN Loss: 3.6272175312042236 | CLS Loss: 0.005236501805484295\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 3.6095945835113525 | KNN Loss: 3.595074415206909 | CLS Loss: 0.014520139433443546\n",
      "Epoch: 094, Loss: 3.6280, Train: 0.9957, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 3.608520269393921 | KNN Loss: 3.6007235050201416 | CLS Loss: 0.00779686076566577\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 3.6627156734466553 | KNN Loss: 3.6591742038726807 | CLS Loss: 0.003541457001119852\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 3.652167797088623 | KNN Loss: 3.620187282562256 | CLS Loss: 0.03198044002056122\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 3.629477024078369 | KNN Loss: 3.6113007068634033 | CLS Loss: 0.0181763656437397\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 3.6480672359466553 | KNN Loss: 3.6360459327697754 | CLS Loss: 0.012021314352750778\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 3.6069819927215576 | KNN Loss: 3.601815938949585 | CLS Loss: 0.0051660118624567986\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 3.6447527408599854 | KNN Loss: 3.642474412918091 | CLS Loss: 0.0022783626336604357\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 3.593837261199951 | KNN Loss: 3.592193365097046 | CLS Loss: 0.0016437978483736515\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 3.6192402839660645 | KNN Loss: 3.604222297668457 | CLS Loss: 0.0150179173797369\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 3.627720832824707 | KNN Loss: 3.5862598419189453 | CLS Loss: 0.041461072862148285\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 3.6409707069396973 | KNN Loss: 3.6371006965637207 | CLS Loss: 0.003870080690830946\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 3.6161768436431885 | KNN Loss: 3.6102700233459473 | CLS Loss: 0.005906757432967424\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 3.6119279861450195 | KNN Loss: 3.6083755493164062 | CLS Loss: 0.003552338806912303\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 3.6250555515289307 | KNN Loss: 3.618492603302002 | CLS Loss: 0.006562980357557535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 3.6254518032073975 | KNN Loss: 3.6028213500976562 | CLS Loss: 0.022630352526903152\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 3.6673552989959717 | KNN Loss: 3.6468217372894287 | CLS Loss: 0.02053362876176834\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 3.6056509017944336 | KNN Loss: 3.5973331928253174 | CLS Loss: 0.008317629806697369\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 3.621460437774658 | KNN Loss: 3.615311622619629 | CLS Loss: 0.006148811895400286\n",
      "Epoch: 095, Loss: 3.6287, Train: 0.9967, Valid: 0.9868, Best: 0.9872\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 3.626277446746826 | KNN Loss: 3.6060903072357178 | CLS Loss: 0.02018715813755989\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 3.5971829891204834 | KNN Loss: 3.5822949409484863 | CLS Loss: 0.014887976460158825\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 3.6301753520965576 | KNN Loss: 3.6139516830444336 | CLS Loss: 0.016223646700382233\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 3.579146385192871 | KNN Loss: 3.576058864593506 | CLS Loss: 0.003087500808760524\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 3.608210325241089 | KNN Loss: 3.6020281314849854 | CLS Loss: 0.006182114593684673\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 3.688845157623291 | KNN Loss: 3.678067922592163 | CLS Loss: 0.010777338407933712\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 3.6198008060455322 | KNN Loss: 3.6106560230255127 | CLS Loss: 0.009144851937890053\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 3.6024162769317627 | KNN Loss: 3.5947163105010986 | CLS Loss: 0.007699858862906694\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 3.6397786140441895 | KNN Loss: 3.611314535140991 | CLS Loss: 0.02846396155655384\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 3.5996766090393066 | KNN Loss: 3.595161199569702 | CLS Loss: 0.004515450913459063\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 3.618417739868164 | KNN Loss: 3.603933572769165 | CLS Loss: 0.014484270475804806\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 3.6373231410980225 | KNN Loss: 3.6232709884643555 | CLS Loss: 0.014052174985408783\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 3.6642980575561523 | KNN Loss: 3.6535136699676514 | CLS Loss: 0.010784437879920006\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 3.623509645462036 | KNN Loss: 3.61208176612854 | CLS Loss: 0.011427958495914936\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 3.623533248901367 | KNN Loss: 3.604539632797241 | CLS Loss: 0.018993649631738663\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 3.614511251449585 | KNN Loss: 3.6060221195220947 | CLS Loss: 0.008489016443490982\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 3.6446754932403564 | KNN Loss: 3.590005397796631 | CLS Loss: 0.05467016622424126\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 3.6290204524993896 | KNN Loss: 3.6108999252319336 | CLS Loss: 0.018120594322681427\n",
      "Epoch: 096, Loss: 3.6288, Train: 0.9949, Valid: 0.9855, Best: 0.9872\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 3.6530003547668457 | KNN Loss: 3.62947940826416 | CLS Loss: 0.023520881310105324\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 3.6241211891174316 | KNN Loss: 3.596381425857544 | CLS Loss: 0.02773969992995262\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 3.6429269313812256 | KNN Loss: 3.5973854064941406 | CLS Loss: 0.045541517436504364\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 3.6433889865875244 | KNN Loss: 3.6220805644989014 | CLS Loss: 0.02130834013223648\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 3.6179041862487793 | KNN Loss: 3.611055374145508 | CLS Loss: 0.006848803721368313\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 3.5961220264434814 | KNN Loss: 3.5910377502441406 | CLS Loss: 0.005084304139018059\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 3.595715045928955 | KNN Loss: 3.5787179470062256 | CLS Loss: 0.016997214406728745\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 3.6185142993927 | KNN Loss: 3.5980818271636963 | CLS Loss: 0.020432433113455772\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 3.65381121635437 | KNN Loss: 3.6371991634368896 | CLS Loss: 0.016611935570836067\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 3.6215710639953613 | KNN Loss: 3.610306739807129 | CLS Loss: 0.011264392174780369\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 3.60632586479187 | KNN Loss: 3.5938072204589844 | CLS Loss: 0.012518695555627346\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 3.614729166030884 | KNN Loss: 3.610877752304077 | CLS Loss: 0.0038514139596372843\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 3.6435883045196533 | KNN Loss: 3.6368205547332764 | CLS Loss: 0.0067677367478609085\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 3.610757827758789 | KNN Loss: 3.6043965816497803 | CLS Loss: 0.006361277773976326\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 3.6636204719543457 | KNN Loss: 3.622204065322876 | CLS Loss: 0.04141644760966301\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 3.6084134578704834 | KNN Loss: 3.5927698612213135 | CLS Loss: 0.015643497928977013\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 3.6628267765045166 | KNN Loss: 3.6407711505889893 | CLS Loss: 0.02205568552017212\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 3.5872154235839844 | KNN Loss: 3.579719066619873 | CLS Loss: 0.007496295031160116\n",
      "Epoch: 097, Loss: 3.6292, Train: 0.9961, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 3.6579678058624268 | KNN Loss: 3.6402063369750977 | CLS Loss: 0.01776145026087761\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 3.603182554244995 | KNN Loss: 3.5972795486450195 | CLS Loss: 0.005902961362153292\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 3.626962423324585 | KNN Loss: 3.6144399642944336 | CLS Loss: 0.012522486969828606\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 3.606334924697876 | KNN Loss: 3.595681667327881 | CLS Loss: 0.010653164237737656\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 3.6020214557647705 | KNN Loss: 3.5980706214904785 | CLS Loss: 0.003950946498662233\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 3.649343252182007 | KNN Loss: 3.6271750926971436 | CLS Loss: 0.022168101742863655\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 3.640686273574829 | KNN Loss: 3.634354829788208 | CLS Loss: 0.006331347394734621\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 3.642530918121338 | KNN Loss: 3.6241657733917236 | CLS Loss: 0.018365146592259407\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 3.62320876121521 | KNN Loss: 3.618363618850708 | CLS Loss: 0.004845032002776861\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 3.6056041717529297 | KNN Loss: 3.592210054397583 | CLS Loss: 0.013394171372056007\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 3.6537325382232666 | KNN Loss: 3.6280105113983154 | CLS Loss: 0.025721963495016098\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 3.6125528812408447 | KNN Loss: 3.6043457984924316 | CLS Loss: 0.008207021281123161\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 3.6004745960235596 | KNN Loss: 3.5910706520080566 | CLS Loss: 0.009403903968632221\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 3.5991835594177246 | KNN Loss: 3.591742992401123 | CLS Loss: 0.007440501358360052\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 3.6066713333129883 | KNN Loss: 3.5960910320281982 | CLS Loss: 0.01058031152933836\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 3.6177585124969482 | KNN Loss: 3.606492519378662 | CLS Loss: 0.011265958659350872\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 3.586944103240967 | KNN Loss: 3.5795609951019287 | CLS Loss: 0.007383154705166817\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 3.6113178730010986 | KNN Loss: 3.5883615016937256 | CLS Loss: 0.022956272587180138\n",
      "Epoch: 098, Loss: 3.6216, Train: 0.9964, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 3.6377084255218506 | KNN Loss: 3.622753620147705 | CLS Loss: 0.014954856596887112\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 3.629956007003784 | KNN Loss: 3.6080522537231445 | CLS Loss: 0.0219037476927042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 3.643935203552246 | KNN Loss: 3.6282942295074463 | CLS Loss: 0.01564090885221958\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 3.628748655319214 | KNN Loss: 3.6232962608337402 | CLS Loss: 0.005452287849038839\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 3.6101179122924805 | KNN Loss: 3.5979905128479004 | CLS Loss: 0.012127382680773735\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 3.614577531814575 | KNN Loss: 3.6094369888305664 | CLS Loss: 0.005140623543411493\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 3.6312336921691895 | KNN Loss: 3.613185167312622 | CLS Loss: 0.01804843731224537\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 3.6148841381073 | KNN Loss: 3.603874921798706 | CLS Loss: 0.011009251698851585\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 3.6315157413482666 | KNN Loss: 3.624821186065674 | CLS Loss: 0.006694588344544172\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 3.6649937629699707 | KNN Loss: 3.645724296569824 | CLS Loss: 0.019269496202468872\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 3.625899076461792 | KNN Loss: 3.580207347869873 | CLS Loss: 0.04569162800908089\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 3.6157898902893066 | KNN Loss: 3.6079585552215576 | CLS Loss: 0.007831321097910404\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 3.5989162921905518 | KNN Loss: 3.5838568210601807 | CLS Loss: 0.015059584751725197\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 3.608350992202759 | KNN Loss: 3.590200662612915 | CLS Loss: 0.018150275573134422\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 3.606581211090088 | KNN Loss: 3.5874836444854736 | CLS Loss: 0.019097475335001945\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 3.628054618835449 | KNN Loss: 3.603435516357422 | CLS Loss: 0.024619026109576225\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 3.6282806396484375 | KNN Loss: 3.6197521686553955 | CLS Loss: 0.008528361096978188\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 3.6096959114074707 | KNN Loss: 3.6033644676208496 | CLS Loss: 0.006331384647637606\n",
      "Epoch: 099, Loss: 3.6277, Train: 0.9956, Valid: 0.9854, Best: 0.9872\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 3.590219259262085 | KNN Loss: 3.5827813148498535 | CLS Loss: 0.007437973283231258\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 3.6553328037261963 | KNN Loss: 3.6250526905059814 | CLS Loss: 0.0302802175283432\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 3.5912327766418457 | KNN Loss: 3.585679531097412 | CLS Loss: 0.005553136579692364\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 3.640951156616211 | KNN Loss: 3.6004819869995117 | CLS Loss: 0.040469247847795486\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 3.5938682556152344 | KNN Loss: 3.5875425338745117 | CLS Loss: 0.006325660273432732\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 3.6657633781433105 | KNN Loss: 3.6503026485443115 | CLS Loss: 0.01546076126396656\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 3.6457905769348145 | KNN Loss: 3.6236000061035156 | CLS Loss: 0.02219051495194435\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 3.6155989170074463 | KNN Loss: 3.592858076095581 | CLS Loss: 0.022740814834833145\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 3.5997490882873535 | KNN Loss: 3.5789706707000732 | CLS Loss: 0.020778419449925423\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 3.643862247467041 | KNN Loss: 3.6260488033294678 | CLS Loss: 0.017813516780734062\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 3.6127712726593018 | KNN Loss: 3.5950474739074707 | CLS Loss: 0.017723724246025085\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 3.6308512687683105 | KNN Loss: 3.6218836307525635 | CLS Loss: 0.008967742323875427\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 3.6300599575042725 | KNN Loss: 3.607492685317993 | CLS Loss: 0.02256726659834385\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 3.639727830886841 | KNN Loss: 3.6214842796325684 | CLS Loss: 0.018243547528982162\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 3.612022876739502 | KNN Loss: 3.6022732257843018 | CLS Loss: 0.009749708697199821\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 3.6144607067108154 | KNN Loss: 3.6076695919036865 | CLS Loss: 0.006791182793676853\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 3.596257448196411 | KNN Loss: 3.5689704418182373 | CLS Loss: 0.02728707157075405\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 3.620354413986206 | KNN Loss: 3.604011058807373 | CLS Loss: 0.016343355178833008\n",
      "Epoch: 100, Loss: 3.6213, Train: 0.9967, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 3.584820508956909 | KNN Loss: 3.5756783485412598 | CLS Loss: 0.009142224676907063\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 3.5673701763153076 | KNN Loss: 3.557689905166626 | CLS Loss: 0.009680318646132946\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 3.6476833820343018 | KNN Loss: 3.615182399749756 | CLS Loss: 0.03250104933977127\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 3.591862678527832 | KNN Loss: 3.5832371711730957 | CLS Loss: 0.008625431917607784\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 3.6109201908111572 | KNN Loss: 3.6046218872070312 | CLS Loss: 0.006298419088125229\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 3.6111083030700684 | KNN Loss: 3.605083703994751 | CLS Loss: 0.006024717353284359\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 3.6040940284729004 | KNN Loss: 3.589792490005493 | CLS Loss: 0.01430147048085928\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 3.5981509685516357 | KNN Loss: 3.5923471450805664 | CLS Loss: 0.0058038486167788506\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 3.630195379257202 | KNN Loss: 3.61574387550354 | CLS Loss: 0.014451570808887482\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 3.620474100112915 | KNN Loss: 3.604224443435669 | CLS Loss: 0.016249755397439003\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 3.6023571491241455 | KNN Loss: 3.6000773906707764 | CLS Loss: 0.002279861830174923\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 3.622783899307251 | KNN Loss: 3.5849039554595947 | CLS Loss: 0.03788001090288162\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 3.6351261138916016 | KNN Loss: 3.627037525177002 | CLS Loss: 0.00808862317353487\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 3.6477959156036377 | KNN Loss: 3.6405084133148193 | CLS Loss: 0.007287606596946716\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 3.6503665447235107 | KNN Loss: 3.619093656539917 | CLS Loss: 0.03127298876643181\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 3.6303679943084717 | KNN Loss: 3.60744309425354 | CLS Loss: 0.02292485348880291\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 3.5871407985687256 | KNN Loss: 3.5831401348114014 | CLS Loss: 0.004000591114163399\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 3.6500771045684814 | KNN Loss: 3.620687246322632 | CLS Loss: 0.029389841482043266\n",
      "Epoch: 101, Loss: 3.6257, Train: 0.9942, Valid: 0.9835, Best: 0.9872\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 3.6263041496276855 | KNN Loss: 3.587872266769409 | CLS Loss: 0.03843197599053383\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 3.6074748039245605 | KNN Loss: 3.6018600463867188 | CLS Loss: 0.0056146797724068165\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 3.616614818572998 | KNN Loss: 3.5837740898132324 | CLS Loss: 0.03284068778157234\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 3.6310477256774902 | KNN Loss: 3.606147527694702 | CLS Loss: 0.024900170043110847\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 3.6504485607147217 | KNN Loss: 3.630753517150879 | CLS Loss: 0.019695067778229713\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 3.6474084854125977 | KNN Loss: 3.6377718448638916 | CLS Loss: 0.009636752307415009\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 3.6063027381896973 | KNN Loss: 3.5991992950439453 | CLS Loss: 0.007103348150849342\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 3.578062057495117 | KNN Loss: 3.5749566555023193 | CLS Loss: 0.0031054813880473375\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 3.585831642150879 | KNN Loss: 3.581348180770874 | CLS Loss: 0.004483452066779137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 3.616023063659668 | KNN Loss: 3.5905110836029053 | CLS Loss: 0.025511950254440308\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 3.5911567211151123 | KNN Loss: 3.586636781692505 | CLS Loss: 0.004519968293607235\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 3.6030962467193604 | KNN Loss: 3.592863082885742 | CLS Loss: 0.010233080945909023\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 3.6229147911071777 | KNN Loss: 3.6107606887817383 | CLS Loss: 0.012154157273471355\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 3.604405403137207 | KNN Loss: 3.594231367111206 | CLS Loss: 0.010174010880291462\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 3.5934271812438965 | KNN Loss: 3.5919947624206543 | CLS Loss: 0.0014323517680168152\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 3.640777587890625 | KNN Loss: 3.6150975227355957 | CLS Loss: 0.025680137798190117\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 3.6158695220947266 | KNN Loss: 3.6067099571228027 | CLS Loss: 0.00915959570556879\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 3.641850471496582 | KNN Loss: 3.6244051456451416 | CLS Loss: 0.01744537055492401\n",
      "Epoch: 102, Loss: 3.6201, Train: 0.9971, Valid: 0.9863, Best: 0.9872\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 3.627918243408203 | KNN Loss: 3.6176013946533203 | CLS Loss: 0.010316865518689156\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 3.607740879058838 | KNN Loss: 3.600989580154419 | CLS Loss: 0.0067512947134673595\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 3.655622720718384 | KNN Loss: 3.643432378768921 | CLS Loss: 0.012190410867333412\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 3.6205594539642334 | KNN Loss: 3.606910467147827 | CLS Loss: 0.013649087399244308\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 3.6069204807281494 | KNN Loss: 3.6035313606262207 | CLS Loss: 0.003389068180695176\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 3.6458513736724854 | KNN Loss: 3.6316397190093994 | CLS Loss: 0.014211578294634819\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 3.6457927227020264 | KNN Loss: 3.624471426010132 | CLS Loss: 0.021321335807442665\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 3.6203057765960693 | KNN Loss: 3.599635124206543 | CLS Loss: 0.020670723170042038\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 3.63285756111145 | KNN Loss: 3.629429817199707 | CLS Loss: 0.003427826566621661\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 3.5941407680511475 | KNN Loss: 3.592399835586548 | CLS Loss: 0.0017409889260306954\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 3.5980541706085205 | KNN Loss: 3.5897715091705322 | CLS Loss: 0.00828262697905302\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 3.668034553527832 | KNN Loss: 3.6296257972717285 | CLS Loss: 0.03840864822268486\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 3.6580419540405273 | KNN Loss: 3.648503541946411 | CLS Loss: 0.009538414888083935\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 3.6251938343048096 | KNN Loss: 3.6085243225097656 | CLS Loss: 0.016669558361172676\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 3.6366395950317383 | KNN Loss: 3.6199491024017334 | CLS Loss: 0.016690557822585106\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 3.6613354682922363 | KNN Loss: 3.64621901512146 | CLS Loss: 0.015116571448743343\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 3.68493914604187 | KNN Loss: 3.6778104305267334 | CLS Loss: 0.00712878443300724\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 3.5977365970611572 | KNN Loss: 3.590933084487915 | CLS Loss: 0.006803447846323252\n",
      "Epoch: 103, Loss: 3.6284, Train: 0.9964, Valid: 0.9861, Best: 0.9872\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 3.6163997650146484 | KNN Loss: 3.6083731651306152 | CLS Loss: 0.00802671629935503\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 3.5732290744781494 | KNN Loss: 3.5712602138519287 | CLS Loss: 0.001968874828889966\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 3.6255290508270264 | KNN Loss: 3.6197221279144287 | CLS Loss: 0.0058069005608558655\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 3.6156375408172607 | KNN Loss: 3.611879825592041 | CLS Loss: 0.0037578027695417404\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 3.6178762912750244 | KNN Loss: 3.5970094203948975 | CLS Loss: 0.02086685784161091\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 3.6719489097595215 | KNN Loss: 3.6563844680786133 | CLS Loss: 0.015564403496682644\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 3.6409993171691895 | KNN Loss: 3.622492551803589 | CLS Loss: 0.018506871536374092\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 3.5973894596099854 | KNN Loss: 3.58540415763855 | CLS Loss: 0.011985380202531815\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 3.6361234188079834 | KNN Loss: 3.6161999702453613 | CLS Loss: 0.01992334984242916\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 3.604783296585083 | KNN Loss: 3.584134817123413 | CLS Loss: 0.020648593083024025\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 3.6496264934539795 | KNN Loss: 3.6370368003845215 | CLS Loss: 0.01258964091539383\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 3.613487720489502 | KNN Loss: 3.6000945568084717 | CLS Loss: 0.013393187895417213\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 3.6702356338500977 | KNN Loss: 3.6337993144989014 | CLS Loss: 0.036436207592487335\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 3.744147777557373 | KNN Loss: 3.7164316177368164 | CLS Loss: 0.027716046199202538\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 3.602167844772339 | KNN Loss: 3.584751844406128 | CLS Loss: 0.017416097223758698\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 3.6366524696350098 | KNN Loss: 3.611950397491455 | CLS Loss: 0.024702021852135658\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 3.645711660385132 | KNN Loss: 3.616710901260376 | CLS Loss: 0.029000816866755486\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 3.6082558631896973 | KNN Loss: 3.6046669483184814 | CLS Loss: 0.003588910913094878\n",
      "Epoch: 104, Loss: 3.6282, Train: 0.9961, Valid: 0.9855, Best: 0.9872\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 3.637775182723999 | KNN Loss: 3.622431755065918 | CLS Loss: 0.015343482606112957\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 3.624415397644043 | KNN Loss: 3.615673303604126 | CLS Loss: 0.008741977624595165\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 3.620974063873291 | KNN Loss: 3.6005232334136963 | CLS Loss: 0.02045084908604622\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 3.575120449066162 | KNN Loss: 3.5503222942352295 | CLS Loss: 0.02479807659983635\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 3.6591477394104004 | KNN Loss: 3.648547887802124 | CLS Loss: 0.010599917732179165\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 3.624190092086792 | KNN Loss: 3.6030828952789307 | CLS Loss: 0.021107247099280357\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 3.6033670902252197 | KNN Loss: 3.5900766849517822 | CLS Loss: 0.013290457427501678\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 3.635293483734131 | KNN Loss: 3.6228833198547363 | CLS Loss: 0.012410279363393784\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 3.6182971000671387 | KNN Loss: 3.614877223968506 | CLS Loss: 0.0034199939109385014\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 3.634291648864746 | KNN Loss: 3.618644952774048 | CLS Loss: 0.015646692365407944\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 3.626391649246216 | KNN Loss: 3.618487596511841 | CLS Loss: 0.007903994992375374\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 3.589294672012329 | KNN Loss: 3.5706112384796143 | CLS Loss: 0.01868342235684395\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 3.6333556175231934 | KNN Loss: 3.6273317337036133 | CLS Loss: 0.0060239024460315704\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 3.595926284790039 | KNN Loss: 3.583648204803467 | CLS Loss: 0.012278120033442974\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 3.6158432960510254 | KNN Loss: 3.5948710441589355 | CLS Loss: 0.02097233571112156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 3.637131929397583 | KNN Loss: 3.627732276916504 | CLS Loss: 0.009399675764143467\n",
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 3.693878412246704 | KNN Loss: 3.6868221759796143 | CLS Loss: 0.0070561314933001995\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 3.666853904724121 | KNN Loss: 3.638063907623291 | CLS Loss: 0.028789926320314407\n",
      "Epoch: 105, Loss: 3.6214, Train: 0.9960, Valid: 0.9868, Best: 0.9872\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 3.6201179027557373 | KNN Loss: 3.6119039058685303 | CLS Loss: 0.008214105851948261\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 3.6124489307403564 | KNN Loss: 3.59419846534729 | CLS Loss: 0.018250498920679092\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 3.623868465423584 | KNN Loss: 3.6168158054351807 | CLS Loss: 0.007052757311612368\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 3.6058387756347656 | KNN Loss: 3.601623058319092 | CLS Loss: 0.004215700086206198\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 3.616649866104126 | KNN Loss: 3.6139848232269287 | CLS Loss: 0.00266513810493052\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 3.6228420734405518 | KNN Loss: 3.596299171447754 | CLS Loss: 0.02654278837144375\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 3.610795259475708 | KNN Loss: 3.598154306411743 | CLS Loss: 0.01264103688299656\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 3.5985710620880127 | KNN Loss: 3.588529348373413 | CLS Loss: 0.01004171185195446\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 3.5895485877990723 | KNN Loss: 3.5807437896728516 | CLS Loss: 0.008804737590253353\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 3.5952978134155273 | KNN Loss: 3.5867865085601807 | CLS Loss: 0.008511273190379143\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 3.6401898860931396 | KNN Loss: 3.6330947875976562 | CLS Loss: 0.007094995118677616\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 3.668259382247925 | KNN Loss: 3.6606433391571045 | CLS Loss: 0.007615998852998018\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 3.6215386390686035 | KNN Loss: 3.6176600456237793 | CLS Loss: 0.0038784965872764587\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 3.605426788330078 | KNN Loss: 3.6006546020507812 | CLS Loss: 0.004772302228957415\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 3.6243836879730225 | KNN Loss: 3.6095545291900635 | CLS Loss: 0.014829058200120926\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 3.592831611633301 | KNN Loss: 3.5826570987701416 | CLS Loss: 0.010174469090998173\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 3.6059954166412354 | KNN Loss: 3.5939340591430664 | CLS Loss: 0.01206127554178238\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 3.6858725547790527 | KNN Loss: 3.667468547821045 | CLS Loss: 0.01840408891439438\n",
      "Epoch: 106, Loss: 3.6214, Train: 0.9962, Valid: 0.9856, Best: 0.9872\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 3.613269805908203 | KNN Loss: 3.6078975200653076 | CLS Loss: 0.005372384563088417\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 3.6175999641418457 | KNN Loss: 3.6116507053375244 | CLS Loss: 0.005949333775788546\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 3.5838751792907715 | KNN Loss: 3.5818676948547363 | CLS Loss: 0.0020074513740837574\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 3.5762829780578613 | KNN Loss: 3.57315731048584 | CLS Loss: 0.003125594463199377\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 3.6094448566436768 | KNN Loss: 3.6011006832122803 | CLS Loss: 0.008344236761331558\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 3.6473488807678223 | KNN Loss: 3.63405442237854 | CLS Loss: 0.013294566422700882\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 3.6013243198394775 | KNN Loss: 3.578141927719116 | CLS Loss: 0.023182306438684464\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 3.614825963973999 | KNN Loss: 3.596977949142456 | CLS Loss: 0.017848001793026924\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 3.6135222911834717 | KNN Loss: 3.610433340072632 | CLS Loss: 0.0030888651963323355\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 3.683481454849243 | KNN Loss: 3.651172399520874 | CLS Loss: 0.03230903297662735\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 3.623993396759033 | KNN Loss: 3.6038758754730225 | CLS Loss: 0.020117616280913353\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 3.6303699016571045 | KNN Loss: 3.616887331008911 | CLS Loss: 0.013482491485774517\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 3.653590679168701 | KNN Loss: 3.6230692863464355 | CLS Loss: 0.03052135743200779\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 3.610989570617676 | KNN Loss: 3.604532241821289 | CLS Loss: 0.006457270123064518\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 3.6187047958374023 | KNN Loss: 3.6071956157684326 | CLS Loss: 0.011509120464324951\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 3.604247570037842 | KNN Loss: 3.5894970893859863 | CLS Loss: 0.014750448055565357\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 3.600426197052002 | KNN Loss: 3.595696210861206 | CLS Loss: 0.004729998763650656\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 3.6344683170318604 | KNN Loss: 3.623229503631592 | CLS Loss: 0.01123881060630083\n",
      "Epoch: 107, Loss: 3.6245, Train: 0.9927, Valid: 0.9823, Best: 0.9872\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 3.6664998531341553 | KNN Loss: 3.627831220626831 | CLS Loss: 0.038668613880872726\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 3.592224359512329 | KNN Loss: 3.581909656524658 | CLS Loss: 0.01031474955379963\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 3.6139843463897705 | KNN Loss: 3.6044082641601562 | CLS Loss: 0.009576049633324146\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 3.6246449947357178 | KNN Loss: 3.6102395057678223 | CLS Loss: 0.014405515044927597\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 3.602874517440796 | KNN Loss: 3.587512969970703 | CLS Loss: 0.015361445024609566\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 3.6441450119018555 | KNN Loss: 3.6286048889160156 | CLS Loss: 0.015540181659162045\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 3.620514154434204 | KNN Loss: 3.6116652488708496 | CLS Loss: 0.008848865516483784\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 3.6042678356170654 | KNN Loss: 3.5995216369628906 | CLS Loss: 0.004746291786432266\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 3.638845205307007 | KNN Loss: 3.62091326713562 | CLS Loss: 0.017931833863258362\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 3.6245079040527344 | KNN Loss: 3.617617607116699 | CLS Loss: 0.006890276912599802\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 3.5940630435943604 | KNN Loss: 3.591949462890625 | CLS Loss: 0.0021136263385415077\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 3.6288182735443115 | KNN Loss: 3.6119844913482666 | CLS Loss: 0.016833709552884102\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 3.5991666316986084 | KNN Loss: 3.5785017013549805 | CLS Loss: 0.020664947107434273\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 3.624661684036255 | KNN Loss: 3.621809244155884 | CLS Loss: 0.0028525402303785086\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 3.6615114212036133 | KNN Loss: 3.631880521774292 | CLS Loss: 0.029630865901708603\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 3.6181087493896484 | KNN Loss: 3.609462261199951 | CLS Loss: 0.008646496571600437\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 3.6450016498565674 | KNN Loss: 3.596372127532959 | CLS Loss: 0.048629555851221085\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 3.625950574874878 | KNN Loss: 3.612370491027832 | CLS Loss: 0.013580004684627056\n",
      "Epoch: 108, Loss: 3.6217, Train: 0.9960, Valid: 0.9844, Best: 0.9872\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 3.634077548980713 | KNN Loss: 3.6239399909973145 | CLS Loss: 0.010137457400560379\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 3.634540319442749 | KNN Loss: 3.617446184158325 | CLS Loss: 0.0170942023396492\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 3.6013851165771484 | KNN Loss: 3.5970489978790283 | CLS Loss: 0.004336235113441944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 3.6160988807678223 | KNN Loss: 3.6098179817199707 | CLS Loss: 0.006280964706093073\n",
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 3.5975704193115234 | KNN Loss: 3.5949535369873047 | CLS Loss: 0.002616843208670616\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 3.6131083965301514 | KNN Loss: 3.61004376411438 | CLS Loss: 0.0030646156519651413\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 3.576046943664551 | KNN Loss: 3.5703213214874268 | CLS Loss: 0.005725712515413761\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 3.6134490966796875 | KNN Loss: 3.6017003059387207 | CLS Loss: 0.011748863384127617\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 3.640180826187134 | KNN Loss: 3.6360015869140625 | CLS Loss: 0.004179274197667837\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 3.6261119842529297 | KNN Loss: 3.6187703609466553 | CLS Loss: 0.007341707590967417\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 3.6968116760253906 | KNN Loss: 3.6741554737091064 | CLS Loss: 0.022656168788671494\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 3.648117780685425 | KNN Loss: 3.6213009357452393 | CLS Loss: 0.02681674435734749\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 3.6246578693389893 | KNN Loss: 3.6012609004974365 | CLS Loss: 0.023396898061037064\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 3.6418297290802 | KNN Loss: 3.602848768234253 | CLS Loss: 0.03898096829652786\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 3.6208508014678955 | KNN Loss: 3.60787034034729 | CLS Loss: 0.012980367988348007\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 3.636594772338867 | KNN Loss: 3.6069421768188477 | CLS Loss: 0.02965247631072998\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 3.603438377380371 | KNN Loss: 3.5972516536712646 | CLS Loss: 0.0061867511831223965\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 3.6082465648651123 | KNN Loss: 3.603179931640625 | CLS Loss: 0.005066626239567995\n",
      "Epoch: 109, Loss: 3.6230, Train: 0.9958, Valid: 0.9856, Best: 0.9872\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 3.610246181488037 | KNN Loss: 3.603264570236206 | CLS Loss: 0.006981713231652975\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 3.635441780090332 | KNN Loss: 3.627446413040161 | CLS Loss: 0.007995263673365116\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 3.5776357650756836 | KNN Loss: 3.574199676513672 | CLS Loss: 0.0034359872806817293\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 3.639417886734009 | KNN Loss: 3.616837978363037 | CLS Loss: 0.022579919546842575\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 3.6123464107513428 | KNN Loss: 3.597057580947876 | CLS Loss: 0.015288776718080044\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 3.631187677383423 | KNN Loss: 3.6028971672058105 | CLS Loss: 0.02829059213399887\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 3.5730245113372803 | KNN Loss: 3.5642917156219482 | CLS Loss: 0.008732705377042294\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 3.5812652111053467 | KNN Loss: 3.5748651027679443 | CLS Loss: 0.006400166545063257\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 3.5874030590057373 | KNN Loss: 3.5732438564300537 | CLS Loss: 0.014159245416522026\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 3.619267225265503 | KNN Loss: 3.600097894668579 | CLS Loss: 0.01916937157511711\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 3.6143457889556885 | KNN Loss: 3.595104932785034 | CLS Loss: 0.019240794703364372\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 3.6782286167144775 | KNN Loss: 3.6638495922088623 | CLS Loss: 0.014379116706550121\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 3.627258777618408 | KNN Loss: 3.6069047451019287 | CLS Loss: 0.020353930070996284\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 3.626115560531616 | KNN Loss: 3.609316349029541 | CLS Loss: 0.016799261793494225\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 3.6226887702941895 | KNN Loss: 3.609574794769287 | CLS Loss: 0.013113975524902344\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 3.6209373474121094 | KNN Loss: 3.6100504398345947 | CLS Loss: 0.01088696625083685\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 3.6336703300476074 | KNN Loss: 3.603773832321167 | CLS Loss: 0.029896415770053864\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 3.636957883834839 | KNN Loss: 3.6310555934906006 | CLS Loss: 0.005902231205254793\n",
      "Epoch: 110, Loss: 3.6184, Train: 0.9963, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 3.6025588512420654 | KNN Loss: 3.5968360900878906 | CLS Loss: 0.0057227821089327335\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 3.634514093399048 | KNN Loss: 3.6176095008850098 | CLS Loss: 0.016904566437005997\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 3.6066935062408447 | KNN Loss: 3.6007189750671387 | CLS Loss: 0.00597453024238348\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 3.5932118892669678 | KNN Loss: 3.584453821182251 | CLS Loss: 0.008758148178458214\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 3.597973108291626 | KNN Loss: 3.5920779705047607 | CLS Loss: 0.005895174108445644\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 3.6705734729766846 | KNN Loss: 3.667856216430664 | CLS Loss: 0.0027171699330210686\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 3.650148391723633 | KNN Loss: 3.6255085468292236 | CLS Loss: 0.024639924988150597\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 3.6464712619781494 | KNN Loss: 3.630998134613037 | CLS Loss: 0.015473018400371075\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 3.627695083618164 | KNN Loss: 3.6075947284698486 | CLS Loss: 0.020100368186831474\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 3.6202890872955322 | KNN Loss: 3.603573799133301 | CLS Loss: 0.01671535335481167\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 3.6011009216308594 | KNN Loss: 3.5978429317474365 | CLS Loss: 0.003257924458011985\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 3.6115386486053467 | KNN Loss: 3.602353811264038 | CLS Loss: 0.009184759110212326\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 3.662628173828125 | KNN Loss: 3.6451632976531982 | CLS Loss: 0.017464758828282356\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 3.617123603820801 | KNN Loss: 3.5979573726654053 | CLS Loss: 0.01916634663939476\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 3.609307050704956 | KNN Loss: 3.588313579559326 | CLS Loss: 0.020993568003177643\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 3.6131787300109863 | KNN Loss: 3.6032447814941406 | CLS Loss: 0.00993389543145895\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 3.6643924713134766 | KNN Loss: 3.6488919258117676 | CLS Loss: 0.015500572510063648\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 3.6445672512054443 | KNN Loss: 3.6337153911590576 | CLS Loss: 0.010851879604160786\n",
      "Epoch: 111, Loss: 3.6244, Train: 0.9957, Valid: 0.9854, Best: 0.9872\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 3.6015889644622803 | KNN Loss: 3.5967910289764404 | CLS Loss: 0.004797979258000851\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 3.6101324558258057 | KNN Loss: 3.5968434810638428 | CLS Loss: 0.01328887976706028\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 3.5833535194396973 | KNN Loss: 3.5805935859680176 | CLS Loss: 0.002760001691058278\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 3.626622200012207 | KNN Loss: 3.6105241775512695 | CLS Loss: 0.016098113730549812\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 3.6129791736602783 | KNN Loss: 3.58842396736145 | CLS Loss: 0.024555176496505737\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 3.6001980304718018 | KNN Loss: 3.5952529907226562 | CLS Loss: 0.004945082124322653\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 3.6081299781799316 | KNN Loss: 3.595127820968628 | CLS Loss: 0.013002267107367516\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 3.5850515365600586 | KNN Loss: 3.580721378326416 | CLS Loss: 0.004330058582127094\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 3.576404094696045 | KNN Loss: 3.568028450012207 | CLS Loss: 0.008375570178031921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 3.6001713275909424 | KNN Loss: 3.5960514545440674 | CLS Loss: 0.004119829274713993\n",
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 3.690674066543579 | KNN Loss: 3.6427431106567383 | CLS Loss: 0.04793107137084007\n",
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 3.6179661750793457 | KNN Loss: 3.613675832748413 | CLS Loss: 0.004290330223739147\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 3.6199963092803955 | KNN Loss: 3.5862138271331787 | CLS Loss: 0.03378257900476456\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 3.6557350158691406 | KNN Loss: 3.653904914855957 | CLS Loss: 0.0018300311639904976\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 3.594385862350464 | KNN Loss: 3.5854032039642334 | CLS Loss: 0.008982697501778603\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 3.666994094848633 | KNN Loss: 3.6585443019866943 | CLS Loss: 0.008449867367744446\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 3.6430749893188477 | KNN Loss: 3.620105266571045 | CLS Loss: 0.022969728335738182\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 3.633082866668701 | KNN Loss: 3.6266860961914062 | CLS Loss: 0.006396777927875519\n",
      "Epoch: 112, Loss: 3.6215, Train: 0.9964, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 3.6041388511657715 | KNN Loss: 3.5953924655914307 | CLS Loss: 0.008746477775275707\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 3.587847948074341 | KNN Loss: 3.5764803886413574 | CLS Loss: 0.011367592960596085\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 3.6142890453338623 | KNN Loss: 3.6090078353881836 | CLS Loss: 0.0052812835201621056\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 3.600301742553711 | KNN Loss: 3.5883827209472656 | CLS Loss: 0.01191908773034811\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 3.589782953262329 | KNN Loss: 3.586043119430542 | CLS Loss: 0.0037398540880531073\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 3.6233038902282715 | KNN Loss: 3.6012585163116455 | CLS Loss: 0.022045383229851723\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 3.6309304237365723 | KNN Loss: 3.6264219284057617 | CLS Loss: 0.004508515354245901\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 3.6135289669036865 | KNN Loss: 3.612050771713257 | CLS Loss: 0.0014781658537685871\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 3.61083722114563 | KNN Loss: 3.600889205932617 | CLS Loss: 0.009947903454303741\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 3.6141629219055176 | KNN Loss: 3.602921724319458 | CLS Loss: 0.011241287924349308\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 3.5749294757843018 | KNN Loss: 3.573291063308716 | CLS Loss: 0.0016384627670049667\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 3.6083667278289795 | KNN Loss: 3.597348690032959 | CLS Loss: 0.011018097400665283\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 3.6084611415863037 | KNN Loss: 3.5920932292938232 | CLS Loss: 0.01636798307299614\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 3.6429641246795654 | KNN Loss: 3.621368169784546 | CLS Loss: 0.021595915779471397\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 3.6402602195739746 | KNN Loss: 3.5887022018432617 | CLS Loss: 0.051557984203100204\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 3.6157031059265137 | KNN Loss: 3.6054229736328125 | CLS Loss: 0.010280237533152103\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 3.611753463745117 | KNN Loss: 3.5919759273529053 | CLS Loss: 0.01977759599685669\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 3.6885673999786377 | KNN Loss: 3.6586012840270996 | CLS Loss: 0.02996612712740898\n",
      "Epoch: 113, Loss: 3.6182, Train: 0.9972, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 3.6505537033081055 | KNN Loss: 3.640566825866699 | CLS Loss: 0.00998683925718069\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 3.6335012912750244 | KNN Loss: 3.598010301589966 | CLS Loss: 0.03549095243215561\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 3.65144681930542 | KNN Loss: 3.63751482963562 | CLS Loss: 0.013932077214121819\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 3.715080976486206 | KNN Loss: 3.6978282928466797 | CLS Loss: 0.017252588644623756\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 3.6365549564361572 | KNN Loss: 3.621446371078491 | CLS Loss: 0.01510867290198803\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 3.607649803161621 | KNN Loss: 3.589514970779419 | CLS Loss: 0.01813475601375103\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 3.5993359088897705 | KNN Loss: 3.5875351428985596 | CLS Loss: 0.011800801381468773\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 3.6014597415924072 | KNN Loss: 3.5918095111846924 | CLS Loss: 0.009650254622101784\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 3.707756757736206 | KNN Loss: 3.6792800426483154 | CLS Loss: 0.02847667969763279\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 3.6331963539123535 | KNN Loss: 3.6095151901245117 | CLS Loss: 0.02368124946951866\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 3.588427782058716 | KNN Loss: 3.579444646835327 | CLS Loss: 0.008983056992292404\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 3.629178285598755 | KNN Loss: 3.614993095397949 | CLS Loss: 0.014185287058353424\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 3.622297525405884 | KNN Loss: 3.605320930480957 | CLS Loss: 0.016976574435830116\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 3.5823042392730713 | KNN Loss: 3.578418493270874 | CLS Loss: 0.0038857366889715195\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 3.617645025253296 | KNN Loss: 3.5961878299713135 | CLS Loss: 0.021457312628626823\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 3.6128990650177 | KNN Loss: 3.598587989807129 | CLS Loss: 0.014311018399894238\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 3.6271936893463135 | KNN Loss: 3.603410005569458 | CLS Loss: 0.02378375083208084\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 3.6409783363342285 | KNN Loss: 3.629460096359253 | CLS Loss: 0.011518350802361965\n",
      "Epoch: 114, Loss: 3.6216, Train: 0.9968, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 3.606172561645508 | KNN Loss: 3.5976967811584473 | CLS Loss: 0.008475766517221928\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 3.6247637271881104 | KNN Loss: 3.617319345474243 | CLS Loss: 0.007444269489496946\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 3.604353189468384 | KNN Loss: 3.601478338241577 | CLS Loss: 0.002874750178307295\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 3.616421937942505 | KNN Loss: 3.583843231201172 | CLS Loss: 0.03257870301604271\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 3.647789478302002 | KNN Loss: 3.6353466510772705 | CLS Loss: 0.012442734092473984\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 3.596184492111206 | KNN Loss: 3.5907704830169678 | CLS Loss: 0.005413963459432125\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 3.6659817695617676 | KNN Loss: 3.633798599243164 | CLS Loss: 0.032183222472667694\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 3.6103155612945557 | KNN Loss: 3.607473850250244 | CLS Loss: 0.002841765061020851\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 3.63187575340271 | KNN Loss: 3.621344804763794 | CLS Loss: 0.010531052947044373\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 3.6214797496795654 | KNN Loss: 3.6148626804351807 | CLS Loss: 0.0066169798374176025\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 3.641159772872925 | KNN Loss: 3.627779006958008 | CLS Loss: 0.01338066067546606\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 3.6456692218780518 | KNN Loss: 3.6268553733825684 | CLS Loss: 0.018813906237483025\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 3.6013355255126953 | KNN Loss: 3.5826539993286133 | CLS Loss: 0.01868145540356636\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 3.61374568939209 | KNN Loss: 3.6052000522613525 | CLS Loss: 0.008545726537704468\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 3.6245758533477783 | KNN Loss: 3.59907603263855 | CLS Loss: 0.025499850511550903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 3.667391300201416 | KNN Loss: 3.659186363220215 | CLS Loss: 0.008204974234104156\n",
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 3.6423676013946533 | KNN Loss: 3.6119027137756348 | CLS Loss: 0.030464958399534225\n",
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 3.674896478652954 | KNN Loss: 3.6354258060455322 | CLS Loss: 0.039470698684453964\n",
      "Epoch: 115, Loss: 3.6166, Train: 0.9967, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 3.5990591049194336 | KNN Loss: 3.5933303833007812 | CLS Loss: 0.00572860985994339\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 3.6124744415283203 | KNN Loss: 3.585911512374878 | CLS Loss: 0.026562850922346115\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 3.6149215698242188 | KNN Loss: 3.6072356700897217 | CLS Loss: 0.007685820106416941\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 3.606109142303467 | KNN Loss: 3.587613344192505 | CLS Loss: 0.01849576272070408\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 3.6060030460357666 | KNN Loss: 3.602444648742676 | CLS Loss: 0.003558426396921277\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 3.6831843852996826 | KNN Loss: 3.673351764678955 | CLS Loss: 0.009832682088017464\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 3.6073837280273438 | KNN Loss: 3.590327024459839 | CLS Loss: 0.017056768760085106\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 3.699251651763916 | KNN Loss: 3.6837916374206543 | CLS Loss: 0.015460041351616383\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 3.61566162109375 | KNN Loss: 3.593437433242798 | CLS Loss: 0.022224269807338715\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 3.670618772506714 | KNN Loss: 3.6600143909454346 | CLS Loss: 0.010604407638311386\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 3.613780975341797 | KNN Loss: 3.6105942726135254 | CLS Loss: 0.0031867444049566984\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 3.596635341644287 | KNN Loss: 3.5880277156829834 | CLS Loss: 0.008607730269432068\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 3.579561471939087 | KNN Loss: 3.575845241546631 | CLS Loss: 0.00371633586473763\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 3.6548404693603516 | KNN Loss: 3.647165536880493 | CLS Loss: 0.007674963679164648\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 3.6923582553863525 | KNN Loss: 3.686546564102173 | CLS Loss: 0.0058117760345339775\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 3.5986227989196777 | KNN Loss: 3.5793650150299072 | CLS Loss: 0.019257809966802597\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 3.672196626663208 | KNN Loss: 3.6517064571380615 | CLS Loss: 0.020490089431405067\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 3.632664680480957 | KNN Loss: 3.6221868991851807 | CLS Loss: 0.010477733798325062\n",
      "Epoch: 116, Loss: 3.6195, Train: 0.9967, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 3.5967776775360107 | KNN Loss: 3.5938377380371094 | CLS Loss: 0.0029400072526186705\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 3.636195421218872 | KNN Loss: 3.6237926483154297 | CLS Loss: 0.012402869760990143\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 3.6223340034484863 | KNN Loss: 3.602825880050659 | CLS Loss: 0.019508179277181625\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 3.6696512699127197 | KNN Loss: 3.6353986263275146 | CLS Loss: 0.034252557903528214\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 3.5777769088745117 | KNN Loss: 3.5740320682525635 | CLS Loss: 0.003744811052456498\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 3.638192892074585 | KNN Loss: 3.618387460708618 | CLS Loss: 0.019805414602160454\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 3.600660562515259 | KNN Loss: 3.597271680831909 | CLS Loss: 0.003388933138921857\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 3.6299853324890137 | KNN Loss: 3.6106293201446533 | CLS Loss: 0.019356101751327515\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 3.609081506729126 | KNN Loss: 3.601875066757202 | CLS Loss: 0.007206376641988754\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 3.574967861175537 | KNN Loss: 3.572087049484253 | CLS Loss: 0.002880866639316082\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 3.608874797821045 | KNN Loss: 3.606600761413574 | CLS Loss: 0.0022740522399544716\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 3.58868145942688 | KNN Loss: 3.5770483016967773 | CLS Loss: 0.011633050628006458\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 3.607917308807373 | KNN Loss: 3.597529172897339 | CLS Loss: 0.010388180613517761\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 3.619931697845459 | KNN Loss: 3.6163525581359863 | CLS Loss: 0.0035790575202554464\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 3.6993930339813232 | KNN Loss: 3.668114423751831 | CLS Loss: 0.03127851337194443\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 3.6249027252197266 | KNN Loss: 3.6062450408935547 | CLS Loss: 0.018657751381397247\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 3.620596408843994 | KNN Loss: 3.5968687534332275 | CLS Loss: 0.02372768335044384\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 3.6259751319885254 | KNN Loss: 3.5992989540100098 | CLS Loss: 0.026676064357161522\n",
      "Epoch: 117, Loss: 3.6177, Train: 0.9969, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 3.5708820819854736 | KNN Loss: 3.5671186447143555 | CLS Loss: 0.003763413755223155\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 3.602874279022217 | KNN Loss: 3.5911898612976074 | CLS Loss: 0.011684316210448742\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 3.5928242206573486 | KNN Loss: 3.589930534362793 | CLS Loss: 0.0028937801253050566\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 3.6415038108825684 | KNN Loss: 3.6308765411376953 | CLS Loss: 0.01062722411006689\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 3.601243495941162 | KNN Loss: 3.5837323665618896 | CLS Loss: 0.01751107908785343\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 3.637112617492676 | KNN Loss: 3.617591142654419 | CLS Loss: 0.019521355628967285\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 3.593757152557373 | KNN Loss: 3.5875637531280518 | CLS Loss: 0.006193408742547035\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 3.587462902069092 | KNN Loss: 3.5840003490448 | CLS Loss: 0.0034626636188477278\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 3.5721304416656494 | KNN Loss: 3.5653555393218994 | CLS Loss: 0.006774913985282183\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 3.6397433280944824 | KNN Loss: 3.621654748916626 | CLS Loss: 0.018088651821017265\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 3.6287662982940674 | KNN Loss: 3.621406078338623 | CLS Loss: 0.0073601496405899525\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 3.6591291427612305 | KNN Loss: 3.652604341506958 | CLS Loss: 0.0065247369930148125\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 3.604755401611328 | KNN Loss: 3.5941593647003174 | CLS Loss: 0.010596048086881638\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 3.634125232696533 | KNN Loss: 3.6254806518554688 | CLS Loss: 0.008644677698612213\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 3.639486074447632 | KNN Loss: 3.61946439743042 | CLS Loss: 0.02002178318798542\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 3.6144747734069824 | KNN Loss: 3.5987634658813477 | CLS Loss: 0.01571120321750641\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 3.617866039276123 | KNN Loss: 3.585702896118164 | CLS Loss: 0.03216313198208809\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 3.5844171047210693 | KNN Loss: 3.579457998275757 | CLS Loss: 0.004959132522344589\n",
      "Epoch: 118, Loss: 3.6144, Train: 0.9972, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 3.6233601570129395 | KNN Loss: 3.62188720703125 | CLS Loss: 0.0014730473048985004\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 3.603872776031494 | KNN Loss: 3.590463638305664 | CLS Loss: 0.013409235514700413\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 3.602893352508545 | KNN Loss: 3.5987796783447266 | CLS Loss: 0.004113661125302315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 3.5880138874053955 | KNN Loss: 3.586416482925415 | CLS Loss: 0.0015974962152540684\n",
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 3.669332265853882 | KNN Loss: 3.6591172218322754 | CLS Loss: 0.01021499466150999\n",
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 3.6062562465667725 | KNN Loss: 3.5904457569122314 | CLS Loss: 0.01581037975847721\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 3.6290996074676514 | KNN Loss: 3.606717348098755 | CLS Loss: 0.02238227240741253\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 3.6070291996002197 | KNN Loss: 3.5953526496887207 | CLS Loss: 0.011676636524498463\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 3.617767572402954 | KNN Loss: 3.5971200466156006 | CLS Loss: 0.020647641271352768\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 3.596949577331543 | KNN Loss: 3.5942912101745605 | CLS Loss: 0.0026583196595311165\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 3.625966787338257 | KNN Loss: 3.6220486164093018 | CLS Loss: 0.003918268717825413\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 3.6297597885131836 | KNN Loss: 3.626126289367676 | CLS Loss: 0.0036334518808871508\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 3.600921630859375 | KNN Loss: 3.587517499923706 | CLS Loss: 0.013404153287410736\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 3.6271181106567383 | KNN Loss: 3.6192123889923096 | CLS Loss: 0.007905833423137665\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 3.5899720191955566 | KNN Loss: 3.573007106781006 | CLS Loss: 0.0169648639857769\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 3.616152048110962 | KNN Loss: 3.6107776165008545 | CLS Loss: 0.005374432075768709\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 3.6237714290618896 | KNN Loss: 3.6028032302856445 | CLS Loss: 0.020968101918697357\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 3.6663451194763184 | KNN Loss: 3.6513617038726807 | CLS Loss: 0.014983524568378925\n",
      "Epoch: 119, Loss: 3.6161, Train: 0.9966, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 3.6631710529327393 | KNN Loss: 3.6414971351623535 | CLS Loss: 0.021673932671546936\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 3.6159512996673584 | KNN Loss: 3.606463670730591 | CLS Loss: 0.009487682022154331\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 3.611769199371338 | KNN Loss: 3.5924952030181885 | CLS Loss: 0.01927397958934307\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 3.6246979236602783 | KNN Loss: 3.6022698879241943 | CLS Loss: 0.022427964955568314\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 3.6010518074035645 | KNN Loss: 3.588681697845459 | CLS Loss: 0.012370161712169647\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 3.609466314315796 | KNN Loss: 3.6082193851470947 | CLS Loss: 0.001246852451004088\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 3.6190576553344727 | KNN Loss: 3.6122405529022217 | CLS Loss: 0.006817190907895565\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 3.5808115005493164 | KNN Loss: 3.5776476860046387 | CLS Loss: 0.0031638704240322113\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 3.630871534347534 | KNN Loss: 3.6122446060180664 | CLS Loss: 0.018626954406499863\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 3.631476879119873 | KNN Loss: 3.625617027282715 | CLS Loss: 0.005859924014657736\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 3.6269850730895996 | KNN Loss: 3.6170248985290527 | CLS Loss: 0.009960229508578777\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 3.6127257347106934 | KNN Loss: 3.5941696166992188 | CLS Loss: 0.018556036055088043\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 3.596191167831421 | KNN Loss: 3.592276096343994 | CLS Loss: 0.0039151739329099655\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 3.649559736251831 | KNN Loss: 3.6223037242889404 | CLS Loss: 0.027255915105342865\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 3.6252992153167725 | KNN Loss: 3.614956855773926 | CLS Loss: 0.010342242196202278\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 3.5861380100250244 | KNN Loss: 3.581266164779663 | CLS Loss: 0.004871932324022055\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 3.610085964202881 | KNN Loss: 3.5974810123443604 | CLS Loss: 0.012605056166648865\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 3.613912343978882 | KNN Loss: 3.587550163269043 | CLS Loss: 0.026362229138612747\n",
      "Epoch: 120, Loss: 3.6196, Train: 0.9962, Valid: 0.9845, Best: 0.9873\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 3.621675968170166 | KNN Loss: 3.617452621459961 | CLS Loss: 0.00422339653596282\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 3.631197452545166 | KNN Loss: 3.620736837387085 | CLS Loss: 0.010460522957146168\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 3.5820584297180176 | KNN Loss: 3.555781364440918 | CLS Loss: 0.026277124881744385\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 3.64180326461792 | KNN Loss: 3.6181652545928955 | CLS Loss: 0.02363796904683113\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 3.6111698150634766 | KNN Loss: 3.60617995262146 | CLS Loss: 0.004989964421838522\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 3.638862371444702 | KNN Loss: 3.630138874053955 | CLS Loss: 0.008723560720682144\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 3.5935299396514893 | KNN Loss: 3.5903759002685547 | CLS Loss: 0.0031541120260953903\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 3.5890791416168213 | KNN Loss: 3.5823605060577393 | CLS Loss: 0.006718732882291079\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 3.6448235511779785 | KNN Loss: 3.614666223526001 | CLS Loss: 0.030157215893268585\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 3.6229894161224365 | KNN Loss: 3.6068637371063232 | CLS Loss: 0.016125721856951714\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 3.6383144855499268 | KNN Loss: 3.618527412414551 | CLS Loss: 0.019787127152085304\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 3.637035608291626 | KNN Loss: 3.6222596168518066 | CLS Loss: 0.014775946736335754\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 3.597928047180176 | KNN Loss: 3.591635227203369 | CLS Loss: 0.006292914971709251\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 3.6705496311187744 | KNN Loss: 3.660179853439331 | CLS Loss: 0.010369832627475262\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 3.6005492210388184 | KNN Loss: 3.5948221683502197 | CLS Loss: 0.005727021023631096\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 3.569634437561035 | KNN Loss: 3.5638632774353027 | CLS Loss: 0.005771128926426172\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 3.617985248565674 | KNN Loss: 3.600694417953491 | CLS Loss: 0.017290879040956497\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 3.6451706886291504 | KNN Loss: 3.6287548542022705 | CLS Loss: 0.016415845602750778\n",
      "Epoch: 121, Loss: 3.6211, Train: 0.9950, Valid: 0.9836, Best: 0.9873\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 3.623906135559082 | KNN Loss: 3.611704111099243 | CLS Loss: 0.01220210362225771\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 3.6550354957580566 | KNN Loss: 3.64748477935791 | CLS Loss: 0.007550814654678106\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 3.5959677696228027 | KNN Loss: 3.591871500015259 | CLS Loss: 0.004096320830285549\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 3.650303840637207 | KNN Loss: 3.640522003173828 | CLS Loss: 0.009781870059669018\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 3.596003532409668 | KNN Loss: 3.5915541648864746 | CLS Loss: 0.004449271596968174\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 3.6428425312042236 | KNN Loss: 3.6369102001190186 | CLS Loss: 0.005932328756898642\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 3.6364760398864746 | KNN Loss: 3.6183974742889404 | CLS Loss: 0.01807853952050209\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 3.6092758178710938 | KNN Loss: 3.5955042839050293 | CLS Loss: 0.013771436177194118\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 3.62729811668396 | KNN Loss: 3.6140964031219482 | CLS Loss: 0.013201791793107986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 3.6284444332122803 | KNN Loss: 3.6070897579193115 | CLS Loss: 0.021354753524065018\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 3.6197142601013184 | KNN Loss: 3.590127468109131 | CLS Loss: 0.02958681434392929\n",
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 3.6331405639648438 | KNN Loss: 3.60144305229187 | CLS Loss: 0.03169739618897438\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 3.637389659881592 | KNN Loss: 3.6289987564086914 | CLS Loss: 0.008390932343900204\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 3.6075961589813232 | KNN Loss: 3.6012182235717773 | CLS Loss: 0.0063778311014175415\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 3.682307004928589 | KNN Loss: 3.6609835624694824 | CLS Loss: 0.02132345549762249\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 3.6095097064971924 | KNN Loss: 3.5997941493988037 | CLS Loss: 0.009715652093291283\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 3.629939556121826 | KNN Loss: 3.615006446838379 | CLS Loss: 0.01493319496512413\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 3.657822847366333 | KNN Loss: 3.642971992492676 | CLS Loss: 0.0148509182035923\n",
      "Epoch: 122, Loss: 3.6225, Train: 0.9963, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 3.6062052249908447 | KNN Loss: 3.6046693325042725 | CLS Loss: 0.0015359384706243873\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 3.612872838973999 | KNN Loss: 3.6005618572235107 | CLS Loss: 0.012310968711972237\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 3.6504149436950684 | KNN Loss: 3.6160519123077393 | CLS Loss: 0.03436306118965149\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 3.6590416431427 | KNN Loss: 3.6362946033477783 | CLS Loss: 0.022747131064534187\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 3.613035202026367 | KNN Loss: 3.6006436347961426 | CLS Loss: 0.012391583062708378\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 3.597356081008911 | KNN Loss: 3.594763994216919 | CLS Loss: 0.0025919857434928417\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 3.639206886291504 | KNN Loss: 3.6316819190979004 | CLS Loss: 0.007525019813328981\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 3.653294563293457 | KNN Loss: 3.6388423442840576 | CLS Loss: 0.014452244155108929\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 3.604447841644287 | KNN Loss: 3.5942745208740234 | CLS Loss: 0.01017331425100565\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 3.622474431991577 | KNN Loss: 3.5989928245544434 | CLS Loss: 0.023481562733650208\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 3.6430251598358154 | KNN Loss: 3.628802537918091 | CLS Loss: 0.0142225231975317\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 3.633159637451172 | KNN Loss: 3.619093179702759 | CLS Loss: 0.014066524803638458\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 3.6240923404693604 | KNN Loss: 3.6178131103515625 | CLS Loss: 0.00627924082800746\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 3.6550581455230713 | KNN Loss: 3.630875825881958 | CLS Loss: 0.02418242022395134\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 3.662954330444336 | KNN Loss: 3.652604103088379 | CLS Loss: 0.010350161232054234\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 3.644937753677368 | KNN Loss: 3.6179075241088867 | CLS Loss: 0.02703033573925495\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 3.5952532291412354 | KNN Loss: 3.581555128097534 | CLS Loss: 0.013698102906346321\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 3.582317352294922 | KNN Loss: 3.5802347660064697 | CLS Loss: 0.002082651946693659\n",
      "Epoch: 123, Loss: 3.6222, Train: 0.9970, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 3.6227777004241943 | KNN Loss: 3.5837759971618652 | CLS Loss: 0.039001621305942535\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 3.6369872093200684 | KNN Loss: 3.6178154945373535 | CLS Loss: 0.019171832129359245\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 3.6541435718536377 | KNN Loss: 3.6420023441314697 | CLS Loss: 0.012141330167651176\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 3.621696710586548 | KNN Loss: 3.615483283996582 | CLS Loss: 0.006213395856320858\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 3.6122548580169678 | KNN Loss: 3.608922004699707 | CLS Loss: 0.003332967171445489\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 3.6027772426605225 | KNN Loss: 3.599490165710449 | CLS Loss: 0.003287132363766432\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 3.6574690341949463 | KNN Loss: 3.648289680480957 | CLS Loss: 0.009179315529763699\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 3.654935121536255 | KNN Loss: 3.6305222511291504 | CLS Loss: 0.024412760511040688\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 3.5834946632385254 | KNN Loss: 3.5768208503723145 | CLS Loss: 0.00667381240054965\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 3.6092822551727295 | KNN Loss: 3.603344202041626 | CLS Loss: 0.005938129033893347\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 3.5772266387939453 | KNN Loss: 3.573439121246338 | CLS Loss: 0.00378761300817132\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 3.6202139854431152 | KNN Loss: 3.6151163578033447 | CLS Loss: 0.005097676534205675\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 3.6301190853118896 | KNN Loss: 3.606236457824707 | CLS Loss: 0.023882586508989334\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 3.604743003845215 | KNN Loss: 3.5924057960510254 | CLS Loss: 0.012337190099060535\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 3.607811450958252 | KNN Loss: 3.5589959621429443 | CLS Loss: 0.04881541058421135\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 3.7327725887298584 | KNN Loss: 3.725645065307617 | CLS Loss: 0.00712743541225791\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 3.630553960800171 | KNN Loss: 3.6132619380950928 | CLS Loss: 0.017292045056819916\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 3.634467363357544 | KNN Loss: 3.631998062133789 | CLS Loss: 0.002469377825036645\n",
      "Epoch: 124, Loss: 3.6189, Train: 0.9966, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 3.5968894958496094 | KNN Loss: 3.5931758880615234 | CLS Loss: 0.0037135679740458727\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 3.5936460494995117 | KNN Loss: 3.588245153427124 | CLS Loss: 0.005400926806032658\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 3.5868403911590576 | KNN Loss: 3.5826289653778076 | CLS Loss: 0.004211308900266886\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 3.599841594696045 | KNN Loss: 3.5850112438201904 | CLS Loss: 0.014830294996500015\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 3.6189632415771484 | KNN Loss: 3.6055855751037598 | CLS Loss: 0.01337758544832468\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 3.6229946613311768 | KNN Loss: 3.604736804962158 | CLS Loss: 0.018257929012179375\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 3.642334461212158 | KNN Loss: 3.606863498687744 | CLS Loss: 0.03547084331512451\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 3.5793159008026123 | KNN Loss: 3.5625977516174316 | CLS Loss: 0.016718052327632904\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 3.5989670753479004 | KNN Loss: 3.5912907123565674 | CLS Loss: 0.007676368113607168\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 3.609217643737793 | KNN Loss: 3.603053569793701 | CLS Loss: 0.006164149381220341\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 3.616985321044922 | KNN Loss: 3.6070189476013184 | CLS Loss: 0.00996626541018486\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 3.5867061614990234 | KNN Loss: 3.5757412910461426 | CLS Loss: 0.01096496544778347\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 3.6137890815734863 | KNN Loss: 3.6025102138519287 | CLS Loss: 0.011278843507170677\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 3.628140449523926 | KNN Loss: 3.6140999794006348 | CLS Loss: 0.01404056791216135\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 3.6531851291656494 | KNN Loss: 3.601957082748413 | CLS Loss: 0.051228005439043045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 3.6021640300750732 | KNN Loss: 3.589186191558838 | CLS Loss: 0.012977758422493935\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 3.6385340690612793 | KNN Loss: 3.633214235305786 | CLS Loss: 0.005319810938090086\n",
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 3.6353070735931396 | KNN Loss: 3.5923147201538086 | CLS Loss: 0.042992401868104935\n",
      "Epoch: 125, Loss: 3.6209, Train: 0.9962, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 3.593187093734741 | KNN Loss: 3.5822174549102783 | CLS Loss: 0.010969581082463264\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 3.5845084190368652 | KNN Loss: 3.580240488052368 | CLS Loss: 0.004268005024641752\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 3.609532117843628 | KNN Loss: 3.6068239212036133 | CLS Loss: 0.0027080923318862915\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 3.6287171840667725 | KNN Loss: 3.6144731044769287 | CLS Loss: 0.01424402929842472\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 3.61871600151062 | KNN Loss: 3.605199098587036 | CLS Loss: 0.013517016544938087\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 3.666313648223877 | KNN Loss: 3.6457085609436035 | CLS Loss: 0.020605064928531647\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 3.614814519882202 | KNN Loss: 3.6121180057525635 | CLS Loss: 0.0026964328717440367\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 3.6151530742645264 | KNN Loss: 3.5962729454040527 | CLS Loss: 0.018880076706409454\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 3.649960517883301 | KNN Loss: 3.6455776691436768 | CLS Loss: 0.004382806364446878\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 3.5987868309020996 | KNN Loss: 3.595886468887329 | CLS Loss: 0.002900416264310479\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 3.6135096549987793 | KNN Loss: 3.601161241531372 | CLS Loss: 0.012348441407084465\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 3.5905654430389404 | KNN Loss: 3.578711748123169 | CLS Loss: 0.011853775009512901\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 3.6282219886779785 | KNN Loss: 3.615461587905884 | CLS Loss: 0.012760414741933346\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 3.5812323093414307 | KNN Loss: 3.5729103088378906 | CLS Loss: 0.008322067558765411\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 3.5997366905212402 | KNN Loss: 3.595891237258911 | CLS Loss: 0.0038454155437648296\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 3.585137128829956 | KNN Loss: 3.576115608215332 | CLS Loss: 0.009021411649882793\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 3.625009775161743 | KNN Loss: 3.6082355976104736 | CLS Loss: 0.016774170100688934\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 3.594526767730713 | KNN Loss: 3.5901644229888916 | CLS Loss: 0.00436245184391737\n",
      "Epoch: 126, Loss: 3.6132, Train: 0.9972, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 3.5876035690307617 | KNN Loss: 3.579702377319336 | CLS Loss: 0.007901078090071678\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 3.6052255630493164 | KNN Loss: 3.5849990844726562 | CLS Loss: 0.020226381719112396\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 3.616422414779663 | KNN Loss: 3.6064133644104004 | CLS Loss: 0.01000907365232706\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 3.609757900238037 | KNN Loss: 3.5979793071746826 | CLS Loss: 0.01177859865128994\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 3.622556447982788 | KNN Loss: 3.619598627090454 | CLS Loss: 0.002957858145236969\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 3.657235860824585 | KNN Loss: 3.6454355716705322 | CLS Loss: 0.011800314299762249\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 3.589888572692871 | KNN Loss: 3.5812413692474365 | CLS Loss: 0.008647211827337742\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 3.6343536376953125 | KNN Loss: 3.624122142791748 | CLS Loss: 0.010231589898467064\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 3.5955517292022705 | KNN Loss: 3.5833780765533447 | CLS Loss: 0.01217361818999052\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 3.590158700942993 | KNN Loss: 3.5824501514434814 | CLS Loss: 0.007708484772592783\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 3.5922980308532715 | KNN Loss: 3.5845248699188232 | CLS Loss: 0.007773214019834995\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 3.5925755500793457 | KNN Loss: 3.5848758220672607 | CLS Loss: 0.007699803914874792\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 3.634614944458008 | KNN Loss: 3.611128091812134 | CLS Loss: 0.02348693273961544\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 3.6001315116882324 | KNN Loss: 3.5851011276245117 | CLS Loss: 0.015030301176011562\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 3.588702440261841 | KNN Loss: 3.5699970722198486 | CLS Loss: 0.018705448135733604\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 3.575632333755493 | KNN Loss: 3.574445962905884 | CLS Loss: 0.001186472363770008\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 3.6682381629943848 | KNN Loss: 3.643860101699829 | CLS Loss: 0.024378154426813126\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 3.6664795875549316 | KNN Loss: 3.6410632133483887 | CLS Loss: 0.025416281074285507\n",
      "Epoch: 127, Loss: 3.6169, Train: 0.9958, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 3.6495778560638428 | KNN Loss: 3.6302528381347656 | CLS Loss: 0.019325127825140953\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 3.603219509124756 | KNN Loss: 3.587782859802246 | CLS Loss: 0.015436735935509205\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 3.70241379737854 | KNN Loss: 3.6853652000427246 | CLS Loss: 0.017048530280590057\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 3.568819284439087 | KNN Loss: 3.5547232627868652 | CLS Loss: 0.014096064493060112\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 3.6486780643463135 | KNN Loss: 3.6456458568573 | CLS Loss: 0.0030322622042149305\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 3.578695774078369 | KNN Loss: 3.5762929916381836 | CLS Loss: 0.0024027940817177296\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 3.580362319946289 | KNN Loss: 3.571655035018921 | CLS Loss: 0.008707326836884022\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 3.60032057762146 | KNN Loss: 3.5896859169006348 | CLS Loss: 0.0106347082182765\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 3.6193900108337402 | KNN Loss: 3.6163077354431152 | CLS Loss: 0.00308223650790751\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 3.6050233840942383 | KNN Loss: 3.58620023727417 | CLS Loss: 0.018823079764842987\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 3.5988612174987793 | KNN Loss: 3.597071886062622 | CLS Loss: 0.0017892755568027496\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 3.6282715797424316 | KNN Loss: 3.612410306930542 | CLS Loss: 0.015861304476857185\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 3.588437080383301 | KNN Loss: 3.5796475410461426 | CLS Loss: 0.008789563551545143\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 3.6775877475738525 | KNN Loss: 3.6672616004943848 | CLS Loss: 0.01032624114304781\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 3.619896650314331 | KNN Loss: 3.604719638824463 | CLS Loss: 0.015177075751125813\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 3.593487501144409 | KNN Loss: 3.582106590270996 | CLS Loss: 0.011380944401025772\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 3.610377073287964 | KNN Loss: 3.579561233520508 | CLS Loss: 0.030815811827778816\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 3.6668097972869873 | KNN Loss: 3.6531436443328857 | CLS Loss: 0.013666252605617046\n",
      "Epoch: 128, Loss: 3.6151, Train: 0.9970, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 3.6167991161346436 | KNN Loss: 3.613668203353882 | CLS Loss: 0.0031310105696320534\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 3.586965560913086 | KNN Loss: 3.5726828575134277 | CLS Loss: 0.01428278349339962\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 3.611079216003418 | KNN Loss: 3.6101932525634766 | CLS Loss: 0.0008859409135766327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 3.601958990097046 | KNN Loss: 3.6009514331817627 | CLS Loss: 0.0010076501639559865\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 3.5804295539855957 | KNN Loss: 3.5635340213775635 | CLS Loss: 0.01689557544887066\n",
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 3.595039129257202 | KNN Loss: 3.5880329608917236 | CLS Loss: 0.007006144616752863\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 3.587733507156372 | KNN Loss: 3.5782101154327393 | CLS Loss: 0.009523285552859306\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 3.6597046852111816 | KNN Loss: 3.6367604732513428 | CLS Loss: 0.022944152355194092\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 3.6338281631469727 | KNN Loss: 3.6102514266967773 | CLS Loss: 0.023576835170388222\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 3.6011688709259033 | KNN Loss: 3.593583345413208 | CLS Loss: 0.0075854165479540825\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 3.643890857696533 | KNN Loss: 3.6272475719451904 | CLS Loss: 0.016643395647406578\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 3.5984745025634766 | KNN Loss: 3.585533618927002 | CLS Loss: 0.012940851040184498\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 3.6541950702667236 | KNN Loss: 3.647063970565796 | CLS Loss: 0.0071310196071863174\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 3.5971152782440186 | KNN Loss: 3.5912091732025146 | CLS Loss: 0.005906003061681986\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 3.6244325637817383 | KNN Loss: 3.5935919284820557 | CLS Loss: 0.030840730294585228\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 3.6547625064849854 | KNN Loss: 3.6295573711395264 | CLS Loss: 0.02520522102713585\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 3.6478235721588135 | KNN Loss: 3.618560314178467 | CLS Loss: 0.029263200238347054\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 3.6075875759124756 | KNN Loss: 3.6003756523132324 | CLS Loss: 0.007211960386484861\n",
      "Epoch: 129, Loss: 3.6218, Train: 0.9952, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 3.572046995162964 | KNN Loss: 3.5657918453216553 | CLS Loss: 0.006255151703953743\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 3.5819013118743896 | KNN Loss: 3.565246820449829 | CLS Loss: 0.01665455661714077\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 3.6070258617401123 | KNN Loss: 3.6043481826782227 | CLS Loss: 0.0026777677703648806\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 3.620184898376465 | KNN Loss: 3.5981178283691406 | CLS Loss: 0.02206701971590519\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 3.5973060131073 | KNN Loss: 3.588697910308838 | CLS Loss: 0.008607989177107811\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 3.5872881412506104 | KNN Loss: 3.579057455062866 | CLS Loss: 0.008230679668486118\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 3.585062026977539 | KNN Loss: 3.5836374759674072 | CLS Loss: 0.001424470217898488\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 3.6664204597473145 | KNN Loss: 3.6545562744140625 | CLS Loss: 0.011864284053444862\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 3.6085352897644043 | KNN Loss: 3.5949554443359375 | CLS Loss: 0.013579841703176498\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 3.6039445400238037 | KNN Loss: 3.5958123207092285 | CLS Loss: 0.008132274262607098\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 3.649118661880493 | KNN Loss: 3.631481885910034 | CLS Loss: 0.017636705189943314\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 3.607795000076294 | KNN Loss: 3.594078779220581 | CLS Loss: 0.013716258108615875\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 3.6414973735809326 | KNN Loss: 3.6213200092315674 | CLS Loss: 0.02017727866768837\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 3.6018550395965576 | KNN Loss: 3.599045991897583 | CLS Loss: 0.0028089636471122503\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 3.6314644813537598 | KNN Loss: 3.6161839962005615 | CLS Loss: 0.0152805857360363\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 3.5990755558013916 | KNN Loss: 3.595635414123535 | CLS Loss: 0.003440231317654252\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 3.6488351821899414 | KNN Loss: 3.6338274478912354 | CLS Loss: 0.01500763837248087\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 3.6130833625793457 | KNN Loss: 3.597877025604248 | CLS Loss: 0.015206319279968739\n",
      "Epoch: 130, Loss: 3.6155, Train: 0.9972, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 3.670403003692627 | KNN Loss: 3.6668753623962402 | CLS Loss: 0.0035276771523058414\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 3.6113107204437256 | KNN Loss: 3.58793306350708 | CLS Loss: 0.023377733305096626\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 3.6221303939819336 | KNN Loss: 3.606823682785034 | CLS Loss: 0.015306616201996803\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 3.575456142425537 | KNN Loss: 3.563495635986328 | CLS Loss: 0.011960540898144245\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 3.664952278137207 | KNN Loss: 3.660588026046753 | CLS Loss: 0.004364257212728262\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 3.596308946609497 | KNN Loss: 3.5757362842559814 | CLS Loss: 0.020572740584611893\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 3.6083033084869385 | KNN Loss: 3.597566843032837 | CLS Loss: 0.010736565105617046\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 3.5859618186950684 | KNN Loss: 3.5842936038970947 | CLS Loss: 0.0016681617125868797\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 3.602318525314331 | KNN Loss: 3.594047784805298 | CLS Loss: 0.008270691148936749\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 3.6283838748931885 | KNN Loss: 3.6209986209869385 | CLS Loss: 0.007385237142443657\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 3.5909900665283203 | KNN Loss: 3.584087371826172 | CLS Loss: 0.006902620196342468\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 3.611870765686035 | KNN Loss: 3.594719171524048 | CLS Loss: 0.01715158298611641\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 3.5977606773376465 | KNN Loss: 3.5805137157440186 | CLS Loss: 0.017247000709176064\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 3.6322200298309326 | KNN Loss: 3.6141715049743652 | CLS Loss: 0.018048519268631935\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 3.6369519233703613 | KNN Loss: 3.6313748359680176 | CLS Loss: 0.005577003583312035\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 3.590616226196289 | KNN Loss: 3.582801342010498 | CLS Loss: 0.007814821787178516\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 3.593918800354004 | KNN Loss: 3.5740909576416016 | CLS Loss: 0.019827788695693016\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 3.617854356765747 | KNN Loss: 3.608661413192749 | CLS Loss: 0.00919291377067566\n",
      "Epoch: 131, Loss: 3.6137, Train: 0.9962, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 3.659501314163208 | KNN Loss: 3.6418046951293945 | CLS Loss: 0.017696563154459\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 3.6169610023498535 | KNN Loss: 3.6042706966400146 | CLS Loss: 0.012690399773418903\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 3.6270394325256348 | KNN Loss: 3.6169211864471436 | CLS Loss: 0.010118193924427032\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 3.6032044887542725 | KNN Loss: 3.5944976806640625 | CLS Loss: 0.008706916123628616\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 3.593568801879883 | KNN Loss: 3.5888779163360596 | CLS Loss: 0.004690867383033037\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 3.6470108032226562 | KNN Loss: 3.6274266242980957 | CLS Loss: 0.01958409883081913\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 3.6126012802124023 | KNN Loss: 3.6081905364990234 | CLS Loss: 0.004410766530781984\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 3.605128526687622 | KNN Loss: 3.591521978378296 | CLS Loss: 0.013606603257358074\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 3.6607792377471924 | KNN Loss: 3.6452796459198 | CLS Loss: 0.015499507077038288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 3.620718002319336 | KNN Loss: 3.5988247394561768 | CLS Loss: 0.021893350407481194\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 3.601369857788086 | KNN Loss: 3.593755006790161 | CLS Loss: 0.007614814210683107\n",
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 3.589838981628418 | KNN Loss: 3.5793421268463135 | CLS Loss: 0.010496850125491619\n",
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 3.6110453605651855 | KNN Loss: 3.602983236312866 | CLS Loss: 0.008062202483415604\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 3.6219592094421387 | KNN Loss: 3.61103892326355 | CLS Loss: 0.010920331813395023\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 3.6495277881622314 | KNN Loss: 3.63167405128479 | CLS Loss: 0.017853671684861183\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 3.6902642250061035 | KNN Loss: 3.668630838394165 | CLS Loss: 0.02163342945277691\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 3.624077081680298 | KNN Loss: 3.600379705429077 | CLS Loss: 0.023697281256318092\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 3.6464731693267822 | KNN Loss: 3.6417715549468994 | CLS Loss: 0.004701583180576563\n",
      "Epoch: 132, Loss: 3.6223, Train: 0.9966, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 3.6072113513946533 | KNN Loss: 3.596182346343994 | CLS Loss: 0.011029069311916828\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 3.649742841720581 | KNN Loss: 3.631138324737549 | CLS Loss: 0.0186044629663229\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 3.611018657684326 | KNN Loss: 3.5967133045196533 | CLS Loss: 0.014305292628705502\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 3.6129825115203857 | KNN Loss: 3.596784830093384 | CLS Loss: 0.01619771495461464\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 3.608935594558716 | KNN Loss: 3.583266019821167 | CLS Loss: 0.02566964365541935\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 3.598175048828125 | KNN Loss: 3.576869487762451 | CLS Loss: 0.021305540576577187\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 3.6378579139709473 | KNN Loss: 3.6305887699127197 | CLS Loss: 0.0072691431269049644\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 3.6358609199523926 | KNN Loss: 3.629631280899048 | CLS Loss: 0.006229610648006201\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 3.5864124298095703 | KNN Loss: 3.57985782623291 | CLS Loss: 0.006554597523063421\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 3.615663528442383 | KNN Loss: 3.608891248703003 | CLS Loss: 0.006772269960492849\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 3.6379759311676025 | KNN Loss: 3.625051498413086 | CLS Loss: 0.01292450726032257\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 3.6419148445129395 | KNN Loss: 3.620614528656006 | CLS Loss: 0.02130030281841755\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 3.602313280105591 | KNN Loss: 3.5999836921691895 | CLS Loss: 0.002329551614820957\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 3.600346565246582 | KNN Loss: 3.590275526046753 | CLS Loss: 0.010071038268506527\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 3.6066207885742188 | KNN Loss: 3.601363182067871 | CLS Loss: 0.005257637705653906\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 3.6387417316436768 | KNN Loss: 3.6328585147857666 | CLS Loss: 0.005883125588297844\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 3.588765859603882 | KNN Loss: 3.584134817123413 | CLS Loss: 0.0046310583129525185\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 3.631805896759033 | KNN Loss: 3.606779098510742 | CLS Loss: 0.025026779621839523\n",
      "Epoch: 133, Loss: 3.6180, Train: 0.9972, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 3.5941262245178223 | KNN Loss: 3.5891425609588623 | CLS Loss: 0.004983638878911734\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 3.6306374073028564 | KNN Loss: 3.6257221698760986 | CLS Loss: 0.004915256518870592\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 3.622375011444092 | KNN Loss: 3.621415853500366 | CLS Loss: 0.0009592648129910231\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 3.6310038566589355 | KNN Loss: 3.6005685329437256 | CLS Loss: 0.030435288324952126\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 3.6027066707611084 | KNN Loss: 3.601569652557373 | CLS Loss: 0.0011371019063517451\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 3.6067354679107666 | KNN Loss: 3.5765268802642822 | CLS Loss: 0.030208587646484375\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 3.5796267986297607 | KNN Loss: 3.5716030597686768 | CLS Loss: 0.008023634552955627\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 3.621555805206299 | KNN Loss: 3.612922191619873 | CLS Loss: 0.008633537217974663\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 3.5804553031921387 | KNN Loss: 3.5784177780151367 | CLS Loss: 0.0020375631283968687\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 3.609286308288574 | KNN Loss: 3.5993080139160156 | CLS Loss: 0.009978232905268669\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 3.5912563800811768 | KNN Loss: 3.5785861015319824 | CLS Loss: 0.012670249678194523\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 3.618375778198242 | KNN Loss: 3.582667827606201 | CLS Loss: 0.035708069801330566\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 3.6663105487823486 | KNN Loss: 3.65230655670166 | CLS Loss: 0.014004094526171684\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 3.6366357803344727 | KNN Loss: 3.624013900756836 | CLS Loss: 0.012621854431927204\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 3.679932117462158 | KNN Loss: 3.6629040241241455 | CLS Loss: 0.017028123140335083\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 3.634190082550049 | KNN Loss: 3.621380090713501 | CLS Loss: 0.01280987448990345\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 3.6020126342773438 | KNN Loss: 3.600247383117676 | CLS Loss: 0.001765164197422564\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 3.6170175075531006 | KNN Loss: 3.613097906112671 | CLS Loss: 0.003919526003301144\n",
      "Epoch: 134, Loss: 3.6223, Train: 0.9969, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 3.611284017562866 | KNN Loss: 3.604585886001587 | CLS Loss: 0.006698149256408215\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 3.6195521354675293 | KNN Loss: 3.5988638401031494 | CLS Loss: 0.020688310265541077\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 3.637712240219116 | KNN Loss: 3.625260591506958 | CLS Loss: 0.01245164219290018\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 3.5871384143829346 | KNN Loss: 3.5844600200653076 | CLS Loss: 0.00267848395742476\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 3.6115972995758057 | KNN Loss: 3.59938645362854 | CLS Loss: 0.012210884131491184\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 3.6444830894470215 | KNN Loss: 3.642115831375122 | CLS Loss: 0.0023671959061175585\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 3.5893521308898926 | KNN Loss: 3.5790679454803467 | CLS Loss: 0.010284257121384144\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 3.641014575958252 | KNN Loss: 3.615429639816284 | CLS Loss: 0.025585051625967026\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 3.612283945083618 | KNN Loss: 3.607374429702759 | CLS Loss: 0.004909542389214039\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 3.612389326095581 | KNN Loss: 3.5854763984680176 | CLS Loss: 0.026913033798336983\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 3.61293363571167 | KNN Loss: 3.5946900844573975 | CLS Loss: 0.018243612721562386\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 3.6219403743743896 | KNN Loss: 3.6054162979125977 | CLS Loss: 0.016524098813533783\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 3.628054141998291 | KNN Loss: 3.601623058319092 | CLS Loss: 0.026431065052747726\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 3.6528818607330322 | KNN Loss: 3.6415929794311523 | CLS Loss: 0.011288859881460667\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 3.6002590656280518 | KNN Loss: 3.587836742401123 | CLS Loss: 0.012422258034348488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 3.607530117034912 | KNN Loss: 3.600569009780884 | CLS Loss: 0.006961209233850241\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 3.5983974933624268 | KNN Loss: 3.58443546295166 | CLS Loss: 0.01396195963025093\n",
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 3.6272025108337402 | KNN Loss: 3.624633312225342 | CLS Loss: 0.0025690984912216663\n",
      "Epoch: 135, Loss: 3.6146, Train: 0.9981, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 3.580533504486084 | KNN Loss: 3.5670857429504395 | CLS Loss: 0.013447693549096584\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 3.5956010818481445 | KNN Loss: 3.582900047302246 | CLS Loss: 0.01270113606005907\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 3.6120312213897705 | KNN Loss: 3.607238292694092 | CLS Loss: 0.0047928267158567905\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 3.6065456867218018 | KNN Loss: 3.6039133071899414 | CLS Loss: 0.0026322815101593733\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 3.6655495166778564 | KNN Loss: 3.663740396499634 | CLS Loss: 0.0018090617377310991\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 3.5906641483306885 | KNN Loss: 3.5678300857543945 | CLS Loss: 0.02283402532339096\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 3.6109464168548584 | KNN Loss: 3.602983236312866 | CLS Loss: 0.007963196374475956\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 3.617664098739624 | KNN Loss: 3.5970659255981445 | CLS Loss: 0.02059822343289852\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 3.621692657470703 | KNN Loss: 3.59955096244812 | CLS Loss: 0.022141600027680397\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 3.6028318405151367 | KNN Loss: 3.6012566089630127 | CLS Loss: 0.0015752781182527542\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 3.630175828933716 | KNN Loss: 3.611743450164795 | CLS Loss: 0.018432317301630974\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 3.6585919857025146 | KNN Loss: 3.644470691680908 | CLS Loss: 0.014121253043413162\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 3.626924753189087 | KNN Loss: 3.617927074432373 | CLS Loss: 0.008997611701488495\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 3.586195230484009 | KNN Loss: 3.5698442459106445 | CLS Loss: 0.01635097712278366\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 3.618903160095215 | KNN Loss: 3.5925426483154297 | CLS Loss: 0.02636040188372135\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 3.61659574508667 | KNN Loss: 3.608081102371216 | CLS Loss: 0.008514671586453915\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 3.585930347442627 | KNN Loss: 3.5728156566619873 | CLS Loss: 0.01311478577554226\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 3.6184425354003906 | KNN Loss: 3.6151490211486816 | CLS Loss: 0.0032934006303548813\n",
      "Epoch: 136, Loss: 3.6212, Train: 0.9971, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 3.639112949371338 | KNN Loss: 3.6329097747802734 | CLS Loss: 0.006203293800354004\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 3.607933759689331 | KNN Loss: 3.598923444747925 | CLS Loss: 0.009010384790599346\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 3.641681671142578 | KNN Loss: 3.635708808898926 | CLS Loss: 0.005972837097942829\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 3.6308677196502686 | KNN Loss: 3.6157214641571045 | CLS Loss: 0.015146209858357906\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 3.6188182830810547 | KNN Loss: 3.611751079559326 | CLS Loss: 0.007067257538437843\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 3.618635654449463 | KNN Loss: 3.6119754314422607 | CLS Loss: 0.006660111248493195\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 3.633531093597412 | KNN Loss: 3.6227612495422363 | CLS Loss: 0.010769916698336601\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 3.598660469055176 | KNN Loss: 3.5962462425231934 | CLS Loss: 0.002414270071312785\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 3.5924856662750244 | KNN Loss: 3.576936960220337 | CLS Loss: 0.015548622235655785\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 3.595466375350952 | KNN Loss: 3.5926315784454346 | CLS Loss: 0.0028348732739686966\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 3.586276054382324 | KNN Loss: 3.584103584289551 | CLS Loss: 0.002172514796257019\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 3.657865047454834 | KNN Loss: 3.6376681327819824 | CLS Loss: 0.020197007805109024\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 3.61044979095459 | KNN Loss: 3.6030113697052 | CLS Loss: 0.007438370957970619\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 3.5946197509765625 | KNN Loss: 3.59014630317688 | CLS Loss: 0.004473464097827673\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 3.5848264694213867 | KNN Loss: 3.5802948474884033 | CLS Loss: 0.004531538113951683\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 3.573765993118286 | KNN Loss: 3.5660696029663086 | CLS Loss: 0.0076964497566223145\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 3.5898468494415283 | KNN Loss: 3.588555335998535 | CLS Loss: 0.0012914445251226425\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 3.7022252082824707 | KNN Loss: 3.694892644882202 | CLS Loss: 0.00733266631141305\n",
      "Epoch: 137, Loss: 3.6171, Train: 0.9961, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 3.6074600219726562 | KNN Loss: 3.5867912769317627 | CLS Loss: 0.020668702200055122\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 3.607081174850464 | KNN Loss: 3.5933351516723633 | CLS Loss: 0.013746124692261219\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 3.575106382369995 | KNN Loss: 3.5710294246673584 | CLS Loss: 0.004077015444636345\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 3.614138126373291 | KNN Loss: 3.6039650440216064 | CLS Loss: 0.010173162445425987\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 3.6251659393310547 | KNN Loss: 3.622148036956787 | CLS Loss: 0.003017892362549901\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 3.607154130935669 | KNN Loss: 3.593407154083252 | CLS Loss: 0.013746928423643112\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 3.619363784790039 | KNN Loss: 3.613298177719116 | CLS Loss: 0.006065490655601025\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 3.6189463138580322 | KNN Loss: 3.6002237796783447 | CLS Loss: 0.018722619861364365\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 3.628673791885376 | KNN Loss: 3.621070146560669 | CLS Loss: 0.0076037198305130005\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 3.593364715576172 | KNN Loss: 3.589949607849121 | CLS Loss: 0.003414991544559598\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 3.6216132640838623 | KNN Loss: 3.6182661056518555 | CLS Loss: 0.003347041318193078\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 3.6009974479675293 | KNN Loss: 3.586414098739624 | CLS Loss: 0.01458324771374464\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 3.636289358139038 | KNN Loss: 3.602694272994995 | CLS Loss: 0.033595118671655655\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 3.6078567504882812 | KNN Loss: 3.605362892150879 | CLS Loss: 0.0024939440190792084\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 3.605344533920288 | KNN Loss: 3.595478057861328 | CLS Loss: 0.009866499342024326\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 3.6330201625823975 | KNN Loss: 3.6132638454437256 | CLS Loss: 0.019756389781832695\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 3.593318462371826 | KNN Loss: 3.586381435394287 | CLS Loss: 0.006937040016055107\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 3.627153158187866 | KNN Loss: 3.6110305786132812 | CLS Loss: 0.016122618690133095\n",
      "Epoch: 138, Loss: 3.6171, Train: 0.9955, Valid: 0.9854, Best: 0.9873\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 3.629305839538574 | KNN Loss: 3.6177332401275635 | CLS Loss: 0.011572507210075855\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 3.596527576446533 | KNN Loss: 3.5931718349456787 | CLS Loss: 0.0033556700218468904\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 3.608186960220337 | KNN Loss: 3.5962302684783936 | CLS Loss: 0.011956616304814816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 3.587672233581543 | KNN Loss: 3.5781185626983643 | CLS Loss: 0.009553562849760056\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 3.638401508331299 | KNN Loss: 3.616711139678955 | CLS Loss: 0.02169027552008629\n",
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 3.6253812313079834 | KNN Loss: 3.594162940979004 | CLS Loss: 0.03121821954846382\n",
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 3.5962934494018555 | KNN Loss: 3.592224597930908 | CLS Loss: 0.004068780690431595\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 3.6255927085876465 | KNN Loss: 3.6206037998199463 | CLS Loss: 0.004988865461200476\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 3.5999655723571777 | KNN Loss: 3.59908127784729 | CLS Loss: 0.0008843513205647469\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 3.6218366622924805 | KNN Loss: 3.59755802154541 | CLS Loss: 0.02427872270345688\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 3.6101150512695312 | KNN Loss: 3.593233823776245 | CLS Loss: 0.01688113436102867\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 3.6011905670166016 | KNN Loss: 3.5925283432006836 | CLS Loss: 0.008662311360239983\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 3.6236002445220947 | KNN Loss: 3.6128125190734863 | CLS Loss: 0.010787653736770153\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 3.601762294769287 | KNN Loss: 3.5932233333587646 | CLS Loss: 0.008539044298231602\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 3.595796585083008 | KNN Loss: 3.590609073638916 | CLS Loss: 0.005187595263123512\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 3.592728853225708 | KNN Loss: 3.589768886566162 | CLS Loss: 0.0029600642155855894\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 3.5964038372039795 | KNN Loss: 3.5929243564605713 | CLS Loss: 0.00347956083714962\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 3.6129496097564697 | KNN Loss: 3.6022863388061523 | CLS Loss: 0.010663238354027271\n",
      "Epoch: 139, Loss: 3.6156, Train: 0.9966, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 3.616831064224243 | KNN Loss: 3.5989177227020264 | CLS Loss: 0.01791326142847538\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 3.6043460369110107 | KNN Loss: 3.5979995727539062 | CLS Loss: 0.006346540525555611\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 3.612025499343872 | KNN Loss: 3.6064059734344482 | CLS Loss: 0.005619570147246122\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 3.608488082885742 | KNN Loss: 3.5998692512512207 | CLS Loss: 0.008618823252618313\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 3.644169807434082 | KNN Loss: 3.6290462017059326 | CLS Loss: 0.015123671852052212\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 3.5964906215667725 | KNN Loss: 3.593047857284546 | CLS Loss: 0.003442788030952215\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 3.6402511596679688 | KNN Loss: 3.6207728385925293 | CLS Loss: 0.01947832852602005\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 3.6039812564849854 | KNN Loss: 3.597595453262329 | CLS Loss: 0.006385833024978638\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 3.61808180809021 | KNN Loss: 3.5909039974212646 | CLS Loss: 0.027177825570106506\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 3.607341766357422 | KNN Loss: 3.6045145988464355 | CLS Loss: 0.0028272492345422506\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 3.564908027648926 | KNN Loss: 3.5628538131713867 | CLS Loss: 0.0020541346166282892\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 3.619324207305908 | KNN Loss: 3.5998122692108154 | CLS Loss: 0.01951182261109352\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 3.570812702178955 | KNN Loss: 3.5665955543518066 | CLS Loss: 0.004217181820422411\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 3.665468454360962 | KNN Loss: 3.6367714405059814 | CLS Loss: 0.02869712933897972\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 3.662137746810913 | KNN Loss: 3.6595194339752197 | CLS Loss: 0.0026182762812823057\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 3.651184558868408 | KNN Loss: 3.636059284210205 | CLS Loss: 0.015125194564461708\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 3.620037317276001 | KNN Loss: 3.6095166206359863 | CLS Loss: 0.010520723648369312\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 3.610663652420044 | KNN Loss: 3.6076502799987793 | CLS Loss: 0.003013469511643052\n",
      "Epoch: 140, Loss: 3.6150, Train: 0.9971, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 3.5914359092712402 | KNN Loss: 3.590252637863159 | CLS Loss: 0.0011832965537905693\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 3.5857033729553223 | KNN Loss: 3.5815083980560303 | CLS Loss: 0.004194979090243578\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 3.58562970161438 | KNN Loss: 3.575355052947998 | CLS Loss: 0.010274626314640045\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 3.5847301483154297 | KNN Loss: 3.583280086517334 | CLS Loss: 0.0014499610988423228\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 3.6858932971954346 | KNN Loss: 3.6536850929260254 | CLS Loss: 0.032208316028118134\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 3.564685583114624 | KNN Loss: 3.5562245845794678 | CLS Loss: 0.008460905402898788\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 3.6032419204711914 | KNN Loss: 3.5895745754241943 | CLS Loss: 0.013667251914739609\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 3.5862603187561035 | KNN Loss: 3.575707197189331 | CLS Loss: 0.010553061030805111\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 3.630023956298828 | KNN Loss: 3.617969036102295 | CLS Loss: 0.012054835446178913\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 3.630441904067993 | KNN Loss: 3.623169422149658 | CLS Loss: 0.007272549904882908\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 3.5903615951538086 | KNN Loss: 3.584845781326294 | CLS Loss: 0.005515822675079107\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 3.6083343029022217 | KNN Loss: 3.595534086227417 | CLS Loss: 0.012800156138837337\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 3.6064953804016113 | KNN Loss: 3.596600294113159 | CLS Loss: 0.009895137511193752\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 3.590775489807129 | KNN Loss: 3.5801327228546143 | CLS Loss: 0.010642720386385918\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 3.5924201011657715 | KNN Loss: 3.585137128829956 | CLS Loss: 0.007282967213541269\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 3.608400344848633 | KNN Loss: 3.6042747497558594 | CLS Loss: 0.004125502426177263\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 3.6324703693389893 | KNN Loss: 3.602976083755493 | CLS Loss: 0.02949419803917408\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 3.6404922008514404 | KNN Loss: 3.6396265029907227 | CLS Loss: 0.0008656533318571746\n",
      "Epoch: 141, Loss: 3.6110, Train: 0.9967, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 3.607081651687622 | KNN Loss: 3.598843812942505 | CLS Loss: 0.008237919770181179\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 3.5885586738586426 | KNN Loss: 3.580198287963867 | CLS Loss: 0.00836029089987278\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 3.6251683235168457 | KNN Loss: 3.5995683670043945 | CLS Loss: 0.025600053369998932\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 3.587946653366089 | KNN Loss: 3.5840985774993896 | CLS Loss: 0.003848063061013818\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 3.5928359031677246 | KNN Loss: 3.5877795219421387 | CLS Loss: 0.0050564915873110294\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 3.5791375637054443 | KNN Loss: 3.5778207778930664 | CLS Loss: 0.0013166875578463078\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 3.6354331970214844 | KNN Loss: 3.633972406387329 | CLS Loss: 0.001460710889659822\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 3.5818326473236084 | KNN Loss: 3.5769522190093994 | CLS Loss: 0.00488033052533865\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 3.5935864448547363 | KNN Loss: 3.58150053024292 | CLS Loss: 0.0120858708396554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 3.6214141845703125 | KNN Loss: 3.6164357662200928 | CLS Loss: 0.004978329408913851\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 3.594512939453125 | KNN Loss: 3.5803816318511963 | CLS Loss: 0.014131244271993637\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 3.601670265197754 | KNN Loss: 3.598320245742798 | CLS Loss: 0.0033500606659799814\n",
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 3.6443235874176025 | KNN Loss: 3.6393051147460938 | CLS Loss: 0.005018517374992371\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 3.60664439201355 | KNN Loss: 3.585989475250244 | CLS Loss: 0.020654991269111633\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 3.6561429500579834 | KNN Loss: 3.637166738510132 | CLS Loss: 0.018976159393787384\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 3.6517677307128906 | KNN Loss: 3.6375603675842285 | CLS Loss: 0.014207348227500916\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 3.6263415813446045 | KNN Loss: 3.6169536113739014 | CLS Loss: 0.009388068690896034\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 3.5718445777893066 | KNN Loss: 3.568558931350708 | CLS Loss: 0.00328563223592937\n",
      "Epoch: 142, Loss: 3.6131, Train: 0.9972, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 3.635819435119629 | KNN Loss: 3.62221360206604 | CLS Loss: 0.01360586378723383\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 3.572925090789795 | KNN Loss: 3.560100555419922 | CLS Loss: 0.012824558652937412\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 3.579625129699707 | KNN Loss: 3.577871799468994 | CLS Loss: 0.001753331394866109\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 3.640092134475708 | KNN Loss: 3.6264777183532715 | CLS Loss: 0.013614377938210964\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 3.604022979736328 | KNN Loss: 3.5925426483154297 | CLS Loss: 0.011480310931801796\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 3.606651782989502 | KNN Loss: 3.5956923961639404 | CLS Loss: 0.010959500446915627\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 3.612318754196167 | KNN Loss: 3.609210729598999 | CLS Loss: 0.0031079596374183893\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 3.619077205657959 | KNN Loss: 3.608367443084717 | CLS Loss: 0.010709686204791069\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 3.6233856678009033 | KNN Loss: 3.6058425903320312 | CLS Loss: 0.017542986199259758\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 3.634303092956543 | KNN Loss: 3.618314743041992 | CLS Loss: 0.015988344326615334\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 3.603839159011841 | KNN Loss: 3.579157829284668 | CLS Loss: 0.02468133345246315\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 3.5965137481689453 | KNN Loss: 3.5875470638275146 | CLS Loss: 0.008966612629592419\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 3.6163933277130127 | KNN Loss: 3.6074349880218506 | CLS Loss: 0.0089582409709692\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 3.6153347492218018 | KNN Loss: 3.611746311187744 | CLS Loss: 0.0035884496755898\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 3.6494879722595215 | KNN Loss: 3.6391396522521973 | CLS Loss: 0.010348271578550339\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 3.611196517944336 | KNN Loss: 3.6072475910186768 | CLS Loss: 0.003949042409658432\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 3.5714497566223145 | KNN Loss: 3.5531957149505615 | CLS Loss: 0.018254008144140244\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 3.604393243789673 | KNN Loss: 3.579752206802368 | CLS Loss: 0.024640962481498718\n",
      "Epoch: 143, Loss: 3.6180, Train: 0.9975, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 3.5916473865509033 | KNN Loss: 3.587507724761963 | CLS Loss: 0.0041396827436983585\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 3.654383659362793 | KNN Loss: 3.6474430561065674 | CLS Loss: 0.006940591614693403\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 3.593379020690918 | KNN Loss: 3.5800578594207764 | CLS Loss: 0.01332111656665802\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 3.6097660064697266 | KNN Loss: 3.602984666824341 | CLS Loss: 0.006781227421015501\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 3.6274311542510986 | KNN Loss: 3.618623971939087 | CLS Loss: 0.008807258680462837\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 3.6434249877929688 | KNN Loss: 3.605766534805298 | CLS Loss: 0.03765837103128433\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 3.6313507556915283 | KNN Loss: 3.6212985515594482 | CLS Loss: 0.010052226483821869\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 3.651634931564331 | KNN Loss: 3.6458351612091064 | CLS Loss: 0.0057998038828372955\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 3.612215042114258 | KNN Loss: 3.601869583129883 | CLS Loss: 0.010345523245632648\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 3.6121788024902344 | KNN Loss: 3.601109266281128 | CLS Loss: 0.011069446802139282\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 3.595162868499756 | KNN Loss: 3.5905277729034424 | CLS Loss: 0.004635161720216274\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 3.6158974170684814 | KNN Loss: 3.60581636428833 | CLS Loss: 0.010081143118441105\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 3.6040048599243164 | KNN Loss: 3.600569725036621 | CLS Loss: 0.0034350482746958733\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 3.594576597213745 | KNN Loss: 3.588092565536499 | CLS Loss: 0.006484100129455328\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 3.5878210067749023 | KNN Loss: 3.5848031044006348 | CLS Loss: 0.003017888870090246\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 3.6390480995178223 | KNN Loss: 3.609362840652466 | CLS Loss: 0.029685189947485924\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 3.594066619873047 | KNN Loss: 3.593067169189453 | CLS Loss: 0.0009994328720495105\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 3.610867977142334 | KNN Loss: 3.595266103744507 | CLS Loss: 0.015601949766278267\n",
      "Epoch: 144, Loss: 3.6206, Train: 0.9972, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 3.608858108520508 | KNN Loss: 3.5933547019958496 | CLS Loss: 0.015503326430916786\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 3.61883807182312 | KNN Loss: 3.616257429122925 | CLS Loss: 0.002580657135695219\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 3.59108304977417 | KNN Loss: 3.5825657844543457 | CLS Loss: 0.008517252281308174\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 3.5986835956573486 | KNN Loss: 3.595998764038086 | CLS Loss: 0.0026847415138036013\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 3.595250368118286 | KNN Loss: 3.588480234146118 | CLS Loss: 0.006770059000700712\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 3.604750156402588 | KNN Loss: 3.585231065750122 | CLS Loss: 0.019519172608852386\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 3.6165218353271484 | KNN Loss: 3.607290029525757 | CLS Loss: 0.009231766685843468\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 3.6244375705718994 | KNN Loss: 3.6209728717803955 | CLS Loss: 0.003464657114818692\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 3.6505048274993896 | KNN Loss: 3.633704900741577 | CLS Loss: 0.016799956560134888\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 3.574697494506836 | KNN Loss: 3.5682907104492188 | CLS Loss: 0.006406710483133793\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 3.624284029006958 | KNN Loss: 3.6139416694641113 | CLS Loss: 0.010342365130782127\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 3.59898042678833 | KNN Loss: 3.5944008827209473 | CLS Loss: 0.00457956176251173\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 3.657693386077881 | KNN Loss: 3.640573263168335 | CLS Loss: 0.017120059579610825\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 3.6494171619415283 | KNN Loss: 3.605930805206299 | CLS Loss: 0.04348646476864815\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 3.667407512664795 | KNN Loss: 3.652461290359497 | CLS Loss: 0.014946148730814457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 3.612424850463867 | KNN Loss: 3.601109027862549 | CLS Loss: 0.01131591945886612\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 3.630927801132202 | KNN Loss: 3.610706090927124 | CLS Loss: 0.02022174745798111\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 3.618440628051758 | KNN Loss: 3.589381217956543 | CLS Loss: 0.029059482738375664\n",
      "Epoch: 145, Loss: 3.6166, Train: 0.9975, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 3.617413282394409 | KNN Loss: 3.6088168621063232 | CLS Loss: 0.008596319705247879\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 3.585026502609253 | KNN Loss: 3.571716070175171 | CLS Loss: 0.01331049483269453\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 3.5845677852630615 | KNN Loss: 3.582979202270508 | CLS Loss: 0.0015885697212070227\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 3.655428171157837 | KNN Loss: 3.640380859375 | CLS Loss: 0.015047217719256878\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 3.5865466594696045 | KNN Loss: 3.5809035301208496 | CLS Loss: 0.005643239710479975\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 3.608546733856201 | KNN Loss: 3.593290328979492 | CLS Loss: 0.015256294049322605\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 3.6039419174194336 | KNN Loss: 3.5977776050567627 | CLS Loss: 0.006164194084703922\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 3.6553902626037598 | KNN Loss: 3.6296112537384033 | CLS Loss: 0.02577889896929264\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 3.592088222503662 | KNN Loss: 3.5880472660064697 | CLS Loss: 0.004040851723402739\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 3.6212425231933594 | KNN Loss: 3.602102518081665 | CLS Loss: 0.019140074029564857\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 3.592820167541504 | KNN Loss: 3.587271213531494 | CLS Loss: 0.005548919551074505\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 3.6242032051086426 | KNN Loss: 3.6221070289611816 | CLS Loss: 0.0020961768459528685\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 3.608645439147949 | KNN Loss: 3.6011834144592285 | CLS Loss: 0.007461961824446917\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 3.6086080074310303 | KNN Loss: 3.5989341735839844 | CLS Loss: 0.00967381615191698\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 3.6080195903778076 | KNN Loss: 3.5928938388824463 | CLS Loss: 0.0151257598772645\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 3.5842199325561523 | KNN Loss: 3.5785160064697266 | CLS Loss: 0.0057038599625229836\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 3.616508722305298 | KNN Loss: 3.6078402996063232 | CLS Loss: 0.008668393827974796\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 3.6118953227996826 | KNN Loss: 3.6050946712493896 | CLS Loss: 0.006800672505050898\n",
      "Epoch: 146, Loss: 3.6115, Train: 0.9969, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 3.614804744720459 | KNN Loss: 3.607401132583618 | CLS Loss: 0.007403620518743992\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 3.6118314266204834 | KNN Loss: 3.6096484661102295 | CLS Loss: 0.0021829467732459307\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 3.5975921154022217 | KNN Loss: 3.5952789783477783 | CLS Loss: 0.0023131289053708315\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 3.612762451171875 | KNN Loss: 3.59163498878479 | CLS Loss: 0.021127397194504738\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 3.5990586280822754 | KNN Loss: 3.591459035873413 | CLS Loss: 0.007599628996104002\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 3.6131651401519775 | KNN Loss: 3.593534469604492 | CLS Loss: 0.01963057555258274\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 3.6068947315216064 | KNN Loss: 3.5903260707855225 | CLS Loss: 0.016568623483181\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 3.6350255012512207 | KNN Loss: 3.6180315017700195 | CLS Loss: 0.016993895173072815\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 3.588298797607422 | KNN Loss: 3.5838685035705566 | CLS Loss: 0.00443029310554266\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 3.5960049629211426 | KNN Loss: 3.589472532272339 | CLS Loss: 0.006532542873173952\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 3.603484869003296 | KNN Loss: 3.601452350616455 | CLS Loss: 0.0020324750803411007\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 3.629441022872925 | KNN Loss: 3.625363349914551 | CLS Loss: 0.004077690187841654\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 3.6341636180877686 | KNN Loss: 3.5976850986480713 | CLS Loss: 0.03647863492369652\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 3.584261655807495 | KNN Loss: 3.5765323638916016 | CLS Loss: 0.007729373872280121\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 3.6065375804901123 | KNN Loss: 3.600928544998169 | CLS Loss: 0.005608979146927595\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 3.596729278564453 | KNN Loss: 3.5933837890625 | CLS Loss: 0.003345432924106717\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 3.5926034450531006 | KNN Loss: 3.5864741802215576 | CLS Loss: 0.006129283457994461\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 3.6114697456359863 | KNN Loss: 3.6024677753448486 | CLS Loss: 0.00900194887071848\n",
      "Epoch: 147, Loss: 3.6122, Train: 0.9970, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 3.5926568508148193 | KNN Loss: 3.592156410217285 | CLS Loss: 0.0005004008417017758\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 3.6265931129455566 | KNN Loss: 3.613570213317871 | CLS Loss: 0.013022986240684986\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 3.5780558586120605 | KNN Loss: 3.5748260021209717 | CLS Loss: 0.0032299587037414312\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 3.616770029067993 | KNN Loss: 3.607013702392578 | CLS Loss: 0.00975643377751112\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 3.5705411434173584 | KNN Loss: 3.569849729537964 | CLS Loss: 0.0006914372788742185\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 3.57401704788208 | KNN Loss: 3.567559242248535 | CLS Loss: 0.0064576976001262665\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 3.5958683490753174 | KNN Loss: 3.586021900177002 | CLS Loss: 0.009846449829638004\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 3.6132538318634033 | KNN Loss: 3.598010540008545 | CLS Loss: 0.015243330970406532\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 3.6155834197998047 | KNN Loss: 3.597670555114746 | CLS Loss: 0.01791292056441307\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 3.635725975036621 | KNN Loss: 3.6270272731781006 | CLS Loss: 0.008698745630681515\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 3.610043525695801 | KNN Loss: 3.609102487564087 | CLS Loss: 0.0009411121136508882\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 3.6020913124084473 | KNN Loss: 3.597144365310669 | CLS Loss: 0.004947052337229252\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 3.58852481842041 | KNN Loss: 3.5823447704315186 | CLS Loss: 0.006180133670568466\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 3.6161959171295166 | KNN Loss: 3.5955610275268555 | CLS Loss: 0.020634900778532028\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 3.600847005844116 | KNN Loss: 3.5920042991638184 | CLS Loss: 0.00884262751787901\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 3.583594560623169 | KNN Loss: 3.5702714920043945 | CLS Loss: 0.013322951272130013\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 3.6081652641296387 | KNN Loss: 3.586944341659546 | CLS Loss: 0.0212209764868021\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 3.617760181427002 | KNN Loss: 3.6133618354797363 | CLS Loss: 0.004398302640765905\n",
      "Epoch: 148, Loss: 3.6129, Train: 0.9968, Valid: 0.9847, Best: 0.9873\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 3.6081411838531494 | KNN Loss: 3.6002049446105957 | CLS Loss: 0.007936310023069382\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 3.6294403076171875 | KNN Loss: 3.611313581466675 | CLS Loss: 0.018126782029867172\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 3.636028528213501 | KNN Loss: 3.6312999725341797 | CLS Loss: 0.004728647414594889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 3.6163346767425537 | KNN Loss: 3.613731622695923 | CLS Loss: 0.002603048225864768\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 3.600409984588623 | KNN Loss: 3.5897397994995117 | CLS Loss: 0.010670186951756477\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 3.607001543045044 | KNN Loss: 3.5936014652252197 | CLS Loss: 0.013400118798017502\n",
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 3.615276336669922 | KNN Loss: 3.6073906421661377 | CLS Loss: 0.007885790430009365\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 3.599039077758789 | KNN Loss: 3.577286720275879 | CLS Loss: 0.02175244502723217\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 3.5807228088378906 | KNN Loss: 3.5710887908935547 | CLS Loss: 0.009634094312787056\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 3.603090286254883 | KNN Loss: 3.5983340740203857 | CLS Loss: 0.004756133072078228\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 3.59619402885437 | KNN Loss: 3.593069076538086 | CLS Loss: 0.0031248852610588074\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 3.624241828918457 | KNN Loss: 3.6161656379699707 | CLS Loss: 0.008076242171227932\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 3.5745058059692383 | KNN Loss: 3.572500228881836 | CLS Loss: 0.0020055926870554686\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 3.6287319660186768 | KNN Loss: 3.6173222064971924 | CLS Loss: 0.011409830302000046\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 3.602646589279175 | KNN Loss: 3.596785306930542 | CLS Loss: 0.005861235782504082\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 3.593651294708252 | KNN Loss: 3.586803436279297 | CLS Loss: 0.006847844924777746\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 3.609179735183716 | KNN Loss: 3.5911943912506104 | CLS Loss: 0.01798531599342823\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 3.577152729034424 | KNN Loss: 3.568735122680664 | CLS Loss: 0.00841765757650137\n",
      "Epoch: 149, Loss: 3.6107, Train: 0.9973, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 3.597733736038208 | KNN Loss: 3.592071533203125 | CLS Loss: 0.005662308540195227\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 3.62858510017395 | KNN Loss: 3.6140778064727783 | CLS Loss: 0.014507307671010494\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 3.6071279048919678 | KNN Loss: 3.6032111644744873 | CLS Loss: 0.003916793502867222\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 3.6086387634277344 | KNN Loss: 3.596503973007202 | CLS Loss: 0.012134730815887451\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 3.6133878231048584 | KNN Loss: 3.610941171646118 | CLS Loss: 0.002446730388328433\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 3.610201835632324 | KNN Loss: 3.6027491092681885 | CLS Loss: 0.007452826015651226\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 3.611865520477295 | KNN Loss: 3.604343891143799 | CLS Loss: 0.007521687541157007\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 3.6345531940460205 | KNN Loss: 3.6176536083221436 | CLS Loss: 0.01689954102039337\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 3.5977911949157715 | KNN Loss: 3.596496820449829 | CLS Loss: 0.0012944047339260578\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 3.5788564682006836 | KNN Loss: 3.568742513656616 | CLS Loss: 0.01011388935148716\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 3.584603786468506 | KNN Loss: 3.5831873416900635 | CLS Loss: 0.0014164564199745655\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 3.6012470722198486 | KNN Loss: 3.5938875675201416 | CLS Loss: 0.007359439041465521\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 3.6128971576690674 | KNN Loss: 3.6041929721832275 | CLS Loss: 0.008704299107193947\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 3.660770893096924 | KNN Loss: 3.631155252456665 | CLS Loss: 0.029615694656968117\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 3.6053385734558105 | KNN Loss: 3.5958101749420166 | CLS Loss: 0.009528490714728832\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 3.6442711353302 | KNN Loss: 3.6275739669799805 | CLS Loss: 0.016697192564606667\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 3.5853278636932373 | KNN Loss: 3.575798511505127 | CLS Loss: 0.009529367089271545\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 3.5934338569641113 | KNN Loss: 3.5884451866149902 | CLS Loss: 0.004988688975572586\n",
      "Epoch: 150, Loss: 3.6170, Train: 0.9956, Valid: 0.9850, Best: 0.9873\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 3.682589292526245 | KNN Loss: 3.6617650985717773 | CLS Loss: 0.020824184641242027\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 3.626251697540283 | KNN Loss: 3.6040265560150146 | CLS Loss: 0.02222519740462303\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 3.628775119781494 | KNN Loss: 3.6186130046844482 | CLS Loss: 0.010162044316530228\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 3.621950626373291 | KNN Loss: 3.6120240688323975 | CLS Loss: 0.009926438331604004\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 3.6292033195495605 | KNN Loss: 3.62258243560791 | CLS Loss: 0.006620907224714756\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 3.633329153060913 | KNN Loss: 3.5866851806640625 | CLS Loss: 0.04664386808872223\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 3.5664002895355225 | KNN Loss: 3.5635952949523926 | CLS Loss: 0.0028050446417182684\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 3.6335813999176025 | KNN Loss: 3.630856990814209 | CLS Loss: 0.00272438139654696\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 3.590150833129883 | KNN Loss: 3.5824155807495117 | CLS Loss: 0.007735323626548052\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 3.5991532802581787 | KNN Loss: 3.5813982486724854 | CLS Loss: 0.017754970118403435\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 3.58016037940979 | KNN Loss: 3.5717456340789795 | CLS Loss: 0.008414726704359055\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 3.6045949459075928 | KNN Loss: 3.5959293842315674 | CLS Loss: 0.008665445260703564\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 3.6356685161590576 | KNN Loss: 3.6242153644561768 | CLS Loss: 0.011453215032815933\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 3.6053431034088135 | KNN Loss: 3.5867919921875 | CLS Loss: 0.018551021814346313\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 3.5742151737213135 | KNN Loss: 3.5677332878112793 | CLS Loss: 0.006481882184743881\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 3.593156099319458 | KNN Loss: 3.585899829864502 | CLS Loss: 0.007256355602294207\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 3.592136859893799 | KNN Loss: 3.584057092666626 | CLS Loss: 0.008079670369625092\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 3.6229984760284424 | KNN Loss: 3.6095187664031982 | CLS Loss: 0.013479616492986679\n",
      "Epoch: 151, Loss: 3.6164, Train: 0.9972, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 3.603994131088257 | KNN Loss: 3.592698335647583 | CLS Loss: 0.011295733042061329\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 3.62361216545105 | KNN Loss: 3.622025489807129 | CLS Loss: 0.0015866884496062994\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 3.5852298736572266 | KNN Loss: 3.580946922302246 | CLS Loss: 0.0042829010635614395\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 3.61372447013855 | KNN Loss: 3.6078803539276123 | CLS Loss: 0.005844205617904663\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 3.618579387664795 | KNN Loss: 3.615297317504883 | CLS Loss: 0.003282062942162156\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 3.6724867820739746 | KNN Loss: 3.6700546741485596 | CLS Loss: 0.002432031324133277\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 3.631401538848877 | KNN Loss: 3.6288304328918457 | CLS Loss: 0.002571074292063713\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 3.626929759979248 | KNN Loss: 3.6077828407287598 | CLS Loss: 0.019147023558616638\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 3.6190106868743896 | KNN Loss: 3.6125450134277344 | CLS Loss: 0.006465735379606485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 3.574205160140991 | KNN Loss: 3.5696210861206055 | CLS Loss: 0.004583998117595911\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 3.602250337600708 | KNN Loss: 3.5985629558563232 | CLS Loss: 0.0036873258650302887\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 3.6003403663635254 | KNN Loss: 3.598818778991699 | CLS Loss: 0.001521618920378387\n",
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 3.5991268157958984 | KNN Loss: 3.5798685550689697 | CLS Loss: 0.01925818808376789\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 3.6267588138580322 | KNN Loss: 3.6045923233032227 | CLS Loss: 0.02216646634042263\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 3.6806697845458984 | KNN Loss: 3.671369791030884 | CLS Loss: 0.009299997240304947\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 3.5981342792510986 | KNN Loss: 3.596355676651001 | CLS Loss: 0.0017787069082260132\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 3.6248607635498047 | KNN Loss: 3.6056692600250244 | CLS Loss: 0.01919158175587654\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 3.614506959915161 | KNN Loss: 3.608347177505493 | CLS Loss: 0.006159736309200525\n",
      "Epoch: 152, Loss: 3.6139, Train: 0.9970, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 3.6194348335266113 | KNN Loss: 3.599797487258911 | CLS Loss: 0.019637389108538628\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 3.5987815856933594 | KNN Loss: 3.591050863265991 | CLS Loss: 0.007730820216238499\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 3.6263883113861084 | KNN Loss: 3.6200859546661377 | CLS Loss: 0.006302295718342066\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 3.5698459148406982 | KNN Loss: 3.5654094219207764 | CLS Loss: 0.004436394665390253\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 3.6412267684936523 | KNN Loss: 3.634244203567505 | CLS Loss: 0.006982628721743822\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 3.6090753078460693 | KNN Loss: 3.603151798248291 | CLS Loss: 0.0059234825894236565\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 3.647531747817993 | KNN Loss: 3.6210641860961914 | CLS Loss: 0.026467515155673027\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 3.620656967163086 | KNN Loss: 3.613900661468506 | CLS Loss: 0.006756385322660208\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 3.6161327362060547 | KNN Loss: 3.6078920364379883 | CLS Loss: 0.008240639232099056\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 3.5987863540649414 | KNN Loss: 3.5913655757904053 | CLS Loss: 0.007420738227665424\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 3.6223971843719482 | KNN Loss: 3.6097402572631836 | CLS Loss: 0.012657026760280132\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 3.6093387603759766 | KNN Loss: 3.602020502090454 | CLS Loss: 0.007318181451410055\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 3.6293911933898926 | KNN Loss: 3.6099371910095215 | CLS Loss: 0.01945403963327408\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 3.655357599258423 | KNN Loss: 3.642625331878662 | CLS Loss: 0.01273217424750328\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 3.613311529159546 | KNN Loss: 3.5946309566497803 | CLS Loss: 0.01868053525686264\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 3.596918821334839 | KNN Loss: 3.590049982070923 | CLS Loss: 0.006868803407996893\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 3.575990676879883 | KNN Loss: 3.573943614959717 | CLS Loss: 0.0020470109302550554\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 3.579780101776123 | KNN Loss: 3.578181505203247 | CLS Loss: 0.0015985156642273068\n",
      "Epoch: 153, Loss: 3.6152, Train: 0.9977, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 3.615480899810791 | KNN Loss: 3.61151123046875 | CLS Loss: 0.003969630692154169\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 3.579686403274536 | KNN Loss: 3.566336154937744 | CLS Loss: 0.013350212015211582\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 3.6017768383026123 | KNN Loss: 3.587013006210327 | CLS Loss: 0.014763929881155491\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 3.6023612022399902 | KNN Loss: 3.5996503829956055 | CLS Loss: 0.002710893517360091\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 3.621917247772217 | KNN Loss: 3.6175317764282227 | CLS Loss: 0.00438558217138052\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 3.609107732772827 | KNN Loss: 3.5782978534698486 | CLS Loss: 0.03080981783568859\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 3.6701340675354004 | KNN Loss: 3.6423308849334717 | CLS Loss: 0.027803165838122368\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 3.5868144035339355 | KNN Loss: 3.5810868740081787 | CLS Loss: 0.005727467592805624\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 3.585114002227783 | KNN Loss: 3.5821480751037598 | CLS Loss: 0.002965899184346199\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 3.5868496894836426 | KNN Loss: 3.586332082748413 | CLS Loss: 0.0005176099366508424\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 3.5757830142974854 | KNN Loss: 3.5680620670318604 | CLS Loss: 0.007721016649156809\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 3.6378262042999268 | KNN Loss: 3.630506753921509 | CLS Loss: 0.0073194303549826145\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 3.662031412124634 | KNN Loss: 3.6480140686035156 | CLS Loss: 0.014017431996762753\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 3.61777400970459 | KNN Loss: 3.6059494018554688 | CLS Loss: 0.011824632063508034\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 3.5985517501831055 | KNN Loss: 3.5938708782196045 | CLS Loss: 0.004680789541453123\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 3.6177284717559814 | KNN Loss: 3.6164348125457764 | CLS Loss: 0.0012937645660713315\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 3.6075305938720703 | KNN Loss: 3.5938754081726074 | CLS Loss: 0.013655249029397964\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 3.6283416748046875 | KNN Loss: 3.618259906768799 | CLS Loss: 0.010081822983920574\n",
      "Epoch: 154, Loss: 3.6186, Train: 0.9952, Valid: 0.9826, Best: 0.9873\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 3.63043475151062 | KNN Loss: 3.604081630706787 | CLS Loss: 0.026353202760219574\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 3.657780408859253 | KNN Loss: 3.647686719894409 | CLS Loss: 0.010093585588037968\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 3.5779521465301514 | KNN Loss: 3.575145721435547 | CLS Loss: 0.0028063906356692314\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 3.6773409843444824 | KNN Loss: 3.675645112991333 | CLS Loss: 0.0016958019696176052\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 3.5856943130493164 | KNN Loss: 3.5818238258361816 | CLS Loss: 0.003870391985401511\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 3.6463005542755127 | KNN Loss: 3.636826276779175 | CLS Loss: 0.009474247694015503\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 3.637364387512207 | KNN Loss: 3.6181252002716064 | CLS Loss: 0.019239161163568497\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 3.6135737895965576 | KNN Loss: 3.606295108795166 | CLS Loss: 0.00727879349142313\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 3.6093084812164307 | KNN Loss: 3.5938830375671387 | CLS Loss: 0.015425372868776321\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 3.6207239627838135 | KNN Loss: 3.6106173992156982 | CLS Loss: 0.010106663219630718\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 3.605034351348877 | KNN Loss: 3.5992279052734375 | CLS Loss: 0.005806384142488241\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 3.679697036743164 | KNN Loss: 3.668501377105713 | CLS Loss: 0.011195593513548374\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 3.620018720626831 | KNN Loss: 3.5799474716186523 | CLS Loss: 0.04007123410701752\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 3.6465671062469482 | KNN Loss: 3.6328587532043457 | CLS Loss: 0.013708469457924366\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 3.6704256534576416 | KNN Loss: 3.649082899093628 | CLS Loss: 0.021342797204852104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 3.652214765548706 | KNN Loss: 3.6428871154785156 | CLS Loss: 0.009327743202447891\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 3.6340417861938477 | KNN Loss: 3.600449800491333 | CLS Loss: 0.03359202668070793\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 3.643828868865967 | KNN Loss: 3.6334309577941895 | CLS Loss: 0.010397886857390404\n",
      "Epoch: 155, Loss: 3.6230, Train: 0.9960, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 3.603025436401367 | KNN Loss: 3.596945285797119 | CLS Loss: 0.006080143619328737\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 3.6273210048675537 | KNN Loss: 3.616830825805664 | CLS Loss: 0.010490186512470245\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 3.591986894607544 | KNN Loss: 3.5867273807525635 | CLS Loss: 0.005259543191641569\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 3.731299638748169 | KNN Loss: 3.728640079498291 | CLS Loss: 0.002659557620063424\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 3.5976176261901855 | KNN Loss: 3.5718328952789307 | CLS Loss: 0.025784779340028763\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 3.5988144874572754 | KNN Loss: 3.5875039100646973 | CLS Loss: 0.011310555972158909\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 3.6002695560455322 | KNN Loss: 3.582521677017212 | CLS Loss: 0.017747769132256508\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 3.6225814819335938 | KNN Loss: 3.6198902130126953 | CLS Loss: 0.0026913387700915337\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 3.6016032695770264 | KNN Loss: 3.5895133018493652 | CLS Loss: 0.012089983560144901\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 3.6222481727600098 | KNN Loss: 3.613532066345215 | CLS Loss: 0.008716009557247162\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 3.6135413646698 | KNN Loss: 3.580702781677246 | CLS Loss: 0.032838497310876846\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 3.602220296859741 | KNN Loss: 3.595066785812378 | CLS Loss: 0.007153618615120649\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 3.606194019317627 | KNN Loss: 3.58174991607666 | CLS Loss: 0.024443989619612694\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 3.6012325286865234 | KNN Loss: 3.5844147205352783 | CLS Loss: 0.016817722469568253\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 3.6672744750976562 | KNN Loss: 3.6301069259643555 | CLS Loss: 0.037167519330978394\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 3.622309923171997 | KNN Loss: 3.607311487197876 | CLS Loss: 0.014998486265540123\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 3.6619458198547363 | KNN Loss: 3.628124952316284 | CLS Loss: 0.03382077440619469\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 3.609778642654419 | KNN Loss: 3.5875375270843506 | CLS Loss: 0.022241201251745224\n",
      "Epoch: 156, Loss: 3.6181, Train: 0.9969, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 3.6062705516815186 | KNN Loss: 3.5865912437438965 | CLS Loss: 0.019679373130202293\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 3.6205742359161377 | KNN Loss: 3.597135543823242 | CLS Loss: 0.02343861386179924\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 3.67435622215271 | KNN Loss: 3.67008638381958 | CLS Loss: 0.004269764758646488\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 3.6166346073150635 | KNN Loss: 3.612323760986328 | CLS Loss: 0.00431076530367136\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 3.6381335258483887 | KNN Loss: 3.605492115020752 | CLS Loss: 0.03264150023460388\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 3.6081295013427734 | KNN Loss: 3.6005027294158936 | CLS Loss: 0.007626726757735014\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 3.622187614440918 | KNN Loss: 3.6088104248046875 | CLS Loss: 0.013377203606069088\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 3.609515905380249 | KNN Loss: 3.5791919231414795 | CLS Loss: 0.030323971062898636\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 3.6033935546875 | KNN Loss: 3.6012508869171143 | CLS Loss: 0.0021426102612167597\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 3.6417057514190674 | KNN Loss: 3.6380622386932373 | CLS Loss: 0.0036435339134186506\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 3.5883371829986572 | KNN Loss: 3.5822970867156982 | CLS Loss: 0.006040074396878481\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 3.595518112182617 | KNN Loss: 3.592092275619507 | CLS Loss: 0.0034258977975696325\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 3.6306002140045166 | KNN Loss: 3.591367483139038 | CLS Loss: 0.03923266753554344\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 3.593935489654541 | KNN Loss: 3.581031322479248 | CLS Loss: 0.01290427427738905\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 3.617490530014038 | KNN Loss: 3.599790096282959 | CLS Loss: 0.017700443044304848\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 3.607304096221924 | KNN Loss: 3.5880613327026367 | CLS Loss: 0.01924281194806099\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 3.6004347801208496 | KNN Loss: 3.5915729999542236 | CLS Loss: 0.00886180717498064\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 3.633828639984131 | KNN Loss: 3.5895841121673584 | CLS Loss: 0.044244419783353806\n",
      "Epoch: 157, Loss: 3.6162, Train: 0.9967, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 3.599053382873535 | KNN Loss: 3.5978751182556152 | CLS Loss: 0.0011782723013311625\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 3.6446521282196045 | KNN Loss: 3.6414003372192383 | CLS Loss: 0.003251677379012108\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 3.589885711669922 | KNN Loss: 3.5849123001098633 | CLS Loss: 0.004973382689058781\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 3.61865234375 | KNN Loss: 3.6130948066711426 | CLS Loss: 0.005557498428970575\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 3.618406295776367 | KNN Loss: 3.6056337356567383 | CLS Loss: 0.012772525660693645\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 3.5878958702087402 | KNN Loss: 3.581017255783081 | CLS Loss: 0.0068786959163844585\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 3.6285910606384277 | KNN Loss: 3.6136603355407715 | CLS Loss: 0.014930718578398228\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 3.602553367614746 | KNN Loss: 3.6002628803253174 | CLS Loss: 0.0022904856596142054\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 3.602001905441284 | KNN Loss: 3.593071937561035 | CLS Loss: 0.008930062875151634\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 3.6493115425109863 | KNN Loss: 3.626193046569824 | CLS Loss: 0.02311858907341957\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 3.6539690494537354 | KNN Loss: 3.6440861225128174 | CLS Loss: 0.009883041493594646\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 3.608391046524048 | KNN Loss: 3.6021742820739746 | CLS Loss: 0.006216792855411768\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 3.5964767932891846 | KNN Loss: 3.59503436088562 | CLS Loss: 0.0014424929395318031\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 3.594545602798462 | KNN Loss: 3.587799072265625 | CLS Loss: 0.006746533326804638\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 3.6004393100738525 | KNN Loss: 3.5989530086517334 | CLS Loss: 0.0014863386750221252\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 3.5719990730285645 | KNN Loss: 3.5661447048187256 | CLS Loss: 0.005854438990354538\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 3.66082501411438 | KNN Loss: 3.6552786827087402 | CLS Loss: 0.005546263884752989\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 3.5860679149627686 | KNN Loss: 3.5832443237304688 | CLS Loss: 0.0028235898353159428\n",
      "Epoch: 158, Loss: 3.6121, Train: 0.9978, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 3.5560920238494873 | KNN Loss: 3.5537912845611572 | CLS Loss: 0.0023006328847259283\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 3.6069464683532715 | KNN Loss: 3.5843124389648438 | CLS Loss: 0.02263396605849266\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 3.6166939735412598 | KNN Loss: 3.5912299156188965 | CLS Loss: 0.02546406164765358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 3.5973193645477295 | KNN Loss: 3.591245412826538 | CLS Loss: 0.006073928903788328\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 3.6194677352905273 | KNN Loss: 3.610872983932495 | CLS Loss: 0.00859485100954771\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 3.6374118328094482 | KNN Loss: 3.6199445724487305 | CLS Loss: 0.01746717467904091\n",
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 3.600090265274048 | KNN Loss: 3.5947842597961426 | CLS Loss: 0.0053061190992593765\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 3.6180572509765625 | KNN Loss: 3.6023590564727783 | CLS Loss: 0.01569819450378418\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 3.6313908100128174 | KNN Loss: 3.6193957328796387 | CLS Loss: 0.011995102278888226\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 3.5974953174591064 | KNN Loss: 3.5915188789367676 | CLS Loss: 0.0059763905592262745\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 3.6428918838500977 | KNN Loss: 3.6372132301330566 | CLS Loss: 0.005678572691977024\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 3.631929636001587 | KNN Loss: 3.628511905670166 | CLS Loss: 0.003417650703340769\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 3.600721836090088 | KNN Loss: 3.5943078994750977 | CLS Loss: 0.0064138672314584255\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 3.6185555458068848 | KNN Loss: 3.616461992263794 | CLS Loss: 0.0020935104694217443\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 3.627149820327759 | KNN Loss: 3.6114003658294678 | CLS Loss: 0.01574934460222721\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 3.5679304599761963 | KNN Loss: 3.5615715980529785 | CLS Loss: 0.0063587455078959465\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 3.6317951679229736 | KNN Loss: 3.6133854389190674 | CLS Loss: 0.018409768119454384\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 3.6262903213500977 | KNN Loss: 3.590932607650757 | CLS Loss: 0.03535781428217888\n",
      "Epoch: 159, Loss: 3.6121, Train: 0.9963, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 3.594254970550537 | KNN Loss: 3.5791127681732178 | CLS Loss: 0.015142192132771015\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 3.6228084564208984 | KNN Loss: 3.5950560569763184 | CLS Loss: 0.027752378955483437\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 3.647324562072754 | KNN Loss: 3.5933008193969727 | CLS Loss: 0.05402373522520065\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 3.603769063949585 | KNN Loss: 3.6014304161071777 | CLS Loss: 0.002338558668270707\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 3.6211702823638916 | KNN Loss: 3.613874673843384 | CLS Loss: 0.0072957053780555725\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 3.630220413208008 | KNN Loss: 3.6066153049468994 | CLS Loss: 0.02360505238175392\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 3.613600730895996 | KNN Loss: 3.6116907596588135 | CLS Loss: 0.0019099611090496182\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 3.5791985988616943 | KNN Loss: 3.5771684646606445 | CLS Loss: 0.0020301344338804483\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 3.589123010635376 | KNN Loss: 3.58599853515625 | CLS Loss: 0.00312455534003675\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 3.6456031799316406 | KNN Loss: 3.6362287998199463 | CLS Loss: 0.009374375455081463\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 3.586866617202759 | KNN Loss: 3.5779168605804443 | CLS Loss: 0.008949730545282364\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 3.6398768424987793 | KNN Loss: 3.628748893737793 | CLS Loss: 0.011127987876534462\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 3.6062936782836914 | KNN Loss: 3.6025564670562744 | CLS Loss: 0.003737302264198661\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 3.6196539402008057 | KNN Loss: 3.6133875846862793 | CLS Loss: 0.006266451440751553\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 3.6685285568237305 | KNN Loss: 3.6518943309783936 | CLS Loss: 0.01663428731262684\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 3.6141374111175537 | KNN Loss: 3.6104066371917725 | CLS Loss: 0.0037308242172002792\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 3.6245250701904297 | KNN Loss: 3.600168466567993 | CLS Loss: 0.024356510490179062\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 3.6061525344848633 | KNN Loss: 3.6005423069000244 | CLS Loss: 0.005610346794128418\n",
      "Epoch: 160, Loss: 3.6176, Train: 0.9967, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 3.600221633911133 | KNN Loss: 3.5786898136138916 | CLS Loss: 0.02153184823691845\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 3.599411964416504 | KNN Loss: 3.5942816734313965 | CLS Loss: 0.005130303092300892\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 3.6139631271362305 | KNN Loss: 3.600229024887085 | CLS Loss: 0.013734069652855396\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 3.5868961811065674 | KNN Loss: 3.5830657482147217 | CLS Loss: 0.0038303835317492485\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 3.60341739654541 | KNN Loss: 3.5993878841400146 | CLS Loss: 0.00402947049587965\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 3.6163206100463867 | KNN Loss: 3.593702554702759 | CLS Loss: 0.02261805161833763\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 3.5753724575042725 | KNN Loss: 3.570719003677368 | CLS Loss: 0.004653398413211107\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 3.57312273979187 | KNN Loss: 3.5645182132720947 | CLS Loss: 0.008604592643678188\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 3.6334259510040283 | KNN Loss: 3.617487907409668 | CLS Loss: 0.015938149765133858\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 3.6493282318115234 | KNN Loss: 3.6251306533813477 | CLS Loss: 0.02419748343527317\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 3.5785720348358154 | KNN Loss: 3.5772438049316406 | CLS Loss: 0.0013282434083521366\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 3.5983147621154785 | KNN Loss: 3.5820672512054443 | CLS Loss: 0.01624748855829239\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 3.5920393466949463 | KNN Loss: 3.5868537425994873 | CLS Loss: 0.005185551941394806\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 3.648669719696045 | KNN Loss: 3.643681049346924 | CLS Loss: 0.004988641012459993\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 3.6778903007507324 | KNN Loss: 3.6540372371673584 | CLS Loss: 0.023853056132793427\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 3.5990183353424072 | KNN Loss: 3.5890190601348877 | CLS Loss: 0.009999223984777927\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 3.5956780910491943 | KNN Loss: 3.5904061794281006 | CLS Loss: 0.005271866451948881\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 3.601670026779175 | KNN Loss: 3.5964319705963135 | CLS Loss: 0.005238034296780825\n",
      "Epoch: 161, Loss: 3.6089, Train: 0.9967, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 3.612227201461792 | KNN Loss: 3.6058547496795654 | CLS Loss: 0.006372358649969101\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 3.5870161056518555 | KNN Loss: 3.5687007904052734 | CLS Loss: 0.018315304070711136\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 3.6270084381103516 | KNN Loss: 3.6206130981445312 | CLS Loss: 0.00639530923217535\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 3.6365163326263428 | KNN Loss: 3.6265828609466553 | CLS Loss: 0.009933524765074253\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 3.6330008506774902 | KNN Loss: 3.6021134853363037 | CLS Loss: 0.0308874249458313\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 3.6215145587921143 | KNN Loss: 3.60975980758667 | CLS Loss: 0.011754672974348068\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 3.614471673965454 | KNN Loss: 3.607591152191162 | CLS Loss: 0.006880518514662981\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 3.619647264480591 | KNN Loss: 3.6153228282928467 | CLS Loss: 0.004324410576373339\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 3.602071523666382 | KNN Loss: 3.5975136756896973 | CLS Loss: 0.004557840060442686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 3.6324679851531982 | KNN Loss: 3.6206247806549072 | CLS Loss: 0.011843198910355568\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 3.652033567428589 | KNN Loss: 3.6354427337646484 | CLS Loss: 0.016590747982263565\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 3.591543436050415 | KNN Loss: 3.589052200317383 | CLS Loss: 0.0024913023225963116\n",
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 3.6497058868408203 | KNN Loss: 3.6349241733551025 | CLS Loss: 0.01478164829313755\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 3.6558566093444824 | KNN Loss: 3.6342878341674805 | CLS Loss: 0.02156883478164673\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 3.6092941761016846 | KNN Loss: 3.5913054943084717 | CLS Loss: 0.017988568171858788\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 3.5948421955108643 | KNN Loss: 3.586367130279541 | CLS Loss: 0.008474988862872124\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 3.6540074348449707 | KNN Loss: 3.6489806175231934 | CLS Loss: 0.005026808939874172\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 3.709221363067627 | KNN Loss: 3.701810836791992 | CLS Loss: 0.007410598453134298\n",
      "Epoch: 162, Loss: 3.6221, Train: 0.9973, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 3.6670641899108887 | KNN Loss: 3.659881830215454 | CLS Loss: 0.0071822903119027615\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 3.6077888011932373 | KNN Loss: 3.6046626567840576 | CLS Loss: 0.003126121126115322\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 3.599348783493042 | KNN Loss: 3.5962555408477783 | CLS Loss: 0.0030931802466511726\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 3.586829900741577 | KNN Loss: 3.5816547870635986 | CLS Loss: 0.005175079684704542\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 3.613109827041626 | KNN Loss: 3.588913679122925 | CLS Loss: 0.024196067824959755\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 3.601732015609741 | KNN Loss: 3.5959553718566895 | CLS Loss: 0.005776761099696159\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 3.6443376541137695 | KNN Loss: 3.6190412044525146 | CLS Loss: 0.02529633790254593\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 3.6325454711914062 | KNN Loss: 3.618640422821045 | CLS Loss: 0.013905106112360954\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 3.572904586791992 | KNN Loss: 3.5711264610290527 | CLS Loss: 0.0017780509078875184\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 3.639859914779663 | KNN Loss: 3.620483160018921 | CLS Loss: 0.019376711919903755\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 3.6292026042938232 | KNN Loss: 3.608093738555908 | CLS Loss: 0.021108876913785934\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 3.676466941833496 | KNN Loss: 3.663301467895508 | CLS Loss: 0.013165480457246304\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 3.6059587001800537 | KNN Loss: 3.5866334438323975 | CLS Loss: 0.019325152039527893\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 3.598386526107788 | KNN Loss: 3.5950329303741455 | CLS Loss: 0.0033535826951265335\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 3.5923287868499756 | KNN Loss: 3.5828568935394287 | CLS Loss: 0.009471929632127285\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 3.6365911960601807 | KNN Loss: 3.621230363845825 | CLS Loss: 0.015360729768872261\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 3.5892770290374756 | KNN Loss: 3.580489158630371 | CLS Loss: 0.008787881582975388\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 3.6307828426361084 | KNN Loss: 3.6194305419921875 | CLS Loss: 0.01135221216827631\n",
      "Epoch: 163, Loss: 3.6117, Train: 0.9974, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 3.612797975540161 | KNN Loss: 3.6026878356933594 | CLS Loss: 0.010110174305737019\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 3.640394449234009 | KNN Loss: 3.6178061962127686 | CLS Loss: 0.02258835732936859\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 3.603679656982422 | KNN Loss: 3.601005792617798 | CLS Loss: 0.0026737460866570473\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 3.5825819969177246 | KNN Loss: 3.5669729709625244 | CLS Loss: 0.015609035268425941\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 3.603782892227173 | KNN Loss: 3.6010661125183105 | CLS Loss: 0.002716880291700363\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 3.6207878589630127 | KNN Loss: 3.618709087371826 | CLS Loss: 0.0020788314286619425\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 3.5737829208374023 | KNN Loss: 3.572477340698242 | CLS Loss: 0.0013055700110271573\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 3.581200122833252 | KNN Loss: 3.5781679153442383 | CLS Loss: 0.003032305045053363\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 3.6026134490966797 | KNN Loss: 3.5901243686676025 | CLS Loss: 0.012489065527915955\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 3.599428415298462 | KNN Loss: 3.592559814453125 | CLS Loss: 0.006868673954159021\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 3.6081228256225586 | KNN Loss: 3.59731125831604 | CLS Loss: 0.010811539366841316\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 3.5982553958892822 | KNN Loss: 3.5937249660491943 | CLS Loss: 0.004530361853539944\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 3.6380887031555176 | KNN Loss: 3.612483501434326 | CLS Loss: 0.025605103000998497\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 3.6662824153900146 | KNN Loss: 3.663072347640991 | CLS Loss: 0.0032100474927574396\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 3.6449551582336426 | KNN Loss: 3.615798234939575 | CLS Loss: 0.029157035052776337\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 3.631002187728882 | KNN Loss: 3.621321439743042 | CLS Loss: 0.009680656716227531\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 3.6096789836883545 | KNN Loss: 3.602997303009033 | CLS Loss: 0.006681597325950861\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 3.5991170406341553 | KNN Loss: 3.5709686279296875 | CLS Loss: 0.028148485347628593\n",
      "Epoch: 164, Loss: 3.6092, Train: 0.9959, Valid: 0.9845, Best: 0.9873\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 3.610485792160034 | KNN Loss: 3.5953316688537598 | CLS Loss: 0.015154151245951653\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 3.607569932937622 | KNN Loss: 3.599177598953247 | CLS Loss: 0.008392423391342163\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 3.5762884616851807 | KNN Loss: 3.574122190475464 | CLS Loss: 0.0021662688814103603\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 3.575608491897583 | KNN Loss: 3.573427200317383 | CLS Loss: 0.0021813849452883005\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 3.6005265712738037 | KNN Loss: 3.5975217819213867 | CLS Loss: 0.003004854777827859\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 3.5779314041137695 | KNN Loss: 3.573289394378662 | CLS Loss: 0.004642043728381395\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 3.592885732650757 | KNN Loss: 3.5768585205078125 | CLS Loss: 0.016027316451072693\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 3.6379077434539795 | KNN Loss: 3.626908540725708 | CLS Loss: 0.010999281890690327\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 3.6148135662078857 | KNN Loss: 3.606433391571045 | CLS Loss: 0.008380142971873283\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 3.647843599319458 | KNN Loss: 3.599125862121582 | CLS Loss: 0.04871770739555359\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 3.5965535640716553 | KNN Loss: 3.5905327796936035 | CLS Loss: 0.006020839791744947\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 3.604750156402588 | KNN Loss: 3.60136079788208 | CLS Loss: 0.0033892598003149033\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 3.5951344966888428 | KNN Loss: 3.5887436866760254 | CLS Loss: 0.006390738300979137\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 3.57668399810791 | KNN Loss: 3.556406021118164 | CLS Loss: 0.020277876406908035\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 3.6049256324768066 | KNN Loss: 3.594326972961426 | CLS Loss: 0.010598570108413696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 3.625072956085205 | KNN Loss: 3.586512804031372 | CLS Loss: 0.038560230284929276\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 3.6518633365631104 | KNN Loss: 3.634127616882324 | CLS Loss: 0.017735827714204788\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 3.6123790740966797 | KNN Loss: 3.607651472091675 | CLS Loss: 0.004727485589683056\n",
      "Epoch: 165, Loss: 3.6103, Train: 0.9953, Valid: 0.9835, Best: 0.9873\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 3.658466339111328 | KNN Loss: 3.6255409717559814 | CLS Loss: 0.03292524814605713\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 3.614391326904297 | KNN Loss: 3.6020262241363525 | CLS Loss: 0.012365058064460754\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 3.6320271492004395 | KNN Loss: 3.6207103729248047 | CLS Loss: 0.011316860094666481\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 3.623945474624634 | KNN Loss: 3.601285934448242 | CLS Loss: 0.022659551352262497\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 3.6122422218322754 | KNN Loss: 3.607516288757324 | CLS Loss: 0.0047258357517421246\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 3.594935417175293 | KNN Loss: 3.5930635929107666 | CLS Loss: 0.0018718339269980788\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 3.5796709060668945 | KNN Loss: 3.5778825283050537 | CLS Loss: 0.001788265653885901\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 3.591550588607788 | KNN Loss: 3.579331636428833 | CLS Loss: 0.012219016440212727\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 3.6130213737487793 | KNN Loss: 3.611729621887207 | CLS Loss: 0.0012918212451040745\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 3.583054542541504 | KNN Loss: 3.577021598815918 | CLS Loss: 0.006032978184521198\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 3.6078238487243652 | KNN Loss: 3.6002190113067627 | CLS Loss: 0.007604846265166998\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 3.6102561950683594 | KNN Loss: 3.6016738414764404 | CLS Loss: 0.00858225580304861\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 3.5929036140441895 | KNN Loss: 3.5894124507904053 | CLS Loss: 0.003491271985694766\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 3.604351758956909 | KNN Loss: 3.602881908416748 | CLS Loss: 0.0014699045568704605\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 3.5833511352539062 | KNN Loss: 3.5782506465911865 | CLS Loss: 0.0051004341803491116\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 3.606436252593994 | KNN Loss: 3.598355770111084 | CLS Loss: 0.00808055978268385\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 3.590959310531616 | KNN Loss: 3.5876669883728027 | CLS Loss: 0.003292259993031621\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 3.6152281761169434 | KNN Loss: 3.589609384536743 | CLS Loss: 0.02561870962381363\n",
      "Epoch: 166, Loss: 3.6104, Train: 0.9975, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 3.658238410949707 | KNN Loss: 3.6499838829040527 | CLS Loss: 0.008254477754235268\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 3.5975944995880127 | KNN Loss: 3.5836219787597656 | CLS Loss: 0.013972613960504532\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 3.66477632522583 | KNN Loss: 3.644768714904785 | CLS Loss: 0.02000749669969082\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 3.5595946311950684 | KNN Loss: 3.55831241607666 | CLS Loss: 0.001282123732380569\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 3.584268093109131 | KNN Loss: 3.5817830562591553 | CLS Loss: 0.0024849525652825832\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 3.602522611618042 | KNN Loss: 3.5887460708618164 | CLS Loss: 0.013776618987321854\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 3.5947630405426025 | KNN Loss: 3.584012031555176 | CLS Loss: 0.01075089629739523\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 3.6674046516418457 | KNN Loss: 3.6637685298919678 | CLS Loss: 0.0036362288519740105\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 3.604008913040161 | KNN Loss: 3.5997915267944336 | CLS Loss: 0.004217322915792465\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 3.639857292175293 | KNN Loss: 3.637913703918457 | CLS Loss: 0.0019435943104326725\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 3.5799689292907715 | KNN Loss: 3.578930377960205 | CLS Loss: 0.0010385538917034864\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 3.652438163757324 | KNN Loss: 3.646977424621582 | CLS Loss: 0.005460844840854406\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 3.603480815887451 | KNN Loss: 3.5902388095855713 | CLS Loss: 0.013241907581686974\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 3.602224349975586 | KNN Loss: 3.5981600284576416 | CLS Loss: 0.0040644314140081406\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 3.5803778171539307 | KNN Loss: 3.561431407928467 | CLS Loss: 0.018946435302495956\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 3.6133127212524414 | KNN Loss: 3.6012394428253174 | CLS Loss: 0.012073352001607418\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 3.6584105491638184 | KNN Loss: 3.6384642124176025 | CLS Loss: 0.019946333020925522\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 3.594391107559204 | KNN Loss: 3.5772132873535156 | CLS Loss: 0.017177898436784744\n",
      "Epoch: 167, Loss: 3.6115, Train: 0.9974, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 3.6083390712738037 | KNN Loss: 3.5887808799743652 | CLS Loss: 0.019558211788535118\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 3.5743372440338135 | KNN Loss: 3.5713558197021484 | CLS Loss: 0.0029814657755196095\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 3.631521701812744 | KNN Loss: 3.610031843185425 | CLS Loss: 0.02148994617164135\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 3.607805013656616 | KNN Loss: 3.5990326404571533 | CLS Loss: 0.008772474713623524\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 3.6290929317474365 | KNN Loss: 3.6250109672546387 | CLS Loss: 0.0040819235146045685\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 3.6342437267303467 | KNN Loss: 3.6053357124328613 | CLS Loss: 0.028907936066389084\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 3.5977487564086914 | KNN Loss: 3.5914676189422607 | CLS Loss: 0.006281050853431225\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 3.5958852767944336 | KNN Loss: 3.5909464359283447 | CLS Loss: 0.004938899539411068\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 3.608889579772949 | KNN Loss: 3.592844009399414 | CLS Loss: 0.016045542433857918\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 3.648796558380127 | KNN Loss: 3.6187198162078857 | CLS Loss: 0.030076857656240463\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 3.6434242725372314 | KNN Loss: 3.6269547939300537 | CLS Loss: 0.01646955870091915\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 3.5706701278686523 | KNN Loss: 3.56624436378479 | CLS Loss: 0.004425755236297846\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 3.5825653076171875 | KNN Loss: 3.5783801078796387 | CLS Loss: 0.004185104742646217\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 3.6024301052093506 | KNN Loss: 3.60048246383667 | CLS Loss: 0.0019475618610158563\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 3.606780767440796 | KNN Loss: 3.5908398628234863 | CLS Loss: 0.015940990298986435\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 3.598010778427124 | KNN Loss: 3.588369607925415 | CLS Loss: 0.009641142562031746\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 3.6127796173095703 | KNN Loss: 3.601381301879883 | CLS Loss: 0.011398284696042538\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 3.631462574005127 | KNN Loss: 3.6155853271484375 | CLS Loss: 0.015877239406108856\n",
      "Epoch: 168, Loss: 3.6162, Train: 0.9971, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 3.5959904193878174 | KNN Loss: 3.585813283920288 | CLS Loss: 0.010177068412303925\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 3.5861966609954834 | KNN Loss: 3.578441619873047 | CLS Loss: 0.007754971738904715\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 3.6676037311553955 | KNN Loss: 3.6623330116271973 | CLS Loss: 0.00527061615139246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 3.64953351020813 | KNN Loss: 3.6454033851623535 | CLS Loss: 0.004130121320486069\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 3.6368253231048584 | KNN Loss: 3.6022422313690186 | CLS Loss: 0.03458316996693611\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 3.624819040298462 | KNN Loss: 3.6238741874694824 | CLS Loss: 0.0009449228527955711\n",
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 3.5972673892974854 | KNN Loss: 3.5870914459228516 | CLS Loss: 0.010175846517086029\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 3.574266195297241 | KNN Loss: 3.566946268081665 | CLS Loss: 0.007320007774978876\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 3.6083102226257324 | KNN Loss: 3.6007401943206787 | CLS Loss: 0.007570106070488691\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 3.616387367248535 | KNN Loss: 3.6151654720306396 | CLS Loss: 0.0012219223426654935\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 3.5915424823760986 | KNN Loss: 3.58522891998291 | CLS Loss: 0.006313580088317394\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 3.597996473312378 | KNN Loss: 3.5950729846954346 | CLS Loss: 0.0029233917593955994\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 3.63984751701355 | KNN Loss: 3.631743907928467 | CLS Loss: 0.00810353085398674\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 3.5903496742248535 | KNN Loss: 3.5870742797851562 | CLS Loss: 0.0032754940912127495\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 3.645185947418213 | KNN Loss: 3.625819206237793 | CLS Loss: 0.01936664991080761\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 3.5869300365448 | KNN Loss: 3.585160732269287 | CLS Loss: 0.0017692593391984701\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 3.633559465408325 | KNN Loss: 3.6303515434265137 | CLS Loss: 0.0032078835647553205\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 3.603022575378418 | KNN Loss: 3.5996811389923096 | CLS Loss: 0.0033414040226489305\n",
      "Epoch: 169, Loss: 3.6118, Train: 0.9966, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 3.665388345718384 | KNN Loss: 3.653679609298706 | CLS Loss: 0.011708674021065235\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 3.5989222526550293 | KNN Loss: 3.594123363494873 | CLS Loss: 0.004798860754817724\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 3.610224962234497 | KNN Loss: 3.6081109046936035 | CLS Loss: 0.002114099683240056\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 3.6074249744415283 | KNN Loss: 3.599691152572632 | CLS Loss: 0.007733919657766819\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 3.5978634357452393 | KNN Loss: 3.5918092727661133 | CLS Loss: 0.006054208148270845\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 3.626622438430786 | KNN Loss: 3.6177785396575928 | CLS Loss: 0.008843907155096531\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 3.6196064949035645 | KNN Loss: 3.598059892654419 | CLS Loss: 0.02154660038650036\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 3.6290154457092285 | KNN Loss: 3.6214640140533447 | CLS Loss: 0.00755145400762558\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 3.626230239868164 | KNN Loss: 3.6071043014526367 | CLS Loss: 0.01912583038210869\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 3.56738543510437 | KNN Loss: 3.56260085105896 | CLS Loss: 0.004784530494362116\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 3.559814929962158 | KNN Loss: 3.5529961585998535 | CLS Loss: 0.006818705704063177\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 3.625441074371338 | KNN Loss: 3.606816530227661 | CLS Loss: 0.018624553456902504\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 3.577059268951416 | KNN Loss: 3.566865921020508 | CLS Loss: 0.01019324455410242\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 3.663128137588501 | KNN Loss: 3.658735752105713 | CLS Loss: 0.004392419476062059\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 3.626105785369873 | KNN Loss: 3.6034016609191895 | CLS Loss: 0.022704120725393295\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 3.5848984718322754 | KNN Loss: 3.5836944580078125 | CLS Loss: 0.0012039184803143144\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 3.6184256076812744 | KNN Loss: 3.6039998531341553 | CLS Loss: 0.014425678178668022\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 3.6076598167419434 | KNN Loss: 3.595569610595703 | CLS Loss: 0.012090185657143593\n",
      "Epoch: 170, Loss: 3.6119, Train: 0.9955, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 3.67577862739563 | KNN Loss: 3.6708426475524902 | CLS Loss: 0.004935910925269127\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 3.600860595703125 | KNN Loss: 3.5943360328674316 | CLS Loss: 0.0065244752913713455\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 3.628025531768799 | KNN Loss: 3.618605136871338 | CLS Loss: 0.009420408867299557\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 3.5932047367095947 | KNN Loss: 3.5829389095306396 | CLS Loss: 0.010265739634633064\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 3.631516218185425 | KNN Loss: 3.618015766143799 | CLS Loss: 0.013500368222594261\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 3.6139185428619385 | KNN Loss: 3.601182699203491 | CLS Loss: 0.012735777534544468\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 3.5964834690093994 | KNN Loss: 3.5812034606933594 | CLS Loss: 0.015279960818588734\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 3.5996012687683105 | KNN Loss: 3.5898900032043457 | CLS Loss: 0.009711254388093948\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 3.611420154571533 | KNN Loss: 3.6053988933563232 | CLS Loss: 0.006021362729370594\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 3.620795249938965 | KNN Loss: 3.610452175140381 | CLS Loss: 0.010343002155423164\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 3.5932509899139404 | KNN Loss: 3.5894856452941895 | CLS Loss: 0.0037653411272913218\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 3.5834813117980957 | KNN Loss: 3.5616822242736816 | CLS Loss: 0.02179899252951145\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 3.6133241653442383 | KNN Loss: 3.5927886962890625 | CLS Loss: 0.020535368472337723\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 3.6306612491607666 | KNN Loss: 3.6220102310180664 | CLS Loss: 0.008650902658700943\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 3.6329305171966553 | KNN Loss: 3.626521348953247 | CLS Loss: 0.006409286055713892\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 3.59322452545166 | KNN Loss: 3.5847208499908447 | CLS Loss: 0.008503660559654236\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 3.637071371078491 | KNN Loss: 3.6101419925689697 | CLS Loss: 0.02692931331694126\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 3.6036930084228516 | KNN Loss: 3.592697858810425 | CLS Loss: 0.010995174758136272\n",
      "Epoch: 171, Loss: 3.6150, Train: 0.9965, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 3.599637985229492 | KNN Loss: 3.5954153537750244 | CLS Loss: 0.004222646355628967\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 3.57741117477417 | KNN Loss: 3.5718162059783936 | CLS Loss: 0.005594976246356964\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 3.5998685359954834 | KNN Loss: 3.592907428741455 | CLS Loss: 0.006961214821785688\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 3.572786331176758 | KNN Loss: 3.5683488845825195 | CLS Loss: 0.004437469877302647\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 3.6755762100219727 | KNN Loss: 3.6568846702575684 | CLS Loss: 0.018691474571824074\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 3.598111867904663 | KNN Loss: 3.595367670059204 | CLS Loss: 0.002744252560660243\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 3.601513624191284 | KNN Loss: 3.584733009338379 | CLS Loss: 0.01678071729838848\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 3.59991455078125 | KNN Loss: 3.573289632797241 | CLS Loss: 0.026624932885169983\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 3.634766101837158 | KNN Loss: 3.6255946159362793 | CLS Loss: 0.00917159952223301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 3.643503427505493 | KNN Loss: 3.628448963165283 | CLS Loss: 0.015054397284984589\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 3.6177072525024414 | KNN Loss: 3.6021597385406494 | CLS Loss: 0.015547611750662327\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 3.5977001190185547 | KNN Loss: 3.5921237468719482 | CLS Loss: 0.005576361436396837\n",
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 3.6594042778015137 | KNN Loss: 3.652432680130005 | CLS Loss: 0.006971603259444237\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 3.6650748252868652 | KNN Loss: 3.6298720836639404 | CLS Loss: 0.035202641040086746\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 3.6301209926605225 | KNN Loss: 3.6064422130584717 | CLS Loss: 0.023678747937083244\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 3.610697031021118 | KNN Loss: 3.609217882156372 | CLS Loss: 0.0014790728455409408\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 3.576448917388916 | KNN Loss: 3.571025848388672 | CLS Loss: 0.005423157941550016\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 3.5889222621917725 | KNN Loss: 3.581188201904297 | CLS Loss: 0.007734027691185474\n",
      "Epoch: 172, Loss: 3.6182, Train: 0.9976, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 3.599663734436035 | KNN Loss: 3.579535484313965 | CLS Loss: 0.020128173753619194\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 3.6046323776245117 | KNN Loss: 3.599310874938965 | CLS Loss: 0.005321477074176073\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 3.6176912784576416 | KNN Loss: 3.6166813373565674 | CLS Loss: 0.0010098859202116728\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 3.629544734954834 | KNN Loss: 3.618786096572876 | CLS Loss: 0.010758675634860992\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 3.6135036945343018 | KNN Loss: 3.5900461673736572 | CLS Loss: 0.023457640781998634\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 3.59907865524292 | KNN Loss: 3.593195676803589 | CLS Loss: 0.005882997065782547\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 3.624835729598999 | KNN Loss: 3.6065359115600586 | CLS Loss: 0.018299752846360207\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 3.6331863403320312 | KNN Loss: 3.6129558086395264 | CLS Loss: 0.020230581983923912\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 3.629504919052124 | KNN Loss: 3.6276438236236572 | CLS Loss: 0.0018611005507409573\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 3.6374664306640625 | KNN Loss: 3.633338212966919 | CLS Loss: 0.004128309432417154\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 3.604841470718384 | KNN Loss: 3.5981645584106445 | CLS Loss: 0.006677029654383659\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 3.6286561489105225 | KNN Loss: 3.612981081008911 | CLS Loss: 0.01567506417632103\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 3.6650216579437256 | KNN Loss: 3.6595537662506104 | CLS Loss: 0.00546799972653389\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 3.6045420169830322 | KNN Loss: 3.599252223968506 | CLS Loss: 0.005289676133543253\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 3.6037087440490723 | KNN Loss: 3.593903064727783 | CLS Loss: 0.009805762208998203\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 3.6126911640167236 | KNN Loss: 3.6064703464508057 | CLS Loss: 0.006220747251063585\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 3.6574618816375732 | KNN Loss: 3.6473119258880615 | CLS Loss: 0.010150055401027203\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 3.621811628341675 | KNN Loss: 3.6091384887695312 | CLS Loss: 0.012673098593950272\n",
      "Epoch: 173, Loss: 3.6112, Train: 0.9974, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 3.633854866027832 | KNN Loss: 3.6157684326171875 | CLS Loss: 0.018086416646838188\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 3.5800323486328125 | KNN Loss: 3.5708670616149902 | CLS Loss: 0.009165323339402676\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 3.605377674102783 | KNN Loss: 3.587644100189209 | CLS Loss: 0.017733652144670486\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 3.591449499130249 | KNN Loss: 3.5855624675750732 | CLS Loss: 0.0058870865032076836\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 3.6141085624694824 | KNN Loss: 3.598463535308838 | CLS Loss: 0.015645109117031097\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 3.5937211513519287 | KNN Loss: 3.5872137546539307 | CLS Loss: 0.006507469341158867\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 3.580303907394409 | KNN Loss: 3.576894521713257 | CLS Loss: 0.0034093454014509916\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 3.564175844192505 | KNN Loss: 3.561382293701172 | CLS Loss: 0.002793662017211318\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 3.6097826957702637 | KNN Loss: 3.604236125946045 | CLS Loss: 0.005546542350202799\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 3.603119134902954 | KNN Loss: 3.596794605255127 | CLS Loss: 0.006324585992842913\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 3.573087692260742 | KNN Loss: 3.5718159675598145 | CLS Loss: 0.0012716579949483275\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 3.600447654724121 | KNN Loss: 3.596494436264038 | CLS Loss: 0.003953327890485525\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 3.6286234855651855 | KNN Loss: 3.6104893684387207 | CLS Loss: 0.018134072422981262\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 3.6106083393096924 | KNN Loss: 3.5911972522735596 | CLS Loss: 0.019411087036132812\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 3.609036445617676 | KNN Loss: 3.5812718868255615 | CLS Loss: 0.027764441445469856\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 3.6554837226867676 | KNN Loss: 3.6500465869903564 | CLS Loss: 0.005437133368104696\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 3.615105152130127 | KNN Loss: 3.5969810485839844 | CLS Loss: 0.018124151974916458\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 3.632493257522583 | KNN Loss: 3.6014394760131836 | CLS Loss: 0.03105372190475464\n",
      "Epoch: 174, Loss: 3.6119, Train: 0.9974, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 3.604858636856079 | KNN Loss: 3.5957751274108887 | CLS Loss: 0.009083588607609272\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 3.6065616607666016 | KNN Loss: 3.5953164100646973 | CLS Loss: 0.011245299130678177\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 3.5834336280822754 | KNN Loss: 3.5719234943389893 | CLS Loss: 0.01151010300964117\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 3.596237897872925 | KNN Loss: 3.593562126159668 | CLS Loss: 0.002675809431821108\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 3.5837607383728027 | KNN Loss: 3.5786874294281006 | CLS Loss: 0.005073218140751123\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 3.638766288757324 | KNN Loss: 3.6112327575683594 | CLS Loss: 0.02753342315554619\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 3.620936155319214 | KNN Loss: 3.5939629077911377 | CLS Loss: 0.02697324939072132\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 3.5976457595825195 | KNN Loss: 3.5963642597198486 | CLS Loss: 0.0012813885696232319\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 3.5855164527893066 | KNN Loss: 3.5797948837280273 | CLS Loss: 0.005721676629036665\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 3.6633777618408203 | KNN Loss: 3.64833402633667 | CLS Loss: 0.015043742954730988\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 3.6883182525634766 | KNN Loss: 3.6692237854003906 | CLS Loss: 0.019094368442893028\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 3.5981764793395996 | KNN Loss: 3.587181329727173 | CLS Loss: 0.010995141230523586\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 3.663933277130127 | KNN Loss: 3.6551315784454346 | CLS Loss: 0.008801665157079697\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 3.6079657077789307 | KNN Loss: 3.593912363052368 | CLS Loss: 0.014053234830498695\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 3.6432411670684814 | KNN Loss: 3.622936248779297 | CLS Loss: 0.02030498906970024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 3.592108964920044 | KNN Loss: 3.579643964767456 | CLS Loss: 0.012464931234717369\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 3.67590594291687 | KNN Loss: 3.662576198577881 | CLS Loss: 0.013329686596989632\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 3.6042051315307617 | KNN Loss: 3.6005187034606934 | CLS Loss: 0.0036863936111330986\n",
      "Epoch: 175, Loss: 3.6178, Train: 0.9960, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 3.6242218017578125 | KNN Loss: 3.6086461544036865 | CLS Loss: 0.015575655736029148\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 3.610130548477173 | KNN Loss: 3.6018142700195312 | CLS Loss: 0.00831635296344757\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 3.662177085876465 | KNN Loss: 3.6481142044067383 | CLS Loss: 0.014062825590372086\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 3.614053726196289 | KNN Loss: 3.5913026332855225 | CLS Loss: 0.022751133888959885\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 3.6007189750671387 | KNN Loss: 3.585719108581543 | CLS Loss: 0.014999797567725182\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 3.6020476818084717 | KNN Loss: 3.596449613571167 | CLS Loss: 0.005598136223852634\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 3.59552264213562 | KNN Loss: 3.593475341796875 | CLS Loss: 0.0020474183838814497\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 3.639988660812378 | KNN Loss: 3.62628436088562 | CLS Loss: 0.013704245910048485\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 3.6089930534362793 | KNN Loss: 3.6013410091400146 | CLS Loss: 0.007652083411812782\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 3.608309745788574 | KNN Loss: 3.6001343727111816 | CLS Loss: 0.008175491355359554\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 3.585885524749756 | KNN Loss: 3.581997871398926 | CLS Loss: 0.003887713421136141\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 3.615915298461914 | KNN Loss: 3.596970558166504 | CLS Loss: 0.01894463039934635\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 3.606980562210083 | KNN Loss: 3.6018407344818115 | CLS Loss: 0.005139857064932585\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 3.5713653564453125 | KNN Loss: 3.568035840988159 | CLS Loss: 0.003329459810629487\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 3.5941429138183594 | KNN Loss: 3.5900208950042725 | CLS Loss: 0.004122109618037939\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 3.60121488571167 | KNN Loss: 3.5961930751800537 | CLS Loss: 0.005021725781261921\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 3.6032097339630127 | KNN Loss: 3.5919628143310547 | CLS Loss: 0.011246851645410061\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 3.599423885345459 | KNN Loss: 3.59391713142395 | CLS Loss: 0.005506747867912054\n",
      "Epoch: 176, Loss: 3.6136, Train: 0.9955, Valid: 0.9847, Best: 0.9873\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 3.6241965293884277 | KNN Loss: 3.6106696128845215 | CLS Loss: 0.013526879251003265\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 3.6180498600006104 | KNN Loss: 3.6089746952056885 | CLS Loss: 0.009075266309082508\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 3.639976739883423 | KNN Loss: 3.63542103767395 | CLS Loss: 0.004555730614811182\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 3.6345372200012207 | KNN Loss: 3.621490716934204 | CLS Loss: 0.013046436943113804\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 3.624328374862671 | KNN Loss: 3.617863893508911 | CLS Loss: 0.006464450620114803\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 3.607731580734253 | KNN Loss: 3.5834100246429443 | CLS Loss: 0.024321604520082474\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 3.609312057495117 | KNN Loss: 3.6040918827056885 | CLS Loss: 0.005220144987106323\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 3.615037679672241 | KNN Loss: 3.6087963581085205 | CLS Loss: 0.006241260562092066\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 3.583890199661255 | KNN Loss: 3.5824334621429443 | CLS Loss: 0.0014566753525286913\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 3.6552062034606934 | KNN Loss: 3.647122621536255 | CLS Loss: 0.008083664812147617\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 3.61926007270813 | KNN Loss: 3.5991132259368896 | CLS Loss: 0.020146800205111504\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 3.605015754699707 | KNN Loss: 3.5999817848205566 | CLS Loss: 0.005033852066844702\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 3.5821404457092285 | KNN Loss: 3.5750346183776855 | CLS Loss: 0.007105883210897446\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 3.590251922607422 | KNN Loss: 3.580319404602051 | CLS Loss: 0.00993261020630598\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 3.609143018722534 | KNN Loss: 3.607741117477417 | CLS Loss: 0.0014019003137946129\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 3.59661865234375 | KNN Loss: 3.580667018890381 | CLS Loss: 0.015951568260788918\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 3.621741771697998 | KNN Loss: 3.6163852214813232 | CLS Loss: 0.005356458481401205\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 3.6727371215820312 | KNN Loss: 3.6463584899902344 | CLS Loss: 0.026378750801086426\n",
      "Epoch: 177, Loss: 3.6150, Train: 0.9965, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 3.591336965560913 | KNN Loss: 3.586230993270874 | CLS Loss: 0.005105855409055948\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 3.6077022552490234 | KNN Loss: 3.604942798614502 | CLS Loss: 0.0027595083229243755\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 3.645387887954712 | KNN Loss: 3.6415889263153076 | CLS Loss: 0.003798983059823513\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 3.6205220222473145 | KNN Loss: 3.612340211868286 | CLS Loss: 0.008181808516383171\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 3.593007802963257 | KNN Loss: 3.5812644958496094 | CLS Loss: 0.011743339709937572\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 3.5927071571350098 | KNN Loss: 3.582465410232544 | CLS Loss: 0.010241635143756866\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 3.6363449096679688 | KNN Loss: 3.6282174587249756 | CLS Loss: 0.00812735129147768\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 3.5749101638793945 | KNN Loss: 3.56935453414917 | CLS Loss: 0.00555573171004653\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 3.6071457862854004 | KNN Loss: 3.579725742340088 | CLS Loss: 0.027420036494731903\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 3.622105121612549 | KNN Loss: 3.6171045303344727 | CLS Loss: 0.005000551231205463\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 3.6485390663146973 | KNN Loss: 3.638073205947876 | CLS Loss: 0.010465952567756176\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 3.6495354175567627 | KNN Loss: 3.6394495964050293 | CLS Loss: 0.010085733607411385\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 3.576000690460205 | KNN Loss: 3.570298433303833 | CLS Loss: 0.005702318623661995\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 3.6118979454040527 | KNN Loss: 3.5903239250183105 | CLS Loss: 0.021574024111032486\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 3.584684371948242 | KNN Loss: 3.5823283195495605 | CLS Loss: 0.002356150420382619\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 3.598294496536255 | KNN Loss: 3.590538263320923 | CLS Loss: 0.007756120525300503\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 3.6402125358581543 | KNN Loss: 3.621466636657715 | CLS Loss: 0.018745943903923035\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 3.686392307281494 | KNN Loss: 3.6825473308563232 | CLS Loss: 0.0038448916748166084\n",
      "Epoch: 178, Loss: 3.6135, Train: 0.9970, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 3.621967077255249 | KNN Loss: 3.6196818351745605 | CLS Loss: 0.0022851889953017235\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 3.6117360591888428 | KNN Loss: 3.5981762409210205 | CLS Loss: 0.013559725135564804\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 3.6249685287475586 | KNN Loss: 3.614563226699829 | CLS Loss: 0.01040519867092371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 3.628148078918457 | KNN Loss: 3.5964274406433105 | CLS Loss: 0.031720541417598724\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 3.644183397293091 | KNN Loss: 3.635913133621216 | CLS Loss: 0.008270302787423134\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 3.6128337383270264 | KNN Loss: 3.5976450443267822 | CLS Loss: 0.015188588760793209\n",
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 3.6255431175231934 | KNN Loss: 3.6192498207092285 | CLS Loss: 0.006293192505836487\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 3.595693588256836 | KNN Loss: 3.5863776206970215 | CLS Loss: 0.009315891191363335\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 3.657918691635132 | KNN Loss: 3.6547350883483887 | CLS Loss: 0.003183704800903797\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 3.6026127338409424 | KNN Loss: 3.5928945541381836 | CLS Loss: 0.009718182496726513\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 3.6397223472595215 | KNN Loss: 3.632829189300537 | CLS Loss: 0.006893202196806669\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 3.612717390060425 | KNN Loss: 3.609379291534424 | CLS Loss: 0.003338185604661703\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 3.638559579849243 | KNN Loss: 3.621875762939453 | CLS Loss: 0.016683919355273247\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 3.607722759246826 | KNN Loss: 3.6007988452911377 | CLS Loss: 0.00692389253526926\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 3.6360549926757812 | KNN Loss: 3.6255295276641846 | CLS Loss: 0.010525534860789776\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 3.5861599445343018 | KNN Loss: 3.5845887660980225 | CLS Loss: 0.0015711564337834716\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 3.588449239730835 | KNN Loss: 3.585575580596924 | CLS Loss: 0.002873562043532729\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 3.595677137374878 | KNN Loss: 3.5873076915740967 | CLS Loss: 0.00836935080587864\n",
      "Epoch: 179, Loss: 3.6147, Train: 0.9980, Valid: 0.9870, Best: 0.9873\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 3.5748488903045654 | KNN Loss: 3.5730905532836914 | CLS Loss: 0.0017584379529580474\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 3.5837016105651855 | KNN Loss: 3.577425241470337 | CLS Loss: 0.006276432424783707\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 3.5928196907043457 | KNN Loss: 3.583632230758667 | CLS Loss: 0.00918741337954998\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 3.6076440811157227 | KNN Loss: 3.6026554107666016 | CLS Loss: 0.004988744854927063\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 3.619661569595337 | KNN Loss: 3.5881741046905518 | CLS Loss: 0.03148757293820381\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 3.6223199367523193 | KNN Loss: 3.614283323287964 | CLS Loss: 0.008036511018872261\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 3.6367225646972656 | KNN Loss: 3.6272993087768555 | CLS Loss: 0.009423281066119671\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 3.640315055847168 | KNN Loss: 3.6359524726867676 | CLS Loss: 0.004362691193819046\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 3.5823984146118164 | KNN Loss: 3.5696160793304443 | CLS Loss: 0.012782321311533451\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 3.615363836288452 | KNN Loss: 3.612781524658203 | CLS Loss: 0.0025822934694588184\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 3.592139959335327 | KNN Loss: 3.5797886848449707 | CLS Loss: 0.012351274490356445\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 3.5789597034454346 | KNN Loss: 3.5778160095214844 | CLS Loss: 0.0011436366476118565\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 3.706040859222412 | KNN Loss: 3.678967237472534 | CLS Loss: 0.02707371860742569\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 3.640857458114624 | KNN Loss: 3.630176067352295 | CLS Loss: 0.010681312531232834\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 3.604475736618042 | KNN Loss: 3.5941340923309326 | CLS Loss: 0.010341743007302284\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 3.5929248332977295 | KNN Loss: 3.5833208560943604 | CLS Loss: 0.009604058228433132\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 3.675588369369507 | KNN Loss: 3.6734490394592285 | CLS Loss: 0.0021393003407865763\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 3.5833311080932617 | KNN Loss: 3.569606304168701 | CLS Loss: 0.013724710792303085\n",
      "Epoch: 180, Loss: 3.6139, Train: 0.9967, Valid: 0.9844, Best: 0.9873\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 3.5922603607177734 | KNN Loss: 3.589715003967285 | CLS Loss: 0.002545374445617199\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 3.590005397796631 | KNN Loss: 3.5883066654205322 | CLS Loss: 0.0016986840637400746\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 3.596956729888916 | KNN Loss: 3.5909698009490967 | CLS Loss: 0.0059869312681257725\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 3.5623958110809326 | KNN Loss: 3.5574443340301514 | CLS Loss: 0.004951474256813526\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 3.6119110584259033 | KNN Loss: 3.6043200492858887 | CLS Loss: 0.00759095698595047\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 3.643167495727539 | KNN Loss: 3.6412549018859863 | CLS Loss: 0.0019127086270600557\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 3.5886712074279785 | KNN Loss: 3.580571413040161 | CLS Loss: 0.008099711500108242\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 3.563967227935791 | KNN Loss: 3.561932325363159 | CLS Loss: 0.0020348848775029182\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 3.577057123184204 | KNN Loss: 3.5631563663482666 | CLS Loss: 0.013900813646614552\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 3.577233076095581 | KNN Loss: 3.5717170238494873 | CLS Loss: 0.005515937227755785\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 3.6128458976745605 | KNN Loss: 3.594198703765869 | CLS Loss: 0.018647296354174614\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 3.5929577350616455 | KNN Loss: 3.5841941833496094 | CLS Loss: 0.008763442747294903\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 3.608583927154541 | KNN Loss: 3.5968759059906006 | CLS Loss: 0.011707980185747147\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 3.590211868286133 | KNN Loss: 3.5862271785736084 | CLS Loss: 0.003984744194895029\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 3.5784876346588135 | KNN Loss: 3.5747811794281006 | CLS Loss: 0.0037064068019390106\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 3.621185779571533 | KNN Loss: 3.605717420578003 | CLS Loss: 0.015468396246433258\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 3.6139354705810547 | KNN Loss: 3.6093249320983887 | CLS Loss: 0.004610474221408367\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 3.6023590564727783 | KNN Loss: 3.5921032428741455 | CLS Loss: 0.010255787521600723\n",
      "Epoch: 181, Loss: 3.6090, Train: 0.9971, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 3.6352901458740234 | KNN Loss: 3.6291980743408203 | CLS Loss: 0.00609208270907402\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 3.619464635848999 | KNN Loss: 3.611961841583252 | CLS Loss: 0.007502757012844086\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 3.609685182571411 | KNN Loss: 3.5789265632629395 | CLS Loss: 0.030758626759052277\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 3.602104663848877 | KNN Loss: 3.5897092819213867 | CLS Loss: 0.012395268306136131\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 3.608156442642212 | KNN Loss: 3.5880539417266846 | CLS Loss: 0.020102540031075478\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 3.5871829986572266 | KNN Loss: 3.58374285697937 | CLS Loss: 0.0034400448203086853\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 3.5971322059631348 | KNN Loss: 3.5914194583892822 | CLS Loss: 0.005712674930691719\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 3.594998598098755 | KNN Loss: 3.5872583389282227 | CLS Loss: 0.007740270346403122\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 3.614445686340332 | KNN Loss: 3.588332176208496 | CLS Loss: 0.026113606989383698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 3.6130211353302 | KNN Loss: 3.600275993347168 | CLS Loss: 0.012745173647999763\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 3.6137053966522217 | KNN Loss: 3.6059470176696777 | CLS Loss: 0.007758395280689001\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 3.617621421813965 | KNN Loss: 3.5978212356567383 | CLS Loss: 0.019800256937742233\n",
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 3.5986597537994385 | KNN Loss: 3.594216823577881 | CLS Loss: 0.004443038254976273\n",
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 3.6056764125823975 | KNN Loss: 3.5979807376861572 | CLS Loss: 0.007695665583014488\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 3.592532157897949 | KNN Loss: 3.5888452529907227 | CLS Loss: 0.00368681363761425\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 3.566488265991211 | KNN Loss: 3.5656583309173584 | CLS Loss: 0.0008300240151584148\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 3.630868673324585 | KNN Loss: 3.62485671043396 | CLS Loss: 0.006011909805238247\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 3.625746965408325 | KNN Loss: 3.607665777206421 | CLS Loss: 0.01808118261396885\n",
      "Epoch: 182, Loss: 3.6101, Train: 0.9967, Valid: 0.9850, Best: 0.9873\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 3.6616930961608887 | KNN Loss: 3.6478893756866455 | CLS Loss: 0.013803775422275066\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 3.5844104290008545 | KNN Loss: 3.57214093208313 | CLS Loss: 0.012269495986402035\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 3.6464459896087646 | KNN Loss: 3.6304571628570557 | CLS Loss: 0.015988731756806374\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 3.574436664581299 | KNN Loss: 3.5736095905303955 | CLS Loss: 0.000827157637104392\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 3.5999839305877686 | KNN Loss: 3.5902321338653564 | CLS Loss: 0.009751783683896065\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 3.643986225128174 | KNN Loss: 3.6349575519561768 | CLS Loss: 0.009028763510286808\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 3.5931813716888428 | KNN Loss: 3.5858452320098877 | CLS Loss: 0.0073362188413739204\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 3.6111552715301514 | KNN Loss: 3.608628988265991 | CLS Loss: 0.0025262904819101095\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 3.6179606914520264 | KNN Loss: 3.6143784523010254 | CLS Loss: 0.0035823036450892687\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 3.611971616744995 | KNN Loss: 3.6008293628692627 | CLS Loss: 0.011142326518893242\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 3.6417837142944336 | KNN Loss: 3.6297073364257812 | CLS Loss: 0.012076345272362232\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 3.5871801376342773 | KNN Loss: 3.5816898345947266 | CLS Loss: 0.005490276962518692\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 3.5918381214141846 | KNN Loss: 3.5875725746154785 | CLS Loss: 0.0042655812576413155\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 3.602935552597046 | KNN Loss: 3.592667579650879 | CLS Loss: 0.010268005542457104\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 3.645676612854004 | KNN Loss: 3.622284412384033 | CLS Loss: 0.023392315953969955\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 3.5950100421905518 | KNN Loss: 3.5782785415649414 | CLS Loss: 0.016731517389416695\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 3.616848945617676 | KNN Loss: 3.6131973266601562 | CLS Loss: 0.0036516825202852488\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 3.6112895011901855 | KNN Loss: 3.5974442958831787 | CLS Loss: 0.013845181092619896\n",
      "Epoch: 183, Loss: 3.6094, Train: 0.9966, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 3.616379737854004 | KNN Loss: 3.606069564819336 | CLS Loss: 0.010310065932571888\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 3.6219348907470703 | KNN Loss: 3.5924906730651855 | CLS Loss: 0.029444215819239616\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 3.6083686351776123 | KNN Loss: 3.6027615070343018 | CLS Loss: 0.00560706527903676\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 3.6158437728881836 | KNN Loss: 3.6054153442382812 | CLS Loss: 0.010428523644804955\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 3.5963926315307617 | KNN Loss: 3.5791404247283936 | CLS Loss: 0.017252115532755852\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 3.592022180557251 | KNN Loss: 3.5818097591400146 | CLS Loss: 0.01021247822791338\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 3.5927724838256836 | KNN Loss: 3.583570718765259 | CLS Loss: 0.009201789274811745\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 3.5742361545562744 | KNN Loss: 3.571883201599121 | CLS Loss: 0.0023528875317424536\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 3.5774378776550293 | KNN Loss: 3.5702497959136963 | CLS Loss: 0.0071880510076880455\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 3.6241884231567383 | KNN Loss: 3.6192009449005127 | CLS Loss: 0.00498757092282176\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 3.5858561992645264 | KNN Loss: 3.5836353302001953 | CLS Loss: 0.0022207540459930897\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 3.5754103660583496 | KNN Loss: 3.5679590702056885 | CLS Loss: 0.007451303768903017\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 3.624971866607666 | KNN Loss: 3.6136953830718994 | CLS Loss: 0.01127651147544384\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 3.5648770332336426 | KNN Loss: 3.5567445755004883 | CLS Loss: 0.00813256949186325\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 3.6417758464813232 | KNN Loss: 3.6401290893554688 | CLS Loss: 0.001646845368668437\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 3.6171796321868896 | KNN Loss: 3.6056978702545166 | CLS Loss: 0.011481820605695248\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 3.6036226749420166 | KNN Loss: 3.59968638420105 | CLS Loss: 0.003936240915209055\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 3.6178970336914062 | KNN Loss: 3.616286516189575 | CLS Loss: 0.001610431121662259\n",
      "Epoch: 184, Loss: 3.6127, Train: 0.9973, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 3.6256914138793945 | KNN Loss: 3.6155855655670166 | CLS Loss: 0.010105767287313938\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 3.6294240951538086 | KNN Loss: 3.619694709777832 | CLS Loss: 0.009729338809847832\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 3.606663942337036 | KNN Loss: 3.5984432697296143 | CLS Loss: 0.008220701478421688\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 3.629819393157959 | KNN Loss: 3.625818967819214 | CLS Loss: 0.004000383894890547\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 3.588844060897827 | KNN Loss: 3.5802338123321533 | CLS Loss: 0.00861018430441618\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 3.5918030738830566 | KNN Loss: 3.5890965461730957 | CLS Loss: 0.0027065586764365435\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 3.6046125888824463 | KNN Loss: 3.585639238357544 | CLS Loss: 0.0189733374863863\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 3.6309449672698975 | KNN Loss: 3.6275787353515625 | CLS Loss: 0.0033662046771496534\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 3.60368013381958 | KNN Loss: 3.5987942218780518 | CLS Loss: 0.004885923583060503\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 3.6087589263916016 | KNN Loss: 3.6071507930755615 | CLS Loss: 0.0016080646310001612\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 3.6192362308502197 | KNN Loss: 3.610541582107544 | CLS Loss: 0.008694537915289402\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 3.614243984222412 | KNN Loss: 3.605940103530884 | CLS Loss: 0.008303854614496231\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 3.6184651851654053 | KNN Loss: 3.603477954864502 | CLS Loss: 0.014987211674451828\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 3.631279468536377 | KNN Loss: 3.615597724914551 | CLS Loss: 0.015681857243180275\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 3.6095316410064697 | KNN Loss: 3.606987953186035 | CLS Loss: 0.0025435967836529016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 3.5888113975524902 | KNN Loss: 3.582388401031494 | CLS Loss: 0.006422976031899452\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 3.605147361755371 | KNN Loss: 3.5967044830322266 | CLS Loss: 0.008442973718047142\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 3.585801124572754 | KNN Loss: 3.5842857360839844 | CLS Loss: 0.0015154159627854824\n",
      "Epoch: 185, Loss: 3.6157, Train: 0.9977, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 3.6137428283691406 | KNN Loss: 3.60479736328125 | CLS Loss: 0.008945409208536148\n",
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 3.654035806655884 | KNN Loss: 3.6368348598480225 | CLS Loss: 0.017201025038957596\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 3.613801956176758 | KNN Loss: 3.6103832721710205 | CLS Loss: 0.003418781328946352\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 3.6219284534454346 | KNN Loss: 3.596198797225952 | CLS Loss: 0.025729753077030182\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 3.607714891433716 | KNN Loss: 3.602743148803711 | CLS Loss: 0.004971625283360481\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 3.5889511108398438 | KNN Loss: 3.585728168487549 | CLS Loss: 0.00322294095531106\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 3.6647183895111084 | KNN Loss: 3.6612143516540527 | CLS Loss: 0.003503997577354312\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 3.6238317489624023 | KNN Loss: 3.6169703006744385 | CLS Loss: 0.006861461792141199\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 3.5958633422851562 | KNN Loss: 3.5925447940826416 | CLS Loss: 0.003318562638014555\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 3.677656412124634 | KNN Loss: 3.66474986076355 | CLS Loss: 0.012906582094728947\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 3.624967336654663 | KNN Loss: 3.6173598766326904 | CLS Loss: 0.007607568055391312\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 3.5735604763031006 | KNN Loss: 3.567685842514038 | CLS Loss: 0.005874519236385822\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 3.615058660507202 | KNN Loss: 3.610361337661743 | CLS Loss: 0.004697326570749283\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 3.5709919929504395 | KNN Loss: 3.56630539894104 | CLS Loss: 0.0046865190379321575\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 3.5782763957977295 | KNN Loss: 3.563136577606201 | CLS Loss: 0.015139706432819366\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 3.6136534214019775 | KNN Loss: 3.6119508743286133 | CLS Loss: 0.0017024639528244734\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 3.5875487327575684 | KNN Loss: 3.585923671722412 | CLS Loss: 0.001624980941414833\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 3.6175167560577393 | KNN Loss: 3.615875482559204 | CLS Loss: 0.0016412955010309815\n",
      "Epoch: 186, Loss: 3.6124, Train: 0.9972, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 3.5759775638580322 | KNN Loss: 3.575427532196045 | CLS Loss: 0.0005500843399204314\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 3.6104438304901123 | KNN Loss: 3.6034998893737793 | CLS Loss: 0.006944059394299984\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 3.582629680633545 | KNN Loss: 3.5721874237060547 | CLS Loss: 0.010442372411489487\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 3.642632007598877 | KNN Loss: 3.6366305351257324 | CLS Loss: 0.00600156607106328\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 3.5971457958221436 | KNN Loss: 3.593123435974121 | CLS Loss: 0.004022388719022274\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 3.5992023944854736 | KNN Loss: 3.5898025035858154 | CLS Loss: 0.009399925358593464\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 3.5893521308898926 | KNN Loss: 3.582021474838257 | CLS Loss: 0.007330697029829025\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 3.601550817489624 | KNN Loss: 3.600391387939453 | CLS Loss: 0.001159345032647252\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 3.5917627811431885 | KNN Loss: 3.5831289291381836 | CLS Loss: 0.008633965626358986\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 3.632225513458252 | KNN Loss: 3.628927707672119 | CLS Loss: 0.003297884948551655\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 3.636439323425293 | KNN Loss: 3.630253314971924 | CLS Loss: 0.006186105776578188\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 3.6066460609436035 | KNN Loss: 3.598696231842041 | CLS Loss: 0.007949831895530224\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 3.629927158355713 | KNN Loss: 3.623821973800659 | CLS Loss: 0.006105297245085239\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 3.604518413543701 | KNN Loss: 3.5930135250091553 | CLS Loss: 0.011504913680255413\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 3.6537699699401855 | KNN Loss: 3.652891159057617 | CLS Loss: 0.0008787577971816063\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 3.621281385421753 | KNN Loss: 3.6101772785186768 | CLS Loss: 0.01110420748591423\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 3.5923073291778564 | KNN Loss: 3.588992118835449 | CLS Loss: 0.0033151237294077873\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 3.6121718883514404 | KNN Loss: 3.602112293243408 | CLS Loss: 0.010059674270451069\n",
      "Epoch: 187, Loss: 3.6045, Train: 0.9971, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 3.6060919761657715 | KNN Loss: 3.596675157546997 | CLS Loss: 0.009416854940354824\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 3.5699822902679443 | KNN Loss: 3.567485809326172 | CLS Loss: 0.0024965449701994658\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 3.6057231426239014 | KNN Loss: 3.6031899452209473 | CLS Loss: 0.00253328331746161\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 3.6198015213012695 | KNN Loss: 3.607243299484253 | CLS Loss: 0.01255831215530634\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 3.57682728767395 | KNN Loss: 3.571552038192749 | CLS Loss: 0.005275148432701826\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 3.632441282272339 | KNN Loss: 3.6147077083587646 | CLS Loss: 0.017733553424477577\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 3.6188485622406006 | KNN Loss: 3.6067380905151367 | CLS Loss: 0.012110549956560135\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 3.7436306476593018 | KNN Loss: 3.721466541290283 | CLS Loss: 0.022164205089211464\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 3.599862575531006 | KNN Loss: 3.590108633041382 | CLS Loss: 0.009753980673849583\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 3.6272315979003906 | KNN Loss: 3.6156740188598633 | CLS Loss: 0.011557644233107567\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 3.5861618518829346 | KNN Loss: 3.5819151401519775 | CLS Loss: 0.004246811382472515\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 3.591568946838379 | KNN Loss: 3.5883007049560547 | CLS Loss: 0.0032681480515748262\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 3.616582155227661 | KNN Loss: 3.5949220657348633 | CLS Loss: 0.021660123020410538\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 3.604851722717285 | KNN Loss: 3.600454568862915 | CLS Loss: 0.004397246520966291\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 3.5950851440429688 | KNN Loss: 3.583725690841675 | CLS Loss: 0.01135955099016428\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 3.611722707748413 | KNN Loss: 3.609222412109375 | CLS Loss: 0.002500177128240466\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 3.590259075164795 | KNN Loss: 3.5892462730407715 | CLS Loss: 0.001012897933833301\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 3.644587993621826 | KNN Loss: 3.634962797164917 | CLS Loss: 0.0096252067014575\n",
      "Epoch: 188, Loss: 3.6021, Train: 0.9972, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 3.610579013824463 | KNN Loss: 3.605252742767334 | CLS Loss: 0.005326206795871258\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 3.610384702682495 | KNN Loss: 3.6083083152770996 | CLS Loss: 0.0020764200016856194\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 3.5892221927642822 | KNN Loss: 3.5881710052490234 | CLS Loss: 0.0010512458393350244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 3.645723342895508 | KNN Loss: 3.6447136402130127 | CLS Loss: 0.001009657047688961\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 3.6180782318115234 | KNN Loss: 3.6140189170837402 | CLS Loss: 0.004059290513396263\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 3.618532180786133 | KNN Loss: 3.59781813621521 | CLS Loss: 0.020713994279503822\n",
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 3.591970682144165 | KNN Loss: 3.588420867919922 | CLS Loss: 0.0035498125944286585\n",
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 3.639238119125366 | KNN Loss: 3.6237573623657227 | CLS Loss: 0.015480652451515198\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 3.6415834426879883 | KNN Loss: 3.6260440349578857 | CLS Loss: 0.015539480373263359\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 3.607095718383789 | KNN Loss: 3.5986931324005127 | CLS Loss: 0.008402650244534016\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 3.6208386421203613 | KNN Loss: 3.6124560832977295 | CLS Loss: 0.008382465690374374\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 3.5969889163970947 | KNN Loss: 3.5927999019622803 | CLS Loss: 0.004189066588878632\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 3.6032490730285645 | KNN Loss: 3.5974576473236084 | CLS Loss: 0.005791384726762772\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 3.635442018508911 | KNN Loss: 3.609149217605591 | CLS Loss: 0.02629287727177143\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 3.6102099418640137 | KNN Loss: 3.5928499698638916 | CLS Loss: 0.017359863966703415\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 3.5840625762939453 | KNN Loss: 3.579862594604492 | CLS Loss: 0.0041998764500021935\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 3.6144702434539795 | KNN Loss: 3.5967931747436523 | CLS Loss: 0.01767713390290737\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 3.619258403778076 | KNN Loss: 3.6150333881378174 | CLS Loss: 0.004225112032145262\n",
      "Epoch: 189, Loss: 3.6129, Train: 0.9975, Valid: 0.9869, Best: 0.9873\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 3.6334633827209473 | KNN Loss: 3.6311261653900146 | CLS Loss: 0.0023371640127152205\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 3.6975231170654297 | KNN Loss: 3.6904032230377197 | CLS Loss: 0.007119848858565092\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 3.6070878505706787 | KNN Loss: 3.601807117462158 | CLS Loss: 0.005280649289488792\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 3.619717597961426 | KNN Loss: 3.601482629776001 | CLS Loss: 0.018235065042972565\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 3.5638837814331055 | KNN Loss: 3.549252510070801 | CLS Loss: 0.014631244353950024\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 3.6016383171081543 | KNN Loss: 3.580294609069824 | CLS Loss: 0.021343622356653214\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 3.6185688972473145 | KNN Loss: 3.6064414978027344 | CLS Loss: 0.01212734542787075\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 3.5997509956359863 | KNN Loss: 3.598808765411377 | CLS Loss: 0.0009422408184036613\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 3.636636734008789 | KNN Loss: 3.633533477783203 | CLS Loss: 0.0031033360864967108\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 3.600851058959961 | KNN Loss: 3.592719793319702 | CLS Loss: 0.008131377398967743\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 3.5973055362701416 | KNN Loss: 3.590369701385498 | CLS Loss: 0.006935926154255867\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 3.60514235496521 | KNN Loss: 3.598283052444458 | CLS Loss: 0.006859315559267998\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 3.6233155727386475 | KNN Loss: 3.6199371814727783 | CLS Loss: 0.003378411056473851\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 3.596308469772339 | KNN Loss: 3.5909361839294434 | CLS Loss: 0.005372361745685339\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 3.5709760189056396 | KNN Loss: 3.567756414413452 | CLS Loss: 0.0032196298707276583\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 3.5794808864593506 | KNN Loss: 3.5652055740356445 | CLS Loss: 0.01427542231976986\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 3.6448097229003906 | KNN Loss: 3.6272993087768555 | CLS Loss: 0.017510490491986275\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 3.6089417934417725 | KNN Loss: 3.598639488220215 | CLS Loss: 0.010302208364009857\n",
      "Epoch: 190, Loss: 3.6097, Train: 0.9978, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 3.647157907485962 | KNN Loss: 3.6466147899627686 | CLS Loss: 0.0005431132158264518\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 3.6018807888031006 | KNN Loss: 3.5968105792999268 | CLS Loss: 0.00507011916488409\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 3.6124179363250732 | KNN Loss: 3.6089088916778564 | CLS Loss: 0.0035090302117168903\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 3.6389031410217285 | KNN Loss: 3.6208338737487793 | CLS Loss: 0.018069365993142128\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 3.618668794631958 | KNN Loss: 3.611348867416382 | CLS Loss: 0.007319933734834194\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 3.575122594833374 | KNN Loss: 3.568692684173584 | CLS Loss: 0.006429832428693771\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 3.584606409072876 | KNN Loss: 3.5805797576904297 | CLS Loss: 0.004026557318866253\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 3.5922842025756836 | KNN Loss: 3.5825345516204834 | CLS Loss: 0.009749552235007286\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 3.596837282180786 | KNN Loss: 3.5957047939300537 | CLS Loss: 0.0011323880171403289\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 3.674020290374756 | KNN Loss: 3.6710329055786133 | CLS Loss: 0.0029873873572796583\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 3.6386184692382812 | KNN Loss: 3.635655641555786 | CLS Loss: 0.0029628535266965628\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 3.5889804363250732 | KNN Loss: 3.588306188583374 | CLS Loss: 0.0006742407567799091\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 3.592954635620117 | KNN Loss: 3.578352689743042 | CLS Loss: 0.014602027833461761\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 3.588634490966797 | KNN Loss: 3.584956169128418 | CLS Loss: 0.003678397973999381\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 3.6387736797332764 | KNN Loss: 3.6160643100738525 | CLS Loss: 0.02270936220884323\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 3.6170928478240967 | KNN Loss: 3.6031112670898438 | CLS Loss: 0.01398152019828558\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 3.6134581565856934 | KNN Loss: 3.601936101913452 | CLS Loss: 0.011522170156240463\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 3.606337785720825 | KNN Loss: 3.5991339683532715 | CLS Loss: 0.007203731685876846\n",
      "Epoch: 191, Loss: 3.6103, Train: 0.9965, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 3.6316287517547607 | KNN Loss: 3.62715220451355 | CLS Loss: 0.004476616624742746\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 3.5974276065826416 | KNN Loss: 3.594693422317505 | CLS Loss: 0.002734157722443342\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 3.592144012451172 | KNN Loss: 3.589695930480957 | CLS Loss: 0.00244805496186018\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 3.580512762069702 | KNN Loss: 3.576129913330078 | CLS Loss: 0.0043828231282532215\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 3.5915513038635254 | KNN Loss: 3.5855484008789062 | CLS Loss: 0.00600299471989274\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 3.593418598175049 | KNN Loss: 3.585371732711792 | CLS Loss: 0.008046923205256462\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 3.565788745880127 | KNN Loss: 3.5630171298980713 | CLS Loss: 0.0027716634795069695\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 3.5980498790740967 | KNN Loss: 3.5890657901763916 | CLS Loss: 0.008984130807220936\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 3.6032469272613525 | KNN Loss: 3.593716859817505 | CLS Loss: 0.009530077688395977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 3.6029415130615234 | KNN Loss: 3.5985329151153564 | CLS Loss: 0.004408539272844791\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 3.6114110946655273 | KNN Loss: 3.6111257076263428 | CLS Loss: 0.00028540604398585856\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 3.574134111404419 | KNN Loss: 3.5719404220581055 | CLS Loss: 0.0021937794517725706\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 3.6275594234466553 | KNN Loss: 3.5978901386260986 | CLS Loss: 0.02966918982565403\n",
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 3.613825559616089 | KNN Loss: 3.602100372314453 | CLS Loss: 0.011725218035280704\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 3.6067306995391846 | KNN Loss: 3.604588270187378 | CLS Loss: 0.002142466139048338\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 3.6595616340637207 | KNN Loss: 3.6351382732391357 | CLS Loss: 0.02442331612110138\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 3.6529884338378906 | KNN Loss: 3.623356819152832 | CLS Loss: 0.02963162213563919\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 3.695920467376709 | KNN Loss: 3.6719582080841064 | CLS Loss: 0.023962311446666718\n",
      "Epoch: 192, Loss: 3.6139, Train: 0.9966, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 3.6303915977478027 | KNN Loss: 3.62117600440979 | CLS Loss: 0.00921570509672165\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 3.6371514797210693 | KNN Loss: 3.626980781555176 | CLS Loss: 0.010170582681894302\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 3.611971378326416 | KNN Loss: 3.6061127185821533 | CLS Loss: 0.0058585889637470245\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 3.573930263519287 | KNN Loss: 3.5703063011169434 | CLS Loss: 0.003623905824497342\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 3.5983543395996094 | KNN Loss: 3.5943524837493896 | CLS Loss: 0.004001825116574764\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 3.606506109237671 | KNN Loss: 3.600641965866089 | CLS Loss: 0.005864189472049475\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 3.5980887413024902 | KNN Loss: 3.5843536853790283 | CLS Loss: 0.01373507734388113\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 3.585406541824341 | KNN Loss: 3.5802102088928223 | CLS Loss: 0.005196284502744675\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 3.659024238586426 | KNN Loss: 3.6417672634124756 | CLS Loss: 0.017256956547498703\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 3.5907132625579834 | KNN Loss: 3.5786099433898926 | CLS Loss: 0.01210331916809082\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 3.5809590816497803 | KNN Loss: 3.5662007331848145 | CLS Loss: 0.014758341014385223\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 3.59092378616333 | KNN Loss: 3.579866647720337 | CLS Loss: 0.011057191528379917\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 3.5913655757904053 | KNN Loss: 3.582878589630127 | CLS Loss: 0.0084870969876647\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 3.6299543380737305 | KNN Loss: 3.6029083728790283 | CLS Loss: 0.02704588882625103\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 3.632624387741089 | KNN Loss: 3.60935378074646 | CLS Loss: 0.023270713165402412\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 3.628661632537842 | KNN Loss: 3.6201915740966797 | CLS Loss: 0.008470055647194386\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 3.5994365215301514 | KNN Loss: 3.5962374210357666 | CLS Loss: 0.0031991261057555676\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 3.5782933235168457 | KNN Loss: 3.5741755962371826 | CLS Loss: 0.004117751959711313\n",
      "Epoch: 193, Loss: 3.6156, Train: 0.9964, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 3.6433138847351074 | KNN Loss: 3.6065738201141357 | CLS Loss: 0.03673998638987541\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 3.600572109222412 | KNN Loss: 3.5962893962860107 | CLS Loss: 0.004282734822481871\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 3.600484848022461 | KNN Loss: 3.5907750129699707 | CLS Loss: 0.009709802456200123\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 3.6366450786590576 | KNN Loss: 3.624208450317383 | CLS Loss: 0.012436716817319393\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 3.6362252235412598 | KNN Loss: 3.6177546977996826 | CLS Loss: 0.01847044751048088\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 3.620518207550049 | KNN Loss: 3.6089868545532227 | CLS Loss: 0.011531436815857887\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 3.6200647354125977 | KNN Loss: 3.6032907962799072 | CLS Loss: 0.01677386462688446\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 3.5974833965301514 | KNN Loss: 3.5957956314086914 | CLS Loss: 0.0016878258902579546\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 3.6349246501922607 | KNN Loss: 3.607603073120117 | CLS Loss: 0.027321621775627136\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 3.606210708618164 | KNN Loss: 3.589195489883423 | CLS Loss: 0.017015106976032257\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 3.571136236190796 | KNN Loss: 3.56819748878479 | CLS Loss: 0.002938786754384637\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 3.590320110321045 | KNN Loss: 3.5745577812194824 | CLS Loss: 0.015762438997626305\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 3.614053249359131 | KNN Loss: 3.6117844581604004 | CLS Loss: 0.0022688601166009903\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 3.6864936351776123 | KNN Loss: 3.6702427864074707 | CLS Loss: 0.016250882297754288\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 3.614330530166626 | KNN Loss: 3.612980842590332 | CLS Loss: 0.001349742989987135\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 3.638631582260132 | KNN Loss: 3.625904083251953 | CLS Loss: 0.012727455236017704\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 3.6239073276519775 | KNN Loss: 3.599372386932373 | CLS Loss: 0.024534953758120537\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 3.629852771759033 | KNN Loss: 3.6160593032836914 | CLS Loss: 0.013793394900858402\n",
      "Epoch: 194, Loss: 3.6131, Train: 0.9969, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 3.5927653312683105 | KNN Loss: 3.5744807720184326 | CLS Loss: 0.018284477293491364\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 3.5764853954315186 | KNN Loss: 3.574120283126831 | CLS Loss: 0.002365059917792678\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 3.5821213722229004 | KNN Loss: 3.5760180950164795 | CLS Loss: 0.006103236228227615\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 3.607910633087158 | KNN Loss: 3.596052885055542 | CLS Loss: 0.011857821606099606\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 3.5948421955108643 | KNN Loss: 3.5911755561828613 | CLS Loss: 0.003666588105261326\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 3.576526165008545 | KNN Loss: 3.5718495845794678 | CLS Loss: 0.004676676355302334\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 3.612950086593628 | KNN Loss: 3.6086485385894775 | CLS Loss: 0.00430154986679554\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 3.6428232192993164 | KNN Loss: 3.6155261993408203 | CLS Loss: 0.027296990156173706\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 3.5791406631469727 | KNN Loss: 3.574754476547241 | CLS Loss: 0.004386140499264002\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 3.6297800540924072 | KNN Loss: 3.608588695526123 | CLS Loss: 0.021191369742155075\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 3.587031841278076 | KNN Loss: 3.5821592807769775 | CLS Loss: 0.004872489254921675\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 3.6253252029418945 | KNN Loss: 3.6010029315948486 | CLS Loss: 0.024322282522916794\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 3.625291109085083 | KNN Loss: 3.609370231628418 | CLS Loss: 0.015920842066407204\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 3.6597654819488525 | KNN Loss: 3.6383416652679443 | CLS Loss: 0.021423781290650368\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 3.570356607437134 | KNN Loss: 3.559358835220337 | CLS Loss: 0.010997719131410122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 3.6119351387023926 | KNN Loss: 3.6010773181915283 | CLS Loss: 0.010857892222702503\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 3.5734660625457764 | KNN Loss: 3.569589614868164 | CLS Loss: 0.0038764362689107656\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 3.6822028160095215 | KNN Loss: 3.662424325942993 | CLS Loss: 0.01977851800620556\n",
      "Epoch: 195, Loss: 3.6062, Train: 0.9974, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 3.5784912109375 | KNN Loss: 3.5717251300811768 | CLS Loss: 0.006766071543097496\n",
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 3.6340038776397705 | KNN Loss: 3.611436367034912 | CLS Loss: 0.02256753109395504\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 3.608452558517456 | KNN Loss: 3.593545436859131 | CLS Loss: 0.01490722969174385\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 3.632634162902832 | KNN Loss: 3.615565299987793 | CLS Loss: 0.01706889271736145\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 3.5954885482788086 | KNN Loss: 3.5916998386383057 | CLS Loss: 0.003788737114518881\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 3.6164915561676025 | KNN Loss: 3.605060577392578 | CLS Loss: 0.011430908925831318\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 3.636519432067871 | KNN Loss: 3.6076059341430664 | CLS Loss: 0.02891341783106327\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 3.595510721206665 | KNN Loss: 3.583261489868164 | CLS Loss: 0.012249158695340157\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 3.6030476093292236 | KNN Loss: 3.5936200618743896 | CLS Loss: 0.009427452459931374\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 3.5981650352478027 | KNN Loss: 3.5948398113250732 | CLS Loss: 0.0033252076245844364\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 3.6197121143341064 | KNN Loss: 3.618462324142456 | CLS Loss: 0.0012498206924647093\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 3.635331153869629 | KNN Loss: 3.61885142326355 | CLS Loss: 0.016479715704917908\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 3.657442331314087 | KNN Loss: 3.651400089263916 | CLS Loss: 0.006042223423719406\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 3.647753953933716 | KNN Loss: 3.6287832260131836 | CLS Loss: 0.018970627337694168\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 3.621614933013916 | KNN Loss: 3.6184182167053223 | CLS Loss: 0.0031966629903763533\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 3.608910322189331 | KNN Loss: 3.5910043716430664 | CLS Loss: 0.017905885353684425\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 3.6191723346710205 | KNN Loss: 3.603091239929199 | CLS Loss: 0.01608111336827278\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 3.6167831420898438 | KNN Loss: 3.605687379837036 | CLS Loss: 0.01109582930803299\n",
      "Epoch: 196, Loss: 3.6161, Train: 0.9972, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 3.6145076751708984 | KNN Loss: 3.604672908782959 | CLS Loss: 0.00983479619026184\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 3.59395170211792 | KNN Loss: 3.5819430351257324 | CLS Loss: 0.012008719146251678\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 3.634470224380493 | KNN Loss: 3.6262829303741455 | CLS Loss: 0.008187264204025269\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 3.580064058303833 | KNN Loss: 3.5731799602508545 | CLS Loss: 0.006884210743010044\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 3.582426071166992 | KNN Loss: 3.576662540435791 | CLS Loss: 0.005763451103121042\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 3.607581615447998 | KNN Loss: 3.605898141860962 | CLS Loss: 0.0016833941917866468\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 3.625364303588867 | KNN Loss: 3.6232311725616455 | CLS Loss: 0.0021331876050680876\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 3.6047122478485107 | KNN Loss: 3.579821825027466 | CLS Loss: 0.02489040233194828\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 3.60711932182312 | KNN Loss: 3.600144386291504 | CLS Loss: 0.006974954158067703\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 3.6028871536254883 | KNN Loss: 3.595198392868042 | CLS Loss: 0.007688697427511215\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 3.596303939819336 | KNN Loss: 3.5938661098480225 | CLS Loss: 0.002437879564240575\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 3.6835591793060303 | KNN Loss: 3.6804039478302 | CLS Loss: 0.0031551665160804987\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 3.5876636505126953 | KNN Loss: 3.5818734169006348 | CLS Loss: 0.005790135823190212\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 3.5814733505249023 | KNN Loss: 3.576289415359497 | CLS Loss: 0.005183972418308258\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 3.600137948989868 | KNN Loss: 3.5753228664398193 | CLS Loss: 0.02481500804424286\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 3.624370574951172 | KNN Loss: 3.61572003364563 | CLS Loss: 0.008650468662381172\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 3.618626356124878 | KNN Loss: 3.6067707538604736 | CLS Loss: 0.011855538934469223\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 3.6042721271514893 | KNN Loss: 3.5970590114593506 | CLS Loss: 0.007213093340396881\n",
      "Epoch: 197, Loss: 3.6105, Train: 0.9976, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 3.5856821537017822 | KNN Loss: 3.580819845199585 | CLS Loss: 0.004862215369939804\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 3.567704200744629 | KNN Loss: 3.557875394821167 | CLS Loss: 0.009828795678913593\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 3.6135454177856445 | KNN Loss: 3.599198341369629 | CLS Loss: 0.01434697862714529\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 3.6056182384490967 | KNN Loss: 3.5978870391845703 | CLS Loss: 0.007731154095381498\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 3.583965539932251 | KNN Loss: 3.5670225620269775 | CLS Loss: 0.01694297045469284\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 3.6009111404418945 | KNN Loss: 3.589432954788208 | CLS Loss: 0.01147820521146059\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 3.649549722671509 | KNN Loss: 3.630315065383911 | CLS Loss: 0.019234590232372284\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 3.6046509742736816 | KNN Loss: 3.5913305282592773 | CLS Loss: 0.013320378959178925\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 3.605705499649048 | KNN Loss: 3.602790594100952 | CLS Loss: 0.0029149861074984074\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 3.588230609893799 | KNN Loss: 3.575897693634033 | CLS Loss: 0.01233284268528223\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 3.5789101123809814 | KNN Loss: 3.5782251358032227 | CLS Loss: 0.000684993457980454\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 3.5575149059295654 | KNN Loss: 3.555333375930786 | CLS Loss: 0.002181486925110221\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 3.606536865234375 | KNN Loss: 3.6039862632751465 | CLS Loss: 0.0025506431702524424\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 3.621685743331909 | KNN Loss: 3.6143271923065186 | CLS Loss: 0.007358647882938385\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 3.611783981323242 | KNN Loss: 3.59946870803833 | CLS Loss: 0.012315284460783005\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 3.5700948238372803 | KNN Loss: 3.560730457305908 | CLS Loss: 0.009364292956888676\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 3.596139907836914 | KNN Loss: 3.5949349403381348 | CLS Loss: 0.0012048919452354312\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 3.590805768966675 | KNN Loss: 3.5884883403778076 | CLS Loss: 0.002317512407898903\n",
      "Epoch: 198, Loss: 3.6083, Train: 0.9978, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 3.5929441452026367 | KNN Loss: 3.591627359390259 | CLS Loss: 0.0013167823199182749\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 3.645487070083618 | KNN Loss: 3.641233205795288 | CLS Loss: 0.004253908060491085\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 3.585505723953247 | KNN Loss: 3.580900192260742 | CLS Loss: 0.004605457186698914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 3.609245538711548 | KNN Loss: 3.6047208309173584 | CLS Loss: 0.0045247189700603485\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 3.595888614654541 | KNN Loss: 3.5880517959594727 | CLS Loss: 0.007836858741939068\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 3.6148111820220947 | KNN Loss: 3.6065025329589844 | CLS Loss: 0.008308730088174343\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 3.579241991043091 | KNN Loss: 3.5780508518218994 | CLS Loss: 0.0011911524925380945\n",
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 3.600745439529419 | KNN Loss: 3.575310468673706 | CLS Loss: 0.02543490007519722\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 3.6279661655426025 | KNN Loss: 3.617826223373413 | CLS Loss: 0.010140030644834042\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 3.5906684398651123 | KNN Loss: 3.584307909011841 | CLS Loss: 0.006360555998980999\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 3.6237735748291016 | KNN Loss: 3.61385440826416 | CLS Loss: 0.00991907250136137\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 3.5993857383728027 | KNN Loss: 3.5820844173431396 | CLS Loss: 0.017301330342888832\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 3.5911078453063965 | KNN Loss: 3.588968515396118 | CLS Loss: 0.0021394197829067707\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 3.6146323680877686 | KNN Loss: 3.6031017303466797 | CLS Loss: 0.011530713178217411\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 3.583164930343628 | KNN Loss: 3.579002857208252 | CLS Loss: 0.004161977209150791\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 3.6517815589904785 | KNN Loss: 3.6442067623138428 | CLS Loss: 0.007574896328151226\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 3.5876269340515137 | KNN Loss: 3.5827558040618896 | CLS Loss: 0.004871174693107605\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 3.59867525100708 | KNN Loss: 3.57504940032959 | CLS Loss: 0.02362595684826374\n",
      "Epoch: 199, Loss: 3.6091, Train: 0.9968, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 3.5864815711975098 | KNN Loss: 3.584278106689453 | CLS Loss: 0.0022035413421690464\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 3.5973100662231445 | KNN Loss: 3.5928547382354736 | CLS Loss: 0.004455292597413063\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 3.5667593479156494 | KNN Loss: 3.5634822845458984 | CLS Loss: 0.0032771748956292868\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 3.5851385593414307 | KNN Loss: 3.578171730041504 | CLS Loss: 0.006966942921280861\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 3.5906553268432617 | KNN Loss: 3.582329750061035 | CLS Loss: 0.008325687609612942\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 3.615804433822632 | KNN Loss: 3.6071689128875732 | CLS Loss: 0.008635629899799824\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 3.6057896614074707 | KNN Loss: 3.589014768600464 | CLS Loss: 0.01677485555410385\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 3.659048080444336 | KNN Loss: 3.628295421600342 | CLS Loss: 0.03075271099805832\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 3.5847835540771484 | KNN Loss: 3.575410842895508 | CLS Loss: 0.009372727945446968\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 3.644476890563965 | KNN Loss: 3.6282424926757812 | CLS Loss: 0.01623450219631195\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 3.6163575649261475 | KNN Loss: 3.5996360778808594 | CLS Loss: 0.01672154851257801\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 3.5935258865356445 | KNN Loss: 3.5928969383239746 | CLS Loss: 0.0006289132870733738\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 3.629465341567993 | KNN Loss: 3.6234242916107178 | CLS Loss: 0.006040969863533974\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 3.5991740226745605 | KNN Loss: 3.5878396034240723 | CLS Loss: 0.011334403418004513\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 3.6019439697265625 | KNN Loss: 3.5987651348114014 | CLS Loss: 0.0031787781044840813\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 3.6325414180755615 | KNN Loss: 3.627955675125122 | CLS Loss: 0.0045858342200517654\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 3.617872953414917 | KNN Loss: 3.5957446098327637 | CLS Loss: 0.02212831936776638\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 3.6016640663146973 | KNN Loss: 3.592203378677368 | CLS Loss: 0.00946057215332985\n",
      "Epoch: 200, Loss: 3.6102, Train: 0.9965, Valid: 0.9854, Best: 0.9873\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9854, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e27adbc7574ae287a29d4d0eb4c010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4084d83f1f547e39409b3ac4cd4b3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45689d08de86402ea577c17ba8b91ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eade12640c414078a44661f5c13fd355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d3dee822cc4b60868cc40759759649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.8574756749349047\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91063d74c7d8436f91d44ae1b6cf068a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "Epoch: 00 | Batch: 000 / 037 | Total loss: 2.232 | Reg loss: 0.012 | Tree loss: 2.232 | Accuracy: 0.064453 | 1.322 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 037 | Total loss: 2.209 | Reg loss: 0.005 | Tree loss: 2.209 | Accuracy: 0.230469 | 0.829 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 037 | Total loss: 2.200 | Reg loss: 0.007 | Tree loss: 2.200 | Accuracy: 0.222656 | 0.824 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 037 | Total loss: 2.187 | Reg loss: 0.009 | Tree loss: 2.187 | Accuracy: 0.226562 | 0.821 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 037 | Total loss: 2.166 | Reg loss: 0.010 | Tree loss: 2.166 | Accuracy: 0.343750 | 0.821 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 037 | Total loss: 2.154 | Reg loss: 0.011 | Tree loss: 2.154 | Accuracy: 0.386719 | 0.82 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 037 | Total loss: 2.142 | Reg loss: 0.013 | Tree loss: 2.142 | Accuracy: 0.398438 | 0.819 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 037 | Total loss: 2.135 | Reg loss: 0.014 | Tree loss: 2.135 | Accuracy: 0.380859 | 0.818 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 037 | Total loss: 2.119 | Reg loss: 0.015 | Tree loss: 2.119 | Accuracy: 0.451172 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 037 | Total loss: 2.122 | Reg loss: 0.016 | Tree loss: 2.122 | Accuracy: 0.392578 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 037 | Total loss: 2.104 | Reg loss: 0.017 | Tree loss: 2.104 | Accuracy: 0.396484 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 037 | Total loss: 2.081 | Reg loss: 0.018 | Tree loss: 2.081 | Accuracy: 0.417969 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 037 | Total loss: 2.070 | Reg loss: 0.019 | Tree loss: 2.070 | Accuracy: 0.443359 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 037 | Total loss: 2.084 | Reg loss: 0.020 | Tree loss: 2.084 | Accuracy: 0.371094 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 037 | Total loss: 2.063 | Reg loss: 0.020 | Tree loss: 2.063 | Accuracy: 0.416016 | 0.82 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 037 | Total loss: 2.048 | Reg loss: 0.021 | Tree loss: 2.048 | Accuracy: 0.371094 | 0.82 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 037 | Total loss: 2.048 | Reg loss: 0.022 | Tree loss: 2.048 | Accuracy: 0.392578 | 0.82 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 037 | Total loss: 2.044 | Reg loss: 0.022 | Tree loss: 2.044 | Accuracy: 0.400391 | 0.82 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 037 | Total loss: 2.016 | Reg loss: 0.023 | Tree loss: 2.016 | Accuracy: 0.404297 | 0.819 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 037 | Total loss: 2.024 | Reg loss: 0.024 | Tree loss: 2.024 | Accuracy: 0.410156 | 0.819 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Batch: 000 / 037 | Total loss: 1.992 | Reg loss: 0.024 | Tree loss: 1.992 | Accuracy: 0.458984 | 0.819 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 037 | Total loss: 1.990 | Reg loss: 0.025 | Tree loss: 1.990 | Accuracy: 0.449219 | 0.819 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 037 | Total loss: 1.980 | Reg loss: 0.025 | Tree loss: 1.980 | Accuracy: 0.478516 | 0.818 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 23 | Batch: 000 / 037 | Total loss: 1.986 | Reg loss: 0.026 | Tree loss: 1.986 | Accuracy: 0.427734 | 0.818 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 037 | Total loss: 1.973 | Reg loss: 0.026 | Tree loss: 1.973 | Accuracy: 0.457031 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 037 | Total loss: 1.929 | Reg loss: 0.027 | Tree loss: 1.929 | Accuracy: 0.466797 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 037 | Total loss: 1.938 | Reg loss: 0.027 | Tree loss: 1.938 | Accuracy: 0.458984 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 037 | Total loss: 1.906 | Reg loss: 0.028 | Tree loss: 1.906 | Accuracy: 0.494141 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 037 | Total loss: 1.875 | Reg loss: 0.028 | Tree loss: 1.875 | Accuracy: 0.521484 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 037 | Total loss: 1.905 | Reg loss: 0.028 | Tree loss: 1.905 | Accuracy: 0.453125 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 037 | Total loss: 1.866 | Reg loss: 0.029 | Tree loss: 1.866 | Accuracy: 0.498047 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 037 | Total loss: 1.851 | Reg loss: 0.029 | Tree loss: 1.851 | Accuracy: 0.494141 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 037 | Total loss: 1.833 | Reg loss: 0.029 | Tree loss: 1.833 | Accuracy: 0.505859 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 037 | Total loss: 1.863 | Reg loss: 0.030 | Tree loss: 1.863 | Accuracy: 0.447266 | 0.817 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 037 | Total loss: 1.840 | Reg loss: 0.030 | Tree loss: 1.840 | Accuracy: 0.462891 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 35 | Batch: 000 / 037 | Total loss: 1.801 | Reg loss: 0.030 | Tree loss: 1.801 | Accuracy: 0.488281 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 037 | Total loss: 1.855 | Reg loss: 0.031 | Tree loss: 1.855 | Accuracy: 0.427734 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 037 | Total loss: 1.789 | Reg loss: 0.031 | Tree loss: 1.789 | Accuracy: 0.500000 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 037 | Total loss: 1.814 | Reg loss: 0.031 | Tree loss: 1.814 | Accuracy: 0.457031 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 037 | Total loss: 1.809 | Reg loss: 0.031 | Tree loss: 1.809 | Accuracy: 0.455078 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Batch: 000 / 037 | Total loss: 1.805 | Reg loss: 0.031 | Tree loss: 1.805 | Accuracy: 0.488281 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 037 | Total loss: 1.828 | Reg loss: 0.032 | Tree loss: 1.828 | Accuracy: 0.429688 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 037 | Total loss: 1.782 | Reg loss: 0.032 | Tree loss: 1.782 | Accuracy: 0.500000 | 0.815 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 037 | Total loss: 1.792 | Reg loss: 0.032 | Tree loss: 1.792 | Accuracy: 0.478516 | 0.815 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 037 | Total loss: 1.805 | Reg loss: 0.032 | Tree loss: 1.805 | Accuracy: 0.457031 | 0.815 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 037 | Total loss: 1.789 | Reg loss: 0.032 | Tree loss: 1.789 | Accuracy: 0.472656 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 46 | Batch: 000 / 037 | Total loss: 1.790 | Reg loss: 0.032 | Tree loss: 1.790 | Accuracy: 0.447266 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 037 | Total loss: 1.765 | Reg loss: 0.033 | Tree loss: 1.765 | Accuracy: 0.460938 | 0.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 037 | Total loss: 1.730 | Reg loss: 0.033 | Tree loss: 1.730 | Accuracy: 0.482422 | 0.814 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 49 | Batch: 000 / 037 | Total loss: 1.773 | Reg loss: 0.033 | Tree loss: 1.773 | Accuracy: 0.451172 | 0.813 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 50 | Batch: 000 / 037 | Total loss: 1.717 | Reg loss: 0.033 | Tree loss: 1.717 | Accuracy: 0.519531 | 0.813 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 51 | Batch: 000 / 037 | Total loss: 1.747 | Reg loss: 0.033 | Tree loss: 1.747 | Accuracy: 0.490234 | 0.811 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 52 | Batch: 000 / 037 | Total loss: 1.704 | Reg loss: 0.034 | Tree loss: 1.704 | Accuracy: 0.482422 | 0.81 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 53 | Batch: 000 / 037 | Total loss: 1.736 | Reg loss: 0.034 | Tree loss: 1.736 | Accuracy: 0.474609 | 0.809 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 54 | Batch: 000 / 037 | Total loss: 1.715 | Reg loss: 0.034 | Tree loss: 1.715 | Accuracy: 0.490234 | 0.809 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 55 | Batch: 000 / 037 | Total loss: 1.723 | Reg loss: 0.034 | Tree loss: 1.723 | Accuracy: 0.486328 | 0.808 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 56 | Batch: 000 / 037 | Total loss: 1.702 | Reg loss: 0.034 | Tree loss: 1.702 | Accuracy: 0.498047 | 0.807 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 57 | Batch: 000 / 037 | Total loss: 1.708 | Reg loss: 0.034 | Tree loss: 1.708 | Accuracy: 0.505859 | 0.807 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 58 | Batch: 000 / 037 | Total loss: 1.720 | Reg loss: 0.035 | Tree loss: 1.720 | Accuracy: 0.470703 | 0.806 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 59 | Batch: 000 / 037 | Total loss: 1.751 | Reg loss: 0.035 | Tree loss: 1.751 | Accuracy: 0.435547 | 0.805 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | Batch: 000 / 037 | Total loss: 1.706 | Reg loss: 0.035 | Tree loss: 1.706 | Accuracy: 0.486328 | 0.804 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 61 | Batch: 000 / 037 | Total loss: 1.706 | Reg loss: 0.035 | Tree loss: 1.706 | Accuracy: 0.498047 | 0.804 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 62 | Batch: 000 / 037 | Total loss: 1.685 | Reg loss: 0.035 | Tree loss: 1.685 | Accuracy: 0.492188 | 0.803 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 63 | Batch: 000 / 037 | Total loss: 1.678 | Reg loss: 0.036 | Tree loss: 1.678 | Accuracy: 0.498047 | 0.802 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 64 | Batch: 000 / 037 | Total loss: 1.702 | Reg loss: 0.036 | Tree loss: 1.702 | Accuracy: 0.492188 | 0.802 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 65 | Batch: 000 / 037 | Total loss: 1.677 | Reg loss: 0.036 | Tree loss: 1.677 | Accuracy: 0.482422 | 0.801 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 66 | Batch: 000 / 037 | Total loss: 1.698 | Reg loss: 0.036 | Tree loss: 1.698 | Accuracy: 0.468750 | 0.801 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 67 | Batch: 000 / 037 | Total loss: 1.699 | Reg loss: 0.036 | Tree loss: 1.699 | Accuracy: 0.482422 | 0.801 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 68 | Batch: 000 / 037 | Total loss: 1.668 | Reg loss: 0.036 | Tree loss: 1.668 | Accuracy: 0.490234 | 0.8 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 69 | Batch: 000 / 037 | Total loss: 1.658 | Reg loss: 0.036 | Tree loss: 1.658 | Accuracy: 0.523438 | 0.799 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 70 | Batch: 000 / 037 | Total loss: 1.651 | Reg loss: 0.037 | Tree loss: 1.651 | Accuracy: 0.527344 | 0.799 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 71 | Batch: 000 / 037 | Total loss: 1.658 | Reg loss: 0.037 | Tree loss: 1.658 | Accuracy: 0.519531 | 0.798 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 72 | Batch: 000 / 037 | Total loss: 1.646 | Reg loss: 0.037 | Tree loss: 1.646 | Accuracy: 0.509766 | 0.798 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 73 | Batch: 000 / 037 | Total loss: 1.642 | Reg loss: 0.037 | Tree loss: 1.642 | Accuracy: 0.517578 | 0.798 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 74 | Batch: 000 / 037 | Total loss: 1.661 | Reg loss: 0.037 | Tree loss: 1.661 | Accuracy: 0.488281 | 0.797 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 75 | Batch: 000 / 037 | Total loss: 1.655 | Reg loss: 0.037 | Tree loss: 1.655 | Accuracy: 0.515625 | 0.797 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 76 | Batch: 000 / 037 | Total loss: 1.669 | Reg loss: 0.037 | Tree loss: 1.669 | Accuracy: 0.439453 | 0.797 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 77 | Batch: 000 / 037 | Total loss: 1.653 | Reg loss: 0.037 | Tree loss: 1.653 | Accuracy: 0.494141 | 0.796 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 78 | Batch: 000 / 037 | Total loss: 1.640 | Reg loss: 0.037 | Tree loss: 1.640 | Accuracy: 0.501953 | 0.795 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 79 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.037 | Tree loss: 1.637 | Accuracy: 0.496094 | 0.795 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Batch: 000 / 037 | Total loss: 1.665 | Reg loss: 0.037 | Tree loss: 1.665 | Accuracy: 0.496094 | 0.795 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 81 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.037 | Tree loss: 1.657 | Accuracy: 0.478516 | 0.794 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 82 | Batch: 000 / 037 | Total loss: 1.613 | Reg loss: 0.037 | Tree loss: 1.613 | Accuracy: 0.525391 | 0.794 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 83 | Batch: 000 / 037 | Total loss: 1.681 | Reg loss: 0.037 | Tree loss: 1.681 | Accuracy: 0.472656 | 0.794 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 84 | Batch: 000 / 037 | Total loss: 1.669 | Reg loss: 0.037 | Tree loss: 1.669 | Accuracy: 0.468750 | 0.793 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 85 | Batch: 000 / 037 | Total loss: 1.675 | Reg loss: 0.038 | Tree loss: 1.675 | Accuracy: 0.466797 | 0.793 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 86 | Batch: 000 / 037 | Total loss: 1.659 | Reg loss: 0.038 | Tree loss: 1.659 | Accuracy: 0.488281 | 0.793 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 87 | Batch: 000 / 037 | Total loss: 1.645 | Reg loss: 0.038 | Tree loss: 1.645 | Accuracy: 0.492188 | 0.792 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 88 | Batch: 000 / 037 | Total loss: 1.679 | Reg loss: 0.038 | Tree loss: 1.679 | Accuracy: 0.460938 | 0.792 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 89 | Batch: 000 / 037 | Total loss: 1.701 | Reg loss: 0.038 | Tree loss: 1.701 | Accuracy: 0.435547 | 0.792 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 90 | Batch: 000 / 037 | Total loss: 1.696 | Reg loss: 0.038 | Tree loss: 1.696 | Accuracy: 0.468750 | 0.792 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 91 | Batch: 000 / 037 | Total loss: 1.652 | Reg loss: 0.038 | Tree loss: 1.652 | Accuracy: 0.484375 | 0.791 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 92 | Batch: 000 / 037 | Total loss: 1.636 | Reg loss: 0.038 | Tree loss: 1.636 | Accuracy: 0.519531 | 0.791 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 93 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.038 | Tree loss: 1.657 | Accuracy: 0.498047 | 0.791 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 94 | Batch: 000 / 037 | Total loss: 1.666 | Reg loss: 0.038 | Tree loss: 1.666 | Accuracy: 0.490234 | 0.79 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 95 | Batch: 000 / 037 | Total loss: 1.644 | Reg loss: 0.038 | Tree loss: 1.644 | Accuracy: 0.492188 | 0.79 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 96 | Batch: 000 / 037 | Total loss: 1.652 | Reg loss: 0.038 | Tree loss: 1.652 | Accuracy: 0.498047 | 0.79 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 97 | Batch: 000 / 037 | Total loss: 1.656 | Reg loss: 0.038 | Tree loss: 1.656 | Accuracy: 0.492188 | 0.79 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 98 | Batch: 000 / 037 | Total loss: 1.689 | Reg loss: 0.038 | Tree loss: 1.689 | Accuracy: 0.478516 | 0.789 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 99 | Batch: 000 / 037 | Total loss: 1.683 | Reg loss: 0.038 | Tree loss: 1.683 | Accuracy: 0.462891 | 0.789 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Batch: 000 / 037 | Total loss: 1.683 | Reg loss: 0.038 | Tree loss: 1.683 | Accuracy: 0.451172 | 0.789 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 101 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.038 | Tree loss: 1.630 | Accuracy: 0.513672 | 0.788 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 102 | Batch: 000 / 037 | Total loss: 1.671 | Reg loss: 0.038 | Tree loss: 1.671 | Accuracy: 0.484375 | 0.788 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 103 | Batch: 000 / 037 | Total loss: 1.639 | Reg loss: 0.038 | Tree loss: 1.639 | Accuracy: 0.482422 | 0.788 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 104 | Batch: 000 / 037 | Total loss: 1.629 | Reg loss: 0.038 | Tree loss: 1.629 | Accuracy: 0.513672 | 0.788 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 105 | Batch: 000 / 037 | Total loss: 1.653 | Reg loss: 0.038 | Tree loss: 1.653 | Accuracy: 0.525391 | 0.788 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 106 | Batch: 000 / 037 | Total loss: 1.647 | Reg loss: 0.038 | Tree loss: 1.647 | Accuracy: 0.507812 | 0.788 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 107 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.038 | Tree loss: 1.657 | Accuracy: 0.488281 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 108 | Batch: 000 / 037 | Total loss: 1.678 | Reg loss: 0.038 | Tree loss: 1.678 | Accuracy: 0.460938 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 109 | Batch: 000 / 037 | Total loss: 1.692 | Reg loss: 0.038 | Tree loss: 1.692 | Accuracy: 0.447266 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 110 | Batch: 000 / 037 | Total loss: 1.650 | Reg loss: 0.038 | Tree loss: 1.650 | Accuracy: 0.488281 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 111 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.038 | Tree loss: 1.641 | Accuracy: 0.474609 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 112 | Batch: 000 / 037 | Total loss: 1.715 | Reg loss: 0.038 | Tree loss: 1.715 | Accuracy: 0.443359 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 113 | Batch: 000 / 037 | Total loss: 1.640 | Reg loss: 0.038 | Tree loss: 1.640 | Accuracy: 0.500000 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 114 | Batch: 000 / 037 | Total loss: 1.662 | Reg loss: 0.038 | Tree loss: 1.662 | Accuracy: 0.466797 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 115 | Batch: 000 / 037 | Total loss: 1.681 | Reg loss: 0.038 | Tree loss: 1.681 | Accuracy: 0.470703 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 116 | Batch: 000 / 037 | Total loss: 1.663 | Reg loss: 0.038 | Tree loss: 1.663 | Accuracy: 0.484375 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 117 | Batch: 000 / 037 | Total loss: 1.662 | Reg loss: 0.038 | Tree loss: 1.662 | Accuracy: 0.441406 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 118 | Batch: 000 / 037 | Total loss: 1.683 | Reg loss: 0.038 | Tree loss: 1.683 | Accuracy: 0.457031 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 119 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.038 | Tree loss: 1.657 | Accuracy: 0.472656 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 | Batch: 000 / 037 | Total loss: 1.666 | Reg loss: 0.038 | Tree loss: 1.666 | Accuracy: 0.478516 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 121 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.038 | Tree loss: 1.632 | Accuracy: 0.464844 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 122 | Batch: 000 / 037 | Total loss: 1.678 | Reg loss: 0.038 | Tree loss: 1.678 | Accuracy: 0.470703 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 123 | Batch: 000 / 037 | Total loss: 1.631 | Reg loss: 0.038 | Tree loss: 1.631 | Accuracy: 0.492188 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 124 | Batch: 000 / 037 | Total loss: 1.617 | Reg loss: 0.038 | Tree loss: 1.617 | Accuracy: 0.519531 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 125 | Batch: 000 / 037 | Total loss: 1.611 | Reg loss: 0.038 | Tree loss: 1.611 | Accuracy: 0.498047 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 126 | Batch: 000 / 037 | Total loss: 1.651 | Reg loss: 0.038 | Tree loss: 1.651 | Accuracy: 0.449219 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 127 | Batch: 000 / 037 | Total loss: 1.655 | Reg loss: 0.038 | Tree loss: 1.655 | Accuracy: 0.460938 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 128 | Batch: 000 / 037 | Total loss: 1.642 | Reg loss: 0.038 | Tree loss: 1.642 | Accuracy: 0.501953 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 129 | Batch: 000 / 037 | Total loss: 1.624 | Reg loss: 0.038 | Tree loss: 1.624 | Accuracy: 0.501953 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 130 | Batch: 000 / 037 | Total loss: 1.621 | Reg loss: 0.038 | Tree loss: 1.621 | Accuracy: 0.509766 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 131 | Batch: 000 / 037 | Total loss: 1.649 | Reg loss: 0.038 | Tree loss: 1.649 | Accuracy: 0.458984 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 132 | Batch: 000 / 037 | Total loss: 1.651 | Reg loss: 0.038 | Tree loss: 1.651 | Accuracy: 0.458984 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 133 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.038 | Tree loss: 1.641 | Accuracy: 0.521484 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 134 | Batch: 000 / 037 | Total loss: 1.697 | Reg loss: 0.038 | Tree loss: 1.697 | Accuracy: 0.468750 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 135 | Batch: 000 / 037 | Total loss: 1.692 | Reg loss: 0.038 | Tree loss: 1.692 | Accuracy: 0.429688 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 136 | Batch: 000 / 037 | Total loss: 1.658 | Reg loss: 0.038 | Tree loss: 1.658 | Accuracy: 0.464844 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 137 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.038 | Tree loss: 1.625 | Accuracy: 0.472656 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 138 | Batch: 000 / 037 | Total loss: 1.663 | Reg loss: 0.038 | Tree loss: 1.663 | Accuracy: 0.478516 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 139 | Batch: 000 / 037 | Total loss: 1.682 | Reg loss: 0.038 | Tree loss: 1.682 | Accuracy: 0.468750 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 | Batch: 000 / 037 | Total loss: 1.670 | Reg loss: 0.038 | Tree loss: 1.670 | Accuracy: 0.460938 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 141 | Batch: 000 / 037 | Total loss: 1.643 | Reg loss: 0.038 | Tree loss: 1.643 | Accuracy: 0.476562 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 142 | Batch: 000 / 037 | Total loss: 1.674 | Reg loss: 0.038 | Tree loss: 1.674 | Accuracy: 0.480469 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 143 | Batch: 000 / 037 | Total loss: 1.659 | Reg loss: 0.038 | Tree loss: 1.659 | Accuracy: 0.460938 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 144 | Batch: 000 / 037 | Total loss: 1.697 | Reg loss: 0.038 | Tree loss: 1.697 | Accuracy: 0.417969 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 145 | Batch: 000 / 037 | Total loss: 1.616 | Reg loss: 0.038 | Tree loss: 1.616 | Accuracy: 0.496094 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 146 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.038 | Tree loss: 1.641 | Accuracy: 0.488281 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 147 | Batch: 000 / 037 | Total loss: 1.640 | Reg loss: 0.038 | Tree loss: 1.640 | Accuracy: 0.478516 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 148 | Batch: 000 / 037 | Total loss: 1.660 | Reg loss: 0.038 | Tree loss: 1.660 | Accuracy: 0.509766 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 149 | Batch: 000 / 037 | Total loss: 1.664 | Reg loss: 0.038 | Tree loss: 1.664 | Accuracy: 0.480469 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 150 | Batch: 000 / 037 | Total loss: 1.661 | Reg loss: 0.038 | Tree loss: 1.661 | Accuracy: 0.480469 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 151 | Batch: 000 / 037 | Total loss: 1.659 | Reg loss: 0.038 | Tree loss: 1.659 | Accuracy: 0.470703 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 152 | Batch: 000 / 037 | Total loss: 1.645 | Reg loss: 0.038 | Tree loss: 1.645 | Accuracy: 0.458984 | 0.781 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 153 | Batch: 000 / 037 | Total loss: 1.640 | Reg loss: 0.038 | Tree loss: 1.640 | Accuracy: 0.488281 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 154 | Batch: 000 / 037 | Total loss: 1.678 | Reg loss: 0.038 | Tree loss: 1.678 | Accuracy: 0.449219 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 155 | Batch: 000 / 037 | Total loss: 1.665 | Reg loss: 0.038 | Tree loss: 1.665 | Accuracy: 0.472656 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 156 | Batch: 000 / 037 | Total loss: 1.670 | Reg loss: 0.038 | Tree loss: 1.670 | Accuracy: 0.457031 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 157 | Batch: 000 / 037 | Total loss: 1.652 | Reg loss: 0.038 | Tree loss: 1.652 | Accuracy: 0.451172 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 158 | Batch: 000 / 037 | Total loss: 1.650 | Reg loss: 0.038 | Tree loss: 1.650 | Accuracy: 0.457031 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 159 | Batch: 000 / 037 | Total loss: 1.600 | Reg loss: 0.038 | Tree loss: 1.600 | Accuracy: 0.525391 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 | Batch: 000 / 037 | Total loss: 1.618 | Reg loss: 0.038 | Tree loss: 1.618 | Accuracy: 0.492188 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 161 | Batch: 000 / 037 | Total loss: 1.671 | Reg loss: 0.038 | Tree loss: 1.671 | Accuracy: 0.453125 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 162 | Batch: 000 / 037 | Total loss: 1.654 | Reg loss: 0.038 | Tree loss: 1.654 | Accuracy: 0.449219 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 163 | Batch: 000 / 037 | Total loss: 1.648 | Reg loss: 0.038 | Tree loss: 1.648 | Accuracy: 0.460938 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 164 | Batch: 000 / 037 | Total loss: 1.695 | Reg loss: 0.038 | Tree loss: 1.695 | Accuracy: 0.414062 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 165 | Batch: 000 / 037 | Total loss: 1.648 | Reg loss: 0.038 | Tree loss: 1.648 | Accuracy: 0.435547 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 166 | Batch: 000 / 037 | Total loss: 1.645 | Reg loss: 0.038 | Tree loss: 1.645 | Accuracy: 0.470703 | 0.782 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 167 | Batch: 000 / 037 | Total loss: 1.643 | Reg loss: 0.038 | Tree loss: 1.643 | Accuracy: 0.474609 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 168 | Batch: 000 / 037 | Total loss: 1.670 | Reg loss: 0.038 | Tree loss: 1.670 | Accuracy: 0.453125 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 169 | Batch: 000 / 037 | Total loss: 1.598 | Reg loss: 0.038 | Tree loss: 1.598 | Accuracy: 0.505859 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 170 | Batch: 000 / 037 | Total loss: 1.677 | Reg loss: 0.038 | Tree loss: 1.677 | Accuracy: 0.451172 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 171 | Batch: 000 / 037 | Total loss: 1.660 | Reg loss: 0.038 | Tree loss: 1.660 | Accuracy: 0.435547 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 172 | Batch: 000 / 037 | Total loss: 1.649 | Reg loss: 0.038 | Tree loss: 1.649 | Accuracy: 0.464844 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 173 | Batch: 000 / 037 | Total loss: 1.633 | Reg loss: 0.038 | Tree loss: 1.633 | Accuracy: 0.484375 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 174 | Batch: 000 / 037 | Total loss: 1.636 | Reg loss: 0.038 | Tree loss: 1.636 | Accuracy: 0.464844 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 175 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.038 | Tree loss: 1.641 | Accuracy: 0.458984 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 176 | Batch: 000 / 037 | Total loss: 1.557 | Reg loss: 0.038 | Tree loss: 1.557 | Accuracy: 0.488281 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 177 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.038 | Tree loss: 1.641 | Accuracy: 0.464844 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 178 | Batch: 000 / 037 | Total loss: 1.633 | Reg loss: 0.038 | Tree loss: 1.633 | Accuracy: 0.486328 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 179 | Batch: 000 / 037 | Total loss: 1.612 | Reg loss: 0.038 | Tree loss: 1.612 | Accuracy: 0.486328 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 | Batch: 000 / 037 | Total loss: 1.645 | Reg loss: 0.038 | Tree loss: 1.645 | Accuracy: 0.458984 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 181 | Batch: 000 / 037 | Total loss: 1.619 | Reg loss: 0.038 | Tree loss: 1.619 | Accuracy: 0.464844 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 182 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.038 | Tree loss: 1.632 | Accuracy: 0.462891 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 183 | Batch: 000 / 037 | Total loss: 1.563 | Reg loss: 0.038 | Tree loss: 1.563 | Accuracy: 0.501953 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 184 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.429688 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 185 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.039 | Tree loss: 1.625 | Accuracy: 0.447266 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 186 | Batch: 000 / 037 | Total loss: 1.605 | Reg loss: 0.039 | Tree loss: 1.605 | Accuracy: 0.470703 | 0.783 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 187 | Batch: 000 / 037 | Total loss: 1.593 | Reg loss: 0.039 | Tree loss: 1.593 | Accuracy: 0.523438 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 188 | Batch: 000 / 037 | Total loss: 1.665 | Reg loss: 0.039 | Tree loss: 1.665 | Accuracy: 0.457031 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 189 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.486328 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 190 | Batch: 000 / 037 | Total loss: 1.601 | Reg loss: 0.039 | Tree loss: 1.601 | Accuracy: 0.509766 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 191 | Batch: 000 / 037 | Total loss: 1.597 | Reg loss: 0.039 | Tree loss: 1.597 | Accuracy: 0.458984 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 192 | Batch: 000 / 037 | Total loss: 1.614 | Reg loss: 0.039 | Tree loss: 1.614 | Accuracy: 0.462891 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 193 | Batch: 000 / 037 | Total loss: 1.581 | Reg loss: 0.039 | Tree loss: 1.581 | Accuracy: 0.478516 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 194 | Batch: 000 / 037 | Total loss: 1.615 | Reg loss: 0.039 | Tree loss: 1.615 | Accuracy: 0.478516 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 195 | Batch: 000 / 037 | Total loss: 1.611 | Reg loss: 0.039 | Tree loss: 1.611 | Accuracy: 0.431641 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 196 | Batch: 000 / 037 | Total loss: 1.650 | Reg loss: 0.039 | Tree loss: 1.650 | Accuracy: 0.451172 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 197 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.039 | Tree loss: 1.641 | Accuracy: 0.437500 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 198 | Batch: 000 / 037 | Total loss: 1.649 | Reg loss: 0.039 | Tree loss: 1.649 | Accuracy: 0.439453 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 199 | Batch: 000 / 037 | Total loss: 1.622 | Reg loss: 0.039 | Tree loss: 1.622 | Accuracy: 0.443359 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 200 | Batch: 000 / 037 | Total loss: 1.618 | Reg loss: 0.039 | Tree loss: 1.618 | Accuracy: 0.431641 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 201 | Batch: 000 / 037 | Total loss: 1.591 | Reg loss: 0.039 | Tree loss: 1.591 | Accuracy: 0.496094 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 202 | Batch: 000 / 037 | Total loss: 1.603 | Reg loss: 0.039 | Tree loss: 1.603 | Accuracy: 0.458984 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 203 | Batch: 000 / 037 | Total loss: 1.604 | Reg loss: 0.039 | Tree loss: 1.604 | Accuracy: 0.474609 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 204 | Batch: 000 / 037 | Total loss: 1.568 | Reg loss: 0.039 | Tree loss: 1.568 | Accuracy: 0.500000 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 205 | Batch: 000 / 037 | Total loss: 1.592 | Reg loss: 0.039 | Tree loss: 1.592 | Accuracy: 0.458984 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 206 | Batch: 000 / 037 | Total loss: 1.599 | Reg loss: 0.039 | Tree loss: 1.599 | Accuracy: 0.474609 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 207 | Batch: 000 / 037 | Total loss: 1.588 | Reg loss: 0.039 | Tree loss: 1.588 | Accuracy: 0.486328 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 208 | Batch: 000 / 037 | Total loss: 1.638 | Reg loss: 0.039 | Tree loss: 1.638 | Accuracy: 0.439453 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 209 | Batch: 000 / 037 | Total loss: 1.592 | Reg loss: 0.039 | Tree loss: 1.592 | Accuracy: 0.470703 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 210 | Batch: 000 / 037 | Total loss: 1.619 | Reg loss: 0.039 | Tree loss: 1.619 | Accuracy: 0.429688 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 211 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.039 | Tree loss: 1.637 | Accuracy: 0.431641 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 212 | Batch: 000 / 037 | Total loss: 1.643 | Reg loss: 0.039 | Tree loss: 1.643 | Accuracy: 0.449219 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 213 | Batch: 000 / 037 | Total loss: 1.574 | Reg loss: 0.039 | Tree loss: 1.574 | Accuracy: 0.474609 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 214 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.039 | Tree loss: 1.630 | Accuracy: 0.457031 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 215 | Batch: 000 / 037 | Total loss: 1.621 | Reg loss: 0.039 | Tree loss: 1.621 | Accuracy: 0.447266 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 216 | Batch: 000 / 037 | Total loss: 1.647 | Reg loss: 0.039 | Tree loss: 1.647 | Accuracy: 0.435547 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 217 | Batch: 000 / 037 | Total loss: 1.582 | Reg loss: 0.039 | Tree loss: 1.582 | Accuracy: 0.464844 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 218 | Batch: 000 / 037 | Total loss: 1.658 | Reg loss: 0.039 | Tree loss: 1.658 | Accuracy: 0.402344 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 219 | Batch: 000 / 037 | Total loss: 1.573 | Reg loss: 0.039 | Tree loss: 1.573 | Accuracy: 0.511719 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 | Batch: 000 / 037 | Total loss: 1.616 | Reg loss: 0.039 | Tree loss: 1.616 | Accuracy: 0.457031 | 0.784 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 221 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.039 | Tree loss: 1.657 | Accuracy: 0.439453 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 222 | Batch: 000 / 037 | Total loss: 1.617 | Reg loss: 0.039 | Tree loss: 1.617 | Accuracy: 0.462891 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 223 | Batch: 000 / 037 | Total loss: 1.602 | Reg loss: 0.039 | Tree loss: 1.602 | Accuracy: 0.478516 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 224 | Batch: 000 / 037 | Total loss: 1.663 | Reg loss: 0.039 | Tree loss: 1.663 | Accuracy: 0.417969 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 225 | Batch: 000 / 037 | Total loss: 1.606 | Reg loss: 0.039 | Tree loss: 1.606 | Accuracy: 0.451172 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 226 | Batch: 000 / 037 | Total loss: 1.652 | Reg loss: 0.039 | Tree loss: 1.652 | Accuracy: 0.416016 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 227 | Batch: 000 / 037 | Total loss: 1.618 | Reg loss: 0.039 | Tree loss: 1.618 | Accuracy: 0.460938 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 228 | Batch: 000 / 037 | Total loss: 1.638 | Reg loss: 0.039 | Tree loss: 1.638 | Accuracy: 0.423828 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 229 | Batch: 000 / 037 | Total loss: 1.611 | Reg loss: 0.039 | Tree loss: 1.611 | Accuracy: 0.455078 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 230 | Batch: 000 / 037 | Total loss: 1.612 | Reg loss: 0.039 | Tree loss: 1.612 | Accuracy: 0.470703 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 231 | Batch: 000 / 037 | Total loss: 1.604 | Reg loss: 0.039 | Tree loss: 1.604 | Accuracy: 0.451172 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 232 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.039 | Tree loss: 1.632 | Accuracy: 0.447266 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 233 | Batch: 000 / 037 | Total loss: 1.611 | Reg loss: 0.039 | Tree loss: 1.611 | Accuracy: 0.445312 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 234 | Batch: 000 / 037 | Total loss: 1.644 | Reg loss: 0.039 | Tree loss: 1.644 | Accuracy: 0.462891 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 235 | Batch: 000 / 037 | Total loss: 1.616 | Reg loss: 0.039 | Tree loss: 1.616 | Accuracy: 0.447266 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 236 | Batch: 000 / 037 | Total loss: 1.620 | Reg loss: 0.039 | Tree loss: 1.620 | Accuracy: 0.462891 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 237 | Batch: 000 / 037 | Total loss: 1.566 | Reg loss: 0.039 | Tree loss: 1.566 | Accuracy: 0.472656 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 238 | Batch: 000 / 037 | Total loss: 1.620 | Reg loss: 0.039 | Tree loss: 1.620 | Accuracy: 0.453125 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 239 | Batch: 000 / 037 | Total loss: 1.602 | Reg loss: 0.039 | Tree loss: 1.602 | Accuracy: 0.470703 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240 | Batch: 000 / 037 | Total loss: 1.650 | Reg loss: 0.039 | Tree loss: 1.650 | Accuracy: 0.421875 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 241 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.039 | Tree loss: 1.625 | Accuracy: 0.460938 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 242 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.039 | Tree loss: 1.625 | Accuracy: 0.458984 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 243 | Batch: 000 / 037 | Total loss: 1.618 | Reg loss: 0.039 | Tree loss: 1.618 | Accuracy: 0.453125 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 244 | Batch: 000 / 037 | Total loss: 1.667 | Reg loss: 0.039 | Tree loss: 1.667 | Accuracy: 0.433594 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 245 | Batch: 000 / 037 | Total loss: 1.597 | Reg loss: 0.039 | Tree loss: 1.597 | Accuracy: 0.496094 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 246 | Batch: 000 / 037 | Total loss: 1.622 | Reg loss: 0.039 | Tree loss: 1.622 | Accuracy: 0.457031 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 247 | Batch: 000 / 037 | Total loss: 1.575 | Reg loss: 0.039 | Tree loss: 1.575 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 248 | Batch: 000 / 037 | Total loss: 1.608 | Reg loss: 0.039 | Tree loss: 1.608 | Accuracy: 0.494141 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 249 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.039 | Tree loss: 1.630 | Accuracy: 0.457031 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 250 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.478516 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 251 | Batch: 000 / 037 | Total loss: 1.574 | Reg loss: 0.039 | Tree loss: 1.574 | Accuracy: 0.503906 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 252 | Batch: 000 / 037 | Total loss: 1.596 | Reg loss: 0.039 | Tree loss: 1.596 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 253 | Batch: 000 / 037 | Total loss: 1.628 | Reg loss: 0.039 | Tree loss: 1.628 | Accuracy: 0.468750 | 0.785 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 254 | Batch: 000 / 037 | Total loss: 1.615 | Reg loss: 0.039 | Tree loss: 1.615 | Accuracy: 0.490234 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 255 | Batch: 000 / 037 | Total loss: 1.615 | Reg loss: 0.039 | Tree loss: 1.615 | Accuracy: 0.476562 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 256 | Batch: 000 / 037 | Total loss: 1.598 | Reg loss: 0.039 | Tree loss: 1.598 | Accuracy: 0.527344 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 257 | Batch: 000 / 037 | Total loss: 1.606 | Reg loss: 0.039 | Tree loss: 1.606 | Accuracy: 0.501953 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 258 | Batch: 000 / 037 | Total loss: 1.589 | Reg loss: 0.039 | Tree loss: 1.589 | Accuracy: 0.529297 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 259 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.484375 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260 | Batch: 000 / 037 | Total loss: 1.622 | Reg loss: 0.039 | Tree loss: 1.622 | Accuracy: 0.501953 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 261 | Batch: 000 / 037 | Total loss: 1.663 | Reg loss: 0.039 | Tree loss: 1.663 | Accuracy: 0.472656 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 262 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.039 | Tree loss: 1.630 | Accuracy: 0.472656 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 263 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.039 | Tree loss: 1.637 | Accuracy: 0.501953 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 264 | Batch: 000 / 037 | Total loss: 1.651 | Reg loss: 0.039 | Tree loss: 1.651 | Accuracy: 0.484375 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 265 | Batch: 000 / 037 | Total loss: 1.624 | Reg loss: 0.039 | Tree loss: 1.624 | Accuracy: 0.546875 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 266 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.039 | Tree loss: 1.657 | Accuracy: 0.478516 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 267 | Batch: 000 / 037 | Total loss: 1.619 | Reg loss: 0.039 | Tree loss: 1.619 | Accuracy: 0.531250 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 268 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.492188 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 269 | Batch: 000 / 037 | Total loss: 1.652 | Reg loss: 0.039 | Tree loss: 1.652 | Accuracy: 0.517578 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 270 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.039 | Tree loss: 1.641 | Accuracy: 0.515625 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 271 | Batch: 000 / 037 | Total loss: 1.651 | Reg loss: 0.039 | Tree loss: 1.651 | Accuracy: 0.498047 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 272 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.039 | Tree loss: 1.632 | Accuracy: 0.527344 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 273 | Batch: 000 / 037 | Total loss: 1.674 | Reg loss: 0.039 | Tree loss: 1.674 | Accuracy: 0.527344 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 274 | Batch: 000 / 037 | Total loss: 1.621 | Reg loss: 0.039 | Tree loss: 1.621 | Accuracy: 0.513672 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 275 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.039 | Tree loss: 1.625 | Accuracy: 0.535156 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 276 | Batch: 000 / 037 | Total loss: 1.666 | Reg loss: 0.039 | Tree loss: 1.666 | Accuracy: 0.515625 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 277 | Batch: 000 / 037 | Total loss: 1.636 | Reg loss: 0.039 | Tree loss: 1.636 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 278 | Batch: 000 / 037 | Total loss: 1.663 | Reg loss: 0.039 | Tree loss: 1.663 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 279 | Batch: 000 / 037 | Total loss: 1.671 | Reg loss: 0.039 | Tree loss: 1.671 | Accuracy: 0.500000 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280 | Batch: 000 / 037 | Total loss: 1.628 | Reg loss: 0.039 | Tree loss: 1.628 | Accuracy: 0.533203 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 281 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.039 | Tree loss: 1.657 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 282 | Batch: 000 / 037 | Total loss: 1.570 | Reg loss: 0.039 | Tree loss: 1.570 | Accuracy: 0.548828 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 283 | Batch: 000 / 037 | Total loss: 1.659 | Reg loss: 0.039 | Tree loss: 1.659 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 284 | Batch: 000 / 037 | Total loss: 1.620 | Reg loss: 0.039 | Tree loss: 1.620 | Accuracy: 0.556641 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 285 | Batch: 000 / 037 | Total loss: 1.593 | Reg loss: 0.039 | Tree loss: 1.593 | Accuracy: 0.582031 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 286 | Batch: 000 / 037 | Total loss: 1.618 | Reg loss: 0.039 | Tree loss: 1.618 | Accuracy: 0.539062 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 287 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.523438 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 288 | Batch: 000 / 037 | Total loss: 1.665 | Reg loss: 0.039 | Tree loss: 1.665 | Accuracy: 0.515625 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 289 | Batch: 000 / 037 | Total loss: 1.680 | Reg loss: 0.039 | Tree loss: 1.680 | Accuracy: 0.468750 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 290 | Batch: 000 / 037 | Total loss: 1.644 | Reg loss: 0.039 | Tree loss: 1.644 | Accuracy: 0.537109 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 291 | Batch: 000 / 037 | Total loss: 1.647 | Reg loss: 0.039 | Tree loss: 1.647 | Accuracy: 0.517578 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 292 | Batch: 000 / 037 | Total loss: 1.663 | Reg loss: 0.039 | Tree loss: 1.663 | Accuracy: 0.496094 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 293 | Batch: 000 / 037 | Total loss: 1.643 | Reg loss: 0.039 | Tree loss: 1.643 | Accuracy: 0.523438 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 294 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.039 | Tree loss: 1.630 | Accuracy: 0.539062 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 295 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.039 | Tree loss: 1.630 | Accuracy: 0.535156 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 296 | Batch: 000 / 037 | Total loss: 1.614 | Reg loss: 0.039 | Tree loss: 1.614 | Accuracy: 0.542969 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 297 | Batch: 000 / 037 | Total loss: 1.651 | Reg loss: 0.039 | Tree loss: 1.651 | Accuracy: 0.517578 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 298 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.525391 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 299 | Batch: 000 / 037 | Total loss: 1.614 | Reg loss: 0.039 | Tree loss: 1.614 | Accuracy: 0.515625 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 | Batch: 000 / 037 | Total loss: 1.602 | Reg loss: 0.039 | Tree loss: 1.602 | Accuracy: 0.556641 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 301 | Batch: 000 / 037 | Total loss: 1.646 | Reg loss: 0.039 | Tree loss: 1.646 | Accuracy: 0.519531 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 302 | Batch: 000 / 037 | Total loss: 1.633 | Reg loss: 0.039 | Tree loss: 1.633 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 303 | Batch: 000 / 037 | Total loss: 1.627 | Reg loss: 0.039 | Tree loss: 1.627 | Accuracy: 0.535156 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 304 | Batch: 000 / 037 | Total loss: 1.648 | Reg loss: 0.039 | Tree loss: 1.648 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 305 | Batch: 000 / 037 | Total loss: 1.612 | Reg loss: 0.039 | Tree loss: 1.612 | Accuracy: 0.515625 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 306 | Batch: 000 / 037 | Total loss: 1.624 | Reg loss: 0.039 | Tree loss: 1.624 | Accuracy: 0.529297 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 307 | Batch: 000 / 037 | Total loss: 1.644 | Reg loss: 0.039 | Tree loss: 1.644 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 308 | Batch: 000 / 037 | Total loss: 1.617 | Reg loss: 0.039 | Tree loss: 1.617 | Accuracy: 0.509766 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 309 | Batch: 000 / 037 | Total loss: 1.602 | Reg loss: 0.039 | Tree loss: 1.602 | Accuracy: 0.519531 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 310 | Batch: 000 / 037 | Total loss: 1.638 | Reg loss: 0.039 | Tree loss: 1.638 | Accuracy: 0.503906 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 311 | Batch: 000 / 037 | Total loss: 1.583 | Reg loss: 0.039 | Tree loss: 1.583 | Accuracy: 0.544922 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 312 | Batch: 000 / 037 | Total loss: 1.608 | Reg loss: 0.039 | Tree loss: 1.608 | Accuracy: 0.521484 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 313 | Batch: 000 / 037 | Total loss: 1.633 | Reg loss: 0.039 | Tree loss: 1.633 | Accuracy: 0.527344 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 314 | Batch: 000 / 037 | Total loss: 1.589 | Reg loss: 0.039 | Tree loss: 1.589 | Accuracy: 0.554688 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 315 | Batch: 000 / 037 | Total loss: 1.606 | Reg loss: 0.039 | Tree loss: 1.606 | Accuracy: 0.525391 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 316 | Batch: 000 / 037 | Total loss: 1.631 | Reg loss: 0.039 | Tree loss: 1.631 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 317 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.039 | Tree loss: 1.632 | Accuracy: 0.539062 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 318 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 319 | Batch: 000 / 037 | Total loss: 1.575 | Reg loss: 0.039 | Tree loss: 1.575 | Accuracy: 0.556641 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320 | Batch: 000 / 037 | Total loss: 1.646 | Reg loss: 0.039 | Tree loss: 1.646 | Accuracy: 0.527344 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 321 | Batch: 000 / 037 | Total loss: 1.636 | Reg loss: 0.039 | Tree loss: 1.636 | Accuracy: 0.496094 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 322 | Batch: 000 / 037 | Total loss: 1.605 | Reg loss: 0.039 | Tree loss: 1.605 | Accuracy: 0.521484 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 323 | Batch: 000 / 037 | Total loss: 1.619 | Reg loss: 0.039 | Tree loss: 1.619 | Accuracy: 0.523438 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 324 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.505859 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 325 | Batch: 000 / 037 | Total loss: 1.613 | Reg loss: 0.039 | Tree loss: 1.613 | Accuracy: 0.527344 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 326 | Batch: 000 / 037 | Total loss: 1.616 | Reg loss: 0.039 | Tree loss: 1.616 | Accuracy: 0.490234 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 327 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.486328 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 328 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.039 | Tree loss: 1.637 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 329 | Batch: 000 / 037 | Total loss: 1.677 | Reg loss: 0.039 | Tree loss: 1.677 | Accuracy: 0.441406 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 330 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.039 | Tree loss: 1.625 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 331 | Batch: 000 / 037 | Total loss: 1.638 | Reg loss: 0.039 | Tree loss: 1.638 | Accuracy: 0.529297 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 332 | Batch: 000 / 037 | Total loss: 1.598 | Reg loss: 0.039 | Tree loss: 1.598 | Accuracy: 0.511719 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 333 | Batch: 000 / 037 | Total loss: 1.622 | Reg loss: 0.039 | Tree loss: 1.622 | Accuracy: 0.490234 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 334 | Batch: 000 / 037 | Total loss: 1.614 | Reg loss: 0.039 | Tree loss: 1.614 | Accuracy: 0.517578 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 335 | Batch: 000 / 037 | Total loss: 1.640 | Reg loss: 0.039 | Tree loss: 1.640 | Accuracy: 0.496094 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 336 | Batch: 000 / 037 | Total loss: 1.656 | Reg loss: 0.039 | Tree loss: 1.656 | Accuracy: 0.486328 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 337 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.039 | Tree loss: 1.637 | Accuracy: 0.523438 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 338 | Batch: 000 / 037 | Total loss: 1.603 | Reg loss: 0.039 | Tree loss: 1.603 | Accuracy: 0.533203 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 339 | Batch: 000 / 037 | Total loss: 1.669 | Reg loss: 0.039 | Tree loss: 1.669 | Accuracy: 0.466797 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340 | Batch: 000 / 037 | Total loss: 1.626 | Reg loss: 0.039 | Tree loss: 1.626 | Accuracy: 0.484375 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 341 | Batch: 000 / 037 | Total loss: 1.634 | Reg loss: 0.039 | Tree loss: 1.634 | Accuracy: 0.492188 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 342 | Batch: 000 / 037 | Total loss: 1.658 | Reg loss: 0.039 | Tree loss: 1.658 | Accuracy: 0.472656 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 343 | Batch: 000 / 037 | Total loss: 1.586 | Reg loss: 0.039 | Tree loss: 1.586 | Accuracy: 0.507812 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 344 | Batch: 000 / 037 | Total loss: 1.643 | Reg loss: 0.039 | Tree loss: 1.643 | Accuracy: 0.488281 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 345 | Batch: 000 / 037 | Total loss: 1.648 | Reg loss: 0.039 | Tree loss: 1.648 | Accuracy: 0.500000 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 346 | Batch: 000 / 037 | Total loss: 1.605 | Reg loss: 0.039 | Tree loss: 1.605 | Accuracy: 0.529297 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 347 | Batch: 000 / 037 | Total loss: 1.613 | Reg loss: 0.039 | Tree loss: 1.613 | Accuracy: 0.503906 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 348 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.507812 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 349 | Batch: 000 / 037 | Total loss: 1.635 | Reg loss: 0.039 | Tree loss: 1.635 | Accuracy: 0.501953 | 0.786 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 350 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.039 | Tree loss: 1.637 | Accuracy: 0.523438 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 351 | Batch: 000 / 037 | Total loss: 1.641 | Reg loss: 0.039 | Tree loss: 1.641 | Accuracy: 0.474609 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 352 | Batch: 000 / 037 | Total loss: 1.615 | Reg loss: 0.039 | Tree loss: 1.615 | Accuracy: 0.496094 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 353 | Batch: 000 / 037 | Total loss: 1.609 | Reg loss: 0.039 | Tree loss: 1.609 | Accuracy: 0.517578 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 354 | Batch: 000 / 037 | Total loss: 1.631 | Reg loss: 0.039 | Tree loss: 1.631 | Accuracy: 0.498047 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 355 | Batch: 000 / 037 | Total loss: 1.633 | Reg loss: 0.039 | Tree loss: 1.633 | Accuracy: 0.494141 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 356 | Batch: 000 / 037 | Total loss: 1.671 | Reg loss: 0.039 | Tree loss: 1.671 | Accuracy: 0.480469 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 357 | Batch: 000 / 037 | Total loss: 1.625 | Reg loss: 0.039 | Tree loss: 1.625 | Accuracy: 0.482422 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 358 | Batch: 000 / 037 | Total loss: 1.658 | Reg loss: 0.039 | Tree loss: 1.658 | Accuracy: 0.486328 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 359 | Batch: 000 / 037 | Total loss: 1.661 | Reg loss: 0.039 | Tree loss: 1.661 | Accuracy: 0.486328 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360 | Batch: 000 / 037 | Total loss: 1.608 | Reg loss: 0.039 | Tree loss: 1.608 | Accuracy: 0.511719 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 361 | Batch: 000 / 037 | Total loss: 1.594 | Reg loss: 0.039 | Tree loss: 1.594 | Accuracy: 0.537109 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 362 | Batch: 000 / 037 | Total loss: 1.629 | Reg loss: 0.039 | Tree loss: 1.629 | Accuracy: 0.498047 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 363 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.517578 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 364 | Batch: 000 / 037 | Total loss: 1.622 | Reg loss: 0.039 | Tree loss: 1.622 | Accuracy: 0.488281 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 365 | Batch: 000 / 037 | Total loss: 1.642 | Reg loss: 0.039 | Tree loss: 1.642 | Accuracy: 0.500000 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 366 | Batch: 000 / 037 | Total loss: 1.626 | Reg loss: 0.039 | Tree loss: 1.626 | Accuracy: 0.498047 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 367 | Batch: 000 / 037 | Total loss: 1.638 | Reg loss: 0.039 | Tree loss: 1.638 | Accuracy: 0.519531 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 368 | Batch: 000 / 037 | Total loss: 1.643 | Reg loss: 0.039 | Tree loss: 1.643 | Accuracy: 0.470703 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 369 | Batch: 000 / 037 | Total loss: 1.654 | Reg loss: 0.039 | Tree loss: 1.654 | Accuracy: 0.460938 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 370 | Batch: 000 / 037 | Total loss: 1.596 | Reg loss: 0.039 | Tree loss: 1.596 | Accuracy: 0.515625 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 371 | Batch: 000 / 037 | Total loss: 1.636 | Reg loss: 0.039 | Tree loss: 1.636 | Accuracy: 0.507812 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 372 | Batch: 000 / 037 | Total loss: 1.660 | Reg loss: 0.039 | Tree loss: 1.660 | Accuracy: 0.466797 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 373 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.039 | Tree loss: 1.632 | Accuracy: 0.496094 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 374 | Batch: 000 / 037 | Total loss: 1.639 | Reg loss: 0.039 | Tree loss: 1.639 | Accuracy: 0.505859 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 375 | Batch: 000 / 037 | Total loss: 1.630 | Reg loss: 0.039 | Tree loss: 1.630 | Accuracy: 0.496094 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 376 | Batch: 000 / 037 | Total loss: 1.627 | Reg loss: 0.039 | Tree loss: 1.627 | Accuracy: 0.513672 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 377 | Batch: 000 / 037 | Total loss: 1.591 | Reg loss: 0.039 | Tree loss: 1.591 | Accuracy: 0.511719 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 378 | Batch: 000 / 037 | Total loss: 1.649 | Reg loss: 0.039 | Tree loss: 1.649 | Accuracy: 0.476562 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 379 | Batch: 000 / 037 | Total loss: 1.631 | Reg loss: 0.039 | Tree loss: 1.631 | Accuracy: 0.478516 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380 | Batch: 000 / 037 | Total loss: 1.632 | Reg loss: 0.039 | Tree loss: 1.632 | Accuracy: 0.490234 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 381 | Batch: 000 / 037 | Total loss: 1.637 | Reg loss: 0.039 | Tree loss: 1.637 | Accuracy: 0.472656 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 382 | Batch: 000 / 037 | Total loss: 1.626 | Reg loss: 0.039 | Tree loss: 1.626 | Accuracy: 0.503906 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 383 | Batch: 000 / 037 | Total loss: 1.642 | Reg loss: 0.039 | Tree loss: 1.642 | Accuracy: 0.494141 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 384 | Batch: 000 / 037 | Total loss: 1.668 | Reg loss: 0.039 | Tree loss: 1.668 | Accuracy: 0.458984 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 385 | Batch: 000 / 037 | Total loss: 1.644 | Reg loss: 0.039 | Tree loss: 1.644 | Accuracy: 0.468750 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 386 | Batch: 000 / 037 | Total loss: 1.667 | Reg loss: 0.039 | Tree loss: 1.667 | Accuracy: 0.464844 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 387 | Batch: 000 / 037 | Total loss: 1.642 | Reg loss: 0.039 | Tree loss: 1.642 | Accuracy: 0.488281 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 388 | Batch: 000 / 037 | Total loss: 1.623 | Reg loss: 0.039 | Tree loss: 1.623 | Accuracy: 0.496094 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 389 | Batch: 000 / 037 | Total loss: 1.608 | Reg loss: 0.039 | Tree loss: 1.608 | Accuracy: 0.529297 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 390 | Batch: 000 / 037 | Total loss: 1.657 | Reg loss: 0.039 | Tree loss: 1.657 | Accuracy: 0.484375 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 391 | Batch: 000 / 037 | Total loss: 1.604 | Reg loss: 0.039 | Tree loss: 1.604 | Accuracy: 0.513672 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 392 | Batch: 000 / 037 | Total loss: 1.634 | Reg loss: 0.039 | Tree loss: 1.634 | Accuracy: 0.500000 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 393 | Batch: 000 / 037 | Total loss: 1.612 | Reg loss: 0.039 | Tree loss: 1.612 | Accuracy: 0.500000 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 394 | Batch: 000 / 037 | Total loss: 1.638 | Reg loss: 0.039 | Tree loss: 1.638 | Accuracy: 0.486328 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 395 | Batch: 000 / 037 | Total loss: 1.569 | Reg loss: 0.039 | Tree loss: 1.569 | Accuracy: 0.546875 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 396 | Batch: 000 / 037 | Total loss: 1.598 | Reg loss: 0.039 | Tree loss: 1.598 | Accuracy: 0.533203 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 397 | Batch: 000 / 037 | Total loss: 1.589 | Reg loss: 0.039 | Tree loss: 1.589 | Accuracy: 0.525391 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 398 | Batch: 000 / 037 | Total loss: 1.671 | Reg loss: 0.039 | Tree loss: 1.671 | Accuracy: 0.468750 | 0.787 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 399 | Batch: 000 / 037 | Total loss: 1.587 | Reg loss: 0.039 | Tree loss: 1.587 | Accuracy: 0.542969 | 0.787 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0225a669c13a4e3cac3e8c4459c5b0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7744365033c84d6bb7187cf1794002ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8c884fec5a477abbf92572e05f299a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23e001755144468986970419acb66c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 7.51063829787234\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 47\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "8\n",
      "============== Pattern 3 ==============\n",
      "57\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "39\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "5190\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "2\n",
      "============== Pattern 19 ==============\n",
      "12\n",
      "============== Pattern 20 ==============\n",
      "7091\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "2952\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "============== Pattern 25 ==============\n",
      "============== Pattern 26 ==============\n",
      "============== Pattern 27 ==============\n",
      "============== Pattern 28 ==============\n",
      "============== Pattern 29 ==============\n",
      "============== Pattern 30 ==============\n",
      "============== Pattern 31 ==============\n",
      "1\n",
      "============== Pattern 32 ==============\n",
      "============== Pattern 33 ==============\n",
      "============== Pattern 34 ==============\n",
      "2760\n",
      "============== Pattern 35 ==============\n",
      "============== Pattern 36 ==============\n",
      "============== Pattern 37 ==============\n",
      "============== Pattern 38 ==============\n",
      "============== Pattern 39 ==============\n",
      "============== Pattern 40 ==============\n",
      "============== Pattern 41 ==============\n",
      "659\n",
      "============== Pattern 42 ==============\n",
      "============== Pattern 43 ==============\n",
      "============== Pattern 44 ==============\n",
      "============== Pattern 45 ==============\n",
      "============== Pattern 46 ==============\n",
      "============== Pattern 47 ==============\n",
      "Average comprehensibility: 42.765957446808514\n",
      "std comprehensibility: 12.565086322666533\n",
      "var comprehensibility: 157.8813942960616\n",
      "minimum comprehensibility: 12\n",
      "maximum comprehensibility: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    }
   ],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
