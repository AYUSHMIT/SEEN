{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128\n",
    "tree_depth = 8\n",
    "batch_size = 512\n",
    "device = 'cpu'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.479093551635742 | KNN Loss: 5.855673789978027 | CLS Loss: 1.623420000076294\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 6.210329532623291 | KNN Loss: 5.366710186004639 | CLS Loss: 0.843619167804718\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 5.910048961639404 | KNN Loss: 5.182383060455322 | CLS Loss: 0.7276658415794373\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 5.910216808319092 | KNN Loss: 5.185675621032715 | CLS Loss: 0.7245411276817322\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 5.7453765869140625 | KNN Loss: 5.1567535400390625 | CLS Loss: 0.5886231064796448\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 5.7135725021362305 | KNN Loss: 5.165256500244141 | CLS Loss: 0.5483161807060242\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 5.619647979736328 | KNN Loss: 5.102312088012695 | CLS Loss: 0.5173361301422119\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 5.560379505157471 | KNN Loss: 5.040430068969727 | CLS Loss: 0.5199493169784546\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 5.610757827758789 | KNN Loss: 5.0879621505737305 | CLS Loss: 0.5227959156036377\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 5.491002082824707 | KNN Loss: 5.0246901512146 | CLS Loss: 0.46631214022636414\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 5.5171332359313965 | KNN Loss: 5.032895088195801 | CLS Loss: 0.4842381179332733\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 5.403461456298828 | KNN Loss: 5.005601406097412 | CLS Loss: 0.3978602886199951\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 5.356472969055176 | KNN Loss: 5.032492160797119 | CLS Loss: 0.3239809572696686\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 5.380525588989258 | KNN Loss: 4.964413166046143 | CLS Loss: 0.41611236333847046\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 5.275345802307129 | KNN Loss: 4.969518184661865 | CLS Loss: 0.305827796459198\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 5.256808280944824 | KNN Loss: 4.9884724617004395 | CLS Loss: 0.2683357000350952\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 5.331142425537109 | KNN Loss: 5.021013259887695 | CLS Loss: 0.3101292550563812\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 5.216300010681152 | KNN Loss: 4.955790996551514 | CLS Loss: 0.2605089545249939\n",
      "Epoch: 001, Loss: 5.6045, Train: 0.9180, Valid: 0.9173, Best: 0.9173\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 5.220153331756592 | KNN Loss: 4.9468817710876465 | CLS Loss: 0.2732713520526886\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 5.2286906242370605 | KNN Loss: 4.943994045257568 | CLS Loss: 0.284696489572525\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 5.23327112197876 | KNN Loss: 4.928304672241211 | CLS Loss: 0.3049663305282593\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 5.268509387969971 | KNN Loss: 4.956780910491943 | CLS Loss: 0.31172868609428406\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 5.1767377853393555 | KNN Loss: 4.951562881469727 | CLS Loss: 0.22517475485801697\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 5.221144676208496 | KNN Loss: 4.954327583312988 | CLS Loss: 0.26681724190711975\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 5.167990207672119 | KNN Loss: 4.963140487670898 | CLS Loss: 0.2048494964838028\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 5.1228532791137695 | KNN Loss: 4.888686180114746 | CLS Loss: 0.23416690528392792\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 5.245615482330322 | KNN Loss: 4.953444957733154 | CLS Loss: 0.29217058420181274\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 5.132757663726807 | KNN Loss: 4.924508571624756 | CLS Loss: 0.20824898779392242\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 5.145330905914307 | KNN Loss: 4.938227653503418 | CLS Loss: 0.20710328221321106\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 5.107914447784424 | KNN Loss: 4.933593273162842 | CLS Loss: 0.17432105541229248\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 5.103091716766357 | KNN Loss: 4.915334701538086 | CLS Loss: 0.18775711953639984\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 5.114663600921631 | KNN Loss: 4.9319868087768555 | CLS Loss: 0.1826767772436142\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 5.073247909545898 | KNN Loss: 4.932718276977539 | CLS Loss: 0.1405298262834549\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 5.119616508483887 | KNN Loss: 4.916291236877441 | CLS Loss: 0.20332518219947815\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 5.075677394866943 | KNN Loss: 4.904143333435059 | CLS Loss: 0.17153416574001312\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 5.117039680480957 | KNN Loss: 4.956773281097412 | CLS Loss: 0.16026633977890015\n",
      "Epoch: 002, Loss: 5.1625, Train: 0.9585, Valid: 0.9569, Best: 0.9569\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 5.043741226196289 | KNN Loss: 4.885836601257324 | CLS Loss: 0.1579045206308365\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 5.018826007843018 | KNN Loss: 4.912355422973633 | CLS Loss: 0.10647039115428925\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 5.040053844451904 | KNN Loss: 4.870877265930176 | CLS Loss: 0.16917651891708374\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 5.0324296951293945 | KNN Loss: 4.882464408874512 | CLS Loss: 0.14996516704559326\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 5.09722375869751 | KNN Loss: 4.91684103012085 | CLS Loss: 0.1803826242685318\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 4.9678168296813965 | KNN Loss: 4.8810930252075195 | CLS Loss: 0.0867239385843277\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 5.049519062042236 | KNN Loss: 4.85524320602417 | CLS Loss: 0.19427604973316193\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 5.074285984039307 | KNN Loss: 4.8991804122924805 | CLS Loss: 0.17510554194450378\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 4.934841156005859 | KNN Loss: 4.857032775878906 | CLS Loss: 0.07780852913856506\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 5.018496513366699 | KNN Loss: 4.887016296386719 | CLS Loss: 0.13148033618927002\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 4.971410751342773 | KNN Loss: 4.847090244293213 | CLS Loss: 0.12432029098272324\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 5.070558071136475 | KNN Loss: 4.86627721786499 | CLS Loss: 0.20428062975406647\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 5.027547359466553 | KNN Loss: 4.87705659866333 | CLS Loss: 0.15049073100090027\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 4.947400093078613 | KNN Loss: 4.856940269470215 | CLS Loss: 0.09045989066362381\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 4.968445301055908 | KNN Loss: 4.855929374694824 | CLS Loss: 0.11251578480005264\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 4.973562717437744 | KNN Loss: 4.820417881011963 | CLS Loss: 0.1531446874141693\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 4.976661682128906 | KNN Loss: 4.869294166564941 | CLS Loss: 0.10736759752035141\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 5.0067362785339355 | KNN Loss: 4.86515474319458 | CLS Loss: 0.14158135652542114\n",
      "Epoch: 003, Loss: 5.0340, Train: 0.9683, Valid: 0.9662, Best: 0.9662\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 5.0478196144104 | KNN Loss: 4.898083686828613 | CLS Loss: 0.14973610639572144\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 4.99127197265625 | KNN Loss: 4.827297687530518 | CLS Loss: 0.16397443413734436\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 5.001672744750977 | KNN Loss: 4.849595069885254 | CLS Loss: 0.15207776427268982\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 4.993931293487549 | KNN Loss: 4.86353874206543 | CLS Loss: 0.13039258122444153\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 4.951101303100586 | KNN Loss: 4.839545726776123 | CLS Loss: 0.11155562847852707\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 5.0047478675842285 | KNN Loss: 4.869592666625977 | CLS Loss: 0.13515526056289673\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 4.984821796417236 | KNN Loss: 4.853938579559326 | CLS Loss: 0.13088326156139374\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 4.943721771240234 | KNN Loss: 4.834925651550293 | CLS Loss: 0.10879615694284439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 4.985884189605713 | KNN Loss: 4.904341697692871 | CLS Loss: 0.08154263347387314\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 4.954887390136719 | KNN Loss: 4.829421043395996 | CLS Loss: 0.1254662275314331\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 5.042200565338135 | KNN Loss: 4.883302211761475 | CLS Loss: 0.15889844298362732\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 4.958935737609863 | KNN Loss: 4.862678050994873 | CLS Loss: 0.09625766426324844\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 4.986711025238037 | KNN Loss: 4.874623775482178 | CLS Loss: 0.11208714544773102\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 5.0000319480896 | KNN Loss: 4.879295825958252 | CLS Loss: 0.12073612213134766\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 4.962998390197754 | KNN Loss: 4.871077537536621 | CLS Loss: 0.09192091226577759\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 4.993232727050781 | KNN Loss: 4.849697589874268 | CLS Loss: 0.14353513717651367\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 4.957733631134033 | KNN Loss: 4.833176136016846 | CLS Loss: 0.1245574876666069\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 4.9251885414123535 | KNN Loss: 4.819238185882568 | CLS Loss: 0.10595039278268814\n",
      "Epoch: 004, Loss: 4.9782, Train: 0.9702, Valid: 0.9670, Best: 0.9670\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 5.012740612030029 | KNN Loss: 4.84622049331665 | CLS Loss: 0.16652008891105652\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 4.957827568054199 | KNN Loss: 4.860414028167725 | CLS Loss: 0.09741333872079849\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 4.933844089508057 | KNN Loss: 4.793126583099365 | CLS Loss: 0.14071741700172424\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 4.88983154296875 | KNN Loss: 4.803256034851074 | CLS Loss: 0.08657535165548325\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 4.896948337554932 | KNN Loss: 4.788809776306152 | CLS Loss: 0.10813863575458527\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 4.9349541664123535 | KNN Loss: 4.826099395751953 | CLS Loss: 0.10885484516620636\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 4.982936859130859 | KNN Loss: 4.873200416564941 | CLS Loss: 0.1097366139292717\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 4.908507823944092 | KNN Loss: 4.849914073944092 | CLS Loss: 0.05859353020787239\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 4.98159646987915 | KNN Loss: 4.856116771697998 | CLS Loss: 0.12547969818115234\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 4.986970901489258 | KNN Loss: 4.875552654266357 | CLS Loss: 0.11141844093799591\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 4.939412593841553 | KNN Loss: 4.8317365646362305 | CLS Loss: 0.1076759472489357\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 4.923760414123535 | KNN Loss: 4.845158576965332 | CLS Loss: 0.07860205322504044\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 4.911590099334717 | KNN Loss: 4.779360294342041 | CLS Loss: 0.13222981989383698\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 4.980249404907227 | KNN Loss: 4.865015506744385 | CLS Loss: 0.1152338981628418\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 4.945214748382568 | KNN Loss: 4.825040340423584 | CLS Loss: 0.12017437815666199\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 4.970921039581299 | KNN Loss: 4.892857551574707 | CLS Loss: 0.07806358486413956\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 4.96634578704834 | KNN Loss: 4.863389015197754 | CLS Loss: 0.1029568761587143\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 4.913033962249756 | KNN Loss: 4.829837799072266 | CLS Loss: 0.08319630473852158\n",
      "Epoch: 005, Loss: 4.9457, Train: 0.9714, Valid: 0.9683, Best: 0.9683\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 4.939547538757324 | KNN Loss: 4.85919189453125 | CLS Loss: 0.080355703830719\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 4.962002754211426 | KNN Loss: 4.866134166717529 | CLS Loss: 0.09586881846189499\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 4.940536975860596 | KNN Loss: 4.838801383972168 | CLS Loss: 0.1017354354262352\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 4.86542272567749 | KNN Loss: 4.812250137329102 | CLS Loss: 0.05317244306206703\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 4.920327186584473 | KNN Loss: 4.807126998901367 | CLS Loss: 0.11320014297962189\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 4.929455757141113 | KNN Loss: 4.826015949249268 | CLS Loss: 0.10343979299068451\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 4.917870044708252 | KNN Loss: 4.820469379425049 | CLS Loss: 0.09740044921636581\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 4.909630298614502 | KNN Loss: 4.8057684898376465 | CLS Loss: 0.10386166721582413\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 4.866305828094482 | KNN Loss: 4.765407562255859 | CLS Loss: 0.10089815407991409\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 4.956921100616455 | KNN Loss: 4.826642990112305 | CLS Loss: 0.13027821481227875\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 4.851604461669922 | KNN Loss: 4.806774616241455 | CLS Loss: 0.04482974112033844\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 4.900396347045898 | KNN Loss: 4.8229079246521 | CLS Loss: 0.07748841494321823\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 4.877077102661133 | KNN Loss: 4.788856029510498 | CLS Loss: 0.08822102099657059\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 4.876760482788086 | KNN Loss: 4.815704822540283 | CLS Loss: 0.061055660247802734\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 4.963531970977783 | KNN Loss: 4.852083683013916 | CLS Loss: 0.1114485040307045\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 4.938748359680176 | KNN Loss: 4.831818103790283 | CLS Loss: 0.10693003982305527\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 4.940641403198242 | KNN Loss: 4.838435649871826 | CLS Loss: 0.10220568627119064\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 4.865445613861084 | KNN Loss: 4.804272174835205 | CLS Loss: 0.061173323541879654\n",
      "Epoch: 006, Loss: 4.9125, Train: 0.9771, Valid: 0.9742, Best: 0.9742\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 4.888725757598877 | KNN Loss: 4.829402446746826 | CLS Loss: 0.05932312831282616\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 4.916110992431641 | KNN Loss: 4.835877418518066 | CLS Loss: 0.08023355156183243\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 4.913922309875488 | KNN Loss: 4.805633544921875 | CLS Loss: 0.10828852653503418\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 4.887730121612549 | KNN Loss: 4.819427490234375 | CLS Loss: 0.06830256432294846\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 4.894503593444824 | KNN Loss: 4.822376728057861 | CLS Loss: 0.07212670892477036\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 4.895318031311035 | KNN Loss: 4.7798357009887695 | CLS Loss: 0.1154821589589119\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 4.897572040557861 | KNN Loss: 4.828449726104736 | CLS Loss: 0.06912244856357574\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 4.953954219818115 | KNN Loss: 4.828971862792969 | CLS Loss: 0.12498245388269424\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 4.910417079925537 | KNN Loss: 4.825992107391357 | CLS Loss: 0.08442509919404984\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 4.962334632873535 | KNN Loss: 4.8582024574279785 | CLS Loss: 0.10413207858800888\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 4.913414001464844 | KNN Loss: 4.8480353355407715 | CLS Loss: 0.06537874042987823\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 4.883162021636963 | KNN Loss: 4.797125339508057 | CLS Loss: 0.08603648841381073\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 4.827962398529053 | KNN Loss: 4.771450996398926 | CLS Loss: 0.056511253118515015\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 4.859889030456543 | KNN Loss: 4.7777180671691895 | CLS Loss: 0.08217114210128784\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 4.88936185836792 | KNN Loss: 4.803297996520996 | CLS Loss: 0.0860639289021492\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 4.866816520690918 | KNN Loss: 4.7713799476623535 | CLS Loss: 0.09543649852275848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 4.893457889556885 | KNN Loss: 4.822717666625977 | CLS Loss: 0.07074011117219925\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 4.861776828765869 | KNN Loss: 4.796504974365234 | CLS Loss: 0.06527180969715118\n",
      "Epoch: 007, Loss: 4.8884, Train: 0.9793, Valid: 0.9767, Best: 0.9767\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 4.8307671546936035 | KNN Loss: 4.7627339363098145 | CLS Loss: 0.06803344935178757\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 4.84659481048584 | KNN Loss: 4.772560119628906 | CLS Loss: 0.07403487712144852\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 4.882425308227539 | KNN Loss: 4.782869338989258 | CLS Loss: 0.09955620020627975\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 4.863083839416504 | KNN Loss: 4.797335147857666 | CLS Loss: 0.06574861705303192\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 4.869645118713379 | KNN Loss: 4.79896879196167 | CLS Loss: 0.07067614048719406\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 4.818186283111572 | KNN Loss: 4.776377201080322 | CLS Loss: 0.04180891811847687\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 4.85737419128418 | KNN Loss: 4.781982421875 | CLS Loss: 0.07539180666208267\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 4.8055877685546875 | KNN Loss: 4.747023582458496 | CLS Loss: 0.058564018458127975\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 4.8618550300598145 | KNN Loss: 4.807627201080322 | CLS Loss: 0.05422785133123398\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 4.791808605194092 | KNN Loss: 4.766867637634277 | CLS Loss: 0.024940961971879005\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 4.864311695098877 | KNN Loss: 4.787135601043701 | CLS Loss: 0.07717600464820862\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 4.814951419830322 | KNN Loss: 4.7687602043151855 | CLS Loss: 0.0461910143494606\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 4.863337516784668 | KNN Loss: 4.774041175842285 | CLS Loss: 0.08929628878831863\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 4.894771099090576 | KNN Loss: 4.793832778930664 | CLS Loss: 0.10093813389539719\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 4.8456902503967285 | KNN Loss: 4.793414115905762 | CLS Loss: 0.05227620154619217\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 4.863373279571533 | KNN Loss: 4.790687561035156 | CLS Loss: 0.07268588244915009\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 4.897335052490234 | KNN Loss: 4.809817314147949 | CLS Loss: 0.08751769363880157\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 4.865009307861328 | KNN Loss: 4.7980875968933105 | CLS Loss: 0.06692156195640564\n",
      "Epoch: 008, Loss: 4.8747, Train: 0.9803, Valid: 0.9763, Best: 0.9767\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 4.809604167938232 | KNN Loss: 4.770430564880371 | CLS Loss: 0.039173420518636703\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 4.874676704406738 | KNN Loss: 4.800140857696533 | CLS Loss: 0.07453598082065582\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 4.869426250457764 | KNN Loss: 4.793569087982178 | CLS Loss: 0.07585718482732773\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 4.890584468841553 | KNN Loss: 4.809957504272461 | CLS Loss: 0.08062700182199478\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 4.887096881866455 | KNN Loss: 4.819343566894531 | CLS Loss: 0.06775324046611786\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 4.873940944671631 | KNN Loss: 4.800131797790527 | CLS Loss: 0.07380911707878113\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 4.842092990875244 | KNN Loss: 4.754906177520752 | CLS Loss: 0.0871867686510086\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 4.844647407531738 | KNN Loss: 4.757884502410889 | CLS Loss: 0.0867629125714302\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 4.866237163543701 | KNN Loss: 4.767035484313965 | CLS Loss: 0.09920156002044678\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 4.894320011138916 | KNN Loss: 4.818155765533447 | CLS Loss: 0.07616428285837173\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 4.8850789070129395 | KNN Loss: 4.799372673034668 | CLS Loss: 0.08570633828639984\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 4.8153533935546875 | KNN Loss: 4.76996374130249 | CLS Loss: 0.04538960009813309\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 4.933495998382568 | KNN Loss: 4.8250908851623535 | CLS Loss: 0.10840504616498947\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 4.855634689331055 | KNN Loss: 4.792835712432861 | CLS Loss: 0.06279900670051575\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 4.818479537963867 | KNN Loss: 4.759065628051758 | CLS Loss: 0.05941389501094818\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 4.883702278137207 | KNN Loss: 4.791101455688477 | CLS Loss: 0.09260087460279465\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 4.839085578918457 | KNN Loss: 4.775118827819824 | CLS Loss: 0.06396691501140594\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 4.847172260284424 | KNN Loss: 4.771687030792236 | CLS Loss: 0.07548519968986511\n",
      "Epoch: 009, Loss: 4.8571, Train: 0.9809, Valid: 0.9777, Best: 0.9777\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 4.865932941436768 | KNN Loss: 4.775441646575928 | CLS Loss: 0.0904913991689682\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 4.828881740570068 | KNN Loss: 4.769733428955078 | CLS Loss: 0.05914847552776337\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 4.851263523101807 | KNN Loss: 4.787129878997803 | CLS Loss: 0.06413374096155167\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 4.846055507659912 | KNN Loss: 4.786232948303223 | CLS Loss: 0.059822387993335724\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 4.85524320602417 | KNN Loss: 4.76405668258667 | CLS Loss: 0.09118646383285522\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 4.826059341430664 | KNN Loss: 4.775280952453613 | CLS Loss: 0.05077816918492317\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 4.829150676727295 | KNN Loss: 4.767484664916992 | CLS Loss: 0.06166621670126915\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 4.816140174865723 | KNN Loss: 4.772651195526123 | CLS Loss: 0.04348886385560036\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 4.822081089019775 | KNN Loss: 4.758386611938477 | CLS Loss: 0.06369443237781525\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 4.832579612731934 | KNN Loss: 4.764272689819336 | CLS Loss: 0.06830696016550064\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 4.9456706047058105 | KNN Loss: 4.833651542663574 | CLS Loss: 0.11201929301023483\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 4.83889102935791 | KNN Loss: 4.764856338500977 | CLS Loss: 0.07403460144996643\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 4.902852535247803 | KNN Loss: 4.822571277618408 | CLS Loss: 0.08028114587068558\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 4.831100940704346 | KNN Loss: 4.750293254852295 | CLS Loss: 0.08080750703811646\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 4.799692153930664 | KNN Loss: 4.756968975067139 | CLS Loss: 0.04272338002920151\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 4.89408540725708 | KNN Loss: 4.831119537353516 | CLS Loss: 0.06296592950820923\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 4.840034484863281 | KNN Loss: 4.796080112457275 | CLS Loss: 0.04395424202084541\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 4.860606670379639 | KNN Loss: 4.780373573303223 | CLS Loss: 0.08023320883512497\n",
      "Epoch: 010, Loss: 4.8470, Train: 0.9807, Valid: 0.9769, Best: 0.9777\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 4.796534061431885 | KNN Loss: 4.744318962097168 | CLS Loss: 0.052214935421943665\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 4.825268745422363 | KNN Loss: 4.7444987297058105 | CLS Loss: 0.0807698667049408\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 4.806785583496094 | KNN Loss: 4.760996341705322 | CLS Loss: 0.04578929767012596\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 4.800074577331543 | KNN Loss: 4.746119022369385 | CLS Loss: 0.05395554378628731\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 4.843008995056152 | KNN Loss: 4.761196136474609 | CLS Loss: 0.08181264251470566\n",
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 4.843369483947754 | KNN Loss: 4.795809745788574 | CLS Loss: 0.047559913247823715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 4.899861812591553 | KNN Loss: 4.8376240730285645 | CLS Loss: 0.06223784387111664\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 4.78014612197876 | KNN Loss: 4.730955600738525 | CLS Loss: 0.04919062554836273\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 4.873658180236816 | KNN Loss: 4.794013977050781 | CLS Loss: 0.07964427769184113\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 4.814882755279541 | KNN Loss: 4.77776575088501 | CLS Loss: 0.03711717575788498\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 4.84725284576416 | KNN Loss: 4.7870941162109375 | CLS Loss: 0.06015869230031967\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 4.857163906097412 | KNN Loss: 4.77741813659668 | CLS Loss: 0.07974568754434586\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 4.795465469360352 | KNN Loss: 4.742465019226074 | CLS Loss: 0.053000494837760925\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 4.8629584312438965 | KNN Loss: 4.793055057525635 | CLS Loss: 0.06990335136651993\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 4.809770107269287 | KNN Loss: 4.74609375 | CLS Loss: 0.06367634236812592\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 4.860249042510986 | KNN Loss: 4.755884170532227 | CLS Loss: 0.1043647974729538\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 4.863665580749512 | KNN Loss: 4.796153545379639 | CLS Loss: 0.06751208752393723\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 4.935515403747559 | KNN Loss: 4.822340965270996 | CLS Loss: 0.1131744384765625\n",
      "Epoch: 011, Loss: 4.8302, Train: 0.9840, Valid: 0.9794, Best: 0.9794\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 4.859168529510498 | KNN Loss: 4.789165496826172 | CLS Loss: 0.07000285387039185\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 4.823047161102295 | KNN Loss: 4.768182277679443 | CLS Loss: 0.05486484244465828\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 4.829535961151123 | KNN Loss: 4.775807857513428 | CLS Loss: 0.05372799560427666\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 4.861014366149902 | KNN Loss: 4.7819671630859375 | CLS Loss: 0.07904732972383499\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 4.828872203826904 | KNN Loss: 4.763452529907227 | CLS Loss: 0.06541960686445236\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 4.847540378570557 | KNN Loss: 4.78790807723999 | CLS Loss: 0.05963240563869476\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 4.823079586029053 | KNN Loss: 4.768698692321777 | CLS Loss: 0.054381050169467926\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 4.863311767578125 | KNN Loss: 4.796216011047363 | CLS Loss: 0.06709569692611694\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 4.796647548675537 | KNN Loss: 4.738306999206543 | CLS Loss: 0.05834066495299339\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 4.838364601135254 | KNN Loss: 4.767170429229736 | CLS Loss: 0.07119409739971161\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 4.83576774597168 | KNN Loss: 4.767259120941162 | CLS Loss: 0.06850885599851608\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 4.7686448097229 | KNN Loss: 4.721112251281738 | CLS Loss: 0.04753275215625763\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 4.8292412757873535 | KNN Loss: 4.77362585067749 | CLS Loss: 0.05561545118689537\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 4.812674045562744 | KNN Loss: 4.768238544464111 | CLS Loss: 0.04443570598959923\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 4.7983317375183105 | KNN Loss: 4.752601146697998 | CLS Loss: 0.04573037475347519\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 4.819312572479248 | KNN Loss: 4.758679389953613 | CLS Loss: 0.060633376240730286\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 4.844689846038818 | KNN Loss: 4.765437602996826 | CLS Loss: 0.07925212383270264\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 4.84287691116333 | KNN Loss: 4.787047863006592 | CLS Loss: 0.0558290034532547\n",
      "Epoch: 012, Loss: 4.8274, Train: 0.9856, Valid: 0.9823, Best: 0.9823\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 4.806999206542969 | KNN Loss: 4.7480974197387695 | CLS Loss: 0.05890166759490967\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 4.797892093658447 | KNN Loss: 4.736815929412842 | CLS Loss: 0.06107638031244278\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 4.798331260681152 | KNN Loss: 4.773254871368408 | CLS Loss: 0.02507629431784153\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 4.828166961669922 | KNN Loss: 4.7589111328125 | CLS Loss: 0.06925592571496964\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 4.823945045471191 | KNN Loss: 4.75722599029541 | CLS Loss: 0.066719189286232\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 4.920102596282959 | KNN Loss: 4.8275146484375 | CLS Loss: 0.0925881639122963\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 4.862303733825684 | KNN Loss: 4.788439750671387 | CLS Loss: 0.07386405766010284\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 4.790016174316406 | KNN Loss: 4.754061222076416 | CLS Loss: 0.03595472872257233\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 4.865042209625244 | KNN Loss: 4.803600788116455 | CLS Loss: 0.06144148111343384\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 4.806666374206543 | KNN Loss: 4.727863788604736 | CLS Loss: 0.07880271226167679\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 4.797545433044434 | KNN Loss: 4.76175594329834 | CLS Loss: 0.035789605230093\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 4.829219341278076 | KNN Loss: 4.795723915100098 | CLS Loss: 0.03349538519978523\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 4.788613796234131 | KNN Loss: 4.755326271057129 | CLS Loss: 0.03328768536448479\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 4.817665100097656 | KNN Loss: 4.773576259613037 | CLS Loss: 0.04408879578113556\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 4.783533096313477 | KNN Loss: 4.74226713180542 | CLS Loss: 0.04126610979437828\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 4.809309959411621 | KNN Loss: 4.774752616882324 | CLS Loss: 0.03455734625458717\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 4.810067176818848 | KNN Loss: 4.735301494598389 | CLS Loss: 0.07476557791233063\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 4.83529806137085 | KNN Loss: 4.768683433532715 | CLS Loss: 0.06661473959684372\n",
      "Epoch: 013, Loss: 4.8188, Train: 0.9852, Valid: 0.9807, Best: 0.9823\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 4.822323322296143 | KNN Loss: 4.743292331695557 | CLS Loss: 0.07903093844652176\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 4.842059135437012 | KNN Loss: 4.789424419403076 | CLS Loss: 0.052634526044130325\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 4.862977027893066 | KNN Loss: 4.780383586883545 | CLS Loss: 0.0825936496257782\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 4.766160488128662 | KNN Loss: 4.724906921386719 | CLS Loss: 0.04125354439020157\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 4.746006965637207 | KNN Loss: 4.6978559494018555 | CLS Loss: 0.048151157796382904\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 4.813364505767822 | KNN Loss: 4.744734287261963 | CLS Loss: 0.06863022595643997\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 4.831761360168457 | KNN Loss: 4.776589870452881 | CLS Loss: 0.05517157167196274\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 4.804422378540039 | KNN Loss: 4.769338130950928 | CLS Loss: 0.03508405387401581\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 4.784436225891113 | KNN Loss: 4.736753940582275 | CLS Loss: 0.0476825013756752\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 4.787259578704834 | KNN Loss: 4.751981258392334 | CLS Loss: 0.03527850657701492\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 4.831813812255859 | KNN Loss: 4.7613420486450195 | CLS Loss: 0.07047196477651596\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 4.84207820892334 | KNN Loss: 4.767763137817383 | CLS Loss: 0.07431525737047195\n",
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 4.831007957458496 | KNN Loss: 4.7826104164123535 | CLS Loss: 0.048397552222013474\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 4.771329879760742 | KNN Loss: 4.7264084815979 | CLS Loss: 0.04492123797535896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 4.8884992599487305 | KNN Loss: 4.823034763336182 | CLS Loss: 0.06546467542648315\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 4.751100540161133 | KNN Loss: 4.7270307540893555 | CLS Loss: 0.02406957373023033\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 4.875583171844482 | KNN Loss: 4.772170543670654 | CLS Loss: 0.10341261327266693\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 4.816015720367432 | KNN Loss: 4.763940334320068 | CLS Loss: 0.052075307816267014\n",
      "Epoch: 014, Loss: 4.8055, Train: 0.9863, Valid: 0.9821, Best: 0.9823\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 4.829922199249268 | KNN Loss: 4.766785144805908 | CLS Loss: 0.0631370022892952\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 4.83040189743042 | KNN Loss: 4.762335777282715 | CLS Loss: 0.06806630641222\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 4.758620738983154 | KNN Loss: 4.724384307861328 | CLS Loss: 0.03423648327589035\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 4.8048014640808105 | KNN Loss: 4.754019737243652 | CLS Loss: 0.05078159272670746\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 4.765931606292725 | KNN Loss: 4.720285415649414 | CLS Loss: 0.0456463024020195\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 4.784811496734619 | KNN Loss: 4.73157262802124 | CLS Loss: 0.05323897674679756\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 4.779931545257568 | KNN Loss: 4.745874404907227 | CLS Loss: 0.03405730798840523\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 4.804789066314697 | KNN Loss: 4.755889892578125 | CLS Loss: 0.048899389803409576\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 4.763599395751953 | KNN Loss: 4.727063179016113 | CLS Loss: 0.036536164581775665\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 4.801609039306641 | KNN Loss: 4.7426228523254395 | CLS Loss: 0.058986254036426544\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 4.772863864898682 | KNN Loss: 4.712629318237305 | CLS Loss: 0.06023455038666725\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 4.812943458557129 | KNN Loss: 4.733813762664795 | CLS Loss: 0.07912960648536682\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 4.7678046226501465 | KNN Loss: 4.715749740600586 | CLS Loss: 0.05205467715859413\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 4.83805513381958 | KNN Loss: 4.74169397354126 | CLS Loss: 0.09636115282773972\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 4.8074798583984375 | KNN Loss: 4.766173362731934 | CLS Loss: 0.04130645468831062\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 4.78163480758667 | KNN Loss: 4.726383686065674 | CLS Loss: 0.05525113269686699\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 4.769895553588867 | KNN Loss: 4.738239765167236 | CLS Loss: 0.031655680388212204\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 4.757384777069092 | KNN Loss: 4.70888090133667 | CLS Loss: 0.048503853380680084\n",
      "Epoch: 015, Loss: 4.7992, Train: 0.9853, Valid: 0.9811, Best: 0.9823\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 4.823910236358643 | KNN Loss: 4.778371334075928 | CLS Loss: 0.045538995414972305\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 4.8095221519470215 | KNN Loss: 4.7442545890808105 | CLS Loss: 0.0652674213051796\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 4.814370632171631 | KNN Loss: 4.774990081787109 | CLS Loss: 0.0393805094063282\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 4.80526065826416 | KNN Loss: 4.72763204574585 | CLS Loss: 0.07762842625379562\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 4.7902703285217285 | KNN Loss: 4.713447570800781 | CLS Loss: 0.0768226906657219\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 4.773434638977051 | KNN Loss: 4.705408573150635 | CLS Loss: 0.06802590936422348\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 4.7868828773498535 | KNN Loss: 4.750214099884033 | CLS Loss: 0.03666882961988449\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 4.80339241027832 | KNN Loss: 4.7461161613464355 | CLS Loss: 0.05727604404091835\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 4.893996715545654 | KNN Loss: 4.769287109375 | CLS Loss: 0.12470939010381699\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 4.769758224487305 | KNN Loss: 4.739800453186035 | CLS Loss: 0.02995775267481804\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 4.784629821777344 | KNN Loss: 4.737162113189697 | CLS Loss: 0.04746747761964798\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 4.733615398406982 | KNN Loss: 4.709226131439209 | CLS Loss: 0.02438947558403015\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 4.761753559112549 | KNN Loss: 4.729470729827881 | CLS Loss: 0.03228267654776573\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 4.7633376121521 | KNN Loss: 4.730112075805664 | CLS Loss: 0.03322537988424301\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 4.851358413696289 | KNN Loss: 4.796779632568359 | CLS Loss: 0.05457896366715431\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 4.789356231689453 | KNN Loss: 4.719977378845215 | CLS Loss: 0.06937886774539948\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 4.770110130310059 | KNN Loss: 4.7198286056518555 | CLS Loss: 0.050281550735235214\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 4.773416519165039 | KNN Loss: 4.7502899169921875 | CLS Loss: 0.023126766085624695\n",
      "Epoch: 016, Loss: 4.7939, Train: 0.9870, Valid: 0.9827, Best: 0.9827\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 4.761082649230957 | KNN Loss: 4.722342491149902 | CLS Loss: 0.03874015063047409\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 4.770927429199219 | KNN Loss: 4.718772888183594 | CLS Loss: 0.05215448886156082\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 4.84399938583374 | KNN Loss: 4.761257171630859 | CLS Loss: 0.08274201303720474\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 4.762173175811768 | KNN Loss: 4.734613418579102 | CLS Loss: 0.027559947222471237\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 4.821740627288818 | KNN Loss: 4.751175880432129 | CLS Loss: 0.07056465744972229\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 4.807553291320801 | KNN Loss: 4.746356964111328 | CLS Loss: 0.0611964650452137\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 4.827611923217773 | KNN Loss: 4.789360523223877 | CLS Loss: 0.03825124725699425\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 4.846250534057617 | KNN Loss: 4.763084888458252 | CLS Loss: 0.08316554874181747\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 4.783812522888184 | KNN Loss: 4.743356227874756 | CLS Loss: 0.0404561385512352\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 4.7942585945129395 | KNN Loss: 4.733145713806152 | CLS Loss: 0.0611129105091095\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 4.788968086242676 | KNN Loss: 4.73414421081543 | CLS Loss: 0.05482405424118042\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 4.773097515106201 | KNN Loss: 4.733463287353516 | CLS Loss: 0.03963445499539375\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 4.9333648681640625 | KNN Loss: 4.849260330200195 | CLS Loss: 0.08410438895225525\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 4.780066013336182 | KNN Loss: 4.764946937561035 | CLS Loss: 0.015119018964469433\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 4.776366710662842 | KNN Loss: 4.752856254577637 | CLS Loss: 0.023510396480560303\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 4.741156101226807 | KNN Loss: 4.710692882537842 | CLS Loss: 0.03046322800219059\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 4.798142433166504 | KNN Loss: 4.738669395446777 | CLS Loss: 0.05947315692901611\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 4.831974029541016 | KNN Loss: 4.764561653137207 | CLS Loss: 0.06741244345903397\n",
      "Epoch: 017, Loss: 4.7934, Train: 0.9881, Valid: 0.9836, Best: 0.9836\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 4.843808174133301 | KNN Loss: 4.7707319259643555 | CLS Loss: 0.0730762705206871\n",
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 4.7093825340271 | KNN Loss: 4.684576034545898 | CLS Loss: 0.024806544184684753\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 4.777569770812988 | KNN Loss: 4.752598285675049 | CLS Loss: 0.02497163973748684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 4.717538833618164 | KNN Loss: 4.7014594078063965 | CLS Loss: 0.016079504042863846\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 4.762868404388428 | KNN Loss: 4.719110012054443 | CLS Loss: 0.04375819116830826\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 4.764823913574219 | KNN Loss: 4.723001956939697 | CLS Loss: 0.041822049766778946\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 4.77712345123291 | KNN Loss: 4.742673873901367 | CLS Loss: 0.034449636936187744\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 4.717177867889404 | KNN Loss: 4.703795433044434 | CLS Loss: 0.013382225297391415\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 4.867327690124512 | KNN Loss: 4.793591499328613 | CLS Loss: 0.07373606413602829\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 4.80062198638916 | KNN Loss: 4.72520112991333 | CLS Loss: 0.07542107254266739\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 4.839138031005859 | KNN Loss: 4.759364604949951 | CLS Loss: 0.07977354526519775\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 4.782364368438721 | KNN Loss: 4.728414535522461 | CLS Loss: 0.053949955850839615\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 4.795731544494629 | KNN Loss: 4.725058078765869 | CLS Loss: 0.07067359238862991\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 4.774460792541504 | KNN Loss: 4.749719619750977 | CLS Loss: 0.024740958586335182\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 4.7153143882751465 | KNN Loss: 4.694103240966797 | CLS Loss: 0.02121136710047722\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 4.796212196350098 | KNN Loss: 4.750699520111084 | CLS Loss: 0.04551270604133606\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 4.803028583526611 | KNN Loss: 4.742606163024902 | CLS Loss: 0.06042252108454704\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 4.7423529624938965 | KNN Loss: 4.702575206756592 | CLS Loss: 0.039777759462594986\n",
      "Epoch: 018, Loss: 4.7835, Train: 0.9880, Valid: 0.9829, Best: 0.9836\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 4.769622802734375 | KNN Loss: 4.729321479797363 | CLS Loss: 0.04030117020010948\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 4.761279106140137 | KNN Loss: 4.724217891693115 | CLS Loss: 0.03706108033657074\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 4.7574896812438965 | KNN Loss: 4.727527141571045 | CLS Loss: 0.02996273711323738\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 4.735989570617676 | KNN Loss: 4.723797798156738 | CLS Loss: 0.012191904708743095\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 4.773618698120117 | KNN Loss: 4.750064373016357 | CLS Loss: 0.023554421961307526\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 4.7569355964660645 | KNN Loss: 4.719870567321777 | CLS Loss: 0.03706500306725502\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 4.800137042999268 | KNN Loss: 4.740014553070068 | CLS Loss: 0.060122642666101456\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 4.840116024017334 | KNN Loss: 4.75935173034668 | CLS Loss: 0.08076413720846176\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 4.766648769378662 | KNN Loss: 4.700435161590576 | CLS Loss: 0.06621354818344116\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 4.76810359954834 | KNN Loss: 4.733827114105225 | CLS Loss: 0.034276481717824936\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 4.801337242126465 | KNN Loss: 4.735760688781738 | CLS Loss: 0.06557637453079224\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 4.780158042907715 | KNN Loss: 4.743571758270264 | CLS Loss: 0.036586251109838486\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 4.776536464691162 | KNN Loss: 4.723527431488037 | CLS Loss: 0.05300907418131828\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 4.7619099617004395 | KNN Loss: 4.7010321617126465 | CLS Loss: 0.060877639800310135\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 4.795478820800781 | KNN Loss: 4.728785514831543 | CLS Loss: 0.06669341772794724\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 4.78319787979126 | KNN Loss: 4.707774639129639 | CLS Loss: 0.07542306184768677\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 4.768133640289307 | KNN Loss: 4.729754447937012 | CLS Loss: 0.038379356265068054\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 4.766397476196289 | KNN Loss: 4.728693962097168 | CLS Loss: 0.037703610956668854\n",
      "Epoch: 019, Loss: 4.7749, Train: 0.9892, Valid: 0.9847, Best: 0.9847\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 4.837493419647217 | KNN Loss: 4.782389163970947 | CLS Loss: 0.05510428547859192\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 4.739564418792725 | KNN Loss: 4.715301036834717 | CLS Loss: 0.024263443425297737\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 4.794407367706299 | KNN Loss: 4.738009452819824 | CLS Loss: 0.056397944688797\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 4.792362213134766 | KNN Loss: 4.707601070404053 | CLS Loss: 0.08476117998361588\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 4.8453898429870605 | KNN Loss: 4.794040679931641 | CLS Loss: 0.05134892836213112\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 4.803613185882568 | KNN Loss: 4.762897968292236 | CLS Loss: 0.04071519151329994\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 4.810849189758301 | KNN Loss: 4.766700267791748 | CLS Loss: 0.044148847460746765\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 4.777004718780518 | KNN Loss: 4.726918697357178 | CLS Loss: 0.05008621886372566\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 4.812133312225342 | KNN Loss: 4.761242866516113 | CLS Loss: 0.050890225917100906\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 4.766560077667236 | KNN Loss: 4.7177414894104 | CLS Loss: 0.048818670213222504\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 4.756251335144043 | KNN Loss: 4.715162754058838 | CLS Loss: 0.041088733822107315\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 4.801646709442139 | KNN Loss: 4.7462992668151855 | CLS Loss: 0.055347345769405365\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 4.797175884246826 | KNN Loss: 4.738827705383301 | CLS Loss: 0.05834820494055748\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 4.833871364593506 | KNN Loss: 4.752709865570068 | CLS Loss: 0.0811614915728569\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 4.796712875366211 | KNN Loss: 4.739394187927246 | CLS Loss: 0.05731869116425514\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 4.774600028991699 | KNN Loss: 4.726374626159668 | CLS Loss: 0.0482252798974514\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 4.719070911407471 | KNN Loss: 4.696930408477783 | CLS Loss: 0.02214033715426922\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 4.761263847351074 | KNN Loss: 4.717123031616211 | CLS Loss: 0.044140834361314774\n",
      "Epoch: 020, Loss: 4.7754, Train: 0.9891, Valid: 0.9836, Best: 0.9847\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 4.751210689544678 | KNN Loss: 4.7168288230896 | CLS Loss: 0.034381989389657974\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 4.759020805358887 | KNN Loss: 4.716947078704834 | CLS Loss: 0.042073555290699005\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 4.737485408782959 | KNN Loss: 4.703022003173828 | CLS Loss: 0.034463200718164444\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 4.814602375030518 | KNN Loss: 4.75651741027832 | CLS Loss: 0.05808480829000473\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 4.719127178192139 | KNN Loss: 4.696897029876709 | CLS Loss: 0.02222994528710842\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 4.798401832580566 | KNN Loss: 4.730299949645996 | CLS Loss: 0.0681019276380539\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 4.807254314422607 | KNN Loss: 4.748054504394531 | CLS Loss: 0.0591997466981411\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 4.810505390167236 | KNN Loss: 4.751584053039551 | CLS Loss: 0.05892130360007286\n",
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 4.770514965057373 | KNN Loss: 4.744103908538818 | CLS Loss: 0.026411056518554688\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 4.737468719482422 | KNN Loss: 4.705909252166748 | CLS Loss: 0.03155951574444771\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 4.859955310821533 | KNN Loss: 4.753737449645996 | CLS Loss: 0.10621775686740875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 4.7034010887146 | KNN Loss: 4.688318729400635 | CLS Loss: 0.015082130208611488\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 4.746294021606445 | KNN Loss: 4.710805892944336 | CLS Loss: 0.03548790141940117\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 4.78123664855957 | KNN Loss: 4.729268550872803 | CLS Loss: 0.051968008279800415\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 4.771313667297363 | KNN Loss: 4.721961975097656 | CLS Loss: 0.04935183748602867\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 4.804829120635986 | KNN Loss: 4.735812187194824 | CLS Loss: 0.06901676952838898\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 4.715946197509766 | KNN Loss: 4.691524982452393 | CLS Loss: 0.02442116290330887\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 4.790764331817627 | KNN Loss: 4.752243518829346 | CLS Loss: 0.03852062672376633\n",
      "Epoch: 021, Loss: 4.7665, Train: 0.9877, Valid: 0.9832, Best: 0.9847\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 4.763450622558594 | KNN Loss: 4.725315093994141 | CLS Loss: 0.038135677576065063\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 4.752259254455566 | KNN Loss: 4.709486961364746 | CLS Loss: 0.04277249053120613\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 4.764852523803711 | KNN Loss: 4.732000350952148 | CLS Loss: 0.032852254807949066\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 4.7939581871032715 | KNN Loss: 4.7513909339904785 | CLS Loss: 0.042567070573568344\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 4.787278652191162 | KNN Loss: 4.749056816101074 | CLS Loss: 0.0382218062877655\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 4.780704975128174 | KNN Loss: 4.73511266708374 | CLS Loss: 0.04559225216507912\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 4.773646831512451 | KNN Loss: 4.730322360992432 | CLS Loss: 0.04332434758543968\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 4.78663444519043 | KNN Loss: 4.72597599029541 | CLS Loss: 0.06065848842263222\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 4.762816429138184 | KNN Loss: 4.725180149078369 | CLS Loss: 0.03763650730252266\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 4.722433090209961 | KNN Loss: 4.707620143890381 | CLS Loss: 0.014813168905675411\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 4.814859867095947 | KNN Loss: 4.755479335784912 | CLS Loss: 0.05938059464097023\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 4.766451358795166 | KNN Loss: 4.733943462371826 | CLS Loss: 0.03250806778669357\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 4.775918960571289 | KNN Loss: 4.727985382080078 | CLS Loss: 0.047933708876371384\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 4.737006664276123 | KNN Loss: 4.707167148590088 | CLS Loss: 0.029839517548680305\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 4.786345481872559 | KNN Loss: 4.733828067779541 | CLS Loss: 0.05251730978488922\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 4.768312931060791 | KNN Loss: 4.732237339019775 | CLS Loss: 0.036075521260499954\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 4.804037094116211 | KNN Loss: 4.753857612609863 | CLS Loss: 0.05017959326505661\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 4.762310028076172 | KNN Loss: 4.732369899749756 | CLS Loss: 0.029940202832221985\n",
      "Epoch: 022, Loss: 4.7672, Train: 0.9901, Valid: 0.9843, Best: 0.9847\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 4.775810718536377 | KNN Loss: 4.750168323516846 | CLS Loss: 0.02564230188727379\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 4.7097296714782715 | KNN Loss: 4.660522937774658 | CLS Loss: 0.04920684173703194\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 4.7395830154418945 | KNN Loss: 4.716015815734863 | CLS Loss: 0.023567307740449905\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 4.825191974639893 | KNN Loss: 4.771887302398682 | CLS Loss: 0.05330466479063034\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 4.713202476501465 | KNN Loss: 4.699033737182617 | CLS Loss: 0.01416875422000885\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 4.767559051513672 | KNN Loss: 4.721145153045654 | CLS Loss: 0.046414121985435486\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 4.739710330963135 | KNN Loss: 4.702060699462891 | CLS Loss: 0.037649575620889664\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 4.75181245803833 | KNN Loss: 4.703075885772705 | CLS Loss: 0.04873654618859291\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 4.814244270324707 | KNN Loss: 4.73646354675293 | CLS Loss: 0.07778048515319824\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 4.771664619445801 | KNN Loss: 4.727951526641846 | CLS Loss: 0.04371306300163269\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 4.79665994644165 | KNN Loss: 4.743655681610107 | CLS Loss: 0.05300447344779968\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 4.803248405456543 | KNN Loss: 4.7409987449646 | CLS Loss: 0.06224950775504112\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 4.776224613189697 | KNN Loss: 4.737061500549316 | CLS Loss: 0.039163004606962204\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 4.7462592124938965 | KNN Loss: 4.718384265899658 | CLS Loss: 0.027875173836946487\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 4.73781156539917 | KNN Loss: 4.702195167541504 | CLS Loss: 0.03561617434024811\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 4.800950050354004 | KNN Loss: 4.7286505699157715 | CLS Loss: 0.07229935377836227\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 4.769556045532227 | KNN Loss: 4.718513011932373 | CLS Loss: 0.05104317516088486\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 4.8157806396484375 | KNN Loss: 4.748136520385742 | CLS Loss: 0.06764432787895203\n",
      "Epoch: 023, Loss: 4.7629, Train: 0.9868, Valid: 0.9812, Best: 0.9847\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 4.765528202056885 | KNN Loss: 4.721556186676025 | CLS Loss: 0.04397188499569893\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 4.7594709396362305 | KNN Loss: 4.698963642120361 | CLS Loss: 0.06050752475857735\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 4.716093063354492 | KNN Loss: 4.694860935211182 | CLS Loss: 0.021232308819890022\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 4.760389804840088 | KNN Loss: 4.715903282165527 | CLS Loss: 0.044486500322818756\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 4.71117639541626 | KNN Loss: 4.689752578735352 | CLS Loss: 0.02142401970922947\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 4.781956195831299 | KNN Loss: 4.732792377471924 | CLS Loss: 0.049163997173309326\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 4.729107856750488 | KNN Loss: 4.697232246398926 | CLS Loss: 0.0318756029009819\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 4.737609386444092 | KNN Loss: 4.693927764892578 | CLS Loss: 0.04368168115615845\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 4.763264179229736 | KNN Loss: 4.7342529296875 | CLS Loss: 0.02901102975010872\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 4.7628173828125 | KNN Loss: 4.723453521728516 | CLS Loss: 0.03936377540230751\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 4.728087425231934 | KNN Loss: 4.7004899978637695 | CLS Loss: 0.02759747952222824\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 4.786129951477051 | KNN Loss: 4.77072811126709 | CLS Loss: 0.015401873737573624\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 4.8028244972229 | KNN Loss: 4.762414932250977 | CLS Loss: 0.040409792214632034\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 4.689573764801025 | KNN Loss: 4.670650959014893 | CLS Loss: 0.018922625109553337\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 4.769071102142334 | KNN Loss: 4.725853443145752 | CLS Loss: 0.043217629194259644\n",
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 4.757749557495117 | KNN Loss: 4.707308769226074 | CLS Loss: 0.050440967082977295\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 4.748404026031494 | KNN Loss: 4.690916538238525 | CLS Loss: 0.057487357407808304\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 4.7847089767456055 | KNN Loss: 4.7223639488220215 | CLS Loss: 0.0623449869453907\n",
      "Epoch: 024, Loss: 4.7622, Train: 0.9898, Valid: 0.9844, Best: 0.9847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 4.754667282104492 | KNN Loss: 4.715234279632568 | CLS Loss: 0.03943293169140816\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 4.731079578399658 | KNN Loss: 4.697120666503906 | CLS Loss: 0.03395884856581688\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 4.701995849609375 | KNN Loss: 4.673275947570801 | CLS Loss: 0.028720084577798843\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 4.757462501525879 | KNN Loss: 4.729284286499023 | CLS Loss: 0.0281781367957592\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 4.768881797790527 | KNN Loss: 4.715585708618164 | CLS Loss: 0.05329617112874985\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 4.754007816314697 | KNN Loss: 4.720300674438477 | CLS Loss: 0.033707145601511\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 4.763588905334473 | KNN Loss: 4.693790912628174 | CLS Loss: 0.06979823112487793\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 4.706191539764404 | KNN Loss: 4.67548942565918 | CLS Loss: 0.030701905488967896\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 4.717106819152832 | KNN Loss: 4.694732666015625 | CLS Loss: 0.02237425558269024\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 4.724778652191162 | KNN Loss: 4.686595439910889 | CLS Loss: 0.03818309307098389\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 4.72794771194458 | KNN Loss: 4.707289695739746 | CLS Loss: 0.020658012479543686\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 4.790975570678711 | KNN Loss: 4.753432273864746 | CLS Loss: 0.03754345700144768\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 4.755350589752197 | KNN Loss: 4.708446025848389 | CLS Loss: 0.04690442234277725\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 4.74798059463501 | KNN Loss: 4.705987930297852 | CLS Loss: 0.0419926680624485\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 4.826494216918945 | KNN Loss: 4.756053447723389 | CLS Loss: 0.07044056057929993\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 4.793334007263184 | KNN Loss: 4.734392166137695 | CLS Loss: 0.05894196778535843\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 4.766669273376465 | KNN Loss: 4.689515590667725 | CLS Loss: 0.07715348899364471\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 4.752291679382324 | KNN Loss: 4.721678256988525 | CLS Loss: 0.030613286420702934\n",
      "Epoch: 025, Loss: 4.7557, Train: 0.9898, Valid: 0.9842, Best: 0.9847\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 4.744228363037109 | KNN Loss: 4.7238969802856445 | CLS Loss: 0.02033153548836708\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 4.767977714538574 | KNN Loss: 4.720059394836426 | CLS Loss: 0.04791811481118202\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 4.728960037231445 | KNN Loss: 4.720973968505859 | CLS Loss: 0.007986093871295452\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 4.782684326171875 | KNN Loss: 4.762616157531738 | CLS Loss: 0.0200680959969759\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 4.741621494293213 | KNN Loss: 4.7157883644104 | CLS Loss: 0.02583303488790989\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 4.7092180252075195 | KNN Loss: 4.683895111083984 | CLS Loss: 0.025322696194052696\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 4.723246097564697 | KNN Loss: 4.685787677764893 | CLS Loss: 0.037458449602127075\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 4.7559967041015625 | KNN Loss: 4.712846755981445 | CLS Loss: 0.043150052428245544\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 4.805539608001709 | KNN Loss: 4.74306058883667 | CLS Loss: 0.06247890740633011\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 4.728065490722656 | KNN Loss: 4.6924028396606445 | CLS Loss: 0.035662490874528885\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 4.765267848968506 | KNN Loss: 4.722138404846191 | CLS Loss: 0.04312923178076744\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 4.7495951652526855 | KNN Loss: 4.694537162780762 | CLS Loss: 0.05505819991230965\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 4.826479911804199 | KNN Loss: 4.792306900024414 | CLS Loss: 0.03417319431900978\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 4.7632670402526855 | KNN Loss: 4.731575965881348 | CLS Loss: 0.03169123828411102\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 4.827985763549805 | KNN Loss: 4.795618534088135 | CLS Loss: 0.0323670320212841\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 4.766779899597168 | KNN Loss: 4.739882946014404 | CLS Loss: 0.026896752417087555\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 4.758362770080566 | KNN Loss: 4.727875709533691 | CLS Loss: 0.030486958101391792\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 4.758342742919922 | KNN Loss: 4.728531837463379 | CLS Loss: 0.029811104759573936\n",
      "Epoch: 026, Loss: 4.7569, Train: 0.9906, Valid: 0.9856, Best: 0.9856\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 4.741379737854004 | KNN Loss: 4.7041473388671875 | CLS Loss: 0.037232354283332825\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 4.723352909088135 | KNN Loss: 4.690185546875 | CLS Loss: 0.03316745534539223\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 4.7312421798706055 | KNN Loss: 4.6986165046691895 | CLS Loss: 0.032625485211610794\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 4.761613368988037 | KNN Loss: 4.726799488067627 | CLS Loss: 0.034814029932022095\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 4.710076808929443 | KNN Loss: 4.679886817932129 | CLS Loss: 0.03018995188176632\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 4.761496067047119 | KNN Loss: 4.725798606872559 | CLS Loss: 0.03569752722978592\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 4.690955638885498 | KNN Loss: 4.676576137542725 | CLS Loss: 0.01437963917851448\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 4.713714122772217 | KNN Loss: 4.667734146118164 | CLS Loss: 0.04597991704940796\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 4.703739643096924 | KNN Loss: 4.677273750305176 | CLS Loss: 0.02646571397781372\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 4.780130386352539 | KNN Loss: 4.710842132568359 | CLS Loss: 0.06928806006908417\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 4.782629489898682 | KNN Loss: 4.729433059692383 | CLS Loss: 0.05319643020629883\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 4.741023063659668 | KNN Loss: 4.726795196533203 | CLS Loss: 0.014228006824851036\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 4.733613014221191 | KNN Loss: 4.7040629386901855 | CLS Loss: 0.029549995437264442\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 4.736567497253418 | KNN Loss: 4.706210613250732 | CLS Loss: 0.030356913805007935\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 4.784621238708496 | KNN Loss: 4.735599517822266 | CLS Loss: 0.04902162775397301\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 4.710054397583008 | KNN Loss: 4.692962646484375 | CLS Loss: 0.017091605812311172\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 4.77238655090332 | KNN Loss: 4.733164310455322 | CLS Loss: 0.03922246769070625\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 4.808151721954346 | KNN Loss: 4.743381023406982 | CLS Loss: 0.0647706612944603\n",
      "Epoch: 027, Loss: 4.7516, Train: 0.9906, Valid: 0.9837, Best: 0.9856\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 4.7403411865234375 | KNN Loss: 4.6912665367126465 | CLS Loss: 0.0490746907889843\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 4.791580677032471 | KNN Loss: 4.711911678314209 | CLS Loss: 0.07966922968626022\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 4.799840450286865 | KNN Loss: 4.745523929595947 | CLS Loss: 0.05431660637259483\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 4.7487359046936035 | KNN Loss: 4.694871425628662 | CLS Loss: 0.053864486515522\n",
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 4.686875820159912 | KNN Loss: 4.675652027130127 | CLS Loss: 0.01122379582375288\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 4.7539873123168945 | KNN Loss: 4.721865653991699 | CLS Loss: 0.032121628522872925\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 4.79980993270874 | KNN Loss: 4.75187873840332 | CLS Loss: 0.04793110862374306\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 4.718904972076416 | KNN Loss: 4.697753429412842 | CLS Loss: 0.02115149050951004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 4.859772205352783 | KNN Loss: 4.802390098571777 | CLS Loss: 0.05738217011094093\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 4.7455878257751465 | KNN Loss: 4.7022881507873535 | CLS Loss: 0.04329954832792282\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 4.741067409515381 | KNN Loss: 4.72560453414917 | CLS Loss: 0.015462839975953102\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 4.756267070770264 | KNN Loss: 4.700916290283203 | CLS Loss: 0.05535084381699562\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 4.73722505569458 | KNN Loss: 4.718879699707031 | CLS Loss: 0.018345534801483154\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 4.838357448577881 | KNN Loss: 4.746140480041504 | CLS Loss: 0.09221718460321426\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 4.710324287414551 | KNN Loss: 4.68350887298584 | CLS Loss: 0.026815634220838547\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 4.743510723114014 | KNN Loss: 4.724666595458984 | CLS Loss: 0.018844058737158775\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 4.755232810974121 | KNN Loss: 4.6959404945373535 | CLS Loss: 0.05929245427250862\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 4.708126068115234 | KNN Loss: 4.694153308868408 | CLS Loss: 0.013972798362374306\n",
      "Epoch: 028, Loss: 4.7517, Train: 0.9901, Valid: 0.9837, Best: 0.9856\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 4.713192462921143 | KNN Loss: 4.694439888000488 | CLS Loss: 0.0187528096139431\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 4.748754978179932 | KNN Loss: 4.71230411529541 | CLS Loss: 0.03645102307200432\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 4.764523506164551 | KNN Loss: 4.746736526489258 | CLS Loss: 0.017786959186196327\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 4.774123191833496 | KNN Loss: 4.755860805511475 | CLS Loss: 0.01826249621808529\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 4.733479022979736 | KNN Loss: 4.717065334320068 | CLS Loss: 0.016413554549217224\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 4.706264019012451 | KNN Loss: 4.6600661277771 | CLS Loss: 0.04619782790541649\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 4.764608383178711 | KNN Loss: 4.729843616485596 | CLS Loss: 0.03476492315530777\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 4.74176025390625 | KNN Loss: 4.723217487335205 | CLS Loss: 0.018542567268013954\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 4.7149505615234375 | KNN Loss: 4.694856643676758 | CLS Loss: 0.020093770697712898\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 4.724926471710205 | KNN Loss: 4.6942644119262695 | CLS Loss: 0.030661914497613907\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 4.769538402557373 | KNN Loss: 4.727354526519775 | CLS Loss: 0.04218374192714691\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 4.788585186004639 | KNN Loss: 4.7544779777526855 | CLS Loss: 0.03410715609788895\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 4.720994472503662 | KNN Loss: 4.713539123535156 | CLS Loss: 0.0074551887810230255\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 4.791393756866455 | KNN Loss: 4.722476959228516 | CLS Loss: 0.06891673803329468\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 4.823648929595947 | KNN Loss: 4.779117584228516 | CLS Loss: 0.044531192630529404\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 4.826079368591309 | KNN Loss: 4.7989702224731445 | CLS Loss: 0.027109084650874138\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 4.749273300170898 | KNN Loss: 4.702543258666992 | CLS Loss: 0.046729955822229385\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 4.782886981964111 | KNN Loss: 4.721454620361328 | CLS Loss: 0.06143248453736305\n",
      "Epoch: 029, Loss: 4.7443, Train: 0.9908, Valid: 0.9846, Best: 0.9856\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 4.762290000915527 | KNN Loss: 4.716935157775879 | CLS Loss: 0.04535507410764694\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 4.752788543701172 | KNN Loss: 4.712011337280273 | CLS Loss: 0.04077723249793053\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 4.794676780700684 | KNN Loss: 4.78652286529541 | CLS Loss: 0.008154099807143211\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 4.72951602935791 | KNN Loss: 4.694533348083496 | CLS Loss: 0.03498249873518944\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 4.781287670135498 | KNN Loss: 4.706533908843994 | CLS Loss: 0.07475368678569794\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 4.762585639953613 | KNN Loss: 4.7035393714904785 | CLS Loss: 0.05904609337449074\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 4.735809803009033 | KNN Loss: 4.714658737182617 | CLS Loss: 0.02115093730390072\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 4.696983337402344 | KNN Loss: 4.678947448730469 | CLS Loss: 0.018035706132650375\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 4.758491039276123 | KNN Loss: 4.735428810119629 | CLS Loss: 0.0230620875954628\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 4.806943416595459 | KNN Loss: 4.762808799743652 | CLS Loss: 0.04413475841283798\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 4.709283828735352 | KNN Loss: 4.687351703643799 | CLS Loss: 0.021932119503617287\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 4.7332048416137695 | KNN Loss: 4.704455375671387 | CLS Loss: 0.02874932996928692\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 4.690891265869141 | KNN Loss: 4.664848327636719 | CLS Loss: 0.02604280598461628\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 4.7703657150268555 | KNN Loss: 4.728712558746338 | CLS Loss: 0.04165302962064743\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 4.749520778656006 | KNN Loss: 4.734251022338867 | CLS Loss: 0.01526954397559166\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 4.754807472229004 | KNN Loss: 4.718997478485107 | CLS Loss: 0.03580998629331589\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 4.695611000061035 | KNN Loss: 4.681145191192627 | CLS Loss: 0.014465630985796452\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 4.734219551086426 | KNN Loss: 4.6926069259643555 | CLS Loss: 0.04161269962787628\n",
      "Epoch: 030, Loss: 4.7493, Train: 0.9907, Valid: 0.9848, Best: 0.9856\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 4.68656063079834 | KNN Loss: 4.652558326721191 | CLS Loss: 0.03400232270359993\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 4.763659477233887 | KNN Loss: 4.7166523933410645 | CLS Loss: 0.04700730741024017\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 4.7942423820495605 | KNN Loss: 4.746001720428467 | CLS Loss: 0.04824060946702957\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 4.745514869689941 | KNN Loss: 4.708650588989258 | CLS Loss: 0.03686405345797539\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 4.70461368560791 | KNN Loss: 4.673931121826172 | CLS Loss: 0.030682455748319626\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 4.721229553222656 | KNN Loss: 4.700547218322754 | CLS Loss: 0.020682334899902344\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 4.738848686218262 | KNN Loss: 4.728003025054932 | CLS Loss: 0.01084547583013773\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 4.721798896789551 | KNN Loss: 4.702040672302246 | CLS Loss: 0.019758306443691254\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 4.732571125030518 | KNN Loss: 4.709878921508789 | CLS Loss: 0.022692246362566948\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 4.7388458251953125 | KNN Loss: 4.695910453796387 | CLS Loss: 0.04293540492653847\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 4.711185932159424 | KNN Loss: 4.687079429626465 | CLS Loss: 0.024106530472636223\n",
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 4.798901081085205 | KNN Loss: 4.766656875610352 | CLS Loss: 0.03224434703588486\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 4.729733467102051 | KNN Loss: 4.713211536407471 | CLS Loss: 0.016521785408258438\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 4.736818313598633 | KNN Loss: 4.710860252380371 | CLS Loss: 0.025957943871617317\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 4.749373435974121 | KNN Loss: 4.70487642288208 | CLS Loss: 0.04449684917926788\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 4.679978370666504 | KNN Loss: 4.663247585296631 | CLS Loss: 0.016730686649680138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 4.731513977050781 | KNN Loss: 4.692133903503418 | CLS Loss: 0.03937986493110657\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 4.703509330749512 | KNN Loss: 4.666195392608643 | CLS Loss: 0.03731381520628929\n",
      "Epoch: 031, Loss: 4.7367, Train: 0.9928, Valid: 0.9853, Best: 0.9856\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 4.7314252853393555 | KNN Loss: 4.713092803955078 | CLS Loss: 0.01833263225853443\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 4.675447463989258 | KNN Loss: 4.643362045288086 | CLS Loss: 0.032085493206977844\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 4.740655899047852 | KNN Loss: 4.719870567321777 | CLS Loss: 0.02078537829220295\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 4.726932525634766 | KNN Loss: 4.716751575469971 | CLS Loss: 0.010180879384279251\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 4.781632423400879 | KNN Loss: 4.747108459472656 | CLS Loss: 0.034523993730545044\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 4.670711040496826 | KNN Loss: 4.648553848266602 | CLS Loss: 0.022157087922096252\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 4.7705864906311035 | KNN Loss: 4.7267961502075195 | CLS Loss: 0.043790336698293686\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 4.732305526733398 | KNN Loss: 4.724984169006348 | CLS Loss: 0.007321461569517851\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 4.718992710113525 | KNN Loss: 4.699202060699463 | CLS Loss: 0.019790465012192726\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 4.704161643981934 | KNN Loss: 4.676816463470459 | CLS Loss: 0.027345120906829834\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 4.727126598358154 | KNN Loss: 4.700671195983887 | CLS Loss: 0.02645524963736534\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 4.747355937957764 | KNN Loss: 4.729626655578613 | CLS Loss: 0.017729513347148895\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 4.746425628662109 | KNN Loss: 4.724721431732178 | CLS Loss: 0.02170407399535179\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 4.712686538696289 | KNN Loss: 4.689923286437988 | CLS Loss: 0.022763343527913094\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 4.6714582443237305 | KNN Loss: 4.664822578430176 | CLS Loss: 0.006635868921875954\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 4.771209716796875 | KNN Loss: 4.726524829864502 | CLS Loss: 0.04468502476811409\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 4.725986003875732 | KNN Loss: 4.68839168548584 | CLS Loss: 0.03759424015879631\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 4.750478744506836 | KNN Loss: 4.725578308105469 | CLS Loss: 0.024900490418076515\n",
      "Epoch: 032, Loss: 4.7414, Train: 0.9923, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 4.789067268371582 | KNN Loss: 4.753346920013428 | CLS Loss: 0.03572052717208862\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 4.761159420013428 | KNN Loss: 4.725569248199463 | CLS Loss: 0.03559039160609245\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 4.7045488357543945 | KNN Loss: 4.681197643280029 | CLS Loss: 0.023351270705461502\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 4.730699062347412 | KNN Loss: 4.715024471282959 | CLS Loss: 0.015674443915486336\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 4.7529706954956055 | KNN Loss: 4.72544527053833 | CLS Loss: 0.027525519952178\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 4.716775417327881 | KNN Loss: 4.706178665161133 | CLS Loss: 0.010596523061394691\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 4.766329288482666 | KNN Loss: 4.705480098724365 | CLS Loss: 0.06084909662604332\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 4.773503303527832 | KNN Loss: 4.745136260986328 | CLS Loss: 0.028367001563310623\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 4.721770763397217 | KNN Loss: 4.711429119110107 | CLS Loss: 0.010341624729335308\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 4.818904399871826 | KNN Loss: 4.777700901031494 | CLS Loss: 0.04120349511504173\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 4.747002124786377 | KNN Loss: 4.711846351623535 | CLS Loss: 0.03515598922967911\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 4.833418846130371 | KNN Loss: 4.805778503417969 | CLS Loss: 0.02764047682285309\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 4.767958164215088 | KNN Loss: 4.7244110107421875 | CLS Loss: 0.04354706034064293\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 4.683925628662109 | KNN Loss: 4.656755447387695 | CLS Loss: 0.02717033214867115\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 4.793965816497803 | KNN Loss: 4.736000061035156 | CLS Loss: 0.05796573683619499\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 4.7291412353515625 | KNN Loss: 4.694319248199463 | CLS Loss: 0.034822169691324234\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 4.706236362457275 | KNN Loss: 4.684469223022461 | CLS Loss: 0.021767225116491318\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 4.700190544128418 | KNN Loss: 4.6737189292907715 | CLS Loss: 0.026471704244613647\n",
      "Epoch: 033, Loss: 4.7427, Train: 0.9917, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 4.723921775817871 | KNN Loss: 4.6945881843566895 | CLS Loss: 0.029333554208278656\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 4.675253391265869 | KNN Loss: 4.646800518035889 | CLS Loss: 0.028453057631850243\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 4.772353649139404 | KNN Loss: 4.745043754577637 | CLS Loss: 0.027309659868478775\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 4.702202796936035 | KNN Loss: 4.681929588317871 | CLS Loss: 0.020273275673389435\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 4.74277400970459 | KNN Loss: 4.703882694244385 | CLS Loss: 0.038891229778528214\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 4.792792797088623 | KNN Loss: 4.748067378997803 | CLS Loss: 0.04472559317946434\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 4.706974983215332 | KNN Loss: 4.69128942489624 | CLS Loss: 0.015685701742768288\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 4.733809471130371 | KNN Loss: 4.699511528015137 | CLS Loss: 0.0342981219291687\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 4.728267669677734 | KNN Loss: 4.692457675933838 | CLS Loss: 0.03581000119447708\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 4.743269920349121 | KNN Loss: 4.706167221069336 | CLS Loss: 0.037102531641721725\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 4.715437889099121 | KNN Loss: 4.695991516113281 | CLS Loss: 0.01944626495242119\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 4.76854944229126 | KNN Loss: 4.730165958404541 | CLS Loss: 0.03838329762220383\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 4.683980941772461 | KNN Loss: 4.669208526611328 | CLS Loss: 0.014772549271583557\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 4.732650279998779 | KNN Loss: 4.711733341217041 | CLS Loss: 0.020917167887091637\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 4.751317501068115 | KNN Loss: 4.714656352996826 | CLS Loss: 0.03666131943464279\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 4.685605525970459 | KNN Loss: 4.663778781890869 | CLS Loss: 0.02182682789862156\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 4.713070392608643 | KNN Loss: 4.68459415435791 | CLS Loss: 0.028476286679506302\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 4.683553218841553 | KNN Loss: 4.654911994934082 | CLS Loss: 0.028641289100050926\n",
      "Epoch: 034, Loss: 4.7318, Train: 0.9930, Valid: 0.9862, Best: 0.9862\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 4.723892688751221 | KNN Loss: 4.706485271453857 | CLS Loss: 0.01740749552845955\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 4.748767852783203 | KNN Loss: 4.7176923751831055 | CLS Loss: 0.031075555831193924\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 4.722517490386963 | KNN Loss: 4.697510242462158 | CLS Loss: 0.025007082149386406\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 4.702811241149902 | KNN Loss: 4.685525417327881 | CLS Loss: 0.017285767942667007\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 4.720386028289795 | KNN Loss: 4.695842742919922 | CLS Loss: 0.024543464183807373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 4.781567096710205 | KNN Loss: 4.727852821350098 | CLS Loss: 0.05371406674385071\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 4.851928234100342 | KNN Loss: 4.803271293640137 | CLS Loss: 0.048656996339559555\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 4.7483696937561035 | KNN Loss: 4.708577632904053 | CLS Loss: 0.0397920198738575\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 4.737277030944824 | KNN Loss: 4.700249671936035 | CLS Loss: 0.03702755644917488\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 4.757837295532227 | KNN Loss: 4.730257987976074 | CLS Loss: 0.027579303830862045\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 4.810493469238281 | KNN Loss: 4.756618976593018 | CLS Loss: 0.05387434735894203\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 4.75885009765625 | KNN Loss: 4.732407093048096 | CLS Loss: 0.026443004608154297\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 4.802587985992432 | KNN Loss: 4.77060079574585 | CLS Loss: 0.031987424939870834\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 4.739650249481201 | KNN Loss: 4.722313404083252 | CLS Loss: 0.017337027937173843\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 4.75581693649292 | KNN Loss: 4.734356880187988 | CLS Loss: 0.02146020345389843\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 4.701559066772461 | KNN Loss: 4.680663585662842 | CLS Loss: 0.02089548669755459\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 4.732674598693848 | KNN Loss: 4.703355312347412 | CLS Loss: 0.02931920252740383\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 4.726238250732422 | KNN Loss: 4.700718879699707 | CLS Loss: 0.025519564747810364\n",
      "Epoch: 035, Loss: 4.7481, Train: 0.9937, Valid: 0.9863, Best: 0.9863\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 4.723644256591797 | KNN Loss: 4.69418478012085 | CLS Loss: 0.029459429904818535\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 4.799751281738281 | KNN Loss: 4.732458591461182 | CLS Loss: 0.06729255616664886\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 4.7702460289001465 | KNN Loss: 4.738157749176025 | CLS Loss: 0.03208821639418602\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 4.735080718994141 | KNN Loss: 4.718369483947754 | CLS Loss: 0.016711242496967316\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 4.730763912200928 | KNN Loss: 4.7033820152282715 | CLS Loss: 0.02738184481859207\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 4.753875732421875 | KNN Loss: 4.728244304656982 | CLS Loss: 0.025631392374634743\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 4.771672248840332 | KNN Loss: 4.742110252380371 | CLS Loss: 0.029562126845121384\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 4.7188720703125 | KNN Loss: 4.688073635101318 | CLS Loss: 0.03079822100698948\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 4.772439002990723 | KNN Loss: 4.732842922210693 | CLS Loss: 0.03959599882364273\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 4.767874240875244 | KNN Loss: 4.722629070281982 | CLS Loss: 0.04524535685777664\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 4.744797706604004 | KNN Loss: 4.730063438415527 | CLS Loss: 0.01473439484834671\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 4.729743957519531 | KNN Loss: 4.707256317138672 | CLS Loss: 0.02248765528202057\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 4.768492221832275 | KNN Loss: 4.744262218475342 | CLS Loss: 0.02422979846596718\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 4.743485450744629 | KNN Loss: 4.717972278594971 | CLS Loss: 0.02551308088004589\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 4.7612223625183105 | KNN Loss: 4.715909004211426 | CLS Loss: 0.045313574373722076\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 4.816521644592285 | KNN Loss: 4.7902960777282715 | CLS Loss: 0.026225781068205833\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 4.777543544769287 | KNN Loss: 4.734357833862305 | CLS Loss: 0.043185535818338394\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 4.760209560394287 | KNN Loss: 4.733950614929199 | CLS Loss: 0.026258792728185654\n",
      "Epoch: 036, Loss: 4.7472, Train: 0.9926, Valid: 0.9852, Best: 0.9863\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 4.716813087463379 | KNN Loss: 4.704124450683594 | CLS Loss: 0.01268839929252863\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 4.724944591522217 | KNN Loss: 4.717241287231445 | CLS Loss: 0.007703512907028198\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 4.692656993865967 | KNN Loss: 4.673597812652588 | CLS Loss: 0.019059211015701294\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 4.809347152709961 | KNN Loss: 4.755234718322754 | CLS Loss: 0.05411257594823837\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 4.793245315551758 | KNN Loss: 4.757053375244141 | CLS Loss: 0.0361919030547142\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 4.7178449630737305 | KNN Loss: 4.704554557800293 | CLS Loss: 0.013290641829371452\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 4.767520427703857 | KNN Loss: 4.736780643463135 | CLS Loss: 0.03073984384536743\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 4.759016990661621 | KNN Loss: 4.728222370147705 | CLS Loss: 0.030794726684689522\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 4.722635746002197 | KNN Loss: 4.711744785308838 | CLS Loss: 0.010890831239521503\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 4.7493438720703125 | KNN Loss: 4.680581569671631 | CLS Loss: 0.06876242160797119\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 4.736114501953125 | KNN Loss: 4.701945781707764 | CLS Loss: 0.03416867554187775\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 4.779794692993164 | KNN Loss: 4.730654716491699 | CLS Loss: 0.04914012551307678\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 4.745161533355713 | KNN Loss: 4.718764781951904 | CLS Loss: 0.02639657072722912\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 4.788266658782959 | KNN Loss: 4.728428363800049 | CLS Loss: 0.0598384365439415\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 4.778532981872559 | KNN Loss: 4.706015110015869 | CLS Loss: 0.0725177526473999\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 4.732960224151611 | KNN Loss: 4.720953941345215 | CLS Loss: 0.012006424367427826\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 4.778767108917236 | KNN Loss: 4.742332935333252 | CLS Loss: 0.036433953791856766\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 4.764412879943848 | KNN Loss: 4.719939708709717 | CLS Loss: 0.044473275542259216\n",
      "Epoch: 037, Loss: 4.7498, Train: 0.9919, Valid: 0.9845, Best: 0.9863\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 4.736563205718994 | KNN Loss: 4.695852279663086 | CLS Loss: 0.040711089968681335\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 4.691211223602295 | KNN Loss: 4.677934169769287 | CLS Loss: 0.013276846148073673\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 4.773271083831787 | KNN Loss: 4.732842445373535 | CLS Loss: 0.04042869061231613\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 4.720788955688477 | KNN Loss: 4.703298091888428 | CLS Loss: 0.017490843310952187\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 4.795213222503662 | KNN Loss: 4.768715858459473 | CLS Loss: 0.02649715356528759\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 4.763326168060303 | KNN Loss: 4.734428405761719 | CLS Loss: 0.028897607699036598\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 4.76128625869751 | KNN Loss: 4.720089435577393 | CLS Loss: 0.04119697958230972\n",
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 4.691551685333252 | KNN Loss: 4.6833720207214355 | CLS Loss: 0.008179448544979095\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 4.7368950843811035 | KNN Loss: 4.721000671386719 | CLS Loss: 0.01589426025748253\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 4.752206325531006 | KNN Loss: 4.741166591644287 | CLS Loss: 0.011039860546588898\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 4.779274940490723 | KNN Loss: 4.731921672821045 | CLS Loss: 0.04735337570309639\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 4.768033981323242 | KNN Loss: 4.735139846801758 | CLS Loss: 0.03289402276277542\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 4.702540397644043 | KNN Loss: 4.697048664093018 | CLS Loss: 0.0054918136447668076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 4.75571870803833 | KNN Loss: 4.711143970489502 | CLS Loss: 0.04457465559244156\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 4.776109218597412 | KNN Loss: 4.75214958190918 | CLS Loss: 0.023959530517458916\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 4.726465225219727 | KNN Loss: 4.706407070159912 | CLS Loss: 0.020058222115039825\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 4.7585344314575195 | KNN Loss: 4.743497371673584 | CLS Loss: 0.01503690704703331\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 4.750986099243164 | KNN Loss: 4.710392951965332 | CLS Loss: 0.04059309884905815\n",
      "Epoch: 038, Loss: 4.7457, Train: 0.9920, Valid: 0.9856, Best: 0.9863\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 4.717318058013916 | KNN Loss: 4.703307151794434 | CLS Loss: 0.014010962098836899\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 4.743936061859131 | KNN Loss: 4.710650444030762 | CLS Loss: 0.03328558802604675\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 4.781208038330078 | KNN Loss: 4.756537437438965 | CLS Loss: 0.02467079646885395\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 4.763457298278809 | KNN Loss: 4.73524284362793 | CLS Loss: 0.028214244171977043\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 4.739419460296631 | KNN Loss: 4.724748134613037 | CLS Loss: 0.014671221375465393\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 4.734675407409668 | KNN Loss: 4.7052483558654785 | CLS Loss: 0.029426859691739082\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 4.718444347381592 | KNN Loss: 4.699056148529053 | CLS Loss: 0.01938808523118496\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 4.743731498718262 | KNN Loss: 4.706306457519531 | CLS Loss: 0.03742501884698868\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 4.701125621795654 | KNN Loss: 4.690573692321777 | CLS Loss: 0.010551749728620052\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 4.725961685180664 | KNN Loss: 4.697900772094727 | CLS Loss: 0.028061149641871452\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 4.737179756164551 | KNN Loss: 4.706648826599121 | CLS Loss: 0.0305311419069767\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 4.741933345794678 | KNN Loss: 4.721347332000732 | CLS Loss: 0.020586160942912102\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 4.7602128982543945 | KNN Loss: 4.730983257293701 | CLS Loss: 0.02922971174120903\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 4.799461841583252 | KNN Loss: 4.754986763000488 | CLS Loss: 0.0444752536714077\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 4.771212100982666 | KNN Loss: 4.746294975280762 | CLS Loss: 0.024916889145970345\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 4.731167316436768 | KNN Loss: 4.70850133895874 | CLS Loss: 0.022665763273835182\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 4.766330718994141 | KNN Loss: 4.736541748046875 | CLS Loss: 0.029789067804813385\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 4.747076034545898 | KNN Loss: 4.710421562194824 | CLS Loss: 0.0366545207798481\n",
      "Epoch: 039, Loss: 4.7439, Train: 0.9927, Valid: 0.9849, Best: 0.9863\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 4.695588111877441 | KNN Loss: 4.665978908538818 | CLS Loss: 0.029609017074108124\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 4.704439640045166 | KNN Loss: 4.6839094161987305 | CLS Loss: 0.0205300971865654\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 4.741901397705078 | KNN Loss: 4.710995197296143 | CLS Loss: 0.03090628609061241\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 4.756962299346924 | KNN Loss: 4.712820529937744 | CLS Loss: 0.04414171725511551\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 4.720543384552002 | KNN Loss: 4.683255672454834 | CLS Loss: 0.037287481129169464\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 4.778294563293457 | KNN Loss: 4.747050762176514 | CLS Loss: 0.031243860721588135\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 4.738857269287109 | KNN Loss: 4.689797401428223 | CLS Loss: 0.04905969649553299\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 4.697685718536377 | KNN Loss: 4.683839797973633 | CLS Loss: 0.013845743611454964\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 4.725044250488281 | KNN Loss: 4.709128379821777 | CLS Loss: 0.01591595448553562\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 4.770014762878418 | KNN Loss: 4.739863395690918 | CLS Loss: 0.03015156276524067\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 4.772128105163574 | KNN Loss: 4.735371112823486 | CLS Loss: 0.03675694763660431\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 4.792482376098633 | KNN Loss: 4.753735065460205 | CLS Loss: 0.03874749690294266\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 4.796034336090088 | KNN Loss: 4.729533672332764 | CLS Loss: 0.06650051474571228\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 4.755364894866943 | KNN Loss: 4.734692573547363 | CLS Loss: 0.020672207698225975\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 4.72997522354126 | KNN Loss: 4.716939449310303 | CLS Loss: 0.01303600613027811\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 4.71008825302124 | KNN Loss: 4.682819366455078 | CLS Loss: 0.02726869285106659\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 4.763445854187012 | KNN Loss: 4.7105865478515625 | CLS Loss: 0.05285950005054474\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 4.77994966506958 | KNN Loss: 4.736462593078613 | CLS Loss: 0.04348698630928993\n",
      "Epoch: 040, Loss: 4.7468, Train: 0.9913, Valid: 0.9831, Best: 0.9863\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 4.763955593109131 | KNN Loss: 4.724152565002441 | CLS Loss: 0.039802804589271545\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 4.866177558898926 | KNN Loss: 4.835412979125977 | CLS Loss: 0.030764801427721977\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 4.703333377838135 | KNN Loss: 4.681940078735352 | CLS Loss: 0.021393368020653725\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 4.742330074310303 | KNN Loss: 4.708583354949951 | CLS Loss: 0.03374660387635231\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 4.74015998840332 | KNN Loss: 4.717413425445557 | CLS Loss: 0.022746730595827103\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 4.695925712585449 | KNN Loss: 4.679844379425049 | CLS Loss: 0.01608145795762539\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 4.73641300201416 | KNN Loss: 4.711599826812744 | CLS Loss: 0.024813098832964897\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 4.80203104019165 | KNN Loss: 4.7937421798706055 | CLS Loss: 0.008288626559078693\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 4.741755962371826 | KNN Loss: 4.705886363983154 | CLS Loss: 0.03586971387267113\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 4.754037857055664 | KNN Loss: 4.732342720031738 | CLS Loss: 0.021695297211408615\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 4.80128812789917 | KNN Loss: 4.775805473327637 | CLS Loss: 0.02548271417617798\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 4.725674152374268 | KNN Loss: 4.70500373840332 | CLS Loss: 0.02067042514681816\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 4.779880523681641 | KNN Loss: 4.729104995727539 | CLS Loss: 0.050775740295648575\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 4.785220623016357 | KNN Loss: 4.706593990325928 | CLS Loss: 0.07862671464681625\n",
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 4.721573829650879 | KNN Loss: 4.713054180145264 | CLS Loss: 0.00851966068148613\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 4.828487396240234 | KNN Loss: 4.795816898345947 | CLS Loss: 0.03267054632306099\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 4.737257957458496 | KNN Loss: 4.7246832847595215 | CLS Loss: 0.012574799358844757\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 4.718667030334473 | KNN Loss: 4.704140663146973 | CLS Loss: 0.014526461251080036\n",
      "Epoch: 041, Loss: 4.7433, Train: 0.9925, Valid: 0.9843, Best: 0.9863\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 4.692342758178711 | KNN Loss: 4.678900241851807 | CLS Loss: 0.013442473486065865\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 4.685445785522461 | KNN Loss: 4.6766438484191895 | CLS Loss: 0.008802139200270176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 4.724581241607666 | KNN Loss: 4.7038373947143555 | CLS Loss: 0.020743614062666893\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 4.723586082458496 | KNN Loss: 4.714700698852539 | CLS Loss: 0.008885176852345467\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 4.765615940093994 | KNN Loss: 4.73288631439209 | CLS Loss: 0.03272943198680878\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 4.805850028991699 | KNN Loss: 4.785758018493652 | CLS Loss: 0.020091840997338295\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 4.717689037322998 | KNN Loss: 4.691269874572754 | CLS Loss: 0.026418928056955338\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 4.703210830688477 | KNN Loss: 4.6879119873046875 | CLS Loss: 0.015299065969884396\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 4.703726291656494 | KNN Loss: 4.696319580078125 | CLS Loss: 0.007406489923596382\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 4.725312232971191 | KNN Loss: 4.70334005355835 | CLS Loss: 0.02197205275297165\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 4.721319675445557 | KNN Loss: 4.709272384643555 | CLS Loss: 0.012047279626131058\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 4.733506202697754 | KNN Loss: 4.714982032775879 | CLS Loss: 0.01852428913116455\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 4.789981842041016 | KNN Loss: 4.7552490234375 | CLS Loss: 0.03473261371254921\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 4.70377779006958 | KNN Loss: 4.692114353179932 | CLS Loss: 0.011663408018648624\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 4.705793380737305 | KNN Loss: 4.684340476989746 | CLS Loss: 0.02145290933549404\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 4.732371807098389 | KNN Loss: 4.719042778015137 | CLS Loss: 0.013329015113413334\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 4.724216461181641 | KNN Loss: 4.705237865447998 | CLS Loss: 0.018978606909513474\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 4.743585109710693 | KNN Loss: 4.721189022064209 | CLS Loss: 0.022396067157387733\n",
      "Epoch: 042, Loss: 4.7377, Train: 0.9939, Valid: 0.9862, Best: 0.9863\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 4.700076580047607 | KNN Loss: 4.6728010177612305 | CLS Loss: 0.027275623753666878\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 4.713962078094482 | KNN Loss: 4.6915998458862305 | CLS Loss: 0.0223622415214777\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 4.720112323760986 | KNN Loss: 4.708941459655762 | CLS Loss: 0.01117105782032013\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 4.696835994720459 | KNN Loss: 4.682403564453125 | CLS Loss: 0.014432468451559544\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 4.716729640960693 | KNN Loss: 4.710453987121582 | CLS Loss: 0.006275424733757973\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 4.730213642120361 | KNN Loss: 4.707704067230225 | CLS Loss: 0.022509625181555748\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 4.786715030670166 | KNN Loss: 4.769341945648193 | CLS Loss: 0.017373237758874893\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 4.744797229766846 | KNN Loss: 4.725656986236572 | CLS Loss: 0.019140038639307022\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 4.772891044616699 | KNN Loss: 4.756561756134033 | CLS Loss: 0.016329314559698105\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 4.74699592590332 | KNN Loss: 4.715949058532715 | CLS Loss: 0.03104706108570099\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 4.723451614379883 | KNN Loss: 4.698429107666016 | CLS Loss: 0.025022385641932487\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 4.701479434967041 | KNN Loss: 4.690212726593018 | CLS Loss: 0.011266849003732204\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 4.785900592803955 | KNN Loss: 4.771064758300781 | CLS Loss: 0.014835825189948082\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 4.728922367095947 | KNN Loss: 4.694246292114258 | CLS Loss: 0.034676216542720795\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 4.78533411026001 | KNN Loss: 4.753432273864746 | CLS Loss: 0.03190206363797188\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 4.7705183029174805 | KNN Loss: 4.730625629425049 | CLS Loss: 0.039892468601465225\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 4.710811614990234 | KNN Loss: 4.695417881011963 | CLS Loss: 0.015393507666885853\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 4.73307466506958 | KNN Loss: 4.711466312408447 | CLS Loss: 0.021608127281069756\n",
      "Epoch: 043, Loss: 4.7372, Train: 0.9932, Valid: 0.9861, Best: 0.9863\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 4.7093682289123535 | KNN Loss: 4.695176124572754 | CLS Loss: 0.014191881753504276\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 4.803736686706543 | KNN Loss: 4.783191204071045 | CLS Loss: 0.02054571732878685\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 4.771466255187988 | KNN Loss: 4.763864517211914 | CLS Loss: 0.007601833902299404\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 4.783114910125732 | KNN Loss: 4.754304885864258 | CLS Loss: 0.028810234740376472\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 4.732187271118164 | KNN Loss: 4.726759433746338 | CLS Loss: 0.00542775634676218\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 4.730312824249268 | KNN Loss: 4.699779987335205 | CLS Loss: 0.03053278848528862\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 4.750231742858887 | KNN Loss: 4.728658676147461 | CLS Loss: 0.02157299779355526\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 4.8141703605651855 | KNN Loss: 4.796603202819824 | CLS Loss: 0.017567288130521774\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 4.719271183013916 | KNN Loss: 4.682214736938477 | CLS Loss: 0.03705643117427826\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 4.730025291442871 | KNN Loss: 4.70408296585083 | CLS Loss: 0.025942107662558556\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 4.724143028259277 | KNN Loss: 4.70909309387207 | CLS Loss: 0.015049715526401997\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 4.749075889587402 | KNN Loss: 4.727149963378906 | CLS Loss: 0.02192615531384945\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 4.7252197265625 | KNN Loss: 4.690998077392578 | CLS Loss: 0.03422148898243904\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 4.7024617195129395 | KNN Loss: 4.692266941070557 | CLS Loss: 0.010194698348641396\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 4.746960639953613 | KNN Loss: 4.726072311401367 | CLS Loss: 0.020888492465019226\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 4.706379413604736 | KNN Loss: 4.698342800140381 | CLS Loss: 0.008036457933485508\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 4.696892261505127 | KNN Loss: 4.6887006759643555 | CLS Loss: 0.008191627450287342\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 4.72782564163208 | KNN Loss: 4.704718589782715 | CLS Loss: 0.02310703508555889\n",
      "Epoch: 044, Loss: 4.7401, Train: 0.9941, Valid: 0.9854, Best: 0.9863\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 4.7635297775268555 | KNN Loss: 4.74506950378418 | CLS Loss: 0.018460307270288467\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 4.758406639099121 | KNN Loss: 4.735972881317139 | CLS Loss: 0.022433727979660034\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 4.743275165557861 | KNN Loss: 4.715147972106934 | CLS Loss: 0.028127387166023254\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 4.697700500488281 | KNN Loss: 4.6925153732299805 | CLS Loss: 0.005185259971767664\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 4.771028518676758 | KNN Loss: 4.748816967010498 | CLS Loss: 0.022211523726582527\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 4.705906391143799 | KNN Loss: 4.686444282531738 | CLS Loss: 0.019462037831544876\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 4.705966949462891 | KNN Loss: 4.694277763366699 | CLS Loss: 0.011689064092934132\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 4.694820404052734 | KNN Loss: 4.6768879890441895 | CLS Loss: 0.017932625487446785\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 4.719933032989502 | KNN Loss: 4.713688850402832 | CLS Loss: 0.006244357209652662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 4.71621561050415 | KNN Loss: 4.695929527282715 | CLS Loss: 0.02028621733188629\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 4.752372741699219 | KNN Loss: 4.7263641357421875 | CLS Loss: 0.02600843645632267\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 4.715632915496826 | KNN Loss: 4.686986923217773 | CLS Loss: 0.0286461990326643\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 4.710268497467041 | KNN Loss: 4.689510822296143 | CLS Loss: 0.020757833495736122\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 4.788549900054932 | KNN Loss: 4.731328010559082 | CLS Loss: 0.057221926748752594\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 4.838242530822754 | KNN Loss: 4.782989501953125 | CLS Loss: 0.05525294691324234\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 4.719775676727295 | KNN Loss: 4.714876651763916 | CLS Loss: 0.00489898631349206\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 4.69456672668457 | KNN Loss: 4.682372570037842 | CLS Loss: 0.01219407469034195\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 4.726835250854492 | KNN Loss: 4.711178302764893 | CLS Loss: 0.015657182782888412\n",
      "Epoch: 045, Loss: 4.7382, Train: 0.9925, Valid: 0.9851, Best: 0.9863\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 4.723719120025635 | KNN Loss: 4.7051239013671875 | CLS Loss: 0.018595445901155472\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 4.765195369720459 | KNN Loss: 4.744178295135498 | CLS Loss: 0.021017253398895264\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 4.755464553833008 | KNN Loss: 4.720788955688477 | CLS Loss: 0.034675467759370804\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 4.6893768310546875 | KNN Loss: 4.67530632019043 | CLS Loss: 0.014070478267967701\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 4.710115909576416 | KNN Loss: 4.688929557800293 | CLS Loss: 0.02118612453341484\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 4.733915328979492 | KNN Loss: 4.724215984344482 | CLS Loss: 0.00969925057142973\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 4.722709655761719 | KNN Loss: 4.706312656402588 | CLS Loss: 0.016397152096033096\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 4.701441287994385 | KNN Loss: 4.682788848876953 | CLS Loss: 0.018652653321623802\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 4.736534118652344 | KNN Loss: 4.69548225402832 | CLS Loss: 0.041051749140024185\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 4.8015971183776855 | KNN Loss: 4.755533695220947 | CLS Loss: 0.04606320708990097\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 4.684848785400391 | KNN Loss: 4.681815147399902 | CLS Loss: 0.0030334782786667347\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 4.720362663269043 | KNN Loss: 4.709617614746094 | CLS Loss: 0.010745000094175339\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 4.7264227867126465 | KNN Loss: 4.677359104156494 | CLS Loss: 0.049063850194215775\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 4.724063873291016 | KNN Loss: 4.688050270080566 | CLS Loss: 0.03601355478167534\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 4.728183269500732 | KNN Loss: 4.718841075897217 | CLS Loss: 0.009342188946902752\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 4.771880626678467 | KNN Loss: 4.700494766235352 | CLS Loss: 0.07138579338788986\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 4.790102958679199 | KNN Loss: 4.770199775695801 | CLS Loss: 0.019903289154171944\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 4.707310676574707 | KNN Loss: 4.690727233886719 | CLS Loss: 0.01658320426940918\n",
      "Epoch: 046, Loss: 4.7343, Train: 0.9942, Valid: 0.9865, Best: 0.9865\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 4.716549873352051 | KNN Loss: 4.690153121948242 | CLS Loss: 0.02639668434858322\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 4.728309154510498 | KNN Loss: 4.71314001083374 | CLS Loss: 0.015169155783951283\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 4.709079742431641 | KNN Loss: 4.696970462799072 | CLS Loss: 0.012109492905437946\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 4.731406211853027 | KNN Loss: 4.690430641174316 | CLS Loss: 0.040975481271743774\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 4.690313339233398 | KNN Loss: 4.676215171813965 | CLS Loss: 0.0140983359888196\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 4.707459926605225 | KNN Loss: 4.681052207946777 | CLS Loss: 0.026407714933156967\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 4.682508945465088 | KNN Loss: 4.674343109130859 | CLS Loss: 0.008165644481778145\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 4.712250232696533 | KNN Loss: 4.68159294128418 | CLS Loss: 0.030657095834612846\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 4.730991840362549 | KNN Loss: 4.71309757232666 | CLS Loss: 0.017894359305500984\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 4.767511367797852 | KNN Loss: 4.714512348175049 | CLS Loss: 0.05299893394112587\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 4.764591693878174 | KNN Loss: 4.726391315460205 | CLS Loss: 0.03820057213306427\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 4.701948165893555 | KNN Loss: 4.689863204956055 | CLS Loss: 0.012085182592272758\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 4.779207229614258 | KNN Loss: 4.765718936920166 | CLS Loss: 0.013488258235156536\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 4.746232986450195 | KNN Loss: 4.7117390632629395 | CLS Loss: 0.03449401631951332\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 4.738279342651367 | KNN Loss: 4.699102878570557 | CLS Loss: 0.03917643055319786\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 4.763574600219727 | KNN Loss: 4.735516548156738 | CLS Loss: 0.028058188036084175\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 4.746973514556885 | KNN Loss: 4.739527702331543 | CLS Loss: 0.007445700000971556\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 4.679567813873291 | KNN Loss: 4.662837505340576 | CLS Loss: 0.01673014461994171\n",
      "Epoch: 047, Loss: 4.7288, Train: 0.9938, Valid: 0.9852, Best: 0.9865\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 4.710322380065918 | KNN Loss: 4.686811923980713 | CLS Loss: 0.023510485887527466\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 4.730811595916748 | KNN Loss: 4.716492652893066 | CLS Loss: 0.014318895526230335\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 4.700653553009033 | KNN Loss: 4.6749162673950195 | CLS Loss: 0.02573731355369091\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 4.78158712387085 | KNN Loss: 4.759286403656006 | CLS Loss: 0.0223005972802639\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 4.678828239440918 | KNN Loss: 4.657984256744385 | CLS Loss: 0.02084401249885559\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 4.712702751159668 | KNN Loss: 4.689732074737549 | CLS Loss: 0.02297089993953705\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 4.722195148468018 | KNN Loss: 4.682339668273926 | CLS Loss: 0.039855364710092545\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 4.731011867523193 | KNN Loss: 4.71164083480835 | CLS Loss: 0.019370976835489273\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 4.678299903869629 | KNN Loss: 4.667430400848389 | CLS Loss: 0.010869606398046017\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 4.763463020324707 | KNN Loss: 4.739322185516357 | CLS Loss: 0.024141032248735428\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 4.731925964355469 | KNN Loss: 4.722475051879883 | CLS Loss: 0.009450850076973438\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 4.7865986824035645 | KNN Loss: 4.7562456130981445 | CLS Loss: 0.03035316802561283\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 4.684340476989746 | KNN Loss: 4.677659034729004 | CLS Loss: 0.006681261584162712\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 4.756988048553467 | KNN Loss: 4.722317695617676 | CLS Loss: 0.03467040881514549\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 4.6840033531188965 | KNN Loss: 4.662534713745117 | CLS Loss: 0.02146880514919758\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 4.722480297088623 | KNN Loss: 4.714297771453857 | CLS Loss: 0.008182338438928127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 4.685040473937988 | KNN Loss: 4.676989555358887 | CLS Loss: 0.008050753735005856\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 4.730463981628418 | KNN Loss: 4.701570510864258 | CLS Loss: 0.028893589973449707\n",
      "Epoch: 048, Loss: 4.7216, Train: 0.9951, Valid: 0.9862, Best: 0.9865\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 4.714487075805664 | KNN Loss: 4.700851917266846 | CLS Loss: 0.013635317794978619\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 4.7296833992004395 | KNN Loss: 4.719689846038818 | CLS Loss: 0.009993338957428932\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 4.691746234893799 | KNN Loss: 4.684889316558838 | CLS Loss: 0.006856848485767841\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 4.774263381958008 | KNN Loss: 4.735970497131348 | CLS Loss: 0.038292814046144485\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 4.696545124053955 | KNN Loss: 4.687640190124512 | CLS Loss: 0.008905141614377499\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 4.7320427894592285 | KNN Loss: 4.698465347290039 | CLS Loss: 0.03357731178402901\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 4.747303485870361 | KNN Loss: 4.718368053436279 | CLS Loss: 0.028935614973306656\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 4.718400001525879 | KNN Loss: 4.704552173614502 | CLS Loss: 0.01384793408215046\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 4.735350608825684 | KNN Loss: 4.71627140045166 | CLS Loss: 0.019079167395830154\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 4.7418437004089355 | KNN Loss: 4.710236072540283 | CLS Loss: 0.03160746023058891\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 4.6774516105651855 | KNN Loss: 4.665807723999023 | CLS Loss: 0.011643998324871063\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 4.7574357986450195 | KNN Loss: 4.73923397064209 | CLS Loss: 0.01820169761776924\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 4.707391262054443 | KNN Loss: 4.678051948547363 | CLS Loss: 0.029339497908949852\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 4.741595268249512 | KNN Loss: 4.700978755950928 | CLS Loss: 0.04061655327677727\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 4.71315336227417 | KNN Loss: 4.695813179016113 | CLS Loss: 0.01734030991792679\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 4.7199788093566895 | KNN Loss: 4.6993842124938965 | CLS Loss: 0.020594535395503044\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 4.765216827392578 | KNN Loss: 4.723653316497803 | CLS Loss: 0.041563715785741806\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 4.729865074157715 | KNN Loss: 4.71116304397583 | CLS Loss: 0.018701966851949692\n",
      "Epoch: 049, Loss: 4.7269, Train: 0.9929, Valid: 0.9834, Best: 0.9865\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 4.741178035736084 | KNN Loss: 4.721677303314209 | CLS Loss: 0.01950089819729328\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 4.744195938110352 | KNN Loss: 4.694857120513916 | CLS Loss: 0.04933863878250122\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 4.866939067840576 | KNN Loss: 4.829169273376465 | CLS Loss: 0.03776993602514267\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 4.748309135437012 | KNN Loss: 4.702015399932861 | CLS Loss: 0.046293675899505615\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 4.716132640838623 | KNN Loss: 4.706460475921631 | CLS Loss: 0.009671982377767563\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 4.741061210632324 | KNN Loss: 4.736253261566162 | CLS Loss: 0.004807786084711552\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 4.724414825439453 | KNN Loss: 4.6902642250061035 | CLS Loss: 0.03415060415863991\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 4.743947982788086 | KNN Loss: 4.721914291381836 | CLS Loss: 0.022033581510186195\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 4.764917850494385 | KNN Loss: 4.718312740325928 | CLS Loss: 0.04660521447658539\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 4.752564907073975 | KNN Loss: 4.737879276275635 | CLS Loss: 0.014685639180243015\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 4.8615193367004395 | KNN Loss: 4.803980827331543 | CLS Loss: 0.05753836780786514\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 4.712680339813232 | KNN Loss: 4.680502891540527 | CLS Loss: 0.03217734023928642\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 4.685915946960449 | KNN Loss: 4.676263809204102 | CLS Loss: 0.00965221505612135\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 4.749755382537842 | KNN Loss: 4.731870651245117 | CLS Loss: 0.01788475178182125\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 4.762095928192139 | KNN Loss: 4.741422176361084 | CLS Loss: 0.020673580467700958\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 4.749878406524658 | KNN Loss: 4.70961332321167 | CLS Loss: 0.04026500880718231\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 4.731474876403809 | KNN Loss: 4.6912665367126465 | CLS Loss: 0.04020833969116211\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 4.70913553237915 | KNN Loss: 4.6785054206848145 | CLS Loss: 0.03063025139272213\n",
      "Epoch: 050, Loss: 4.7348, Train: 0.9951, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 4.677786350250244 | KNN Loss: 4.675055503845215 | CLS Loss: 0.0027310492005199194\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 4.705911159515381 | KNN Loss: 4.694725513458252 | CLS Loss: 0.01118586678057909\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 4.65954065322876 | KNN Loss: 4.65600061416626 | CLS Loss: 0.0035400583874434233\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 4.6833815574646 | KNN Loss: 4.674186706542969 | CLS Loss: 0.009194940328598022\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 4.707109451293945 | KNN Loss: 4.698808193206787 | CLS Loss: 0.00830147136002779\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 4.687350749969482 | KNN Loss: 4.662621021270752 | CLS Loss: 0.024729548022150993\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 4.667000770568848 | KNN Loss: 4.66102409362793 | CLS Loss: 0.005976831540465355\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 4.690634727478027 | KNN Loss: 4.6646013259887695 | CLS Loss: 0.026033516973257065\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 4.772242546081543 | KNN Loss: 4.744250774383545 | CLS Loss: 0.027991829439997673\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 4.734653472900391 | KNN Loss: 4.711034774780273 | CLS Loss: 0.023618899285793304\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 4.742151260375977 | KNN Loss: 4.712935924530029 | CLS Loss: 0.02921544760465622\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 4.793857097625732 | KNN Loss: 4.7610554695129395 | CLS Loss: 0.03280169144272804\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 4.709774971008301 | KNN Loss: 4.697097301483154 | CLS Loss: 0.012677858583629131\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 4.691893100738525 | KNN Loss: 4.679202079772949 | CLS Loss: 0.012690841220319271\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 4.785601615905762 | KNN Loss: 4.766555309295654 | CLS Loss: 0.019046414643526077\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 4.718289375305176 | KNN Loss: 4.6916093826293945 | CLS Loss: 0.026679757982492447\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 4.806891441345215 | KNN Loss: 4.7586469650268555 | CLS Loss: 0.04824436455965042\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 4.7499189376831055 | KNN Loss: 4.718686580657959 | CLS Loss: 0.03123229555785656\n",
      "Epoch: 051, Loss: 4.7206, Train: 0.9936, Valid: 0.9856, Best: 0.9866\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 4.736027240753174 | KNN Loss: 4.710147380828857 | CLS Loss: 0.02587989531457424\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 4.685049057006836 | KNN Loss: 4.6707444190979 | CLS Loss: 0.01430447120219469\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 4.695983409881592 | KNN Loss: 4.674644470214844 | CLS Loss: 0.02133895456790924\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 4.6814398765563965 | KNN Loss: 4.673250198364258 | CLS Loss: 0.00818950030952692\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 4.753906726837158 | KNN Loss: 4.7469868659973145 | CLS Loss: 0.006919799838215113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 4.692766189575195 | KNN Loss: 4.681344509124756 | CLS Loss: 0.011421863920986652\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 4.729835510253906 | KNN Loss: 4.671848773956299 | CLS Loss: 0.057986583560705185\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 4.748166084289551 | KNN Loss: 4.743180274963379 | CLS Loss: 0.00498565100133419\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 4.693648338317871 | KNN Loss: 4.673943042755127 | CLS Loss: 0.019705500453710556\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 4.69476318359375 | KNN Loss: 4.68264102935791 | CLS Loss: 0.012122022919356823\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 4.694419860839844 | KNN Loss: 4.678998947143555 | CLS Loss: 0.015420942567288876\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 4.744701385498047 | KNN Loss: 4.728053092956543 | CLS Loss: 0.016648251563310623\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 4.684564590454102 | KNN Loss: 4.67384147644043 | CLS Loss: 0.010723193176090717\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 4.797050476074219 | KNN Loss: 4.778021335601807 | CLS Loss: 0.019028987735509872\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 4.8605427742004395 | KNN Loss: 4.816359996795654 | CLS Loss: 0.04418297857046127\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 4.688598155975342 | KNN Loss: 4.6740031242370605 | CLS Loss: 0.014595099724829197\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 4.69472599029541 | KNN Loss: 4.668163299560547 | CLS Loss: 0.026562560349702835\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 4.721093654632568 | KNN Loss: 4.708086967468262 | CLS Loss: 0.0130066629499197\n",
      "Epoch: 052, Loss: 4.7274, Train: 0.9933, Valid: 0.9865, Best: 0.9866\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 4.683018684387207 | KNN Loss: 4.67549991607666 | CLS Loss: 0.00751889031380415\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 4.740350246429443 | KNN Loss: 4.712823390960693 | CLS Loss: 0.027526844292879105\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 4.708575248718262 | KNN Loss: 4.699800491333008 | CLS Loss: 0.008774837478995323\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 4.735994338989258 | KNN Loss: 4.709802150726318 | CLS Loss: 0.02619202435016632\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 4.670856952667236 | KNN Loss: 4.658355712890625 | CLS Loss: 0.012501196935772896\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 4.736236095428467 | KNN Loss: 4.728597164154053 | CLS Loss: 0.00763904070481658\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 4.677464962005615 | KNN Loss: 4.670312404632568 | CLS Loss: 0.0071526882238686085\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 4.723794460296631 | KNN Loss: 4.678244113922119 | CLS Loss: 0.04555036872625351\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 4.73388147354126 | KNN Loss: 4.717281818389893 | CLS Loss: 0.016599617898464203\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 4.801978588104248 | KNN Loss: 4.773778915405273 | CLS Loss: 0.028199665248394012\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 4.72471809387207 | KNN Loss: 4.7052130699157715 | CLS Loss: 0.01950484700500965\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 4.722012042999268 | KNN Loss: 4.708247661590576 | CLS Loss: 0.013764314353466034\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 4.748405456542969 | KNN Loss: 4.709461212158203 | CLS Loss: 0.0389443002641201\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 4.685701847076416 | KNN Loss: 4.678005218505859 | CLS Loss: 0.0076967878267169\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 4.70474910736084 | KNN Loss: 4.687708854675293 | CLS Loss: 0.017040405422449112\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 4.710079193115234 | KNN Loss: 4.698702335357666 | CLS Loss: 0.01137670036405325\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 4.686891555786133 | KNN Loss: 4.666414737701416 | CLS Loss: 0.020476633682847023\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 4.695365905761719 | KNN Loss: 4.678120136260986 | CLS Loss: 0.017245806753635406\n",
      "Epoch: 053, Loss: 4.7234, Train: 0.9942, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 4.686270236968994 | KNN Loss: 4.680137634277344 | CLS Loss: 0.006132736336439848\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 4.69980525970459 | KNN Loss: 4.690515995025635 | CLS Loss: 0.00928941834717989\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 4.683311939239502 | KNN Loss: 4.679023742675781 | CLS Loss: 0.004288120660930872\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 4.75195837020874 | KNN Loss: 4.736217498779297 | CLS Loss: 0.015740755945444107\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 4.753490924835205 | KNN Loss: 4.712577819824219 | CLS Loss: 0.04091331735253334\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 4.8057475090026855 | KNN Loss: 4.764325141906738 | CLS Loss: 0.041422463953495026\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 4.7145490646362305 | KNN Loss: 4.701277732849121 | CLS Loss: 0.013271237723529339\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 4.713675022125244 | KNN Loss: 4.704034328460693 | CLS Loss: 0.009640751406550407\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 4.728806495666504 | KNN Loss: 4.715924263000488 | CLS Loss: 0.012882210314273834\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 4.672267913818359 | KNN Loss: 4.658040523529053 | CLS Loss: 0.014227211475372314\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 4.744973182678223 | KNN Loss: 4.727137565612793 | CLS Loss: 0.017835451290011406\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 4.6933112144470215 | KNN Loss: 4.677220344543457 | CLS Loss: 0.016091007739305496\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 4.7381978034973145 | KNN Loss: 4.728012561798096 | CLS Loss: 0.01018544938415289\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 4.754082202911377 | KNN Loss: 4.71868371963501 | CLS Loss: 0.03539864346385002\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 4.698270797729492 | KNN Loss: 4.681268215179443 | CLS Loss: 0.017002392560243607\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 4.794547080993652 | KNN Loss: 4.77843713760376 | CLS Loss: 0.016110144555568695\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 4.712355613708496 | KNN Loss: 4.679504871368408 | CLS Loss: 0.03285066783428192\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 4.714212894439697 | KNN Loss: 4.673586368560791 | CLS Loss: 0.040626659989356995\n",
      "Epoch: 054, Loss: 4.7291, Train: 0.9919, Valid: 0.9841, Best: 0.9866\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 4.7562994956970215 | KNN Loss: 4.6972455978393555 | CLS Loss: 0.05905385687947273\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 4.693490982055664 | KNN Loss: 4.688088893890381 | CLS Loss: 0.005402108654379845\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 4.684787750244141 | KNN Loss: 4.680752277374268 | CLS Loss: 0.004035246092826128\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 4.722533702850342 | KNN Loss: 4.700584411621094 | CLS Loss: 0.02194913476705551\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 4.743249416351318 | KNN Loss: 4.702304840087891 | CLS Loss: 0.04094459116458893\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 4.724496364593506 | KNN Loss: 4.713923454284668 | CLS Loss: 0.010572805069386959\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 4.736041069030762 | KNN Loss: 4.7182464599609375 | CLS Loss: 0.01779482141137123\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 4.7127485275268555 | KNN Loss: 4.688248157501221 | CLS Loss: 0.024500418454408646\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 4.715473651885986 | KNN Loss: 4.7009687423706055 | CLS Loss: 0.014504893682897091\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 4.69425630569458 | KNN Loss: 4.658420562744141 | CLS Loss: 0.03583560883998871\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 4.7185587882995605 | KNN Loss: 4.699651718139648 | CLS Loss: 0.01890702359378338\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 4.718313217163086 | KNN Loss: 4.711816310882568 | CLS Loss: 0.006497094873338938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 4.728991508483887 | KNN Loss: 4.7077202796936035 | CLS Loss: 0.021271103993058205\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 4.728135585784912 | KNN Loss: 4.71952486038208 | CLS Loss: 0.008610825054347515\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 4.692447185516357 | KNN Loss: 4.672152996063232 | CLS Loss: 0.020294370129704475\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 4.69741678237915 | KNN Loss: 4.685597896575928 | CLS Loss: 0.01181864831596613\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 4.734898567199707 | KNN Loss: 4.700370788574219 | CLS Loss: 0.0345279797911644\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 4.729795455932617 | KNN Loss: 4.71120023727417 | CLS Loss: 0.018595360219478607\n",
      "Epoch: 055, Loss: 4.7154, Train: 0.9948, Valid: 0.9858, Best: 0.9866\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 4.685880184173584 | KNN Loss: 4.657973766326904 | CLS Loss: 0.027906406670808792\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 4.757310390472412 | KNN Loss: 4.722769260406494 | CLS Loss: 0.03454115614295006\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 4.671789169311523 | KNN Loss: 4.651299953460693 | CLS Loss: 0.020489294081926346\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 4.683227062225342 | KNN Loss: 4.679236888885498 | CLS Loss: 0.0039900015108287334\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 4.7075910568237305 | KNN Loss: 4.678598403930664 | CLS Loss: 0.028992807492613792\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 4.754673957824707 | KNN Loss: 4.7444915771484375 | CLS Loss: 0.010182196274399757\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 4.667595863342285 | KNN Loss: 4.659158229827881 | CLS Loss: 0.008437598124146461\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 4.713281631469727 | KNN Loss: 4.68500280380249 | CLS Loss: 0.028279006481170654\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 4.766574382781982 | KNN Loss: 4.732700824737549 | CLS Loss: 0.03387376293540001\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 4.743345260620117 | KNN Loss: 4.719840049743652 | CLS Loss: 0.023505259305238724\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 4.681737422943115 | KNN Loss: 4.670124053955078 | CLS Loss: 0.011613557115197182\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 4.743921756744385 | KNN Loss: 4.725826263427734 | CLS Loss: 0.0180955920368433\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 4.668262481689453 | KNN Loss: 4.643733978271484 | CLS Loss: 0.02452859841287136\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 4.771226406097412 | KNN Loss: 4.728220462799072 | CLS Loss: 0.043006014078855515\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 4.711293697357178 | KNN Loss: 4.697678565979004 | CLS Loss: 0.013615096919238567\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 4.7087626457214355 | KNN Loss: 4.701067924499512 | CLS Loss: 0.007694521453231573\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 4.719042778015137 | KNN Loss: 4.7081298828125 | CLS Loss: 0.010913126170635223\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 4.674988746643066 | KNN Loss: 4.65767765045166 | CLS Loss: 0.017311325296759605\n",
      "Epoch: 056, Loss: 4.7187, Train: 0.9949, Valid: 0.9858, Best: 0.9866\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 4.723528861999512 | KNN Loss: 4.714315891265869 | CLS Loss: 0.009212850593030453\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 4.727932929992676 | KNN Loss: 4.711886405944824 | CLS Loss: 0.016046572476625443\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 4.696722030639648 | KNN Loss: 4.693595886230469 | CLS Loss: 0.0031260307878255844\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 4.741611480712891 | KNN Loss: 4.7273640632629395 | CLS Loss: 0.014247190207242966\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 4.716540813446045 | KNN Loss: 4.704665184020996 | CLS Loss: 0.011875846423208714\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 4.734480381011963 | KNN Loss: 4.713923931121826 | CLS Loss: 0.020556556060910225\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 4.711689472198486 | KNN Loss: 4.680495262145996 | CLS Loss: 0.03119426593184471\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 4.737159252166748 | KNN Loss: 4.704882621765137 | CLS Loss: 0.032276686280965805\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 4.749061584472656 | KNN Loss: 4.72343111038208 | CLS Loss: 0.02563059702515602\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 4.801267147064209 | KNN Loss: 4.774285316467285 | CLS Loss: 0.026981858536601067\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 4.796252250671387 | KNN Loss: 4.769092559814453 | CLS Loss: 0.027159493416547775\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 4.77895975112915 | KNN Loss: 4.765985012054443 | CLS Loss: 0.012974615208804607\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 4.713338851928711 | KNN Loss: 4.686152935028076 | CLS Loss: 0.027185987681150436\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 4.701352596282959 | KNN Loss: 4.6745710372924805 | CLS Loss: 0.02678171917796135\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 4.7184882164001465 | KNN Loss: 4.695659160614014 | CLS Loss: 0.0228290855884552\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 4.716969966888428 | KNN Loss: 4.685032844543457 | CLS Loss: 0.03193705156445503\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 4.711126804351807 | KNN Loss: 4.703388690948486 | CLS Loss: 0.007738160900771618\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 4.696945667266846 | KNN Loss: 4.686728477478027 | CLS Loss: 0.010216992348432541\n",
      "Epoch: 057, Loss: 4.7273, Train: 0.9944, Valid: 0.9863, Best: 0.9866\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 4.779135227203369 | KNN Loss: 4.759877681732178 | CLS Loss: 0.019257720559835434\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 4.6919331550598145 | KNN Loss: 4.683523178100586 | CLS Loss: 0.008410214446485043\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 4.730103969573975 | KNN Loss: 4.705017566680908 | CLS Loss: 0.02508622780442238\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 4.731913089752197 | KNN Loss: 4.692336559295654 | CLS Loss: 0.03957675024867058\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 4.726859092712402 | KNN Loss: 4.688715934753418 | CLS Loss: 0.038142938166856766\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 4.70153284072876 | KNN Loss: 4.698131084442139 | CLS Loss: 0.0034019406884908676\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 4.685969352722168 | KNN Loss: 4.674251079559326 | CLS Loss: 0.011718361638486385\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 4.8176798820495605 | KNN Loss: 4.7919535636901855 | CLS Loss: 0.025726113468408585\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 4.767089366912842 | KNN Loss: 4.75342321395874 | CLS Loss: 0.013666050508618355\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 4.700242519378662 | KNN Loss: 4.689635276794434 | CLS Loss: 0.010607342235744\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 4.685041427612305 | KNN Loss: 4.680628299713135 | CLS Loss: 0.004413160961121321\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 4.880083084106445 | KNN Loss: 4.865912914276123 | CLS Loss: 0.01417018286883831\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 4.753031253814697 | KNN Loss: 4.738539695739746 | CLS Loss: 0.014491664245724678\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 4.69234561920166 | KNN Loss: 4.685438632965088 | CLS Loss: 0.0069067771546542645\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 4.740447998046875 | KNN Loss: 4.706389904022217 | CLS Loss: 0.034057941287755966\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 4.75654411315918 | KNN Loss: 4.740047931671143 | CLS Loss: 0.01649615168571472\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 4.71956205368042 | KNN Loss: 4.684451103210449 | CLS Loss: 0.03511100262403488\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 4.755758285522461 | KNN Loss: 4.705716133117676 | CLS Loss: 0.05004227161407471\n",
      "Epoch: 058, Loss: 4.7271, Train: 0.9939, Valid: 0.9848, Best: 0.9866\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 4.682894706726074 | KNN Loss: 4.658784866333008 | CLS Loss: 0.02410980500280857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 4.755058288574219 | KNN Loss: 4.67966890335083 | CLS Loss: 0.07538935542106628\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 4.689681529998779 | KNN Loss: 4.65852165222168 | CLS Loss: 0.031159790232777596\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 4.6968536376953125 | KNN Loss: 4.684027194976807 | CLS Loss: 0.01282651536166668\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 4.700145721435547 | KNN Loss: 4.679486274719238 | CLS Loss: 0.02065940946340561\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 4.745163917541504 | KNN Loss: 4.726982593536377 | CLS Loss: 0.018181195482611656\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 4.687380790710449 | KNN Loss: 4.681849479675293 | CLS Loss: 0.005531215574592352\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 4.718723297119141 | KNN Loss: 4.699902057647705 | CLS Loss: 0.018821345642209053\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 4.683139801025391 | KNN Loss: 4.681013584136963 | CLS Loss: 0.002126186154782772\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 4.738803863525391 | KNN Loss: 4.710112571716309 | CLS Loss: 0.02869117073714733\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 4.693979740142822 | KNN Loss: 4.678431987762451 | CLS Loss: 0.015547649003565311\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 4.730091571807861 | KNN Loss: 4.709394931793213 | CLS Loss: 0.02069668658077717\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 4.683109760284424 | KNN Loss: 4.664499759674072 | CLS Loss: 0.01860988512635231\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 4.670557022094727 | KNN Loss: 4.659524440765381 | CLS Loss: 0.01103267353028059\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 4.717404842376709 | KNN Loss: 4.700012683868408 | CLS Loss: 0.017392292618751526\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 4.704962253570557 | KNN Loss: 4.681291103363037 | CLS Loss: 0.02367131970822811\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 4.654008388519287 | KNN Loss: 4.633922576904297 | CLS Loss: 0.020085787400603294\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 4.724113941192627 | KNN Loss: 4.695414066314697 | CLS Loss: 0.028699928894639015\n",
      "Epoch: 059, Loss: 4.7187, Train: 0.9957, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 4.706161975860596 | KNN Loss: 4.701456546783447 | CLS Loss: 0.004705415572971106\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 4.69365119934082 | KNN Loss: 4.684957504272461 | CLS Loss: 0.008693814277648926\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 4.658872604370117 | KNN Loss: 4.646025657653809 | CLS Loss: 0.012846814468502998\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 4.688875675201416 | KNN Loss: 4.676303386688232 | CLS Loss: 0.012572242878377438\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 4.681656837463379 | KNN Loss: 4.66915225982666 | CLS Loss: 0.012504671700298786\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 4.71484899520874 | KNN Loss: 4.6881422996521 | CLS Loss: 0.026706479489803314\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 4.733850002288818 | KNN Loss: 4.70775842666626 | CLS Loss: 0.026091642677783966\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 4.6753411293029785 | KNN Loss: 4.654510974884033 | CLS Loss: 0.020830191671848297\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 4.690441608428955 | KNN Loss: 4.671540260314941 | CLS Loss: 0.018901167437434196\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 4.684749126434326 | KNN Loss: 4.674020767211914 | CLS Loss: 0.010728206485509872\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 4.736603736877441 | KNN Loss: 4.7208452224731445 | CLS Loss: 0.015758385881781578\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 4.702846050262451 | KNN Loss: 4.685850143432617 | CLS Loss: 0.01699608750641346\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 4.724527359008789 | KNN Loss: 4.694666862487793 | CLS Loss: 0.029860449954867363\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 4.672861576080322 | KNN Loss: 4.6621012687683105 | CLS Loss: 0.010760248638689518\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 4.6877031326293945 | KNN Loss: 4.682385444641113 | CLS Loss: 0.0053175026550889015\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 4.730862617492676 | KNN Loss: 4.718845844268799 | CLS Loss: 0.012016773223876953\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 4.716228485107422 | KNN Loss: 4.70614767074585 | CLS Loss: 0.01008074264973402\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 4.699815273284912 | KNN Loss: 4.692986965179443 | CLS Loss: 0.006828240118920803\n",
      "Epoch: 060, Loss: 4.7105, Train: 0.9963, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 4.642531394958496 | KNN Loss: 4.636978626251221 | CLS Loss: 0.005552858579903841\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 4.752475738525391 | KNN Loss: 4.722042560577393 | CLS Loss: 0.03043304570019245\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 4.694872856140137 | KNN Loss: 4.686916351318359 | CLS Loss: 0.007956304587423801\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 4.692594051361084 | KNN Loss: 4.6750688552856445 | CLS Loss: 0.01752525381743908\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 4.780433654785156 | KNN Loss: 4.753518104553223 | CLS Loss: 0.026915641501545906\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 4.720433712005615 | KNN Loss: 4.703927516937256 | CLS Loss: 0.016506051644682884\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 4.722457408905029 | KNN Loss: 4.707537651062012 | CLS Loss: 0.014919916167855263\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 4.705275535583496 | KNN Loss: 4.695547103881836 | CLS Loss: 0.009728474542498589\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 4.726747989654541 | KNN Loss: 4.708986282348633 | CLS Loss: 0.01776186376810074\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 4.769998073577881 | KNN Loss: 4.75291109085083 | CLS Loss: 0.01708691380918026\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 4.7484965324401855 | KNN Loss: 4.720993518829346 | CLS Loss: 0.027502814307808876\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 4.749322414398193 | KNN Loss: 4.736362934112549 | CLS Loss: 0.012959574349224567\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 4.711885929107666 | KNN Loss: 4.690820217132568 | CLS Loss: 0.021065808832645416\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 4.702880382537842 | KNN Loss: 4.685074329376221 | CLS Loss: 0.017805950716137886\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 4.7292985916137695 | KNN Loss: 4.721251487731934 | CLS Loss: 0.008046979084610939\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 4.68398380279541 | KNN Loss: 4.677268028259277 | CLS Loss: 0.006715592462569475\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 4.689004421234131 | KNN Loss: 4.665938854217529 | CLS Loss: 0.02306566759943962\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 4.729218006134033 | KNN Loss: 4.6989264488220215 | CLS Loss: 0.030291400849819183\n",
      "Epoch: 061, Loss: 4.7177, Train: 0.9951, Valid: 0.9850, Best: 0.9867\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 4.712679386138916 | KNN Loss: 4.695343971252441 | CLS Loss: 0.01733538694679737\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 4.692958831787109 | KNN Loss: 4.657311916351318 | CLS Loss: 0.03564702346920967\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 4.7273101806640625 | KNN Loss: 4.6847028732299805 | CLS Loss: 0.04260745644569397\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 4.738055229187012 | KNN Loss: 4.726701259613037 | CLS Loss: 0.011353841051459312\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 4.682064056396484 | KNN Loss: 4.677160739898682 | CLS Loss: 0.004903338383883238\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 4.729198455810547 | KNN Loss: 4.7178778648376465 | CLS Loss: 0.011320561170578003\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 4.742363929748535 | KNN Loss: 4.718773365020752 | CLS Loss: 0.023590605705976486\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 4.6853179931640625 | KNN Loss: 4.6779022216796875 | CLS Loss: 0.007415783125907183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 4.678022861480713 | KNN Loss: 4.660522937774658 | CLS Loss: 0.01750010997056961\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 4.8311920166015625 | KNN Loss: 4.788859844207764 | CLS Loss: 0.042332377284765244\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 4.725604057312012 | KNN Loss: 4.722499370574951 | CLS Loss: 0.003104632953181863\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 4.7709197998046875 | KNN Loss: 4.731648921966553 | CLS Loss: 0.03927066549658775\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 4.7206854820251465 | KNN Loss: 4.710465908050537 | CLS Loss: 0.010219573974609375\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 4.700364589691162 | KNN Loss: 4.696147441864014 | CLS Loss: 0.004216935019940138\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 4.746033191680908 | KNN Loss: 4.738822937011719 | CLS Loss: 0.007210229989141226\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 4.696201801300049 | KNN Loss: 4.690025329589844 | CLS Loss: 0.006176529452204704\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 4.715381145477295 | KNN Loss: 4.693116188049316 | CLS Loss: 0.02226496860384941\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 4.718231201171875 | KNN Loss: 4.708792686462402 | CLS Loss: 0.0094384104013443\n",
      "Epoch: 062, Loss: 4.7111, Train: 0.9940, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 4.673549175262451 | KNN Loss: 4.668689250946045 | CLS Loss: 0.0048601352609694\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 4.709133148193359 | KNN Loss: 4.693907260894775 | CLS Loss: 0.015226016752421856\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 4.728155136108398 | KNN Loss: 4.704596996307373 | CLS Loss: 0.02355797216296196\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 4.704014778137207 | KNN Loss: 4.689860820770264 | CLS Loss: 0.014153819531202316\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 4.689205646514893 | KNN Loss: 4.682719707489014 | CLS Loss: 0.006486036349087954\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 4.73600435256958 | KNN Loss: 4.715117454528809 | CLS Loss: 0.020887112244963646\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 4.718120574951172 | KNN Loss: 4.7010178565979 | CLS Loss: 0.017102880403399467\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 4.750819683074951 | KNN Loss: 4.723565101623535 | CLS Loss: 0.02725481055676937\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 4.686898708343506 | KNN Loss: 4.6680426597595215 | CLS Loss: 0.018856210634112358\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 4.707857608795166 | KNN Loss: 4.691567897796631 | CLS Loss: 0.016289565712213516\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 4.724980354309082 | KNN Loss: 4.7202911376953125 | CLS Loss: 0.004689169116318226\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 4.692982196807861 | KNN Loss: 4.671596050262451 | CLS Loss: 0.021386032924056053\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 4.6644287109375 | KNN Loss: 4.631189346313477 | CLS Loss: 0.033239513635635376\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 4.672863960266113 | KNN Loss: 4.658905029296875 | CLS Loss: 0.013958887197077274\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 4.700785160064697 | KNN Loss: 4.668636798858643 | CLS Loss: 0.03214816749095917\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 4.738863468170166 | KNN Loss: 4.700632095336914 | CLS Loss: 0.03823160007596016\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 4.684871673583984 | KNN Loss: 4.675652027130127 | CLS Loss: 0.009219811297953129\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 4.751598834991455 | KNN Loss: 4.721614837646484 | CLS Loss: 0.02998385950922966\n",
      "Epoch: 063, Loss: 4.7159, Train: 0.9955, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 4.723296642303467 | KNN Loss: 4.716382026672363 | CLS Loss: 0.006914808414876461\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 4.771766185760498 | KNN Loss: 4.745310306549072 | CLS Loss: 0.026456115767359734\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 4.7336554527282715 | KNN Loss: 4.7096405029296875 | CLS Loss: 0.024015169590711594\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 4.728728294372559 | KNN Loss: 4.70447301864624 | CLS Loss: 0.024255137890577316\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 4.674771308898926 | KNN Loss: 4.651744842529297 | CLS Loss: 0.023026293143630028\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 4.683182239532471 | KNN Loss: 4.670166969299316 | CLS Loss: 0.013015445321798325\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 4.672581195831299 | KNN Loss: 4.66061544418335 | CLS Loss: 0.01196597795933485\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 4.724032402038574 | KNN Loss: 4.694919109344482 | CLS Loss: 0.029113097116351128\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 4.725630283355713 | KNN Loss: 4.72146463394165 | CLS Loss: 0.004165575373917818\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 4.676172256469727 | KNN Loss: 4.653368949890137 | CLS Loss: 0.022803349420428276\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 4.739720344543457 | KNN Loss: 4.726925373077393 | CLS Loss: 0.01279515027999878\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 4.695754051208496 | KNN Loss: 4.679324626922607 | CLS Loss: 0.0164293572306633\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 4.685647964477539 | KNN Loss: 4.674618244171143 | CLS Loss: 0.011029640212655067\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 4.678709983825684 | KNN Loss: 4.661342144012451 | CLS Loss: 0.01736799068748951\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 4.697944641113281 | KNN Loss: 4.681824684143066 | CLS Loss: 0.01612011529505253\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 4.720330238342285 | KNN Loss: 4.708428382873535 | CLS Loss: 0.011901672929525375\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 4.749110221862793 | KNN Loss: 4.716560363769531 | CLS Loss: 0.0325499065220356\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 4.729270935058594 | KNN Loss: 4.703986167907715 | CLS Loss: 0.025284795090556145\n",
      "Epoch: 064, Loss: 4.7162, Train: 0.9952, Valid: 0.9860, Best: 0.9867\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 4.683720588684082 | KNN Loss: 4.666882038116455 | CLS Loss: 0.01683863252401352\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 4.755092144012451 | KNN Loss: 4.735247611999512 | CLS Loss: 0.01984430104494095\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 4.735010623931885 | KNN Loss: 4.726163864135742 | CLS Loss: 0.008846959099173546\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 4.859104633331299 | KNN Loss: 4.815286159515381 | CLS Loss: 0.043818533420562744\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 4.693136692047119 | KNN Loss: 4.685339450836182 | CLS Loss: 0.007797202095389366\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 4.7348151206970215 | KNN Loss: 4.711076259613037 | CLS Loss: 0.023739032447338104\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 4.728830814361572 | KNN Loss: 4.701210021972656 | CLS Loss: 0.027620954439044\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 4.7669830322265625 | KNN Loss: 4.715521812438965 | CLS Loss: 0.05146114155650139\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 4.720376968383789 | KNN Loss: 4.705410480499268 | CLS Loss: 0.014966634102165699\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 4.762304782867432 | KNN Loss: 4.741947174072266 | CLS Loss: 0.020357642322778702\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 4.68544864654541 | KNN Loss: 4.672460556030273 | CLS Loss: 0.012988036498427391\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 4.657577991485596 | KNN Loss: 4.649302959442139 | CLS Loss: 0.008274896070361137\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 4.739504814147949 | KNN Loss: 4.726297378540039 | CLS Loss: 0.01320759765803814\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 4.703322410583496 | KNN Loss: 4.678308486938477 | CLS Loss: 0.025013945996761322\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 4.796833038330078 | KNN Loss: 4.7588582038879395 | CLS Loss: 0.03797507286071777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 4.731400966644287 | KNN Loss: 4.710884094238281 | CLS Loss: 0.020516861230134964\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 4.696679592132568 | KNN Loss: 4.670450687408447 | CLS Loss: 0.02622891589999199\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 4.736091613769531 | KNN Loss: 4.703755855560303 | CLS Loss: 0.03233577683568001\n",
      "Epoch: 065, Loss: 4.7219, Train: 0.9928, Valid: 0.9853, Best: 0.9867\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 4.71272087097168 | KNN Loss: 4.6901326179504395 | CLS Loss: 0.022588247433304787\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 4.691913604736328 | KNN Loss: 4.67496919631958 | CLS Loss: 0.016944216564297676\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 4.72657585144043 | KNN Loss: 4.702298641204834 | CLS Loss: 0.024277029559016228\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 4.691000938415527 | KNN Loss: 4.661459445953369 | CLS Loss: 0.029541458934545517\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 4.734333038330078 | KNN Loss: 4.724510192871094 | CLS Loss: 0.009822648949921131\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 4.686416149139404 | KNN Loss: 4.665494918823242 | CLS Loss: 0.020920997485518456\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 4.745214462280273 | KNN Loss: 4.732480049133301 | CLS Loss: 0.01273440569639206\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 4.697540283203125 | KNN Loss: 4.684627532958984 | CLS Loss: 0.012912736274302006\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 4.716479778289795 | KNN Loss: 4.688282012939453 | CLS Loss: 0.028197648003697395\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 4.7371296882629395 | KNN Loss: 4.725358009338379 | CLS Loss: 0.011771528981626034\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 4.751359939575195 | KNN Loss: 4.719095230102539 | CLS Loss: 0.03226485475897789\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 4.751842975616455 | KNN Loss: 4.7115797996521 | CLS Loss: 0.04026305675506592\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 4.732842445373535 | KNN Loss: 4.710026264190674 | CLS Loss: 0.022816181182861328\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 4.692605972290039 | KNN Loss: 4.690639972686768 | CLS Loss: 0.001965964213013649\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 4.714267730712891 | KNN Loss: 4.6903533935546875 | CLS Loss: 0.0239145178347826\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 4.694176197052002 | KNN Loss: 4.678756237030029 | CLS Loss: 0.015419955365359783\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 4.714718341827393 | KNN Loss: 4.704462051391602 | CLS Loss: 0.010256271809339523\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 4.751656532287598 | KNN Loss: 4.738100528717041 | CLS Loss: 0.013556033372879028\n",
      "Epoch: 066, Loss: 4.7193, Train: 0.9959, Valid: 0.9863, Best: 0.9867\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 4.7028398513793945 | KNN Loss: 4.698329448699951 | CLS Loss: 0.004510193597525358\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 4.692639350891113 | KNN Loss: 4.687328338623047 | CLS Loss: 0.005311114247888327\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 4.733301639556885 | KNN Loss: 4.727052211761475 | CLS Loss: 0.0062495507299900055\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 4.751226902008057 | KNN Loss: 4.73146390914917 | CLS Loss: 0.019763227552175522\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 4.703394889831543 | KNN Loss: 4.695589065551758 | CLS Loss: 0.0078058550134301186\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 4.700755596160889 | KNN Loss: 4.693474769592285 | CLS Loss: 0.007281002588570118\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 4.784811019897461 | KNN Loss: 4.753586292266846 | CLS Loss: 0.031224632635712624\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 4.705649375915527 | KNN Loss: 4.686241149902344 | CLS Loss: 0.019408026710152626\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 4.673141956329346 | KNN Loss: 4.646752834320068 | CLS Loss: 0.02638906054198742\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 4.788297176361084 | KNN Loss: 4.780862331390381 | CLS Loss: 0.007435054983943701\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 4.769583702087402 | KNN Loss: 4.754518032073975 | CLS Loss: 0.015065454877912998\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 4.7619242668151855 | KNN Loss: 4.736937046051025 | CLS Loss: 0.0249869953840971\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 4.783518314361572 | KNN Loss: 4.771312713623047 | CLS Loss: 0.012205579318106174\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 4.703857898712158 | KNN Loss: 4.6970295906066895 | CLS Loss: 0.006828291341662407\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 4.6842265129089355 | KNN Loss: 4.66610050201416 | CLS Loss: 0.018125899136066437\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 4.773658752441406 | KNN Loss: 4.749487400054932 | CLS Loss: 0.024171583354473114\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 4.67893123626709 | KNN Loss: 4.675154685974121 | CLS Loss: 0.0037763474974781275\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 4.740009784698486 | KNN Loss: 4.6881842613220215 | CLS Loss: 0.051825735718011856\n",
      "Epoch: 067, Loss: 4.7164, Train: 0.9966, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 4.70963716506958 | KNN Loss: 4.705255508422852 | CLS Loss: 0.004381551407277584\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 4.724374294281006 | KNN Loss: 4.694745063781738 | CLS Loss: 0.029629407450556755\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 4.69936466217041 | KNN Loss: 4.682687282562256 | CLS Loss: 0.016677208244800568\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 4.715483665466309 | KNN Loss: 4.706981182098389 | CLS Loss: 0.008502556011080742\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 4.6935930252075195 | KNN Loss: 4.689055442810059 | CLS Loss: 0.00453760614618659\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 4.724961280822754 | KNN Loss: 4.7015380859375 | CLS Loss: 0.023423226550221443\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 4.741630554199219 | KNN Loss: 4.7222700119018555 | CLS Loss: 0.019360709935426712\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 4.704620361328125 | KNN Loss: 4.7002973556518555 | CLS Loss: 0.004322947468608618\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 4.66050386428833 | KNN Loss: 4.651841640472412 | CLS Loss: 0.008662461303174496\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 4.737096786499023 | KNN Loss: 4.730347156524658 | CLS Loss: 0.006749478168785572\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 4.715994358062744 | KNN Loss: 4.707243919372559 | CLS Loss: 0.008750582113862038\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 4.729137420654297 | KNN Loss: 4.689380168914795 | CLS Loss: 0.039757076650857925\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 4.675376892089844 | KNN Loss: 4.668476104736328 | CLS Loss: 0.006900680251419544\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 4.727370262145996 | KNN Loss: 4.702933311462402 | CLS Loss: 0.024436870589852333\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 4.7211222648620605 | KNN Loss: 4.7134690284729 | CLS Loss: 0.0076530855149030685\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 4.698183059692383 | KNN Loss: 4.6821770668029785 | CLS Loss: 0.01600612699985504\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 4.761974334716797 | KNN Loss: 4.742828369140625 | CLS Loss: 0.01914617232978344\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 4.661279201507568 | KNN Loss: 4.655480861663818 | CLS Loss: 0.005798324476927519\n",
      "Epoch: 068, Loss: 4.7126, Train: 0.9968, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 4.724682331085205 | KNN Loss: 4.71281623840332 | CLS Loss: 0.01186592597514391\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 4.687189102172852 | KNN Loss: 4.6505351066589355 | CLS Loss: 0.03665418177843094\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 4.7048187255859375 | KNN Loss: 4.688216209411621 | CLS Loss: 0.01660258136689663\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 4.818292617797852 | KNN Loss: 4.806307792663574 | CLS Loss: 0.011984806507825851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 4.741040229797363 | KNN Loss: 4.739066123962402 | CLS Loss: 0.0019740709103643894\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 4.739317893981934 | KNN Loss: 4.719746112823486 | CLS Loss: 0.019571971148252487\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 4.705991268157959 | KNN Loss: 4.699800491333008 | CLS Loss: 0.006190769840031862\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 4.6821208000183105 | KNN Loss: 4.680339813232422 | CLS Loss: 0.001781064784154296\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 4.733116149902344 | KNN Loss: 4.712962627410889 | CLS Loss: 0.020153380930423737\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 4.693075180053711 | KNN Loss: 4.666686058044434 | CLS Loss: 0.026389243081212044\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 4.669792652130127 | KNN Loss: 4.6653828620910645 | CLS Loss: 0.004409815184772015\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 4.72755241394043 | KNN Loss: 4.70800256729126 | CLS Loss: 0.019549736753106117\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 4.777317523956299 | KNN Loss: 4.746263027191162 | CLS Loss: 0.031054483726620674\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 4.746714115142822 | KNN Loss: 4.71195125579834 | CLS Loss: 0.034763090312480927\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 4.761464595794678 | KNN Loss: 4.747644424438477 | CLS Loss: 0.013820306397974491\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 4.717363357543945 | KNN Loss: 4.67479944229126 | CLS Loss: 0.042563989758491516\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 4.713052272796631 | KNN Loss: 4.688769817352295 | CLS Loss: 0.024282589554786682\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 4.730531215667725 | KNN Loss: 4.708837509155273 | CLS Loss: 0.021693775430321693\n",
      "Epoch: 069, Loss: 4.7067, Train: 0.9961, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 4.708459854125977 | KNN Loss: 4.6779584884643555 | CLS Loss: 0.030501391738653183\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 4.709625720977783 | KNN Loss: 4.6776814460754395 | CLS Loss: 0.031944405287504196\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 4.666106224060059 | KNN Loss: 4.654828071594238 | CLS Loss: 0.011277969926595688\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 4.731380462646484 | KNN Loss: 4.705055236816406 | CLS Loss: 0.02632508985698223\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 4.727059364318848 | KNN Loss: 4.712411403656006 | CLS Loss: 0.014647739008069038\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 4.70065450668335 | KNN Loss: 4.693554401397705 | CLS Loss: 0.007100302260369062\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 4.655095100402832 | KNN Loss: 4.6510090827941895 | CLS Loss: 0.004085848573595285\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 4.673722743988037 | KNN Loss: 4.666543483734131 | CLS Loss: 0.007179124280810356\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 4.784470081329346 | KNN Loss: 4.773157596588135 | CLS Loss: 0.011312449350953102\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 4.704646587371826 | KNN Loss: 4.696044921875 | CLS Loss: 0.00860168132930994\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 4.704072952270508 | KNN Loss: 4.675662040710449 | CLS Loss: 0.028411120176315308\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 4.712013244628906 | KNN Loss: 4.704648971557617 | CLS Loss: 0.007364360615611076\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 4.728495121002197 | KNN Loss: 4.705227851867676 | CLS Loss: 0.023267431184649467\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 4.758786201477051 | KNN Loss: 4.7179179191589355 | CLS Loss: 0.0408681184053421\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 4.689260959625244 | KNN Loss: 4.685144901275635 | CLS Loss: 0.00411603506654501\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 4.723870754241943 | KNN Loss: 4.692419052124023 | CLS Loss: 0.03145148977637291\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 4.705990314483643 | KNN Loss: 4.700179100036621 | CLS Loss: 0.005811119452118874\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 4.721240520477295 | KNN Loss: 4.693054676055908 | CLS Loss: 0.028186023235321045\n",
      "Epoch: 070, Loss: 4.7046, Train: 0.9949, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 4.739516258239746 | KNN Loss: 4.718315601348877 | CLS Loss: 0.02120060846209526\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 4.6922807693481445 | KNN Loss: 4.679649829864502 | CLS Loss: 0.01263109315186739\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 4.6621246337890625 | KNN Loss: 4.654141902923584 | CLS Loss: 0.007982497103512287\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 4.673243522644043 | KNN Loss: 4.6372904777526855 | CLS Loss: 0.03595298156142235\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 4.6560187339782715 | KNN Loss: 4.65118932723999 | CLS Loss: 0.004829320590943098\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 4.756161689758301 | KNN Loss: 4.729410648345947 | CLS Loss: 0.026751236990094185\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 4.646193981170654 | KNN Loss: 4.642301082611084 | CLS Loss: 0.003892810083925724\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 4.69333553314209 | KNN Loss: 4.677369594573975 | CLS Loss: 0.015965884551405907\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 4.7352094650268555 | KNN Loss: 4.701906204223633 | CLS Loss: 0.033303067088127136\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 4.784415245056152 | KNN Loss: 4.763356685638428 | CLS Loss: 0.021058782935142517\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 4.718254089355469 | KNN Loss: 4.7007880210876465 | CLS Loss: 0.01746584102511406\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 4.69871711730957 | KNN Loss: 4.66538667678833 | CLS Loss: 0.03333047032356262\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 4.742857456207275 | KNN Loss: 4.710582256317139 | CLS Loss: 0.032275255769491196\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 4.692009449005127 | KNN Loss: 4.679964542388916 | CLS Loss: 0.012044754810631275\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 4.711547374725342 | KNN Loss: 4.69803524017334 | CLS Loss: 0.013512293808162212\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 4.681551456451416 | KNN Loss: 4.667284965515137 | CLS Loss: 0.014266659505665302\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 4.716558933258057 | KNN Loss: 4.685273170471191 | CLS Loss: 0.031285595148801804\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 4.713009834289551 | KNN Loss: 4.701189041137695 | CLS Loss: 0.01182099524885416\n",
      "Epoch: 071, Loss: 4.7048, Train: 0.9965, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 4.726745128631592 | KNN Loss: 4.721736431121826 | CLS Loss: 0.00500861182808876\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 4.673797607421875 | KNN Loss: 4.662426471710205 | CLS Loss: 0.011370940133929253\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 4.686511993408203 | KNN Loss: 4.680125713348389 | CLS Loss: 0.006386175751686096\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 4.722585678100586 | KNN Loss: 4.712350845336914 | CLS Loss: 0.01023480948060751\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 4.704769134521484 | KNN Loss: 4.685140609741211 | CLS Loss: 0.019628429785370827\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 4.68683385848999 | KNN Loss: 4.682044506072998 | CLS Loss: 0.0047892360016703606\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 4.7032694816589355 | KNN Loss: 4.689719200134277 | CLS Loss: 0.013550140894949436\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 4.758464336395264 | KNN Loss: 4.750685214996338 | CLS Loss: 0.007778914645314217\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 4.7348713874816895 | KNN Loss: 4.732083797454834 | CLS Loss: 0.0027876750100404024\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 4.7473673820495605 | KNN Loss: 4.74174165725708 | CLS Loss: 0.005625871475785971\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 4.696878433227539 | KNN Loss: 4.681295871734619 | CLS Loss: 0.015582562424242496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 4.736121654510498 | KNN Loss: 4.7034382820129395 | CLS Loss: 0.0326836034655571\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 4.663413047790527 | KNN Loss: 4.6573662757873535 | CLS Loss: 0.00604686513543129\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 4.715249061584473 | KNN Loss: 4.684045314788818 | CLS Loss: 0.03120359778404236\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 4.707891941070557 | KNN Loss: 4.6946940422058105 | CLS Loss: 0.013198046013712883\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 4.687875270843506 | KNN Loss: 4.678534030914307 | CLS Loss: 0.009341307915747166\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 4.689694881439209 | KNN Loss: 4.676888942718506 | CLS Loss: 0.01280574407428503\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 4.681415557861328 | KNN Loss: 4.66070032119751 | CLS Loss: 0.02071525529026985\n",
      "Epoch: 072, Loss: 4.7052, Train: 0.9959, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 4.7109503746032715 | KNN Loss: 4.70725154876709 | CLS Loss: 0.0036987948697060347\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 4.705386638641357 | KNN Loss: 4.690736770629883 | CLS Loss: 0.01464967243373394\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 4.79538106918335 | KNN Loss: 4.75170373916626 | CLS Loss: 0.04367753490805626\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 4.709320068359375 | KNN Loss: 4.692289352416992 | CLS Loss: 0.017030688002705574\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 4.74174690246582 | KNN Loss: 4.725179195404053 | CLS Loss: 0.016567833721637726\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 4.721360206604004 | KNN Loss: 4.7029008865356445 | CLS Loss: 0.018459446728229523\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 4.734005928039551 | KNN Loss: 4.722287654876709 | CLS Loss: 0.011718245223164558\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 4.719326019287109 | KNN Loss: 4.698519229888916 | CLS Loss: 0.0208066888153553\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 4.6848602294921875 | KNN Loss: 4.670688629150391 | CLS Loss: 0.014171382412314415\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 4.66406774520874 | KNN Loss: 4.654058933258057 | CLS Loss: 0.010008667595684528\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 4.8011474609375 | KNN Loss: 4.795091152191162 | CLS Loss: 0.006056194193661213\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 4.7526021003723145 | KNN Loss: 4.739348411560059 | CLS Loss: 0.013253717683255672\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 4.666613578796387 | KNN Loss: 4.6613030433654785 | CLS Loss: 0.0053105768747627735\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 4.652577877044678 | KNN Loss: 4.649109363555908 | CLS Loss: 0.003468454349786043\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 4.693924427032471 | KNN Loss: 4.6779632568359375 | CLS Loss: 0.015961376950144768\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 4.719802379608154 | KNN Loss: 4.700013160705566 | CLS Loss: 0.019789395853877068\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 4.761590480804443 | KNN Loss: 4.732644081115723 | CLS Loss: 0.028946401551365852\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 4.730964660644531 | KNN Loss: 4.720364093780518 | CLS Loss: 0.01060059666633606\n",
      "Epoch: 073, Loss: 4.7074, Train: 0.9949, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 4.696839809417725 | KNN Loss: 4.692746162414551 | CLS Loss: 0.00409347377717495\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 4.688700199127197 | KNN Loss: 4.681328296661377 | CLS Loss: 0.0073720794171094894\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 4.649655342102051 | KNN Loss: 4.639780521392822 | CLS Loss: 0.009874628856778145\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 4.736435413360596 | KNN Loss: 4.727621555328369 | CLS Loss: 0.00881380308419466\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 4.670680999755859 | KNN Loss: 4.659465789794922 | CLS Loss: 0.011215385980904102\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 4.723267555236816 | KNN Loss: 4.715616703033447 | CLS Loss: 0.007650801911950111\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 4.691170692443848 | KNN Loss: 4.674468994140625 | CLS Loss: 0.016701586544513702\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 4.738433361053467 | KNN Loss: 4.719720363616943 | CLS Loss: 0.01871318370103836\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 4.6935343742370605 | KNN Loss: 4.691561222076416 | CLS Loss: 0.0019730497151613235\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 4.710216522216797 | KNN Loss: 4.695635795593262 | CLS Loss: 0.014580952003598213\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 4.7378106117248535 | KNN Loss: 4.718405246734619 | CLS Loss: 0.019405389204621315\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 4.766361236572266 | KNN Loss: 4.731623649597168 | CLS Loss: 0.034737683832645416\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 4.725103378295898 | KNN Loss: 4.7030415534973145 | CLS Loss: 0.02206164039671421\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 4.69976282119751 | KNN Loss: 4.680077075958252 | CLS Loss: 0.01968584954738617\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 4.662374973297119 | KNN Loss: 4.651381969451904 | CLS Loss: 0.010992917232215405\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 4.765719890594482 | KNN Loss: 4.73979377746582 | CLS Loss: 0.025925982743501663\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 4.752574443817139 | KNN Loss: 4.72733211517334 | CLS Loss: 0.02524246647953987\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 4.678416728973389 | KNN Loss: 4.670080661773682 | CLS Loss: 0.008336208760738373\n",
      "Epoch: 074, Loss: 4.7087, Train: 0.9961, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 4.690782070159912 | KNN Loss: 4.682592868804932 | CLS Loss: 0.00818901788443327\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 4.642143249511719 | KNN Loss: 4.63761043548584 | CLS Loss: 0.004532835446298122\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 4.712460041046143 | KNN Loss: 4.692039966583252 | CLS Loss: 0.020420262590050697\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 4.7019500732421875 | KNN Loss: 4.690535068511963 | CLS Loss: 0.011415142565965652\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 4.717222213745117 | KNN Loss: 4.687283039093018 | CLS Loss: 0.02993902564048767\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 4.704057693481445 | KNN Loss: 4.682410717010498 | CLS Loss: 0.02164677157998085\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 4.675292015075684 | KNN Loss: 4.663243770599365 | CLS Loss: 0.012048357166349888\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 4.716452598571777 | KNN Loss: 4.703379154205322 | CLS Loss: 0.013073598966002464\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 4.740274429321289 | KNN Loss: 4.708827972412109 | CLS Loss: 0.03144633769989014\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 4.725363731384277 | KNN Loss: 4.702996730804443 | CLS Loss: 0.022367173805832863\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 4.742177486419678 | KNN Loss: 4.739855766296387 | CLS Loss: 0.00232163374312222\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 4.722283840179443 | KNN Loss: 4.708446025848389 | CLS Loss: 0.013837800361216068\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 4.712656021118164 | KNN Loss: 4.6911468505859375 | CLS Loss: 0.021509122103452682\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 4.6768479347229 | KNN Loss: 4.6671977043151855 | CLS Loss: 0.00965026579797268\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 4.761496067047119 | KNN Loss: 4.715301513671875 | CLS Loss: 0.04619454964995384\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 4.835454940795898 | KNN Loss: 4.801205635070801 | CLS Loss: 0.0342492014169693\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 4.786781311035156 | KNN Loss: 4.766617298126221 | CLS Loss: 0.02016407996416092\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 4.720254898071289 | KNN Loss: 4.709069728851318 | CLS Loss: 0.011185330338776112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 075, Loss: 4.7168, Train: 0.9942, Valid: 0.9839, Best: 0.9872\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 4.727001190185547 | KNN Loss: 4.7065629959106445 | CLS Loss: 0.02043803222477436\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 4.701597213745117 | KNN Loss: 4.690100193023682 | CLS Loss: 0.011497098952531815\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 4.68812370300293 | KNN Loss: 4.663998126983643 | CLS Loss: 0.02412549778819084\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 4.715468406677246 | KNN Loss: 4.688493728637695 | CLS Loss: 0.026974670588970184\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 4.761530876159668 | KNN Loss: 4.755425453186035 | CLS Loss: 0.006105518899857998\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 4.7031989097595215 | KNN Loss: 4.699009895324707 | CLS Loss: 0.004188897088170052\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 4.687836647033691 | KNN Loss: 4.677367687225342 | CLS Loss: 0.010468875989317894\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 4.6788763999938965 | KNN Loss: 4.667930603027344 | CLS Loss: 0.01094584446400404\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 4.6813645362854 | KNN Loss: 4.676451683044434 | CLS Loss: 0.004912723321467638\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 4.733064651489258 | KNN Loss: 4.715853691101074 | CLS Loss: 0.017210857942700386\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 4.701386451721191 | KNN Loss: 4.676453113555908 | CLS Loss: 0.024933507665991783\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 4.672085762023926 | KNN Loss: 4.661025524139404 | CLS Loss: 0.011060134507715702\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 4.799088001251221 | KNN Loss: 4.764493942260742 | CLS Loss: 0.03459426760673523\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 4.700661659240723 | KNN Loss: 4.689140319824219 | CLS Loss: 0.011521471664309502\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 4.714049339294434 | KNN Loss: 4.699429512023926 | CLS Loss: 0.014619599096477032\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 4.777567386627197 | KNN Loss: 4.757439613342285 | CLS Loss: 0.020127704367041588\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 4.6386613845825195 | KNN Loss: 4.634884357452393 | CLS Loss: 0.003777171252295375\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 4.672008991241455 | KNN Loss: 4.66796875 | CLS Loss: 0.004040151834487915\n",
      "Epoch: 076, Loss: 4.7016, Train: 0.9958, Valid: 0.9860, Best: 0.9872\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 4.711074352264404 | KNN Loss: 4.69438362121582 | CLS Loss: 0.01669078879058361\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 4.672309875488281 | KNN Loss: 4.650219440460205 | CLS Loss: 0.022090524435043335\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 4.670395851135254 | KNN Loss: 4.664059638977051 | CLS Loss: 0.006336445454508066\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 4.724643230438232 | KNN Loss: 4.6756157875061035 | CLS Loss: 0.049027279019355774\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 4.7114386558532715 | KNN Loss: 4.703510284423828 | CLS Loss: 0.007928198203444481\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 4.7480010986328125 | KNN Loss: 4.739955425262451 | CLS Loss: 0.00804583914577961\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 4.699132442474365 | KNN Loss: 4.695522308349609 | CLS Loss: 0.003610184183344245\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 4.688587665557861 | KNN Loss: 4.683747291564941 | CLS Loss: 0.004840361885726452\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 4.685760498046875 | KNN Loss: 4.671638488769531 | CLS Loss: 0.014121838845312595\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 4.694784164428711 | KNN Loss: 4.670559406280518 | CLS Loss: 0.024224521592259407\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 4.748592376708984 | KNN Loss: 4.702831745147705 | CLS Loss: 0.045760784298181534\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 4.726931571960449 | KNN Loss: 4.715606689453125 | CLS Loss: 0.011324761435389519\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 4.697808265686035 | KNN Loss: 4.673933506011963 | CLS Loss: 0.023874539881944656\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 4.6975202560424805 | KNN Loss: 4.686895847320557 | CLS Loss: 0.010624592192471027\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 4.8011674880981445 | KNN Loss: 4.790930271148682 | CLS Loss: 0.010237111710011959\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 4.756145477294922 | KNN Loss: 4.726991176605225 | CLS Loss: 0.02915436215698719\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 4.708188533782959 | KNN Loss: 4.705323219299316 | CLS Loss: 0.0028651272878050804\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 4.757795333862305 | KNN Loss: 4.737038612365723 | CLS Loss: 0.020756632089614868\n",
      "Epoch: 077, Loss: 4.7055, Train: 0.9961, Valid: 0.9866, Best: 0.9872\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 4.742189407348633 | KNN Loss: 4.718315601348877 | CLS Loss: 0.023873625323176384\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 4.700061798095703 | KNN Loss: 4.691202163696289 | CLS Loss: 0.008859613910317421\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 4.678183555603027 | KNN Loss: 4.666903018951416 | CLS Loss: 0.011280303820967674\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 4.71231746673584 | KNN Loss: 4.702911853790283 | CLS Loss: 0.00940551795065403\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 4.788206577301025 | KNN Loss: 4.7409586906433105 | CLS Loss: 0.04724791646003723\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 4.711596965789795 | KNN Loss: 4.705282211303711 | CLS Loss: 0.006314604543149471\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 4.673755645751953 | KNN Loss: 4.670889854431152 | CLS Loss: 0.0028659203089773655\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 4.758364677429199 | KNN Loss: 4.7513861656188965 | CLS Loss: 0.006978459190577269\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 4.712191581726074 | KNN Loss: 4.678642749786377 | CLS Loss: 0.03354868292808533\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 4.68084716796875 | KNN Loss: 4.66166877746582 | CLS Loss: 0.01917850412428379\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 4.689961910247803 | KNN Loss: 4.6853346824646 | CLS Loss: 0.004627334885299206\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 4.673439025878906 | KNN Loss: 4.668298721313477 | CLS Loss: 0.005140149500221014\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 4.71034049987793 | KNN Loss: 4.6865153312683105 | CLS Loss: 0.02382500097155571\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 4.704302787780762 | KNN Loss: 4.686427593231201 | CLS Loss: 0.017875248566269875\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 4.72149658203125 | KNN Loss: 4.7132110595703125 | CLS Loss: 0.008285460993647575\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 4.674566268920898 | KNN Loss: 4.670537948608398 | CLS Loss: 0.004028460942208767\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 4.697192668914795 | KNN Loss: 4.665763854980469 | CLS Loss: 0.0314289815723896\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 4.674279689788818 | KNN Loss: 4.667514801025391 | CLS Loss: 0.0067649600096046925\n",
      "Epoch: 078, Loss: 4.7091, Train: 0.9965, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 4.693693161010742 | KNN Loss: 4.685186386108398 | CLS Loss: 0.008506781421601772\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 4.6986260414123535 | KNN Loss: 4.666819095611572 | CLS Loss: 0.031806908547878265\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 4.7247209548950195 | KNN Loss: 4.709333896636963 | CLS Loss: 0.015386893413960934\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 4.6966657638549805 | KNN Loss: 4.694142818450928 | CLS Loss: 0.0025230718310922384\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 4.666642665863037 | KNN Loss: 4.6612372398376465 | CLS Loss: 0.00540529191493988\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 4.658339977264404 | KNN Loss: 4.65421199798584 | CLS Loss: 0.004127878230065107\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 4.6883134841918945 | KNN Loss: 4.682425498962402 | CLS Loss: 0.005887794308364391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 4.728180885314941 | KNN Loss: 4.691195011138916 | CLS Loss: 0.03698594123125076\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 4.744700908660889 | KNN Loss: 4.724522113800049 | CLS Loss: 0.0201788991689682\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 4.811827182769775 | KNN Loss: 4.787870407104492 | CLS Loss: 0.023956604301929474\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 4.7140302658081055 | KNN Loss: 4.7020039558410645 | CLS Loss: 0.012026101350784302\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 4.77559232711792 | KNN Loss: 4.73651647567749 | CLS Loss: 0.039075929671525955\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 4.679646968841553 | KNN Loss: 4.671733856201172 | CLS Loss: 0.007913208566606045\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 4.733114242553711 | KNN Loss: 4.700106620788574 | CLS Loss: 0.0330076664686203\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 4.653071880340576 | KNN Loss: 4.649571418762207 | CLS Loss: 0.0035005758982151747\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 4.71516752243042 | KNN Loss: 4.691677570343018 | CLS Loss: 0.02349000796675682\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 4.740382194519043 | KNN Loss: 4.705448150634766 | CLS Loss: 0.03493384271860123\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 4.741693019866943 | KNN Loss: 4.7247185707092285 | CLS Loss: 0.016974374651908875\n",
      "Epoch: 079, Loss: 4.7112, Train: 0.9949, Valid: 0.9859, Best: 0.9872\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 4.694174766540527 | KNN Loss: 4.656463623046875 | CLS Loss: 0.03771092742681503\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 4.6830925941467285 | KNN Loss: 4.670690059661865 | CLS Loss: 0.012402570806443691\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 4.734620571136475 | KNN Loss: 4.72352933883667 | CLS Loss: 0.01109111774712801\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 4.667346000671387 | KNN Loss: 4.653584957122803 | CLS Loss: 0.013761268928647041\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 4.679722785949707 | KNN Loss: 4.674083232879639 | CLS Loss: 0.005639367271214724\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 4.6934967041015625 | KNN Loss: 4.670726299285889 | CLS Loss: 0.022770382463932037\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 4.716422080993652 | KNN Loss: 4.708334922790527 | CLS Loss: 0.008087079040706158\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 4.65658712387085 | KNN Loss: 4.645809650421143 | CLS Loss: 0.010777623392641544\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 4.720134735107422 | KNN Loss: 4.70762825012207 | CLS Loss: 0.012506422586739063\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 4.678584098815918 | KNN Loss: 4.668005466461182 | CLS Loss: 0.010578393936157227\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 4.6768107414245605 | KNN Loss: 4.670687675476074 | CLS Loss: 0.006123128812760115\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 4.710959434509277 | KNN Loss: 4.6989874839782715 | CLS Loss: 0.011971970088779926\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 4.694430351257324 | KNN Loss: 4.6697468757629395 | CLS Loss: 0.02468353696167469\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 4.695725440979004 | KNN Loss: 4.686269283294678 | CLS Loss: 0.00945616327226162\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 4.768564224243164 | KNN Loss: 4.7299065589904785 | CLS Loss: 0.038657475262880325\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 4.686420917510986 | KNN Loss: 4.664214611053467 | CLS Loss: 0.022206075489521027\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 4.697651386260986 | KNN Loss: 4.690058708190918 | CLS Loss: 0.007592721842229366\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 4.739469051361084 | KNN Loss: 4.7202911376953125 | CLS Loss: 0.019177893176674843\n",
      "Epoch: 080, Loss: 4.7058, Train: 0.9965, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 4.734795093536377 | KNN Loss: 4.718198776245117 | CLS Loss: 0.016596199944615364\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 4.685782432556152 | KNN Loss: 4.661108016967773 | CLS Loss: 0.02467450127005577\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 4.6758527755737305 | KNN Loss: 4.671372890472412 | CLS Loss: 0.004479785915464163\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 4.705423355102539 | KNN Loss: 4.6800103187561035 | CLS Loss: 0.02541290409862995\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 4.705563068389893 | KNN Loss: 4.6991705894470215 | CLS Loss: 0.006392523180693388\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 4.68687629699707 | KNN Loss: 4.684720516204834 | CLS Loss: 0.0021559481974691153\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 4.686537265777588 | KNN Loss: 4.678834915161133 | CLS Loss: 0.007702507544308901\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 4.6930460929870605 | KNN Loss: 4.686574459075928 | CLS Loss: 0.006471422966569662\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 4.7069315910339355 | KNN Loss: 4.683605194091797 | CLS Loss: 0.023326179012656212\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 4.732698440551758 | KNN Loss: 4.708852767944336 | CLS Loss: 0.02384590171277523\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 4.732352256774902 | KNN Loss: 4.726717948913574 | CLS Loss: 0.005634427070617676\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 4.76128625869751 | KNN Loss: 4.755258083343506 | CLS Loss: 0.0060280608013272285\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 4.675378322601318 | KNN Loss: 4.663660526275635 | CLS Loss: 0.01171785406768322\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 4.691975116729736 | KNN Loss: 4.67845344543457 | CLS Loss: 0.013521689921617508\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 4.690273284912109 | KNN Loss: 4.688241004943848 | CLS Loss: 0.002032429678365588\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 4.694597244262695 | KNN Loss: 4.658957481384277 | CLS Loss: 0.035639941692352295\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 4.693580627441406 | KNN Loss: 4.671971321105957 | CLS Loss: 0.021609490737318993\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 4.70680046081543 | KNN Loss: 4.696697235107422 | CLS Loss: 0.010103228501975536\n",
      "Epoch: 081, Loss: 4.7104, Train: 0.9955, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 4.6828532218933105 | KNN Loss: 4.666844367980957 | CLS Loss: 0.01600871980190277\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 4.698268413543701 | KNN Loss: 4.6851372718811035 | CLS Loss: 0.013130909763276577\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 4.732230186462402 | KNN Loss: 4.70727014541626 | CLS Loss: 0.024960078299045563\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 4.727895736694336 | KNN Loss: 4.696974754333496 | CLS Loss: 0.030921056866645813\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 4.660221099853516 | KNN Loss: 4.643601417541504 | CLS Loss: 0.016619710251688957\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 4.6784186363220215 | KNN Loss: 4.671689510345459 | CLS Loss: 0.006729083601385355\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 4.678865909576416 | KNN Loss: 4.6707258224487305 | CLS Loss: 0.008139978162944317\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 4.69359016418457 | KNN Loss: 4.688889503479004 | CLS Loss: 0.004700583405792713\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 4.682392120361328 | KNN Loss: 4.6733574867248535 | CLS Loss: 0.009034611284732819\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 4.677614212036133 | KNN Loss: 4.671457767486572 | CLS Loss: 0.006156450603157282\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 4.707840442657471 | KNN Loss: 4.698675155639648 | CLS Loss: 0.00916523952037096\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 4.7062458992004395 | KNN Loss: 4.679898738861084 | CLS Loss: 0.026347024366259575\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 4.68398380279541 | KNN Loss: 4.674030303955078 | CLS Loss: 0.009953583590686321\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 4.691899299621582 | KNN Loss: 4.668859481811523 | CLS Loss: 0.023039592429995537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 4.69216775894165 | KNN Loss: 4.683448791503906 | CLS Loss: 0.00871878769248724\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 4.6821112632751465 | KNN Loss: 4.658242702484131 | CLS Loss: 0.023868370801210403\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 4.659106731414795 | KNN Loss: 4.65635871887207 | CLS Loss: 0.002748072613030672\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 4.7101945877075195 | KNN Loss: 4.683586120605469 | CLS Loss: 0.026608334854245186\n",
      "Epoch: 082, Loss: 4.7005, Train: 0.9969, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 4.698898792266846 | KNN Loss: 4.681894302368164 | CLS Loss: 0.01700431853532791\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 4.673853397369385 | KNN Loss: 4.646125316619873 | CLS Loss: 0.027728192508220673\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 4.693404197692871 | KNN Loss: 4.680067539215088 | CLS Loss: 0.013336624018847942\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 4.717255115509033 | KNN Loss: 4.715692043304443 | CLS Loss: 0.0015628885012120008\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 4.70646858215332 | KNN Loss: 4.689705848693848 | CLS Loss: 0.016762610524892807\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 4.685171127319336 | KNN Loss: 4.681835651397705 | CLS Loss: 0.0033355760388076305\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 4.662033557891846 | KNN Loss: 4.655381679534912 | CLS Loss: 0.006651798728853464\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 4.683416366577148 | KNN Loss: 4.6714677810668945 | CLS Loss: 0.011948371306061745\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 4.694272518157959 | KNN Loss: 4.67561674118042 | CLS Loss: 0.018655898049473763\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 4.676236152648926 | KNN Loss: 4.664647102355957 | CLS Loss: 0.01158882211893797\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 4.685173988342285 | KNN Loss: 4.663589000701904 | CLS Loss: 0.021585164591670036\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 4.638858795166016 | KNN Loss: 4.634469032287598 | CLS Loss: 0.0043898699805140495\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 4.7055134773254395 | KNN Loss: 4.691948413848877 | CLS Loss: 0.013565274886786938\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 4.744115352630615 | KNN Loss: 4.716452121734619 | CLS Loss: 0.02766304835677147\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 4.675040245056152 | KNN Loss: 4.665807247161865 | CLS Loss: 0.009233012795448303\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 4.763838291168213 | KNN Loss: 4.719193935394287 | CLS Loss: 0.04464446008205414\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 4.748541355133057 | KNN Loss: 4.712905406951904 | CLS Loss: 0.03563574329018593\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 4.712670803070068 | KNN Loss: 4.693728923797607 | CLS Loss: 0.01894201710820198\n",
      "Epoch: 083, Loss: 4.7011, Train: 0.9943, Valid: 0.9841, Best: 0.9872\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 4.742084980010986 | KNN Loss: 4.722358703613281 | CLS Loss: 0.019726170226931572\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 4.662108898162842 | KNN Loss: 4.651351451873779 | CLS Loss: 0.010757665149867535\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 4.682460308074951 | KNN Loss: 4.67173957824707 | CLS Loss: 0.010720783844590187\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 4.725733757019043 | KNN Loss: 4.7171406745910645 | CLS Loss: 0.008593139238655567\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 4.664340019226074 | KNN Loss: 4.646076679229736 | CLS Loss: 0.018263285979628563\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 4.732659339904785 | KNN Loss: 4.724539279937744 | CLS Loss: 0.008120215497910976\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 4.73518705368042 | KNN Loss: 4.7008843421936035 | CLS Loss: 0.03430278226733208\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 4.677537441253662 | KNN Loss: 4.6418585777282715 | CLS Loss: 0.035678815096616745\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 4.703663349151611 | KNN Loss: 4.692259311676025 | CLS Loss: 0.01140426006168127\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 4.777941703796387 | KNN Loss: 4.7524333000183105 | CLS Loss: 0.025508543476462364\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 4.72157621383667 | KNN Loss: 4.70695686340332 | CLS Loss: 0.014619204215705395\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 4.677291393280029 | KNN Loss: 4.6707611083984375 | CLS Loss: 0.006530160084366798\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 4.6524739265441895 | KNN Loss: 4.646133899688721 | CLS Loss: 0.006339882500469685\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 4.739293098449707 | KNN Loss: 4.708094120025635 | CLS Loss: 0.03119892254471779\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 4.647385597229004 | KNN Loss: 4.643468379974365 | CLS Loss: 0.003917446825653315\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 4.672792434692383 | KNN Loss: 4.671298980712891 | CLS Loss: 0.0014935660874471068\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 4.697006702423096 | KNN Loss: 4.686822414398193 | CLS Loss: 0.010184277780354023\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 4.740785598754883 | KNN Loss: 4.72873067855835 | CLS Loss: 0.012054827064275742\n",
      "Epoch: 084, Loss: 4.7144, Train: 0.9949, Valid: 0.9860, Best: 0.9872\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 4.678042888641357 | KNN Loss: 4.673302173614502 | CLS Loss: 0.004740797448903322\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 4.7177605628967285 | KNN Loss: 4.706117630004883 | CLS Loss: 0.011642706580460072\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 4.705376625061035 | KNN Loss: 4.686384677886963 | CLS Loss: 0.018991859629750252\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 4.710418701171875 | KNN Loss: 4.699524402618408 | CLS Loss: 0.010894383303821087\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 4.797203063964844 | KNN Loss: 4.775103569030762 | CLS Loss: 0.022099483758211136\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 4.785581588745117 | KNN Loss: 4.781247138977051 | CLS Loss: 0.004334608092904091\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 4.67523717880249 | KNN Loss: 4.666197299957275 | CLS Loss: 0.00903965625911951\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 4.705345630645752 | KNN Loss: 4.692389011383057 | CLS Loss: 0.012956405058503151\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 4.714100360870361 | KNN Loss: 4.706892490386963 | CLS Loss: 0.00720804650336504\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 4.726390838623047 | KNN Loss: 4.709988594055176 | CLS Loss: 0.01640203408896923\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 4.721088886260986 | KNN Loss: 4.710634708404541 | CLS Loss: 0.010454279370605946\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 4.674800872802734 | KNN Loss: 4.665210247039795 | CLS Loss: 0.009590701200067997\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 4.682470798492432 | KNN Loss: 4.672366142272949 | CLS Loss: 0.010104565881192684\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 4.735188961029053 | KNN Loss: 4.731448650360107 | CLS Loss: 0.003740150248631835\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 4.721380710601807 | KNN Loss: 4.711323261260986 | CLS Loss: 0.010057623498141766\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 4.687544822692871 | KNN Loss: 4.663536071777344 | CLS Loss: 0.02400856278836727\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 4.708548069000244 | KNN Loss: 4.700934886932373 | CLS Loss: 0.0076133799739181995\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 4.7667646408081055 | KNN Loss: 4.757887840270996 | CLS Loss: 0.008876780979335308\n",
      "Epoch: 085, Loss: 4.7036, Train: 0.9964, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 4.693726062774658 | KNN Loss: 4.687437534332275 | CLS Loss: 0.006288548931479454\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 4.700437068939209 | KNN Loss: 4.69705867767334 | CLS Loss: 0.003378513967618346\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 4.735440254211426 | KNN Loss: 4.718713283538818 | CLS Loss: 0.016727054491639137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 4.678218364715576 | KNN Loss: 4.668631553649902 | CLS Loss: 0.009586694650352001\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 4.734948635101318 | KNN Loss: 4.722637176513672 | CLS Loss: 0.012311398051679134\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 4.696827411651611 | KNN Loss: 4.6686506271362305 | CLS Loss: 0.028176721185445786\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 4.713253498077393 | KNN Loss: 4.702340602874756 | CLS Loss: 0.010913092643022537\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 4.738593578338623 | KNN Loss: 4.718464374542236 | CLS Loss: 0.020129339769482613\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 4.6677680015563965 | KNN Loss: 4.6575751304626465 | CLS Loss: 0.010192830115556717\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 4.698948860168457 | KNN Loss: 4.6800432205200195 | CLS Loss: 0.018905552104115486\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 4.6785173416137695 | KNN Loss: 4.661759376525879 | CLS Loss: 0.016758188605308533\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 4.704184055328369 | KNN Loss: 4.693126201629639 | CLS Loss: 0.011057671159505844\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 4.705127716064453 | KNN Loss: 4.684449195861816 | CLS Loss: 0.020678488537669182\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 4.7304582595825195 | KNN Loss: 4.6771392822265625 | CLS Loss: 0.05331882834434509\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 4.71977424621582 | KNN Loss: 4.703509330749512 | CLS Loss: 0.0162649042904377\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 4.682229042053223 | KNN Loss: 4.665328025817871 | CLS Loss: 0.016901222988963127\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 4.705648422241211 | KNN Loss: 4.695953369140625 | CLS Loss: 0.009695140644907951\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 4.649279594421387 | KNN Loss: 4.632682800292969 | CLS Loss: 0.01659657433629036\n",
      "Epoch: 086, Loss: 4.7033, Train: 0.9968, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 4.668025493621826 | KNN Loss: 4.6526055335998535 | CLS Loss: 0.015419823117554188\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 4.696054935455322 | KNN Loss: 4.672740936279297 | CLS Loss: 0.023314151912927628\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 4.673455238342285 | KNN Loss: 4.66676139831543 | CLS Loss: 0.006694016978144646\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 4.704451560974121 | KNN Loss: 4.674585819244385 | CLS Loss: 0.02986551634967327\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 4.707589626312256 | KNN Loss: 4.706005096435547 | CLS Loss: 0.001584720565006137\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 4.70669412612915 | KNN Loss: 4.692298889160156 | CLS Loss: 0.014395110309123993\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 4.673891544342041 | KNN Loss: 4.6706318855285645 | CLS Loss: 0.003259622724726796\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 4.70062255859375 | KNN Loss: 4.696590900421143 | CLS Loss: 0.004031622316688299\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 4.7109599113464355 | KNN Loss: 4.7045416831970215 | CLS Loss: 0.006418062373995781\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 4.722708702087402 | KNN Loss: 4.697078227996826 | CLS Loss: 0.025630418211221695\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 4.684776306152344 | KNN Loss: 4.664396286010742 | CLS Loss: 0.02038024738430977\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 4.6662116050720215 | KNN Loss: 4.657899856567383 | CLS Loss: 0.008311745710670948\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 4.706767559051514 | KNN Loss: 4.672894477844238 | CLS Loss: 0.03387320786714554\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 4.655556678771973 | KNN Loss: 4.65287446975708 | CLS Loss: 0.002682012040168047\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 4.703671932220459 | KNN Loss: 4.6767897605896 | CLS Loss: 0.026882046833634377\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 4.676350116729736 | KNN Loss: 4.665878772735596 | CLS Loss: 0.010471152141690254\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 4.716351509094238 | KNN Loss: 4.699076175689697 | CLS Loss: 0.017275337129831314\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 4.680098056793213 | KNN Loss: 4.660725116729736 | CLS Loss: 0.019373146817088127\n",
      "Epoch: 087, Loss: 4.7024, Train: 0.9962, Valid: 0.9857, Best: 0.9872\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 4.723871231079102 | KNN Loss: 4.713766574859619 | CLS Loss: 0.01010467391461134\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 4.669841289520264 | KNN Loss: 4.664065361022949 | CLS Loss: 0.005775939207524061\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 4.669784069061279 | KNN Loss: 4.662613868713379 | CLS Loss: 0.007170314900577068\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 4.7911553382873535 | KNN Loss: 4.769377708435059 | CLS Loss: 0.021777598187327385\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 4.680233001708984 | KNN Loss: 4.657432556152344 | CLS Loss: 0.022800499573349953\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 4.757477760314941 | KNN Loss: 4.7478108406066895 | CLS Loss: 0.009666768833994865\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 4.719684600830078 | KNN Loss: 4.706266403198242 | CLS Loss: 0.013418328016996384\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 4.7154951095581055 | KNN Loss: 4.698482990264893 | CLS Loss: 0.017012106254696846\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 4.709680557250977 | KNN Loss: 4.697211742401123 | CLS Loss: 0.012468832544982433\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 4.730601787567139 | KNN Loss: 4.709923267364502 | CLS Loss: 0.020678505301475525\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 4.678650379180908 | KNN Loss: 4.6689372062683105 | CLS Loss: 0.009713216684758663\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 4.667522430419922 | KNN Loss: 4.653169631958008 | CLS Loss: 0.014352899044752121\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 4.704864025115967 | KNN Loss: 4.692507743835449 | CLS Loss: 0.012356222607195377\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 4.751060485839844 | KNN Loss: 4.731696605682373 | CLS Loss: 0.019363701343536377\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 4.726744174957275 | KNN Loss: 4.689189434051514 | CLS Loss: 0.03755461424589157\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 4.695106029510498 | KNN Loss: 4.663990497589111 | CLS Loss: 0.031115615740418434\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 4.68126916885376 | KNN Loss: 4.670933246612549 | CLS Loss: 0.010336004197597504\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 4.700937747955322 | KNN Loss: 4.674045085906982 | CLS Loss: 0.026892617344856262\n",
      "Epoch: 088, Loss: 4.7010, Train: 0.9958, Valid: 0.9851, Best: 0.9872\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 4.734249114990234 | KNN Loss: 4.730306625366211 | CLS Loss: 0.003942357841879129\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 4.700136184692383 | KNN Loss: 4.694530963897705 | CLS Loss: 0.005605109967291355\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 4.720186710357666 | KNN Loss: 4.709963798522949 | CLS Loss: 0.010222796350717545\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 4.699637413024902 | KNN Loss: 4.693154335021973 | CLS Loss: 0.006483034230768681\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 4.669281005859375 | KNN Loss: 4.66625452041626 | CLS Loss: 0.0030266514513641596\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 4.722860336303711 | KNN Loss: 4.717618465423584 | CLS Loss: 0.005241741426289082\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 4.656895637512207 | KNN Loss: 4.6307477951049805 | CLS Loss: 0.026148073375225067\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 4.6969451904296875 | KNN Loss: 4.669530868530273 | CLS Loss: 0.02741451933979988\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 4.728736877441406 | KNN Loss: 4.699096202850342 | CLS Loss: 0.029640579596161842\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 4.68040132522583 | KNN Loss: 4.6692328453063965 | CLS Loss: 0.011168698780238628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 4.696671962738037 | KNN Loss: 4.683212757110596 | CLS Loss: 0.013459126465022564\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 4.685176849365234 | KNN Loss: 4.669690132141113 | CLS Loss: 0.01548655703663826\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 4.692789077758789 | KNN Loss: 4.681221961975098 | CLS Loss: 0.011567292734980583\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 4.678859233856201 | KNN Loss: 4.669167518615723 | CLS Loss: 0.009691828861832619\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 4.731479167938232 | KNN Loss: 4.70622444152832 | CLS Loss: 0.025254879146814346\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 4.6768083572387695 | KNN Loss: 4.667814254760742 | CLS Loss: 0.008994298987090588\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 4.726377964019775 | KNN Loss: 4.714968681335449 | CLS Loss: 0.011409463360905647\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 4.695120334625244 | KNN Loss: 4.6849870681762695 | CLS Loss: 0.010133106261491776\n",
      "Epoch: 089, Loss: 4.6953, Train: 0.9963, Valid: 0.9864, Best: 0.9872\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 4.682436466217041 | KNN Loss: 4.675294876098633 | CLS Loss: 0.007141801528632641\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 4.693684101104736 | KNN Loss: 4.677299499511719 | CLS Loss: 0.01638472080230713\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 4.668759822845459 | KNN Loss: 4.648000240325928 | CLS Loss: 0.020759809762239456\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 4.690351486206055 | KNN Loss: 4.687088489532471 | CLS Loss: 0.003262943122535944\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 4.713661193847656 | KNN Loss: 4.692229747772217 | CLS Loss: 0.021431559696793556\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 4.674801826477051 | KNN Loss: 4.671266555786133 | CLS Loss: 0.003535354509949684\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 4.745405673980713 | KNN Loss: 4.721350193023682 | CLS Loss: 0.024055644869804382\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 4.70823860168457 | KNN Loss: 4.693808555603027 | CLS Loss: 0.014430084265768528\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 4.703113555908203 | KNN Loss: 4.687704563140869 | CLS Loss: 0.015408801846206188\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 4.74235200881958 | KNN Loss: 4.735233783721924 | CLS Loss: 0.007118095178157091\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 4.67495584487915 | KNN Loss: 4.655576229095459 | CLS Loss: 0.01937955431640148\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 4.675051689147949 | KNN Loss: 4.673065185546875 | CLS Loss: 0.0019863424822688103\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 4.66452169418335 | KNN Loss: 4.659961223602295 | CLS Loss: 0.004560636822134256\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 4.77827262878418 | KNN Loss: 4.744907379150391 | CLS Loss: 0.0333651527762413\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 4.691130638122559 | KNN Loss: 4.6789703369140625 | CLS Loss: 0.01216030027717352\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 4.711623191833496 | KNN Loss: 4.695619583129883 | CLS Loss: 0.01600365713238716\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 4.717235565185547 | KNN Loss: 4.693650722503662 | CLS Loss: 0.023584960028529167\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 4.714699745178223 | KNN Loss: 4.69865083694458 | CLS Loss: 0.01604912430047989\n",
      "Epoch: 090, Loss: 4.7029, Train: 0.9964, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 4.700738430023193 | KNN Loss: 4.693318843841553 | CLS Loss: 0.007419432979077101\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 4.693575859069824 | KNN Loss: 4.686730861663818 | CLS Loss: 0.006844864226877689\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 4.717382907867432 | KNN Loss: 4.691564083099365 | CLS Loss: 0.02581898123025894\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 4.732924461364746 | KNN Loss: 4.717015266418457 | CLS Loss: 0.015909122303128242\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 4.706283092498779 | KNN Loss: 4.695837497711182 | CLS Loss: 0.010445443913340569\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 4.680558204650879 | KNN Loss: 4.673117637634277 | CLS Loss: 0.007440357469022274\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 4.656144142150879 | KNN Loss: 4.651203632354736 | CLS Loss: 0.004940601997077465\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 4.696157932281494 | KNN Loss: 4.6709465980529785 | CLS Loss: 0.025211354717612267\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 4.692741870880127 | KNN Loss: 4.679564952850342 | CLS Loss: 0.013176699168980122\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 4.665131092071533 | KNN Loss: 4.650710105895996 | CLS Loss: 0.01442082691937685\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 4.679592609405518 | KNN Loss: 4.672404766082764 | CLS Loss: 0.007187970913946629\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 4.677515029907227 | KNN Loss: 4.670351028442383 | CLS Loss: 0.007164231035858393\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 4.6695051193237305 | KNN Loss: 4.663679122924805 | CLS Loss: 0.005825914908200502\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 4.712035655975342 | KNN Loss: 4.688596248626709 | CLS Loss: 0.02343958243727684\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 4.698156356811523 | KNN Loss: 4.677714824676514 | CLS Loss: 0.0204415712505579\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 4.727949619293213 | KNN Loss: 4.703351974487305 | CLS Loss: 0.02459760196506977\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 4.7495198249816895 | KNN Loss: 4.729445934295654 | CLS Loss: 0.020073818042874336\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 4.745112895965576 | KNN Loss: 4.717640399932861 | CLS Loss: 0.02747233211994171\n",
      "Epoch: 091, Loss: 4.7087, Train: 0.9952, Valid: 0.9869, Best: 0.9872\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 4.7080888748168945 | KNN Loss: 4.681189060211182 | CLS Loss: 0.026899775490164757\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 4.694015979766846 | KNN Loss: 4.665127754211426 | CLS Loss: 0.028887996450066566\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 4.71066427230835 | KNN Loss: 4.685329914093018 | CLS Loss: 0.025334451347589493\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 4.716977119445801 | KNN Loss: 4.680723667144775 | CLS Loss: 0.036253537982702255\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 4.683756351470947 | KNN Loss: 4.675507068634033 | CLS Loss: 0.008249210193753242\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 4.6644978523254395 | KNN Loss: 4.661090850830078 | CLS Loss: 0.0034068881068378687\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 4.703218936920166 | KNN Loss: 4.690215110778809 | CLS Loss: 0.013003897853195667\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 4.780719757080078 | KNN Loss: 4.742602825164795 | CLS Loss: 0.03811696544289589\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 4.736950397491455 | KNN Loss: 4.721299171447754 | CLS Loss: 0.01565144956111908\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 4.689382553100586 | KNN Loss: 4.677204132080078 | CLS Loss: 0.01217857375741005\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 4.727170944213867 | KNN Loss: 4.705605506896973 | CLS Loss: 0.02156561240553856\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 4.678646564483643 | KNN Loss: 4.668755054473877 | CLS Loss: 0.009891625493764877\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 4.704315185546875 | KNN Loss: 4.682128429412842 | CLS Loss: 0.022186655551195145\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 4.657669544219971 | KNN Loss: 4.6533203125 | CLS Loss: 0.0043490370735526085\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 4.7128119468688965 | KNN Loss: 4.688623428344727 | CLS Loss: 0.02418830431997776\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 4.69340181350708 | KNN Loss: 4.678103923797607 | CLS Loss: 0.015297762118279934\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 4.6865620613098145 | KNN Loss: 4.677675724029541 | CLS Loss: 0.008886285126209259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 4.696181297302246 | KNN Loss: 4.677591800689697 | CLS Loss: 0.01858963444828987\n",
      "Epoch: 092, Loss: 4.7105, Train: 0.9964, Valid: 0.9859, Best: 0.9872\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 4.6847028732299805 | KNN Loss: 4.680771827697754 | CLS Loss: 0.003931147512048483\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 4.655590534210205 | KNN Loss: 4.651773452758789 | CLS Loss: 0.0038171089254319668\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 4.789667129516602 | KNN Loss: 4.769301414489746 | CLS Loss: 0.020365657284855843\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 4.728115081787109 | KNN Loss: 4.700418472290039 | CLS Loss: 0.02769654430449009\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 4.697596073150635 | KNN Loss: 4.6905694007873535 | CLS Loss: 0.007026592269539833\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 4.691486835479736 | KNN Loss: 4.673923015594482 | CLS Loss: 0.017563797533512115\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 4.813193321228027 | KNN Loss: 4.788944721221924 | CLS Loss: 0.024248482659459114\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 4.679189205169678 | KNN Loss: 4.669376373291016 | CLS Loss: 0.00981272291392088\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 4.651048183441162 | KNN Loss: 4.630156993865967 | CLS Loss: 0.020891325548291206\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 4.691539287567139 | KNN Loss: 4.68010950088501 | CLS Loss: 0.0114296805113554\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 4.723654270172119 | KNN Loss: 4.711445331573486 | CLS Loss: 0.012208735570311546\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 4.7151384353637695 | KNN Loss: 4.686546325683594 | CLS Loss: 0.028591951355338097\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 4.665294170379639 | KNN Loss: 4.652403831481934 | CLS Loss: 0.012890268117189407\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 4.68463659286499 | KNN Loss: 4.671199321746826 | CLS Loss: 0.013437144458293915\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 4.680610656738281 | KNN Loss: 4.675919532775879 | CLS Loss: 0.004690953064709902\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 4.707028388977051 | KNN Loss: 4.691074848175049 | CLS Loss: 0.015953700989484787\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 4.689382553100586 | KNN Loss: 4.680456161499023 | CLS Loss: 0.008926366455852985\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 4.681631088256836 | KNN Loss: 4.67277717590332 | CLS Loss: 0.008854021318256855\n",
      "Epoch: 093, Loss: 4.6986, Train: 0.9967, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 4.718698501586914 | KNN Loss: 4.700412750244141 | CLS Loss: 0.01828569360077381\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 4.771916389465332 | KNN Loss: 4.765721321105957 | CLS Loss: 0.006194853223860264\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 4.724827766418457 | KNN Loss: 4.721120834350586 | CLS Loss: 0.003706963500007987\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 4.702488899230957 | KNN Loss: 4.698866844177246 | CLS Loss: 0.003621854819357395\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 4.669200420379639 | KNN Loss: 4.646240234375 | CLS Loss: 0.022959988564252853\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 4.684092044830322 | KNN Loss: 4.662961006164551 | CLS Loss: 0.021131206303834915\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 4.680331707000732 | KNN Loss: 4.672506809234619 | CLS Loss: 0.007824817672371864\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 4.69909143447876 | KNN Loss: 4.688631534576416 | CLS Loss: 0.010460137389600277\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 4.692042350769043 | KNN Loss: 4.6793389320373535 | CLS Loss: 0.012703590095043182\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 4.728855133056641 | KNN Loss: 4.710605144500732 | CLS Loss: 0.01825018599629402\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 4.641932010650635 | KNN Loss: 4.63295316696167 | CLS Loss: 0.008978711441159248\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 4.74752950668335 | KNN Loss: 4.693431377410889 | CLS Loss: 0.05409809201955795\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 4.7148003578186035 | KNN Loss: 4.7058210372924805 | CLS Loss: 0.008979235775768757\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 4.688574314117432 | KNN Loss: 4.672851085662842 | CLS Loss: 0.015723060816526413\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 4.699917316436768 | KNN Loss: 4.696264743804932 | CLS Loss: 0.003652620827779174\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 4.684946537017822 | KNN Loss: 4.677150249481201 | CLS Loss: 0.007796307560056448\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 4.727622032165527 | KNN Loss: 4.720663070678711 | CLS Loss: 0.006958844605833292\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 4.713459014892578 | KNN Loss: 4.695201873779297 | CLS Loss: 0.01825729012489319\n",
      "Epoch: 094, Loss: 4.7020, Train: 0.9965, Valid: 0.9872, Best: 0.9872\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 4.721341133117676 | KNN Loss: 4.716799736022949 | CLS Loss: 0.004541345406323671\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 4.708273887634277 | KNN Loss: 4.6985368728637695 | CLS Loss: 0.009736941196024418\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 4.670037269592285 | KNN Loss: 4.667677402496338 | CLS Loss: 0.0023599578998982906\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 4.6898193359375 | KNN Loss: 4.682342529296875 | CLS Loss: 0.007476971484720707\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 4.714994430541992 | KNN Loss: 4.699528694152832 | CLS Loss: 0.015465691685676575\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 4.710105895996094 | KNN Loss: 4.68118143081665 | CLS Loss: 0.028924424201250076\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 4.7499680519104 | KNN Loss: 4.738729000091553 | CLS Loss: 0.011239076033234596\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 4.698997974395752 | KNN Loss: 4.671477794647217 | CLS Loss: 0.02752012573182583\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 4.703719139099121 | KNN Loss: 4.6982245445251465 | CLS Loss: 0.005494514014571905\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 4.698702335357666 | KNN Loss: 4.681220531463623 | CLS Loss: 0.017481796443462372\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 4.649740695953369 | KNN Loss: 4.6459150314331055 | CLS Loss: 0.0038255788385868073\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 4.7130842208862305 | KNN Loss: 4.702686309814453 | CLS Loss: 0.01039767824113369\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 4.68857479095459 | KNN Loss: 4.672703742980957 | CLS Loss: 0.015871085226535797\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 4.746710777282715 | KNN Loss: 4.722763538360596 | CLS Loss: 0.023947015404701233\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 4.7606401443481445 | KNN Loss: 4.749591827392578 | CLS Loss: 0.011048302054405212\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 4.693321704864502 | KNN Loss: 4.6807637214660645 | CLS Loss: 0.012557887472212315\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 4.658079147338867 | KNN Loss: 4.656108856201172 | CLS Loss: 0.001970202662050724\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 4.69447135925293 | KNN Loss: 4.69209098815918 | CLS Loss: 0.002380309859290719\n",
      "Epoch: 095, Loss: 4.7016, Train: 0.9968, Valid: 0.9865, Best: 0.9872\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 4.782754898071289 | KNN Loss: 4.745939254760742 | CLS Loss: 0.03681585192680359\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 4.681308746337891 | KNN Loss: 4.6673712730407715 | CLS Loss: 0.013937240466475487\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 4.756577491760254 | KNN Loss: 4.753042221069336 | CLS Loss: 0.00353540969081223\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 4.70664119720459 | KNN Loss: 4.681459903717041 | CLS Loss: 0.02518128789961338\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 4.670293807983398 | KNN Loss: 4.666202545166016 | CLS Loss: 0.0040912628173828125\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 4.7736310958862305 | KNN Loss: 4.753453254699707 | CLS Loss: 0.02017797902226448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 4.715567588806152 | KNN Loss: 4.693706035614014 | CLS Loss: 0.021861374378204346\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 4.68407678604126 | KNN Loss: 4.6768059730529785 | CLS Loss: 0.007270941976457834\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 4.700981616973877 | KNN Loss: 4.687576770782471 | CLS Loss: 0.01340483222156763\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 4.694089889526367 | KNN Loss: 4.668557167053223 | CLS Loss: 0.02553291618824005\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 4.676794052124023 | KNN Loss: 4.664745807647705 | CLS Loss: 0.01204825658351183\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 4.658322811126709 | KNN Loss: 4.649949550628662 | CLS Loss: 0.008373203687369823\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 4.710494518280029 | KNN Loss: 4.7052693367004395 | CLS Loss: 0.005225078668445349\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 4.706723213195801 | KNN Loss: 4.690600395202637 | CLS Loss: 0.01612301729619503\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 4.686532497406006 | KNN Loss: 4.6686530113220215 | CLS Loss: 0.017879270017147064\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 4.754839897155762 | KNN Loss: 4.734221458435059 | CLS Loss: 0.020618589594960213\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 4.693885803222656 | KNN Loss: 4.678655624389648 | CLS Loss: 0.01523031760007143\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 4.674182891845703 | KNN Loss: 4.666685581207275 | CLS Loss: 0.007497161626815796\n",
      "Epoch: 096, Loss: 4.6994, Train: 0.9962, Valid: 0.9867, Best: 0.9872\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 4.713688373565674 | KNN Loss: 4.701198577880859 | CLS Loss: 0.012490023858845234\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 4.692115783691406 | KNN Loss: 4.674465179443359 | CLS Loss: 0.017650391906499863\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 4.665888786315918 | KNN Loss: 4.664730072021484 | CLS Loss: 0.0011586546897888184\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 4.729506492614746 | KNN Loss: 4.723443031311035 | CLS Loss: 0.0060636685229837894\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 4.687764644622803 | KNN Loss: 4.677487373352051 | CLS Loss: 0.010277374647557735\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 4.723505020141602 | KNN Loss: 4.702740669250488 | CLS Loss: 0.0207643061876297\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 4.668888092041016 | KNN Loss: 4.666881561279297 | CLS Loss: 0.002006581285968423\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 4.71467924118042 | KNN Loss: 4.693060874938965 | CLS Loss: 0.021618522703647614\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 4.67976713180542 | KNN Loss: 4.668750286102295 | CLS Loss: 0.01101696863770485\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 4.666140556335449 | KNN Loss: 4.651006698608398 | CLS Loss: 0.015133799985051155\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 4.719297409057617 | KNN Loss: 4.687099456787109 | CLS Loss: 0.03219807520508766\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 4.689352989196777 | KNN Loss: 4.682376384735107 | CLS Loss: 0.006976723205298185\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 4.66196870803833 | KNN Loss: 4.648308277130127 | CLS Loss: 0.01366026233881712\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 4.705254554748535 | KNN Loss: 4.68344259262085 | CLS Loss: 0.02181205525994301\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 4.711533546447754 | KNN Loss: 4.6996846199035645 | CLS Loss: 0.011848977766931057\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 4.641902923583984 | KNN Loss: 4.638686180114746 | CLS Loss: 0.0032167788594961166\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 4.6831278800964355 | KNN Loss: 4.668063640594482 | CLS Loss: 0.015064205974340439\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 4.668944358825684 | KNN Loss: 4.65269660949707 | CLS Loss: 0.016247553750872612\n",
      "Epoch: 097, Loss: 4.7064, Train: 0.9966, Valid: 0.9862, Best: 0.9872\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 4.677968502044678 | KNN Loss: 4.675475120544434 | CLS Loss: 0.0024935919791460037\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 4.719942092895508 | KNN Loss: 4.718332767486572 | CLS Loss: 0.0016094900202006102\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 4.690722465515137 | KNN Loss: 4.681971549987793 | CLS Loss: 0.008750824257731438\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 4.760606288909912 | KNN Loss: 4.759249210357666 | CLS Loss: 0.0013570634182542562\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 4.707882881164551 | KNN Loss: 4.684892177581787 | CLS Loss: 0.022990886121988297\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 4.699019432067871 | KNN Loss: 4.665578842163086 | CLS Loss: 0.03344069421291351\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 4.662161827087402 | KNN Loss: 4.6560211181640625 | CLS Loss: 0.0061409445479512215\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 4.736953258514404 | KNN Loss: 4.728980541229248 | CLS Loss: 0.007972546853125095\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 4.6833906173706055 | KNN Loss: 4.672410488128662 | CLS Loss: 0.010979946702718735\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 4.733148574829102 | KNN Loss: 4.700069427490234 | CLS Loss: 0.033079080283641815\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 4.663786888122559 | KNN Loss: 4.655952453613281 | CLS Loss: 0.007834197022020817\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 4.734889030456543 | KNN Loss: 4.717932224273682 | CLS Loss: 0.01695701852440834\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 4.650990962982178 | KNN Loss: 4.6422529220581055 | CLS Loss: 0.00873781368136406\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 4.696086883544922 | KNN Loss: 4.6911940574646 | CLS Loss: 0.0048926337622106075\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 4.705976486206055 | KNN Loss: 4.698482990264893 | CLS Loss: 0.007493569515645504\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 4.694526195526123 | KNN Loss: 4.683954238891602 | CLS Loss: 0.01057215966284275\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 4.721185684204102 | KNN Loss: 4.703530311584473 | CLS Loss: 0.017655184492468834\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 4.691356658935547 | KNN Loss: 4.674341201782227 | CLS Loss: 0.017015604302287102\n",
      "Epoch: 098, Loss: 4.7000, Train: 0.9963, Valid: 0.9871, Best: 0.9872\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 4.6760077476501465 | KNN Loss: 4.674602508544922 | CLS Loss: 0.0014051968464627862\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 4.6681318283081055 | KNN Loss: 4.665645122528076 | CLS Loss: 0.0024864852894097567\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 4.715762138366699 | KNN Loss: 4.71232271194458 | CLS Loss: 0.0034394823014736176\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 4.655094146728516 | KNN Loss: 4.643199443817139 | CLS Loss: 0.011894562281668186\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 4.667413711547852 | KNN Loss: 4.665689945220947 | CLS Loss: 0.0017237673746421933\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 4.700718402862549 | KNN Loss: 4.681722164154053 | CLS Loss: 0.018996119499206543\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 4.737207412719727 | KNN Loss: 4.696383476257324 | CLS Loss: 0.0408238023519516\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 4.7745256423950195 | KNN Loss: 4.7627058029174805 | CLS Loss: 0.011819995008409023\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 4.745499610900879 | KNN Loss: 4.71939754486084 | CLS Loss: 0.02610214427113533\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 4.688239574432373 | KNN Loss: 4.67794942855835 | CLS Loss: 0.010290324687957764\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 4.690794944763184 | KNN Loss: 4.687474727630615 | CLS Loss: 0.0033204134088009596\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 4.833401203155518 | KNN Loss: 4.818355083465576 | CLS Loss: 0.015046283602714539\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 4.775653839111328 | KNN Loss: 4.765872955322266 | CLS Loss: 0.009780708700418472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 4.736800670623779 | KNN Loss: 4.686923980712891 | CLS Loss: 0.04987671226263046\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 4.702376365661621 | KNN Loss: 4.692188739776611 | CLS Loss: 0.010187593288719654\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 4.709314346313477 | KNN Loss: 4.698884963989258 | CLS Loss: 0.01042957417666912\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 4.7336812019348145 | KNN Loss: 4.706918716430664 | CLS Loss: 0.02676249109208584\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 4.706286907196045 | KNN Loss: 4.699099063873291 | CLS Loss: 0.007187775336205959\n",
      "Epoch: 099, Loss: 4.7095, Train: 0.9960, Valid: 0.9858, Best: 0.9872\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 4.689737796783447 | KNN Loss: 4.677109241485596 | CLS Loss: 0.012628618627786636\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 4.661083698272705 | KNN Loss: 4.643423557281494 | CLS Loss: 0.01766018196940422\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 4.67326021194458 | KNN Loss: 4.670028209686279 | CLS Loss: 0.003232042072340846\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 4.66906213760376 | KNN Loss: 4.650912761688232 | CLS Loss: 0.018149320036172867\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 4.692038059234619 | KNN Loss: 4.685201644897461 | CLS Loss: 0.006836306769400835\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 4.693256378173828 | KNN Loss: 4.690070152282715 | CLS Loss: 0.003186001442372799\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 4.700400352478027 | KNN Loss: 4.68032169342041 | CLS Loss: 0.020078565925359726\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 4.734853267669678 | KNN Loss: 4.7098307609558105 | CLS Loss: 0.025022493675351143\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 4.673500061035156 | KNN Loss: 4.6707987785339355 | CLS Loss: 0.0027011975180357695\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 4.677245140075684 | KNN Loss: 4.67399263381958 | CLS Loss: 0.0032526953145861626\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 4.712594509124756 | KNN Loss: 4.702945232391357 | CLS Loss: 0.00964917242527008\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 4.707974910736084 | KNN Loss: 4.689654350280762 | CLS Loss: 0.01832062192261219\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 4.687770843505859 | KNN Loss: 4.678356647491455 | CLS Loss: 0.00941440835595131\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 4.733322620391846 | KNN Loss: 4.725582122802734 | CLS Loss: 0.00774048175662756\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 4.680936813354492 | KNN Loss: 4.667171478271484 | CLS Loss: 0.013765565119683743\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 4.695596218109131 | KNN Loss: 4.671566009521484 | CLS Loss: 0.024030368775129318\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 4.739665508270264 | KNN Loss: 4.710124492645264 | CLS Loss: 0.02954086847603321\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 4.724038124084473 | KNN Loss: 4.69734525680542 | CLS Loss: 0.026692861691117287\n",
      "Epoch: 100, Loss: 4.7046, Train: 0.9928, Valid: 0.9836, Best: 0.9872\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 4.7214837074279785 | KNN Loss: 4.702719211578369 | CLS Loss: 0.01876472681760788\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 4.656217098236084 | KNN Loss: 4.651917457580566 | CLS Loss: 0.004299822263419628\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 4.717781066894531 | KNN Loss: 4.711200714111328 | CLS Loss: 0.006580447778105736\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 4.705712795257568 | KNN Loss: 4.683713436126709 | CLS Loss: 0.021999532356858253\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 4.68643856048584 | KNN Loss: 4.670511245727539 | CLS Loss: 0.015927424654364586\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 4.6855974197387695 | KNN Loss: 4.679652690887451 | CLS Loss: 0.00594483083114028\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 4.712167263031006 | KNN Loss: 4.666207790374756 | CLS Loss: 0.0459594801068306\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 4.6543684005737305 | KNN Loss: 4.650961399078369 | CLS Loss: 0.003406831994652748\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 4.700224876403809 | KNN Loss: 4.6754150390625 | CLS Loss: 0.024809693917632103\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 4.708462715148926 | KNN Loss: 4.6891350746154785 | CLS Loss: 0.019327636808156967\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 4.709208965301514 | KNN Loss: 4.673228740692139 | CLS Loss: 0.03598002716898918\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 4.680673599243164 | KNN Loss: 4.675537109375 | CLS Loss: 0.005136617925018072\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 4.687283992767334 | KNN Loss: 4.6845383644104 | CLS Loss: 0.0027455235831439495\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 4.684238910675049 | KNN Loss: 4.667637825012207 | CLS Loss: 0.016601206734776497\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 4.639819145202637 | KNN Loss: 4.620495796203613 | CLS Loss: 0.019323304295539856\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 4.698697566986084 | KNN Loss: 4.676117897033691 | CLS Loss: 0.022579718381166458\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 4.723768711090088 | KNN Loss: 4.689586639404297 | CLS Loss: 0.03418208286166191\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 4.690585613250732 | KNN Loss: 4.682817459106445 | CLS Loss: 0.00776815228164196\n",
      "Epoch: 101, Loss: 4.6987, Train: 0.9945, Valid: 0.9844, Best: 0.9872\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 4.688669204711914 | KNN Loss: 4.683102607727051 | CLS Loss: 0.005566734354943037\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 4.739330768585205 | KNN Loss: 4.713161945343018 | CLS Loss: 0.026168987154960632\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 4.802712440490723 | KNN Loss: 4.789653778076172 | CLS Loss: 0.013058456592261791\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 4.786282062530518 | KNN Loss: 4.75652551651001 | CLS Loss: 0.029756594449281693\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 4.7024970054626465 | KNN Loss: 4.681939601898193 | CLS Loss: 0.02055756375193596\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 4.725457191467285 | KNN Loss: 4.723962783813477 | CLS Loss: 0.0014942616689950228\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 4.686427593231201 | KNN Loss: 4.668832302093506 | CLS Loss: 0.017595188692212105\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 4.694501876831055 | KNN Loss: 4.688386917114258 | CLS Loss: 0.006114913150668144\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 4.680171012878418 | KNN Loss: 4.671898365020752 | CLS Loss: 0.008272846229374409\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 4.675171375274658 | KNN Loss: 4.670090675354004 | CLS Loss: 0.0050808219239115715\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 4.6602606773376465 | KNN Loss: 4.658743858337402 | CLS Loss: 0.001516632386483252\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 4.707602500915527 | KNN Loss: 4.67972469329834 | CLS Loss: 0.027877897024154663\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 4.674266815185547 | KNN Loss: 4.66808557510376 | CLS Loss: 0.0061814566142857075\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 4.76252555847168 | KNN Loss: 4.735949516296387 | CLS Loss: 0.02657606452703476\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 4.7517409324646 | KNN Loss: 4.746203899383545 | CLS Loss: 0.005536864977329969\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 4.671627521514893 | KNN Loss: 4.668567180633545 | CLS Loss: 0.0030604808125644922\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 4.695828914642334 | KNN Loss: 4.689976215362549 | CLS Loss: 0.005852649454027414\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 4.683082580566406 | KNN Loss: 4.673954963684082 | CLS Loss: 0.009127499535679817\n",
      "Epoch: 102, Loss: 4.7030, Train: 0.9971, Valid: 0.9859, Best: 0.9872\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 4.703843116760254 | KNN Loss: 4.69710111618042 | CLS Loss: 0.0067419977858662605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 4.678947925567627 | KNN Loss: 4.6758270263671875 | CLS Loss: 0.0031210239976644516\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 4.65442419052124 | KNN Loss: 4.6470770835876465 | CLS Loss: 0.007346881553530693\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 4.6808648109436035 | KNN Loss: 4.672391891479492 | CLS Loss: 0.008472945541143417\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 4.759029388427734 | KNN Loss: 4.7434797286987305 | CLS Loss: 0.015549637377262115\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 4.728278160095215 | KNN Loss: 4.719176292419434 | CLS Loss: 0.009101921692490578\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 4.678065776824951 | KNN Loss: 4.6706109046936035 | CLS Loss: 0.007454941049218178\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 4.651780605316162 | KNN Loss: 4.64718770980835 | CLS Loss: 0.0045930808410048485\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 4.657245635986328 | KNN Loss: 4.652898788452148 | CLS Loss: 0.00434679351747036\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 4.729494094848633 | KNN Loss: 4.701395511627197 | CLS Loss: 0.02809876948595047\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 4.67445707321167 | KNN Loss: 4.664077281951904 | CLS Loss: 0.010379855521023273\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 4.68490743637085 | KNN Loss: 4.677553176879883 | CLS Loss: 0.007354232016950846\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 4.771124839782715 | KNN Loss: 4.749949932098389 | CLS Loss: 0.02117493934929371\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 4.680897235870361 | KNN Loss: 4.668471813201904 | CLS Loss: 0.012425611726939678\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 4.680849552154541 | KNN Loss: 4.6602582931518555 | CLS Loss: 0.02059127949178219\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 4.675495147705078 | KNN Loss: 4.665555953979492 | CLS Loss: 0.009939031675457954\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 4.704614639282227 | KNN Loss: 4.673231601715088 | CLS Loss: 0.03138291463255882\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 4.681671142578125 | KNN Loss: 4.677351474761963 | CLS Loss: 0.004319505300372839\n",
      "Epoch: 103, Loss: 4.7005, Train: 0.9969, Valid: 0.9861, Best: 0.9872\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 4.666707515716553 | KNN Loss: 4.665114402770996 | CLS Loss: 0.0015932567184790969\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 4.672398090362549 | KNN Loss: 4.663314342498779 | CLS Loss: 0.009083922021090984\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 4.695754051208496 | KNN Loss: 4.663354396820068 | CLS Loss: 0.032399874180555344\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 4.723034858703613 | KNN Loss: 4.7192063331604 | CLS Loss: 0.003828483633697033\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 4.736784934997559 | KNN Loss: 4.719557285308838 | CLS Loss: 0.017227431759238243\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 4.694238662719727 | KNN Loss: 4.691534042358398 | CLS Loss: 0.0027044303715229034\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 4.678146839141846 | KNN Loss: 4.671028137207031 | CLS Loss: 0.007118816487491131\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 4.715524196624756 | KNN Loss: 4.698163032531738 | CLS Loss: 0.017361249774694443\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 4.684451580047607 | KNN Loss: 4.660820484161377 | CLS Loss: 0.023631300777196884\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 4.707181453704834 | KNN Loss: 4.68100118637085 | CLS Loss: 0.02618042565882206\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 4.674908638000488 | KNN Loss: 4.669276714324951 | CLS Loss: 0.005631950218230486\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 4.697436809539795 | KNN Loss: 4.692398548126221 | CLS Loss: 0.005038052797317505\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 4.6939287185668945 | KNN Loss: 4.683563232421875 | CLS Loss: 0.01036557462066412\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 4.684701442718506 | KNN Loss: 4.675524711608887 | CLS Loss: 0.009176759049296379\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 4.699940204620361 | KNN Loss: 4.685413837432861 | CLS Loss: 0.014526311308145523\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 4.725557327270508 | KNN Loss: 4.72046422958374 | CLS Loss: 0.005092974752187729\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 4.657081604003906 | KNN Loss: 4.645374298095703 | CLS Loss: 0.011707291938364506\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 4.6714043617248535 | KNN Loss: 4.646826267242432 | CLS Loss: 0.024577997624874115\n",
      "Epoch: 104, Loss: 4.7042, Train: 0.9956, Valid: 0.9860, Best: 0.9872\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 4.75435733795166 | KNN Loss: 4.750975131988525 | CLS Loss: 0.0033820278476923704\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 4.727866172790527 | KNN Loss: 4.716620922088623 | CLS Loss: 0.011245276778936386\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 4.697545051574707 | KNN Loss: 4.68880033493042 | CLS Loss: 0.008744601160287857\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 4.671907901763916 | KNN Loss: 4.654331207275391 | CLS Loss: 0.017576487734913826\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 4.698353290557861 | KNN Loss: 4.669417858123779 | CLS Loss: 0.028935274109244347\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 4.702012538909912 | KNN Loss: 4.697356700897217 | CLS Loss: 0.004655672237277031\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 4.644864082336426 | KNN Loss: 4.636277675628662 | CLS Loss: 0.008586317300796509\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 4.677181243896484 | KNN Loss: 4.6684651374816895 | CLS Loss: 0.008716322481632233\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 4.710536479949951 | KNN Loss: 4.688913345336914 | CLS Loss: 0.021622933447360992\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 4.6824517250061035 | KNN Loss: 4.6695122718811035 | CLS Loss: 0.012939564883708954\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 4.69364595413208 | KNN Loss: 4.687877655029297 | CLS Loss: 0.0057680741883814335\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 4.656067848205566 | KNN Loss: 4.640476226806641 | CLS Loss: 0.015591397881507874\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 4.63889741897583 | KNN Loss: 4.618795394897461 | CLS Loss: 0.020101917907595634\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 4.716489315032959 | KNN Loss: 4.709496974945068 | CLS Loss: 0.006992300972342491\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 4.700743675231934 | KNN Loss: 4.690537929534912 | CLS Loss: 0.01020552683621645\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
